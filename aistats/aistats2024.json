[
    {
        "id": "1e99751b70",
        "title": "A 4-Approximation Algorithm for Min Max Correlation Clustering",
        "site": "https://proceedings.mlr.press/v238/heidrich24a.html",
        "author": "Holger S. G. Heidrich; Jannik Irmai; Bjoern Andres",
        "abstract": "We introduce a lower bounding technique for the min max correlation clustering problem and, based on this technique, a combinatorial 4-approximation algorithm for complete graphs. This improves upon the previous best known approximation guarantees of 5, using a linear program formulation (Kalhan et al., 2019), and 40, for a combinatorial algorithm (Davies et al., 2023). We extend this algorithm by a greedy joining heuristic and show empirically that it improves the state of the art in solution quality and runtime on several benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v238-heidrich24a,\n  title = \t {A 4-Approximation Algorithm for Min Max Correlation Clustering},\n  author =       {Heidrich, Holger S. G. and Irmai, Jannik and Andres, Bjoern},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1945--1953},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/heidrich24a/heidrich24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/heidrich24a.html},\n  abstract = \t {We introduce a lower bounding technique for the min max correlation clustering problem and, based on this technique, a combinatorial 4-approximation algorithm for complete graphs. This improves upon the previous best known approximation guarantees of 5, using a linear program formulation (Kalhan et al., 2019), and 40, for a combinatorial algorithm (Davies et al., 2023). We extend this algorithm by a greedy joining heuristic and show empirically that it improves the state of the art in solution quality and runtime on several benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/heidrich24a/heidrich24a.pdf",
        "supp": "",
        "pdf_size": 783689,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16509175896794813899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a8eb7600a7",
        "title": "A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent",
        "site": "https://proceedings.mlr.press/v238/jafarnia-jahromi24a.html",
        "author": "Mehdi Jafarnia Jahromi; Rahul A Jain; Ashutosh Nayyar",
        "abstract": "In this paper, we propose Posterior Sampling Reinforcement Learning for Zero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that achieves Bayesian regret bound of $\\tilde\\mathcal{O}(HS\\sqrt{AT})$ in the infinite-horizon zero-sum stochastic games with average-reward criterion. Here $H$ is an upper bound on the span of the bias function, $S$ is the number of states, $A$ is the number of joint actions and $T$ is the horizon. We consider the online setting where the opponent can not be controlled and can take any arbitrary time-adaptive history-dependent strategy. Our regret bound improves on the best existing regret bound of $\\tilde\\mathcal{O}(\\sqrt[3]{DS^2AT^2})$ by Wei et al., (2017) under the same assumption and matches the theoretical lower bound in $T$.",
        "bibtex": "@InProceedings{pmlr-v238-jafarnia-jahromi24a,\n  title = \t {A {B}ayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent},\n  author =       {Jafarnia Jahromi, Mehdi and A Jain, Rahul and Nayyar, Ashutosh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3880--3888},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jafarnia-jahromi24a/jafarnia-jahromi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jafarnia-jahromi24a.html},\n  abstract = \t {In this paper, we propose Posterior Sampling Reinforcement Learning for Zero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that achieves Bayesian regret bound of $\\tilde\\mathcal{O}(HS\\sqrt{AT})$ in the infinite-horizon zero-sum stochastic games with average-reward criterion. Here $H$ is an upper bound on the span of the bias function, $S$ is the number of states, $A$ is the number of joint actions and $T$ is the horizon. We consider the online setting where the opponent can not be controlled and can take any arbitrary time-adaptive history-dependent strategy. Our regret bound improves on the best existing regret bound of $\\tilde\\mathcal{O}(\\sqrt[3]{DS^2AT^2})$ by Wei et al., (2017) under the same assumption and matches the theoretical lower bound in $T$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jafarnia-jahromi24a/jafarnia-jahromi24a.pdf",
        "supp": "",
        "pdf_size": 427621,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16301245012516659972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ca5fc48104",
        "title": "A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/maniyar24a.html",
        "author": "Mizhaan P. Maniyar; Prashanth L.A.; Akash Mondal; Shalabh Bhatnagar",
        "abstract": "We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an $\\epsilon$-SOSP is $O(\\epsilon^{-3.5})$, which is an improvement over the state-of-the-art sample complexity of $O(\\epsilon^{-4.5})$.",
        "bibtex": "@InProceedings{pmlr-v238-maniyar24a,\n  title = \t {A Cubic-regularized Policy {N}ewton Algorithm for Reinforcement Learning},\n  author =       {Maniyar, Mizhaan P. and L.A., Prashanth and Mondal, Akash and Bhatnagar, Shalabh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4708--4716},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/maniyar24a/maniyar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/maniyar24a.html},\n  abstract = \t {We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an $\\epsilon$-SOSP is $O(\\epsilon^{-3.5})$, which is an improvement over the state-of-the-art sample complexity of $O(\\epsilon^{-4.5})$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/maniyar24a/maniyar24a.pdf",
        "supp": "",
        "pdf_size": 596628,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15481434818760372096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3e6f8c66bb",
        "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/kim24c.html",
        "author": "Wonyoung Kim; Garud Iyengar; Assaf Zeevi",
        "abstract": "We propose a new regret minimization algorithm for episodic sparse linear Markov decision process (SMDP) where the state-transition distribution is a linear function of observed features. The only previously known algorithm for SMDP requires the knowledge of the sparsity parameter and oracle access to an unknown policy. We overcome these limitations by combining the doubly robust method that allows one to use feature vectors of \\emph{all} actions with a novel analysis technique that enables the algorithm to use data from all periods in all episodes. The regret of the proposed algorithm is $\\tilde{O}(\\sigma^{-1}_{\\min}s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$ denotes the restrictive the minimum eigenvalue of the average Gram matrix of feature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an episode, and $N$ is the number of rounds. We provide a lower regret bound that matches the upper bound to logarithmic factors on a newly identified subclass of SMDPs. Our numerical experiments support our theoretical results and demonstrate the superior performance of our algorithm.",
        "bibtex": "@InProceedings{pmlr-v238-kim24c,\n  title = \t {A Doubly Robust Approach to Sparse Reinforcement Learning},\n  author =       {Kim, Wonyoung and Iyengar, Garud and Zeevi, Assaf},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2305--2313},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kim24c/kim24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kim24c.html},\n  abstract = \t {We propose a new regret minimization algorithm for episodic sparse linear Markov decision process (SMDP) where the state-transition distribution is a linear function of observed features. The only previously known algorithm for SMDP requires the knowledge of the sparsity parameter and oracle access to an unknown policy. We overcome these limitations by combining the doubly robust method that allows one to use feature vectors of \\emph{all} actions with a novel analysis technique that enables the algorithm to use data from all periods in all episodes. The regret of the proposed algorithm is $\\tilde{O}(\\sigma^{-1}_{\\min}s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$ denotes the restrictive the minimum eigenvalue of the average Gram matrix of feature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an episode, and $N$ is the number of rounds. We provide a lower regret bound that matches the upper bound to logarithmic factors on a newly identified subclass of SMDPs. Our numerical experiments support our theoretical results and demonstrate the superior performance of our algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kim24c/kim24c.pdf",
        "supp": "",
        "pdf_size": 993750,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6911129990643125618&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4aae4c7fe5",
        "title": "A General Algorithm for Solving Rank-one Matrix Sensing",
        "site": "https://proceedings.mlr.press/v238/qin24a.html",
        "author": "Lianke Qin; Zhao Song; Ruizhe Zhang",
        "abstract": "Matrix sensing has many real-world applications in science and engineering, such as system control, distance embedding, and computer vision. The goal of matrix sensing is to recover a matrix $A_\\star \\in \\mathbb{R}^{n \\times n}$, based on a sequence of measurements $(u_i,b_i) \\in \\mathbb{R}^{n} \\times \\mathbb{R}$ such that $u_i^\\top A_\\star u_i = b_i$. Previous work (Zhong et al., 2015) focused on the scenario where matrix $A_{\\star}$ has a small rank, e.g. rank-$k$. Their analysis heavily relies on the RIP assumption, making it unclear how to generalize to high-rank matrices. In this paper, we relax that rank-$k$ assumption and solve a much more general matrix sensing problem. Given an accuracy parameter $\\delta \\in (0,1)$, we can compute $A \\in \\mathbb{R}^{n \\times n}$ in $\\widetilde{O}(m^{3/2} n^2 \\delta^{-1} )$, such that $ |u_i^\\top A u_i - b_i| \\leq \\delta$ for all $i \\in [m]$. We design an efficient algorithm with provable convergence guarantees using stochastic gradient descent for this problem.",
        "bibtex": "@InProceedings{pmlr-v238-qin24a,\n  title = \t {A General Algorithm for Solving Rank-one Matrix Sensing},\n  author =       {Qin, Lianke and Song, Zhao and Zhang, Ruizhe},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {757--765},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/qin24a/qin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/qin24a.html},\n  abstract = \t {Matrix sensing has many real-world applications in science and engineering, such as system control, distance embedding, and computer vision. The goal of matrix sensing is to recover a matrix $A_\\star \\in \\mathbb{R}^{n \\times n}$, based on a sequence of measurements $(u_i,b_i) \\in \\mathbb{R}^{n} \\times \\mathbb{R}$ such that $u_i^\\top A_\\star u_i = b_i$. Previous work (Zhong et al., 2015) focused on the scenario where matrix $A_{\\star}$ has a small rank, e.g. rank-$k$. Their analysis heavily relies on the RIP assumption, making it unclear how to generalize to high-rank matrices. In this paper, we relax that rank-$k$ assumption and solve a much more general matrix sensing problem. Given an accuracy parameter $\\delta \\in (0,1)$, we can compute $A \\in \\mathbb{R}^{n \\times n}$ in $\\widetilde{O}(m^{3/2} n^2 \\delta^{-1} )$, such that $ |u_i^\\top A u_i - b_i| \\leq \\delta$ for all $i \\in [m]$. We design an efficient algorithm with provable convergence guarantees using stochastic gradient descent for this problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/qin24a/qin24a.pdf",
        "supp": "",
        "pdf_size": 439995,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12527749768419923433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "UC Santa Barbara; Adobe Research; Simons Institute, UC Berkeley",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of California, Santa Barbara;Adobe;University of California, Berkeley",
        "aff_unique_dep": ";Adobe Research;Simons Institute",
        "aff_unique_url": "https://www.ucsb.edu;https://research.adobe.com;https://simons.berkeley.edu",
        "aff_unique_abbr": "UCSB;Adobe;UC Berkeley",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Santa Barbara;;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "825b26bca8",
        "title": "A General Theoretical Paradigm to Understand Learning from Human Preferences",
        "site": "https://proceedings.mlr.press/v238/gheshlaghi-azar24a.html",
        "author": "Mohammad Gheshlaghi Azar; Zhaohan Daniel Guo; Bilal Piot; Remi Munos; Mark Rowland; Michal Valko; Daniele Calandriello",
        "abstract": "The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation DPO has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation. In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called ${\\Psi}$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an in-depth analysis of the behavior of RLHF and DPO (as special cases of ${\\Psi}$PO) and to identify their potential pitfalls. We then consider another special case for ${\\Psi}$PO by setting $\\Psi$ simply to Identity, for which we can derive an efficient optimisation procedure, prove performance guarantees and demonstrate its empirical superiority to DPO on some illustrative examples.",
        "bibtex": "@InProceedings{pmlr-v238-gheshlaghi-azar24a,\n  title = \t {A General Theoretical Paradigm to Understand Learning from Human Preferences},\n  author =       {Gheshlaghi Azar, Mohammad and Daniel Guo, Zhaohan and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4447--4455},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gheshlaghi-azar24a/gheshlaghi-azar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gheshlaghi-azar24a.html},\n  abstract = \t {The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation DPO has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation. In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called ${\\Psi}$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an in-depth analysis of the behavior of RLHF and DPO (as special cases of ${\\Psi}$PO) and to identify their potential pitfalls. We then consider another special case for ${\\Psi}$PO by setting $\\Psi$ simply to Identity, for which we can derive an efficient optimisation procedure, prove performance guarantees and demonstrate its empirical superiority to DPO on some illustrative examples.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gheshlaghi-azar24a/gheshlaghi-azar24a.pdf",
        "supp": "",
        "pdf_size": 2561808,
        "gs_citation": 548,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11694404983995605431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d4eb818677",
        "title": "A Greedy Approximation for k-Determinantal Point Processes",
        "site": "https://proceedings.mlr.press/v238/grosse24a.html",
        "author": "Julia Grosse; Rahel Fischer; Roman Garnett; Philipp Hennig",
        "abstract": "Determinantal point processes (DPPs) are an important concept in random matrix theory and combinatorics, and increasingly in machine learning. Samples from these processes exhibit a form of self-avoidance, so they are also helpful in guiding algorithms that explore to reduce uncertainty, such as in active learning, Bayesian optimization, reinforcement learning, and marginalization in graphical models. The best-known algorithms for sampling from DPPs exactly require significant computational expense, which can be unwelcome in machine learning applications when the cost of sampling is relatively low and capturing the precise repulsive nature of the DPP may not be critical. We suggest an inexpensive approximate strategy for sampling a fixed number of points (as would typically be desired in a machine learning setting) from a so-called $k$-DPP based on iterative inverse transform sampling. We prove that our algorithm satisfies a $(1 - 1/\\epsilon)$ approximation guarantee relative to exact sampling from the $k$-DPP, and provide an efficient implementation for many common kernels used in machine learning, including the Gaussian and Mat\u00e9rn class. Finally, we compare the empirical runtime of our method to exact and Markov-Chain-Monte-Carlo (MCMC) samplers and investigate the approximation quality in a Bayesian Quadrature (BQ) setting.",
        "bibtex": "@InProceedings{pmlr-v238-grosse24a,\n  title = \t {A Greedy Approximation for k-Determinantal Point Processes},\n  author =       {Grosse, Julia and Fischer, Rahel and Garnett, Roman and Hennig, Philipp},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3052--3060},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/grosse24a/grosse24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/grosse24a.html},\n  abstract = \t {Determinantal point processes (DPPs) are an important concept in random matrix theory and combinatorics, and increasingly in machine learning. Samples from these processes exhibit a form of self-avoidance, so they are also helpful in guiding algorithms that explore to reduce uncertainty, such as in active learning, Bayesian optimization, reinforcement learning, and marginalization in graphical models. The best-known algorithms for sampling from DPPs exactly require significant computational expense, which can be unwelcome in machine learning applications when the cost of sampling is relatively low and capturing the precise repulsive nature of the DPP may not be critical. We suggest an inexpensive approximate strategy for sampling a fixed number of points (as would typically be desired in a machine learning setting) from a so-called $k$-DPP based on iterative inverse transform sampling. We prove that our algorithm satisfies a $(1 - 1/\\epsilon)$ approximation guarantee relative to exact sampling from the $k$-DPP, and provide an efficient implementation for many common kernels used in machine learning, including the Gaussian and Mat\u00e9rn class. Finally, we compare the empirical runtime of our method to exact and Markov-Chain-Monte-Carlo (MCMC) samplers and investigate the approximation quality in a Bayesian Quadrature (BQ) setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/grosse24a/grosse24a.pdf",
        "supp": "",
        "pdf_size": 3070770,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6135245466592381211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "287db817dc",
        "title": "A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization",
        "site": "https://proceedings.mlr.press/v238/dagreou24a.html",
        "author": "Mathieu Dagr\u00e9ou; Thomas Moreau; Samuel Vaiter; Pierre Ablin",
        "abstract": "Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $O((n+m)^{1/2}\\epsilon^{-1})$ oracle calls to achieve $\\epsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, making it optimal in terms of sample complexity.",
        "bibtex": "@InProceedings{pmlr-v238-dagreou24a,\n  title = \t {A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization},\n  author =       {Dagr\\'{e}ou, Mathieu and Moreau, Thomas and Vaiter, Samuel and Ablin, Pierre},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {82--90},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dagreou24a/dagreou24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dagreou24a.html},\n  abstract = \t {Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $O((n+m)^{1/2}\\epsilon^{-1})$ oracle calls to achieve $\\epsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, making it optimal in terms of sample complexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dagreou24a/dagreou24a.pdf",
        "supp": "",
        "pdf_size": 1452866,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5547382153075385063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7941aedaf5",
        "title": "A Neural Architecture Predictor based on GNN-Enhanced Transformer",
        "site": "https://proceedings.mlr.press/v238/xiang24a.html",
        "author": "Xunzhi Xiang; Kun Jing; Jungang Xu",
        "abstract": "Neural architecture performance predictor is an efficient approach for architecture estimation in Neural Architecture Search (NAS). However, existing predictors based on Graph Neural Networks (GNNs) are deficient in modeling long-range interactions between operation nodes and prone to the problem of over-smoothing, which limits their ability to learn neural architecture representation. Furthermore, some Transformer-based predictors use simple position encodings to improve performance via self-attention mechanism, but they fail to fully exploit the subgraph structure information of the graph. To solve this problem, we propose a novel method to enhance the graph representation of neural architectures by combining GNNs and Transformer blocks. We evaluate the effectiveness of our predictor on NAS-Bench-101 and NAS-bench-201 benchmarks, the discovered architecture on DARTS search space achieves an accuracy of 97.61% on CIFAR-10 dataset, which outperforms traditional position encoding methods such as adjacency and Laplacian matrices. The code of our work is available at \\url{https://github.com/GNET}.",
        "bibtex": "@InProceedings{pmlr-v238-xiang24a,\n  title = \t {A Neural Architecture Predictor based on {GNN}-Enhanced Transformer},\n  author =       {Xiang, Xunzhi and Jing, Kun and Xu, Jungang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1729--1737},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xiang24a/xiang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xiang24a.html},\n  abstract = \t {Neural architecture performance predictor is an efficient approach for architecture estimation in Neural Architecture Search (NAS). However, existing predictors based on Graph Neural Networks (GNNs) are deficient in modeling long-range interactions between operation nodes and prone to the problem of over-smoothing, which limits their ability to learn neural architecture representation. Furthermore, some Transformer-based predictors use simple position encodings to improve performance via self-attention mechanism, but they fail to fully exploit the subgraph structure information of the graph. To solve this problem, we propose a novel method to enhance the graph representation of neural architectures by combining GNNs and Transformer blocks. We evaluate the effectiveness of our predictor on NAS-Bench-101 and NAS-bench-201 benchmarks, the discovered architecture on DARTS search space achieves an accuracy of 97.61% on CIFAR-10 dataset, which outperforms traditional position encoding methods such as adjacency and Laplacian matrices. The code of our work is available at \\url{https://github.com/GNET}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xiang24a/xiang24a.pdf",
        "supp": "",
        "pdf_size": 1298714,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rCVOmQzwIj8J:scholar.google.com/&scioq=A+Neural+Architecture+Predictor+based+on+GNN-Enhanced+Transformer&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "School of Computer Science and Technology, University of Chinese Academy of Sciences, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, China",
        "aff_domain": "mails.ucas.ac.cn; ; ",
        "email": "mails.ucas.ac.cn; ; ",
        "github": "https://github.com/GNET",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ucas.ac.cn",
        "aff_unique_abbr": "UCAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "301de34e89",
        "title": "A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/hong24a.html",
        "author": "Kihyuk Hong; Yuhang Li; Ambuj Tewari",
        "abstract": "Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected cumulative cost using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate and the dual player acts greedily to minimize the Lagrangian estimate. We show that PDCA finds a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and a strong Bellman completeness assumption, PDCA only requires concentrability and realizability assumptions for sample-efficient learning.",
        "bibtex": "@InProceedings{pmlr-v238-hong24a,\n  title = \t {A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning},\n  author =       {Hong, Kihyuk and Li, Yuhang and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {280--288},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hong24a/hong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hong24a.html},\n  abstract = \t {Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected cumulative cost using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate and the dual player acts greedily to minimize the Lagrangian estimate. We show that PDCA finds a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and a strong Bellman completeness assumption, PDCA only requires concentrability and realizability assumptions for sample-efficient learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hong24a/hong24a.pdf",
        "supp": "",
        "pdf_size": 1008031,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12965923841582807330&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e20c3427a1",
        "title": "A Scalable Algorithm for Individually Fair k-Means Clustering",
        "site": "https://proceedings.mlr.press/v238/bateni24a.html",
        "author": "MohammadHossein Bateni; Vincent Cohen-Addad; Alessandro Epasto; Silvio Lattanzi",
        "abstract": "We present a scalable algorithm for the individually fair ($p$, $k$)-clustering problem introduced by Jung et al. and Mahabadi et al. Given $n$ points $P$ in a metric space, let $\\delta(x)$ for $x\\in P$ be the radius of the smallest ball around $x$ containing at least $n / k$ points. A clustering is then called individually fair if it has centers within distance $\\delta(x)$ of $x$ for each $x\\in P$. While good approximation algorithms are known for this problem no efficient practical algorithms with good theoretical guarantees have been presented. We design the first fast local-search algorithm that runs in \u00a0$O(nk^2)$ time and obtains a bicriteria $(O(1), 6)$ approximation. Then we show empirically that not only is our algorithm much faster than prior work, but it also produces lower-cost solutions.",
        "bibtex": "@InProceedings{pmlr-v238-bateni24a,\n  title = \t {A Scalable Algorithm for Individually Fair k-Means Clustering},\n  author =       {Bateni, MohammadHossein and Cohen-Addad, Vincent and Epasto, Alessandro and Lattanzi, Silvio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3151--3159},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bateni24a/bateni24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bateni24a.html},\n  abstract = \t {We present a scalable algorithm for the individually fair ($p$, $k$)-clustering problem introduced by Jung et al. and Mahabadi et al. Given $n$ points $P$ in a metric space, let $\\delta(x)$ for $x\\in P$ be the radius of the smallest ball around $x$ containing at least $n / k$ points. A clustering is then called individually fair if it has centers within distance $\\delta(x)$ of $x$ for each $x\\in P$. While good approximation algorithms are known for this problem no efficient practical algorithms with good theoretical guarantees have been presented. We design the first fast local-search algorithm that runs in \u00a0$O(nk^2)$ time and obtains a bicriteria $(O(1), 6)$ approximation. Then we show empirically that not only is our algorithm much faster than prior work, but it also produces lower-cost solutions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bateni24a/bateni24a.pdf",
        "supp": "",
        "pdf_size": 750464,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15946316201789388086&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Google Research; Google Research; Google Research",
        "aff_domain": "google.com;google.com;google.com;cohengoogle.com",
        "email": "google.com;google.com;google.com;cohengoogle.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6c6602194c",
        "title": "A Specialized Semismooth Newton Method for Kernel-Based Optimal Transport",
        "site": "https://proceedings.mlr.press/v238/lin24a.html",
        "author": "Tianyi Lin; Marco Cuturi; Michael Jordan",
        "abstract": "Kernel-based optimal transport (OT) estimators offer an alternative, functional estimation procedure to address OT problems from samples. Recent works suggest that these estimators are more statistically efficient than plug-in (linear programming-based) OT estimators when comparing probability measures in high-dimensions (Vacher et al., 2021). Unfortunately,that statistical benefit comes at a very steep computational price: because their computation relies on the short-step interior-point method (SSIPM), which comes with a large iteration count in practice, these estimators quickly become intractable w.r.t. sample size $n$. To scale these estimators to larger $n$, we propose a nonsmooth fixedpoint model for the kernel-based OT problem, and show that it can be efficiently solved via a specialized semismooth Newton (SSN) method: We show, exploring the problem\u2019s structure, that the per-iteration cost of performing one SSN step can be significantly reduced in practice. We prove that our SSN method achieves a global convergence rate of $O(1/\\sqrt{k})$, and a local quadratic convergence rate under standard regularity conditions. We show substantial speedups over SSIPM on both synthetic and real datasets.",
        "bibtex": "@InProceedings{pmlr-v238-lin24a,\n  title = \t {A Specialized Semismooth {N}ewton Method for Kernel-Based Optimal Transport},\n  author =       {Lin, Tianyi and Cuturi, Marco and Jordan, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {145--153},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lin24a/lin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lin24a.html},\n  abstract = \t {Kernel-based optimal transport (OT) estimators offer an alternative, functional estimation procedure to address OT problems from samples. Recent works suggest that these estimators are more statistically efficient than plug-in (linear programming-based) OT estimators when comparing probability measures in high-dimensions (Vacher et al., 2021). Unfortunately,that statistical benefit comes at a very steep computational price: because their computation relies on the short-step interior-point method (SSIPM), which comes with a large iteration count in practice, these estimators quickly become intractable w.r.t. sample size $n$. To scale these estimators to larger $n$, we propose a nonsmooth fixedpoint model for the kernel-based OT problem, and show that it can be efficiently solved via a specialized semismooth Newton (SSN) method: We show, exploring the problem\u2019s structure, that the per-iteration cost of performing one SSN step can be significantly reduced in practice. We prove that our SSN method achieves a global convergence rate of $O(1/\\sqrt{k})$, and a local quadratic convergence rate under standard regularity conditions. We show substantial speedups over SSIPM on both synthetic and real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lin24a/lin24a.pdf",
        "supp": "",
        "pdf_size": 6863331,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11479753157603941986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "MIT; Apple; UC Berkeley",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;Apple;University of California, Berkeley",
        "aff_unique_dep": ";Apple Inc.;",
        "aff_unique_url": "https://web.mit.edu;https://www.apple.com;https://www.berkeley.edu",
        "aff_unique_abbr": "MIT;Apple;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "71cd5a4db0",
        "title": "A Unified Framework for Discovering Discrete Symmetries",
        "site": "https://proceedings.mlr.press/v238/karjol24a.html",
        "author": "Pavan Karjol; Rohan Kashyap; Aditya Gopalan; A. P. Prathosh",
        "abstract": "We consider the problem of learning a function respecting a symmetry from among a class of symmetries. We develop a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear, matrix-valued and non-linear functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the non-linear functions, respectively, and to infer the symmetry that is ultimately learnt. We also discuss the necessity of the matrix-valued functions in the architecture. Experiments on image-digit sum and polynomial regression tasks demonstrate the effectiveness of our approach.",
        "bibtex": "@InProceedings{pmlr-v238-karjol24a,\n  title = \t {A Unified Framework for Discovering Discrete Symmetries},\n  author =       {Karjol, Pavan and Kashyap, Rohan and Gopalan, Aditya and Prathosh, A. P.},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {793--801},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/karjol24a/karjol24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/karjol24a.html},\n  abstract = \t {We consider the problem of learning a function respecting a symmetry from among a class of symmetries. We develop a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear, matrix-valued and non-linear functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the non-linear functions, respectively, and to infer the symmetry that is ultimately learnt. We also discuss the necessity of the matrix-valued functions in the architecture. Experiments on image-digit sum and polynomial regression tasks demonstrate the effectiveness of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/karjol24a/karjol24a.pdf",
        "supp": "",
        "pdf_size": 1121713,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1030091702087119460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "524d43e4f3",
        "title": "A Unifying Variational Framework for Gaussian Process Motion Planning",
        "site": "https://proceedings.mlr.press/v238/cosier24a.html",
        "author": "Lucas C. Cosier; Rares Iordan; Sicelukwanda N. T. Zwane; Giovanni Franzese; James T. Wilson; Marc Deisenroth; Alexander Terenin; Yasemin Bekiroglu",
        "abstract": "To control how a robot moves, motion planning algorithms must compute paths in high-dimensional state spaces while accounting for physical constraints related to motors and joints, generating smooth and stable motions, avoiding obstacles, and preventing collisions. A motion planning algorithm must therefore balance competing demands, and should ideally incorporate uncertainty to handle noise, model errors, and facilitate deployment in complex environments. To address these issues, we introduce a framework for robot motion planning based on variational Gaussian processes, which unifies and generalizes various probabilistic-inference-based motion planning algorithms, and connects them with optimization-based planners. Our framework provides a principled and flexible way to incorporate equality-based, inequality-based, and soft motion-planning constraints during end-to-end training, is straightforward to implement, and provides both interval-based and Monte-Carlo-based uncertainty estimates. We conduct experiments using different environments and robots, comparing against baseline approaches based on the feasibility of the planned paths, and obstacle avoidance quality. Results show that our proposed approach yields a good balance between success rates and path quality.",
        "bibtex": "@InProceedings{pmlr-v238-cosier24a,\n  title = \t {A Unifying Variational Framework for {G}aussian Process Motion Planning},\n  author =       {Cosier, Lucas C. and Iordan, Rares and Zwane, Sicelukwanda N. T. and Franzese, Giovanni and Wilson, James T. and Deisenroth, Marc and Terenin, Alexander and Bekiroglu, Yasemin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1315--1323},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cosier24a/cosier24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cosier24a.html},\n  abstract = \t {To control how a robot moves, motion planning algorithms must compute paths in high-dimensional state spaces while accounting for physical constraints related to motors and joints, generating smooth and stable motions, avoiding obstacles, and preventing collisions. A motion planning algorithm must therefore balance competing demands, and should ideally incorporate uncertainty to handle noise, model errors, and facilitate deployment in complex environments. To address these issues, we introduce a framework for robot motion planning based on variational Gaussian processes, which unifies and generalizes various probabilistic-inference-based motion planning algorithms, and connects them with optimization-based planners. Our framework provides a principled and flexible way to incorporate equality-based, inequality-based, and soft motion-planning constraints during end-to-end training, is straightforward to implement, and provides both interval-based and Monte-Carlo-based uncertainty estimates. We conduct experiments using different environments and robots, comparing against baseline approaches based on the feasibility of the planned paths, and obstacle avoidance quality. Results show that our proposed approach yields a good balance between success rates and path quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cosier24a/cosier24a.pdf",
        "supp": "",
        "pdf_size": 2296133,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11285141868705149933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University College London + ETH Z\u00fcrich; University College London; University College London; TU Delft; Imperial College London; University College London; Imperial College London + University of Cambridge + Cornell University; University College London + Chalmers University of Technology",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "https://github.com/luke-ck/vgpmp",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;2;3;0;3+4+5;0+6",
        "aff_unique_norm": "University College London;ETH Zurich;Delft University of Technology;Imperial College London;University of Cambridge;Cornell University;Chalmers University of Technology",
        "aff_unique_dep": ";;;;;;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ethz.ch;https://www.tudelft.nl;https://www.imperial.ac.uk;https://www.cam.ac.uk;https://www.cornell.edu;https://www.chalmers.se",
        "aff_unique_abbr": "UCL;ETHZ;TU Delft;ICL;Cambridge;Cornell;Chalmers",
        "aff_campus_unique_index": ";1;2;",
        "aff_campus_unique": ";Delft;Cambridge",
        "aff_country_unique_index": "0+1;0;0;2;0;0;0+0+3;0+4",
        "aff_country_unique": "United Kingdom;Switzerland;Netherlands;United States;Sweden"
    },
    {
        "id": "5702500db2",
        "title": "A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models",
        "site": "https://proceedings.mlr.press/v238/guo24a.html",
        "author": "Zhongliang Guo; Weiye Li; Yifei Qian; Ognjen Arandjelovic; Lei Fang",
        "abstract": "In this paper, we tackle the challenge of white-box false positive adversarial attacks on contrastive loss based offline handwritten signature verification models. We propose a novel attack method that treats the attack as a style transfer between closely related but distinct writing styles. To guide the generation of deceptive images, we introduce two new loss functions that enhance the attack success rate by perturbing the Euclidean distance between the embedding vectors of the original and synthesized samples, while ensuring minimal perturbations by reducing the difference between the generated image and the original image. Our method demonstrates state-of-the-art performance in white-box attacks on contrastive loss based offline handwritten signature verification models, as evidenced by our experiments. The key contributions of this paper include a novel false positive attack method, two new loss functions, effective style transfer in handwriting styles, and superior performance in white-box false positive attacks compared to other white-box attack methods.",
        "bibtex": "@InProceedings{pmlr-v238-guo24a,\n  title = \t {A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models},\n  author =       {Guo, Zhongliang and Li, Weiye and Qian, Yifei and Arandjelovic, Ognjen and Fang, Lei},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {901--909},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/guo24a/guo24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/guo24a.html},\n  abstract = \t {In this paper, we tackle the challenge of white-box false positive adversarial attacks on contrastive loss based offline handwritten signature verification models. We propose a novel attack method that treats the attack as a style transfer between closely related but distinct writing styles. To guide the generation of deceptive images, we introduce two new loss functions that enhance the attack success rate by perturbing the Euclidean distance between the embedding vectors of the original and synthesized samples, while ensuring minimal perturbations by reducing the difference between the generated image and the original image. Our method demonstrates state-of-the-art performance in white-box attacks on contrastive loss based offline handwritten signature verification models, as evidenced by our experiments. The key contributions of this paper include a novel false positive attack method, two new loss functions, effective style transfer in handwriting styles, and superior performance in white-box false positive attacks compared to other white-box attack methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/guo24a/guo24a.pdf",
        "supp": "",
        "pdf_size": 850060,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4918299641935313769&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of St Andrews, St Andrews, United Kingdom; University of St Andrews, St Andrews, United Kingdom; ; ; ",
        "aff_domain": "st-andrews.ac.uk;st-andrews.ac.uk; ; ; ",
        "email": "st-andrews.ac.uk;st-andrews.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of St Andrews",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.st-andrews.ac.uk",
        "aff_unique_abbr": "St Andrews",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "St Andrews",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "2b3679bfa4",
        "title": "A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity",
        "site": "https://proceedings.mlr.press/v238/xiong24a.html",
        "author": "Zhihan Xiong; Romain Camilleri; Maryam Fazel; Lalit Jain; Kevin Jamieson",
        "abstract": "We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\\mathcal{X}\\subset\\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\\left\\lbrace\\theta_t\\right\\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \\arg\\max_{x\\in\\mathcal{X}}x^\\top\\sum_{t=1}^{T}\\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\\theta_t = \\theta_1$ for all $t$ and demonstrated that the error probability decreases as $\\exp(-T /\\rho^*)$ for a problem-dependent constant $\\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\\mathcal{X}$ at each time then the error probability decreases as $\\exp(-T\\Delta^2_{(1)}/d)$, where $\\Delta_{(1)} = \\min_{x \\neq x^*} (x^* - x)^\\top \\frac{1}{T}\\sum_{t=1}^T \\theta_t$. As there exist environments where $\\Delta_{(1)}^2/ d \\ll 1/ \\rho^*$, we are motivated to propose a novel algorithm P1-RAGE that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of P1-RAGE and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting.",
        "bibtex": "@InProceedings{pmlr-v238-xiong24a,\n  title = \t {{A}/{B} Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity},\n  author =       {Xiong, Zhihan and Camilleri, Romain and Fazel, Maryam and Jain, Lalit and Jamieson, Kevin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1585--1593},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xiong24a/xiong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xiong24a.html},\n  abstract = \t {We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\\mathcal{X}\\subset\\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\\left\\lbrace\\theta_t\\right\\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \\arg\\max_{x\\in\\mathcal{X}}x^\\top\\sum_{t=1}^{T}\\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\\theta_t = \\theta_1$ for all $t$ and demonstrated that the error probability decreases as $\\exp(-T /\\rho^*)$ for a problem-dependent constant $\\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\\mathcal{X}$ at each time then the error probability decreases as $\\exp(-T\\Delta^2_{(1)}/d)$, where $\\Delta_{(1)} = \\min_{x \\neq x^*} (x^* - x)^\\top \\frac{1}{T}\\sum_{t=1}^T \\theta_t$. As there exist environments where $\\Delta_{(1)}^2/ d \\ll 1/ \\rho^*$, we are motivated to propose a novel algorithm P1-RAGE that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of P1-RAGE and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xiong24a/xiong24a.pdf",
        "supp": "",
        "pdf_size": 958621,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16785706032754122953&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Washington; University of Washington; University of Washington; University of Washington; University of Washington",
        "aff_domain": "uw.edu;uw.edu;uw.edu;uw.edu;uw.edu",
        "email": "uw.edu;uw.edu;uw.edu;uw.edu;uw.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8010b631f7",
        "title": "A/B testing under Interference with Partial Network Information",
        "site": "https://proceedings.mlr.press/v238/shankar24a.html",
        "author": "Shiv Shankar; Ritwik Sinha; Yash Chandak; Saayan Mitra; Madalina Fiterau",
        "abstract": "A/B tests are often required to be conducted on subjects that might have social connections. For e.g., experiments on social media, or medical and social interventions to control the spread of an epidemic. In such settings, the SUTVA assumption for randomized-controlled trials is violated due to network interference, or spill-over effects, as treatments to group A can potentially also affect the control group B. When the underlying social network is known exactly, prior works have demonstrated how to conduct A/B tests adequately to estimate the global average treatment effect (GATE). However, in practice, it is often impossible to obtain knowledge about the exact underlying network. In this paper, we present UNITE: a novel estimator that relax this assumption and can identify GATE while only relying on knowledge of the superset of neighbors for any subject in the graph. Through theoretical analysis and extensive experiments, we show that the proposed approach performs better in comparison to standard estimators.",
        "bibtex": "@InProceedings{pmlr-v238-shankar24a,\n  title = \t {{A}/{B} testing under Interference with Partial Network Information},\n  author =       {Shankar, Shiv and Sinha, Ritwik and Chandak, Yash and Mitra, Saayan and Fiterau, Madalina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {19--27},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shankar24a/shankar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shankar24a.html},\n  abstract = \t {A/B tests are often required to be conducted on subjects that might have social connections. For e.g., experiments on social media, or medical and social interventions to control the spread of an epidemic. In such settings, the SUTVA assumption for randomized-controlled trials is violated due to network interference, or spill-over effects, as treatments to group A can potentially also affect the control group B. When the underlying social network is known exactly, prior works have demonstrated how to conduct A/B tests adequately to estimate the global average treatment effect (GATE). However, in practice, it is often impossible to obtain knowledge about the exact underlying network. In this paper, we present UNITE: a novel estimator that relax this assumption and can identify GATE while only relying on knowledge of the superset of neighbors for any subject in the graph. Through theoretical analysis and extensive experiments, we show that the proposed approach performs better in comparison to standard estimators.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shankar24a/shankar24a.pdf",
        "supp": "",
        "pdf_size": 1317219,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14217155908732174520&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "UMass; Adobe Research; Stanford University; Adobe; UMass",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University of Massachusetts;Adobe;Stanford University",
        "aff_unique_dep": ";Adobe Research;",
        "aff_unique_url": "https://www.umass.edu;https://research.adobe.com;https://www.stanford.edu",
        "aff_unique_abbr": "UMass;Adobe;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "149009c5a2",
        "title": "ALAS: Active Learning for Autoconversion Rates Prediction from Satellite Data",
        "site": "https://proceedings.mlr.press/v238/novitasari24a.html",
        "author": "Maria C. Novitasari; Johannes Quaas; Miguel Rodrigues",
        "abstract": "High-resolution simulations, such as the ICOsahedral Non-hydrostatic Large-Eddy Model (ICON-LEM), provide valuable insights into the complex interactions among aerosols, clouds, and precipitation, which are the major contributors to climate change uncertainty. However, due to their exorbitant computational costs, they can only be employed for a limited period and geographical area. To address this, we propose a more cost-effective method powered by an emerging machine learning approach to better understand the intricate dynamics of the climate system. Our approach involves active learning techniques by leveraging high-resolution climate simulation as an oracle that is queried based on an abundant amount of unlabeled data drawn from satellite observations. In particular, we aim to predict autoconversion rates, a crucial step in precipitation formation, while significantly reducing the need for a large number of labeled instances. In this study, we present novel methods: custom fusion query strategies for labeling instances \u2013 weight fusion (WiFi) and merge fusion (MeFi) \u2013 along with active feature selection based on SHAP. These methods are designed to tackle real-world challenges \u2013 in this case, climate change, with a specific focus on the prediction of autoconversion rates \u2013 due to their simplicity and practicality in application.",
        "bibtex": "@InProceedings{pmlr-v238-novitasari24a,\n  title = \t {{ALAS}: Active Learning for Autoconversion Rates Prediction from Satellite Data},\n  author =       {Novitasari, Maria C. and Quaas, Johannes and Rodrigues, Miguel},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3358--3366},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/novitasari24a/novitasari24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/novitasari24a.html},\n  abstract = \t {High-resolution simulations, such as the ICOsahedral Non-hydrostatic Large-Eddy Model (ICON-LEM), provide valuable insights into the complex interactions among aerosols, clouds, and precipitation, which are the major contributors to climate change uncertainty. However, due to their exorbitant computational costs, they can only be employed for a limited period and geographical area. To address this, we propose a more cost-effective method powered by an emerging machine learning approach to better understand the intricate dynamics of the climate system. Our approach involves active learning techniques by leveraging high-resolution climate simulation as an oracle that is queried based on an abundant amount of unlabeled data drawn from satellite observations. In particular, we aim to predict autoconversion rates, a crucial step in precipitation formation, while significantly reducing the need for a large number of labeled instances. In this study, we present novel methods: custom fusion query strategies for labeling instances \u2013 weight fusion (WiFi) and merge fusion (MeFi) \u2013 along with active feature selection based on SHAP. These methods are designed to tackle real-world challenges \u2013 in this case, climate change, with a specific focus on the prediction of autoconversion rates \u2013 due to their simplicity and practicality in application.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/novitasari24a/novitasari24a.pdf",
        "supp": "",
        "pdf_size": 6372744,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mrFlAZ3e7psJ:scholar.google.com/&scioq=ALAS:+Active+Learning+for+Autoconversion+Rates+Prediction+from+Satellite+Data&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3f084313db",
        "title": "Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses",
        "site": "https://proceedings.mlr.press/v238/ma24a.html",
        "author": "Ziye Ma; Ying Chen; Javad Lavaei; Somayeh Sojoudi",
        "abstract": "Matrix sensing problems exhibit pervasive non-convexity, plaguing optimization with a proliferation of suboptimal spurious solutions. Avoiding convergence to these critical points poses a major challenge. This work provides new theoretical insights that help demystify the intricacies of the non-convex landscape. In this work, we prove that under certain conditions, critical points sufficiently distant from the ground truth matrix exhibit favorable geometry by being strict saddle points rather than troublesome local minima. Moreover, we introduce the notion of higher-order losses for the matrix sensing problem and show that the incorporation of such losses into the objective function amplifies the negative curvature around those distant critical points. This implies that increasing the complexity of the objective function via high-order losses accelerates the escape from such critical points and acts as a desirable alternative to increasing the complexity of the optimization problem via over-parametrization. By elucidating key characteristics of the non-convex optimization landscape, this work makes progress towards a comprehensive framework for tackling broader machine learning objectives plagued by non-convexity.",
        "bibtex": "@InProceedings{pmlr-v238-ma24a,\n  title = \t {Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses},\n  author =       {Ma, Ziye and Chen, Ying and Lavaei, Javad and Sojoudi, Somayeh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1603--1611},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ma24a/ma24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ma24a.html},\n  abstract = \t {Matrix sensing problems exhibit pervasive non-convexity, plaguing optimization with a proliferation of suboptimal spurious solutions. Avoiding convergence to these critical points poses a major challenge. This work provides new theoretical insights that help demystify the intricacies of the non-convex landscape. In this work, we prove that under certain conditions, critical points sufficiently distant from the ground truth matrix exhibit favorable geometry by being strict saddle points rather than troublesome local minima. Moreover, we introduce the notion of higher-order losses for the matrix sensing problem and show that the incorporation of such losses into the objective function amplifies the negative curvature around those distant critical points. This implies that increasing the complexity of the objective function via high-order losses accelerates the escape from such critical points and acts as a desirable alternative to increasing the complexity of the optimization problem via over-parametrization. By elucidating key characteristics of the non-convex optimization landscape, this work makes progress towards a comprehensive framework for tackling broader machine learning objectives plagued by non-convexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ma24a/ma24a.pdf",
        "supp": "",
        "pdf_size": 569282,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1787082009845994216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical Engineering and Computer Science1 + University of California, Berkeley; Department of Industrial Engineering and Operations Research2 + University of California, Berkeley; Department of Industrial Engineering and Operations Research2 + University of California, Berkeley; Department of Electrical Engineering and Computer Science1 + University of California, Berkeley",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1+1;1+1;0+1",
        "aff_unique_norm": "University of Michigan;University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;",
        "aff_unique_url": "https://www.eecs.umich.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UM EECS;UC Berkeley",
        "aff_campus_unique_index": "1;1+1;1+1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "df84249e5d",
        "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
        "site": "https://proceedings.mlr.press/v238/zheng24b.html",
        "author": "Haoyang Zheng; Wei Deng; Christian Moya; Guang Lin",
        "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde O}(\\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.",
        "bibtex": "@InProceedings{pmlr-v238-zheng24b,\n  title = \t {Accelerating Approximate {T}hompson Sampling with Underdamped {L}angevin {M}onte {C}arlo},\n  author =       {Zheng, Haoyang and Deng, Wei and Moya, Christian and Lin, Guang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2611--2619},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zheng24b/zheng24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zheng24b.html},\n  abstract = \t {Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde O}(\\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zheng24b/zheng24b.pdf",
        "supp": "",
        "pdf_size": 633636,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=881248755727462358&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e04df18d71",
        "title": "Acceleration and Implicit Regularization in Gaussian Phase Retrieval",
        "site": "https://proceedings.mlr.press/v238/maunu24a.html",
        "author": "Tyler Maunu; Martin Molina-Fructuoso",
        "abstract": "We study accelerated optimization methods in the Gaussian phase retrieval problem. In this setting, we prove that gradient methods with Polyak or Nesterov momentum have similar implicit regularization to gradient descent. This implicit regularization ensures that the algorithms remain in a nice region, where the cost function is strongly convex and smooth despite being nonconvex in general. This ensures that these accelerated methods achieve faster rates of convergence than gradient descent. Experimental evidence demonstrates that the accelerated methods converge faster than gradient descent in practice.",
        "bibtex": "@InProceedings{pmlr-v238-maunu24a,\n  title = \t {Acceleration and Implicit Regularization in {G}aussian Phase Retrieval},\n  author =       {Maunu, Tyler and Molina-Fructuoso, Martin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4060--4068},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/maunu24a/maunu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/maunu24a.html},\n  abstract = \t {We study accelerated optimization methods in the Gaussian phase retrieval problem. In this setting, we prove that gradient methods with Polyak or Nesterov momentum have similar implicit regularization to gradient descent. This implicit regularization ensures that the algorithms remain in a nice region, where the cost function is strongly convex and smooth despite being nonconvex in general. This ensures that these accelerated methods achieve faster rates of convergence than gradient descent. Experimental evidence demonstrates that the accelerated methods converge faster than gradient descent in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/maunu24a/maunu24a.pdf",
        "supp": "",
        "pdf_size": 1031645,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Lov-fDOPYewJ:scholar.google.com/&scioq=Acceleration+and+Implicit+Regularization+in+Gaussian+Phase+Retrieval&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "aff": "Brandeis University; Brandeis University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Brandeis University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.brandeis.edu",
        "aff_unique_abbr": "Brandeis",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "696bff501b",
        "title": "Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex",
        "site": "https://proceedings.mlr.press/v238/esaki24a.html",
        "author": "Yasushi Esaki; Akihiro Nakamura; Keisuke Kawano; Ryoko Tokuhisa; Takuro Kutsuna",
        "abstract": "Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-esaki24a,\n  title = \t {Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex},\n  author =       {Esaki, Yasushi and Nakamura, Akihiro and Kawano, Keisuke and Tokuhisa, Ryoko and Kutsuna, Takuro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1666--1674},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/esaki24a/esaki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/esaki24a.html},\n  abstract = \t {Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/esaki24a/esaki24a.pdf",
        "supp": "",
        "pdf_size": 952112,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10416331645512388442&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Toyota Central R&D Labs., Inc.; Toyota Central R&D Labs., Inc.; Toyota Central R&D Labs., Inc.; Toyota Central R&D Labs., Inc.; Toyota Central R&D Labs., Inc.",
        "aff_domain": "mosk.tytlabs.co.jp; ; ; ; ",
        "email": "mosk.tytlabs.co.jp; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Toyota Central R&D Labs",
        "aff_unique_dep": "R&D",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "855689ad1f",
        "title": "Achieving Fairness through Separability: A Unified Framework for Fair Representation Learning",
        "site": "https://proceedings.mlr.press/v238/jang24a.html",
        "author": "Taeuk Jang; Hongchang Gao; Pengyi Shi; Xiaoqian Wang",
        "abstract": "Fairness is a growing concern in machine learning as state-of-the-art models may amplify social prejudice by making biased predictions against specific demographics such as race and gender. Such discrimination raises issues in various fields such as employment, criminal justice, and trust score evaluation. To address the concerns, we propose learning fair representation through a straightforward yet effective approach to project intrinsic information while filtering sensitive information for downstream tasks. Our model consists of two goals: one is to ensure that the latent data from different demographic groups is non-separable (i.e., make the latent data distribution independent of the sensitive feature to improve fairness); the other is to maximize the separability of latent data from different classes (i.e., maintain the discriminative power of data for the sake of the downstream tasks like classification). Our method adopts a non-zero-sum adversarial game to minimize the distance between data from different demographic groups while maximizing the margin between data from different classes. Moreover, the proposed objective function can be easily generalized to multiple sensitive attributes and multi-class scenarios as it upper bounds popular fairness metrics in these cases. We provide theoretical analysis of the fairness of our model and validate w.r.t. both fairness and predictive performance on benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v238-jang24a,\n  title = \t {Achieving Fairness through Separability: A Unified Framework for Fair Representation Learning},\n  author =       {Jang, Taeuk and Gao, Hongchang and Shi, Pengyi and Wang, Xiaoqian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {28--36},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jang24a/jang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jang24a.html},\n  abstract = \t {Fairness is a growing concern in machine learning as state-of-the-art models may amplify social prejudice by making biased predictions against specific demographics such as race and gender. Such discrimination raises issues in various fields such as employment, criminal justice, and trust score evaluation. To address the concerns, we propose learning fair representation through a straightforward yet effective approach to project intrinsic information while filtering sensitive information for downstream tasks. Our model consists of two goals: one is to ensure that the latent data from different demographic groups is non-separable (i.e., make the latent data distribution independent of the sensitive feature to improve fairness); the other is to maximize the separability of latent data from different classes (i.e., maintain the discriminative power of data for the sake of the downstream tasks like classification). Our method adopts a non-zero-sum adversarial game to minimize the distance between data from different demographic groups while maximizing the margin between data from different classes. Moreover, the proposed objective function can be easily generalized to multiple sensitive attributes and multi-class scenarios as it upper bounds popular fairness metrics in these cases. We provide theoretical analysis of the fairness of our model and validate w.r.t. both fairness and predictive performance on benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jang24a/jang24a.pdf",
        "supp": "",
        "pdf_size": 3506885,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10548559463630200453&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3ef222d219",
        "title": "Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers",
        "site": "https://proceedings.mlr.press/v238/martinez24a.html",
        "author": "Natalia L. Martinez; Martin A. Bertran; Guillermo Sapiro",
        "abstract": "Group distributional robustness optimization methods (GDRO) learn models that guarantee performance across a broad set of demographics. GDRO is often framed as a minimax game where an adversary proposes data distributions under which the model performs poorly; importance weights are used to mimic the adversarial distribution on finite samples. Prior work has show that applying GDRO with interpolating classifiers requires strong regularization to generalize to unseen data. Moreover, these classifiers are not responsive to importance weights in the asymptotic training regime. In this work we propose Bi-level GDRO, a provably convergent formulation that decouples the adversary\u2019s and model learner\u2019s objective and improves generalization guarantees. To address non-responsiveness of importance weights, we combine Bi-level GDRO with a learner that optimizes a temperature-scaled loss that can provably trade off performance between demographics, even on interpolating classifiers. We experimentally demonstrate the effectiveness of our proposed method on learning minimax classifiers on a variety of datasets. Code is available at github.com/MartinBertran/BiLevelGDRO.",
        "bibtex": "@InProceedings{pmlr-v238-martinez24a,\n  title = \t {Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers},\n  author =       {Martinez, Natalia L. and Bertran, Martin A. and Sapiro, Guillermo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2629--2637},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/martinez24a/martinez24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/martinez24a.html},\n  abstract = \t {Group distributional robustness optimization methods (GDRO) learn models that guarantee performance across a broad set of demographics. GDRO is often framed as a minimax game where an adversary proposes data distributions under which the model performs poorly; importance weights are used to mimic the adversarial distribution on finite samples. Prior work has show that applying GDRO with interpolating classifiers requires strong regularization to generalize to unseen data. Moreover, these classifiers are not responsive to importance weights in the asymptotic training regime. In this work we propose Bi-level GDRO, a provably convergent formulation that decouples the adversary\u2019s and model learner\u2019s objective and improves generalization guarantees. To address non-responsiveness of importance weights, we combine Bi-level GDRO with a learner that optimizes a temperature-scaled loss that can provably trade off performance between demographics, even on interpolating classifiers. We experimentally demonstrate the effectiveness of our proposed method on learning minimax classifiers on a variety of datasets. Code is available at github.com/MartinBertran/BiLevelGDRO.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/martinez24a/martinez24a.pdf",
        "supp": "",
        "pdf_size": 2504181,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BwbH6FU1D4YJ:scholar.google.com/&scioq=Achieving+Group+Distributional+Robustness+and+Minimax+Group+Fairness+with+Interpolating+Classifiers&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "IBM Research; Amazon Science; Duke University & Apple",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "github.com/MartinBertran/BiLevelGDRO",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "IBM;Amazon;Duke University",
        "aff_unique_dep": "IBM Research;Amazon Science;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.amazon.science;https://www.duke.edu",
        "aff_unique_abbr": "IBM;Amazon Science;Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4aff8a1793",
        "title": "Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach",
        "site": "https://proceedings.mlr.press/v238/adachi24b.html",
        "author": "Masaki Adachi; Satoshi Hayakawa; Martin J\u00f8rgensen; Xingchen Wan; Vu Nguyen; Harald Oberhauser; Michael A. Osborne",
        "abstract": "Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed\u2014larger batches are more costly, smaller batches lead to slower wall-clock run-times\u2014and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications.",
        "bibtex": "@InProceedings{pmlr-v238-adachi24b,\n  title = \t {Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach},\n  author =       {Adachi, Masaki and Hayakawa, Satoshi and J\\o{}rgensen, Martin and Wan, Xingchen and Nguyen, Vu and Oberhauser, Harald and A. Osborne, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {496--504},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/adachi24b/adachi24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/adachi24b.html},\n  abstract = \t {Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed\u2014larger batches are more costly, smaller batches lead to slower wall-clock run-times\u2014and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/adachi24b/adachi24b.pdf",
        "supp": "",
        "pdf_size": 3694744,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9924454498635058057&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Machine Learning Research Group, University of Oxford + Toyota Motor Corporation; Mathematical Institute, University of Oxford; Department of Computer Science, University of Helsinki; Machine Learning Research Group, University of Oxford; Amazon; Mathematical Institute, University of Oxford; Machine Learning Research Group, University of Oxford",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;2;0;3;0;0",
        "aff_unique_norm": "University of Oxford;Toyota Motor Corporation;University of Helsinki;Amazon",
        "aff_unique_dep": "Machine Learning Research Group;;Department of Computer Science;Amazon.com, Inc.",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.toyota-global.com;https://www.helsinki.fi;https://www.amazon.com",
        "aff_unique_abbr": "Oxford;Toyota;UH;Amazon",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0+1;0;2;0;3;0;0",
        "aff_country_unique": "United Kingdom;Japan;Finland;United States"
    },
    {
        "id": "2006d19802",
        "title": "Adaptive Compression in Federated Learning via Side Information",
        "site": "https://proceedings.mlr.press/v238/isik24a.html",
        "author": "Berivan Isik; Francesco Pase; Deniz Gunduz; Sanmi Koyejo; Tsachy Weissman; Michele Zorzi",
        "abstract": "The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods \u2013 in which the client n sends a sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the server estimates the mean of the clients\u2019 distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a global distribution $p_{\\theta}$ that is close to the client-only distribution $q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this \\emph{closeness} between the clients\u2019 distributions $q_{\\phi^{(n)}}$\u2019s and the side information $p_{\\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks to attain the same (and often higher) test accuracy with up to 82 times smaller bitrate than the prior work \u2013 corresponding to 2,650 times overall compression.",
        "bibtex": "@InProceedings{pmlr-v238-isik24a,\n  title = \t {Adaptive Compression in Federated Learning via Side Information},\n  author =       {Isik, Berivan and Pase, Francesco and Gunduz, Deniz and Koyejo, Sanmi and Weissman, Tsachy and Zorzi, Michele},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {487--495},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/isik24a/isik24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/isik24a.html},\n  abstract = \t {The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods \u2013 in which the client n sends a sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the server estimates the mean of the clients\u2019 distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a global distribution $p_{\\theta}$ that is close to the client-only distribution $q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this \\emph{closeness} between the clients\u2019 distributions $q_{\\phi^{(n)}}$\u2019s and the side information $p_{\\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks to attain the same (and often higher) test accuracy with up to 82 times smaller bitrate than the prior work \u2013 corresponding to 2,650 times overall compression.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/isik24a/isik24a.pdf",
        "supp": "",
        "pdf_size": 1312552,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8303072872299026278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Stanford University; University of Padova; Imperial College London; Stanford University; Stanford University; University of Padova",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0;1",
        "aff_unique_norm": "Stanford University;University of Padova;Imperial College London",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.unipd.it;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Stanford;UNIPD;ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;1;2;0;0;1",
        "aff_country_unique": "United States;Italy;United Kingdom"
    },
    {
        "id": "6fcf5aa89f",
        "title": "Adaptive Discretization for Event PredicTion (ADEPT)",
        "site": "https://proceedings.mlr.press/v238/hickey24a.html",
        "author": "Jimmy Hickey; Ricardo Henao; Daniel Wojdyla; Michael Pencina; Matthew Engelhard",
        "abstract": "Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop Adaptive Discretization for Event PredicTion (ADEPT) to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical decision-making by suggesting time intervals that are most appropriate for each task, in the sense that they facilitate more accurate risk prediction.",
        "bibtex": "@InProceedings{pmlr-v238-hickey24a,\n  title = \t {Adaptive Discretization for Event PredicTion {(ADEPT)}},\n  author =       {Hickey, Jimmy and Henao, Ricardo and Wojdyla, Daniel and Pencina, Michael and Engelhard, Matthew},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1351--1359},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hickey24a/hickey24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hickey24a.html},\n  abstract = \t {Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop Adaptive Discretization for Event PredicTion (ADEPT) to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical decision-making by suggesting time intervals that are most appropriate for each task, in the sense that they facilitate more accurate risk prediction.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hickey24a/hickey24a.pdf",
        "supp": "",
        "pdf_size": 880278,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FYHeNq-2JRUJ:scholar.google.com/&scioq=Adaptive+Discretization+for+Event+PredicTion+(ADEPT)&hl=en&as_sdt=0,33",
        "gs_version_total": 7,
        "aff": "North Carolina State University; King Abdullah University of Science and Technology+Duke AI Health+Duke University School of Medicine; Duke Clinical Research Institute; Duke AI Health+Duke University School of Medicine; Duke AI Health+Duke University School of Medicine",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2+2;2;2+2;2+2",
        "aff_unique_norm": "North Carolina State University;King Abdullah University of Science and Technology;Duke University",
        "aff_unique_dep": ";;Duke AI Health",
        "aff_unique_url": "https://www.ncsu.edu;https://www.kast.kau.edu.sa;https://duke.ai",
        "aff_unique_abbr": "NCSU;KAUST;Duke AI Health",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0+0;0;0+0;0+0",
        "aff_country_unique": "United States;Saudi Arabia"
    },
    {
        "id": "5f8a3a8e83",
        "title": "Adaptive Experiment Design with Synthetic Controls",
        "site": "https://proceedings.mlr.press/v238/huyuk24a.html",
        "author": "Alihan H\u00fcy\u00fck; Zhaozhi Qian; Mihaela van der Schaar",
        "abstract": "Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations\u2014especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through experiments.",
        "bibtex": "@InProceedings{pmlr-v238-huyuk24a,\n  title = \t {Adaptive Experiment Design with Synthetic Controls},\n  author =       {H\\\"{u}y\\\"{u}k, Alihan and Qian, Zhaozhi and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1180--1188},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/huyuk24a/huyuk24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/huyuk24a.html},\n  abstract = \t {Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations\u2014especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/huyuk24a/huyuk24a.pdf",
        "supp": "",
        "pdf_size": 889070,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1226977635230558994&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; University of Cambridge; University of Cambridge",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "3cd4024c41",
        "title": "Adaptive Federated Minimax Optimization with Lower Complexities",
        "site": "https://proceedings.mlr.press/v238/huang24c.html",
        "author": "Feihu Huang; Xinrui Wang; Junyi Li; Songcan Chen",
        "abstract": "Federated learning is a popular distributed and privacy-preserving learning paradigm in machine learning. Recently, some federated learning algorithms have been proposed to solve the distributed minimax problems. However, these federated minimax algorithms still suffer from high gradient or communication complexity. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate these algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrices. Theoretically, we provide a solid convergence analysis framework for our AdaFGDA algorithm under non-i.i.d. setting. Moreover, we prove our AdaFGDA algorithm obtains a lower gradient (i.e., stochastic first-order oracle, SFO) complexity of $\\tilde{O}(\\epsilon^{-3})$ with lower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding $\\epsilon$-stationary point of the nonconvex minimax problems. Experimentally, we conduct some experiments on the deep AUC maximization and robust neural network training tasks to verify efficiency of our algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-huang24c,\n  title = \t {Adaptive Federated Minimax Optimization with Lower Complexities},\n  author =       {Huang, Feihu and Wang, Xinrui and Li, Junyi and Chen, Songcan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4663--4671},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/huang24c/huang24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/huang24c.html},\n  abstract = \t {Federated learning is a popular distributed and privacy-preserving learning paradigm in machine learning. Recently, some federated learning algorithms have been proposed to solve the distributed minimax problems. However, these federated minimax algorithms still suffer from high gradient or communication complexity. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate these algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrices. Theoretically, we provide a solid convergence analysis framework for our AdaFGDA algorithm under non-i.i.d. setting. Moreover, we prove our AdaFGDA algorithm obtains a lower gradient (i.e., stochastic first-order oracle, SFO) complexity of $\\tilde{O}(\\epsilon^{-3})$ with lower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding $\\epsilon$-stationary point of the nonconvex minimax problems. Experimentally, we conduct some experiments on the deep AUC maximization and robust neural network training tasks to verify efficiency of our algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/huang24c/huang24c.pdf",
        "supp": "",
        "pdf_size": 1645367,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2787462844465393508&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China+MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China+MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, China; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, USA; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China+MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, China",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;2;0+1",
        "aff_unique_norm": "Nanjing University of Aeronautics and Astronautics;MIIT;University of Pittsburgh",
        "aff_unique_dep": "College of Computer Science and Technology;Key Laboratory of Pattern Analysis and Machine Intelligence;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.nuaa.edu.cn;;https://www.pitt.edu",
        "aff_unique_abbr": "NUAA;MIIT;Pitt",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Nanjing;;Pittsburgh",
        "aff_country_unique_index": "0+0;0+0;1;0+0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8ff3b8528a",
        "title": "Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification",
        "site": "https://proceedings.mlr.press/v238/heidari24a.html",
        "author": "Marzi Heidari; Abdullah Alchihabi; Qing En; Yuhong Guo",
        "abstract": "Cross-domain few-shot classification induces a much more challenging problem than its in-domain counterpart due to the existence of domain shifts between the training and test tasks. In this paper, we develop a novel Adaptive Parametric Prototype Learning (APPL) method under the meta-learning convention for cross-domain few-shot classification. Different from existing prototypical few-shot methods that use the averages of support instances to calculate the class prototypes, we propose to learn class prototypes from the concatenated features of the support set in a parametric fashion and meta-learn the model by enforcing prototype-based regularization on the query set. In addition, we fine-tune the model in the target domain in a transductive manner using a weighted-moving-average self-training approach on the query instances. We conduct experiments on multiple cross-domain few-shot benchmark datasets. The empirical results demonstrate that APPL yields superior performance to many state-of-the-art cross-domain few-shot learning methods.",
        "bibtex": "@InProceedings{pmlr-v238-heidari24a,\n  title = \t {Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification},\n  author =       {Heidari, Marzi and Alchihabi, Abdullah and En, Qing and Guo, Yuhong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1369--1377},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/heidari24a/heidari24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/heidari24a.html},\n  abstract = \t {Cross-domain few-shot classification induces a much more challenging problem than its in-domain counterpart due to the existence of domain shifts between the training and test tasks. In this paper, we develop a novel Adaptive Parametric Prototype Learning (APPL) method under the meta-learning convention for cross-domain few-shot classification. Different from existing prototypical few-shot methods that use the averages of support instances to calculate the class prototypes, we propose to learn class prototypes from the concatenated features of the support set in a parametric fashion and meta-learn the model by enforcing prototype-based regularization on the query set. In addition, we fine-tune the model in the target domain in a transductive manner using a weighted-moving-average self-training approach on the query instances. We conduct experiments on multiple cross-domain few-shot benchmark datasets. The empirical results demonstrate that APPL yields superior performance to many state-of-the-art cross-domain few-shot learning methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/heidari24a/heidari24a.pdf",
        "supp": "",
        "pdf_size": 1456176,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:zdLTnrAif2UJ:scholar.google.com/&scioq=Adaptive+Parametric+Prototype+Learning+for+Cross-Domain+Few-Shot+Classification&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "School of Computer Science, Carleton University, Ottawa, Canada; School of Computer Science, Carleton University, Ottawa, Canada; School of Computer Science, Carleton University, Ottawa, Canada; School of Computer Science, Carleton University, Ottawa, Canada + Canada CIFAR AI Chair, Amii, Canada",
        "aff_domain": "cmail.carleton.ca;cmail.carleton.ca;cunet.carleton.ca;carleton.ca",
        "email": "cmail.carleton.ca;cmail.carleton.ca;cunet.carleton.ca;carleton.ca",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+1",
        "aff_unique_norm": "Carleton University;Amii",
        "aff_unique_dep": "School of Computer Science;Canada CIFAR AI Chair",
        "aff_unique_url": "https://carleton.ca;",
        "aff_unique_abbr": "Carleton;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ottawa;",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "0464c631e0",
        "title": "Adaptive Quasi-Newton and Anderson Acceleration Framework with Explicit Global (Accelerated) Convergence Rates",
        "site": "https://proceedings.mlr.press/v238/scieur24a.html",
        "author": "Damien Scieur",
        "abstract": "Despite the impressive numerical performance of the quasi-Newton and Anderson/nonlinear acceleration methods, their global convergence rates have remained elusive for over 50 years. This study addresses this long-standing issue by introducing a framework that derives novel, adaptive quasi-Newton and nonlinear/Anderson acceleration schemes. Under mild assumptions, the proposed iterative methods exhibit explicit, non-asymptotic convergence rates that blend those of the gradient descent and Cubic Regularized Newton\u2019s methods. The proposed approach also includes an accelerated version for convex functions. Notably, these rates are achieved adaptively without prior knowledge of the function\u2019s parameters. The framework presented in this study is generic, and its special cases include algorithms such as Newton\u2019s method with random subspaces, finite differences, or lazy Hessian. Numerical experiments demonstrated the efficiency of the proposed framework, even compared to the l-BFGS algorithm with Wolfe line-search. The code used in the experiments is available on \\url{https://github.com/windows7lover/QN_With_Guarantees}.",
        "bibtex": "@InProceedings{pmlr-v238-scieur24a,\n  title = \t {Adaptive Quasi-{N}ewton and {A}nderson Acceleration Framework with Explicit Global (Accelerated) Convergence Rates},\n  author =       {Scieur, Damien},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {883--891},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/scieur24a/scieur24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/scieur24a.html},\n  abstract = \t {Despite the impressive numerical performance of the quasi-Newton and Anderson/nonlinear acceleration methods, their global convergence rates have remained elusive for over 50 years. This study addresses this long-standing issue by introducing a framework that derives novel, adaptive quasi-Newton and nonlinear/Anderson acceleration schemes. Under mild assumptions, the proposed iterative methods exhibit explicit, non-asymptotic convergence rates that blend those of the gradient descent and Cubic Regularized Newton\u2019s methods. The proposed approach also includes an accelerated version for convex functions. Notably, these rates are achieved adaptively without prior knowledge of the function\u2019s parameters. The framework presented in this study is generic, and its special cases include algorithms such as Newton\u2019s method with random subspaces, finite differences, or lazy Hessian. Numerical experiments demonstrated the efficiency of the proposed framework, even compared to the l-BFGS algorithm with Wolfe line-search. The code used in the experiments is available on \\url{https://github.com/windows7lover/QN_With_Guarantees}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/scieur24a/scieur24a.pdf",
        "supp": "",
        "pdf_size": 3144462,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9456750774619753786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Samsung SAIL Montreal",
        "aff_domain": "",
        "email": "",
        "github": "https://github.com/windows7lover/QN_With_Guarantees",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "Samsung AI Lab",
        "aff_unique_url": "https://www.samsung.com",
        "aff_unique_abbr": "Samsung SAIL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "3906349b4b",
        "title": "Adaptive and non-adaptive minimax rates for weighted Laplacian-Eigenmap based nonparametric regression",
        "site": "https://proceedings.mlr.press/v238/shi24b.html",
        "author": "Zhaoyang Shi; Krishna Balasubramanian; Wolfgang Polonik",
        "abstract": "We show both adaptive and non-adaptive minimax rates of convergence for a family of weighted Laplacian-Eigenmap based nonparametric regression methods, when the true regression function belongs to a Sobolev space and the sampling density is bounded from above and below. The adaptation methodology is based on extensions of Lepski\u2019s method and is over both the smoothness parameter ($s\\in\\mathbb{N}_{+}$) and the norm parameter ($M>0$) determining the constraints on the Sobolev space. Our results extend the non-adaptive result in Green et al., (2023), established for a specific normalized graph Laplacian, to a wide class of weighted Laplacian matrices used in practice, including the unnormalized Laplacian and random walk Laplacian.",
        "bibtex": "@InProceedings{pmlr-v238-shi24b,\n  title = \t {Adaptive and non-adaptive minimax rates for weighted {L}aplacian-Eigenmap based nonparametric regression},\n  author =       {Shi, Zhaoyang and Balasubramanian, Krishna and Polonik, Wolfgang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2800--2808},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shi24b/shi24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shi24b.html},\n  abstract = \t {We show both adaptive and non-adaptive minimax rates of convergence for a family of weighted Laplacian-Eigenmap based nonparametric regression methods, when the true regression function belongs to a Sobolev space and the sampling density is bounded from above and below. The adaptation methodology is based on extensions of Lepski\u2019s method and is over both the smoothness parameter ($s\\in\\mathbb{N}_{+}$) and the norm parameter ($M>0$) determining the constraints on the Sobolev space. Our results extend the non-adaptive result in Green et al., (2023), established for a specific normalized graph Laplacian, to a wide class of weighted Laplacian matrices used in practice, including the unnormalized Laplacian and random walk Laplacian.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shi24b/shi24b.pdf",
        "supp": "",
        "pdf_size": 527358,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:p1yCgb-3qbQJ:scholar.google.com/&scioq=Adaptive+and+non-adaptive+minimax+rates+for+weighted+Laplacian-Eigenmap+based+nonparametric+regression&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "University of California, Davis; University of California, Davis; University of California, Davis",
        "aff_domain": "ucdavis.edu;ucdavis.edu;ucdavis.edu",
        "email": "ucdavis.edu;ucdavis.edu;ucdavis.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ab3697cf71",
        "title": "Adaptive importance sampling for heavy-tailed distributions via $\u03b1$-divergence minimization",
        "site": "https://proceedings.mlr.press/v238/guilmeau24a.html",
        "author": "Thomas Guilmeau; Nicola Branchini; Emilie Chouzenoux; Victor Elvira",
        "abstract": "Adaptive importance sampling (AIS) algorithms are widely used to approximate expectations with respect to complicated target probability distributions. When the target has heavy tails, existing AIS algorithms can provide inconsistent estimators or exhibit slow convergence, as they often neglect the target\u2019s tail behaviour. To avoid this pitfall, we propose an AIS algorithm that approximates the target by Student-t proposal distributions. We adapt location and scale parameters by matching the escort moments - which are defined even for heavy-tailed distributions - of the target and proposal. These updates minimize the $\\alpha$-divergence between the target and the proposal, thereby connecting with variational inference. We then show that the $\\alpha$-divergence can be approximated by a generalized notion of effective sample size and leverage this new perspective to adapt the tail parameter with Bayesian optimization. We demonstrate the efficacy of our approach through applications to synthetic targets and a Bayesian Student-t regression task on a real example with clinical trial data.",
        "bibtex": "@InProceedings{pmlr-v238-guilmeau24a,\n  title = \t {Adaptive importance sampling for heavy-tailed distributions via $\u03b1$-divergence minimization},\n  author =       {Guilmeau, Thomas and Branchini, Nicola and Chouzenoux, Emilie and Elvira, Victor},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3871--3879},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/guilmeau24a/guilmeau24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/guilmeau24a.html},\n  abstract = \t {Adaptive importance sampling (AIS) algorithms are widely used to approximate expectations with respect to complicated target probability distributions. When the target has heavy tails, existing AIS algorithms can provide inconsistent estimators or exhibit slow convergence, as they often neglect the target\u2019s tail behaviour. To avoid this pitfall, we propose an AIS algorithm that approximates the target by Student-t proposal distributions. We adapt location and scale parameters by matching the escort moments - which are defined even for heavy-tailed distributions - of the target and proposal. These updates minimize the $\\alpha$-divergence between the target and the proposal, thereby connecting with variational inference. We then show that the $\\alpha$-divergence can be approximated by a generalized notion of effective sample size and leverage this new perspective to adapt the tail parameter with Bayesian optimization. We demonstrate the efficacy of our approach through applications to synthetic targets and a Bayesian Student-t regression task on a real example with clinical trial data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/guilmeau24a/guilmeau24a.pdf",
        "supp": "",
        "pdf_size": 649656,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2195812716344680508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "da274a9953",
        "title": "Adaptivity of Diffusion Models to Manifold Structures",
        "site": "https://proceedings.mlr.press/v238/tang24a.html",
        "author": "Rong Tang; Yun Yang",
        "abstract": "Empirical studies have demonstrated the effectiveness of (score-based) diffusion models in generating high-dimensional data, such as texts and images, which typically exhibit a low-dimensional manifold nature. These empirical successes raise the theoretical question of whether score-based diffusion models can optimally adapt to low-dimensional manifold structures. While recent work has validated the minimax optimality of diffusion models when the target distribution admits a smooth density with respect to the Lebesgue measure of the ambient data space, these findings do not fully account for the ability of diffusion models in avoiding the the curse of dimensionality when estimating high-dimensional distributions. This work considers two common classes of diffusion models: Langevin diffusion and forward-backward diffusion. We show that both models can adapt to the intrinsic manifold structure by showing that the convergence rate of the inducing distribution estimator depends only on the intrinsic dimension of the data. Moreover, our considered estimator does not require knowing or explicitly estimating the manifold. We also demonstrate that the forward-backward diffusion can achieve the minimax optimal rate under the Wasserstein metric when the target distribution possesses a smooth density with respect to the volume measure of the low-dimensional manifold.",
        "bibtex": "@InProceedings{pmlr-v238-tang24a,\n  title = \t {Adaptivity of Diffusion Models to Manifold Structures},\n  author =       {Tang, Rong and Yang, Yun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1648--1656},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tang24a/tang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tang24a.html},\n  abstract = \t {Empirical studies have demonstrated the effectiveness of (score-based) diffusion models in generating high-dimensional data, such as texts and images, which typically exhibit a low-dimensional manifold nature. These empirical successes raise the theoretical question of whether score-based diffusion models can optimally adapt to low-dimensional manifold structures. While recent work has validated the minimax optimality of diffusion models when the target distribution admits a smooth density with respect to the Lebesgue measure of the ambient data space, these findings do not fully account for the ability of diffusion models in avoiding the the curse of dimensionality when estimating high-dimensional distributions. This work considers two common classes of diffusion models: Langevin diffusion and forward-backward diffusion. We show that both models can adapt to the intrinsic manifold structure by showing that the convergence rate of the inducing distribution estimator depends only on the intrinsic dimension of the data. Moreover, our considered estimator does not require knowing or explicitly estimating the manifold. We also demonstrate that the forward-backward diffusion can achieve the minimax optimal rate under the Wasserstein metric when the target distribution possesses a smooth density with respect to the volume measure of the low-dimensional manifold.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tang24a/tang24a.pdf",
        "supp": "",
        "pdf_size": 3452529,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3226787950778157752&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Hong Kong University of Science and Technology; University of Illinois Urbana-Champaign",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of Illinois Urbana-Champaign",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ust.hk;https://illinois.edu",
        "aff_unique_abbr": "HKUST;UIUC",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Hong Kong SAR;Urbana-Champaign",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "b3337bbba1",
        "title": "Agnostic Multi-Robust Learning using ERM",
        "site": "https://proceedings.mlr.press/v238/ahmadi24a.html",
        "author": "Saba Ahmadi; Avrim Blum; Omar Montasser; Kevin M Stangl",
        "abstract": "A fundamental problem in robust learning is asymmetry: a learner needs to correctly classify every one of exponentially-many perturbations that an adversary might make to a test-time natural example. In contrast, the attacker only needs to find one successful perturbation. Xiang et al.[2022] proposed an algorithm that in the context of patch attacks for image classification, reduces the effective number of perturbations from an exponential to a polynomial number of perturbations and learns using an ERM oracle. However, to achieve its guarantee, their algorithm requires the natural examples to be robustly realizable. This prompts the natural question; can we extend their approach to the non-robustly-realizable case where there is no classifier with zero robust error? Our first contribution is to answer this question affirmatively by reducing this problem to a setting in which an algorithm proposed by Feige et al. [2015] can be applied, and in the process extend their guarantees. Next, we extend our results to a multi-group setting and introduce a novel agnostic multi-robust learning problem where the goal is to learn a predictor that achieves low robust loss on a (potentially) rich collection of subgroups.",
        "bibtex": "@InProceedings{pmlr-v238-ahmadi24a,\n  title = \t {Agnostic Multi-Robust Learning using {ERM}},\n  author =       {Ahmadi, Saba and Blum, Avrim and Montasser, Omar and M Stangl, Kevin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2242--2250},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ahmadi24a/ahmadi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ahmadi24a.html},\n  abstract = \t {A fundamental problem in robust learning is asymmetry: a learner needs to correctly classify every one of exponentially-many perturbations that an adversary might make to a test-time natural example. In contrast, the attacker only needs to find one successful perturbation. Xiang et al.[2022] proposed an algorithm that in the context of patch attacks for image classification, reduces the effective number of perturbations from an exponential to a polynomial number of perturbations and learns using an ERM oracle. However, to achieve its guarantee, their algorithm requires the natural examples to be robustly realizable. This prompts the natural question; can we extend their approach to the non-robustly-realizable case where there is no classifier with zero robust error? Our first contribution is to answer this question affirmatively by reducing this problem to a setting in which an algorithm proposed by Feige et al. [2015] can be applied, and in the process extend their guarantees. Next, we extend our results to a multi-group setting and introduce a novel agnostic multi-robust learning problem where the goal is to learn a predictor that achieves low robust loss on a (potentially) rich collection of subgroups.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ahmadi24a/ahmadi24a.pdf",
        "supp": "",
        "pdf_size": 464401,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:odZ2WrNEG7QJ:scholar.google.com/&scioq=Agnostic+Multi-Robust+Learning+using+ERM&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "49f2eefb0b",
        "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
        "site": "https://proceedings.mlr.press/v238/wright24a.html",
        "author": "Oren Wright; Yorie Nakahira; Jos\u00e9 M. F. Moura",
        "abstract": "Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.",
        "bibtex": "@InProceedings{pmlr-v238-wright24a,\n  title = \t {An Analytic Solution to Covariance Propagation in Neural Networks},\n  author =       {Wright, Oren and Nakahira, Yorie and M. F. Moura, Jos\\'{e}},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4087--4095},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wright24a/wright24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wright24a.html},\n  abstract = \t {Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wright24a/wright24a.pdf",
        "supp": "",
        "pdf_size": 843320,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7076623720954100883&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f488fdadd3",
        "title": "An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization",
        "site": "https://proceedings.mlr.press/v238/chen24b.html",
        "author": "Lesi Chen; Haishan Ye; Luo Luo",
        "abstract": "This paper studies the stochastic nonconvex-strongly-concave minimax optimization over a multi-agent network. We propose an efficient algorithm, called Decentralized Recursive gradient descEnt Ascent Method (DREAM), which achieves the best-known theoretical guarantee for finding the $\\epsilon$-stationary points. Concretely, it requires $\\mathcal{O}(\\min (\\kappa^3\\epsilon^{-3},\\kappa^2 \\sqrt{N} \\epsilon^{-2} ))$ stochastic first-order oracle (SFO) calls and $\\tilde \\mathcal O(\\kappa^2 \\epsilon^{-2})$ communication rounds, where $\\kappa$ is the condition number and $N$ is the total number of individual functions. Our numerical experiments also validate the superiority of DREAM over previous methods.",
        "bibtex": "@InProceedings{pmlr-v238-chen24b,\n  title = \t {An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization},\n  author =       {Chen, Lesi and Ye, Haishan and Luo, Luo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1990--1998},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24b/chen24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24b.html},\n  abstract = \t {This paper studies the stochastic nonconvex-strongly-concave minimax optimization over a multi-agent network. We propose an efficient algorithm, called Decentralized Recursive gradient descEnt Ascent Method (DREAM), which achieves the best-known theoretical guarantee for finding the $\\epsilon$-stationary points. Concretely, it requires $\\mathcal{O}(\\min (\\kappa^3\\epsilon^{-3},\\kappa^2 \\sqrt{N} \\epsilon^{-2} ))$ stochastic first-order oracle (SFO) calls and $\\tilde \\mathcal O(\\kappa^2 \\epsilon^{-2})$ communication rounds, where $\\kappa$ is the condition number and $N$ is the total number of individual functions. Our numerical experiments also validate the superiority of DREAM over previous methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24b/chen24b.pdf",
        "supp": "",
        "pdf_size": 641994,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15173687218607316629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua Univerisity; School of Management, Xi\u2019an Jiaotong University + SGIT AI Lab, State Grid Corporation of China; School of Data Science, Fudan University + Shanghai Key Laboratory for Contemporary Applied Mathematics",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3+4",
        "aff_unique_norm": "Tsinghua University;Xi'an Jiao Tong University;State Grid Corporation of China;Fudan University;Shanghai Key Laboratory for Contemporary Applied Mathematics",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;School of Management;SGIT AI Lab;School of Data Science;Contemporary Applied Mathematics",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://en.xjtu.edu.cn/;http://www.sgcc.com.cn;https://www.fudan.edu.cn;",
        "aff_unique_abbr": "Tsinghua;XJTU;;Fudan;",
        "aff_campus_unique_index": "0;1;",
        "aff_campus_unique": "Beijing;Xi'an;",
        "aff_country_unique_index": "0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "3b6ec67a75",
        "title": "An Impossibility Theorem for Node Embedding",
        "site": "https://proceedings.mlr.press/v238/mitchell-roddenberry24a.html",
        "author": "T. Mitchell Roddenberry; Yu Zhu; Santiago Segarra",
        "abstract": "With the increasing popularity of graph-based methods for dimensionality reduction and representation learning, node embedding functions have become important objects of study in the literature. In this paper, we take an axiomatic approach to understanding node embedding methods. Motivated by desirable properties of node embeddings for encoding the role of a node in the structure of a network, we first state three properties for embedding dissimilarity networks. We then prove that no node embedding method can satisfy all three properties at once, reflecting fundamental difficulties inherent to the task. Having identified these difficulties, we show that mild relaxations of these axioms allow for certain node embedding methods to be admissible.",
        "bibtex": "@InProceedings{pmlr-v238-mitchell-roddenberry24a,\n  title = \t {An Impossibility Theorem for Node Embedding},\n  author =       {Mitchell Roddenberry, T. and Zhu, Yu and Segarra, Santiago},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2422--2430},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mitchell-roddenberry24a/mitchell-roddenberry24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mitchell-roddenberry24a.html},\n  abstract = \t {With the increasing popularity of graph-based methods for dimensionality reduction and representation learning, node embedding functions have become important objects of study in the literature. In this paper, we take an axiomatic approach to understanding node embedding methods. Motivated by desirable properties of node embeddings for encoding the role of a node in the structure of a network, we first state three properties for embedding dissimilarity networks. We then prove that no node embedding method can satisfy all three properties at once, reflecting fundamental difficulties inherent to the task. Having identified these difficulties, we show that mild relaxations of these axioms allow for certain node embedding methods to be admissible.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mitchell-roddenberry24a/mitchell-roddenberry24a.pdf",
        "supp": "",
        "pdf_size": 521108,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:utw4cazPaVkJ:scholar.google.com/&scioq=An+Impossibility+Theorem+for+Node+Embedding&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c9bbef3af2",
        "title": "An Improved Algorithm for Learning Drifting Discrete Distributions",
        "site": "https://proceedings.mlr.press/v238/mazzetto24a.html",
        "author": "Alessio Mazzetto",
        "abstract": "We present a new adaptive algorithm for learning discrete distributions under distribution drift. In this setting, we observe a sequence of independent samples from a discrete distribution that is changing over time, and the goal is to estimate the current distribution. Since we have access to only a single sample for each time step, a good estimation requires a careful choice of the number of past samples to use. To use more samples, we must resort to samples further in the past, and we incur a drift error due to the bias introduced by the change in distribution. On the other hand, if we use a small number of past samples, we incur a large statistical error as the estimation has a high variance. We present a novel adaptive algorithm that can solve this trade-off without any prior knowledge of the drift. Unlike previous adaptive results, our algorithm characterizes the statistical error using data-dependent bounds. This technicality enables us to overcome the limitations of the previous work that require a fixed finite support whose size is known in advance and that cannot change over time. Additionally, we can obtain tighter bounds depending on the complexity of the drifting distribution, and also consider distributions with infinite support.",
        "bibtex": "@InProceedings{pmlr-v238-mazzetto24a,\n  title = \t {An Improved Algorithm for Learning Drifting Discrete Distributions},\n  author =       {Mazzetto, Alessio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4159--4167},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mazzetto24a/mazzetto24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mazzetto24a.html},\n  abstract = \t {We present a new adaptive algorithm for learning discrete distributions under distribution drift. In this setting, we observe a sequence of independent samples from a discrete distribution that is changing over time, and the goal is to estimate the current distribution. Since we have access to only a single sample for each time step, a good estimation requires a careful choice of the number of past samples to use. To use more samples, we must resort to samples further in the past, and we incur a drift error due to the bias introduced by the change in distribution. On the other hand, if we use a small number of past samples, we incur a large statistical error as the estimation has a high variance. We present a novel adaptive algorithm that can solve this trade-off without any prior knowledge of the drift. Unlike previous adaptive results, our algorithm characterizes the statistical error using data-dependent bounds. This technicality enables us to overcome the limitations of the previous work that require a fixed finite support whose size is known in advance and that cannot change over time. Additionally, we can obtain tighter bounds depending on the complexity of the drifting distribution, and also consider distributions with infinite support.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mazzetto24a/mazzetto24a.pdf",
        "supp": "",
        "pdf_size": 322046,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12176348070777089803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Brown University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1ff6484e6b",
        "title": "An Online Bootstrap for Time Series",
        "site": "https://proceedings.mlr.press/v238/palm24a.html",
        "author": "Nicolai Palm; Thomas Nagler",
        "abstract": "Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and practitioners in dynamic, data-rich environments.",
        "bibtex": "@InProceedings{pmlr-v238-palm24a,\n  title = \t {An Online Bootstrap for Time Series},\n  author =       {Palm, Nicolai and Nagler, Thomas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {190--198},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/palm24a/palm24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/palm24a.html},\n  abstract = \t {Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and practitioners in dynamic, data-rich environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/palm24a/palm24a.pdf",
        "supp": "",
        "pdf_size": 542264,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:226MUQVMIgkJ:scholar.google.com/&scioq=An+Online+Bootstrap+for+Time+Series&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "LMU Munich + Munich Center for Machine Learning (MCML); LMU Munich + Munich Center for Machine Learning (MCML)",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Ludwig Maximilian University of Munich;Munich Center for Machine Learning",
        "aff_unique_dep": ";Center for Machine Learning",
        "aff_unique_url": "https://www.lmu.de;https://www.munich-center-for-machine-learning.de",
        "aff_unique_abbr": "LMU;MCML",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "2f685b7bb5",
        "title": "Analysis of Kernel Mirror Prox for Measure Optimization",
        "site": "https://proceedings.mlr.press/v238/dvurechensky24a.html",
        "author": "Pavel Dvurechensky; Jia-Jie Zhu",
        "abstract": "By choosing a suitable function space as the dual to the non-negative measure cone, we study in a unified framework a class of functional saddle-point optimization problems, which we term the Mixed Functional Nash Equilibrium (MFNE), that underlies several existing machine learning algorithms, such as implicit generative models, distributionally robust optimization (DRO), and Wasserstein barycenters. We model the saddle-point optimization dynamics as an interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as a reproducing kernel Hilbert space (RKHS). As a discrete time counterpart, we propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual step in the RKHS, and a primal entropic mirror prox step. We then provide a unified convergence analysis of KMP in an infinite-dimensional setting for this class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the deterministic case and $O(1/\\sqrt{N})$ in the stochastic case, where $N$ is the iteration counter. As a case study, we apply our analysis to DRO, providing algorithmic guarantees for DRO robustness and convergence.",
        "bibtex": "@InProceedings{pmlr-v238-dvurechensky24a,\n  title = \t {Analysis of Kernel Mirror Prox for Measure Optimization},\n  author =       {Dvurechensky, Pavel and Zhu, Jia-Jie},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2350--2358},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dvurechensky24a/dvurechensky24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dvurechensky24a.html},\n  abstract = \t {By choosing a suitable function space as the dual to the non-negative measure cone, we study in a unified framework a class of functional saddle-point optimization problems, which we term the Mixed Functional Nash Equilibrium (MFNE), that underlies several existing machine learning algorithms, such as implicit generative models, distributionally robust optimization (DRO), and Wasserstein barycenters. We model the saddle-point optimization dynamics as an interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as a reproducing kernel Hilbert space (RKHS). As a discrete time counterpart, we propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual step in the RKHS, and a primal entropic mirror prox step. We then provide a unified convergence analysis of KMP in an infinite-dimensional setting for this class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the deterministic case and $O(1/\\sqrt{N})$ in the stochastic case, where $N$ is the iteration counter. As a case study, we apply our analysis to DRO, providing algorithmic guarantees for DRO robustness and convergence.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dvurechensky24a/dvurechensky24a.pdf",
        "supp": "",
        "pdf_size": 484207,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15634765705398145125&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2757fae19f",
        "title": "Analysis of Privacy Leakage in Federated Large Language Models",
        "site": "https://proceedings.mlr.press/v238/vu24a.html",
        "author": "Minh Vu; Truc Nguyen; Tre\u2019 Jeter; My T. Thai",
        "abstract": "With the rapid adoption of Federated Learning (FL) as the training and tuning protocol for applications utilizing Large Language Models (LLMs), recent research highlights the need for significant modifications to FL to accommodate the large-scale of LLMs. While substantial adjustments to the protocol have been introduced as a response, comprehensive privacy analysis for the adapted FL protocol is currently lacking. To address this gap, our work delves into an extensive examination of the privacy analysis of FL when used for training LLMs, both from theoretical and practical perspectives. In particular, we design two active membership inference attacks with guaranteed theoretical success rates to assess the privacy leakages of various adapted FL configurations. Our theoretical findings are translated into practical attacks, revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa, DistilBERT, and OpenAI\u2019s GPTs, across multiple real-world language datasets. Additionally, we conduct thorough experiments to evaluate the privacy leakage of these models when data is protected by state-of-the-art differential privacy (DP) mechanisms.",
        "bibtex": "@InProceedings{pmlr-v238-vu24a,\n  title = \t {Analysis of Privacy Leakage in Federated Large Language Models},\n  author =       {Vu, Minh and Nguyen, Truc and Jeter, Tre' and T. Thai, My},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1423--1431},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vu24a/vu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vu24a.html},\n  abstract = \t {With the rapid adoption of Federated Learning (FL) as the training and tuning protocol for applications utilizing Large Language Models (LLMs), recent research highlights the need for significant modifications to FL to accommodate the large-scale of LLMs. While substantial adjustments to the protocol have been introduced as a response, comprehensive privacy analysis for the adapted FL protocol is currently lacking. To address this gap, our work delves into an extensive examination of the privacy analysis of FL when used for training LLMs, both from theoretical and practical perspectives. In particular, we design two active membership inference attacks with guaranteed theoretical success rates to assess the privacy leakages of various adapted FL configurations. Our theoretical findings are translated into practical attacks, revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa, DistilBERT, and OpenAI\u2019s GPTs, across multiple real-world language datasets. Additionally, we conduct thorough experiments to evaluate the privacy leakage of these models when data is protected by state-of-the-art differential privacy (DP) mechanisms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vu24a/vu24a.pdf",
        "supp": "",
        "pdf_size": 2128377,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14435660885233252506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d8f41a2321",
        "title": "Analysis of Using Sigmoid Loss for Contrastive Learning",
        "site": "https://proceedings.mlr.press/v238/lee24a.html",
        "author": "Chungpa Lee; Joonhwan Chang; Jy-yong Sohn",
        "abstract": "Contrastive learning has emerged as a prominent branch of self-supervised learning for several years. Especially, CLIP, which applies contrastive learning to large sets of captioned images, has garnered significant attention. Recently, SigLIP, a variant of CLIP, has been proposed, which uses the sigmoid loss instead of the standard InfoNCE loss. SigLIP achieves the performance comparable to CLIP in a more efficient manner by eliminating the need for a global view. However, theoretical understanding of using the sigmoid loss in contrastive learning is underexplored. In this paper, we provide a theoretical analysis of using the sigmoid loss in contrastive learning, in the perspective of the geometric structure of learned embeddings. First, we propose the double-Constant Embedding Model (CCEM), a framework for parameterizing various well-known embedding structures by a single variable. Interestingly, the proposed CCEM is proven to contain the optimal embedding with respect to the sigmoid loss. Second, we mathematically analyze the optimal embedding minimizing the sigmoid loss for contrastive learning. The optimal embedding ranges from simplex equiangular-tight-frame to antipodal structure, depending on the temperature parameter used in the sigmoid loss. Third, our experimental results on synthetic datasets coincide with the theoretical results on the optimal embedding structures.",
        "bibtex": "@InProceedings{pmlr-v238-lee24a,\n  title = \t {Analysis of Using Sigmoid Loss for Contrastive Learning},\n  author =       {Lee, Chungpa and Chang, Joonhwan and Sohn, Jy-yong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1747--1755},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lee24a/lee24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lee24a.html},\n  abstract = \t {Contrastive learning has emerged as a prominent branch of self-supervised learning for several years. Especially, CLIP, which applies contrastive learning to large sets of captioned images, has garnered significant attention. Recently, SigLIP, a variant of CLIP, has been proposed, which uses the sigmoid loss instead of the standard InfoNCE loss. SigLIP achieves the performance comparable to CLIP in a more efficient manner by eliminating the need for a global view. However, theoretical understanding of using the sigmoid loss in contrastive learning is underexplored. In this paper, we provide a theoretical analysis of using the sigmoid loss in contrastive learning, in the perspective of the geometric structure of learned embeddings. First, we propose the double-Constant Embedding Model (CCEM), a framework for parameterizing various well-known embedding structures by a single variable. Interestingly, the proposed CCEM is proven to contain the optimal embedding with respect to the sigmoid loss. Second, we mathematically analyze the optimal embedding minimizing the sigmoid loss for contrastive learning. The optimal embedding ranges from simplex equiangular-tight-frame to antipodal structure, depending on the temperature parameter used in the sigmoid loss. Third, our experimental results on synthetic datasets coincide with the theoretical results on the optimal embedding structures.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lee24a/lee24a.pdf",
        "supp": "",
        "pdf_size": 3390497,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5910079190538811691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c72e9c5aac",
        "title": "Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions",
        "site": "https://proceedings.mlr.press/v238/khan24a.html",
        "author": "Zulqarnain Q. Khan; Davin Hill; Aria Masoomi; Joshua T. Bone; Jennifer Dy",
        "abstract": "Machine learning methods have significantly improved in their predictive capabilities, but at the same time they are becoming more complex and less transparent. As a result, explainers are often relied on to provide interpretability to these black-box prediction models. As crucial diagnostics tools, it is important that these explainers themselves are robust. In this paper we focus on one particular aspect of robustness, namely that an explainer should give similar explanations for similar data inputs. We formalize this notion by introducing and defining explainer astuteness, analogous to astuteness of prediction functions. Our formalism allows us to connect explainer robustness to the predictor\u2019s probabilistic Lipschitzness, which captures the probability of local smoothness of a function. We provide lower bound guarantees on the astuteness of a variety of explainers (e.g., SHAP, RISE, CXPlain) given the Lipschitzness of the prediction function. These theoretical results imply that locally smooth prediction functions lend themselves to locally robust explanations. We evaluate these results empirically on simulated as well as real datasets.",
        "bibtex": "@InProceedings{pmlr-v238-khan24a,\n  title = \t {Analyzing Explainer Robustness via Probabilistic {L}ipschitzness of Prediction Functions},\n  author =       {Khan, Zulqarnain Q. and Hill, Davin and Masoomi, Aria and Bone, Joshua T. and Dy, Jennifer},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1378--1386},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/khan24a/khan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/khan24a.html},\n  abstract = \t {Machine learning methods have significantly improved in their predictive capabilities, but at the same time they are becoming more complex and less transparent. As a result, explainers are often relied on to provide interpretability to these black-box prediction models. As crucial diagnostics tools, it is important that these explainers themselves are robust. In this paper we focus on one particular aspect of robustness, namely that an explainer should give similar explanations for similar data inputs. We formalize this notion by introducing and defining explainer astuteness, analogous to astuteness of prediction functions. Our formalism allows us to connect explainer robustness to the predictor\u2019s probabilistic Lipschitzness, which captures the probability of local smoothness of a function. We provide lower bound guarantees on the astuteness of a variety of explainers (e.g., SHAP, RISE, CXPlain) given the Lipschitzness of the prediction function. These theoretical results imply that locally smooth prediction functions lend themselves to locally robust explanations. We evaluate these results empirically on simulated as well as real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/khan24a/khan24a.pdf",
        "supp": "",
        "pdf_size": 3518637,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16049520578413964611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University",
        "aff_domain": "ece.neu.edu;ece.neu.edu;northeastern.edu;northeastern.edu;ece.neu.edu",
        "email": "ece.neu.edu;ece.neu.edu;northeastern.edu;northeastern.edu;ece.neu.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2b2c953c22",
        "title": "Any-dimensional equivariant neural networks",
        "site": "https://proceedings.mlr.press/v238/levin24a.html",
        "author": "Eitan Levin; Mateo Diaz",
        "abstract": "Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is black-box and user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-levin24a,\n  title = \t {Any-dimensional equivariant neural networks},\n  author =       {Levin, Eitan and Diaz, Mateo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2773--2781},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/levin24a/levin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/levin24a.html},\n  abstract = \t {Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is black-box and user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/levin24a/levin24a.pdf",
        "supp": "",
        "pdf_size": 1370607,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3645343379606546057&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "California Institute of Technology; Johns Hopkins University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "California Institute of Technology;Johns Hopkins University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.caltech.edu;https://www.jhu.edu",
        "aff_unique_abbr": "Caltech;JHU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f1753d4e20",
        "title": "Anytime-Constrained Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/mcmahan24a.html",
        "author": "Jeremy McMahan; Xiaojin Zhu",
        "abstract": "We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints. An anytime constraint requires the agent to never violate its budget at any point in time, almost surely. Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs. In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP. However, we also show that computing non-trivial approximately optimal policies is NP-hard in general. To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an arbitrarily accurate approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or the absolute budget. Given our hardness results, our approximation guarantees are the best possible under worst-case analysis.",
        "bibtex": "@InProceedings{pmlr-v238-mcmahan24a,\n  title = \t {Anytime-Constrained Reinforcement Learning},\n  author =       {McMahan, Jeremy and Zhu, Xiaojin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4321--4329},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mcmahan24a/mcmahan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mcmahan24a.html},\n  abstract = \t {We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints. An anytime constraint requires the agent to never violate its budget at any point in time, almost surely. Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs. In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP. However, we also show that computing non-trivial approximately optimal policies is NP-hard in general. To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an arbitrarily accurate approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or the absolute budget. Given our hardness results, our approximation guarantees are the best possible under worst-case analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mcmahan24a/mcmahan24a.pdf",
        "supp": "",
        "pdf_size": 1283035,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12459091943861350808&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d656d8ebc1",
        "title": "Approximate Bayesian Class-Conditional Models under Continuous Representation Shift",
        "site": "https://proceedings.mlr.press/v238/lee24c.html",
        "author": "Thomas L. Lee; Amos Storkey",
        "abstract": "For models consisting of a classifier in some representation space, learning online from a non-stationary data stream often necessitates changes in the representation. So, the question arises of what is the best way to adapt the classifier to shifts in representation. Current methods only slowly change the classifier to representation shift, introducing noise into learning as the classifier is misaligned to the representation. We propose DeepCCG, an empirical Bayesian approach to solve this problem. DeepCCG works by updating the posterior of a class conditional Gaussian classifier such that the classifier adapts in one step to representation shift. The use of a class conditional Gaussian classifier also enables DeepCCG to use a log conditional marginal likelihood loss to update the representation. To perform the update to the classifier and representation, DeepCCG maintains a fixed number of examples in memory and so a key part of DeepCCG is selecting what examples to store, choosing the subset that minimises the KL divergence between the true posterior and the posterior induced by the subset. We explore the behaviour of DeepCCG in online continual learning (CL), demonstrating that it performs well against a spectrum of online CL methods and that it reduces the change in performance due to representation shift.",
        "bibtex": "@InProceedings{pmlr-v238-lee24c,\n  title = \t {Approximate {B}ayesian Class-Conditional Models under Continuous Representation Shift},\n  author =       {Lee, Thomas L. and Storkey, Amos},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3628--3636},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lee24c/lee24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lee24c.html},\n  abstract = \t {For models consisting of a classifier in some representation space, learning online from a non-stationary data stream often necessitates changes in the representation. So, the question arises of what is the best way to adapt the classifier to shifts in representation. Current methods only slowly change the classifier to representation shift, introducing noise into learning as the classifier is misaligned to the representation. We propose DeepCCG, an empirical Bayesian approach to solve this problem. DeepCCG works by updating the posterior of a class conditional Gaussian classifier such that the classifier adapts in one step to representation shift. The use of a class conditional Gaussian classifier also enables DeepCCG to use a log conditional marginal likelihood loss to update the representation. To perform the update to the classifier and representation, DeepCCG maintains a fixed number of examples in memory and so a key part of DeepCCG is selecting what examples to store, choosing the subset that minimises the KL divergence between the true posterior and the posterior induced by the subset. We explore the behaviour of DeepCCG in online continual learning (CL), demonstrating that it performs well against a spectrum of online CL methods and that it reduces the change in performance due to representation shift.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lee24c/lee24c.pdf",
        "supp": "",
        "pdf_size": 1083110,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9587574524798557229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh",
        "aff_domain": "sms.ed.ac.uk;ed.ac.uk",
        "email": "sms.ed.ac.uk;ed.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "60b9ccb09f",
        "title": "Approximate Control for Continuous-Time POMDPs",
        "site": "https://proceedings.mlr.press/v238/eich24a.html",
        "author": "Yannick Eich; Bastian Alt; Heinz Koeppl",
        "abstract": "This work proposes a decision-making framework for partially observable systems in continuous time with discrete state and action spaces. As optimal decision-making becomes intractable for large state spaces we employ approximation methods for the filtering and the control problem that scale well with an increasing number of states. Specifically, we approximate the high-dimensional filtering distribution by projecting it onto a parametric family of distributions, and integrate it into a control heuristic based on the fully observable system to obtain a scalable policy. We demonstrate the effectiveness of our approach on several partially observed systems, including queueing systems and chemical reaction networks.",
        "bibtex": "@InProceedings{pmlr-v238-eich24a,\n  title = \t {Approximate Control for Continuous-Time {POMDPs}},\n  author =       {Eich, Yannick and Alt, Bastian and Koeppl, Heinz},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3160--3168},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/eich24a/eich24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/eich24a.html},\n  abstract = \t {This work proposes a decision-making framework for partially observable systems in continuous time with discrete state and action spaces. As optimal decision-making becomes intractable for large state spaces we employ approximation methods for the filtering and the control problem that scale well with an increasing number of states. Specifically, we approximate the high-dimensional filtering distribution by projecting it onto a parametric family of distributions, and integrate it into a control heuristic based on the fully observable system to obtain a scalable policy. We demonstrate the effectiveness of our approach on several partially observed systems, including queueing systems and chemical reaction networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/eich24a/eich24a.pdf",
        "supp": "",
        "pdf_size": 1597338,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3963082254303754891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt",
        "aff_domain": "tu-darmstadt.de;tu-darmstadt.de;tu-darmstadt.de",
        "email": "tu-darmstadt.de;tu-darmstadt.de;tu-darmstadt.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "b657809d0b",
        "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$ Regularizers",
        "site": "https://proceedings.mlr.press/v238/auddy24a.html",
        "author": "Arnab Auddy; Haolin Zou; Kamiar Rahnamarad; Arian Maleki",
        "abstract": "The out-of-sample error (OO) is the main quantity of interest in risk estimation and model selection. Leave-one-out cross validation (LO) offers a (nearly) distribution-free yet computationally demanding method to estimate OO. Recent theoretical work showed that approximate leave-one-out cross validation (ALO) is a computationally efficient and statistically reliable estimate of LO (and OO) for generalized linear models with twice differentiable regularizers. For problems involving non-differentiable regularizers, despite significant empirical evidence, the theoretical understanding of ALO\u2019s error remains unknown. In this paper, we present a novel theory for a wide class of problems in the generalized linear model family with the non-differentiable $\\ell_1$ regularizer. We bound the error \\(|{\\rm ALO}-{\\rm LO}|\\){in} terms of intuitive metrics such as the size of leave-\\(i\\)-out perturbations in active sets, sample size $n$, number of features $p$ and signal-to-noise ratio (SNR). As a consequence, for the $\\ell_1$ regularized problems, we show that $|{\\rm ALO}-{\\rm LO}| \\stackrel{p\\rightarrow \\infty}{\\longrightarrow} 0$ while $n/p$ and SNR remain bounded.",
        "bibtex": "@InProceedings{pmlr-v238-auddy24a,\n  title = \t {Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$ Regularizers},\n  author =       {Auddy, Arnab and Zou, Haolin and Rahnamarad, Kamiar and Maleki, Arian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2377--2385},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/auddy24a/auddy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/auddy24a.html},\n  abstract = \t {The out-of-sample error (OO) is the main quantity of interest in risk estimation and model selection. Leave-one-out cross validation (LO) offers a (nearly) distribution-free yet computationally demanding method to estimate OO. Recent theoretical work showed that approximate leave-one-out cross validation (ALO) is a computationally efficient and statistically reliable estimate of LO (and OO) for generalized linear models with twice differentiable regularizers. For problems involving non-differentiable regularizers, despite significant empirical evidence, the theoretical understanding of ALO\u2019s error remains unknown. In this paper, we present a novel theory for a wide class of problems in the generalized linear model family with the non-differentiable $\\ell_1$ regularizer. We bound the error \\(|{\\rm ALO}-{\\rm LO}|\\){in} terms of intuitive metrics such as the size of leave-\\(i\\)-out perturbations in active sets, sample size $n$, number of features $p$ and signal-to-noise ratio (SNR). As a consequence, for the $\\ell_1$ regularized problems, we show that $|{\\rm ALO}-{\\rm LO}| \\stackrel{p\\rightarrow \\infty}{\\longrightarrow} 0$ while $n/p$ and SNR remain bounded.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/auddy24a/auddy24a.pdf",
        "supp": "",
        "pdf_size": 1383451,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7274496150261005301&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "225e7d3956",
        "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
        "site": "https://proceedings.mlr.press/v238/islamov24a.html",
        "author": "Rustem Islamov; Mher Safaryan; Dan Alistarh",
        "abstract": "We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-once mini-batch SGD. The derived rates match the best-known results for those algorithms, highlighting the tightness of our approach. Finally, our numerical evaluations support theoretical findings and show the good practical performance of our method.",
        "bibtex": "@InProceedings{pmlr-v238-islamov24a,\n  title = \t {{AsGrad}: A Sharp Unified Analysis of Asynchronous-{SGD} Algorithms},\n  author =       {Islamov, Rustem and Safaryan, Mher and Alistarh, Dan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {649--657},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/islamov24a/islamov24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/islamov24a.html},\n  abstract = \t {We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-once mini-batch SGD. The derived rates match the best-known results for those algorithms, highlighting the tightness of our approach. Finally, our numerical evaluations support theoretical findings and show the good practical performance of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/islamov24a/islamov24a.pdf",
        "supp": "",
        "pdf_size": 4462839,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8410182159970430775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c7fe81631c",
        "title": "Asymptotic Characterisation of the Performance of Robust Linear Regression in the Presence of Outliers",
        "site": "https://proceedings.mlr.press/v238/vilucchio24a.html",
        "author": "Matteo Vilucchio; Emanuele Troiani; Vittorio Erba; Florent Krzakala",
        "abstract": "We study robust linear regression in high-dimension, when both the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\\alpha=n/d$, and study a data model that includes outliers. We provide exact asymptotics for the performances of the empirical risk minimisation (ERM) using $\\ell_2$-regularised $\\ell_2$, $\\ell_1$, and Huber losses, which are the standard approach to such problems. We focus on two metrics for the performance: the generalisation error to similar datasets with outliers, and the estimation error of the original, unpolluted function. Our results are compared with the information theoretic Bayes-optimal estimation bound. For the generalization error, we find that optimally-regularised ERM is asymptotically consistent in the large sample complexity limit if one perform a simple calibration, and compute the rates of convergence. For the estimation error however, we show that due to a norm calibration mismatch, the consistency of the estimator requires an oracle estimate of the optimal norm, or the presence of a cross-validation set not corrupted by the outliers. We examine in detail how performance depends on the loss function and on the degree of outlier corruption in the training set and identify a region of parameters where the optimal performance of the Huber loss is identical to that of the $\\ell_2$ loss, offering insights into the use cases of different loss functions.",
        "bibtex": "@InProceedings{pmlr-v238-vilucchio24a,\n  title = \t {Asymptotic Characterisation of the Performance of Robust Linear Regression in the Presence of Outliers},\n  author =       {Vilucchio, Matteo and Troiani, Emanuele and Erba, Vittorio and Krzakala, Florent},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {811--819},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vilucchio24a/vilucchio24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vilucchio24a.html},\n  abstract = \t {We study robust linear regression in high-dimension, when both the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\\alpha=n/d$, and study a data model that includes outliers. We provide exact asymptotics for the performances of the empirical risk minimisation (ERM) using $\\ell_2$-regularised $\\ell_2$, $\\ell_1$, and Huber losses, which are the standard approach to such problems. We focus on two metrics for the performance: the generalisation error to similar datasets with outliers, and the estimation error of the original, unpolluted function. Our results are compared with the information theoretic Bayes-optimal estimation bound. For the generalization error, we find that optimally-regularised ERM is asymptotically consistent in the large sample complexity limit if one perform a simple calibration, and compute the rates of convergence. For the estimation error however, we show that due to a norm calibration mismatch, the consistency of the estimator requires an oracle estimate of the optimal norm, or the presence of a cross-validation set not corrupted by the outliers. We examine in detail how performance depends on the loss function and on the degree of outlier corruption in the training set and identify a region of parameters where the optimal performance of the Huber loss is identical to that of the $\\ell_2$ loss, offering insights into the use cases of different loss functions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vilucchio24a/vilucchio24a.pdf",
        "supp": "",
        "pdf_size": 1269944,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3848230752328177832&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "IdePHICS laboratory, EPFL, 1015, Lausanne, Switzerland; SPOC laboratory, EPFL, 1015, Lausanne, Switzerland; SPOC laboratory, EPFL, 1015, Lausanne, Switzerland; IdePHICS laboratory, EPFL, 1015, Lausanne, Switzerland",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "IdePHICS laboratory",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "001d1d27f9",
        "title": "Asynchronous Randomized Trace Estimation",
        "site": "https://proceedings.mlr.press/v238/kalantzis24a.html",
        "author": "Vasileios Kalantzis; Shashanka Ubaru; Chai Wah Wu; Georgios Kollias; Lior Horesh",
        "abstract": "Randomized trace estimation is a popular technique to approximate the trace of an implicitly-defined matrix $A$ by averaging the quadratic form $x\u2019Ax$ across several samples of a random vector $x$. This paper focuses on the application of randomized trace estimators on asynchronous computing environments where the quadratic form $x\u2019Ax$ is computed partially by observing only a random row subset of $A$ for each sample of the random vector $x$. Our asynchronous framework treats the number of rows, as well as the row subset observed for each sample, as random variables, and our theoretical analysis establishes the variance of the randomized estimator for Rademacher and Gaussian samples. We also present error analysis and sampling complexity bounds for the proposed asynchronous randomized trace estimator. Our numerical experiments illustrate that the asynchronous variant can be competitive even when a small number of rows is updated per each sample.",
        "bibtex": "@InProceedings{pmlr-v238-kalantzis24a,\n  title = \t {Asynchronous Randomized Trace Estimation},\n  author =       {Kalantzis, Vasileios and Ubaru, Shashanka and Wah Wu, Chai and Kollias, Georgios and Horesh, Lior},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4294--4302},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kalantzis24a/kalantzis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kalantzis24a.html},\n  abstract = \t {Randomized trace estimation is a popular technique to approximate the trace of an implicitly-defined matrix $A$ by averaging the quadratic form $x\u2019Ax$ across several samples of a random vector $x$. This paper focuses on the application of randomized trace estimators on asynchronous computing environments where the quadratic form $x\u2019Ax$ is computed partially by observing only a random row subset of $A$ for each sample of the random vector $x$. Our asynchronous framework treats the number of rows, as well as the row subset observed for each sample, as random variables, and our theoretical analysis establishes the variance of the randomized estimator for Rademacher and Gaussian samples. We also present error analysis and sampling complexity bounds for the proposed asynchronous randomized trace estimator. Our numerical experiments illustrate that the asynchronous variant can be competitive even when a small number of rows is updated per each sample.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kalantzis24a/kalantzis24a.pdf",
        "supp": "",
        "pdf_size": 9838873,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18152581681923341314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "IBM Research, Thomas J. Watson Research Center, USA; IBM Research, Thomas J. Watson Research Center, USA; IBM Research, Thomas J. Watson Research Center, USA; IBM Research, Thomas J. Watson Research Center, USA; IBM Research, Thomas J. Watson Research Center, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "IBM",
        "aff_unique_dep": "IBM Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Thomas J. Watson Research Center",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2ccb54b126",
        "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization",
        "site": "https://proceedings.mlr.press/v238/even24a.html",
        "author": "Mathieu Even; Anastasia Koloskova; Laurent Massoulie",
        "abstract": "Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) \u2014 a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.",
        "bibtex": "@InProceedings{pmlr-v238-even24a,\n  title = \t {Asynchronous {SGD} on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization},\n  author =       {Even, Mathieu and Koloskova, Anastasia and Massoulie, Laurent},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {64--72},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/even24a/even24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/even24a.html},\n  abstract = \t {Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) \u2014 a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/even24a/even24a.pdf",
        "supp": "",
        "pdf_size": 653635,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14451024635841793380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2b8bf1894d",
        "title": "Auditing Fairness under Unobserved Confounding",
        "site": "https://proceedings.mlr.press/v238/byun24a.html",
        "author": "Yewon Byun; Dylan Sam; Michael Oberst; Zachary Lipton; Bryan Wilder",
        "abstract": "A fundamental problem in decision-making systems is the presence of inequity along demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables \u201cexplain\u201d an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any allocation, to derive unbiased estimates of risk. We apply our framework to a real-world setting of Paxlovid allocation to COVID-19 patients, finding that observed racial inequity cannot be explained by unobserved confounders of the same strength as important observed covariates.",
        "bibtex": "@InProceedings{pmlr-v238-byun24a,\n  title = \t {Auditing Fairness under Unobserved Confounding},\n  author =       {Byun, Yewon and Sam, Dylan and Oberst, Michael and Lipton, Zachary and Wilder, Bryan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4339--4347},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/byun24a/byun24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/byun24a.html},\n  abstract = \t {A fundamental problem in decision-making systems is the presence of inequity along demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables \u201cexplain\u201d an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any allocation, to derive unbiased estimates of risk. We apply our framework to a real-world setting of Paxlovid allocation to COVID-19 patients, finding that observed racial inequity cannot be explained by unobserved confounders of the same strength as important observed covariates.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/byun24a/byun24a.pdf",
        "supp": "",
        "pdf_size": 732008,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4144636606399686884&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Machine Learning Department, Carnegie Mellon University; Machine Learning Department, Carnegie Mellon University; Machine Learning Department, Carnegie Mellon University; Machine Learning Department, Carnegie Mellon University; Machine Learning Department, Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f3733581b7",
        "title": "Autoregressive Bandits",
        "site": "https://proceedings.mlr.press/v238/bacchiocchi24a.html",
        "author": "Francesco Bacchiocchi; Gianmarco Genalti; Davide Maran; Marco Mussi; Marcello Restelli; Nicola Gatti; Alberto Maria Metelli",
        "abstract": "Autoregressive processes naturally arise in a large variety of real-world scenarios, including stock markets, sales forecasting, weather prediction, advertising, and pricing. When facing a sequential decision-making problem in such a context, the temporal dependence between consecutive observations should be properly accounted for guaranteeing convergence to the optimal policy. In this work, we propose a novel online learning setting, namely, Autoregressive Bandits (ARBs), in which the observed reward is governed by an autoregressive process of order $k$, whose parameters depend on the chosen action. We show that, under mild assumptions on the reward process, the optimal policy can be conveniently computed. Then, we devise a new optimistic regret minimization algorithm, namely, AutoRegressive Upper Confidence Bound (AR-UCB), that suffers sublinear regret of order $\\tilde{O} ( \\frac{(k+1)^{3/2}\\sqrt{nT}}{(1-\\Gamma)^2} )$, where $T$ is the optimization horizon, $n$ is the number of actions, and $\\Gamma < 1$ is a stability index of the process. Finally, we empirically validate our algorithm, illustrating its advantages w.r.t. bandit baselines and its robustness to misspecification of key parameters.",
        "bibtex": "@InProceedings{pmlr-v238-bacchiocchi24a,\n  title = \t {Autoregressive Bandits},\n  author =       {Bacchiocchi, Francesco and Genalti, Gianmarco and Maran, Davide and Mussi, Marco and Restelli, Marcello and Gatti, Nicola and Maria Metelli, Alberto},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {937--945},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bacchiocchi24a/bacchiocchi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bacchiocchi24a.html},\n  abstract = \t {Autoregressive processes naturally arise in a large variety of real-world scenarios, including stock markets, sales forecasting, weather prediction, advertising, and pricing. When facing a sequential decision-making problem in such a context, the temporal dependence between consecutive observations should be properly accounted for guaranteeing convergence to the optimal policy. In this work, we propose a novel online learning setting, namely, Autoregressive Bandits (ARBs), in which the observed reward is governed by an autoregressive process of order $k$, whose parameters depend on the chosen action. We show that, under mild assumptions on the reward process, the optimal policy can be conveniently computed. Then, we devise a new optimistic regret minimization algorithm, namely, AutoRegressive Upper Confidence Bound (AR-UCB), that suffers sublinear regret of order $\\tilde{O} ( \\frac{(k+1)^{3/2}\\sqrt{nT}}{(1-\\Gamma)^2} )$, where $T$ is the optimization horizon, $n$ is the number of actions, and $\\Gamma < 1$ is a stability index of the process. Finally, we empirically validate our algorithm, illustrating its advantages w.r.t. bandit baselines and its robustness to misspecification of key parameters.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bacchiocchi24a/bacchiocchi24a.pdf",
        "supp": "",
        "pdf_size": 1531357,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4615594162767936175&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2d7259de5e",
        "title": "BLIS-Net: Classifying and Analyzing Signals on Graphs",
        "site": "https://proceedings.mlr.press/v238/xu24c.html",
        "author": "Charles Xu; Laney Goldman; Valentina Guo; Benjamin Hollander-Bodie; Maedee Trank-Greene; Ian Adelstein; Edward De Brouwer; Rex Ying; Smita Krishnaswamy; Michael Perlmutter",
        "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for tasks such as node classification and graph classification. However, much less work has been done on signal classification, where the data consists of many functions (referred to as signals) defined on the vertices of a single graph. These tasks require networks designed differently from those designed for traditional GNN tasks. Indeed, traditional GNNs rely on localized low-pass filters, and signals of interest may have intricate multi-frequency behavior and exhibit long range interactions. This motivates us to introduce the BLIS-Net (Bi-Lipschitz Scattering Net), a novel GNN that builds on the previously introduced geometric scattering transform. Our network is able to capture both local and global signal structure and is able to capture both low-frequency and high-frequency information. We make several crucial changes to the original geometric scattering architecture which we prove increase the ability of our network to capture information about the input signal and show that BLIS-Net achieves superior performance on both synthetic and real-world data sets based on traffic flow and fMRI data.",
        "bibtex": "@InProceedings{pmlr-v238-xu24c,\n  title = \t {{BLIS}-{N}et: Classifying and Analyzing Signals on Graphs},\n  author =       {Xu, Charles and Goldman, Laney and Guo, Valentina and Hollander-Bodie, Benjamin and Trank-Greene, Maedee and Adelstein, Ian and De Brouwer, Edward and Ying, Rex and Krishnaswamy, Smita and Perlmutter, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4537--4545},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xu24c/xu24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xu24c.html},\n  abstract = \t {Graph neural networks (GNNs) have emerged as a powerful tool for tasks such as node classification and graph classification. However, much less work has been done on signal classification, where the data consists of many functions (referred to as signals) defined on the vertices of a single graph. These tasks require networks designed differently from those designed for traditional GNN tasks. Indeed, traditional GNNs rely on localized low-pass filters, and signals of interest may have intricate multi-frequency behavior and exhibit long range interactions. This motivates us to introduce the BLIS-Net (Bi-Lipschitz Scattering Net), a novel GNN that builds on the previously introduced geometric scattering transform. Our network is able to capture both local and global signal structure and is able to capture both low-frequency and high-frequency information. We make several crucial changes to the original geometric scattering architecture which we prove increase the ability of our network to capture information about the input signal and show that BLIS-Net achieves superior performance on both synthetic and real-world data sets based on traffic flow and fMRI data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xu24c/xu24c.pdf",
        "supp": "",
        "pdf_size": 16177922,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12335613462900117168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Yale University; Harvey Mudd College; Yale University; Yale University; University of Colorado Boulder; Yale University; Yale University; Yale University; Yale University; Boise State University",
        "aff_domain": "yale.edu; ; ; ; ; ; ; ; ; ",
        "email": "yale.edu; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;2;0;0;0;0;3",
        "aff_unique_norm": "Yale University;Harvey Mudd College;University of Colorado;Boise State University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.yale.edu;https://www.hmc.edu;https://www.colorado.edu;https://www.boisestate.edu",
        "aff_unique_abbr": "Yale;HMC;CU;BSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Boulder",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "014dacd75f",
        "title": "BOBA: Byzantine-Robust Federated Learning with Label Skewness",
        "site": "https://proceedings.mlr.press/v238/bao24a.html",
        "author": "Wenxuan Bao; Jun Wu; Jingrui He",
        "abstract": "In federated learning, most existing robust aggregation rules (AGRs) combat Byzantine attacks in the IID setting, where client data is assumed to be independent and identically distributed. In this paper, we address label skewness, a more realistic and challenging non-IID setting, where each client only has access to a few classes of data. In this setting, state-of-the-art AGRs suffer from selection bias, leading to significant performance drop for particular classes; they are also more vulnerable to Byzantine attacks due to the increased variation among gradients of honest clients. To address these limitations, we propose an efficient two-stage method named BOBA. Theoretically, we prove the convergence of BOBA with an error of the optimal order. Our empirical evaluations demonstrate BOBA\u2019s superior unbiasedness and robustness across diverse models and datasets when compared to various baselines.",
        "bibtex": "@InProceedings{pmlr-v238-bao24a,\n  title = \t {{BOBA}: Byzantine-Robust Federated Learning with Label Skewness},\n  author =       {Bao, Wenxuan and Wu, Jun and He, Jingrui},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {892--900},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bao24a/bao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bao24a.html},\n  abstract = \t {In federated learning, most existing robust aggregation rules (AGRs) combat Byzantine attacks in the IID setting, where client data is assumed to be independent and identically distributed. In this paper, we address label skewness, a more realistic and challenging non-IID setting, where each client only has access to a few classes of data. In this setting, state-of-the-art AGRs suffer from selection bias, leading to significant performance drop for particular classes; they are also more vulnerable to Byzantine attacks due to the increased variation among gradients of honest clients. To address these limitations, we propose an efficient two-stage method named BOBA. Theoretically, we prove the convergence of BOBA with an error of the optimal order. Our empirical evaluations demonstrate BOBA\u2019s superior unbiasedness and robustness across diverse models and datasets when compared to various baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bao24a/bao24a.pdf",
        "supp": "",
        "pdf_size": 1337162,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10098878695763424800&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign",
        "aff_domain": "illinois.edu;illinois.edu;illinois.edu",
        "email": "illinois.edu;illinois.edu;illinois.edu",
        "github": "https://github.com/baowenxuan/BOBA",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8da1a618b9",
        "title": "Backward Filtering Forward Deciding in Linear Non-Gaussian State Space Models",
        "site": "https://proceedings.mlr.press/v238/li24j.html",
        "author": "Yun-Peng Li; Hans-Andrea Loeliger",
        "abstract": "The paper considers linear state space models with non-Gaussian inputs and/or constraints. As shown previously, NUP representations (normal with unknown parameters) allow to compute MAP estimates in such models by iterating Kalman smoothing recursions. In this paper, we propose to compute such MAP estimates by iterating backward-forward recursions where the forward recursion amounts to coordinatewise input estimation. The advantages of the proposed approach include faster convergence, no \u201czero-variance stucking\u201d, and easier control of constraint satisfaction. The approach is demonstrated with simulation results of exemplary applications including (i) regression with non-Gaussian priors or constraints on k-th order differences and (ii) control with linearly constrained inputs.",
        "bibtex": "@InProceedings{pmlr-v238-li24j,\n  title = \t {Backward Filtering Forward Deciding in Linear Non-{G}aussian State Space Models},\n  author =       {Li, Yun-Peng and Loeliger, Hans-Andrea},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2287--2295},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24j/li24j.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24j.html},\n  abstract = \t {The paper considers linear state space models with non-Gaussian inputs and/or constraints. As shown previously, NUP representations (normal with unknown parameters) allow to compute MAP estimates in such models by iterating Kalman smoothing recursions. In this paper, we propose to compute such MAP estimates by iterating backward-forward recursions where the forward recursion amounts to coordinatewise input estimation. The advantages of the proposed approach include faster convergence, no \u201czero-variance stucking\u201d, and easier control of constraint satisfaction. The approach is demonstrated with simulation results of exemplary applications including (i) regression with non-Gaussian priors or constraints on k-th order differences and (ii) control with linearly constrained inputs.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24j/li24j.pdf",
        "supp": "",
        "pdf_size": 1237535,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8152706760665783255&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "c8a7952058",
        "title": "Bandit Pareto Set Identification: the Fixed Budget Setting",
        "site": "https://proceedings.mlr.press/v238/kone24a.html",
        "author": "Cyrille Kone; Emilie Kaufmann; Laura Richert",
        "abstract": "We study a multi-objective pure exploration problem in a multi-armed bandit model. Each arm is associated to an unknown multi-variate distribution and the goal is to identify the distributions whose mean is not uniformly worse than that of another distribution: the Pareto optimal set. We propose and analyze the first algorithms for the \\emph{fixed budget} Pareto Set Identification task. We propose Empirical Gap Elimination, a family of algorithms combining a careful estimation of the \u201chardness to classify\u201d each arm in or out of the Pareto set with a generic elimination scheme. We prove that two particular instances, EGE-SR and EGE-SH, have a probability of error that decays exponentially fast with the budget, with an exponent supported by an information theoretic lower-bound. We complement these findings with an empirical study using real-world and synthetic datasets, which showcase the good performance of our algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-kone24a,\n  title = \t {Bandit {P}areto Set Identification: the Fixed Budget Setting},\n  author =       {Kone, Cyrille and Kaufmann, Emilie and Richert, Laura},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2548--2556},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kone24a/kone24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kone24a.html},\n  abstract = \t {We study a multi-objective pure exploration problem in a multi-armed bandit model. Each arm is associated to an unknown multi-variate distribution and the goal is to identify the distributions whose mean is not uniformly worse than that of another distribution: the Pareto optimal set. We propose and analyze the first algorithms for the \\emph{fixed budget} Pareto Set Identification task. We propose Empirical Gap Elimination, a family of algorithms combining a careful estimation of the \u201chardness to classify\u201d each arm in or out of the Pareto set with a generic elimination scheme. We prove that two particular instances, EGE-SR and EGE-SH, have a probability of error that decays exponentially fast with the budget, with an exponent supported by an information theoretic lower-bound. We complement these findings with an empirical study using real-world and synthetic datasets, which showcase the good performance of our algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kone24a/kone24a.pdf",
        "supp": "",
        "pdf_size": 1640100,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10268156981262821790&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "adb00a58dc",
        "title": "Bayesian Online Learning for Consensus Prediction",
        "site": "https://proceedings.mlr.press/v238/showalter24a.html",
        "author": "Samuel Showalter; Alex J Boyd; Padhraic Smyth; Mark Steyvers",
        "abstract": "Given a pre-trained classifier and multiple human experts, we investigate the task of online classification where model predictions are provided for free but querying humans incurs a cost. In this practical but under-explored setting, oracle ground truth is not available. Instead, the prediction target is defined as the consensus vote of all experts. Given that querying full consensus can be costly, we propose a general framework for online Bayesian consensus estimation, leveraging properties of the multivariate hypergeometric distribution. Based on this framework, we propose a family of methods that dynamically estimate expert consensus from partial feedback by producing a posterior over expert and model beliefs. Analyzing this posterior induces an interpretable trade-off between querying cost and classification performance. We demonstrate the efficacy of our framework against a variety of baselines on CIFAR-10H and ImageNet-16H, two large-scale crowdsourced datasets.",
        "bibtex": "@InProceedings{pmlr-v238-showalter24a,\n  title = \t {Bayesian Online Learning for Consensus Prediction},\n  author =       {Showalter, Samuel and J Boyd, Alex and Smyth, Padhraic and Steyvers, Mark},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2539--2547},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/showalter24a/showalter24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/showalter24a.html},\n  abstract = \t {Given a pre-trained classifier and multiple human experts, we investigate the task of online classification where model predictions are provided for free but querying humans incurs a cost. In this practical but under-explored setting, oracle ground truth is not available. Instead, the prediction target is defined as the consensus vote of all experts. Given that querying full consensus can be costly, we propose a general framework for online Bayesian consensus estimation, leveraging properties of the multivariate hypergeometric distribution. Based on this framework, we propose a family of methods that dynamically estimate expert consensus from partial feedback by producing a posterior over expert and model beliefs. Analyzing this posterior induces an interpretable trade-off between querying cost and classification performance. We demonstrate the efficacy of our framework against a variety of baselines on CIFAR-10H and ImageNet-16H, two large-scale crowdsourced datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/showalter24a/showalter24a.pdf",
        "supp": "",
        "pdf_size": 2129185,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6266502295532244475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of California, Irvine + Department of Statistics, University of California, Irvine; Department of Statistics, University of California, Irvine; Department of Computer Science, University of California, Irvine + Department of Cognitive Science, University of California, Irvine; Department of Computer Science, University of California, Irvine + Department of Cognitive Science, University of California, Irvine",
        "aff_domain": "uci.edu; ; ; ",
        "email": "uci.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0;0+0;0+0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0+0;0;0+0;0+0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0+0;0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8768e7ff9f",
        "title": "Bayesian Semi-structured Subspace Inference",
        "site": "https://proceedings.mlr.press/v238/dold24a.html",
        "author": "Daniel Dold; David Ruegamer; Beate Sick; Oliver D\u00fcrr",
        "abstract": "Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach\u2019s efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-dold24a,\n  title = \t {Bayesian Semi-structured Subspace Inference},\n  author =       {Dold, Daniel and Ruegamer, David and Sick, Beate and D\\\"{u}rr, Oliver},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1819--1827},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dold24a/dold24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dold24a.html},\n  abstract = \t {Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach\u2019s efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dold24a/dold24a.pdf",
        "supp": "",
        "pdf_size": 2110369,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=329212698965711281&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a911aa0bef",
        "title": "Benchmarking Observational Studies with Experimental Data under Right-Censoring",
        "site": "https://proceedings.mlr.press/v238/demirel24a.html",
        "author": "Ilker Demirel; Edward De Brouwer; Zeshan M Hussain; Michael Oberst; Anthony A Philippakis; David Sontag",
        "abstract": "Drawing causal inferences from observational studies (OS) requires unverifiable validity assumptions; however, one can falsify those assumptions by benchmarking the OS with experimental data from a randomized controlled trial (RCT). A major limitation of existing procedures is not accounting for censoring, despite the abundance of RCTs and OSes that report right-censored time-to-event outcomes. We consider two cases where censoring time (1) is independent of time-to-event and (2) depends on time-to-event the same way in OS and RCT. For the former, we adopt a censoring-doubly-robust signal for the conditional average treatment effect (CATE) to facilitate an equivalence test of CATEs in OS and RCT, which serves as a proxy for testing if the validity assumptions hold. For the latter, we show that the same test can still be used even though unbiased CATE estimation may not be possible. We verify the effectiveness of our censoring-aware tests via semi-synthetic experiments and analyze RCT and OS data from the Women\u2019s Health Initiative study.",
        "bibtex": "@InProceedings{pmlr-v238-demirel24a,\n  title = \t {Benchmarking Observational Studies with Experimental Data under Right-Censoring},\n  author =       {Demirel, Ilker and De Brouwer, Edward and M Hussain, Zeshan and Oberst, Michael and A Philippakis, Anthony and Sontag, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4285--4293},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/demirel24a/demirel24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/demirel24a.html},\n  abstract = \t {Drawing causal inferences from observational studies (OS) requires unverifiable validity assumptions; however, one can falsify those assumptions by benchmarking the OS with experimental data from a randomized controlled trial (RCT). A major limitation of existing procedures is not accounting for censoring, despite the abundance of RCTs and OSes that report right-censored time-to-event outcomes. We consider two cases where censoring time (1) is independent of time-to-event and (2) depends on time-to-event the same way in OS and RCT. For the former, we adopt a censoring-doubly-robust signal for the conditional average treatment effect (CATE) to facilitate an equivalence test of CATEs in OS and RCT, which serves as a proxy for testing if the validity assumptions hold. For the latter, we show that the same test can still be used even though unbiased CATE estimation may not be possible. We verify the effectiveness of our censoring-aware tests via semi-synthetic experiments and analyze RCT and OS data from the Women\u2019s Health Initiative study.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/demirel24a/demirel24a.pdf",
        "supp": "",
        "pdf_size": 1208123,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3648712265520919703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b5336c6037",
        "title": "Benefits of Non-Linear Scale Parameterizations in Black Box Variational Inference through Smoothness Results and Gradient Variance Bounds",
        "site": "https://proceedings.mlr.press/v238/hotti24a.html",
        "author": "Alexandra Maria Hotti; Lennart Alexander Van der Goten; Jens Lagergren",
        "abstract": "Black box variational inference has consistently produced impressive empirical results. Convergence guarantees require that the variational objective exhibits specific structural properties and that the noise of the gradient estimator can be controlled. In this work we study the smoothness and the variance of the gradient estimator for location-scale variational families with non-linear covariance parameterizations. Specifically, we derive novel theoretical results for the popular exponential covariance parameterization and tighter gradient variance bounds for the softplus parameterization. These results reveal the benefits of using non-linear scale parameterizations on large scale datasets. With a non-linear scale parameterization, the smoothness constant of the variational objective and the upper bound on the gradient variance decrease as the scale parameter becomes smaller. Learning posterior approximations with small scales is essential in Bayesian statistics with sufficient amount of data, since under appropriate assumptions, the posterior distribution is known to contract around the parameter of interest as the sample size increases. We validate our theoretical findings through empirical analysis on several large-scale datasets, underscoring the importance of non-linear parameterizations.",
        "bibtex": "@InProceedings{pmlr-v238-hotti24a,\n  title = \t {Benefits of Non-Linear Scale Parameterizations in Black Box Variational Inference through Smoothness Results and Gradient Variance Bounds},\n  author =       {Hotti, Alexandra Maria and Van der Goten, Lennart Alexander and Lagergren, Jens},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3538--3546},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hotti24a/hotti24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hotti24a.html},\n  abstract = \t {Black box variational inference has consistently produced impressive empirical results. Convergence guarantees require that the variational objective exhibits specific structural properties and that the noise of the gradient estimator can be controlled. In this work we study the smoothness and the variance of the gradient estimator for location-scale variational families with non-linear covariance parameterizations. Specifically, we derive novel theoretical results for the popular exponential covariance parameterization and tighter gradient variance bounds for the softplus parameterization. These results reveal the benefits of using non-linear scale parameterizations on large scale datasets. With a non-linear scale parameterization, the smoothness constant of the variational objective and the upper bound on the gradient variance decrease as the scale parameter becomes smaller. Learning posterior approximations with small scales is essential in Bayesian statistics with sufficient amount of data, since under appropriate assumptions, the posterior distribution is known to contract around the parameter of interest as the sample size increases. We validate our theoretical findings through empirical analysis on several large-scale datasets, underscoring the importance of non-linear parameterizations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hotti24a/hotti24a.pdf",
        "supp": "",
        "pdf_size": 988508,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3598561596006490405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f8ea4c46cc",
        "title": "Best Arm Identification with Resource Constraints",
        "site": "https://proceedings.mlr.press/v238/li24c.html",
        "author": "Zitian Li; Wang Chi Cheung",
        "abstract": "Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption.",
        "bibtex": "@InProceedings{pmlr-v238-li24c,\n  title = \t {Best Arm Identification with Resource Constraints},\n  author =       {Li, Zitian and Chi Cheung, Wang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {253--261},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24c/li24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24c.html},\n  abstract = \t {Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24c/li24c.pdf",
        "supp": "",
        "pdf_size": 784234,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4JPfhOrJXEoJ:scholar.google.com/&scioq=Best+Arm+Identification+with+Resource+Constraints&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Department of ISEM, National University of Singapore; Department of ISEM, National University of Singapore",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of ISEM",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "6025d1b53a",
        "title": "Best-of-Both-Worlds Algorithms for Linear Contextual Bandits",
        "site": "https://proceedings.mlr.press/v238/kuroki24a.html",
        "author": "Yuko Kuroki; Alberto Rumi; Taira Tsuchiya; Fabio Vitale; Nicol\u00f2 Cesa-Bianchi",
        "abstract": "We study best-of-both-worlds algorithms for $K$-armed linear contextual bandits. Our algorithms deliver near-optimal regret bounds in both the adversarial and stochastic regimes, without prior knowledge about the environment. In the stochastic regime, we achieve the polylogarithmic rate $\\frac{(dK)^2\\mathrm{poly}\\!\\log(dKT)}{\\Delta_{\\min}}$, where $\\Delta_{\\min}$ is the minimum suboptimality gap over the $d$-dimensional context space. In the adversarial regime, we obtain either the first-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{L^*})$ bound, or the second-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{\\Lambda^*})$ bound, where $L^*$ is the cumulative loss of the best action and $\\Lambda^*$ is a notion of the cumulative second moment for the losses incurred by the algorithm. Moreover, we develop an algorithm based on FTRL with Shannon entropy regularizer that does not require the knowledge of the inverse of the covariance matrix, and achieves a polylogarithmic regret in the stochastic regime while obtaining $\\widetilde{\\mathcal{O}}\\big(dK\\sqrt{T}\\big)$ regret bounds in the adversarial regime.",
        "bibtex": "@InProceedings{pmlr-v238-kuroki24a,\n  title = \t {Best-of-Both-Worlds Algorithms for Linear Contextual Bandits},\n  author =       {Kuroki, Yuko and Rumi, Alberto and Tsuchiya, Taira and Vitale, Fabio and Cesa-Bianchi, Nicol\\`{o}},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1216--1224},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kuroki24a/kuroki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kuroki24a.html},\n  abstract = \t {We study best-of-both-worlds algorithms for $K$-armed linear contextual bandits. Our algorithms deliver near-optimal regret bounds in both the adversarial and stochastic regimes, without prior knowledge about the environment. In the stochastic regime, we achieve the polylogarithmic rate $\\frac{(dK)^2\\mathrm{poly}\\!\\log(dKT)}{\\Delta_{\\min}}$, where $\\Delta_{\\min}$ is the minimum suboptimality gap over the $d$-dimensional context space. In the adversarial regime, we obtain either the first-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{L^*})$ bound, or the second-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{\\Lambda^*})$ bound, where $L^*$ is the cumulative loss of the best action and $\\Lambda^*$ is a notion of the cumulative second moment for the losses incurred by the algorithm. Moreover, we develop an algorithm based on FTRL with Shannon entropy regularizer that does not require the knowledge of the inverse of the covariance matrix, and achieves a polylogarithmic regret in the stochastic regime while obtaining $\\widetilde{\\mathcal{O}}\\big(dK\\sqrt{T}\\big)$ regret bounds in the adversarial regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kuroki24a/kuroki24a.pdf",
        "supp": "",
        "pdf_size": 407722,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1813414651783761243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "03a1461b11",
        "title": "Better Batch for Deep Probabilistic Time Series Forecasting",
        "site": "https://proceedings.mlr.press/v238/zheng24a.html",
        "author": "Zhihao Zheng; Seongjin Choi; Lijun Sun",
        "abstract": "Deep probabilistic time series forecasting has gained attention for its ability to provide nonlinear approximation and valuable uncertainty quantification for decision-making. However, existing models often oversimplify the problem by assuming a time-independent error process and overlooking serial correlation. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance probabilistic forecasting accuracy. Our method constructs a mini-batch as a collection of D consecutive time series segments for model training. It explicitly learns a time-varying covariance matrix over each mini-batch, encoding error correlation among adjacent time steps. The learned covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantification. We evaluate our method on two different neural forecasting models and multiple public datasets. Experimental results confirm the effectiveness of the proposed approach in improving the performance of both models across a range of datasets, resulting in notable improvements in predictive accuracy.",
        "bibtex": "@InProceedings{pmlr-v238-zheng24a,\n  title = \t {Better Batch for Deep Probabilistic Time Series Forecasting},\n  author =       {Zheng, Zhihao and Choi, Seongjin and Sun, Lijun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {91--99},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zheng24a/zheng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zheng24a.html},\n  abstract = \t {Deep probabilistic time series forecasting has gained attention for its ability to provide nonlinear approximation and valuable uncertainty quantification for decision-making. However, existing models often oversimplify the problem by assuming a time-independent error process and overlooking serial correlation. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance probabilistic forecasting accuracy. Our method constructs a mini-batch as a collection of D consecutive time series segments for model training. It explicitly learns a time-varying covariance matrix over each mini-batch, encoding error correlation among adjacent time steps. The learned covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantification. We evaluate our method on two different neural forecasting models and multiple public datasets. Experimental results confirm the effectiveness of the proposed approach in improving the performance of both models across a range of datasets, resulting in notable improvements in predictive accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zheng24a/zheng24a.pdf",
        "supp": "",
        "pdf_size": 704643,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7897173507148742087&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0997312c8e",
        "title": "Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective",
        "site": "https://proceedings.mlr.press/v238/xing24a.html",
        "author": "Yue Xing; Xiaofeng Lin; Qifan Song; Yi Xu; Belinda Zeng; Guang Cheng",
        "abstract": "Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., Kim et al. (2020), empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks.",
        "bibtex": "@InProceedings{pmlr-v238-xing24a,\n  title = \t {Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective},\n  author =       {Xing, Yue and Lin, Xiaofeng and Song, Qifan and Xu, Yi and Zeng, Belinda and Cheng, Guang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {199--207},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xing24a/xing24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xing24a.html},\n  abstract = \t {Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., Kim et al. (2020), empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xing24a/xing24a.pdf",
        "supp": "",
        "pdf_size": 2673740,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:_nDzaCN-WVYJ:scholar.google.com/&scioq=Better+Representations+via+Adversarial+Training+in+Pre-Training:+A+Theoretical+Perspective&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "Michigan State University; University of California, Los Angeles; Purdue University; Amazon Search-M5; Amazon Search-M5; University of California, Los Angeles + Amazon Search-M5",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;3;1+3",
        "aff_unique_norm": "Michigan State University;University of California, Los Angeles;Purdue University;Amazon",
        "aff_unique_dep": ";;;Amazon Search-M5",
        "aff_unique_url": "https://www.msu.edu;https://www.ucla.edu;https://www.purdue.edu;https://www.amazon.com",
        "aff_unique_abbr": "MSU;UCLA;Purdue;Amazon",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7add22fa8c",
        "title": "Beyond Bayesian Model Averaging over Paths in Probabilistic Programs with Stochastic Support",
        "site": "https://proceedings.mlr.press/v238/reichelt24a.html",
        "author": "Tim Reichelt; Luke Ong; Tom Rainforth",
        "abstract": "The posterior in probabilistic programs with stochastic support decomposes as a weighted sum of the local posterior distributions associated with each possible program path. We show that making predictions with this full posterior implicitly performs a Bayesian model averaging (BMA) over paths. This is potentially problematic, as BMA weights can be unstable due to model misspecification or inference approximations, leading to sub-optimal predictions in turn. To remedy this issue, we propose alternative mechanisms for path weighting: one based on stacking and one based on ideas from PAC-Bayes. We show how both can be implemented as a cheap post-processing step on top of existing inference engines. In our experiments, we find them to be more robust and lead to better predictions compared to the default BMA weights.",
        "bibtex": "@InProceedings{pmlr-v238-reichelt24a,\n  title = \t {Beyond {B}ayesian Model Averaging over Paths in Probabilistic Programs with Stochastic Support},\n  author =       {Reichelt, Tim and Ong, Luke and Rainforth, Tom},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {829--837},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/reichelt24a/reichelt24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/reichelt24a.html},\n  abstract = \t {The posterior in probabilistic programs with stochastic support decomposes as a weighted sum of the local posterior distributions associated with each possible program path. We show that making predictions with this full posterior implicitly performs a Bayesian model averaging (BMA) over paths. This is potentially problematic, as BMA weights can be unstable due to model misspecification or inference approximations, leading to sub-optimal predictions in turn. To remedy this issue, we propose alternative mechanisms for path weighting: one based on stacking and one based on ideas from PAC-Bayes. We show how both can be implemented as a cheap post-processing step on top of existing inference engines. In our experiments, we find them to be more robust and lead to better predictions compared to the default BMA weights.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/reichelt24a/reichelt24a.pdf",
        "supp": "",
        "pdf_size": 6501122,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17864831180283551710&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Oxford; Nanyang Technological University; University of Oxford",
        "aff_domain": "robots.ox.ac.uk; ; ",
        "email": "robots.ox.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Oxford;Nanyang Technological University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.ntu.edu.sg",
        "aff_unique_abbr": "Oxford;NTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Singapore"
    },
    {
        "id": "a7c19368e6",
        "title": "BlockBoost: Scalable and Efficient Blocking through Boosting",
        "site": "https://proceedings.mlr.press/v238/ramos24a.html",
        "author": "Thiago Ramos; Rodrigo Loro Schuller; Alex Akira Okuno; Lucas Nissenbaum; Roberto I Oliveira; Paulo Orenstein",
        "abstract": "As datasets grow larger, matching and merging entries from different databases has become a costly task in modern data pipelines. To avoid expensive comparisons between entries, blocking similar items is a popular preprocessing step. In this paper, we introduce BlockBoost, a novel boosting-based method that generates compact binary hash codes for database entries, through which blocking can be performed efficiently. The algorithm is fast and scalable, resulting in computational costs that are orders of magnitude lower than current benchmarks. Unlike existing alternatives, BlockBoost comes with associated feature importance measures for interpretability, and possesses strong theoretical guarantees, including lower bounds on critical performance metrics like recall and reduction ratio. Finally, we show that BlockBoost delivers great empirical results, outperforming state-of-the-art blocking benchmarks in terms of both performance metrics and computational cost.",
        "bibtex": "@InProceedings{pmlr-v238-ramos24a,\n  title = \t {BlockBoost: Scalable and Efficient Blocking through Boosting},\n  author =       {Ramos, Thiago and Loro Schuller, Rodrigo and Akira Okuno, Alex and Nissenbaum, Lucas and I Oliveira, Roberto and Orenstein, Paulo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2575--2583},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ramos24a/ramos24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ramos24a.html},\n  abstract = \t {As datasets grow larger, matching and merging entries from different databases has become a costly task in modern data pipelines. To avoid expensive comparisons between entries, blocking similar items is a popular preprocessing step. In this paper, we introduce BlockBoost, a novel boosting-based method that generates compact binary hash codes for database entries, through which blocking can be performed efficiently. The algorithm is fast and scalable, resulting in computational costs that are orders of magnitude lower than current benchmarks. Unlike existing alternatives, BlockBoost comes with associated feature importance measures for interpretability, and possesses strong theoretical guarantees, including lower bounds on critical performance metrics like recall and reduction ratio. Finally, we show that BlockBoost delivers great empirical results, outperforming state-of-the-art blocking benchmarks in terms of both performance metrics and computational cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ramos24a/ramos24a.pdf",
        "supp": "",
        "pdf_size": 508621,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:e7-gm5sJ3qwJ:scholar.google.com/&scioq=BlockBoost:+Scalable+and+Efficient+Blocking+through+Boosting&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b7c29b0f65",
        "title": "Boundary-Aware Uncertainty for Feature Attribution Explainers",
        "site": "https://proceedings.mlr.press/v238/hill24a.html",
        "author": "Davin Hill; Aria Masoomi; Max Torop; Sandesh Ghimire; Jennifer Dy",
        "abstract": "Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v238-hill24a,\n  title = \t {Boundary-Aware Uncertainty for Feature Attribution Explainers},\n  author =       {Hill, Davin and Masoomi, Aria and Torop, Max and Ghimire, Sandesh and Dy, Jennifer},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {55--63},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hill24a/hill24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hill24a.html},\n  abstract = \t {Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hill24a/hill24a.pdf",
        "supp": "",
        "pdf_size": 9760715,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3410052880360459571&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University",
        "aff_domain": "ece.neu.edu;northeastern.edu;northeastern.edu;gmail.com;ece.neu.edu",
        "email": "ece.neu.edu;northeastern.edu;northeastern.edu;gmail.com;ece.neu.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1da9020b69",
        "title": "Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty",
        "site": "https://proceedings.mlr.press/v238/inatsu24a.html",
        "author": "Yu Inatsu; Shion Takeno; Hiroyuki Hanada; Kazuki Iwata; Ichiro Takeuchi",
        "abstract": "In this study, we propose a novel multi-objective Bayesian optimization (MOBO) method to efficiently identify the Pareto front (PF) defined by risk measures for black-box functions under the presence of input uncertainty (IU). Existing BO methods for Pareto optimization in the presence of IU are risk-specific or without theoretical guarantees, whereas our proposed method addresses general risk measures and has theoretical guarantees. The basic idea of the proposed method is to assume a Gaussian process (GP) model for the black-box function and to construct high-probability bounding boxes for the risk measures using the GP model. Furthermore, in order to reduce the uncertainty of non-dominated bounding boxes, we propose a method of selecting the next evaluation point using a maximin distance defined by the maximum value of a quasi distance based on bounding boxes. As theoretical analysis, we prove that the algorithm can return an arbitrary-accurate solution in a finite number of iterations with high probability, for various risk measures such as Bayes risk, worst-case risk, and value-at-risk. We also give a theoretical analysis that takes into account approximation errors because there exist non-negligible approximation errors (e.g., finite approximation of PFs and sampling-based approximation of bounding boxes) in practice. We confirm that the proposed method performs as well or better than existing methods not only in the setting with IU but also in the setting of ordinary MOBO through numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-inatsu24a,\n  title = \t {Bounding Box-based Multi-objective {B}ayesian Optimization of Risk Measures under Input Uncertainty},\n  author =       {Inatsu, Yu and Takeno, Shion and Hanada, Hiroyuki and Iwata, Kazuki and Takeuchi, Ichiro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4564--4572},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/inatsu24a/inatsu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/inatsu24a.html},\n  abstract = \t {In this study, we propose a novel multi-objective Bayesian optimization (MOBO) method to efficiently identify the Pareto front (PF) defined by risk measures for black-box functions under the presence of input uncertainty (IU). Existing BO methods for Pareto optimization in the presence of IU are risk-specific or without theoretical guarantees, whereas our proposed method addresses general risk measures and has theoretical guarantees. The basic idea of the proposed method is to assume a Gaussian process (GP) model for the black-box function and to construct high-probability bounding boxes for the risk measures using the GP model. Furthermore, in order to reduce the uncertainty of non-dominated bounding boxes, we propose a method of selecting the next evaluation point using a maximin distance defined by the maximum value of a quasi distance based on bounding boxes. As theoretical analysis, we prove that the algorithm can return an arbitrary-accurate solution in a finite number of iterations with high probability, for various risk measures such as Bayes risk, worst-case risk, and value-at-risk. We also give a theoretical analysis that takes into account approximation errors because there exist non-negligible approximation errors (e.g., finite approximation of PFs and sampling-based approximation of bounding boxes) in practice. We confirm that the proposed method performs as well or better than existing methods not only in the setting with IU but also in the setting of ordinary MOBO through numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/inatsu24a/inatsu24a.pdf",
        "supp": "",
        "pdf_size": 714507,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8639737070510915510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Nagoya Institute of Technology; RIKEN; RIKEN; Nagoya Institute of Technology; Nagoya University/RIKEN",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "Nagoya Institute of Technology;RIKEN;Nagoya University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nitech.ac.jp;https://www.riken.jp;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "NIT;RIKEN;Nagoya U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "eceb827563",
        "title": "Breaking isometric ties and introducing priors in Gromov-Wasserstein distances",
        "site": "https://proceedings.mlr.press/v238/demetci24a.html",
        "author": "Pinar Demetci; Quang Huy Tran; Ievgen Redko; Ritambhara Singh",
        "abstract": "Gromov-Wasserstein distance has many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariant property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport formulation, called Augmented Gromov-Wasserstein (AGW), that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We first present theoretical insights into the proposed method. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and heterogeneous domain adaptation in machine learning.",
        "bibtex": "@InProceedings{pmlr-v238-demetci24a,\n  title = \t {Breaking isometric ties and introducing priors in {G}romov-{W}asserstein distances},\n  author =       {Demetci, Pinar and Huy Tran, Quang and Redko, Ievgen and Singh, Ritambhara},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {298--306},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/demetci24a/demetci24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/demetci24a.html},\n  abstract = \t {Gromov-Wasserstein distance has many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariant property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport formulation, called Augmented Gromov-Wasserstein (AGW), that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We first present theoretical insights into the proposed method. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and heterogeneous domain adaptation in machine learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/demetci24a/demetci24a.pdf",
        "supp": "",
        "pdf_size": 3660649,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5297147798479442763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Eric and Wendy Schmidt Center1, Broad Institute of MIT and Harvard; Universit\u00e9 Bretagne-Sud, IRISA, CMAP, Ecole Polytechnique, IP Paris; Paris Noah\u2019s Ark Lab, Huawei Technologies; Department of Computer Science, Center for Computational Molecular Biology, Brown University",
        "aff_domain": "broadinstitute.org;univ-ubs.fr;gmail.com;brown.edu",
        "email": "broadinstitute.org;univ-ubs.fr;gmail.com;brown.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Broad Institute of MIT and Harvard;Universit\u00e9 Bretagne-Sud;Huawei;Brown University",
        "aff_unique_dep": "Eric and Wendy Schmidt Center1;IRISA;Noah\u2019s Ark Lab;Department of Computer Science",
        "aff_unique_url": "https://www.broadinstitute.org;https://www.univ-ubs.fr;https://www.huawei.com;https://www.brown.edu",
        "aff_unique_abbr": "Broad Institute;UBS;Huawei;Brown",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;France;China"
    },
    {
        "id": "2531da013f",
        "title": "Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems",
        "site": "https://proceedings.mlr.press/v238/puchkin24a.html",
        "author": "Nikita Puchkin; Eduard Gorbunov; Nickolay Kutuzov; Alexander Gasnikov",
        "abstract": "We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $O(K^{-2(\\alpha - 1) / \\alpha})$, when the stochastic gradients have finite $\\alpha$-th moment, $\\alpha \\in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.",
        "bibtex": "@InProceedings{pmlr-v238-puchkin24a,\n  title = \t {Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems},\n  author =       {Puchkin, Nikita and Gorbunov, Eduard and Kutuzov, Nickolay and Gasnikov, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {856--864},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/puchkin24a/puchkin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/puchkin24a.html},\n  abstract = \t {We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $O(K^{-2(\\alpha - 1) / \\alpha})$, when the stochastic gradients have finite $\\alpha$-th moment, $\\alpha \\in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/puchkin24a/puchkin24a.pdf",
        "supp": "",
        "pdf_size": 1259635,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14452420010699382576&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "22cb5b3484",
        "title": "Bures-Wasserstein Means of Graphs",
        "site": "https://proceedings.mlr.press/v238/haasler24a.html",
        "author": "Isabel Haasler; Pascal Frossard",
        "abstract": "Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured aligned graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent performance, outperforms existing baseline approaches, and improves the performance of state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v238-haasler24a,\n  title = \t {Bures-{W}asserstein Means of Graphs},\n  author =       {Haasler, Isabel and Frossard, Pascal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1873--1881},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/haasler24a/haasler24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/haasler24a.html},\n  abstract = \t {Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured aligned graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent performance, outperforms existing baseline approaches, and improves the performance of state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/haasler24a/haasler24a.pdf",
        "supp": "",
        "pdf_size": 1605953,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1530915644475654271&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "EPFL; EPFL",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "b931b4d99a",
        "title": "CAD-DA: Controllable Anomaly Detection after Domain Adaptation by Statistical Inference",
        "site": "https://proceedings.mlr.press/v238/nguyen-le-duy24a.html",
        "author": "Vo Nguyen Le Duy; Hsuan-Tien Lin; Ichiro Takeuchi",
        "abstract": "We propose a novel statistical method for testing the results of anomaly detection (AD) under domain adaptation (DA), which we call CAD-DA\u2014controllable AD under DA. The distinct advantage of the CAD-DA lies in its ability to control the probability of misidentifying anomalies under a pre-specified level $\\alpha$ (e.g., 0.05). The challenge within this DA setting is the necessity to account for the influence of DA to ensure the validity of the inference results. We overcome the challenge by leveraging the concept of Selective Inference to handle the impact of DA. To our knowledge, this is the first work capable of conducting a valid statistical inference within the context of DA. We evaluate the performance of the CAD-DA method on both synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-nguyen-le-duy24a,\n  title = \t {CAD-DA: Controllable Anomaly Detection after Domain Adaptation by Statistical Inference},\n  author =       {Nguyen Le Duy, Vo and Lin, Hsuan-Tien and Takeuchi, Ichiro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1828--1836},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nguyen-le-duy24a/nguyen-le-duy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nguyen-le-duy24a.html},\n  abstract = \t {We propose a novel statistical method for testing the results of anomaly detection (AD) under domain adaptation (DA), which we call CAD-DA\u2014controllable AD under DA. The distinct advantage of the CAD-DA lies in its ability to control the probability of misidentifying anomalies under a pre-specified level $\\alpha$ (e.g., 0.05). The challenge within this DA setting is the necessity to account for the influence of DA to ensure the validity of the inference results. We overcome the challenge by leveraging the concept of Selective Inference to handle the impact of DA. To our knowledge, this is the first work capable of conducting a valid statistical inference within the context of DA. We evaluate the performance of the CAD-DA method on both synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nguyen-le-duy24a/nguyen-le-duy24a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18436787968997682125&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d57c29772d",
        "title": "Can Probabilistic Feedback Drive User Impacts in Online Platforms?",
        "site": "https://proceedings.mlr.press/v238/dai24b.html",
        "author": "Jessica Dai; Bailey Flanigan; Nika Haghtalab; Meena Jagadeesan; Chara Podimata",
        "abstract": "A common explanation for negative user impacts of content recommender systems is misalignment between the platform\u2019s objective and user welfare. In this work, we show that misalignment in the platform\u2019s objective is not the only potential cause of unintended impacts on users: even when the platform\u2019s objective is fully aligned with user welfare, the platform\u2019s learning algorithm can induce negative downstream impacts on users. The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience. Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties. Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm\u2019s engagement with individual arms for different no-regret algorithms. We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times. From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm\u2019s performance, and assessing the nature of a learning algorithm\u2019s engagement with different types of content as well as their resulting downstream impacts.",
        "bibtex": "@InProceedings{pmlr-v238-dai24b,\n  title = \t {Can Probabilistic Feedback Drive User Impacts in Online Platforms?},\n  author =       {Dai, Jessica and Flanigan, Bailey and Haghtalab, Nika and Jagadeesan, Meena and Podimata, Chara},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2512--2520},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dai24b/dai24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dai24b.html},\n  abstract = \t {A common explanation for negative user impacts of content recommender systems is misalignment between the platform\u2019s objective and user welfare. In this work, we show that misalignment in the platform\u2019s objective is not the only potential cause of unintended impacts on users: even when the platform\u2019s objective is fully aligned with user welfare, the platform\u2019s learning algorithm can induce negative downstream impacts on users. The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience. Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties. Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm\u2019s engagement with individual arms for different no-regret algorithms. We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times. From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm\u2019s performance, and assessing the nature of a learning algorithm\u2019s engagement with different types of content as well as their resulting downstream impacts.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dai24b/dai24b.pdf",
        "supp": "",
        "pdf_size": 903980,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1096368242530063332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "U.C. Berkeley; Carnegie Mellon University; U.C. Berkeley; U.C. Berkeley; Massachussetts Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "https://arxiv.org/",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu;https://web.mit.edu",
        "aff_unique_abbr": "UC Berkeley;CMU;MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e810644247",
        "title": "Categorical Generative Model Evaluation via Synthetic Distribution Coarsening",
        "site": "https://proceedings.mlr.press/v238/regol24a.html",
        "author": "Florence Regol; Mark Coates",
        "abstract": "As we expect to see a rapid integration of generative models in our day to day lives, the development of rigorous methods of evaluation and analysis for generative models has never been more pressing. Multiple works have highlighted the shortcomings of widely used metrics and exposed how they fail to behave as expected in some settings. So far, the response has been to use a variety of metrics that target different desirable and interpretable properties such as fidelity, diversity, and authenticity, to obtain a clearer picture of a generative model\u2019s capabilities. These methods mainly focus on ordinal data and they all suffer from the same unavoidable issues stemming from estimating quantities of high-dimensional data from a limited number of samples. We propose to take an alternative approach and to return to the synthetic data setting where the ground truth is explicit and known. We focus on nominal categorical data and introduce an evaluation method that can scale to the high-dimensional settings often encountered in practice. Our method involves successively binning the large space to obtain smaller probability spaces and coarser distributions where meaningful statistical estimates can be obtained. This allows us to provide probabilistic guarantees and sample complexities and we illustrate how our method can be applied to distinguish between the capabilities of several state-of-the-art categorical models.",
        "bibtex": "@InProceedings{pmlr-v238-regol24a,\n  title = \t {Categorical Generative Model Evaluation via Synthetic Distribution Coarsening},\n  author =       {Regol, Florence and Coates, Mark},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {910--918},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/regol24a/regol24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/regol24a.html},\n  abstract = \t {As we expect to see a rapid integration of generative models in our day to day lives, the development of rigorous methods of evaluation and analysis for generative models has never been more pressing. Multiple works have highlighted the shortcomings of widely used metrics and exposed how they fail to behave as expected in some settings. So far, the response has been to use a variety of metrics that target different desirable and interpretable properties such as fidelity, diversity, and authenticity, to obtain a clearer picture of a generative model\u2019s capabilities. These methods mainly focus on ordinal data and they all suffer from the same unavoidable issues stemming from estimating quantities of high-dimensional data from a limited number of samples. We propose to take an alternative approach and to return to the synthetic data setting where the ground truth is explicit and known. We focus on nominal categorical data and introduce an evaluation method that can scale to the high-dimensional settings often encountered in practice. Our method involves successively binning the large space to obtain smaller probability spaces and coarser distributions where meaningful statistical estimates can be obtained. This allows us to provide probabilistic guarantees and sample complexities and we illustrate how our method can be applied to distinguish between the capabilities of several state-of-the-art categorical models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/regol24a/regol24a.pdf",
        "supp": "",
        "pdf_size": 867866,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:B43oxZHDweoJ:scholar.google.com/&scioq=Categorical+Generative+Model+Evaluation+via+Synthetic+Distribution+Coarsening&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": "McGill University, International Laboratory on Learning Systems (ILLS) and Mila - Quebec AI Institute; McGill University, International Laboratory on Learning Systems (ILLS) and Mila - Quebec AI Institute",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "International Laboratory on Learning Systems (ILLS)",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8d9b0a8b15",
        "title": "Causal Bandits with General Causal Models and Interventions",
        "site": "https://proceedings.mlr.press/v238/yan24a.html",
        "author": "Zirui Yan; Dennis Wei; Dmitriy A Katz; Prasanna Sattigeri; Ali Tajer",
        "abstract": "This paper considers causal bandits (CBs) for the sequential design of interventions in a causal system. The objective is to optimize a reward function via minimizing a measure of cumulative regret with respect to the best sequence of interventions in hindsight. The paper advances the results on CBs in three directions. First, the structural causal models (SCMs) are assumed to be unknown and drawn arbitrarily from a general class $\\mathcal{F}$ of Lipschitz-continuous functions. Existing results are often focused on (generalized) linear SCMs. Second, the interventions are assumed to be generalized soft with any desired level of granularity, resulting in an infinite number of possible interventions. The existing literature, in contrast, generally adopts atomic and hard interventions. Third, we provide general upper and lower bounds on regret. The upper bounds subsume (and improve) known bounds for special cases. The lower bounds are generally hitherto unknown. These bounds are characterized as functions of the (i) graph parameters, (ii) eluder dimension of the space of SCMs, denoted by $\\mathrm{dim}(\\mathcal{F})$, and (iii)\u00a0the covering number of the function space, denoted by $\\mathrm{cn}(\\mathcal{F})$. Specifically, the cumulative achievable regret over horizon $T$ is $\\mathcal{O}(K d^{L-1}\\sqrt{T\\,\\mathrm{dim}(\\mathcal{F}) \\log(\\mathrm{cn}(\\mathcal{F}))})$, where $K$ is related to the Lipschitz constants, $d$ is the graph\u2019s maximum in-degree, and $L$ is the length of the longest causal path. The upper bound is further refined for special classes of SCMs (neural network, polynomial, and linear), and their corresponding lower bounds are provided.",
        "bibtex": "@InProceedings{pmlr-v238-yan24a,\n  title = \t {Causal Bandits with General Causal Models and Interventions},\n  author =       {Yan, Zirui and Wei, Dennis and A Katz, Dmitriy and Sattigeri, Prasanna and Tajer, Ali},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4609--4617},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yan24a/yan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yan24a.html},\n  abstract = \t {This paper considers causal bandits (CBs) for the sequential design of interventions in a causal system. The objective is to optimize a reward function via minimizing a measure of cumulative regret with respect to the best sequence of interventions in hindsight. The paper advances the results on CBs in three directions. First, the structural causal models (SCMs) are assumed to be unknown and drawn arbitrarily from a general class $\\mathcal{F}$ of Lipschitz-continuous functions. Existing results are often focused on (generalized) linear SCMs. Second, the interventions are assumed to be generalized soft with any desired level of granularity, resulting in an infinite number of possible interventions. The existing literature, in contrast, generally adopts atomic and hard interventions. Third, we provide general upper and lower bounds on regret. The upper bounds subsume (and improve) known bounds for special cases. The lower bounds are generally hitherto unknown. These bounds are characterized as functions of the (i) graph parameters, (ii) eluder dimension of the space of SCMs, denoted by $\\mathrm{dim}(\\mathcal{F})$, and (iii)\u00a0the covering number of the function space, denoted by $\\mathrm{cn}(\\mathcal{F})$. Specifically, the cumulative achievable regret over horizon $T$ is $\\mathcal{O}(K d^{L-1}\\sqrt{T\\,\\mathrm{dim}(\\mathcal{F}) \\log(\\mathrm{cn}(\\mathcal{F}))})$, where $K$ is related to the Lipschitz constants, $d$ is the graph\u2019s maximum in-degree, and $L$ is the length of the longest causal path. The upper bound is further refined for special classes of SCMs (neural network, polynomial, and linear), and their corresponding lower bounds are provided.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yan24a/yan24a.pdf",
        "supp": "",
        "pdf_size": 1528551,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14567458668952466557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Rensselaer Polytechnic Institute; IBM Research; IBM Research; IBM Research; Rensselaer Polytechnic Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute;IBM",
        "aff_unique_dep": ";IBM Research",
        "aff_unique_url": "https://www.rpi.edu;https://www.ibm.com/research",
        "aff_unique_abbr": "RPI;IBM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d7381322a4",
        "title": "Causal Discovery under Off-Target Interventions",
        "site": "https://proceedings.mlr.press/v238/choo24a.html",
        "author": "Davin Choo; Kirankumar Shiragur; Caroline Uhler",
        "abstract": "Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a \\emph{distribution dependent on attempted action}. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results.",
        "bibtex": "@InProceedings{pmlr-v238-choo24a,\n  title = \t {Causal Discovery under Off-Target Interventions},\n  author =       {Choo, Davin and Shiragur, Kirankumar and Uhler, Caroline},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1621--1629},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/choo24a/choo24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/choo24a.html},\n  abstract = \t {Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a \\emph{distribution dependent on attempted action}. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/choo24a/choo24a.pdf",
        "supp": "",
        "pdf_size": 7587652,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6131105415747776687&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "National University of Singapore; Broad Institute of MIT and Harvard; Massachusetts Institute of Technology",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "National University of Singapore;Broad Institute;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.broadinstitute.org;https://web.mit.edu",
        "aff_unique_abbr": "NUS;Broad;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "be36f96b17",
        "title": "Causal Modeling with Stationary Diffusions",
        "site": "https://proceedings.mlr.press/v238/lorch24a.html",
        "author": "Lars Lorch; Andreas Krause; Bernhard Sch\u00f6lkopf",
        "abstract": "We develop a novel approach towards causal inference. Rather than structural equations over a causal graph, we learn stochastic differential equations (SDEs) whose stationary densities model a system\u2019s behavior under interventions. These stationary diffusion models do not require the formalism of causal graphs, let alone the common assumption of acyclicity. We show that in several cases, they generalize to unseen interventions on their variables, often better than classical approaches. Our inference method is based on a new theoretical result that expresses a stationarity condition on the diffusion\u2019s generator in a reproducing kernel Hilbert space. The resulting kernel deviation from stationarity (KDS) is an objective function of independent interest.",
        "bibtex": "@InProceedings{pmlr-v238-lorch24a,\n  title = \t {Causal Modeling with Stationary Diffusions},\n  author =       {Lorch, Lars and Krause, Andreas and Sch\\\"{o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1927--1935},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lorch24a/lorch24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lorch24a.html},\n  abstract = \t {We develop a novel approach towards causal inference. Rather than structural equations over a causal graph, we learn stochastic differential equations (SDEs) whose stationary densities model a system\u2019s behavior under interventions. These stationary diffusion models do not require the formalism of causal graphs, let alone the common assumption of acyclicity. We show that in several cases, they generalize to unseen interventions on their variables, often better than classical approaches. Our inference method is based on a new theoretical result that expresses a stationarity condition on the diffusion\u2019s generator in a reproducing kernel Hilbert space. The resulting kernel deviation from stationarity (KDS) is an objective function of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lorch24a/lorch24a.pdf",
        "supp": "",
        "pdf_size": 1877360,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13956753075207801894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cf48769958",
        "title": "Causal Q-Aggregation for CATE Model Selection",
        "site": "https://proceedings.mlr.press/v238/lan24a.html",
        "author": "Hui Lan; Vasilis Syrgkanis",
        "abstract": "Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a non-trivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical works leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on $Q$-aggregation using the doubly robust loss. Our main result shows that causal $Q$-aggregation achieves statistically optimal oracle model selection regret rates of $\\log(M)/n$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error terms related to products of errors in the nuisance functions. Crucially, our regret rate does not require that any of the candidate CATE models be close to the truth. We validate our new method on many semi-synthetic datasets and also provide extensions of our work to CATE model selection with instrumental variables and unobserved confounding.",
        "bibtex": "@InProceedings{pmlr-v238-lan24a,\n  title = \t {Causal {Q}-Aggregation for {CATE} Model Selection},\n  author =       {Lan, Hui and Syrgkanis, Vasilis},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4366--4374},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lan24a/lan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lan24a.html},\n  abstract = \t {Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a non-trivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical works leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on $Q$-aggregation using the doubly robust loss. Our main result shows that causal $Q$-aggregation achieves statistically optimal oracle model selection regret rates of $\\log(M)/n$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error terms related to products of errors in the nuisance functions. Crucially, our regret rate does not require that any of the candidate CATE models be close to the truth. We validate our new method on many semi-synthetic datasets and also provide extensions of our work to CATE model selection with instrumental variables and unobserved confounding.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lan24a/lan24a.pdf",
        "supp": "",
        "pdf_size": 696028,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13020491292768085275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "stanford.edu;stanford.edu",
        "email": "stanford.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5341dfe6ee",
        "title": "Causally Inspired Regularization Enables Domain General Representations",
        "site": "https://proceedings.mlr.press/v238/salaudeen24a.html",
        "author": "Olawale Salaudeen; Sanmi Koyejo",
        "abstract": "Given a causal graph representing the data-generating process shared across different domains/distributions, enforcing sufficient graph-implied conditional independencies can identify domain-general (non-spurious) feature representations. For the standard input-output predictive setting, we categorize the set of graphs considered in the literature into two distinct groups: (i) those in which the empirical risk minimizer across training domains gives domain-general representations and (ii) those where it does not. For the latter case (ii), we propose a novel framework with regularizations, which we demonstrate are sufficient for identifying domain-general feature representations without a priori knowledge (or proxies) of the spurious features. Empirically, our proposed method is effective for both (semi) synthetic and real-world data, outperforming other state-of-the-art methods in average and worst-domain transfer accuracy.",
        "bibtex": "@InProceedings{pmlr-v238-salaudeen24a,\n  title = \t {Causally Inspired Regularization Enables Domain General Representations},\n  author =       {Salaudeen, Olawale and Koyejo, Sanmi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3124--3132},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/salaudeen24a/salaudeen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/salaudeen24a.html},\n  abstract = \t {Given a causal graph representing the data-generating process shared across different domains/distributions, enforcing sufficient graph-implied conditional independencies can identify domain-general (non-spurious) feature representations. For the standard input-output predictive setting, we categorize the set of graphs considered in the literature into two distinct groups: (i) those in which the empirical risk minimizer across training domains gives domain-general representations and (ii) those where it does not. For the latter case (ii), we propose a novel framework with regularizations, which we demonstrate are sufficient for identifying domain-general feature representations without a priori knowledge (or proxies) of the spurious features. Empirically, our proposed method is effective for both (semi) synthetic and real-world data, outperforming other state-of-the-art methods in average and worst-domain transfer accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/salaudeen24a/salaudeen24a.pdf",
        "supp": "",
        "pdf_size": 559960,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6643023575424048374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Illinois at Urbana-Champaign; Stanford University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://illinois.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UIUC;Stanford",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Urbana-Champaign;Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0c5b6546c2",
        "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications",
        "site": "https://proceedings.mlr.press/v238/hu24b.html",
        "author": "Jie Hu; Vishwaraj Doshi; Do Young Eun",
        "abstract": "Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. 2020. In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approximation using Markovian samples and show their identical asymptotic performance, a perspective not evident from current finite-time bounds.",
        "bibtex": "@InProceedings{pmlr-v238-hu24b,\n  title = \t {Central Limit Theorem for Two-Timescale Stochastic Approximation with {M}arkovian Noise: Theory and Applications},\n  author =       {Hu, Jie and Doshi, Vishwaraj and Young Eun, Do},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1477--1485},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hu24b/hu24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hu24b.html},\n  abstract = \t {Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. 2020. In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approximation using Markovian samples and show their identical asymptotic performance, a perspective not evident from current finite-time bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hu24b/hu24b.pdf",
        "supp": "",
        "pdf_size": 1086266,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13901416246902298396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "North Carolina State University; IQVIA Inc.; North Carolina State University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "North Carolina State University;IQVIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ncsu.edu;https://www.iqvia.com",
        "aff_unique_abbr": "NCSU;IQVIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "56badb89de",
        "title": "Certified private data release for sparse Lipschitz functions",
        "site": "https://proceedings.mlr.press/v238/donhauser24a.html",
        "author": "Konstantin Donhauser; Johan Lokna; Amartya Sanyal; March Boedihardjo; Robert H\u00f6nig; Fanny Yang",
        "abstract": "As machine learning has become more relevant for everyday applications, a natural requirement is the protection of the privacy of the training data. When the relevant learning questions are unknown in advance, or hyper-parameter tuning plays a central role, one solution is to release a differentially private synthetic data set that leads to similar conclusions as the original training data. In this work, we introduce an algorithm that enjoys fast rates for the utility loss for sparse Lipschitz queries. Furthermore, we show how to obtain a certificate for the utility loss for a large class of algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-donhauser24a,\n  title = \t {Certified private data release for sparse {L}ipschitz functions},\n  author =       {Donhauser, Konstantin and Lokna, Johan and Sanyal, Amartya and Boedihardjo, March and H\\\"{o}nig, Robert and Yang, Fanny},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1396--1404},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/donhauser24a/donhauser24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/donhauser24a.html},\n  abstract = \t {As machine learning has become more relevant for everyday applications, a natural requirement is the protection of the privacy of the training data. When the relevant learning questions are unknown in advance, or hyper-parameter tuning plays a central role, one solution is to release a differentially private synthetic data set that leads to similar conclusions as the original training data. In this work, we introduce an algorithm that enjoys fast rates for the utility loss for sparse Lipschitz queries. Furthermore, we show how to obtain a certificate for the utility loss for a large class of algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/donhauser24a/donhauser24a.pdf",
        "supp": "",
        "pdf_size": 1731967,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=756976070935989431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "afd0baef66",
        "title": "Classifier Calibration with ROC-Regularized Isotonic Regression",
        "site": "https://proceedings.mlr.press/v238/berta24a.html",
        "author": "Eug\u00e8ne Berta; Francis Bach; Michael Jordan",
        "abstract": "Calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model outputs and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy with respect to monotone transformations. IR acts as an adaptive binning procedure that is able to achieve a calibration error of zero but leaves open the issue of the effect on performance. We first prove that IR preserves the convex hull of the ROC curve\u2014an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for over-fitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with $K$-classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the $K$-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding over-fitting of the calibration set.",
        "bibtex": "@InProceedings{pmlr-v238-berta24a,\n  title = \t {Classifier Calibration with {ROC}-Regularized Isotonic Regression},\n  author =       {Berta, Eug\\`{e}ne and Bach, Francis and Jordan, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1972--1980},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/berta24a/berta24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/berta24a.html},\n  abstract = \t {Calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model outputs and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy with respect to monotone transformations. IR acts as an adaptive binning procedure that is able to achieve a calibration error of zero but leaves open the issue of the effect on performance. We first prove that IR preserves the convex hull of the ROC curve\u2014an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for over-fitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with $K$-classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the $K$-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding over-fitting of the calibration set.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/berta24a/berta24a.pdf",
        "supp": "",
        "pdf_size": 1592405,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2404930487393293126&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Inria, Ecole Normale Sup\u00b4erieure, PSL Research University; Inria, Ecole Normale Sup\u00b4erieure, PSL Research University; Inria, Ecole Normale Sup\u00b4erieure, PSL Research University, University of California, Berkeley",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "ddf1792b48",
        "title": "Clustering Items From Adaptively Collected Inconsistent Feedback",
        "site": "https://proceedings.mlr.press/v238/gupta24a.html",
        "author": "Shubham Gupta; Peter W J Staar; Christian de Sainte Marie",
        "abstract": "We study clustering in a query-based model where the learner can repeatedly query an oracle to determine if two items belong to the same cluster. However, these queries are costly and the oracle\u2019s responses are marred by inconsistency and noise. The learner\u2019s goal is to adaptively make a small number of queries and return the correct clusters for \\emph{all} $n$ items with high confidence. We develop efficient algorithms for this problem using the sequential hypothesis testing framework. We derive high probability upper bounds on their sample complexity (the number of queries they make) and complement this analysis with an information-theoretic lower bound. In particular, we show that our algorithm for two clusters is nearly optimal when the oracle\u2019s error probability is a constant. Our experiments verify these findings and highlight a few shortcomings of our algorithms. Namely, we show that their sample complexity deviates from the lower bound when the error probability of the oracle depends on $n$. We suggest an improvement based on a more efficient sequential hypothesis test and demonstrate it empirically.",
        "bibtex": "@InProceedings{pmlr-v238-gupta24a,\n  title = \t {Clustering Items From Adaptively Collected Inconsistent Feedback},\n  author =       {Gupta, Shubham and W J Staar, Peter and de Sainte Marie, Christian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {604--612},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gupta24a/gupta24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gupta24a.html},\n  abstract = \t {We study clustering in a query-based model where the learner can repeatedly query an oracle to determine if two items belong to the same cluster. However, these queries are costly and the oracle\u2019s responses are marred by inconsistency and noise. The learner\u2019s goal is to adaptively make a small number of queries and return the correct clusters for \\emph{all} $n$ items with high confidence. We develop efficient algorithms for this problem using the sequential hypothesis testing framework. We derive high probability upper bounds on their sample complexity (the number of queries they make) and complement this analysis with an information-theoretic lower bound. In particular, we show that our algorithm for two clusters is nearly optimal when the oracle\u2019s error probability is a constant. Our experiments verify these findings and highlight a few shortcomings of our algorithms. Namely, we show that their sample complexity deviates from the lower bound when the error probability of the oracle depends on $n$. We suggest an improvement based on a more efficient sequential hypothesis test and demonstrate it empirically.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gupta24a/gupta24a.pdf",
        "supp": "",
        "pdf_size": 697909,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16164661312129358780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5940de5e04",
        "title": "Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates",
        "site": "https://proceedings.mlr.press/v238/rammal24a.html",
        "author": "Ahmad Rammal; Kaja Gruntkowska; Nikita Fedin; Eduard Gorbunov; Peter Richtarik",
        "abstract": "Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression \u2013 Byz-DASHA-PAGE \u2013 and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback \u2013 Byz-EF21 \u2013 along with its bi-directional compression version \u2013 Byz-EF21-BC \u2013 and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-rammal24a,\n  title = \t {Communication Compression for {B}yzantine Robust Learning: New Efficient Algorithms and Improved Rates},\n  author =       {Rammal, Ahmad and Gruntkowska, Kaja and Fedin, Nikita and Gorbunov, Eduard and Richtarik, Peter},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1207--1215},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rammal24a/rammal24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rammal24a.html},\n  abstract = \t {Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression \u2013 Byz-DASHA-PAGE \u2013 and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback \u2013 Byz-EF21 \u2013 along with its bi-directional compression version \u2013 Byz-EF21-BC \u2013 and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rammal24a/rammal24a.pdf",
        "supp": "",
        "pdf_size": 5580349,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=694544092588860739&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "KAUST; \u00c9cole Polytechnique+KAUST; MIPT; MBZUAI; KAUST",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;2;3;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology;Ecole Polytechnique;Moscow Institute of Physics and Technology;Mohamed bin Zayed University of Artificial Intelligence",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.kaust.edu.sa;https://www.polytechnique.edu;https://mipt.ru;https://www.mbzuai.ac.ae",
        "aff_unique_abbr": "KAUST;X;MIPT;MBZUAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;2;3;0",
        "aff_country_unique": "Saudi Arabia;France;Russian Federation;United Arab Emirates"
    },
    {
        "id": "352547eadb",
        "title": "Communication-Efficient Federated Learning With Data and Client Heterogeneity",
        "site": "https://proceedings.mlr.press/v238/zakerinia24a.html",
        "author": "Hossein Zakerinia; Shayan Talaei; Giorgi Nadiradze; Dan Alistarh",
        "abstract": "Federated Learning (FL) enables large-scale distributed training of machine learning models, while still allowing individual nodes to maintain data locally. However, executing FL at scale comes with inherent practical challenges: 1) heterogeneity of the local node data distributions, 2) heterogeneity of node computational speeds (asynchrony), but also 3) constraints in the amount of communication between the clients and the server. In this work, we present the first variant of the classic federated averaging (FedAvg) algorithm which, at the same time, supports data heterogeneity, partial client asynchrony, and communication compression. Our algorithm comes with a novel, rigorous analysis showing that, in spite of these system relaxations, it can provide similar convergence to FedAvg in interesting parameter regimes. Experimental results in the rigorous LEAF benchmark on setups of up to $300$ nodes show that our algorithm ensures fast convergence for standard federated tasks, improving upon prior quantized and asynchronous approaches.",
        "bibtex": "@InProceedings{pmlr-v238-zakerinia24a,\n  title = \t {Communication-Efficient Federated Learning With Data and Client Heterogeneity},\n  author =       {Zakerinia, Hossein and Talaei, Shayan and Nadiradze, Giorgi and Alistarh, Dan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3448--3456},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zakerinia24a/zakerinia24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zakerinia24a.html},\n  abstract = \t {Federated Learning (FL) enables large-scale distributed training of machine learning models, while still allowing individual nodes to maintain data locally. However, executing FL at scale comes with inherent practical challenges: 1) heterogeneity of the local node data distributions, 2) heterogeneity of node computational speeds (asynchrony), but also 3) constraints in the amount of communication between the clients and the server. In this work, we present the first variant of the classic federated averaging (FedAvg) algorithm which, at the same time, supports data heterogeneity, partial client asynchrony, and communication compression. Our algorithm comes with a novel, rigorous analysis showing that, in spite of these system relaxations, it can provide similar convergence to FedAvg in interesting parameter regimes. Experimental results in the rigorous LEAF benchmark on setups of up to $300$ nodes show that our algorithm ensures fast convergence for standard federated tasks, improving upon prior quantized and asynchronous approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zakerinia24a/zakerinia24a.pdf",
        "supp": "",
        "pdf_size": 2026422,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1664317069639169133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4cb8928121",
        "title": "Comparing Comparators in Generalization Bounds",
        "site": "https://proceedings.mlr.press/v238/hellstrom24a.html",
        "author": "Fredrik Hellstr\u00f6m; Benjamin Guedj",
        "abstract": "We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training loss and the population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\u00e9r function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.",
        "bibtex": "@InProceedings{pmlr-v238-hellstrom24a,\n  title = \t {Comparing Comparators in Generalization Bounds},\n  author =       {Hellstr\\\"{o}m, Fredrik and Guedj, Benjamin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {73--81},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hellstrom24a/hellstrom24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hellstrom24a.html},\n  abstract = \t {We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training loss and the population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\u00e9r function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hellstrom24a/hellstrom24a.pdf",
        "supp": "",
        "pdf_size": 932769,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=672316218644711908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University College London; Inria and University College London",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University College London;INRIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.inria.fr",
        "aff_unique_abbr": "UCL;Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "id": "aa6f205456",
        "title": "Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints",
        "site": "https://proceedings.mlr.press/v238/alacaoglu24a.html",
        "author": "Ahmet Alacaoglu; Stephen J Wright",
        "abstract": "We analyze the sample complexity of single-loop quadratic penalty and augmented Lagrangian algorithms for solving nonconvex optimization problems with functional equality constraints. We consider three cases, in all of which the objective is stochastic, that is, an expectation over an unknown distribution that is accessed by sampling. The nature of the equality constraints differs among the three cases: deterministic and linear in the first case, deterministic and nonlinear in the second case, and stochastic and nonlinear in the third case. Variance reduction techniques are used to improve the complexity. To find a point that satisfies $\\varepsilon$-approximate first-order conditions, we require $\\widetilde{O}(\\varepsilon^{-3})$ complexity in the first case, $\\widetilde{O}(\\varepsilon^{-4})$ in the second case, and $\\widetilde{O}(\\varepsilon^{-5})$ in the third case. For the first and third cases, they are the first algorithms of \u201csingle loop\u201d type that also use $O(1)$ samples at each iteration and still achieve the best-known complexity guarantees.",
        "bibtex": "@InProceedings{pmlr-v238-alacaoglu24a,\n  title = \t {Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints},\n  author =       {Alacaoglu, Ahmet and J Wright, Stephen},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4627--4635},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/alacaoglu24a/alacaoglu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/alacaoglu24a.html},\n  abstract = \t {We analyze the sample complexity of single-loop quadratic penalty and augmented Lagrangian algorithms for solving nonconvex optimization problems with functional equality constraints. We consider three cases, in all of which the objective is stochastic, that is, an expectation over an unknown distribution that is accessed by sampling. The nature of the equality constraints differs among the three cases: deterministic and linear in the first case, deterministic and nonlinear in the second case, and stochastic and nonlinear in the third case. Variance reduction techniques are used to improve the complexity. To find a point that satisfies $\\varepsilon$-approximate first-order conditions, we require $\\widetilde{O}(\\varepsilon^{-3})$ complexity in the first case, $\\widetilde{O}(\\varepsilon^{-4})$ in the second case, and $\\widetilde{O}(\\varepsilon^{-5})$ in the third case. For the first and third cases, they are the first algorithms of \u201csingle loop\u201d type that also use $O(1)$ samples at each iteration and still achieve the best-known complexity guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/alacaoglu24a/alacaoglu24a.pdf",
        "supp": "",
        "pdf_size": 565454,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=323998077227846151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Wisconsin\u2013Madison; University of Wisconsin\u2013Madison",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "77f8afe272",
        "title": "Compression with Exact Error Distribution for Federated Learning",
        "site": "https://proceedings.mlr.press/v238/hegazy24a.html",
        "author": "Mahmoud Hegazy; R\u00e9mi Leluc; Cheuk Ting Li; Aymeric Dieuleveut",
        "abstract": "Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.",
        "bibtex": "@InProceedings{pmlr-v238-hegazy24a,\n  title = \t {Compression with Exact Error Distribution for Federated Learning},\n  author =       {Hegazy, Mahmoud and Leluc, R\\'{e}mi and Ting Li, Cheuk and Dieuleveut, Aymeric},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {613--621},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hegazy24a/hegazy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hegazy24a.html},\n  abstract = \t {Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hegazy24a/hegazy24a.pdf",
        "supp": "",
        "pdf_size": 14851780,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10983702442208360653&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cef55f7db6",
        "title": "Computing epidemic metrics with edge differential privacy",
        "site": "https://proceedings.mlr.press/v238/li24q.html",
        "author": "George Z. Li; Dung Nguyen; Anil Vullikanti",
        "abstract": "Metrics such as the outbreak size in an epidemic process on a network are fundamental quantities used in public health analyses. The datasets used in such models used in practice, e.g., the contact network and disease states, are sensitive in many settings. We study the complexity of computing epidemic outbreak size within a given time horizon, under edge differential privacy. These quantities have high sensitivity, and we show that giving algorithms with good utility guarantees is impossible for general graphs. To address these hardness results, we consider a smaller class of graphs with similar properties as social networks (called expander graphs) and give a polynomial-time algorithm with strong utility guarantees. Our results are the first to give any non-trivial guarantees for differentially private infection size estimation.",
        "bibtex": "@InProceedings{pmlr-v238-li24q,\n  title = \t {Computing epidemic metrics with edge differential privacy},\n  author =       {Li, George Z. and Nguyen, Dung and Vullikanti, Anil},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4303--4311},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24q/li24q.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24q.html},\n  abstract = \t {Metrics such as the outbreak size in an epidemic process on a network are fundamental quantities used in public health analyses. The datasets used in such models used in practice, e.g., the contact network and disease states, are sensitive in many settings. We study the complexity of computing epidemic outbreak size within a given time horizon, under edge differential privacy. These quantities have high sensitivity, and we show that giving algorithms with good utility guarantees is impossible for general graphs. To address these hardness results, we consider a smaller class of graphs with similar properties as social networks (called expander graphs) and give a polynomial-time algorithm with strong utility guarantees. Our results are the first to give any non-trivial guarantees for differentially private infection size estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24q/li24q.pdf",
        "supp": "",
        "pdf_size": 351472,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7297967035881314675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a65e3286b5",
        "title": "Conditional Adjustment in a Markov Equivalence Class",
        "site": "https://proceedings.mlr.press/v238/laplante24a.html",
        "author": "Sara LaPlante; Emilija Perkovic",
        "abstract": "We consider the problem of identifying a conditional causal effect through covariate adjustment. We focus on the setting where the causal graph is known up to one of two types of graphs: a maximally oriented partially directed acyclic graph (MPDAG) or a partial ancestral graph (PAG). Both MPDAGs and PAGs represent equivalence classes of possible underlying causal models. After defining adjustment sets in this setting, we provide a necessary and sufficient graphical criterion \u2013 the conditional adjustment criterion \u2013 for finding these sets under conditioning on variables unaffected by treatment. We further provide explicit sets from the graph that satisfy the conditional adjustment criterion, and therefore, can be used as adjustment sets for conditional causal effect identification.",
        "bibtex": "@InProceedings{pmlr-v238-laplante24a,\n  title = \t {Conditional Adjustment in a {M}arkov Equivalence Class},\n  author =       {LaPlante, Sara and Perkovic, Emilija},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2782--2790},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/laplante24a/laplante24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/laplante24a.html},\n  abstract = \t {We consider the problem of identifying a conditional causal effect through covariate adjustment. We focus on the setting where the causal graph is known up to one of two types of graphs: a maximally oriented partially directed acyclic graph (MPDAG) or a partial ancestral graph (PAG). Both MPDAGs and PAGs represent equivalence classes of possible underlying causal models. After defining adjustment sets in this setting, we provide a necessary and sufficient graphical criterion \u2013 the conditional adjustment criterion \u2013 for finding these sets under conditioning on variables unaffected by treatment. We further provide explicit sets from the graph that satisfy the conditional adjustment criterion, and therefore, can be used as adjustment sets for conditional causal effect identification.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/laplante24a/laplante24a.pdf",
        "supp": "",
        "pdf_size": 565194,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3228831387695187579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Washington; University of Washington",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f21402d536",
        "title": "Conditions on Preference Relations that Guarantee the Existence of Optimal Policies",
        "site": "https://proceedings.mlr.press/v238/colaco-carr24a.html",
        "author": "Jonathan Cola\u00e7o Carr; Prakash Panangaden; Doina Precup",
        "abstract": "Learning from Preferential Feedback (LfPF) plays an essential role in training Large Language Models, as well as certain types of interactive learning agents. However, a substantial gap exists between the theory and application of LfPF algorithms. Current results guaranteeing the existence of optimal policies in LfPF problems assume that both the preferences and transition dynamics are determined by a Markov Decision Process. We introduce the Direct Preference Process, a new framework for analyzing LfPF problems in partially-observable, non-Markovian environments. Within this framework, we establish conditions that guarantee the existence of optimal policies by considering the ordinal structure of the preferences. We show that a decision-making problem can have optimal policies \u2013 that are characterized by recursive optimality equations \u2013 even when no reward function can express the learning goal. These findings underline the need to explore preference-based learning strategies which do not assume that preferences are generated by reward.",
        "bibtex": "@InProceedings{pmlr-v238-colaco-carr24a,\n  title = \t {Conditions on Preference Relations that Guarantee the Existence of Optimal Policies},\n  author =       {Cola\\c{c}o Carr, Jonathan and Panangaden, Prakash and Precup, Doina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3916--3924},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/colaco-carr24a/colaco-carr24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/colaco-carr24a.html},\n  abstract = \t {Learning from Preferential Feedback (LfPF) plays an essential role in training Large Language Models, as well as certain types of interactive learning agents. However, a substantial gap exists between the theory and application of LfPF algorithms. Current results guaranteeing the existence of optimal policies in LfPF problems assume that both the preferences and transition dynamics are determined by a Markov Decision Process. We introduce the Direct Preference Process, a new framework for analyzing LfPF problems in partially-observable, non-Markovian environments. Within this framework, we establish conditions that guarantee the existence of optimal policies by considering the ordinal structure of the preferences. We show that a decision-making problem can have optimal policies \u2013 that are characterized by recursive optimality equations \u2013 even when no reward function can express the learning goal. These findings underline the need to explore preference-based learning strategies which do not assume that preferences are generated by reward.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/colaco-carr24a/colaco-carr24a.pdf",
        "supp": "",
        "pdf_size": 443226,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10635584926045044984&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "557d3c27c3",
        "title": "Confident Feature Ranking",
        "site": "https://proceedings.mlr.press/v238/neuhof24a.html",
        "author": "Bitya Neuhof; Yuval Benjamini",
        "abstract": "Machine learning models are widely applied in various fields. Stakeholders often use post-hoc feature importance methods to better understand the input features\u2019 contribution to the models\u2019 predictions. The interpretation of the importance values provided by these methods is frequently based on the relative order of the features (their ranking) rather than the importance values themselves. Since the order may be unstable, we present a framework for quantifying the uncertainty in global importance values. We propose a novel method for the post-hoc interpretation of feature importance values that is based on the framework and pairwise comparisons of the feature importance values. This method produces simultaneous confidence intervals for the features\u2019 ranks, which include the \u201ctrue\u201d (infinite sample) ranks with high probability, and enables the selection of the set of top-k important features.",
        "bibtex": "@InProceedings{pmlr-v238-neuhof24a,\n  title = \t {Confident Feature Ranking},\n  author =       {Neuhof, Bitya and Benjamini, Yuval},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1468--1476},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/neuhof24a/neuhof24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/neuhof24a.html},\n  abstract = \t {Machine learning models are widely applied in various fields. Stakeholders often use post-hoc feature importance methods to better understand the input features\u2019 contribution to the models\u2019 predictions. The interpretation of the importance values provided by these methods is frequently based on the relative order of the features (their ranking) rather than the importance values themselves. Since the order may be unstable, we present a framework for quantifying the uncertainty in global importance values. We propose a novel method for the post-hoc interpretation of feature importance values that is based on the framework and pairwise comparisons of the feature importance values. This method produces simultaneous confidence intervals for the features\u2019 ranks, which include the \u201ctrue\u201d (infinite sample) ranks with high probability, and enables the selection of the set of top-k important features.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/neuhof24a/neuhof24a.pdf",
        "supp": "",
        "pdf_size": 1172766,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12385572798226851504&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The Hebrew University of Jerusalem, Israel; The Hebrew University of Jerusalem, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hebrew University of Jerusalem",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.huji.ac.il",
        "aff_unique_abbr": "HUJI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "f506f04d3a",
        "title": "Conformal Contextual Robust Optimization",
        "site": "https://proceedings.mlr.press/v238/patel24a.html",
        "author": "Yash P. Patel; Sahana Rayan; Ambuj Tewari",
        "abstract": "Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decision-making. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating results on a suite of simulation-based inference benchmark tasks and a vehicle routing task based on probabilistic weather prediction.",
        "bibtex": "@InProceedings{pmlr-v238-patel24a,\n  title = \t {Conformal Contextual Robust Optimization},\n  author =       {Patel, Yash P. and Rayan, Sahana and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2485--2493},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/patel24a/patel24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/patel24a.html},\n  abstract = \t {Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decision-making. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating results on a suite of simulation-based inference benchmark tasks and a vehicle routing task based on probabilistic weather prediction.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/patel24a/patel24a.pdf",
        "supp": "",
        "pdf_size": 6294333,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10696578034796115705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Michigan; University of Michigan; University of Michigan",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "285574b654",
        "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
        "site": "https://proceedings.mlr.press/v238/diamant24a.html",
        "author": "Nathaniel Diamant; Ehsan Hajiramezanali; Tommaso Biancalani; Gabriele Scalia",
        "abstract": "Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural- network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically reflected by our experiments. SPICE is compatible with two different efficient-to- compute conformal scores, one designed for size-efficient marginal coverage (SPICE-ND) and the other for size-efficient conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available.",
        "bibtex": "@InProceedings{pmlr-v238-diamant24a,\n  title = \t {Conformalized Deep Splines for Optimal and Efficient Prediction Sets},\n  author =       {Diamant, Nathaniel and Hajiramezanali, Ehsan and Biancalani, Tommaso and Scalia, Gabriele},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1657--1665},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/diamant24a/diamant24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/diamant24a.html},\n  abstract = \t {Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural- network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically reflected by our experiments. SPICE is compatible with two different efficient-to- compute conformal scores, one designed for size-efficient marginal coverage (SPICE-ND) and the other for size-efficient conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/diamant24a/diamant24a.pdf",
        "supp": "",
        "pdf_size": 633992,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9188101725315250368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "224ec9e9f6",
        "title": "Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection",
        "site": "https://proceedings.mlr.press/v238/han24b.html",
        "author": "Yujin Han; Mingwenchan Xu; Leying Guan",
        "abstract": "The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes under arbitrarily label-shift in the test data. We compare CSForest with state-of-the-art methods using synthetic examples and various real-world datasets, under different types of distribution changes in the test domain. Our results highlight CSForest\u2019s effective prediction of inliers and its ability to detect outlier samples unique to the test data. In addition, CSForest shows persistently good performance as the sizes of the training and test sets vary. Codes of CSForest are available at https://github.com/yujinhan98/CSForest.",
        "bibtex": "@InProceedings{pmlr-v238-han24b,\n  title = \t {Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection},\n  author =       {Han, Yujin and Xu, Mingwenchan and Guan, Leying},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2881--2889},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/han24b/han24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/han24b.html},\n  abstract = \t {The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes under arbitrarily label-shift in the test data. We compare CSForest with state-of-the-art methods using synthetic examples and various real-world datasets, under different types of distribution changes in the test domain. Our results highlight CSForest\u2019s effective prediction of inliers and its ability to detect outlier samples unique to the test data. In addition, CSForest shows persistently good performance as the sizes of the training and test sets vary. Codes of CSForest are available at https://github.com/yujinhan98/CSForest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/han24b/han24b.pdf",
        "supp": "",
        "pdf_size": 1362715,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4273166881243548552&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of IEMS, Northwestern University, Illinois, USA; Department of Biostatistics, Yale University, New Haven, USA",
        "aff_domain": "hku.hk;northwestern.edu;yale.edu",
        "email": "hku.hk;northwestern.edu;yale.edu",
        "github": "https://github.com/yujinhan98/CSForest",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Hong Kong;Northwestern University;Yale University",
        "aff_unique_dep": "Department of Computer Science;Department of IEMS;Department of Biostatistics",
        "aff_unique_url": "https://www.hku.hk;https://www.northwestern.edu;https://www.yale.edu",
        "aff_unique_abbr": "HKU;NU;Yale",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Hong Kong;Illinois;New Haven",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "208dcc2491",
        "title": "Consistency of Dictionary-Based Manifold Learning",
        "site": "https://proceedings.mlr.press/v238/koelle24a.html",
        "author": "Samson J. Koelle; Hanyu Zhang; Octavian-Vlad Murad; Marina Meila",
        "abstract": "We analyze a paradigm for interpretable Manifold Learning for scientific data analysis, whereby one parametrizes a manifold with d smooth functions from a scientist-provided dictionary of meaningful, domain-related functions. When such a parametrization exists, we provide an algorithm for finding it based on sparse regression in the manifold tangent bundle, bypassing more standard, agnostic manifold learning algorithms. We prove conditions for the existence of such parameterizations in function space and the first end to end recovery results from finite samples. The method is demonstrated on both synthetic problems and with data from a real scientific domain.",
        "bibtex": "@InProceedings{pmlr-v238-koelle24a,\n  title = \t {Consistency of Dictionary-Based Manifold Learning},\n  author =       {Koelle, Samson J. and Zhang, Hanyu and Murad, Octavian-Vlad and Meila, Marina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4348--4356},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/koelle24a/koelle24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/koelle24a.html},\n  abstract = \t {We analyze a paradigm for interpretable Manifold Learning for scientific data analysis, whereby one parametrizes a manifold with d smooth functions from a scientist-provided dictionary of meaningful, domain-related functions. When such a parametrization exists, we provide an algorithm for finding it based on sparse regression in the manifold tangent bundle, bypassing more standard, agnostic manifold learning algorithms. We prove conditions for the existence of such parameterizations in function space and the first end to end recovery results from finite samples. The method is demonstrated on both synthetic problems and with data from a real scientific domain.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/koelle24a/koelle24a.pdf",
        "supp": "",
        "pdf_size": 6851695,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=618025084718337575&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af7009eed9",
        "title": "Consistent Hierarchical Classification with A Generalized Metric",
        "site": "https://proceedings.mlr.press/v238/cao24a.html",
        "author": "Yuzhou Cao; Lei Feng; Bo An",
        "abstract": "In multi-class hierarchical classification, a natural evaluation metric is the tree distance loss that takes the value of two labels\u2019 distance on the pre-defined tree hierarchy. This metric is motivated by that its Bayes optimal solution is the deepest label on the tree whose induced superclass (subtree rooted at it) includes the true label with probability at least $\\frac{1}{2}$. However, it can hardly handle the risk sensitivity of different tasks since its accuracy requirement for induced superclasses is fixed at $\\frac{1}{2}$. In this paper, we first introduce a new evaluation metric that generalizes the tree distance loss, whose solution\u2019s accuracy constraint $\\frac{1+c}{2}$ can be controlled by a penalty value $c$ tailored for different tasks: a higher c indicates the emphasis on prediction\u2019s accuracy and a lower one indicates that on specificity. Then, we propose a novel class of consistent surrogate losses based on an intuitive presentation of our generalized metric and its regret, which can be compatible with various binary losses. Finally, we theoretically derive the regret transfer bounds for our proposed surrogates and empirically validate their usefulness on benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v238-cao24a,\n  title = \t {Consistent Hierarchical Classification with A Generalized Metric},\n  author =       {Cao, Yuzhou and Feng, Lei and An, Bo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4825--4833},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cao24a/cao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cao24a.html},\n  abstract = \t {In multi-class hierarchical classification, a natural evaluation metric is the tree distance loss that takes the value of two labels\u2019 distance on the pre-defined tree hierarchy. This metric is motivated by that its Bayes optimal solution is the deepest label on the tree whose induced superclass (subtree rooted at it) includes the true label with probability at least $\\frac{1}{2}$. However, it can hardly handle the risk sensitivity of different tasks since its accuracy requirement for induced superclasses is fixed at $\\frac{1}{2}$. In this paper, we first introduce a new evaluation metric that generalizes the tree distance loss, whose solution\u2019s accuracy constraint $\\frac{1+c}{2}$ can be controlled by a penalty value $c$ tailored for different tasks: a higher c indicates the emphasis on prediction\u2019s accuracy and a lower one indicates that on specificity. Then, we propose a novel class of consistent surrogate losses based on an intuitive presentation of our generalized metric and its regret, which can be compatible with various binary losses. Finally, we theoretically derive the regret transfer bounds for our proposed surrogates and empirically validate their usefulness on benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cao24a/cao24a.pdf",
        "supp": "",
        "pdf_size": 648871,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10102896491866124575&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore + Skywork AI, Singapore",
        "aff_domain": ";gmail.com; ",
        "email": ";gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Nanyang Technological University;Skywork AI",
        "aff_unique_dep": "School of Computer Science and Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "92a74099ee",
        "title": "Consistent Optimal Transport with Empirical Conditional Measures",
        "site": "https://proceedings.mlr.press/v238/manupriya24a.html",
        "author": "Piyushi Manupriya; Rachit K. Das; Sayantan Biswas; SakethaNath N Jagarlapudi",
        "abstract": "Given samples from two joint distributions, we consider the problem of Optimal Transportation (OT) between them when conditioned on a common variable. We focus on the general setting where the conditioned variable may be continuous, and the marginals of this variable in the two joint distributions may not be the same. In such settings, standard OT variants cannot be employed, and novel estimation techniques are necessary. Since the main challenge is that the conditional distributions are not explicitly available, the key idea in our OT formulation is to employ kernelized-least-squares terms computed over the joint samples, which implicitly match the transport plan\u2019s marginals with the empirical conditionals. Under mild conditions, we prove that our estimated transport plans, as a function of the conditioned variable, are asymptotically optimal. For finite samples, we show that the deviation in terms of our regularized objective is bounded by $O(m^{-1/4})$, where $m$ is the number of samples. We also discuss how the conditional transport plan could be modelled using explicit probabilistic models as well as using implicit generative ones. We empirically verify the consistency of our estimator on synthetic datasets, where the optimal plan is analytically known. When employed in applications like prompt learning for few-shot classification and conditional-generation in the context of predicting cell responses to treatment, our methodology improves upon state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v238-manupriya24a,\n  title = \t {Consistent Optimal Transport with Empirical Conditional Measures},\n  author =       {Manupriya, Piyushi and Das, Rachit K. and Biswas, Sayantan and N Jagarlapudi, SakethaNath},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3646--3654},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/manupriya24a/manupriya24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/manupriya24a.html},\n  abstract = \t {Given samples from two joint distributions, we consider the problem of Optimal Transportation (OT) between them when conditioned on a common variable. We focus on the general setting where the conditioned variable may be continuous, and the marginals of this variable in the two joint distributions may not be the same. In such settings, standard OT variants cannot be employed, and novel estimation techniques are necessary. Since the main challenge is that the conditional distributions are not explicitly available, the key idea in our OT formulation is to employ kernelized-least-squares terms computed over the joint samples, which implicitly match the transport plan\u2019s marginals with the empirical conditionals. Under mild conditions, we prove that our estimated transport plans, as a function of the conditioned variable, are asymptotically optimal. For finite samples, we show that the deviation in terms of our regularized objective is bounded by $O(m^{-1/4})$, where $m$ is the number of samples. We also discuss how the conditional transport plan could be modelled using explicit probabilistic models as well as using implicit generative ones. We empirically verify the consistency of our estimator on synthetic datasets, where the optimal plan is analytically known. When employed in applications like prompt learning for few-shot classification and conditional-generation in the context of predicting cell responses to treatment, our methodology improves upon state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/manupriya24a/manupriya24a.pdf",
        "supp": "",
        "pdf_size": 2086575,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10908955753120752876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "IIT Hyderabad, INDIA; Microsoft, INDIA + IIT Hyderabad, INDIA; Amazon, INDIA + IIT Hyderabad, INDIA; IIT Hyderabad, INDIA",
        "aff_domain": "iith.ac.in; ; ; ",
        "email": "iith.ac.in; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;2+0;0",
        "aff_unique_norm": "Indian Institute of Technology, Hyderabad;Microsoft;Amazon",
        "aff_unique_dep": ";Microsoft Corporation;Amazon",
        "aff_unique_url": "https://www.iith.ac.in;https://www.microsoft.com;https://www.amazon.in",
        "aff_unique_abbr": "IIT Hyderabad;Microsoft;Amazon",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;0+0;0+0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "ec93012408",
        "title": "Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors",
        "site": "https://proceedings.mlr.press/v238/popordanoska24a.html",
        "author": "Teodora Popordanoska; Sebastian Gregor Gruber; Aleksei Tiulpin; Florian Buettner; Matthew B. Blaschko",
        "abstract": "Proper scoring rules evaluate the quality of probabilistic predictions, playing an essential role in the pursuit of accurate and well-calibrated models. Every proper score decomposes into two fundamental components \u2013 proper calibration error and refinement \u2013 utilizing a Bregman divergence. While uncertainty calibration has gained significant attention, current literature lacks a general estimator for these quantities with known statistical properties. To address this gap, we propose a method that allows consistent, and asymptotically unbiased estimation of all proper calibration errors and refinement terms. In particular, we introduce Kullback-Leibler calibration error, induced by the commonly used cross-entropy loss. As part of our results, we prove the relation between refinement and f-divergences, which implies information monotonicity in neural networks, regardless of which proper scoring rule is optimized. Our experiments validate empirically the claimed properties of the proposed estimator and suggest that the selection of a post-hoc calibration method should be determined by the particular calibration error of interest.",
        "bibtex": "@InProceedings{pmlr-v238-popordanoska24a,\n  title = \t {Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors},\n  author =       {Popordanoska, Teodora and Gregor Gruber, Sebastian and Tiulpin, Aleksei and Buettner, Florian and B. Blaschko, Matthew},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3466--3474},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/popordanoska24a/popordanoska24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/popordanoska24a.html},\n  abstract = \t {Proper scoring rules evaluate the quality of probabilistic predictions, playing an essential role in the pursuit of accurate and well-calibrated models. Every proper score decomposes into two fundamental components \u2013 proper calibration error and refinement \u2013 utilizing a Bregman divergence. While uncertainty calibration has gained significant attention, current literature lacks a general estimator for these quantities with known statistical properties. To address this gap, we propose a method that allows consistent, and asymptotically unbiased estimation of all proper calibration errors and refinement terms. In particular, we introduce Kullback-Leibler calibration error, induced by the commonly used cross-entropy loss. As part of our results, we prove the relation between refinement and f-divergences, which implies information monotonicity in neural networks, regardless of which proper scoring rule is optimized. Our experiments validate empirically the claimed properties of the proposed estimator and suggest that the selection of a post-hoc calibration method should be determined by the particular calibration error of interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/popordanoska24a/popordanoska24a.pdf",
        "supp": "",
        "pdf_size": 1002025,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11105638678406967777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "ESAT-PSI, KU Leuven, Belgium+German Cancer Research Center (DKFZ), German Cancer Consortium (DKTK), Goethe University Frankfurt, Germany; ESAT-PSI, KU Leuven, Belgium+German Cancer Research Center (DKFZ), German Cancer Consortium (DKTK), Goethe University Frankfurt, Germany; HST Unit, University of Oulu, Finland+Preon Health Oy, Finland; German Cancer Research Center (DKFZ), German Cancer Consortium (DKTK), Frankfurt Cancer Institute, Germany+Goethe University Frankfurt, Germany; ESAT-PSI, KU Leuven, Belgium",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;2+3;4+5;0",
        "aff_unique_norm": "KU Leuven;German Cancer Research Center (DKFZ);University of Oulu;Preon Health Oy;German Cancer Research Center;Goethe University Frankfurt",
        "aff_unique_dep": "ESAT-PSI;;HST Unit;;Cancer Research;",
        "aff_unique_url": "https://www.kuleuven.be;https://www.dkfz.de;https://www.oulu.fi;;https://www.dkfz.de;https://www.uni-frankfurt.de",
        "aff_unique_abbr": "KU Leuven;DKFZ;;;DKFZ;GU Frankfurt",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;0+1;2+2;1+1;0",
        "aff_country_unique": "Belgium;Germany;Finland"
    },
    {
        "id": "a74c1059e9",
        "title": "Constant or Logarithmic Regret in Asynchronous Multiplayer Bandits with Limited Communication",
        "site": "https://proceedings.mlr.press/v238/richard24a.html",
        "author": "Hugo Richard; Etienne Boursier; Vianney Perchet",
        "abstract": "Multiplayer bandits have recently garnered significant attention due to their relevance in cognitive radio networks. While the existing body of literature predominantly focuses on synchronous players, real-world radio networks, such as those in IoT applications, often feature asynchronous (i.e., randomly activated) devices. This highlights the need for addressing the more challenging asynchronous multiplayer bandits problem. Our first result shows that a natural extension of UCB achieves a minimax regret of $\\mathcal{O}(\\sqrt{T\\log(T)})$ in the centralized setting. More significantly, we introduce Cautious Greedy, which uses $\\mathcal{O}(\\log(T))$ communications and whose instance-dependent regret is constant if the optimal policy assigns at least one player to each arm (a situation proven to occur when arm means are sufficiently close). Otherwise, the regret is, as usual, $\\log(T)$ times the sum of some inverse sub-optimality gaps. We substantiate the optimality of Cautious Greedy through lower-bound analysis based on data-dependent terms. Therefore, we establish a strong baseline for asynchronous multiplayer bandits, at least with $\\mathcal{O}(\\log(T))$ communications.",
        "bibtex": "@InProceedings{pmlr-v238-richard24a,\n  title = \t {Constant or Logarithmic Regret in Asynchronous Multiplayer Bandits with Limited Communication},\n  author =       {Richard, Hugo and Boursier, Etienne and Perchet, Vianney},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {388--396},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/richard24a/richard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/richard24a.html},\n  abstract = \t {Multiplayer bandits have recently garnered significant attention due to their relevance in cognitive radio networks. While the existing body of literature predominantly focuses on synchronous players, real-world radio networks, such as those in IoT applications, often feature asynchronous (i.e., randomly activated) devices. This highlights the need for addressing the more challenging asynchronous multiplayer bandits problem. Our first result shows that a natural extension of UCB achieves a minimax regret of $\\mathcal{O}(\\sqrt{T\\log(T)})$ in the centralized setting. More significantly, we introduce Cautious Greedy, which uses $\\mathcal{O}(\\log(T))$ communications and whose instance-dependent regret is constant if the optimal policy assigns at least one player to each arm (a situation proven to occur when arm means are sufficiently close). Otherwise, the regret is, as usual, $\\log(T)$ times the sum of some inverse sub-optimality gaps. We substantiate the optimality of Cautious Greedy through lower-bound analysis based on data-dependent terms. Therefore, we establish a strong baseline for asynchronous multiplayer bandits, at least with $\\mathcal{O}(\\log(T))$ communications.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/richard24a/richard24a.pdf",
        "supp": "",
        "pdf_size": 1040552,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13339087331848596042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "55cf87eda7",
        "title": "Contextual Bandits with Budgeted Information Reveal",
        "site": "https://proceedings.mlr.press/v238/gan24a.html",
        "author": "Kyra Gan; Esmaeil Keyvanshokooh; Xueqing Liu; Susan Murphy",
        "abstract": "Contextual bandit algorithms are commonly used in digital health to recommend personalized treatments. However, to ensure the effectiveness of the treatments, patients are often requested to take actions that have no immediate benefit to them, which we refer to as pro-treatment actions. In practice, clinicians have a limited budget to encourage patients to take these actions and collect additional information. We introduce a novel optimization and learning algorithm to address this problem. This algorithm effectively combines the strengths of two algorithmic approaches in a seamless manner, including 1) an online primal-dual algorithm for deciding the optimal timing to reach out to patients, and 2) a contextual bandit learning algorithm to deliver personalized treatment to the patient. We prove that this algorithm admits a sub-linear regret bound. We illustrate the usefulness of this algorithm on both synthetic and real-world data.",
        "bibtex": "@InProceedings{pmlr-v238-gan24a,\n  title = \t {Contextual Bandits with Budgeted Information Reveal},\n  author =       {Gan, Kyra and Keyvanshokooh, Esmaeil and Liu, Xueqing and Murphy, Susan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3970--3978},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gan24a/gan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gan24a.html},\n  abstract = \t {Contextual bandit algorithms are commonly used in digital health to recommend personalized treatments. However, to ensure the effectiveness of the treatments, patients are often requested to take actions that have no immediate benefit to them, which we refer to as pro-treatment actions. In practice, clinicians have a limited budget to encourage patients to take these actions and collect additional information. We introduce a novel optimization and learning algorithm to address this problem. This algorithm effectively combines the strengths of two algorithmic approaches in a seamless manner, including 1) an online primal-dual algorithm for deciding the optimal timing to reach out to patients, and 2) a contextual bandit learning algorithm to deliver personalized treatment to the patient. We prove that this algorithm admits a sub-linear regret bound. We illustrate the usefulness of this algorithm on both synthetic and real-world data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gan24a/gan24a.pdf",
        "supp": "",
        "pdf_size": 3260491,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3255316624246291279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1113f92da0",
        "title": "Contextual Directed Acyclic Graphs",
        "site": "https://proceedings.mlr.press/v238/thompson24a.html",
        "author": "Ryan Thompson; Edwin V. Bonilla; Robert Kohn",
        "abstract": "Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available \"contextual\" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail.",
        "bibtex": "@InProceedings{pmlr-v238-thompson24a,\n  title = \t {Contextual Directed Acyclic Graphs},\n  author =       {Thompson, Ryan and V. Bonilla, Edwin and Kohn, Robert},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2872--2880},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/thompson24a/thompson24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/thompson24a.html},\n  abstract = \t {Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available \"contextual\" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/thompson24a/thompson24a.pdf",
        "supp": "",
        "pdf_size": 624968,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17963050197833977240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ce169333c",
        "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
        "site": "https://proceedings.mlr.press/v238/shen24a.html",
        "author": "Yan Shen; Zhanghexuan Ji; Chunwei Ma; Mingchen Gao",
        "abstract": "Domain adversarial adaptation in a continual setting poses significant challenges due to the limitations of accessing previous source domain data. Despite extensive research in continual learning, adversarial adaptation cannot be effectively accomplished using only a small number of stored source domain data, a standard setting in memory replay approaches. This limitation arises from the erroneous empirical estimation of $\\mathcal{H}$-divergence with few source domain samples. To tackle this problem, we propose a double-head discriminator algorithm by introducing an addition source-only domain discriminator trained solely on the source learning phase. We prove that by introducing a pre-trained source-only domain discriminator, the empirical estimation error of $\\mathcal{H}$-divergence related adversarial loss is reduced from the source domain side. Further experiments on existing domain adaptation benchmarks show that our proposed algorithm achieves more than 2$%$ improvement on all categories of target domain adaptation tasks while significantly mitigating the forgetting of the source domain.",
        "bibtex": "@InProceedings{pmlr-v238-shen24a,\n  title = \t {Continual Domain Adversarial Adaptation via Double-Head Discriminators},\n  author =       {Shen, Yan and Ji, Zhanghexuan and Ma, Chunwei and Gao, Mingchen},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2584--2592},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shen24a/shen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shen24a.html},\n  abstract = \t {Domain adversarial adaptation in a continual setting poses significant challenges due to the limitations of accessing previous source domain data. Despite extensive research in continual learning, adversarial adaptation cannot be effectively accomplished using only a small number of stored source domain data, a standard setting in memory replay approaches. This limitation arises from the erroneous empirical estimation of $\\mathcal{H}$-divergence with few source domain samples. To tackle this problem, we propose a double-head discriminator algorithm by introducing an addition source-only domain discriminator trained solely on the source learning phase. We prove that by introducing a pre-trained source-only domain discriminator, the empirical estimation error of $\\mathcal{H}$-divergence related adversarial loss is reduced from the source domain side. Further experiments on existing domain adaptation benchmarks show that our proposed algorithm achieves more than 2$%$ improvement on all categories of target domain adaptation tasks while significantly mitigating the forgetting of the source domain.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shen24a/shen24a.pdf",
        "supp": "",
        "pdf_size": 1406348,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11538889541778894777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a1be717d55",
        "title": "Convergence to Nash Equilibrium and No-regret Guarantee in (Markov) Potential Games",
        "site": "https://proceedings.mlr.press/v238/dong24a.html",
        "author": "Jing Dong; Baoxiang Wang; Yaoliang Yu",
        "abstract": "In this work, we study potential games and Markov potential games under stochastic cost and bandit feedback. We propose a variant of the Frank-Wolfe algorithm with sufficient exploration and recursive gradient estimation, which provably converges to the Nash equilibrium while attaining sublinear regret for each individual player. Our algorithm simultaneously achieves a Nash regret and a regret bound of $O(T^{4/5})$ for potential games, which matches the best available result, without using additional projection steps. Through carefully balancing the reuse of past samples and exploration of new samples, we then extend the results to Markov potential games and improve the best available Nash regret from $O(T^{5/6})$ to $O(T^{4/5})$. Moreover, our algorithm requires no knowledge of the game, such as the distribution mismatch coefficient, which provides more flexibility in its practical implementation. Experimental results corroborate our theoretical findings and underscore the practical effectiveness of our method.",
        "bibtex": "@InProceedings{pmlr-v238-dong24a,\n  title = \t {Convergence to {N}ash Equilibrium and No-regret Guarantee in ({M}arkov) Potential Games},\n  author =       {Dong, Jing and Wang, Baoxiang and Yu, Yaoliang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2044--2052},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dong24a/dong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dong24a.html},\n  abstract = \t {In this work, we study potential games and Markov potential games under stochastic cost and bandit feedback. We propose a variant of the Frank-Wolfe algorithm with sufficient exploration and recursive gradient estimation, which provably converges to the Nash equilibrium while attaining sublinear regret for each individual player. Our algorithm simultaneously achieves a Nash regret and a regret bound of $O(T^{4/5})$ for potential games, which matches the best available result, without using additional projection steps. Through carefully balancing the reuse of past samples and exploration of new samples, we then extend the results to Markov potential games and improve the best available Nash regret from $O(T^{5/6})$ to $O(T^{4/5})$. Moreover, our algorithm requires no knowledge of the game, such as the distribution mismatch coefficient, which provides more flexibility in its practical implementation. Experimental results corroborate our theoretical findings and underscore the practical effectiveness of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dong24a/dong24a.pdf",
        "supp": "",
        "pdf_size": 474397,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:XmXmSiF7DbYJ:scholar.google.com/&scioq=Convergence+to+Nash+Equilibrium+and+No-regret+Guarantee+in+(Markov)+Potential+Games&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Chinese University of Hong Kong, Shenzhen; Chinese University of Hong Kong, Shenzhen; University of Waterloo",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;University of Waterloo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;https://uwaterloo.ca",
        "aff_unique_abbr": "CUHK;UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "fae8c3ae9b",
        "title": "Coreset Markov chain Monte Carlo",
        "site": "https://proceedings.mlr.press/v238/chen24f.html",
        "author": "Naitong Chen; Trevor Campbell",
        "abstract": "A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method\u2014coreset MCMC\u2014that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that coreset MCMC has a higher sampling efficiency with competitively accurate posterior approximations.",
        "bibtex": "@InProceedings{pmlr-v238-chen24f,\n  title = \t {{C}oreset {M}arkov chain {M}onte {C}arlo},\n  author =       {Chen, Naitong and Campbell, Trevor},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4438--4446},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24f/chen24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24f.html},\n  abstract = \t {A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method\u2014coreset MCMC\u2014that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that coreset MCMC has a higher sampling efficiency with competitively accurate posterior approximations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24f/chen24f.pdf",
        "supp": "",
        "pdf_size": 1866050,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11819146105901263589&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, University of British Columbia; Department of Statistics, University of British Columbia",
        "aff_domain": "stat.ubc.ca;stat.ubc.ca",
        "email": "stat.ubc.ca;stat.ubc.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Vancouver",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "b0c7469b95",
        "title": "Corruption-Robust Offline Two-Player Zero-Sum Markov Games",
        "site": "https://proceedings.mlr.press/v238/nika24a.html",
        "author": "Andi Nika; Debmalya Mandal; Adish Singla; Goran Radanovic",
        "abstract": "We study data corruption robustness in offline two-player zero-sum Markov games. Given a dataset of realized trajectories of two players, an adversary is allowed to modify an $\\epsilon$-fraction of it. The learner\u2019s goal is to identify an approximate Nash Equilibrium policy pair from the corrupted data. We consider this problem in linear Markov games under different degrees of data coverage and corruption. We start by providing an information-theoretic lower bound on the suboptimality gap of any learner. Next, we propose robust versions of the Pessimistic Minimax Value Iteration algorithm (Zhong et al., 2022), both under coverage on the corrupted data and under coverage only on the clean data, and show that they achieve (near)-optimal suboptimality gap bounds with respect to $\\epsilon$. We note that we are the first to provide such a characterization of the problem of learning approximate Nash Equilibrium policies in offline two-player zero-sum Markov games under data corruption.",
        "bibtex": "@InProceedings{pmlr-v238-nika24a,\n  title = \t {Corruption-Robust Offline Two-Player Zero-Sum {M}arkov Games},\n  author =       {Nika, Andi and Mandal, Debmalya and Singla, Adish and Radanovic, Goran},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1243--1251},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nika24a/nika24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nika24a.html},\n  abstract = \t {We study data corruption robustness in offline two-player zero-sum Markov games. Given a dataset of realized trajectories of two players, an adversary is allowed to modify an $\\epsilon$-fraction of it. The learner\u2019s goal is to identify an approximate Nash Equilibrium policy pair from the corrupted data. We consider this problem in linear Markov games under different degrees of data coverage and corruption. We start by providing an information-theoretic lower bound on the suboptimality gap of any learner. Next, we propose robust versions of the Pessimistic Minimax Value Iteration algorithm (Zhong et al., 2022), both under coverage on the corrupted data and under coverage only on the clean data, and show that they achieve (near)-optimal suboptimality gap bounds with respect to $\\epsilon$. We note that we are the first to provide such a characterization of the problem of learning approximate Nash Equilibrium policies in offline two-player zero-sum Markov games under data corruption.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nika24a/nika24a.pdf",
        "supp": "",
        "pdf_size": 707874,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11653610710568316230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7dc66b948e",
        "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning",
        "site": "https://proceedings.mlr.press/v238/pasarkar24a.html",
        "author": "Amey P. Pasarkar; Adji Bousso Dieng",
        "abstract": "Measuring diversity accurately is important for many scientific fields, including machine learning (ML), ecology, and chemistry. The Vendi Score was introduced as a generic similarity-based diversity metric that extends the Hill number of order $q=1$ by leveraging ideas from quantum statistical mechanics. Contrary to many diversity metrics in ecology, the Vendi Score accounts for similarity and does not require knowledge of the prevalence of the categories in the collection to be evaluated for diversity. However, the Vendi Score treats each item in a given collection with a level of sensitivity proportional to the item\u2019s prevalence. This is undesirable in settings where there is a significant imbalance in item prevalence. In this paper, we extend the other Hill numbers using similarity to provide flexibility in allocating sensitivity to rare or common items. This leads to a family of diversity metrics\u2013Vendi scores with different levels of sensitivity controlled by the order $q$\u2013that can be used in a variety of applications. We study the properties of the scores in a synthetic controlled setting where the ground truth diversity is known. We then test the utility of the Vendi scores in improving molecular simulations via Vendi Sampling. Finally, we use the scores to better understand the behavior of image generative models in terms of memorization, duplication, diversity, and sample quality.",
        "bibtex": "@InProceedings{pmlr-v238-pasarkar24a,\n  title = \t {Cousins Of The {V}endi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning},\n  author =       {Pasarkar, Amey P. and Dieng, Adji Bousso},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3808--3816},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pasarkar24a/pasarkar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pasarkar24a.html},\n  abstract = \t {Measuring diversity accurately is important for many scientific fields, including machine learning (ML), ecology, and chemistry. The Vendi Score was introduced as a generic similarity-based diversity metric that extends the Hill number of order $q=1$ by leveraging ideas from quantum statistical mechanics. Contrary to many diversity metrics in ecology, the Vendi Score accounts for similarity and does not require knowledge of the prevalence of the categories in the collection to be evaluated for diversity. However, the Vendi Score treats each item in a given collection with a level of sensitivity proportional to the item\u2019s prevalence. This is undesirable in settings where there is a significant imbalance in item prevalence. In this paper, we extend the other Hill numbers using similarity to provide flexibility in allocating sensitivity to rare or common items. This leads to a family of diversity metrics\u2013Vendi scores with different levels of sensitivity controlled by the order $q$\u2013that can be used in a variety of applications. We study the properties of the scores in a synthetic controlled setting where the ground truth diversity is known. We then test the utility of the Vendi scores in improving molecular simulations via Vendi Sampling. Finally, we use the scores to better understand the behavior of image generative models in terms of memorization, duplication, diversity, and sample quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pasarkar24a/pasarkar24a.pdf",
        "supp": "",
        "pdf_size": 8279375,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11206957030886740421&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Vertaix; Department of Computer Science, Princeton University",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Vertaix;Princeton University",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": ";https://www.princeton.edu",
        "aff_unique_abbr": ";Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "13008d507d",
        "title": "Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation",
        "site": "https://proceedings.mlr.press/v238/en24a.html",
        "author": "Qing En; Yuhong Guo",
        "abstract": "Medical image segmentation typically demands extensive dense annotations for model training, which is both time-consuming and skill-intensive. To mitigate this burden, exemplar-based medical image segmentation methods have been introduced to achieve effective training with only one annotated image. In this paper, we introduce a novel Cross-model Mutual learning framework for Exemplar-based Medical image Segmentation (CMEMS), which leverages two models to mutually excavate implicit information from unlabeled data at multiple granularities. CMEMS can eliminate confirmation bias and enable collaborative training to learn complementary information by enforcing consistency at different granularities across models. Concretely, cross-model image perturbation based mutual learning is devised by using weakly perturbed images to generate high-confidence pseudo-labels, supervising predictions of strongly perturbed images across models. This approach enables joint pursuit of prediction consistency at the image granularity. Moreover, cross-model multi-level feature perturbation based mutual learning is designed by letting pseudo-labels supervise predictions from perturbed multi-level features with different resolutions, which can broaden the perturbation space and enhance the robustness of our framework. CMEMS is jointly trained using exemplar data, synthetic data, and unlabeled data in an end-to-end manner. Experimental results on two medical image datasets indicate that the proposed CMEMS outperforms the state-of-the-art segmentation methods with extremely limited supervision.",
        "bibtex": "@InProceedings{pmlr-v238-en24a,\n  title = \t {Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation},\n  author =       {En, Qing and Guo, Yuhong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1441--1449},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/en24a/en24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/en24a.html},\n  abstract = \t {Medical image segmentation typically demands extensive dense annotations for model training, which is both time-consuming and skill-intensive. To mitigate this burden, exemplar-based medical image segmentation methods have been introduced to achieve effective training with only one annotated image. In this paper, we introduce a novel Cross-model Mutual learning framework for Exemplar-based Medical image Segmentation (CMEMS), which leverages two models to mutually excavate implicit information from unlabeled data at multiple granularities. CMEMS can eliminate confirmation bias and enable collaborative training to learn complementary information by enforcing consistency at different granularities across models. Concretely, cross-model image perturbation based mutual learning is devised by using weakly perturbed images to generate high-confidence pseudo-labels, supervising predictions of strongly perturbed images across models. This approach enables joint pursuit of prediction consistency at the image granularity. Moreover, cross-model multi-level feature perturbation based mutual learning is designed by letting pseudo-labels supervise predictions from perturbed multi-level features with different resolutions, which can broaden the perturbation space and enhance the robustness of our framework. CMEMS is jointly trained using exemplar data, synthetic data, and unlabeled data in an end-to-end manner. Experimental results on two medical image datasets indicate that the proposed CMEMS outperforms the state-of-the-art segmentation methods with extremely limited supervision.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/en24a/en24a.pdf",
        "supp": "",
        "pdf_size": 2521262,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:NdsjC2oVJVUJ:scholar.google.com/&scioq=Cross-model+Mutual+Learning+for+Exemplar-based+Medical+Image+Segmentation&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "School of Computer Science, Carleton University, Ottawa, Canada + Canada CIFAR AI Chair, Amii, Canada; School of Computer Science, Carleton University, Ottawa, Canada + Canada CIFAR AI Chair, Amii, Canada",
        "aff_domain": "cunet.carleton.ca;carleton.ca",
        "email": "cunet.carleton.ca;carleton.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Carleton University;Amii",
        "aff_unique_dep": "School of Computer Science;Canada CIFAR AI Chair",
        "aff_unique_url": "https://carleton.ca;",
        "aff_unique_abbr": "Carleton;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ottawa;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "dfd02b418e",
        "title": "Cylindrical Thompson Sampling for High-Dimensional Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v238/rashidi24a.html",
        "author": "Bahador Rashidi; Kerrick Johnstonbaugh; Chao Gao",
        "abstract": "Many industrial and scientific applications require optimization of one or more objectives by tuning dozens or hundreds of input parameters. While Bayesian optimization has been a popular approach for the efficient optimization of blackbox functions, its performance decreases drastically as the dimensionality of the search space increases (i.e., above twenty). Recent advancements in high-dimensional Bayesian optimization (HDBO) seek to mitigate this issue through techniques such as adaptive local search with trust regions or dimensionality reduction using random embeddings. In this paper, we provide a close examination of these advancements and show that sampling strategy plays a prominent role and is key to tackling the curse-of-dimensionality. We then propose cylindrical Thompson sampling (CTS), a novel strategy that can be integrated into single- and multi-objective HDBO algorithms. We demonstrate this by integrating CTS as a modular component in state-of-the-art HDBO algorithms. We verify the effectiveness of CTS on both synthetic and real-world high-dimensional problems, and show that CTS largely enhances existing HDBO methods.",
        "bibtex": "@InProceedings{pmlr-v238-rashidi24a,\n  title = \t {Cylindrical {T}hompson Sampling for High-Dimensional {B}ayesian Optimization},\n  author =       {Rashidi, Bahador and Johnstonbaugh, Kerrick and Gao, Chao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3502--3510},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rashidi24a/rashidi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rashidi24a.html},\n  abstract = \t {Many industrial and scientific applications require optimization of one or more objectives by tuning dozens or hundreds of input parameters. While Bayesian optimization has been a popular approach for the efficient optimization of blackbox functions, its performance decreases drastically as the dimensionality of the search space increases (i.e., above twenty). Recent advancements in high-dimensional Bayesian optimization (HDBO) seek to mitigate this issue through techniques such as adaptive local search with trust regions or dimensionality reduction using random embeddings. In this paper, we provide a close examination of these advancements and show that sampling strategy plays a prominent role and is key to tackling the curse-of-dimensionality. We then propose cylindrical Thompson sampling (CTS), a novel strategy that can be integrated into single- and multi-objective HDBO algorithms. We demonstrate this by integrating CTS as a modular component in state-of-the-art HDBO algorithms. We verify the effectiveness of CTS on both synthetic and real-world high-dimensional problems, and show that CTS largely enhances existing HDBO methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rashidi24a/rashidi24a.pdf",
        "supp": "",
        "pdf_size": 2483532,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8965095608322588431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Huawei Canada; Huawei Canada; Huawei Canada",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Huawei",
        "aff_unique_url": "https://www.huawei.com/ca-en/",
        "aff_unique_abbr": "Huawei Canada",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "3c3e9d08f0",
        "title": "DAGnosis: Localized Identification of Data Inconsistencies using Structures",
        "site": "https://proceedings.mlr.press/v238/huynh24a.html",
        "author": "Nicolas Huynh; Jeroen Berrevoets; Nabeel Seedat; Jonathan Crabb\u00e9; Zhaozhi Qian; Mihaela van der Schaar",
        "abstract": "Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set\u2019s features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspect overlooked by previous approaches. Moreover, we show empirically that leveraging these interactions (1) leads to more accurate conclusions in detecting inconsistencies, as well as (2) provides more detailed insights into why some samples are flagged.",
        "bibtex": "@InProceedings{pmlr-v238-huynh24a,\n  title = \t {{DAGnosis}: Localized Identification of Data Inconsistencies using Structures},\n  author =       {Huynh, Nicolas and Berrevoets, Jeroen and Seedat, Nabeel and Crabb\\'{e}, Jonathan and Qian, Zhaozhi and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1864--1872},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/huynh24a/huynh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/huynh24a.html},\n  abstract = \t {Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set\u2019s features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspect overlooked by previous approaches. Moreover, we show empirically that leveraging these interactions (1) leads to more accurate conclusions in detecting inconsistencies, as well as (2) provides more detailed insights into why some samples are flagged.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/huynh24a/huynh24a.pdf",
        "supp": "",
        "pdf_size": 606980,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11087446970815924463&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cb9b0a4ef9",
        "title": "DE-HNN: An effective neural model for Circuit Netlist representation",
        "site": "https://proceedings.mlr.press/v238/luo24a.html",
        "author": "Zhishang Luo; Truong Son Hy; Puoya Tabaghi; Micha\u00ebl Defferrard; Elahe Rezaei; Ryan M. Carey; Rhett Davis; Rajeev Jain; Yusu Wang",
        "abstract": "The run-time for optimization tools used in chip design has grown with the complexity of designs to the point where it can take several days to go through one design cycle which has become a bottleneck. Designers want fast tools that can quickly give feedback on a design. Using the input and output data of the tools from past designs, one can attempt to build a machine learning model that predicts the outcome of a design in significantly shorter time than running the tool. The accuracy of such models is affected by the representation of the design data, which is usually a netlist that describes the elements of the digital circuit and how they are connected. Graph representations for the netlist together with graph neural networks have been investigated for such models. However, the characteristics of netlists pose several challenges for existing graph learning frameworks, due to the large number of nodes and the importance of long-range interactions between nodes. To address these challenges, we represent the netlist as a directed hypergraph and propose a Directional Equivariant Hypergraph Neural Network (DE-HNN) for the effective learning of (directed) hypergraphs. Theoretically, we show that our DE-HNN can universally approximate any node or hyperedge based function that satisfies certain permutation equivariant and invariant properties natural for directed hypergraphs. We compare the proposed DE-HNN with several State-of-the-art (SOTA) machine learning models for (hyper)graphs and netlists, and show that the DE-HNN significantly outperforms them in predicting the outcome of optimized place-and-route tools directly from the input netlists.",
        "bibtex": "@InProceedings{pmlr-v238-luo24a,\n  title = \t {{DE-HNN}: An effective neural model for Circuit {N}etlist representation},\n  author =       {Luo, Zhishang and Son Hy, Truong and Tabaghi, Puoya and Defferrard, Micha\\\"{e}l and Rezaei, Elahe and Carey, Ryan M. and Davis, Rhett and Jain, Rajeev and Wang, Yusu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4258--4266},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/luo24a/luo24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/luo24a.html},\n  abstract = \t {The run-time for optimization tools used in chip design has grown with the complexity of designs to the point where it can take several days to go through one design cycle which has become a bottleneck. Designers want fast tools that can quickly give feedback on a design. Using the input and output data of the tools from past designs, one can attempt to build a machine learning model that predicts the outcome of a design in significantly shorter time than running the tool. The accuracy of such models is affected by the representation of the design data, which is usually a netlist that describes the elements of the digital circuit and how they are connected. Graph representations for the netlist together with graph neural networks have been investigated for such models. However, the characteristics of netlists pose several challenges for existing graph learning frameworks, due to the large number of nodes and the importance of long-range interactions between nodes. To address these challenges, we represent the netlist as a directed hypergraph and propose a Directional Equivariant Hypergraph Neural Network (DE-HNN) for the effective learning of (directed) hypergraphs. Theoretically, we show that our DE-HNN can universally approximate any node or hyperedge based function that satisfies certain permutation equivariant and invariant properties natural for directed hypergraphs. We compare the proposed DE-HNN with several State-of-the-art (SOTA) machine learning models for (hyper)graphs and netlists, and show that the DE-HNN significantly outperforms them in predicting the outcome of optimized place-and-route tools directly from the input netlists.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/luo24a/luo24a.pdf",
        "supp": "",
        "pdf_size": 942208,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13663561275724183190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;;;;",
        "aff_domain": ";;;;;;;;",
        "email": ";;;;;;;;",
        "github": "https://github.com/YusuLab/chips.git",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d7533c000e",
        "title": "DHMConv: Directed Hypergraph Momentum Convolution Framework",
        "site": "https://proceedings.mlr.press/v238/zhao24c.html",
        "author": "Wenbo Zhao; Zitong Ma; Zhe Yang",
        "abstract": "Due to its capability to capture high-order information, the hypergraph model has shown greater potential than the graph model in various scenarios. Real-world entity relations frequently involve directionality, in order to express high-order information while capturing directional information in relationships, we present a directed hypergraph spatial convolution framework that is designed to acquire vertex embeddings of directed hypergraphs. The framework characterizes the information propagation of directed hypergraphs through two stages: hyperedge information aggregation and hyperedge information broadcasting. During the hyperedge information aggregation stage, we optimize the acquisition of hyperedge information using attention mechanisms. In the hyperedge information broadcasting stage, we leverage a directed hypergraph momentum encoder to capture the directional information of directed hyperedges. Experimental results on five publicly available directed graph datasets of three different categories demonstrate that our proposed DHMConv outperforms various commonly used graph and hypergraph models.",
        "bibtex": "@InProceedings{pmlr-v238-zhao24c,\n  title = \t {{DHMConv}: Directed Hypergraph Momentum Convolution Framework},\n  author =       {Zhao, Wenbo and Ma, Zitong and Yang, Zhe},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3385--3393},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhao24c/zhao24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhao24c.html},\n  abstract = \t {Due to its capability to capture high-order information, the hypergraph model has shown greater potential than the graph model in various scenarios. Real-world entity relations frequently involve directionality, in order to express high-order information while capturing directional information in relationships, we present a directed hypergraph spatial convolution framework that is designed to acquire vertex embeddings of directed hypergraphs. The framework characterizes the information propagation of directed hypergraphs through two stages: hyperedge information aggregation and hyperedge information broadcasting. During the hyperedge information aggregation stage, we optimize the acquisition of hyperedge information using attention mechanisms. In the hyperedge information broadcasting stage, we leverage a directed hypergraph momentum encoder to capture the directional information of directed hyperedges. Experimental results on five publicly available directed graph datasets of three different categories demonstrate that our proposed DHMConv outperforms various commonly used graph and hypergraph models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhao24c/zhao24c.pdf",
        "supp": "",
        "pdf_size": 4591533,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5885236773850449294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Soochow University; Soochow University; Soochow University",
        "aff_domain": "stu.suda.edu.cn;stu.suda.edu.cn;suda.edu.cn",
        "email": "stu.suda.edu.cn;stu.suda.edu.cn;suda.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Soochow University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.soochow.edu.cn",
        "aff_unique_abbr": "Soochow U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "b5aa99eb5b",
        "title": "DNNLasso: Scalable Graph Learning for Matrix-Variate Data",
        "site": "https://proceedings.mlr.press/v238/lin24b.html",
        "author": "Meixia Lin; Yangjing Zhang",
        "abstract": "We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time.",
        "bibtex": "@InProceedings{pmlr-v238-lin24b,\n  title = \t {{DNNLasso}: Scalable Graph Learning for Matrix-Variate Data},\n  author =       {Lin, Meixia and Zhang, Yangjing},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {316--324},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lin24b/lin24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lin24b.html},\n  abstract = \t {We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lin24b/lin24b.pdf",
        "supp": "",
        "pdf_size": 3918481,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:laJcRU7vXvoJ:scholar.google.com/&scioq=DNNLasso:+Scalable+Graph+Learning+for+Matrix-Variate+Data&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "aff": "Singapore University of Technology and Design; Chinese Academy of Sciences",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/YangjingZhang/DNNLasso",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Singapore University of Technology and Design;Chinese Academy of Sciences",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sutd.edu.sg;https://www.cas.cn",
        "aff_unique_abbr": "SUTD;CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "065de2df70",
        "title": "Data Driven Threshold and Potential Initialization for Spiking Neural Networks",
        "site": "https://proceedings.mlr.press/v238/bojkovic24a.html",
        "author": "Velibor Bojkovic; Srinivas Anumasa; Giulia De Masi; Bin Gu; Huan Xiong",
        "abstract": "Spiking neural networks (SNNs) present an increasingly popular alternative to artificial neural networks (ANNs), due to their energy and time efficiency when deployed on neuromorphic hardware. However, due to their discrete and highly non-differentiable nature, training SNNs is a challenging task and remains an active area of research. Some of the most prominent ways to train SNNs are based on ANN-to-SNN conversion where an SNN model is initialized with parameters from the corresponding, pre-trained ANN model. SNN models trained through ANN-to-SNN conversion or hybrid training show state of the art performance among SNNs on many machine learning tasks, comparable to those of ANNs. However, the top performing models need high latency or tailored ANNs to perform well, and in general are not using the full information available from ANNs. In this work, we propose novel method to initialize SNN\u2019s thresholds and initial membrane potential after ANN-to-SNN conversion, using distributions of ANN\u2019s activation values. We provide a theoretical framework for feature distribution-based conversion error, providing theoretical results on optimal membrane initialization and thresholds which minimize this error, as well as a practical algorithm for finding these optimal values. We test our method, both as a stand-alone ANN-to-SNN conversion and in combination with other methods, and show state of the art results on high-dimensional datasets such as CIFAR10, CIFAR100 and ImageNet and various architectures. Our code is available at \\url{https://github.com/srinuvaasu/data_driven_init}",
        "bibtex": "@InProceedings{pmlr-v238-bojkovic24a,\n  title = \t {Data Driven Threshold and Potential Initialization for Spiking Neural Networks},\n  author =       {Bojkovic, Velibor and Anumasa, Srinivas and De Masi, Giulia and Gu, Bin and Xiong, Huan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4771--4779},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bojkovic24a/bojkovic24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bojkovic24a.html},\n  abstract = \t {Spiking neural networks (SNNs) present an increasingly popular alternative to artificial neural networks (ANNs), due to their energy and time efficiency when deployed on neuromorphic hardware. However, due to their discrete and highly non-differentiable nature, training SNNs is a challenging task and remains an active area of research. Some of the most prominent ways to train SNNs are based on ANN-to-SNN conversion where an SNN model is initialized with parameters from the corresponding, pre-trained ANN model. SNN models trained through ANN-to-SNN conversion or hybrid training show state of the art performance among SNNs on many machine learning tasks, comparable to those of ANNs. However, the top performing models need high latency or tailored ANNs to perform well, and in general are not using the full information available from ANNs. In this work, we propose novel method to initialize SNN\u2019s thresholds and initial membrane potential after ANN-to-SNN conversion, using distributions of ANN\u2019s activation values. We provide a theoretical framework for feature distribution-based conversion error, providing theoretical results on optimal membrane initialization and thresholds which minimize this error, as well as a practical algorithm for finding these optimal values. We test our method, both as a stand-alone ANN-to-SNN conversion and in combination with other methods, and show state of the art results on high-dimensional datasets such as CIFAR10, CIFAR100 and ImageNet and various architectures. Our code is available at \\url{https://github.com/srinuvaasu/data_driven_init}}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bojkovic24a/bojkovic24a.pdf",
        "supp": "",
        "pdf_size": 1245116,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7400346267794124807&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Mohamed bin Zayed University of Artificial Intelligence, UAE; Mohamed bin Zayed University of Artificial Intelligence, UAE; ARRC, Technology Innovation Institute, UAE+BioRobotics Institute, Sant\u2019Anna School of Advanced Studies Pisa, Italy; School of Artificial Intelligence, Jilin University, China+Mohamed bin Zayed University of Artificial Intelligence, UAE; Harbin Institute of Technology, China+Mohamed bin Zayed University of Artificial Intelligence, UAE",
        "aff_domain": "gmail.com;gmail.com; ; ; ",
        "email": "gmail.com;gmail.com; ; ; ",
        "github": "https://github.com/srinuvaasu/data_driven_init",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;3+0;4+0",
        "aff_unique_norm": "Mohamed bin Zayed University of Artificial Intelligence;Technology Innovation Institute;Sant\u2019Anna School of Advanced Studies;Jilin University;Harbin Institute of Technology",
        "aff_unique_dep": ";;BioRobotics Institute;School of Artificial Intelligence;",
        "aff_unique_url": "https://mbzuai.ac.ae;;https://www.sssup.it;http://www.jlu.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "MBZUAI;;SSSUP;JLU;HIT",
        "aff_campus_unique_index": "1;;",
        "aff_campus_unique": ";Pisa",
        "aff_country_unique_index": "0;0;0+1;2+0;2+0",
        "aff_country_unique": "United Arab Emirates;Italy;China"
    },
    {
        "id": "e1031ddc38",
        "title": "Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations",
        "site": "https://proceedings.mlr.press/v238/wu24b.html",
        "author": "Mohan Wu; Martin Lysy",
        "abstract": "Estimating the parameters of ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODEs are typically approximated with deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local maxima in the likelihood function \u2013 a problem which existing probabilistic solvers have yet to resolve. Here we present a novel probabilistic ODE likelihood approximation, DALTON, which can dramatically reduce parameter sensitivity by learning from noisy ODE measurements in a data-adaptive manner. Our approximation scales linearly in both ODE variables and time discretization points, and is applicable to ODEs with both partially-unobserved components and non-Gaussian measurement models. Several examples demonstrate that DALTON produces more accurate parameter estimates via numerical optimization than existing probabilistic ODE solvers, and even in some cases than the exact ODE likelihood itself.",
        "bibtex": "@InProceedings{pmlr-v238-wu24b,\n  title = \t {Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations},\n  author =       {Wu, Mohan and Lysy, Martin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1018--1026},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24b/wu24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24b.html},\n  abstract = \t {Estimating the parameters of ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODEs are typically approximated with deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local maxima in the likelihood function \u2013 a problem which existing probabilistic solvers have yet to resolve. Here we present a novel probabilistic ODE likelihood approximation, DALTON, which can dramatically reduce parameter sensitivity by learning from noisy ODE measurements in a data-adaptive manner. Our approximation scales linearly in both ODE variables and time discretization points, and is applicable to ODEs with both partially-unobserved components and non-Gaussian measurement models. Several examples demonstrate that DALTON produces more accurate parameter estimates via numerical optimization than existing probabilistic ODE solvers, and even in some cases than the exact ODE likelihood itself.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24b/wu24b.pdf",
        "supp": "",
        "pdf_size": 1669175,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13989457855771148189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Waterloo; University of Waterloo",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "15c01abe42",
        "title": "Data-Driven Confidence Intervals with Optimal Rates for the Mean of Heavy-Tailed Distributions",
        "site": "https://proceedings.mlr.press/v238/tamas24a.html",
        "author": "Ambrus Tam\u00e1s; Szabolcs Szentp\u00e9teri; Bal\u00e1zs Cs\u00e1ji",
        "abstract": "Estimating the expected value is one of the key problems of statistics, and it serves as a backbone for countless methods in machine learning. In this paper we propose a new algorithm to build non-asymptotically exact confidence intervals for the mean of a symmetric distribution based on an independent, identically distributed sample. The method combines resampling with median-of-means estimates to ensure optimal subgaussian bounds for the sizes of the confidence intervals under mild, heavy-tailed moment conditions. The scheme is completely data-driven: the construction does not need any information about the moments, yet it manages to build exact confidence regions which shrink at the optimal rate. We also show how to generalize the approach to higher dimensions and prove dimension-free, subgaussian PAC bounds for the exclusion probabilities of false candidates. Finally, we illustrate the method and its properties for heavy-tailed distributions with numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-tamas24a,\n  title = \t {Data-Driven Confidence Intervals with Optimal Rates for the Mean of Heavy-Tailed Distributions},\n  author =       {Tam\\'{a}s, Ambrus and Szentp\\'{e}teri, Szabolcs and Cs\\'{a}ji, Bal\\'{a}zs},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3439--3447},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tamas24a/tamas24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tamas24a.html},\n  abstract = \t {Estimating the expected value is one of the key problems of statistics, and it serves as a backbone for countless methods in machine learning. In this paper we propose a new algorithm to build non-asymptotically exact confidence intervals for the mean of a symmetric distribution based on an independent, identically distributed sample. The method combines resampling with median-of-means estimates to ensure optimal subgaussian bounds for the sizes of the confidence intervals under mild, heavy-tailed moment conditions. The scheme is completely data-driven: the construction does not need any information about the moments, yet it manages to build exact confidence regions which shrink at the optimal rate. We also show how to generalize the approach to higher dimensions and prove dimension-free, subgaussian PAC bounds for the exclusion probabilities of false candidates. Finally, we illustrate the method and its properties for heavy-tailed distributions with numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tamas24a/tamas24a.pdf",
        "supp": "",
        "pdf_size": 808140,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13902671324176044178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "795a198c43",
        "title": "Data-Driven Online Model Selection With Regret Guarantees",
        "site": "https://proceedings.mlr.press/v238/dann24a.html",
        "author": "Chris Dann; Claudio Gentile; Aldo Pacchiano",
        "abstract": "We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the *realized* regret incurred by each base learner for the learning environment at hand (as opposed to the *expected* regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets instead of candidate regret bounds.",
        "bibtex": "@InProceedings{pmlr-v238-dann24a,\n  title = \t {Data-Driven Online Model Selection With Regret Guarantees},\n  author =       {Dann, Chris and Gentile, Claudio and Pacchiano, Aldo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1531--1539},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dann24a/dann24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dann24a.html},\n  abstract = \t {We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the *realized* regret incurred by each base learner for the learning environment at hand (as opposed to the *expected* regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets instead of candidate regret bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dann24a/dann24a.pdf",
        "supp": "",
        "pdf_size": 2947572,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17664636521872930665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Boston University; Broad Institute of MIT and Harvard; Google Research + Google Research",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+2",
        "aff_unique_norm": "Boston University;Broad Institute;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://www.bu.edu;https://www.broadinstitute.org;https://research.google",
        "aff_unique_abbr": "BU;Broad;Google Research",
        "aff_campus_unique_index": "1+1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3ace55c226",
        "title": "Data-Efficient Contrastive Language-Image Pretraining: Prioritizing Data Quality over Quantity",
        "site": "https://proceedings.mlr.press/v238/joshi24a.html",
        "author": "Siddharth Joshi; Arnav Jain; Ali Payani; Baharan Mirzasoleiman",
        "abstract": "Contrastive Language-Image Pre-training (CLIP) on large-scale image-caption datasets learns representations that can achieve remarkable zero-shot generalization. However, such models require a massive amount of pre-training data. Improving the quality of the pre-training data has been shown to be much more effective in improving CLIP\u2019s performance than increasing its volume. Nevertheless, finding small subsets of training data that provably generalize best has remained an open question. In this work, we propose the first theoretically rigorous data selection method for CLIP. We show that subsets that closely preserve the cross-covariance of the images and captions of the full data provably achieve a superior generalization performance.Our extensive experiments on ConceptualCaptions3M and ConceptualCaptions12M demonstrate that subsets found by \\textsc{ClipCov} achieve over 2.7x and 1.4x the accuracy of the next best baseline on ImageNet and its shifted versions. Moreover, we show that our subsets obtain 1.5x the average accuracy across 11 downstream datasets, of the next best baseline. The code is available at: \\url{https://github.com/BigML-CS-UCLA/clipcov-data-efficient-clip}.",
        "bibtex": "@InProceedings{pmlr-v238-joshi24a,\n  title = \t {Data-Efficient Contrastive Language-Image Pretraining: Prioritizing Data Quality over Quantity},\n  author =       {Joshi, Siddharth and Jain, Arnav and Payani, Ali and Mirzasoleiman, Baharan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1000--1008},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/joshi24a/joshi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/joshi24a.html},\n  abstract = \t {Contrastive Language-Image Pre-training (CLIP) on large-scale image-caption datasets learns representations that can achieve remarkable zero-shot generalization. However, such models require a massive amount of pre-training data. Improving the quality of the pre-training data has been shown to be much more effective in improving CLIP\u2019s performance than increasing its volume. Nevertheless, finding small subsets of training data that provably generalize best has remained an open question. In this work, we propose the first theoretically rigorous data selection method for CLIP. We show that subsets that closely preserve the cross-covariance of the images and captions of the full data provably achieve a superior generalization performance.Our extensive experiments on ConceptualCaptions3M and ConceptualCaptions12M demonstrate that subsets found by \\textsc{ClipCov} achieve over 2.7x and 1.4x the accuracy of the next best baseline on ImageNet and its shifted versions. Moreover, we show that our subsets obtain 1.5x the average accuracy across 11 downstream datasets, of the next best baseline. The code is available at: \\url{https://github.com/BigML-CS-UCLA/clipcov-data-efficient-clip}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/joshi24a/joshi24a.pdf",
        "supp": "",
        "pdf_size": 475742,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13101549415791181113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "UCLA CS; UCLA CS; Cisco Systems Inc.; UCLA CS",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/BigML-CS-UCLA/clipcov-data-efficient-clip",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Cisco Systems",
        "aff_unique_dep": "Computer Science;",
        "aff_unique_url": "https://www.ucla.edu;https://www.cisco.com",
        "aff_unique_abbr": "UCLA;Cisco",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e1a3423c85",
        "title": "Decentralized Multi-Level Compositional Optimization Algorithms with Level-Independent Convergence Rate",
        "site": "https://proceedings.mlr.press/v238/gao24b.html",
        "author": "Hongchang Gao",
        "abstract": "Stochastic multi-level compositional optimization problems cover many new machine learning paradigms, e.g., multi-step model-agnostic meta-learning, which require efficient optimization algorithms for large-scale data. This paper studies the decentralized stochastic multi-level optimization algorithm, which is challenging because the multi-level structure and decentralized communication scheme may make the number of levels significantly affect the order of the convergence rate. To this end, we develop two novel decentralized optimization algorithms to optimize the multi-level compositional optimization problem. Our theoretical results show that both algorithms can achieve the level-independent convergence rate for nonconvex problems under much milder conditions compared with existing single-machine algorithms. To the best of our knowledge, this is the first work that achieves the level-independent convergence rate under the decentralized setting. Moreover, extensive experiments confirm the efficacy of our proposed algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-gao24b,\n  title = \t {Decentralized Multi-Level Compositional Optimization Algorithms with Level-Independent Convergence Rate},\n  author =       {Gao, Hongchang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4402--4410},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gao24b/gao24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gao24b.html},\n  abstract = \t {Stochastic multi-level compositional optimization problems cover many new machine learning paradigms, e.g., multi-step model-agnostic meta-learning, which require efficient optimization algorithms for large-scale data. This paper studies the decentralized stochastic multi-level optimization algorithm, which is challenging because the multi-level structure and decentralized communication scheme may make the number of levels significantly affect the order of the convergence rate. To this end, we develop two novel decentralized optimization algorithms to optimize the multi-level compositional optimization problem. Our theoretical results show that both algorithms can achieve the level-independent convergence rate for nonconvex problems under much milder conditions compared with existing single-machine algorithms. To the best of our knowledge, this is the first work that achieves the level-independent convergence rate under the decentralized setting. Moreover, extensive experiments confirm the efficacy of our proposed algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gao24b/gao24b.pdf",
        "supp": "",
        "pdf_size": 533324,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11640962976482201531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Temple University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Temple University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.temple.edu",
        "aff_unique_abbr": "Temple",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fd919ab35e",
        "title": "Deep Classifier Mimicry without Data Access",
        "site": "https://proceedings.mlr.press/v238/braun24b.html",
        "author": "Steven Braun; Martin Mundt; Kristian Kersting",
        "abstract": "Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model\u2019s decision boundary. We empirically corroborate CAKE\u2019s effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.",
        "bibtex": "@InProceedings{pmlr-v238-braun24b,\n  title = \t {Deep Classifier Mimicry without Data Access},\n  author =       {Braun, Steven and Mundt, Martin and Kersting, Kristian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4762--4770},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/braun24b/braun24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/braun24b.html},\n  abstract = \t {Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model\u2019s decision boundary. We empirically corroborate CAKE\u2019s effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/braun24b/braun24b.pdf",
        "supp": "",
        "pdf_size": 1045892,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16966320885925489343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, TU Darmstadt, Darmstadt, Germany + Hessian Center for AI (hessian.AI), Darmstadt, Germany + German Research Center for Artificial Intelligence (DFKI), Darmstadt, Germany + Centre for Cognitive Science, TU Darmstadt, Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Darmstadt, Germany + Hessian Center for AI (hessian.AI), Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Darmstadt, Germany + Hessian Center for AI (hessian.AI), Darmstadt, Germany + German Research Center for Artificial Intelligence (DFKI), Darmstadt, Germany + Centre for Cognitive Science, TU Darmstadt, Darmstadt, Germany",
        "aff_domain": "cs.tu-darmstadt.de;cs.tu-darmstadt.de;cs.tu-darmstadt.de",
        "email": "cs.tu-darmstadt.de;cs.tu-darmstadt.de;cs.tu-darmstadt.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2+3;0+1;0+1+2+3",
        "aff_unique_norm": "TU Darmstadt;Hessian Center for AI;German Research Center for Artificial Intelligence;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Computer Science;AI Research;;Centre for Cognitive Science",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://hessian.ai;https://www.dFKI.de;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD;hessian.AI;DFKI;TU Darmstadt",
        "aff_campus_unique_index": "0+0+0+0;0+0;0+0+0+0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0+0+0+0;0+0;0+0+0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "bacaaf6b72",
        "title": "Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification",
        "site": "https://proceedings.mlr.press/v238/arya24a.html",
        "author": "Shivvrat Arya; Yu Xiang; Vibhav Gogate",
        "abstract": "We present a unified framework called deep dependency networks (DDNs) that combines dependency networks and deep learning architectures for multi-label classification, with a particular emphasis on image and video data. The primary advantage of dependency networks is their ease of training, in contrast to other probabilistic graphical models like Markov networks. In particular, when combined with deep learning architectures, they provide an intuitive, easy-to-use loss function for multi-label classification. A drawback of DDNs compared to Markov networks is their lack of advanced inference schemes, necessitating the use of Gibbs sampling. To address this challenge, we propose novel inference schemes based on local search and integer linear programming for computing the most likely assignment to the labels given observations. We evaluate our novel methods on three video datasets (Charades, TACoS, Wetlab) and three image datasets (MS-COCO, PASCAL VOC, NUS-WIDE), comparing their performance with (a) basic neural architectures and (b) neural architectures combined with Markov networks equipped with advanced inference and learning techniques. Our results demonstrate the superiority of our new DDN methods over the two competing approaches.",
        "bibtex": "@InProceedings{pmlr-v238-arya24a,\n  title = \t {Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification},\n  author =       {Arya, Shivvrat and Xiang, Yu and Gogate, Vibhav},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2818--2826},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/arya24a/arya24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/arya24a.html},\n  abstract = \t {We present a unified framework called deep dependency networks (DDNs) that combines dependency networks and deep learning architectures for multi-label classification, with a particular emphasis on image and video data. The primary advantage of dependency networks is their ease of training, in contrast to other probabilistic graphical models like Markov networks. In particular, when combined with deep learning architectures, they provide an intuitive, easy-to-use loss function for multi-label classification. A drawback of DDNs compared to Markov networks is their lack of advanced inference schemes, necessitating the use of Gibbs sampling. To address this challenge, we propose novel inference schemes based on local search and integer linear programming for computing the most likely assignment to the labels given observations. We evaluate our novel methods on three video datasets (Charades, TACoS, Wetlab) and three image datasets (MS-COCO, PASCAL VOC, NUS-WIDE), comparing their performance with (a) basic neural architectures and (b) neural architectures combined with Markov networks equipped with advanced inference and learning techniques. Our results demonstrate the superiority of our new DDN methods over the two competing approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/arya24a/arya24a.pdf",
        "supp": "",
        "pdf_size": 4555413,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18286041309084489261&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e71b598875",
        "title": "Deep Learning-Based Alternative Route Computation",
        "site": "https://proceedings.mlr.press/v238/zhai24b.html",
        "author": "Alex Zhai; Dee Guo; Sreenivas Gollapudi; Kostas Kollias; Daniel Delling",
        "abstract": "Algorithms for the computation of alternative routes in road networks power many geographic navigation systems. A good set of alternative routes offers meaningful options to the user of the system and can support applications such as routing that is robust to failures (e.g., road closures, extreme traffic congestion, etc.) and routing with diverse preferences and objective functions. Algorithmic techniques for alternative route computation include the penalty method, via-node type algorithms (which deploy bidirectional search and finding plateaus), and, more recently, electrical-circuit based algorithms. In this work we focus on the practically important family of via-node type algorithms and aim to produce high quality alternative routes for road networks using a novel deep learning-based approach that learns a representation of the underlying road network. We show that this approach can support natural objectives, such as the uniformly bounded stretch, that are difficult and computationally expensive to support through traditional algorithmic techniques. Moreover, we achieve this in a practical system based on the Customizable Route Planning (CRP) hierarchical routing architecture. Our training methodology uses the hierarchical partition of the graph and trains a model to predict which boundary nodes in the partition should be crossed by the alternative routes. We describe our methods in detail and evaluate them against previously studied baselines, showing quality improvements in the road networks of Seattle, Paris, and Bangalore.",
        "bibtex": "@InProceedings{pmlr-v238-zhai24b,\n  title = \t {Deep Learning-Based Alternative Route Computation},\n  author =       {Zhai, Alex and Guo, Dee and Gollapudi, Sreenivas and Kollias, Kostas and Delling, Daniel},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4078--4086},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhai24b/zhai24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhai24b.html},\n  abstract = \t {Algorithms for the computation of alternative routes in road networks power many geographic navigation systems. A good set of alternative routes offers meaningful options to the user of the system and can support applications such as routing that is robust to failures (e.g., road closures, extreme traffic congestion, etc.) and routing with diverse preferences and objective functions. Algorithmic techniques for alternative route computation include the penalty method, via-node type algorithms (which deploy bidirectional search and finding plateaus), and, more recently, electrical-circuit based algorithms. In this work we focus on the practically important family of via-node type algorithms and aim to produce high quality alternative routes for road networks using a novel deep learning-based approach that learns a representation of the underlying road network. We show that this approach can support natural objectives, such as the uniformly bounded stretch, that are difficult and computationally expensive to support through traditional algorithmic techniques. Moreover, we achieve this in a practical system based on the Customizable Route Planning (CRP) hierarchical routing architecture. Our training methodology uses the hierarchical partition of the graph and trains a model to predict which boundary nodes in the partition should be crossed by the alternative routes. We describe our methods in detail and evaluate them against previously studied baselines, showing quality improvements in the road networks of Seattle, Paris, and Bangalore.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhai24b/zhai24b.pdf",
        "supp": "",
        "pdf_size": 1703566,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:yWwKtvzn2ZsJ:scholar.google.com/&scioq=Deep+Learning-Based+Alternative+Route+Computation&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": "Google; Google; Google; Google; Google",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "43260ff890",
        "title": "Deep anytime-valid hypothesis testing",
        "site": "https://proceedings.mlr.press/v238/pandeva24a.html",
        "author": "Teodora Pandeva; Patrick Forr\u00e9; Aaditya Ramdas; Shubhanshu Shekhar",
        "abstract": "We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models within the testing-by-betting framework, a game-theoretic approach for designing sequential tests. Empirical results on synthetic and real-world datasets demonstrate that tests instantiated using our general framework are competitive against specialized baselines on several tasks.",
        "bibtex": "@InProceedings{pmlr-v238-pandeva24a,\n  title = \t {Deep anytime-valid hypothesis testing},\n  author =       {Pandeva, Teodora and Forr\\'{e}, Patrick and Ramdas, Aaditya and Shekhar, Shubhanshu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {622--630},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pandeva24a/pandeva24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pandeva24a.html},\n  abstract = \t {We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models within the testing-by-betting framework, a game-theoretic approach for designing sequential tests. Empirical results on synthetic and real-world datasets demonstrate that tests instantiated using our general framework are competitive against specialized baselines on several tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pandeva24a/pandeva24a.pdf",
        "supp": "",
        "pdf_size": 1419877,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16565002100042091968&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cd0dc8fb42",
        "title": "DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data",
        "site": "https://proceedings.mlr.press/v238/kim24b.html",
        "author": "Taehyo Kim; Hai Shu; Qiran Jia; Mony de Leon",
        "abstract": "Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer\u2019s disease FDG-PET image analysis, demonstrate DeepFDR\u2019s superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but also boasts exceptional computational efficiency highly suited for tackling large-scale neuroimaging data.",
        "bibtex": "@InProceedings{pmlr-v238-kim24b,\n  title = \t {{DeepFDR}: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data},\n  author =       {Kim, Taehyo and Shu, Hai and Jia, Qiran and de Leon, Mony},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {946--954},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kim24b/kim24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kim24b.html},\n  abstract = \t {Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer\u2019s disease FDG-PET image analysis, demonstrate DeepFDR\u2019s superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but also boasts exceptional computational efficiency highly suited for tackling large-scale neuroimaging data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kim24b/kim24b.pdf",
        "supp": "",
        "pdf_size": 7961126,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6648081204377774259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Biostatistics, School of Global Public Health, New York University + Department of Population and Public Health Sciences, University of Southern California; Department of Biostatistics, School of Global Public Health, New York University + Brain Health Imaging Institute, Department of Radiology, Weill Cornell Medicine; Department of Population and Public Health Sciences, University of Southern California; Brain Health Imaging Institute, Department of Radiology, Weill Cornell Medicine",
        "aff_domain": "nyu.edu;nyu.edu; ; ",
        "email": "nyu.edu;nyu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+2;1;2",
        "aff_unique_norm": "New York University;University of Southern California;Weill Cornell Medicine",
        "aff_unique_dep": "Department of Biostatistics;Department of Population and Public Health Sciences;Department of Radiology",
        "aff_unique_url": "https://www.nyu.edu;https://www.usc.edu;https://weill.cornell.edu",
        "aff_unique_abbr": "NYU;USC;Weill Cornell",
        "aff_campus_unique_index": "0+1;0;1",
        "aff_campus_unique": "New York;Los Angeles;",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6553d26b2e",
        "title": "Delegating Data Collection in Decentralized Machine Learning",
        "site": "https://proceedings.mlr.press/v238/ananthakrishnan24a.html",
        "author": "Nivasini Ananthakrishnan; Stephen Bates; Michael Jordan; Nika Haghtalab",
        "abstract": "Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve $1-1/\\epsilon$ fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also analyze the optimal utility and linear contracts for the more complex setting of multiple interactions.",
        "bibtex": "@InProceedings{pmlr-v238-ananthakrishnan24a,\n  title = \t {Delegating Data Collection in Decentralized Machine Learning},\n  author =       {Ananthakrishnan, Nivasini and Bates, Stephen and Jordan, Michael and Haghtalab, Nika},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {478--486},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ananthakrishnan24a/ananthakrishnan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ananthakrishnan24a.html},\n  abstract = \t {Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve $1-1/\\epsilon$ fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also analyze the optimal utility and linear contracts for the more complex setting of multiple interactions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ananthakrishnan24a/ananthakrishnan24a.pdf",
        "supp": "",
        "pdf_size": 648409,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12844516853220748731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "12e0670611",
        "title": "Density Uncertainty Layers for Reliable Uncertainty Estimation",
        "site": "https://proceedings.mlr.press/v238/park24a.html",
        "author": "Yookoon Park; David Blei",
        "abstract": "Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the common approaches that approximate the parameter posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper, we propose a novel criterion for reliable predictive uncertainty: a model\u2019s predictive variance should be grounded in the empirical density of the input. That is, the model should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, a stochastic neural network architecture that satisfies the density uncertain criterion by design. We study density uncertainty layers on the UCI and CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density uncertainty layers provide more reliable uncertainty estimates and robust out-of-distribution detection performance.",
        "bibtex": "@InProceedings{pmlr-v238-park24a,\n  title = \t {Density Uncertainty Layers for Reliable Uncertainty Estimation},\n  author =       {Park, Yookoon and Blei, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {163--171},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/park24a/park24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/park24a.html},\n  abstract = \t {Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the common approaches that approximate the parameter posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper, we propose a novel criterion for reliable predictive uncertainty: a model\u2019s predictive variance should be grounded in the empirical density of the input. That is, the model should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, a stochastic neural network architecture that satisfies the density uncertain criterion by design. We study density uncertainty layers on the UCI and CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density uncertainty layers provide more reliable uncertainty estimates and robust out-of-distribution detection performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/park24a/park24a.pdf",
        "supp": "",
        "pdf_size": 557578,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8150343132746303525&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Columbia University, New York, NY 10027, USA; Department of Computer Science, Statistics, Columbia University, New York, NY 10027, USA",
        "aff_domain": "columbia.edu;columbia.edu",
        "email": "columbia.edu;columbia.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6341c4a4ed",
        "title": "Density-Regression: Efficient and Distance-aware Deep Regressor for Uncertainty Estimation under Distribution Shifts",
        "site": "https://proceedings.mlr.press/v238/manh-bui24a.html",
        "author": "Ha Manh Bui; Anqi Liu",
        "abstract": "Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower model size and a faster inference speed.",
        "bibtex": "@InProceedings{pmlr-v238-manh-bui24a,\n  title = \t {Density-Regression: Efficient and Distance-aware Deep Regressor for Uncertainty Estimation under Distribution Shifts},\n  author =       {Manh Bui, Ha and Liu, Anqi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2998--3006},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/manh-bui24a/manh-bui24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/manh-bui24a.html},\n  abstract = \t {Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower model size and a faster inference speed.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/manh-bui24a/manh-bui24a.pdf",
        "supp": "",
        "pdf_size": 3720443,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18288634206521382438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bdaab9990b",
        "title": "Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models via Reparameterisation and Smoothing",
        "site": "https://proceedings.mlr.press/v238/wagner24a.html",
        "author": "Dominik Wagner; Basim Khajwal; Luke Ong",
        "abstract": "It is well-known that the reparameterisation gradient estimator, which exhibits low variance in practice, is biased for non-differentiable models. This may compromise correctness of gradient-based optimisation methods such as stochastic gradient descent (SGD). We introduce a simple syntactic framework to define non-differentiable functions piecewisely and present a systematic approach to obtain smoothings for which the reparameterisation gradient estimator is unbiased. Our main contribution is a novel variant of SGD, Diagonalisation Stochastic Gradient Descent, which progressively enhances the accuracy of the smoothed approximation during optimisation, and we prove convergence to stationary points of the unsmoothed (original) objective. Our empirical evaluation reveals benefits over the state of the art: our approach is simple, fast, stable and attains orders of magnitude reduction in work-normalised variance.",
        "bibtex": "@InProceedings{pmlr-v238-wagner24a,\n  title = \t {Diagonalisation {SGD}: Fast & Convergent {SGD} for Non-Differentiable Models via Reparameterisation and Smoothing},\n  author =       {Wagner, Dominik and Khajwal, Basim and Ong, Luke},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1801--1809},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wagner24a/wagner24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wagner24a.html},\n  abstract = \t {It is well-known that the reparameterisation gradient estimator, which exhibits low variance in practice, is biased for non-differentiable models. This may compromise correctness of gradient-based optimisation methods such as stochastic gradient descent (SGD). We introduce a simple syntactic framework to define non-differentiable functions piecewisely and present a systematic approach to obtain smoothings for which the reparameterisation gradient estimator is unbiased. Our main contribution is a novel variant of SGD, Diagonalisation Stochastic Gradient Descent, which progressively enhances the accuracy of the smoothed approximation during optimisation, and we prove convergence to stationary points of the unsmoothed (original) objective. Our empirical evaluation reveals benefits over the state of the art: our approach is simple, fast, stable and attains orders of magnitude reduction in work-normalised variance.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wagner24a/wagner24a.pdf",
        "supp": "",
        "pdf_size": 625643,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8157706633540831903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "NTU Singapore; Jane Street; NTU Singapore",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Jane Street",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.janestreet.com",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "6e84f97d38",
        "title": "DiffRed: Dimensionality reduction guided by stable rank",
        "site": "https://proceedings.mlr.press/v238/shukla24a.html",
        "author": "Prarabdh Shukla; Gagan Raj Gupta; Kunal Dutta",
        "abstract": "In this work, we propose a novel dimensionality reduction technique, \\textit{DiffRed}, which first projects the data matrix, A, along first $k_1$ principal components and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank approximation) along $k_2$ Gaussian random vectors. We evaluate \\emph{M1}, the distortion of mean-squared pair-wise distance, and \\emph{Stress}, the normalized value of RMS of distortion of the pairwise distances. We rigorously prove that \\textit{DiffRed} achieves a general upper bound of $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ on \\emph{Stress} and $O\\left(\\frac{1-p}{\\sqrt{k_2*\\rho(A^{*})}}\\right)$ on \\emph{M1} where $p$ is the fraction of variance explained by the first $k_1$ principal components and $\\rho(A^{*})$ is the \\textit{stable rank} of $A^{*}$. These bounds are tighter than the currently known results for Random maps. Our extensive experiments on a variety of real-world datasets demonstrate that \\textit{DiffRed} achieves near zero \\emph{M1} and much lower values of \\emph{Stress} as compared to the well-known dimensionality reduction techniques. In particular, \\textit{DiffRed} can map a 6 million dimensional dataset to 10 dimensions with 54% lower \\emph{Stress} than PCA.",
        "bibtex": "@InProceedings{pmlr-v238-shukla24a,\n  title = \t {{D}iff{R}ed: Dimensionality reduction guided by stable rank},\n  author =       {Shukla, Prarabdh and Raj Gupta, Gagan and Dutta, Kunal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3430--3438},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shukla24a/shukla24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shukla24a.html},\n  abstract = \t {In this work, we propose a novel dimensionality reduction technique, \\textit{DiffRed}, which first projects the data matrix, A, along first $k_1$ principal components and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank approximation) along $k_2$ Gaussian random vectors. We evaluate \\emph{M1}, the distortion of mean-squared pair-wise distance, and \\emph{Stress}, the normalized value of RMS of distortion of the pairwise distances. We rigorously prove that \\textit{DiffRed} achieves a general upper bound of $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ on \\emph{Stress} and $O\\left(\\frac{1-p}{\\sqrt{k_2*\\rho(A^{*})}}\\right)$ on \\emph{M1} where $p$ is the fraction of variance explained by the first $k_1$ principal components and $\\rho(A^{*})$ is the \\textit{stable rank} of $A^{*}$. These bounds are tighter than the currently known results for Random maps. Our extensive experiments on a variety of real-world datasets demonstrate that \\textit{DiffRed} achieves near zero \\emph{M1} and much lower values of \\emph{Stress} as compared to the well-known dimensionality reduction techniques. In particular, \\textit{DiffRed} can map a 6 million dimensional dataset to 10 dimensions with 54% lower \\emph{Stress} than PCA.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shukla24a/shukla24a.pdf",
        "supp": "",
        "pdf_size": 1137413,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17826197186147713345&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of CSE, Indian Institute of Technology, Bhilai, Bhilai, India; Department of CSE, Indian Institute of Technology, Bhilai, Bhilai, India; Institute of Informatics, University of Warsaw, Warsaw, Poland",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Indian Institute of Technology Bhilai;University of Warsaw",
        "aff_unique_dep": "Department of CSE;Institute of Informatics",
        "aff_unique_url": "https://www.iitbhilai.ac.in;https://www.uw.edu.pl",
        "aff_unique_abbr": "IIT Bhilai;UW",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Bhilai;Warsaw",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "India;Poland"
    },
    {
        "id": "3e8d26fd35",
        "title": "Differentiable Rendering with Reparameterized Volume Sampling",
        "site": "https://proceedings.mlr.press/v238/morozov24a.html",
        "author": "Nikita Morozov; Denis Rakitin; Oleg Desheulin; Dmitry P Vetrov; Kirill Struminsky",
        "abstract": "In view synthesis, a neural radiance field approximates underlying density and radiance fields based on a sparse set of scene pictures. To generate a pixel of a novel view, it marches a ray through the pixel and computes a weighted sum of radiance emitted from a dense set of ray points. This rendering algorithm is fully differentiable and facilitates gradient-based optimization of the fields. However, in practice, only a tiny opaque portion of the ray contributes most of the radiance to the sum. We propose a simple end-to-end differentiable sampling algorithm based on inverse transform sampling. It generates samples according to the probability distribution induced by the density field and picks non-transparent points on the ray. We utilize the algorithm in two ways. First, we propose a novel rendering approach based on Monte Carlo estimates. This approach allows for evaluating and optimizing a neural radiance field with just a few radiance field calls per ray. Second, we use the sampling algorithm to modify the hierarchical scheme proposed in the original NeRF work. We show that our modification improves reconstruction quality of hierarchical models, at the same time simplifying the training procedure by removing the need for auxiliary proposal network losses.",
        "bibtex": "@InProceedings{pmlr-v238-morozov24a,\n  title = \t {Differentiable Rendering with Reparameterized Volume Sampling},\n  author =       {Morozov, Nikita and Rakitin, Denis and Desheulin, Oleg and P Vetrov, Dmitry and Struminsky, Kirill},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4852--4860},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/morozov24a/morozov24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/morozov24a.html},\n  abstract = \t {In view synthesis, a neural radiance field approximates underlying density and radiance fields based on a sparse set of scene pictures. To generate a pixel of a novel view, it marches a ray through the pixel and computes a weighted sum of radiance emitted from a dense set of ray points. This rendering algorithm is fully differentiable and facilitates gradient-based optimization of the fields. However, in practice, only a tiny opaque portion of the ray contributes most of the radiance to the sum. We propose a simple end-to-end differentiable sampling algorithm based on inverse transform sampling. It generates samples according to the probability distribution induced by the density field and picks non-transparent points on the ray. We utilize the algorithm in two ways. First, we propose a novel rendering approach based on Monte Carlo estimates. This approach allows for evaluating and optimizing a neural radiance field with just a few radiance field calls per ray. Second, we use the sampling algorithm to modify the hierarchical scheme proposed in the original NeRF work. We show that our modification improves reconstruction quality of hierarchical models, at the same time simplifying the training procedure by removing the need for auxiliary proposal network losses.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/morozov24a/morozov24a.pdf",
        "supp": "",
        "pdf_size": 9572302,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9880741046140630434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "HSE University; HSE University; HSE University; Constructor University, Bremen + HSE University; HSE University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1+0;0",
        "aff_unique_norm": "Higher School of Economics;Constructor University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://hse.ru;",
        "aff_unique_abbr": "HSE;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bremen",
        "aff_country_unique_index": "0;0;0;1+0;0",
        "aff_country_unique": "Russian Federation;Germany"
    },
    {
        "id": "2cec4076f9",
        "title": "Differentially Private Conditional Independence Testing",
        "site": "https://proceedings.mlr.press/v238/kalemaj24a.html",
        "author": "Iden Kalemaj; Shiva Kasiviswanathan; Aaditya Ramdas",
        "abstract": "Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \\perp \\!\\!\\! \\perp Y \\mid Z$, where $X \\in \\mathbb{R}, Y \\in \\mathbb{R}, Z \\in \\mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand{\u00e8}s et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests with rigorous theoretical guarantees that work for the general case when $Z$ is continuous.",
        "bibtex": "@InProceedings{pmlr-v238-kalemaj24a,\n  title = \t {Differentially Private Conditional Independence Testing},\n  author =       {Kalemaj, Iden and Kasiviswanathan, Shiva and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3700--3708},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kalemaj24a/kalemaj24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kalemaj24a.html},\n  abstract = \t {Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \\perp \\!\\!\\! \\perp Y \\mid Z$, where $X \\in \\mathbb{R}, Y \\in \\mathbb{R}, Z \\in \\mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand{\u00e8}s et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests with rigorous theoretical guarantees that work for the general case when $Z$ is continuous.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kalemaj24a/kalemaj24a.pdf",
        "supp": "",
        "pdf_size": 636694,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2248585269687315119&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Boston University; Amazon; Carnegie Mellon University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Boston University;Amazon;Carnegie Mellon University",
        "aff_unique_dep": ";Amazon.com, Inc.;",
        "aff_unique_url": "https://www.bu.edu;https://www.amazon.com;https://www.cmu.edu",
        "aff_unique_abbr": "BU;Amazon;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "08564d10ba",
        "title": "Differentially Private Reward Estimation with Preference Feedback",
        "site": "https://proceedings.mlr.press/v238/ray-chowdhury24a.html",
        "author": "Sayak Ray Chowdhury; Xingyu Zhou; Nagarajan Natarajan",
        "abstract": "Learning from preference-based feedback has recently gained considerable traction as a promising approach to align generative models with human interests. Instead of relying on numerical rewards, the generative models are trained using reinforcement learning with human feedback (RLHF). These approaches first solicit feedback from human labelers typically in the form of pairwise comparisons between two possible actions, then estimate a reward model using these comparisons, and finally employ a policy based on the estimated reward model. An adversarial attack in any step of the above pipeline might reveal private and sensitive information of human labelers. In this work, we adopt the notion of \\emph{label differential privacy} (DP) and focus on the problem of reward estimation from preference-based feedback while protecting privacy of each individual labelers. Specifically, we consider the parametric Bradley-Terry-Luce (BTL) model for such pairwise comparison feedback involving a latent reward parameter $\\theta^* \\in \\mathbb{R}^d$. Within a standard minimax estimation framework, we provide tight upper and lower bounds on the error in estimating $\\theta^*$ under both \\emph{local} and \\emph{central} models of DP. We show, for a given privacy budget $\\epsilon$ and number of samples $n$, that the additional cost to ensure label-DP under local model is $\\Theta \\big(\\frac{1}{ e^\\epsilon-1}\\sqrt{\\frac{d}{n}}\\big)$, while it is $\\Theta\\big(\\frac{\\sqrt{d}}{\\epsilon n} \\big)$ under the weaker central model. We perform simulations on synthetic data that corroborate these theoretical results.",
        "bibtex": "@InProceedings{pmlr-v238-ray-chowdhury24a,\n  title = \t {Differentially Private Reward Estimation with Preference Feedback},\n  author =       {Ray Chowdhury, Sayak and Zhou, Xingyu and Natarajan, Nagarajan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4843--4851},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ray-chowdhury24a/ray-chowdhury24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ray-chowdhury24a.html},\n  abstract = \t {Learning from preference-based feedback has recently gained considerable traction as a promising approach to align generative models with human interests. Instead of relying on numerical rewards, the generative models are trained using reinforcement learning with human feedback (RLHF). These approaches first solicit feedback from human labelers typically in the form of pairwise comparisons between two possible actions, then estimate a reward model using these comparisons, and finally employ a policy based on the estimated reward model. An adversarial attack in any step of the above pipeline might reveal private and sensitive information of human labelers. In this work, we adopt the notion of \\emph{label differential privacy} (DP) and focus on the problem of reward estimation from preference-based feedback while protecting privacy of each individual labelers. Specifically, we consider the parametric Bradley-Terry-Luce (BTL) model for such pairwise comparison feedback involving a latent reward parameter $\\theta^* \\in \\mathbb{R}^d$. Within a standard minimax estimation framework, we provide tight upper and lower bounds on the error in estimating $\\theta^*$ under both \\emph{local} and \\emph{central} models of DP. We show, for a given privacy budget $\\epsilon$ and number of samples $n$, that the additional cost to ensure label-DP under local model is $\\Theta \\big(\\frac{1}{ e^\\epsilon-1}\\sqrt{\\frac{d}{n}}\\big)$, while it is $\\Theta\\big(\\frac{\\sqrt{d}}{\\epsilon n} \\big)$ under the weaker central model. We perform simulations on synthetic data that corroborate these theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ray-chowdhury24a/ray-chowdhury24a.pdf",
        "supp": "",
        "pdf_size": 920732,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1827109676252496667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "99f6c7b8cc",
        "title": "Directed Hypergraph Representation Learning for Link Prediction",
        "site": "https://proceedings.mlr.press/v238/ma24b.html",
        "author": "Zitong Ma; Wenbo Zhao; Zhe Yang",
        "abstract": "Link prediction is a critical problem in network structure processing. With the prevalence of deep learning, graph-based learning pattern in link prediction has been well-proven to successfully apply. However, existing representation-based computing paradigms retain some lack in processing complex networks: most methods only consider low-order pairwise information or eliminate the direction message, which tends to obtain a sub-optimal representation. To tackle the above challenges, we propose using directed hypergraph to model the real world and design a directed hypergraph neural network framework for data representation learning. Specifically, our work can be concluded into two sophisticated aspects: (1) We define the approximate Laplacian of the directed hypergraph, and further formulate the convolution operation on the directed hypergraph structure, solving the issue of the directed hypergraph structure representation learning. (2) By efficiently learning complex information from directed hypergraphs to obtain high-quality representations, we develop a framework DHGNN for link prediction on directed hypergraph structures. We empirically show that the merit of DHGNN lies in its ability to model complex correlations and encode information effectively of directed hypergraphs. Extensive experiments conducted on multi-field datasets demonstrate the superiority of the proposed DHGNN over various state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v238-ma24b,\n  title = \t {Directed Hypergraph Representation Learning for Link Prediction},\n  author =       {Ma, Zitong and Zhao, Wenbo and Yang, Zhe},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3268--3276},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ma24b/ma24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ma24b.html},\n  abstract = \t {Link prediction is a critical problem in network structure processing. With the prevalence of deep learning, graph-based learning pattern in link prediction has been well-proven to successfully apply. However, existing representation-based computing paradigms retain some lack in processing complex networks: most methods only consider low-order pairwise information or eliminate the direction message, which tends to obtain a sub-optimal representation. To tackle the above challenges, we propose using directed hypergraph to model the real world and design a directed hypergraph neural network framework for data representation learning. Specifically, our work can be concluded into two sophisticated aspects: (1) We define the approximate Laplacian of the directed hypergraph, and further formulate the convolution operation on the directed hypergraph structure, solving the issue of the directed hypergraph structure representation learning. (2) By efficiently learning complex information from directed hypergraphs to obtain high-quality representations, we develop a framework DHGNN for link prediction on directed hypergraph structures. We empirically show that the merit of DHGNN lies in its ability to model complex correlations and encode information effectively of directed hypergraphs. Extensive experiments conducted on multi-field datasets demonstrate the superiority of the proposed DHGNN over various state-of-the-art approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ma24b/ma24b.pdf",
        "supp": "",
        "pdf_size": 724892,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5819116643187700200&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "School of Computer Science and Technology, Soochow University; School of Computer Science and Technology, Soochow University; School of Computer Science and Technology, Soochow University",
        "aff_domain": "stu.suda.edu.cn;stu.suda.edu.cn;suda.edu.cn",
        "email": "stu.suda.edu.cn;stu.suda.edu.cn;suda.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Soochow University",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "https://eng.suda.edu.cn/",
        "aff_unique_abbr": "Soochow U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "000fabf205",
        "title": "Directional Optimism for Safe Linear Bandits",
        "site": "https://proceedings.mlr.press/v238/hutchinson24a.html",
        "author": "Spencer Hutchinson; Berkay Turan; Mahnoosh Alizadeh",
        "abstract": "The safe linear bandit problem is a version of the classical stochastic linear bandit problem where the learner\u2019s actions must satisfy an uncertain constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. By leveraging a novel approach that we call directional optimism, we find that it is possible to achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Furthermore, we propose a novel algorithm for this setting that improves on existing algorithms in terms of empirical performance, while enjoying matching regret guarantees. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach.",
        "bibtex": "@InProceedings{pmlr-v238-hutchinson24a,\n  title = \t {Directional Optimism for Safe Linear Bandits},\n  author =       {Hutchinson, Spencer and Turan, Berkay and Alizadeh, Mahnoosh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {658--666},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hutchinson24a/hutchinson24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hutchinson24a.html},\n  abstract = \t {The safe linear bandit problem is a version of the classical stochastic linear bandit problem where the learner\u2019s actions must satisfy an uncertain constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. By leveraging a novel approach that we call directional optimism, we find that it is possible to achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Furthermore, we propose a novel algorithm for this setting that improves on existing algorithms in terms of empirical performance, while enjoying matching regret guarantees. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hutchinson24a/hutchinson24a.pdf",
        "supp": "",
        "pdf_size": 780029,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3470643489986329766&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6b00bd6fd0",
        "title": "Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods",
        "site": "https://proceedings.mlr.press/v238/zhang24h.html",
        "author": "Jiaxin Zhang; Kamalika Das; Sricharan Kumar",
        "abstract": "Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24h,\n  title = \t {Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods},\n  author =       {Zhang, Jiaxin and Das, Kamalika and Kumar, Sricharan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2917--2925},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24h/zhang24h.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24h.html},\n  abstract = \t {Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24h/zhang24h.pdf",
        "supp": "",
        "pdf_size": 1399101,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4zcmFqCzZwcJ:scholar.google.com/&scioq=Discriminant+Distance-Aware+Representation+on+Deterministic+Uncertainty+Quantification+Methods&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Intuit AI Research; Intuit AI Research; Intuit AI Research",
        "aff_domain": "intuit.com;intuit.com;intuit.com",
        "email": "intuit.com;intuit.com;intuit.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Intuit",
        "aff_unique_dep": "Intuit AI Research",
        "aff_unique_url": "https://intuit.com/",
        "aff_unique_abbr": "Intuit",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ae7ffe96f9",
        "title": "Discriminator Guidance for Autoregressive Diffusion Models",
        "site": "https://proceedings.mlr.press/v238/ekstrom-kelvinius24a.html",
        "author": "Filip Ekstr\u00f6m Kelvinius; Fredrik Lindsten",
        "abstract": "We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discriminator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.",
        "bibtex": "@InProceedings{pmlr-v238-ekstrom-kelvinius24a,\n  title = \t {Discriminator Guidance for Autoregressive Diffusion Models},\n  author =       {Ekstr\\\"{o}m Kelvinius, Filip and Lindsten, Fredrik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3403--3411},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ekstrom-kelvinius24a/ekstrom-kelvinius24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ekstrom-kelvinius24a.html},\n  abstract = \t {We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discriminator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ekstrom-kelvinius24a/ekstrom-kelvinius24a.pdf",
        "supp": "",
        "pdf_size": 378506,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14605671915778989079&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Link\u00f6ping University; Link\u00f6ping University",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/filipekstrm/graph_ardm",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Link\u00f6ping University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.liu.se",
        "aff_unique_abbr": "LiU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "a489e28364",
        "title": "Dissimilarity Bandits",
        "site": "https://proceedings.mlr.press/v238/battellani24a.html",
        "author": "Paolo Battellani; Alberto Maria Metelli; Francesco Trov\u00f2",
        "abstract": "We study a novel sequential decision-making setting, namely the dissimilarity bandits. At each round, the learner pulls an arm that provides a stochastic d-dimensional observation vector. The learner aims to identify the pair of arms with the maximum dissimilarity, where such an index is computed over pairs of expected observation vectors. We propose Successive Elimination for Dissimilarity (SED), a fixed-confidence best-pair identification algorithm based on sequential elimination. SED discards individual arms when there is statistical evidence that they cannot belong to a pair of most dissimilar arms and, thus, effectively exploits the structure of the setting by reusing the estimates of the expected observation vectors. We provide results on the sample complexity of SED, depending on {HP}, a novel index characterizing the complexity of identifying the pair of the most dissimilar arms. Then, we provide a sample complexity lower bound, highlighting the challenges of the identification problem for dissimilarity bandits, which is almost matched by our SED. Finally, we compare our approach over synthetically generated data and a realistic environmental monitoring domain against classical and combinatorial best-arm identification algorithms for the cases $d=1$ and $d>1$.",
        "bibtex": "@InProceedings{pmlr-v238-battellani24a,\n  title = \t {Dissimilarity Bandits},\n  author =       {Battellani, Paolo and Maria Metelli, Alberto and Trov\\`{o}, Francesco},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3637--3645},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/battellani24a/battellani24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/battellani24a.html},\n  abstract = \t {We study a novel sequential decision-making setting, namely the dissimilarity bandits. At each round, the learner pulls an arm that provides a stochastic d-dimensional observation vector. The learner aims to identify the pair of arms with the maximum dissimilarity, where such an index is computed over pairs of expected observation vectors. We propose Successive Elimination for Dissimilarity (SED), a fixed-confidence best-pair identification algorithm based on sequential elimination. SED discards individual arms when there is statistical evidence that they cannot belong to a pair of most dissimilar arms and, thus, effectively exploits the structure of the setting by reusing the estimates of the expected observation vectors. We provide results on the sample complexity of SED, depending on {HP}, a novel index characterizing the complexity of identifying the pair of the most dissimilar arms. Then, we provide a sample complexity lower bound, highlighting the challenges of the identification problem for dissimilarity bandits, which is almost matched by our SED. Finally, we compare our approach over synthetically generated data and a realistic environmental monitoring domain against classical and combinatorial best-arm identification algorithms for the cases $d=1$ and $d>1$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/battellani24a/battellani24a.pdf",
        "supp": "",
        "pdf_size": 517797,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:EtHTAR87zZ8J:scholar.google.com/&scioq=Dissimilarity+Bandits&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano",
        "aff_domain": "mail.polimi.it;polimi.it;polimi.it",
        "email": "mail.polimi.it;polimi.it;polimi.it",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "a85c05ce3d",
        "title": "Distributionally Robust Model-based Reinforcement Learning with Large State Spaces",
        "site": "https://proceedings.mlr.press/v238/sundhar-ramesh24a.html",
        "author": "Shyam Sundhar Ramesh; Pier Giuseppe Sessa; Yifan Hu; Andreas Krause; Ilija Bogunovic",
        "abstract": "Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed.",
        "bibtex": "@InProceedings{pmlr-v238-sundhar-ramesh24a,\n  title = \t {Distributionally Robust Model-based Reinforcement Learning with Large State Spaces},\n  author =       {Sundhar Ramesh, Shyam and Giuseppe Sessa, Pier and Hu, Yifan and Krause, Andreas and Bogunovic, Ilija},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {100--108},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sundhar-ramesh24a/sundhar-ramesh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sundhar-ramesh24a.html},\n  abstract = \t {Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sundhar-ramesh24a/sundhar-ramesh24a.pdf",
        "supp": "",
        "pdf_size": 1914320,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17206816469138346225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University College London; ETH Zurich; EPFL; ETH Zurich; Univeristy College London",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University College London;ETH Zurich;EPFL",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ethz.ch;https://www.epfl.ch",
        "aff_unique_abbr": "UCL;ETHZ;EPFL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "United Kingdom;Switzerland"
    },
    {
        "id": "211cfa8b08",
        "title": "Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation",
        "site": "https://proceedings.mlr.press/v238/liu24d.html",
        "author": "Zhishuai Liu; Pan Xu",
        "abstract": "We study off-dynamics Reinforcement Learning (RL), where the policy is trained on a source domain and deployed to a distinct target domain. We aim to solve this problem via online distributionally robust Markov decision processes (DRMDPs), where the learning algorithm actively interacts with the source domain while seeking the optimal performance under the worst possible dynamics that is within an uncertainty set of the source domain\u2019s transition kernel. We provide the first study on online DRMDPs with function approximation for off-dynamics RL. We find that DRMDPs\u2019 dual formulation can induce nonlinearity, even when the nominal transition kernel is linear, leading to error propagation. By designing a $d$-rectangular uncertainty set using the total variation distance, we remove this additional nonlinearity and bypass the error propagation. We then introduce DR-LSVI-UCB, the first provably efficient online DRMDP algorithm for off-dynamics RL with function approximation, and establish a polynomial suboptimality bound that is independent of the state and action space sizes. Our work makes the first step towards a deeper understanding of the provable efficiency of online DRMDPs with linear function approximation. Finally, we substantiate the performance and robustness of DR-LSVI-UCB through different numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-liu24d,\n  title = \t {Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation},\n  author =       {Liu, Zhishuai and Xu, Pan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2719--2727},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24d/liu24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24d.html},\n  abstract = \t {We study off-dynamics Reinforcement Learning (RL), where the policy is trained on a source domain and deployed to a distinct target domain. We aim to solve this problem via online distributionally robust Markov decision processes (DRMDPs), where the learning algorithm actively interacts with the source domain while seeking the optimal performance under the worst possible dynamics that is within an uncertainty set of the source domain\u2019s transition kernel. We provide the first study on online DRMDPs with function approximation for off-dynamics RL. We find that DRMDPs\u2019 dual formulation can induce nonlinearity, even when the nominal transition kernel is linear, leading to error propagation. By designing a $d$-rectangular uncertainty set using the total variation distance, we remove this additional nonlinearity and bypass the error propagation. We then introduce DR-LSVI-UCB, the first provably efficient online DRMDP algorithm for off-dynamics RL with function approximation, and establish a polynomial suboptimality bound that is independent of the state and action space sizes. Our work makes the first step towards a deeper understanding of the provable efficiency of online DRMDPs with linear function approximation. Finally, we substantiate the performance and robustness of DR-LSVI-UCB through different numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24d/liu24d.pdf",
        "supp": "",
        "pdf_size": 5185778,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12695111087859948680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Duke University; Duke University",
        "aff_domain": "duke.edu;duke.edu",
        "email": "duke.edu;duke.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "747f60b7e6",
        "title": "Distributionally Robust Quickest Change Detection using Wasserstein Uncertainty Sets",
        "site": "https://proceedings.mlr.press/v238/xie24a.html",
        "author": "Liyan Xie; Yuchen Liang; Venugopal V. Veeravalli",
        "abstract": "The problem of quickest detection of a change in the distribution of streaming data is considered. It is assumed that the pre-change distribution is known, while the only information about the post-change is through a (small) set of labeled data. This post-change data is used in a data-driven minimax robust framework, where an uncertainty set for the post-change distribution is constructed. The robust change detection problem is studied in an asymptotic setting where the mean time to false alarm goes to infinity. It is shown that the least favorable distribution (LFD) is an exponentially tilted version of the pre-change density and can be obtained efficiently. A Cumulative Sum (CuSum) test based on the LFD, which is referred to as the distributionally robust (DR) CuSum test, is then shown to be asymptotically robust. The results are extended to the case with multiple post-change uncertainty sets and validated using synthetic and real data examples.",
        "bibtex": "@InProceedings{pmlr-v238-xie24a,\n  title = \t {Distributionally Robust Quickest Change Detection using {W}asserstein Uncertainty Sets},\n  author =       {Xie, Liyan and Liang, Yuchen and V. Veeravalli, Venugopal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1063--1071},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xie24a/xie24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xie24a.html},\n  abstract = \t {The problem of quickest detection of a change in the distribution of streaming data is considered. It is assumed that the pre-change distribution is known, while the only information about the post-change is through a (small) set of labeled data. This post-change data is used in a data-driven minimax robust framework, where an uncertainty set for the post-change distribution is constructed. The robust change detection problem is studied in an asymptotic setting where the mean time to false alarm goes to infinity. It is shown that the least favorable distribution (LFD) is an exponentially tilted version of the pre-change density and can be obtained efficiently. A Cumulative Sum (CuSum) test based on the LFD, which is referred to as the distributionally robust (DR) CuSum test, is then shown to be asymptotically robust. The results are extended to the case with multiple post-change uncertainty sets and validated using synthetic and real data examples.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xie24a/xie24a.pdf",
        "supp": "",
        "pdf_size": 882932,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4972048604900003350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "CUHK-Shenzhen; Ohio State University; University of Illinois Urbana-Champaign",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Chinese University of Hong Kong, Shenzhen;Ohio State University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cuhk.edu.cn/shenzhen;https://www.osu.edu;https://illinois.edu",
        "aff_unique_abbr": "CUHK-Shenzhen;OSU;UIUC",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Shenzhen;;Urbana-Champaign",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "ace521b4b2",
        "title": "Don\u2019t Be Pessimistic Too Early: Look K Steps Ahead!",
        "site": "https://proceedings.mlr.press/v238/wang24h.html",
        "author": "Chaoqi Wang; Ziyu Ye; Kevin Murphy; Yuxin Chen",
        "abstract": "Offline reinforcement learning (RL) considers to train highly rewarding policies exclusively from existing data, showing great real-world impacts. Pessimism, \\emph{i.e.}, avoiding uncertain states or actions during decision making, has long been the main theme for offline RL. However, existing works often lead to overly conservative policies with rather sub-optimal performance. To tackle this challenge, we introduce the notion of \\emph{lookahead pessimism} within the model-based offline RL paradigm. Intuitively, while the classical pessimism principle asks to terminate whenever the RL agent reaches an uncertain region, our method allows the agent to use a lookahead set carefully crafted from the learned model, and to make a move by properties of the lookahead set. Remarkably, we show that this enables learning a less conservative policy with a better performance guarantee. We refer to our method as Lookahead Pessimistic MDP (LP-MDP). Theoretically, we provide a rigorous analysis on the performance lower bound, which monotonically improves with the lookahead steps. Empirically, with the easy-to-implement design of LP-MDP, we demonstrate a solid performance improvement over baseline methods on widely used offline RL benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-wang24h,\n  title = \t {Don\u2019t Be Pessimistic Too Early: Look {K} Steps Ahead!},\n  author =       {Wang, Chaoqi and Ye, Ziyu and Murphy, Kevin and Chen, Yuxin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3313--3321},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24h/wang24h.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24h.html},\n  abstract = \t {Offline reinforcement learning (RL) considers to train highly rewarding policies exclusively from existing data, showing great real-world impacts. Pessimism, \\emph{i.e.}, avoiding uncertain states or actions during decision making, has long been the main theme for offline RL. However, existing works often lead to overly conservative policies with rather sub-optimal performance. To tackle this challenge, we introduce the notion of \\emph{lookahead pessimism} within the model-based offline RL paradigm. Intuitively, while the classical pessimism principle asks to terminate whenever the RL agent reaches an uncertain region, our method allows the agent to use a lookahead set carefully crafted from the learned model, and to make a move by properties of the lookahead set. Remarkably, we show that this enables learning a less conservative policy with a better performance guarantee. We refer to our method as Lookahead Pessimistic MDP (LP-MDP). Theoretically, we provide a rigorous analysis on the performance lower bound, which monotonically improves with the lookahead steps. Empirically, with the easy-to-implement design of LP-MDP, we demonstrate a solid performance improvement over baseline methods on widely used offline RL benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24h/wang24h.pdf",
        "supp": "",
        "pdf_size": 10877501,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Unversity of Chicago; Unversity of Chicago; Google DeepMind; Unversity of Chicago",
        "aff_domain": "uchicago.edu; ; ; ",
        "email": "uchicago.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Chicago;Google",
        "aff_unique_dep": ";Google DeepMind",
        "aff_unique_url": "https://www.uchicago.edu;https://deepmind.com",
        "aff_unique_abbr": "UChicago;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "c430df20e0",
        "title": "Double InfoGAN for Contrastive Analysis",
        "site": "https://proceedings.mlr.press/v238/carton24a.html",
        "author": "Florence Carton; Robin Louiset; Pietro Gori",
        "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don\u2019t enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online.",
        "bibtex": "@InProceedings{pmlr-v238-carton24a,\n  title = \t {Double {InfoGAN} for Contrastive Analysis},\n  author =       {Carton, Florence and Louiset, Robin and Gori, Pietro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {172--180},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/carton24a/carton24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/carton24a.html},\n  abstract = \t {Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don\u2019t enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/carton24a/carton24a.pdf",
        "supp": "",
        "pdf_size": 3984587,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9926268397231058715&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f03751b1c7",
        "title": "Dynamic Inter-treatment Information Sharing for Individualized Treatment Effects Estimation",
        "site": "https://proceedings.mlr.press/v238/chauhan24a.html",
        "author": "Vinod Kumar Chauhan; Jiandong Zhou; Ghadeer Ghosheh; Soheila Molaei; David A Clifton",
        "abstract": "Estimation of individualized treatment effects (ITE) from observational studies is a fundamental problem in causal inference and holds significant importance across domains, including healthcare. However, limited observational datasets pose challenges in reliable ITE estimation as data have to be split among treatment groups to train an ITE learner. While information sharing among treatment groups can partially alleviate the problem, there is currently no general framework for end-to-end information sharing in ITE estimation. To tackle this problem, we propose a deep learning framework based on \u2018\\textit{soft weight sharing}\u2019 to train ITE learners, enabling \\textit{dynamic end-to-end} information sharing among treatment groups. The proposed framework complements existing ITE learners, and introduces a new class of ITE learners, referred to as \\textit{HyperITE}. We extend state-of-the-art ITE learners with \\textit{HyperITE} versions and evaluate them on IHDP, ACIC-2016, and Twins benchmarks. Our experimental results show that the proposed framework improves ITE estimation error, with increasing effectiveness for smaller datasets.",
        "bibtex": "@InProceedings{pmlr-v238-chauhan24a,\n  title = \t {Dynamic Inter-treatment Information Sharing for Individualized Treatment Effects Estimation},\n  author =       {Chauhan, Vinod Kumar and Zhou, Jiandong and Ghosheh, Ghadeer and Molaei, Soheila and A Clifton, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3529--3537},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chauhan24a/chauhan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chauhan24a.html},\n  abstract = \t {Estimation of individualized treatment effects (ITE) from observational studies is a fundamental problem in causal inference and holds significant importance across domains, including healthcare. However, limited observational datasets pose challenges in reliable ITE estimation as data have to be split among treatment groups to train an ITE learner. While information sharing among treatment groups can partially alleviate the problem, there is currently no general framework for end-to-end information sharing in ITE estimation. To tackle this problem, we propose a deep learning framework based on \u2018\\textit{soft weight sharing}\u2019 to train ITE learners, enabling \\textit{dynamic end-to-end} information sharing among treatment groups. The proposed framework complements existing ITE learners, and introduces a new class of ITE learners, referred to as \\textit{HyperITE}. We extend state-of-the-art ITE learners with \\textit{HyperITE} versions and evaluate them on IHDP, ACIC-2016, and Twins benchmarks. Our experimental results show that the proposed framework improves ITE estimation error, with increasing effectiveness for smaller datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chauhan24a/chauhan24a.pdf",
        "supp": "",
        "pdf_size": 1141004,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15556229215713921185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Institute of Biomedical Engineering, University of Oxford, OX3 7DQ, UK; Institute of Biomedical Engineering, University of Oxford, OX3 7DQ, UK; Institute of Biomedical Engineering, University of Oxford, OX3 7DQ, UK; Institute of Biomedical Engineering, University of Oxford, OX3 7DQ, UK; Institute of Biomedical Engineering, University of Oxford, OX3 7DQ, UK + Oxford-Suzhou Institute of Advanced Research (OSCAR), Suzhou, China",
        "aff_domain": "eng.ox.ac.uk; ; ; ; ",
        "email": "eng.ox.ac.uk; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0+1",
        "aff_unique_norm": "University of Oxford;Oxford-Suzhou Institute of Advanced Research",
        "aff_unique_dep": "Institute of Biomedical Engineering;",
        "aff_unique_url": "https://www.ox.ac.uk;",
        "aff_unique_abbr": "Oxford;OSCAR",
        "aff_campus_unique_index": "0;0;0;0;0+1",
        "aff_campus_unique": "Oxford;Suzhou",
        "aff_country_unique_index": "0;0;0;0;0+1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "cc6db77b6c",
        "title": "E(3)-Equivariant Mesh Neural Networks",
        "site": "https://proceedings.mlr.press/v238/anh-trang24a.html",
        "author": "Thuan Anh Trang; Nhat Khang Ngo; Daniel T. Levy; Thieu Ngoc Vo; Siamak Ravanbakhsh; Truong Son Hy",
        "abstract": "Triangular meshes are widely used to represent three-dimensional objects. As a result, many recent works have addressed the need for geometric deep learning on 3D meshes. However, we observe that the complexities in many of these architectures do not translate to practical performance, and simple deep models for geometric graphs are competitive in practice. Motivated by this observation, we minimally extend the update equations of E(n)-Equivariant Graph Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face information and further improve it to account for long-range interactions through a hierarchy. The resulting architecture, Equivariant Mesh Neural Network (EMNN), outperforms other, more complicated equivariant methods on mesh tasks, with a fast run-time and no expensive preprocessing. Our implementation is available at \\url{https://github.com/HySonLab/EquiMesh}.",
        "bibtex": "@InProceedings{pmlr-v238-anh-trang24a,\n  title = \t {E(3)-Equivariant Mesh Neural Networks},\n  author =       {Anh Trang, Thuan and Ngo, Nhat Khang and Levy, Daniel T. and Ngoc Vo, Thieu and Ravanbakhsh, Siamak and Son Hy, Truong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {748--756},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/anh-trang24a/anh-trang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/anh-trang24a.html},\n  abstract = \t {Triangular meshes are widely used to represent three-dimensional objects. As a result, many recent works have addressed the need for geometric deep learning on 3D meshes. However, we observe that the complexities in many of these architectures do not translate to practical performance, and simple deep models for geometric graphs are competitive in practice. Motivated by this observation, we minimally extend the update equations of E(n)-Equivariant Graph Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face information and further improve it to account for long-range interactions through a hierarchy. The resulting architecture, Equivariant Mesh Neural Network (EMNN), outperforms other, more complicated equivariant methods on mesh tasks, with a fast run-time and no expensive preprocessing. Our implementation is available at \\url{https://github.com/HySonLab/EquiMesh}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/anh-trang24a/anh-trang24a.pdf",
        "supp": "",
        "pdf_size": 1237763,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4964059453042260189&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "FPT Software AI Center; FPT Software AI Center; McGill University+Mila - Quebec AI Institute; Ton Duc Thang University; McGill University+Mila - Quebec AI Institute; FPT Software AI Center+Indiana State University",
        "aff_domain": "fpt-software.com;fpt-software.com;cs.mcgill.ca;tdtu.edu.vn;cs.mcgill.ca;indstate.edu",
        "email": "fpt-software.com;fpt-software.com;cs.mcgill.ca;tdtu.edu.vn;cs.mcgill.ca;indstate.edu",
        "github": "https://github.com/HySonLab/EquiMesh",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;3;1+2;0+4",
        "aff_unique_norm": "FPT Software;McGill University;Quebec AI Institute;Ton Duc Thang University;Indiana State University",
        "aff_unique_dep": "AI Center;;AI Institute;;",
        "aff_unique_url": "https://www.fpt-software.com;https://www.mcgill.ca;https://mila.quebec;https://www.tdtu.edu.vn;https://www.indstate.edu",
        "aff_unique_abbr": ";McGill;Mila;TDTU;ISU",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1+1;0;1+1;0+2",
        "aff_country_unique": "Vietnam;Canada;United States"
    },
    {
        "id": "07c2145482",
        "title": "EM for Mixture of Linear Regression with Clustered Data",
        "site": "https://proceedings.mlr.press/v238/reisizadeh24a.html",
        "author": "Amirhossein Reisizadeh; Khashayar Gatmiry; Asuman Ozdaglar",
        "abstract": "Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from m batches of dependent samples each containing n measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\\log(mn/d))$ iterations to reach the statistical accuracy of $O(\\sqrt{d/(mn)}$). In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as m grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v238-reisizadeh24a,\n  title = \t {{EM} for Mixture of Linear Regression with Clustered Data},\n  author =       {Reisizadeh, Amirhossein and Gatmiry, Khashayar and Ozdaglar, Asuman},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2341--2349},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/reisizadeh24a/reisizadeh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/reisizadeh24a.html},\n  abstract = \t {Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from m batches of dependent samples each containing n measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\\log(mn/d))$ iterations to reach the statistical accuracy of $O(\\sqrt{d/(mn)}$). In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as m grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/reisizadeh24a/reisizadeh24a.pdf",
        "supp": "",
        "pdf_size": 1084705,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8288864489771459129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "36c9504636",
        "title": "Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability",
        "site": "https://proceedings.mlr.press/v238/haldar24a.html",
        "author": "Rajdeep Haldar; Yue Xing; Qifan Song",
        "abstract": "The existence of adversarial attacks on machine learning models imperceptible to a human is still quite a mystery from a theoretical perspective. In this work, we introduce two notions of adversarial attacks: natural or on-manifold attacks, which are perceptible by a human/oracle, and unnatural or off-manifold attacks, which are not. We argue that the existence of the off-manifold attacks is a natural consequence of the dimension gap between the intrinsic and ambient dimensions of the data. For 2-layer ReLU networks, we prove that even though the dimension gap does not affect generalization performance on samples drawn from the observed data space, it makes the clean-trained model more vulnerable to adversarial perturbations in the off-manifold direction of the data space. Our main results provide an explicit relationship between the $\\ell_2,\\ell_{\\infty}$ attack strength of the on/off-manifold attack and the dimension gap.",
        "bibtex": "@InProceedings{pmlr-v238-haldar24a,\n  title = \t {Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability},\n  author =       {Haldar, Rajdeep and Xing, Yue and Song, Qifan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1090--1098},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/haldar24a/haldar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/haldar24a.html},\n  abstract = \t {The existence of adversarial attacks on machine learning models imperceptible to a human is still quite a mystery from a theoretical perspective. In this work, we introduce two notions of adversarial attacks: natural or on-manifold attacks, which are perceptible by a human/oracle, and unnatural or off-manifold attacks, which are not. We argue that the existence of the off-manifold attacks is a natural consequence of the dimension gap between the intrinsic and ambient dimensions of the data. For 2-layer ReLU networks, we prove that even though the dimension gap does not affect generalization performance on samples drawn from the observed data space, it makes the clean-trained model more vulnerable to adversarial perturbations in the off-manifold direction of the data space. Our main results provide an explicit relationship between the $\\ell_2,\\ell_{\\infty}$ attack strength of the on/off-manifold attack and the dimension gap.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/haldar24a/haldar24a.pdf",
        "supp": "",
        "pdf_size": 1230026,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6978205452340546062&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "69478777e9",
        "title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach",
        "site": "https://proceedings.mlr.press/v238/li24p.html",
        "author": "Yinan Li; Chicheng Zhang",
        "abstract": "We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise\u00a0(Tsybakov, 2004) under structured unlabeled data distributions. Inspired by\u00a0Diakonikolas et al., (2020c), we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\\tilde{O}(d (\\frac{1}{\\epsilon})^{\\frac{8-6\\alpha}{3\\alpha-1}})$, under the assumption that the Tsybakov noise parameter $\\alpha \\in (\\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms\u00a0(Diakonikolas et al., 2020b; Zhang and Li, 2021) and the information-theoretic lower bound in this setting.",
        "bibtex": "@InProceedings{pmlr-v238-li24p,\n  title = \t {Efficient Active Learning Halfspaces with {T}sybakov Noise: A Non-convex Optimization Approach},\n  author =       {Li, Yinan and Zhang, Chicheng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4744--4752},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24p/li24p.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24p.html},\n  abstract = \t {We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise\u00a0(Tsybakov, 2004) under structured unlabeled data distributions. Inspired by\u00a0Diakonikolas et al., (2020c), we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\\tilde{O}(d (\\frac{1}{\\epsilon})^{\\frac{8-6\\alpha}{3\\alpha-1}})$, under the assumption that the Tsybakov noise parameter $\\alpha \\in (\\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms\u00a0(Diakonikolas et al., 2020b; Zhang and Li, 2021) and the information-theoretic lower bound in this setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24p/li24p.pdf",
        "supp": "",
        "pdf_size": 485487,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14128413150433738860&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Arizona; University of Arizona",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Arizona",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.arizona.edu",
        "aff_unique_abbr": "UA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c160843176",
        "title": "Efficient Conformal Prediction under Data Heterogeneity",
        "site": "https://proceedings.mlr.press/v238/plassier24a.html",
        "author": "Vincent Plassier; Nikita Kotelevskii; Aleksandr Rubashevskii; Fedor Noskov; Maksim Velikanov; Alexander Fishkov; Samuel Horvath; Martin Takac; Eric Moulines; Maxim Panov",
        "abstract": "Conformal prediction (CP) stands out as a robust framework for uncertainty quantification, which is crucial for ensuring the reliability of predictions. However, common CP methods heavily rely on the data exchangeability, a condition often violated in practice. Existing approaches for tackling non-exchangeability lead to methods that are not computable beyond the simplest examples. In this work, we introduce a new efficient approach to CP that produces provably valid confidence sets for fairly general non-exchangeable data distributions. We illustrate the general theory with applications to the challenging setting of federated learning under data heterogeneity between agents. Our method allows constructing provably valid personalized prediction sets for agents in a fully federated way. The effectiveness of the proposed method is demonstrated in a series of experiments on real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-plassier24a,\n  title = \t {Efficient Conformal Prediction under Data Heterogeneity},\n  author =       {Plassier, Vincent and Kotelevskii, Nikita and Rubashevskii, Aleksandr and Noskov, Fedor and Velikanov, Maksim and Fishkov, Alexander and Horvath, Samuel and Takac, Martin and Moulines, Eric and Panov, Maxim},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4879--4887},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/plassier24a/plassier24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/plassier24a.html},\n  abstract = \t {Conformal prediction (CP) stands out as a robust framework for uncertainty quantification, which is crucial for ensuring the reliability of predictions. However, common CP methods heavily rely on the data exchangeability, a condition often violated in practice. Existing approaches for tackling non-exchangeability lead to methods that are not computable beyond the simplest examples. In this work, we introduce a new efficient approach to CP that produces provably valid confidence sets for fairly general non-exchangeable data distributions. We illustrate the general theory with applications to the challenging setting of federated learning under data heterogeneity between agents. Our method allows constructing provably valid personalized prediction sets for agents in a fully federated way. The effectiveness of the proposed method is demonstrated in a series of experiments on real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/plassier24a/plassier24a.pdf",
        "supp": "",
        "pdf_size": 783403,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10442492147512164559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Lagrange Mathematics and Computing Research Center+CMAP, Ecole Polytechnique, Paris; Skolkovo Institute of Science and Technology+Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; Skolkovo Institute of Science and Technology+Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; HSE University, Moscow; CMAP, Ecole Polytechnique, Paris+Technology Innovation Institute+Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; Skolkovo Institute of Science and Technology+Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; CMAP, Ecole Polytechnique, Paris+Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi; Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi",
        "aff_domain": ";;;;;;;;;",
        "email": ";;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+3;2+3;4;1+5+3;2+3;3;3;1+3;3",
        "aff_unique_norm": "Lagrange Mathematics and Computing Research Center;Ecole Polytechnique;Skolkovo Institute of Science and Technology;Mohamed bin Zayed University of Artificial Intelligence;HSE University;Technology Innovation Institute",
        "aff_unique_dep": "Mathematics and Computing Research;CMAP;;;;",
        "aff_unique_url": ";https://www.polytechnique.edu;https://www.skoltech.ru;https://mbzuai.ac.ae;https://hse.ru;",
        "aff_unique_abbr": ";Polytechnique;Skoltech;MBZUAI;HSE;",
        "aff_campus_unique_index": "1;2;2;3;1+2;2;2;2;1+2;2",
        "aff_campus_unique": ";Paris;Abu Dhabi;Moscow",
        "aff_country_unique_index": "1;2+3;2+3;2;1+3;2+3;3;3;1+3;3",
        "aff_country_unique": ";France;Russian Federation;United Arab Emirates"
    },
    {
        "id": "8ae8f43361",
        "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
        "site": "https://proceedings.mlr.press/v238/wang24e.html",
        "author": "Jiachen T. Wang; Prateek Mittal; Ruoxi Jia",
        "abstract": "This work aims to address an open problem in data valuation literature concerning the efficient computation of Data Shapley for weighted $K$ nearest neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label KNN with discretized weights as the utility function, we reframe the computation of WKNN-Shapley into a counting problem and introduce a quadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the best result from existing literature. We develop a deterministic approximation algorithm that further improves computational efficiency while maintaining the key fairness properties of the Shapley value. Through extensive experiments, we demonstrate WKNN-Shapley\u2019s computational efficiency and its superior performance in discerning data quality compared to its unweighted counterpart.",
        "bibtex": "@InProceedings{pmlr-v238-wang24e,\n  title = \t {Efficient Data {S}hapley for Weighted Nearest Neighbor Algorithms},\n  author =       {Wang, Jiachen T. and Mittal, Prateek and Jia, Ruoxi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2557--2565},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24e/wang24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24e.html},\n  abstract = \t {This work aims to address an open problem in data valuation literature concerning the efficient computation of Data Shapley for weighted $K$ nearest neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label KNN with discretized weights as the utility function, we reframe the computation of WKNN-Shapley into a counting problem and introduce a quadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the best result from existing literature. We develop a deterministic approximation algorithm that further improves computational efficiency while maintaining the key fairness properties of the Shapley value. Through extensive experiments, we demonstrate WKNN-Shapley\u2019s computational efficiency and its superior performance in discerning data quality compared to its unweighted counterpart.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24e/wang24e.pdf",
        "supp": "",
        "pdf_size": 2990772,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=770330636929113294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Princeton University; Princeton University; Virginia Tech",
        "aff_domain": "princeton.edu; ;vt.edu",
        "email": "princeton.edu; ;vt.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Princeton University;Virginia Tech",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.princeton.edu;https://www.vt.edu",
        "aff_unique_abbr": "Princeton;VT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c387e35f31",
        "title": "Efficient Graph Laplacian Estimation by Proximal Newton",
        "site": "https://proceedings.mlr.press/v238/medvedovsky24a.html",
        "author": "Yakov Medvedovsky; Eran Treister; Tirza S Routtenberg",
        "abstract": "The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common multivariate statistical model for learning a weighted sparse dependency graph from given data. This graph learning problem can be formulated as a maximum likelihood estimation (MLE) of the precision matrix, subject to Laplacian structural constraints, with a sparsity-inducing penalty term. This paper aims to solve this learning problem accurately and efficiently. First, since the commonly used $\\ell_1$-norm penalty is inappropriate in this setting and may lead to a complete graph, we employ the nonconvex minimax concave penalty (MCP), which promotes sparse solutions with lower estimation bias. Second, as opposed to existing first-order methods for this problem, we develop a second-order proximal Newton approach to obtain an efficient solver, utilizing several algorithmic features, such as using conjugate gradients, preconditioning, and splitting to active/free sets. Numerical experiments demonstrate the advantages of the proposed method in terms of both computational complexity and graph learning accuracy compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v238-medvedovsky24a,\n  title = \t {Efficient Graph {L}aplacian Estimation by Proximal {N}ewton},\n  author =       {Medvedovsky, Yakov and Treister, Eran and S Routtenberg, Tirza},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1171--1179},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/medvedovsky24a/medvedovsky24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/medvedovsky24a.html},\n  abstract = \t {The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common multivariate statistical model for learning a weighted sparse dependency graph from given data. This graph learning problem can be formulated as a maximum likelihood estimation (MLE) of the precision matrix, subject to Laplacian structural constraints, with a sparsity-inducing penalty term. This paper aims to solve this learning problem accurately and efficiently. First, since the commonly used $\\ell_1$-norm penalty is inappropriate in this setting and may lead to a complete graph, we employ the nonconvex minimax concave penalty (MCP), which promotes sparse solutions with lower estimation bias. Second, as opposed to existing first-order methods for this problem, we develop a second-order proximal Newton approach to obtain an efficient solver, utilizing several algorithmic features, such as using conjugate gradients, preconditioning, and splitting to active/free sets. Numerical experiments demonstrate the advantages of the proposed method in terms of both computational complexity and graph learning accuracy compared to existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/medvedovsky24a/medvedovsky24a.pdf",
        "supp": "",
        "pdf_size": 824095,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10169390983880363722&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5918fe8f18",
        "title": "Efficient Low-Dimensional Compression of Overparameterized Models",
        "site": "https://proceedings.mlr.press/v238/min-kwon24a.html",
        "author": "Soo Min Kwon; Zekai Zhang; Dogyoon Song; Laura Balzano; Qing Qu",
        "abstract": "In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structure of the problem, we observe that our compressed network converges faster than the original network, consistently yielding smaller recovery errors. We substantiate this observation by developing a theory focused on deep matrix factorization. Finally, we empirically demonstrate how our compressed model has the potential to improve the utility of deep nonlinear models. Overall, our algorithm improves the training efficiency by more than 2x, without compromising generalization.",
        "bibtex": "@InProceedings{pmlr-v238-min-kwon24a,\n  title = \t {Efficient Low-Dimensional Compression of Overparameterized Models},\n  author =       {Min Kwon, Soo and Zhang, Zekai and Song, Dogyoon and Balzano, Laura and Qu, Qing},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1009--1017},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/min-kwon24a/min-kwon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/min-kwon24a.html},\n  abstract = \t {In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structure of the problem, we observe that our compressed network converges faster than the original network, consistently yielding smaller recovery errors. We substantiate this observation by developing a theory focused on deep matrix factorization. Finally, we empirically demonstrate how our compressed model has the potential to improve the utility of deep nonlinear models. Overall, our algorithm improves the training efficiency by more than 2x, without compromising generalization.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/min-kwon24a/min-kwon24a.pdf",
        "supp": "",
        "pdf_size": 11032265,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17695099048996541730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University of Michigan; Tsinghua University; University of Michigan; University of Michigan; University of Michigan",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Michigan;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.umich.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UM;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "102583347c",
        "title": "Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent",
        "site": "https://proceedings.mlr.press/v238/moreno24a.html",
        "author": "Bianca M. Moreno; Margaux Bregere; Pierre Gaillard; Nadia Oudjane",
        "abstract": "Many machine learning tasks can be solved by minimizing a convex function of an occupancy measure over the policies that generate them. These include reinforcement learning, imitation learning, among others. This more general paradigm is called the Concave Utility Reinforcement Learning problem (CURL). Since CURL invalidates classical Bellman equations, it requires new algorithms. We introduce MD-CURL, a new algorithm for CURL in a finite horizon Markov decision process. MD-CURL is inspired by mirror descent and uses a non-standard regularization to achieve convergence guarantees and a simple closed-form solution, eliminating the need for computationally expensive projection steps typically found in mirror descent approaches. We then extend CURL to an online learning scenario and present Greedy MD-CURL, a new method adapting MD-CURL to an online, episode-based setting with partially unknown dynamics. Like MD-CURL, the online version Greedy MD-CURL benefits from low computational complexity, while guaranteeing sub-linear or even logarithmic regret, depending on the level of information available on the underlying dynamics.",
        "bibtex": "@InProceedings{pmlr-v238-moreno24a,\n  title = \t {Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent},\n  author =       {Moreno, Bianca M. and Bregere, Margaux and Gaillard, Pierre and Oudjane, Nadia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2206--2214},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/moreno24a/moreno24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/moreno24a.html},\n  abstract = \t {Many machine learning tasks can be solved by minimizing a convex function of an occupancy measure over the policies that generate them. These include reinforcement learning, imitation learning, among others. This more general paradigm is called the Concave Utility Reinforcement Learning problem (CURL). Since CURL invalidates classical Bellman equations, it requires new algorithms. We introduce MD-CURL, a new algorithm for CURL in a finite horizon Markov decision process. MD-CURL is inspired by mirror descent and uses a non-standard regularization to achieve convergence guarantees and a simple closed-form solution, eliminating the need for computationally expensive projection steps typically found in mirror descent approaches. We then extend CURL to an online learning scenario and present Greedy MD-CURL, a new method adapting MD-CURL to an online, episode-based setting with partially unknown dynamics. Like MD-CURL, the online version Greedy MD-CURL benefits from low computational complexity, while guaranteeing sub-linear or even logarithmic regret, depending on the level of information available on the underlying dynamics.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/moreno24a/moreno24a.pdf",
        "supp": "",
        "pdf_size": 1231531,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13054163165265235572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7ca10f5946",
        "title": "Efficient Neural Architecture Design via Capturing Architecture-Performance Joint Distribution",
        "site": "https://proceedings.mlr.press/v238/liu24b.html",
        "author": "Yue Liu; Ziyi Yu; Zitu Liu; Wenjie Tian",
        "abstract": "The relationship between architecture and performance is critical for improving the efficiency of neural architecture design, yet few efforts have been devoted to understanding this relationship between architecture and performance, especially architecture-performance joint distribution. In this paper, we propose Semi-Supervised Generative Adversarial Networks Neural Architecture Design Method or SemiGAN-NAD to capture the architecture-performance joint distribution with few performance labels. It is composed of Bidirectional Transformer of Architecture and Performance (Bi-Arch2Perf) and Neural Architecture Conditional Generation (NACG). Bi-Arch2Perf is developed to learn the joint distribution of architecture and performance from bidirectional conditional distribution through the adversarial training of the discriminator, the architecture generator, and the performance predictor. Then, the incorporation of semi-supervised learning optimizes the construction of Bi-Arch2Perf by utilizing a large amount of architecture information without performance annotation in search space. Based on the learned bidirectional relationship, the performance of architecture is predicted by NACG in high-performance architecture space to efficiently discover well-promising neural architectures. The experimental results on NAS benchmarks demonstrate that SemiGAN-NAD achieves competitive performance with reduced evaluation time compared with the latest NAS methods. Moreover, the high-performance architecture signatures learned by Bi-Arch2Perf are also illustrated in our experiments.",
        "bibtex": "@InProceedings{pmlr-v238-liu24b,\n  title = \t {Efficient Neural Architecture Design via Capturing Architecture-Performance Joint Distribution},\n  author =       {Liu, Yue and Yu, Ziyi and Liu, Zitu and Tian, Wenjie},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1738--1746},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24b/liu24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24b.html},\n  abstract = \t {The relationship between architecture and performance is critical for improving the efficiency of neural architecture design, yet few efforts have been devoted to understanding this relationship between architecture and performance, especially architecture-performance joint distribution. In this paper, we propose Semi-Supervised Generative Adversarial Networks Neural Architecture Design Method or SemiGAN-NAD to capture the architecture-performance joint distribution with few performance labels. It is composed of Bidirectional Transformer of Architecture and Performance (Bi-Arch2Perf) and Neural Architecture Conditional Generation (NACG). Bi-Arch2Perf is developed to learn the joint distribution of architecture and performance from bidirectional conditional distribution through the adversarial training of the discriminator, the architecture generator, and the performance predictor. Then, the incorporation of semi-supervised learning optimizes the construction of Bi-Arch2Perf by utilizing a large amount of architecture information without performance annotation in search space. Based on the learned bidirectional relationship, the performance of architecture is predicted by NACG in high-performance architecture space to efficiently discover well-promising neural architectures. The experimental results on NAS benchmarks demonstrate that SemiGAN-NAD achieves competitive performance with reduced evaluation time compared with the latest NAS methods. Moreover, the high-performance architecture signatures learned by Bi-Arch2Perf are also illustrated in our experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24b/liu24b.pdf",
        "supp": "",
        "pdf_size": 1248638,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6569830969581899449&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "44d513b539",
        "title": "Efficient Quantum Agnostic Improper Learning of Decision Trees",
        "site": "https://proceedings.mlr.press/v238/chatterjee24a.html",
        "author": "Sagnik Chatterjee; Tharrmashastha SAPV; Debajyoti Bera",
        "abstract": "The agnostic setting is the hardest generalization of the PAC model since it is akin to learning with adversarial noise. In this paper, we give a poly $(n, t, 1/\\epsilon)$ quantum algorithm for learning size $t$ decision trees over $n$-bit inputs with uniform marginal over instances, in the agnostic setting, without membership queries (MQ). This is the first algorithm (classical or quantum) for efficiently learning decision trees without MQ. First, we construct a quantum agnostic weak learner by designing a quantum variant of the classical Goldreich-Levin algorithm that works with strongly biased function oracles. Next, we show how to quantize the agnostic boosting algorithm by Kalai and Kanade (2009) to obtain the first efficient quantum agnostic boosting algorithm (that has a polynomial speedup over existing adaptive quantum boosting algorithms). We then use the quantum agnostic boosting algorithm to boost the weak quantum agnostic learner constructed previously to obtain a quantum agnostic learner for decision trees. Using the above framework, we also give quantum decision tree learning algorithms without MQ in weaker noise models.",
        "bibtex": "@InProceedings{pmlr-v238-chatterjee24a,\n  title = \t {Efficient Quantum Agnostic Improper Learning of Decision Trees},\n  author =       {Chatterjee, Sagnik and SAPV, Tharrmashastha and Bera, Debajyoti},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {514--522},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chatterjee24a/chatterjee24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chatterjee24a.html},\n  abstract = \t {The agnostic setting is the hardest generalization of the PAC model since it is akin to learning with adversarial noise. In this paper, we give a poly $(n, t, 1/\\epsilon)$ quantum algorithm for learning size $t$ decision trees over $n$-bit inputs with uniform marginal over instances, in the agnostic setting, without membership queries (MQ). This is the first algorithm (classical or quantum) for efficiently learning decision trees without MQ. First, we construct a quantum agnostic weak learner by designing a quantum variant of the classical Goldreich-Levin algorithm that works with strongly biased function oracles. Next, we show how to quantize the agnostic boosting algorithm by Kalai and Kanade (2009) to obtain the first efficient quantum agnostic boosting algorithm (that has a polynomial speedup over existing adaptive quantum boosting algorithms). We then use the quantum agnostic boosting algorithm to boost the weak quantum agnostic learner constructed previously to obtain a quantum agnostic learner for decision trees. Using the above framework, we also give quantum decision tree learning algorithms without MQ in weaker noise models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chatterjee24a/chatterjee24a.pdf",
        "supp": "",
        "pdf_size": 925930,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4270646654172992505&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b04acbec3b",
        "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems",
        "site": "https://proceedings.mlr.press/v238/jali24a.html",
        "author": "Neharika Jali; Guannan Qu; Weina Wang; Gauri Joshi",
        "abstract": "We consider the problem of efficiently routing jobs that arrive into a central queue to a system of heterogeneous servers. Unlike homogeneous systems, a threshold policy, that routes jobs to the slow server(s) when the queue length exceeds a certain threshold, is known to be optimal for the one-fast-one-slow two-server system. But an optimal policy for the multi-server system is unknown and non-trivial to find. While Reinforcement Learning (RL) has been recognized to have great potential for learning policies in such cases, our problem has an exponentially large state space size, rendering standard RL inefficient. In this work, we propose ACHQ, an efficient policy gradient based algorithm with a low dimensional soft threshold policy parameterization that leverages the underlying queueing structure. We provide stationary-point convergence guarantees for the general case and despite the low-dimensional parameterization prove that ACHQ converges to an approximate global optimum for the special case of two servers. Simulations demonstrate an improvement in expected response time of up to ${\\sim}30%$ over the greedy policy that routes to the fastest available server.",
        "bibtex": "@InProceedings{pmlr-v238-jali24a,\n  title = \t {Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems},\n  author =       {Jali, Neharika and Qu, Guannan and Wang, Weina and Joshi, Gauri},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4177--4185},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jali24a/jali24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jali24a.html},\n  abstract = \t {We consider the problem of efficiently routing jobs that arrive into a central queue to a system of heterogeneous servers. Unlike homogeneous systems, a threshold policy, that routes jobs to the slow server(s) when the queue length exceeds a certain threshold, is known to be optimal for the one-fast-one-slow two-server system. But an optimal policy for the multi-server system is unknown and non-trivial to find. While Reinforcement Learning (RL) has been recognized to have great potential for learning policies in such cases, our problem has an exponentially large state space size, rendering standard RL inefficient. In this work, we propose ACHQ, an efficient policy gradient based algorithm with a low dimensional soft threshold policy parameterization that leverages the underlying queueing structure. We provide stationary-point convergence guarantees for the general case and despite the low-dimensional parameterization prove that ACHQ converges to an approximate global optimum for the special case of two servers. Simulations demonstrate an improvement in expected response time of up to ${\\sim}30%$ over the greedy policy that routes to the fastest available server.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jali24a/jali24a.pdf",
        "supp": "",
        "pdf_size": 910092,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6001076784882570496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c7bb31f31a",
        "title": "Efficient Variational Sequential Information Control",
        "site": "https://proceedings.mlr.press/v238/shen24b.html",
        "author": "Jianwei Shen; Jason Pacheco",
        "abstract": "We develop a family of fast variational methods for sequential control in dynamic settings where an agent is incentivized to maximize information gain. We consider the case of optimal control in continuous nonlinear dynamical systems that prohibit exact evaluation of the mutual information (MI) reward. Our approach couples efficient message-passing inference with variational bounds on the MI objective under Gaussian projections. We also develop a Gaussian mixture approximation that enables exact MI evaluation under constraints on the component covariances. We validate our methodology in nonlinear systems with superior and faster control compared to standard particle-based methods. We show our approach improves the accuracy and efficiency of one-shot robotic learning with intrinsic MI rewards. Furthermore, we demonstrate that our method is applicable to a wider range of contexts, e.g., the active information acquisition problem.",
        "bibtex": "@InProceedings{pmlr-v238-shen24b,\n  title = \t {Efficient Variational Sequential Information Control},\n  author =       {Shen, Jianwei and Pacheco, Jason},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3907--3915},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shen24b/shen24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shen24b.html},\n  abstract = \t {We develop a family of fast variational methods for sequential control in dynamic settings where an agent is incentivized to maximize information gain. We consider the case of optimal control in continuous nonlinear dynamical systems that prohibit exact evaluation of the mutual information (MI) reward. Our approach couples efficient message-passing inference with variational bounds on the MI objective under Gaussian projections. We also develop a Gaussian mixture approximation that enables exact MI evaluation under constraints on the component covariances. We validate our methodology in nonlinear systems with superior and faster control compared to standard particle-based methods. We show our approach improves the accuracy and efficiency of one-shot robotic learning with intrinsic MI rewards. Furthermore, we demonstrate that our method is applicable to a wider range of contexts, e.g., the active information acquisition problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shen24b/shen24b.pdf",
        "supp": "",
        "pdf_size": 1900462,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:oPvut7IvzYgJ:scholar.google.com/&scioq=Efficient+Variational+Sequential+Information+Control&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "University of Arizona, Department of Computer Science; University of Arizona, Department of Computer Science",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Arizona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.arizona.edu",
        "aff_unique_abbr": "UArizona",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f7a9413904",
        "title": "Efficiently Computable Safety Bounds for Gaussian Processes in Active Learning",
        "site": "https://proceedings.mlr.press/v238/tebbe24a.html",
        "author": "J\u00f6rn Tebbe; Christoph Zimmer; Ansgar Steland; Markus Lange-Hegermann; Fabian Mies",
        "abstract": "Active learning of physical systems must commonly respect practical safety constraints, which restricts the exploration of the design space. Gaussian Processes (GPs) and their calibrated uncertainty estimations are widely used for this purpose. In many technical applications the design space is explored via continuous trajectories, along which the safety needs to be assessed. This is particularly challenging for strict safety requirements in GP methods, as it employs computationally expensive Monte Carlo sampling of high quantiles. We address these challenges by providing provable safety bounds based on the adaptively sampled median of the supremum of the posterior GP. Our method significantly reduces the number of samples required for estimating high safety probabilities, resulting in faster evaluation without sacrificing accuracy and exploration speed. The effectiveness of our safe active learning approach is demonstrated through extensive simulations and validated using a real-world engine example.",
        "bibtex": "@InProceedings{pmlr-v238-tebbe24a,\n  title = \t {Efficiently Computable Safety Bounds for {G}aussian Processes in Active Learning},\n  author =       {Tebbe, J\\\"{o}rn and Zimmer, Christoph and Steland, Ansgar and Lange-Hegermann, Markus and Mies, Fabian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1333--1341},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tebbe24a/tebbe24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tebbe24a.html},\n  abstract = \t {Active learning of physical systems must commonly respect practical safety constraints, which restricts the exploration of the design space. Gaussian Processes (GPs) and their calibrated uncertainty estimations are widely used for this purpose. In many technical applications the design space is explored via continuous trajectories, along which the safety needs to be assessed. This is particularly challenging for strict safety requirements in GP methods, as it employs computationally expensive Monte Carlo sampling of high quantiles. We address these challenges by providing provable safety bounds based on the adaptively sampled median of the supremum of the posterior GP. Our method significantly reduces the number of samples required for estimating high safety probabilities, resulting in faster evaluation without sacrificing accuracy and exploration speed. The effectiveness of our safe active learning approach is demonstrated through extensive simulations and validated using a real-world engine example.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tebbe24a/tebbe24a.pdf",
        "supp": "",
        "pdf_size": 1119977,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11673615227001924952&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "OWL University of Applied Sciences and Arts; Bosch Center for Artificial Intelligence; RWTH Aachen University; OWL University of Applied Sciences and Arts; TU Delft",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "OWL University of Applied Sciences and Arts;Bosch Center for Artificial Intelligence;RWTH Aachen University;Delft University of Technology",
        "aff_unique_dep": ";Center for Artificial Intelligence;;",
        "aff_unique_url": "https://www.owl.hs '/',\n  \"abbr\": \";https://www.bosch-ai.com;https://www.rwth-aachen.de;https://www.tudelft.nl",
        "aff_unique_abbr": ";BCAI;RWTH;TU Delft",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Aachen;Delft",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "c77428011d",
        "title": "Electronic Medical Records Assisted Digital Clinical Trial Design",
        "site": "https://proceedings.mlr.press/v238/ruan24a.html",
        "author": "Xinrui Ruan; Jingshen Wang; Yingfei Wang; Waverly Wei",
        "abstract": "Randomized controlled trials (RCTs) are gold standards for assessing intervention efficacy. Yet, generalizing evidence from classical RCTs can be challenging and sometimes problematic due to their limited external validity under stringent eligibility criteria and inadequate statistical power resulting from limited sample sizes under budgetary constraints. \"Digital clinical trial,\" which utilizes digital technology and electronic medical records (EMRs) to expand eligibility criteria and enhance data collection efficiency, offers a promising concept for solving the above-mentioned conundrums encountered in classical RCTs. In this paper, we propose two novel digital clinical trial design strategies assisted by EMRs collected from diverse patient populations. On the one hand, leveraging digital technologies, our design strategies adaptively modify both the eligibility criteria and treatment assignment mechanism to enhance data collection efficiency. As a result, evidence gathered from our design can possess greater statistical power. On the other hand, since EMRs capture diverse patient populations and provide large sample sizes, our design not only broadens the trial\u2019s eligibility criteria but also enhances its statistical power, enabling us to collect more generalizable evidence with boosted statistical power for evaluating intervention efficacy than classical RCTs. We demonstrate the validity and merit of the proposed designs with detailed theoretical investigation, simulation studies, and a synthetic case study.",
        "bibtex": "@InProceedings{pmlr-v238-ruan24a,\n  title = \t {Electronic Medical Records Assisted Digital Clinical Trial Design},\n  author =       {Ruan, Xinrui and Wang, Jingshen and Wang, Yingfei and Wei, Waverly},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2836--2844},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ruan24a/ruan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ruan24a.html},\n  abstract = \t {Randomized controlled trials (RCTs) are gold standards for assessing intervention efficacy. Yet, generalizing evidence from classical RCTs can be challenging and sometimes problematic due to their limited external validity under stringent eligibility criteria and inadequate statistical power resulting from limited sample sizes under budgetary constraints. \"Digital clinical trial,\" which utilizes digital technology and electronic medical records (EMRs) to expand eligibility criteria and enhance data collection efficiency, offers a promising concept for solving the above-mentioned conundrums encountered in classical RCTs. In this paper, we propose two novel digital clinical trial design strategies assisted by EMRs collected from diverse patient populations. On the one hand, leveraging digital technologies, our design strategies adaptively modify both the eligibility criteria and treatment assignment mechanism to enhance data collection efficiency. As a result, evidence gathered from our design can possess greater statistical power. On the other hand, since EMRs capture diverse patient populations and provide large sample sizes, our design not only broadens the trial\u2019s eligibility criteria but also enhances its statistical power, enabling us to collect more generalizable evidence with boosted statistical power for evaluating intervention efficacy than classical RCTs. We demonstrate the validity and merit of the proposed designs with detailed theoretical investigation, simulation studies, and a synthetic case study.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ruan24a/ruan24a.pdf",
        "supp": "",
        "pdf_size": 565056,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17575635871625541478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "288741ebc9",
        "title": "Emergent specialization from participation dynamics and multi-learner retraining",
        "site": "https://proceedings.mlr.press/v238/dean24a.html",
        "author": "Sarah Dean; Mihaela Curmei; Lillian Ratliff; Jamie Morgenstern; Maryam Fazel",
        "abstract": "Numerous online services are data-driven: the behavior of users affects the system\u2019s parameters, and the system\u2019s parameters affect the users\u2019 experience of the service, which in turn affects the way users may interact with the system. For example, people may choose to use a service only for tasks that already works well, or they may choose to switch to a different service. These adaptations influence the ability of a system to learn about a population of users and tasks in order to improve its performance broadly. In this work, we analyze a class of such dynamics\u2014where users allocate their participation amongst services to reduce the individual risk they experience, and services update their model parameters to reduce the service\u2019s risk on their current user population. We refer to these dynamics as \\emph{risk-reducing}, which cover a broad class of common model updates including gradient descent and multiplicative weights. For this general class of dynamics, we show that asymptotically stable equilibria are always segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss with a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data.",
        "bibtex": "@InProceedings{pmlr-v238-dean24a,\n  title = \t {Emergent specialization from participation dynamics and multi-learner retraining},\n  author =       {Dean, Sarah and Curmei, Mihaela and Ratliff, Lillian and Morgenstern, Jamie and Fazel, Maryam},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {343--351},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dean24a/dean24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dean24a.html},\n  abstract = \t {Numerous online services are data-driven: the behavior of users affects the system\u2019s parameters, and the system\u2019s parameters affect the users\u2019 experience of the service, which in turn affects the way users may interact with the system. For example, people may choose to use a service only for tasks that already works well, or they may choose to switch to a different service. These adaptations influence the ability of a system to learn about a population of users and tasks in order to improve its performance broadly. In this work, we analyze a class of such dynamics\u2014where users allocate their participation amongst services to reduce the individual risk they experience, and services update their model parameters to reduce the service\u2019s risk on their current user population. We refer to these dynamics as \\emph{risk-reducing}, which cover a broad class of common model updates including gradient descent and multiplicative weights. For this general class of dynamics, we show that asymptotically stable equilibria are always segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss with a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dean24a/dean24a.pdf",
        "supp": "",
        "pdf_size": 1956941,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3793319221963846372&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Cornell University; University of California Berkeley; University of Washington; University of Washington; University of Washington",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Cornell University;University of California, Berkeley;University of Washington",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cornell.edu;https://www.berkeley.edu;https://www.washington.edu",
        "aff_unique_abbr": "Cornell;UC Berkeley;UW",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ff92800a95",
        "title": "End-to-end Feature Selection Approach for Learning Skinny Trees",
        "site": "https://proceedings.mlr.press/v238/ibrahim24a.html",
        "author": "Shibal Ibrahim; Kayhan Behdin; Rahul Mazumder",
        "abstract": "We propose a new optimization-based approach for feature selection in tree ensembles, an important problem in statistics and machine learning. Popular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests support feature selection post-training based on feature importance scores, while very popular, they are known to have drawbacks. We propose Skinny Trees: an end-to-end toolkit for feature selection in tree ensembles where we train a tree ensemble while controlling the number of selected features. Our optimization-based approach learns an ensemble of differentiable trees, and simultaneously performs feature selection using a grouped $\\ell_0$-regularizer. We use first-order methods for optimization and present convergence guarantees for our approach. We use a dense-to-sparse regularization scheduling scheme that can lead to more expressive and sparser tree ensembles. On 15 synthetic and real-world datasets, Skinny Trees can achieve $1.5{\\times}$\u2013$620{\\times}$ feature compression rates, leading up to $10{\\times}$ faster inference over dense trees, without any loss in performance. Skinny Trees lead to superior feature selection than many existing toolkits e.g., in terms of AUC performance for 25% feature budget, Skinny Trees outperforms LightGBM by 10.2% (up to 37.7%), and Random Forests by 3% (up to 12.5%).",
        "bibtex": "@InProceedings{pmlr-v238-ibrahim24a,\n  title = \t {End-to-end Feature Selection Approach for Learning Skinny Trees},\n  author =       {Ibrahim, Shibal and Behdin, Kayhan and Mazumder, Rahul},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2863--2871},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ibrahim24a/ibrahim24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ibrahim24a.html},\n  abstract = \t {We propose a new optimization-based approach for feature selection in tree ensembles, an important problem in statistics and machine learning. Popular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests support feature selection post-training based on feature importance scores, while very popular, they are known to have drawbacks. We propose Skinny Trees: an end-to-end toolkit for feature selection in tree ensembles where we train a tree ensemble while controlling the number of selected features. Our optimization-based approach learns an ensemble of differentiable trees, and simultaneously performs feature selection using a grouped $\\ell_0$-regularizer. We use first-order methods for optimization and present convergence guarantees for our approach. We use a dense-to-sparse regularization scheduling scheme that can lead to more expressive and sparser tree ensembles. On 15 synthetic and real-world datasets, Skinny Trees can achieve $1.5{\\times}$\u2013$620{\\times}$ feature compression rates, leading up to $10{\\times}$ faster inference over dense trees, without any loss in performance. Skinny Trees lead to superior feature selection than many existing toolkits e.g., in terms of AUC performance for 25% feature budget, Skinny Trees outperforms LightGBM by 10.2% (up to 37.7%), and Random Forests by 3% (up to 12.5%).}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ibrahim24a/ibrahim24a.pdf",
        "supp": "",
        "pdf_size": 972044,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8796947122809203116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "MIT; MIT; MIT",
        "aff_domain": "mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "35773cb3cf",
        "title": "Enhancing Distributional Stability among Sub-populations",
        "site": "https://proceedings.mlr.press/v238/liu24c.html",
        "author": "Jiashuo Liu; Jiayun Wu; Jie Peng; Xiaoyu Wu; Yang Zheng; Bo Li; Peng Cui",
        "abstract": "Enhancing the stability of machine learning algorithms under distributional shifts is at the heart of the Out-of-Distribution (OOD) Generalization problem. Derived from causal learning, recent works of invariant learning pursue strict invariance with multiple training environments. Although intuitively reasonable, strong assumptions on the availability and quality of environments are made to learn the strict invariance property. In this work, we come up with the \u201cdistributional stability\" notion to mitigate such limitations. It quantifies the stability of prediction mechanisms among sub-populations down to a prescribed scale. Based on this, we propose the learnability assumption and derive the generalization error bound under distribution shifts. Inspired by theoretical analyses, we propose our novel stable risk minimization (SRM) algorithm to enhance the model\u2019s stability w.r.t. shifts in prediction mechanisms (Y|X-shifts). Experimental results are consistent with our intuition and validate the effectiveness of our algorithm. The code can be found at https://github.com/LJSthu/SRM.",
        "bibtex": "@InProceedings{pmlr-v238-liu24c,\n  title = \t {Enhancing Distributional Stability among Sub-populations},\n  author =       {Liu, Jiashuo and Wu, Jiayun and Peng, Jie and Wu, Xiaoyu and Zheng, Yang and Li, Bo and Cui, Peng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2125--2133},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24c/liu24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24c.html},\n  abstract = \t {Enhancing the stability of machine learning algorithms under distributional shifts is at the heart of the Out-of-Distribution (OOD) Generalization problem. Derived from causal learning, recent works of invariant learning pursue strict invariance with multiple training environments. Although intuitively reasonable, strong assumptions on the availability and quality of environments are made to learn the strict invariance property. In this work, we come up with the \u201cdistributional stability\" notion to mitigate such limitations. It quantifies the stability of prediction mechanisms among sub-populations down to a prescribed scale. Based on this, we propose the learnability assumption and derive the generalization error bound under distribution shifts. Inspired by theoretical analyses, we propose our novel stable risk minimization (SRM) algorithm to enhance the model\u2019s stability w.r.t. shifts in prediction mechanisms (Y|X-shifts). Experimental results are consistent with our intuition and validate the effectiveness of our algorithm. The code can be found at https://github.com/LJSthu/SRM.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24c/liu24c.pdf",
        "supp": "",
        "pdf_size": 1268923,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15410687760331796622&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Technology, Tsinghua University; Department of Computer Science and Technology, Tsinghua University; Department of Computer Science and Technology, Tsinghua University; RAMS Lab, Huawei Technologies Co Ltd; RAMS Lab, Huawei Technologies Co Ltd; School of Economics and Management, Tsinghua University; Department of Computer Science and Technology, Tsinghua University",
        "aff_domain": "gmail.com; ; ; ; ; ;tsinghua.edu.cn",
        "email": "gmail.com; ; ; ; ; ;tsinghua.edu.cn",
        "github": "https://github.com/LJSthu/SRM",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Tsinghua University;Huawei",
        "aff_unique_dep": "Department of Computer Science and Technology;RAMS Lab",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "THU;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "d8adb70480",
        "title": "Enhancing Hypergradients Estimation: A Study of Preconditioning and Reparameterization",
        "site": "https://proceedings.mlr.press/v238/ye24a.html",
        "author": "Zhenzhang Ye; Gabriel Peyr\u00e9; Daniel Cremers; Pierre Ablin",
        "abstract": "Bilevel optimization aims to optimize an outer objective function that depends on the solution to an inner optimization problem. It is routinely used in Machine Learning, notably for hyperparameter tuning. The conventional method to compute the so-called hypergradient of the outer problem is to use the Implicit Function Theorem (IFT). As a function of the error of the inner problem resolution, we study the error of the IFT method. We analyze two strategies to reduce this error: preconditioning the IFT formula and reparameterizing the inner problem. We give a detailed account of the impact of these two modifications on the error, highlighting the role played by higher-order derivatives of the functionals at stake. Our theoretical findings explain when super efficiency, namely reaching an error on the hypergradient that depends quadratically on the error on the inner problem, is achievable and compare the two approaches when this is impossible. Numerical evaluations on hyperparameter tuning for regression problems substantiate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-ye24a,\n  title = \t {Enhancing Hypergradients Estimation: A Study of Preconditioning and Reparameterization},\n  author =       {Ye, Zhenzhang and Peyr\\'{e}, Gabriel and Cremers, Daniel and Ablin, Pierre},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {955--963},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ye24a/ye24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ye24a.html},\n  abstract = \t {Bilevel optimization aims to optimize an outer objective function that depends on the solution to an inner optimization problem. It is routinely used in Machine Learning, notably for hyperparameter tuning. The conventional method to compute the so-called hypergradient of the outer problem is to use the Implicit Function Theorem (IFT). As a function of the error of the inner problem resolution, we study the error of the IFT method. We analyze two strategies to reduce this error: preconditioning the IFT formula and reparameterizing the inner problem. We give a detailed account of the impact of these two modifications on the error, highlighting the role played by higher-order derivatives of the functionals at stake. Our theoretical findings explain when super efficiency, namely reaching an error on the hypergradient that depends quadratically on the error on the inner problem, is achievable and compare the two approaches when this is impossible. Numerical evaluations on hyperparameter tuning for regression problems substantiate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ye24a/ye24a.pdf",
        "supp": "",
        "pdf_size": 1362491,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9175393567361352855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Technical University of Munich+Munich Center for Machine Learning; CNRS, ENS - PSL University; Technical University of Munich+Munich Center for Machine Learning; Apple",
        "aff_domain": "tum.de;ens.fr;tum.de;apple.com",
        "email": "tum.de;ens.fr;tum.de;apple.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;0+1;3",
        "aff_unique_norm": "Technical University of Munich;Munich Center for Machine Learning;CNRS;Apple",
        "aff_unique_dep": ";Center for Machine Learning;;Apple Inc.",
        "aff_unique_url": "https://www.tum.de;https://www.munich-center-for-machine-learning.de;https://www.cnrs.fr;https://www.apple.com",
        "aff_unique_abbr": "TUM;;CNRS;Apple",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;1;0+0;2",
        "aff_country_unique": "Germany;France;United States"
    },
    {
        "id": "0d1004ef5c",
        "title": "Enhancing In-context Learning via Linear Probe Calibration",
        "site": "https://proceedings.mlr.press/v238/abbas24a.html",
        "author": "Momin Abbas; Yi Zhou; Parikshit Ram; Nathalie Baracaldo; Horst Samulowitz; Theodoros Salonidis; Tianyi Chen",
        "abstract": "In-context learning (ICL) is a new paradigm for natural language processing that utilizes Generative Pre-trained Transformer (GPT)-like models. This approach uses prompts that include in-context demonstrations to generate the corresponding output for a new query input. However, applying ICL in real cases does not scale with the number of samples, and lacks robustness to different prompt templates and demonstration permutations. In this paper, we first show that GPT-like models using ICL result in unreliable predictions based on a new metric based on Shannon entropy. Then, to solve this problem, we propose a new technique called the Linear Probe Calibration (LinC), a method that calibrates the model\u2019s output probabilities, resulting in reliable predictions and improved performance, while requiring only minimal additional samples (as few as five labeled data samples). LinC significantly enhances the ICL test performance of GPT models on various benchmark datasets, with an average improvement of up to 21%, and up to a 50% improvement in some cases, and significantly boosts the performance of PEFT methods, especially in the low resource regime. Moreover, LinC achieves lower expected calibration error, and is highly robust to varying label proportions, prompt templates, and demonstration permutations.",
        "bibtex": "@InProceedings{pmlr-v238-abbas24a,\n  title = \t {Enhancing In-context Learning via Linear Probe Calibration},\n  author =       {Abbas, Momin and Zhou, Yi and Ram, Parikshit and Baracaldo, Nathalie and Samulowitz, Horst and Salonidis, Theodoros and Chen, Tianyi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {307--315},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/abbas24a/abbas24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/abbas24a.html},\n  abstract = \t {In-context learning (ICL) is a new paradigm for natural language processing that utilizes Generative Pre-trained Transformer (GPT)-like models. This approach uses prompts that include in-context demonstrations to generate the corresponding output for a new query input. However, applying ICL in real cases does not scale with the number of samples, and lacks robustness to different prompt templates and demonstration permutations. In this paper, we first show that GPT-like models using ICL result in unreliable predictions based on a new metric based on Shannon entropy. Then, to solve this problem, we propose a new technique called the Linear Probe Calibration (LinC), a method that calibrates the model\u2019s output probabilities, resulting in reliable predictions and improved performance, while requiring only minimal additional samples (as few as five labeled data samples). LinC significantly enhances the ICL test performance of GPT models on various benchmark datasets, with an average improvement of up to 21%, and up to a 50% improvement in some cases, and significantly boosts the performance of PEFT methods, especially in the low resource regime. Moreover, LinC achieves lower expected calibration error, and is highly robust to varying label proportions, prompt templates, and demonstration permutations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/abbas24a/abbas24a.pdf",
        "supp": "",
        "pdf_size": 3645864,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6742468676093118870&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a1dffcc849",
        "title": "Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels",
        "site": "https://proceedings.mlr.press/v238/long24a.html",
        "author": "Da Long; Wei Xing; Aditi Krishnapriyan; Robert Kirby; Shandian Zhe; Michael W. Mahoney",
        "abstract": "Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity and noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior \u2014 an ideal Bayesian sparse distribution \u2014 for effective operator selection and uncertainty quantification. We develop an expectation-propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we place the function values on a mesh and induce a Kronecker product construction, and we use tensor algebra to enable efficient computation and optimization. We show the advantages of KBASS on a list of benchmark ODE and PDE discovery tasks. The code is available at \\url{https://github.com/long-da/KBASS}.",
        "bibtex": "@InProceedings{pmlr-v238-long24a,\n  title = \t {Equation Discovery with {B}ayesian Spike-and-Slab Priors and Efficient Kernels},\n  author =       {Long, Da and Xing, Wei and Krishnapriyan, Aditi and Kirby, Robert and Zhe, Shandian and W. Mahoney, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2413--2421},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/long24a/long24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/long24a.html},\n  abstract = \t {Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity and noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior \u2014 an ideal Bayesian sparse distribution \u2014 for effective operator selection and uncertainty quantification. We develop an expectation-propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we place the function values on a mesh and induce a Kronecker product construction, and we use tensor algebra to enable efficient computation and optimization. We show the advantages of KBASS on a list of benchmark ODE and PDE discovery tasks. The code is available at \\url{https://github.com/long-da/KBASS}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/long24a/long24a.pdf",
        "supp": "",
        "pdf_size": 2974446,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14459082705187697702&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Utah; The University of Sheffield; University of California, Berkeley; The University of Utah; The University of Utah; University of California, Berkeley + Lawrence Berkeley National Laboratory + International Computer Science Institute",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "https://github.com/long-da/KBASS",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0;2+3+4",
        "aff_unique_norm": "University of Utah;University of Sheffield;University of California, Berkeley;Lawrence Berkeley National Laboratory;International Computer Science Institute",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.utah.edu;https://www.sheffield.ac.uk;https://www.berkeley.edu;https://www.lbl.gov;https://www.icsi.berkeley.edu/",
        "aff_unique_abbr": "Utah;Sheffield;UC Berkeley;LBNL;ICSI",
        "aff_campus_unique_index": "1;1+1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;0;0;0;0+0+0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "20d34305c8",
        "title": "Equivalence Testing: The Power of Bounded Adaptivity",
        "site": "https://proceedings.mlr.press/v238/chakraborty24b.html",
        "author": "Diptarka Chakraborty; Sourav Chakraborty; Gunjan Kumar; Kuldeep Meel",
        "abstract": "Equivalence testing, a fundamental problem in the field of distribution testing, seeks to infer if two unknown distributions on $[n]$ are the same or far apart in the total variation distance. Conditional sampling has emerged as a powerful query model and has been investigated by theoreticians and practitioners alike, leading to the design of optimal algorithms albeit in a sequential setting (also referred to as adaptive tester). Given the profound impact of parallel computing over the past decades, there has been a strong desire to design algorithms that enable high parallelization. Despite significant algorithmic advancements over the last decade, parallelizable techniques (also termed non-adaptive testers) have $\\tilde{O}(\\log^{12}n)$ query complexity, a prohibitively large complexity to be of practical usage. Therefore, the primary challenge is whether it is possible to design algorithms that enable high parallelization while achieving efficient query complexity. Our work provides an affirmative answer to the aforementioned challenge: we present a highly parallelizable tester with a query complexity of $\\tilde{O}(\\log n)$, achieved through a single round of adaptivity, marking a significant stride towards harmonizing parallelizability and efficiency in equivalence testing.",
        "bibtex": "@InProceedings{pmlr-v238-chakraborty24b,\n  title = \t {Equivalence Testing: The Power of Bounded Adaptivity},\n  author =       {Chakraborty, Diptarka and Chakraborty, Sourav and Kumar, Gunjan and Meel, Kuldeep},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3592--3600},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chakraborty24b/chakraborty24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chakraborty24b.html},\n  abstract = \t {Equivalence testing, a fundamental problem in the field of distribution testing, seeks to infer if two unknown distributions on $[n]$ are the same or far apart in the total variation distance. Conditional sampling has emerged as a powerful query model and has been investigated by theoreticians and practitioners alike, leading to the design of optimal algorithms albeit in a sequential setting (also referred to as adaptive tester). Given the profound impact of parallel computing over the past decades, there has been a strong desire to design algorithms that enable high parallelization. Despite significant algorithmic advancements over the last decade, parallelizable techniques (also termed non-adaptive testers) have $\\tilde{O}(\\log^{12}n)$ query complexity, a prohibitively large complexity to be of practical usage. Therefore, the primary challenge is whether it is possible to design algorithms that enable high parallelization while achieving efficient query complexity. Our work provides an affirmative answer to the aforementioned challenge: we present a highly parallelizable tester with a query complexity of $\\tilde{O}(\\log n)$, achieved through a single round of adaptivity, marking a significant stride towards harmonizing parallelizability and efficiency in equivalence testing.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chakraborty24b/chakraborty24b.pdf",
        "supp": "",
        "pdf_size": 386568,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12424062817664838011&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "31e0e562dc",
        "title": "Equivariant bootstrapping for uncertainty quantification in imaging inverse problems",
        "site": "https://proceedings.mlr.press/v238/pereyra24a.html",
        "author": "Marcelo Pereyra; Juli\u00e1n Tachella",
        "abstract": "Scientific imaging problems are often severely ill-posed and hence have significant intrinsic uncertainty. Accurately quantifying the uncertainty in the solutions to such problems is therefore critical for the rigorous interpretation of experimental results as well as for reliably using the reconstructed images as scientific evidence. Unfortunately, existing imaging methods are unable to quantify the uncertainty in the reconstructed images in a way that is robust to experiment replications. This paper presents a new uncertainty quantification methodology based on an equivariant formulation of the parametric bootstrap algorithm that leverages symmetries and invariance properties commonly encountered in imaging problems. Additionally, the proposed methodology is general and can be easily applied with any image reconstruction technique, including unsupervised training strategies that can be trained from observed data alone, thus enabling uncertainty quantification in situations where there is no ground truth data available. We demonstrate the proposed approach with a series of experiments and comparisons with alternative state-of-the-art uncertainty quantification strategies. In all our experiments, the proposed equivariant bootstrap delivers remarkably accurate high-dimensional confidence regions and outperforms the competing approaches in terms of estimation accuracy, uncertainty quantification accuracy, and computing time. These empirical findings are supported by a detailed theoretical analysis of equivariant bootstrap for linear estimators.",
        "bibtex": "@InProceedings{pmlr-v238-pereyra24a,\n  title = \t {Equivariant bootstrapping for uncertainty quantification in imaging inverse problems},\n  author =       {Pereyra, Marcelo and Tachella, Juli\\'{a}n},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4141--4149},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pereyra24a/pereyra24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pereyra24a.html},\n  abstract = \t {Scientific imaging problems are often severely ill-posed and hence have significant intrinsic uncertainty. Accurately quantifying the uncertainty in the solutions to such problems is therefore critical for the rigorous interpretation of experimental results as well as for reliably using the reconstructed images as scientific evidence. Unfortunately, existing imaging methods are unable to quantify the uncertainty in the reconstructed images in a way that is robust to experiment replications. This paper presents a new uncertainty quantification methodology based on an equivariant formulation of the parametric bootstrap algorithm that leverages symmetries and invariance properties commonly encountered in imaging problems. Additionally, the proposed methodology is general and can be easily applied with any image reconstruction technique, including unsupervised training strategies that can be trained from observed data alone, thus enabling uncertainty quantification in situations where there is no ground truth data available. We demonstrate the proposed approach with a series of experiments and comparisons with alternative state-of-the-art uncertainty quantification strategies. In all our experiments, the proposed equivariant bootstrap delivers remarkably accurate high-dimensional confidence regions and outperforms the competing approaches in terms of estimation accuracy, uncertainty quantification accuracy, and computing time. These empirical findings are supported by a detailed theoretical analysis of equivariant bootstrap for linear estimators.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pereyra24a/pereyra24a.pdf",
        "supp": "",
        "pdf_size": 12475931,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1797296671960801866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Laboratoire de Physique, CNRS & ENS de Lyon; Heriot-Watt University & Maxwell Institute for Mathematical Sciences",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "CNRS & ENS de Lyon;Heriot-Watt University",
        "aff_unique_dep": "Laboratoire de Physique;Maxwell Institute for Mathematical Sciences",
        "aff_unique_url": "https://www.ens-lyon.fr;https://www.hw.ac.uk",
        "aff_unique_abbr": ";HWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "41437c129d",
        "title": "Error bounds for any regression model using Gaussian processes with gradient information",
        "site": "https://proceedings.mlr.press/v238/savvides24a.html",
        "author": "Rafael Savvides; Hoang Phuc Hau Luu; Kai Puolam\u00e4ki",
        "abstract": "We provide an upper bound for the expected quadratic loss on new data for any regression model. We derive the bound by modelling the underlying function by a Gaussian process (GP). Instead of a single kernel or family of kernels of the same form, we consider all GPs with translation-invariant and continuously twice differentiable kernels having a bounded signal variance and prior covariance of the gradient. To obtain a bound for the expected posterior loss, we present bounds for the posterior variance and squared bias. The squared bias bound depends on the regression model used, which can be arbitrary and not based on GPs. The bounds scale well with data size, in contrast to computing the GP posterior by a Cholesky factorisation of a large matrix. More importantly, our bounds do not require strong prior knowledge as we do not specify the exact kernel form. We validate our theoretical findings by numerical experiments and show that the bounds have applications in uncertainty estimation and concept drift detection.",
        "bibtex": "@InProceedings{pmlr-v238-savvides24a,\n  title = \t {Error bounds for any regression model using {G}aussian processes with gradient information},\n  author =       {Savvides, Rafael and Phuc Hau Luu, Hoang and Puolam\\\"{a}ki, Kai},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {397--405},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/savvides24a/savvides24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/savvides24a.html},\n  abstract = \t {We provide an upper bound for the expected quadratic loss on new data for any regression model. We derive the bound by modelling the underlying function by a Gaussian process (GP). Instead of a single kernel or family of kernels of the same form, we consider all GPs with translation-invariant and continuously twice differentiable kernels having a bounded signal variance and prior covariance of the gradient. To obtain a bound for the expected posterior loss, we present bounds for the posterior variance and squared bias. The squared bias bound depends on the regression model used, which can be arbitrary and not based on GPs. The bounds scale well with data size, in contrast to computing the GP posterior by a Cholesky factorisation of a large matrix. More importantly, our bounds do not require strong prior knowledge as we do not specify the exact kernel form. We validate our theoretical findings by numerical experiments and show that the bounds have applications in uncertainty estimation and concept drift detection.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/savvides24a/savvides24a.pdf",
        "supp": "",
        "pdf_size": 6887874,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1403522618508005850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e6b45cb78f",
        "title": "Escaping Saddle Points in Heterogeneous Federated Learning via Distributed SGD with Communication Compression",
        "site": "https://proceedings.mlr.press/v238/chen24d.html",
        "author": "Sijin Chen; Zhize Li; Yuejie Chi",
        "abstract": "We consider the problem of finding second-order stationary points in the optimization of heterogeneous federated learning (FL). Previous works in FL mostly focus on first-order convergence guarantees, which do not rule out the scenario of unstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve communication efficiency without compensating the learning accuracy, especially when local data are highly heterogeneous across different clients. Given this, we propose a novel algorithm PowerEF-SGD that only communicates compressed information via a novel error-feedback scheme. To our knowledge, PowerEF-SGD is the first distributed and compressed SGD algorithm that provably escapes saddle points in heterogeneous FL without any data homogeneity assumptions. In particular, PowerEF-SGD improves to second-order stationary points after visiting first-order (possibly saddle) points, using additional gradient queries and communication rounds only of almost the same order required by first-order convergence, and the convergence rate shows a linear-speedup pattern in terms of the number of workers. Our theory improves/recovers previous results, while extending to much more tolerant settings on the local data. Numerical experiments are provided to complement the theory.",
        "bibtex": "@InProceedings{pmlr-v238-chen24d,\n  title = \t {Escaping Saddle Points in Heterogeneous Federated Learning via Distributed {SGD} with Communication Compression},\n  author =       {Chen, Sijin and Li, Zhize and Chi, Yuejie},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2701--2709},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24d/chen24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24d.html},\n  abstract = \t {We consider the problem of finding second-order stationary points in the optimization of heterogeneous federated learning (FL). Previous works in FL mostly focus on first-order convergence guarantees, which do not rule out the scenario of unstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve communication efficiency without compensating the learning accuracy, especially when local data are highly heterogeneous across different clients. Given this, we propose a novel algorithm PowerEF-SGD that only communicates compressed information via a novel error-feedback scheme. To our knowledge, PowerEF-SGD is the first distributed and compressed SGD algorithm that provably escapes saddle points in heterogeneous FL without any data homogeneity assumptions. In particular, PowerEF-SGD improves to second-order stationary points after visiting first-order (possibly saddle) points, using additional gradient queries and communication rounds only of almost the same order required by first-order convergence, and the convergence rate shows a linear-speedup pattern in terms of the number of workers. Our theory improves/recovers previous results, while extending to much more tolerant settings on the local data. Numerical experiments are provided to complement the theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24d/chen24d.pdf",
        "supp": "",
        "pdf_size": 2707677,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9104518049037972188&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "09e1277db1",
        "title": "Estimating treatment effects from single-arm trials via latent-variable modeling",
        "site": "https://proceedings.mlr.press/v238/haussmann24a.html",
        "author": "Manuel Haussmann; Tran Minh Son Le; Viivi Halla-aho; Samu Kurki; Jussi Leinonen; Miika Koskinen; Samuel Kaski; Harri L\u00e4hdesm\u00e4ki",
        "abstract": "Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for {\\em (i)} patient matching if treatment outcomes are not available for the treatment group, or for {\\em (ii)} direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT study and real-world electronic health records. Compared to previous methods, our results show improved performance both for direct treatment effect estimation as well as for effect estimation via patient matching.",
        "bibtex": "@InProceedings{pmlr-v238-haussmann24a,\n  title = \t {Estimating treatment effects from single-arm trials via latent-variable modeling},\n  author =       {Haussmann, Manuel and Minh Son Le, Tran and Halla-aho, Viivi and Kurki, Samu and Leinonen, Jussi and Koskinen, Miika and Kaski, Samuel and L\\\"{a}hdesm\\\"{a}ki, Harri},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2926--2934},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/haussmann24a/haussmann24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/haussmann24a.html},\n  abstract = \t {Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for {\\em (i)} patient matching if treatment outcomes are not available for the treatment group, or for {\\em (ii)} direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT study and real-world electronic health records. Compared to previous methods, our results show improved performance both for direct treatment effect estimation as well as for effect estimation via patient matching.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/haussmann24a/haussmann24a.pdf",
        "supp": "",
        "pdf_size": 729882,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13721970239635717442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "061ea75c40",
        "title": "Estimation of partially known Gaussian graphical models with score-based structural priors",
        "site": "https://proceedings.mlr.press/v238/sevilla24a.html",
        "author": "Mart\u00edn Sevilla; Antonio G. Marques; Santiago Segarra",
        "abstract": "We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or maximum a posteriori approach using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments in different setups demonstrate the benefits of our approach.",
        "bibtex": "@InProceedings{pmlr-v238-sevilla24a,\n  title = \t {Estimation of partially known {G}aussian graphical models with score-based structural priors},\n  author =       {Sevilla, Mart\\'{i}n and G. Marques, Antonio and Segarra, Santiago},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1558--1566},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sevilla24a/sevilla24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sevilla24a.html},\n  abstract = \t {We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or maximum a posteriori approach using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments in different setups demonstrate the benefits of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sevilla24a/sevilla24a.pdf",
        "supp": "",
        "pdf_size": 624576,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=553514154060660649&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b7014ffbf4",
        "title": "Ethics in Action: Training Reinforcement Learning Agents for Moral Decision-making In Text-based Adventure Games",
        "site": "https://proceedings.mlr.press/v238/li24i.html",
        "author": "Weichen Li; Rati Devidze; Waleed Mustafa; Sophie Fellenz",
        "abstract": "Reinforcement Learning (RL) has demonstrated its potential in solving goal-oriented sequential tasks. However, with the increasing capabilities of RL agents, ensuring morally responsible agent behavior is becoming a pressing concern. Previous approaches have included moral considerations by statically assigning a moral score to each action at runtime. However, these methods do not account for the potential moral value of future states when evaluating immoral actions. This limits the ability to find trade-offs between different aspects of moral behavior and the utility of the action. In this paper, we aim to factor in moral scores by adding a constraint to the RL objective that is incorporated during training, thereby dynamically adapting the policy function. By combining Lagrangian optimization and meta-gradient learning, we develop an RL method that is able to find a trade-off between immoral behavior and performance in the decision-making process.",
        "bibtex": "@InProceedings{pmlr-v238-li24i,\n  title = \t {Ethics in Action: Training Reinforcement Learning Agents for Moral Decision-making In Text-based Adventure Games},\n  author =       {Li, Weichen and Devidze, Rati and Mustafa, Waleed and Fellenz, Sophie},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1954--1962},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24i/li24i.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24i.html},\n  abstract = \t {Reinforcement Learning (RL) has demonstrated its potential in solving goal-oriented sequential tasks. However, with the increasing capabilities of RL agents, ensuring morally responsible agent behavior is becoming a pressing concern. Previous approaches have included moral considerations by statically assigning a moral score to each action at runtime. However, these methods do not account for the potential moral value of future states when evaluating immoral actions. This limits the ability to find trade-offs between different aspects of moral behavior and the utility of the action. In this paper, we aim to factor in moral scores by adding a constraint to the RL objective that is incorporated during training, thereby dynamically adapting the policy function. By combining Lagrangian optimization and meta-gradient learning, we develop an RL method that is able to find a trade-off between immoral behavior and performance in the decision-making process.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24i/li24i.pdf",
        "supp": "",
        "pdf_size": 2340478,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14382478935803971641&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c962fafcb2",
        "title": "Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers",
        "site": "https://proceedings.mlr.press/v238/haan24a.html",
        "author": "Pim de Haan; Taco Cohen; Johann Brehmer",
        "abstract": "The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.",
        "bibtex": "@InProceedings{pmlr-v238-haan24a,\n  title = \t {Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers},\n  author =       {de Haan, Pim and Cohen, Taco and Brehmer, Johann},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3088--3096},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/haan24a/haan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/haan24a.html},\n  abstract = \t {The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/haan24a/haan24a.pdf",
        "supp": "",
        "pdf_size": 837487,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=970595651277536514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f38fdec2e",
        "title": "Explanation-based Training with Differentiable Insertion/Deletion Metric-aware Regularizers",
        "site": "https://proceedings.mlr.press/v238/yoshikawa24a.html",
        "author": "Yuya Yoshikawa; Tomoharu Iwata",
        "abstract": "The quality of explanations for the predictions made by complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how accurately the explanations reflect the predictor\u2019s behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both the insertion and deletion scores of the explanations while maintaining their predictive accuracy. Because the original insertion and deletion metrics are non-differentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics so that they are differentiable and use them to formalize insertion and deletion metric-based regularizers. Our experimental results on image and tabular datasets show that the deep neural network-based predictors that are fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful and easier-to-interpret explanations while maintaining high predictive accuracy. The code is available at https://github.com/yuyay/idexpo.",
        "bibtex": "@InProceedings{pmlr-v238-yoshikawa24a,\n  title = \t {Explanation-based Training with Differentiable Insertion/Deletion Metric-aware Regularizers},\n  author =       {Yoshikawa, Yuya and Iwata, Tomoharu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {370--378},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yoshikawa24a/yoshikawa24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yoshikawa24a.html},\n  abstract = \t {The quality of explanations for the predictions made by complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how accurately the explanations reflect the predictor\u2019s behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both the insertion and deletion scores of the explanations while maintaining their predictive accuracy. Because the original insertion and deletion metrics are non-differentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics so that they are differentiable and use them to formalize insertion and deletion metric-based regularizers. Our experimental results on image and tabular datasets show that the deep neural network-based predictors that are fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful and easier-to-interpret explanations while maintaining high predictive accuracy. The code is available at https://github.com/yuyay/idexpo.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yoshikawa24a/yoshikawa24a.pdf",
        "supp": "",
        "pdf_size": 3453577,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2959591059844708803&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "STAIR Lab, Chiba Institute of Technology; NTT Corporation",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/yuyay/idexpo",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Chiba Institute of Technology;NTT Corporation",
        "aff_unique_dep": "STAIR Lab;",
        "aff_unique_url": "https://www.cit.ac.jp;https://www.ntt.co.jp",
        "aff_unique_abbr": ";NTT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "dc1f4bc7bf",
        "title": "Exploration via linearly perturbed loss minimisation",
        "site": "https://proceedings.mlr.press/v238/janz24a.html",
        "author": "David Janz; Shuai Liu; Alex Ayoub; Csaba Szepesv\u00e1ri",
        "abstract": "We introduce \\emph{exploration via linear loss perturbations} (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. We propose data-dependent perturbations not present in previous PHE-type methods that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code.",
        "bibtex": "@InProceedings{pmlr-v238-janz24a,\n  title = \t {Exploration via linearly perturbed loss minimisation},\n  author =       {Janz, David and Liu, Shuai and Ayoub, Alex and Szepesv\\'{a}ri, Csaba},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {721--729},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/janz24a/janz24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/janz24a.html},\n  abstract = \t {We introduce \\emph{exploration via linear loss perturbations} (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. We propose data-dependent perturbations not present in previous PHE-type methods that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/janz24a/janz24a.pdf",
        "supp": "",
        "pdf_size": 631981,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3868316289802863914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Alberta; University of Alberta; University of Alberta; University of Alberta",
        "aff_domain": "ualberta.ca;ualberta.ca;ualberta.ca;ualberta.ca",
        "email": "ualberta.ca;ualberta.ca;ualberta.ca;ualberta.ca",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "1f0237ca94",
        "title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems",
        "site": "https://proceedings.mlr.press/v238/qian24a.html",
        "author": "Chendi Qian; Didier Ch\u00e9telat; Christopher Morris",
        "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs\u2019 effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.",
        "bibtex": "@InProceedings{pmlr-v238-qian24a,\n  title = \t {Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems},\n  author =       {Qian, Chendi and Ch\\'{e}telat, Didier and Morris, Christopher},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1432--1440},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/qian24a/qian24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/qian24a.html},\n  abstract = \t {Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs\u2019 effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/qian24a/qian24a.pdf",
        "supp": "",
        "pdf_size": 520063,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6858291601847175342&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "abc6777404",
        "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
        "site": "https://proceedings.mlr.press/v238/september24a.html",
        "author": "Marcus A. K. September; Francesco Sanna Passino; Leonie Goldmann; Anton Hinel",
        "abstract": "Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark dataset, demonstrate the superior performance of the EDAIN layer when compared to conventional normalization methods and existing adaptive time series preprocessing layers.",
        "bibtex": "@InProceedings{pmlr-v238-september24a,\n  title = \t {Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks},\n  author =       {September, Marcus A. K. and Sanna Passino, Francesco and Goldmann, Leonie and Hinel, Anton},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1891--1899},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/september24a/september24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/september24a.html},\n  abstract = \t {Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark dataset, demonstrate the superior performance of the EDAIN layer when compared to conventional normalization methods and existing adaptive time series preprocessing layers.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/september24a/september24a.pdf",
        "supp": "",
        "pdf_size": 1340184,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17054421919120297451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7694a6f808",
        "title": "Extragradient Type Methods for Riemannian Variational Inequality Problems",
        "site": "https://proceedings.mlr.press/v238/hu24c.html",
        "author": "Zihao Hu; Guanghui Wang; Xi Wang; Andre Wibisono; Jacob D Abernethy; Molei Tao",
        "abstract": "In this work, we consider monotone Riemannian Variational Inequality Problems (RVIPs), which encompass both Riemannian convex optimization and minimax optimization as particular cases. In Euclidean space, the last-iterates of both the extragradient (EG) and past extragradient (PEG) methods converge to the solution of monotone variational inequality problems at a rate of $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ (Cai et al., 2022). However, analogous behavior on Riemannian manifolds remains open. To bridge this gap, we introduce the Riemannian extragradient (REG) and Riemannian past extragradient (RPEG) methods. We demonstrate that both exhibit $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ last-iterate convergence and $O\\left(\\frac{1}{{T}}\\right)$ average-iterate convergence, aligning with observations in the Euclidean case. These results are enabled by judiciously addressing the holonomy effect so that additional complications in Riemannian cases can be reduced and the Euclidean proof inspired by the performance estimation problem (PEP) technique or the sum-of-squares (SOS) technique can be applied again.",
        "bibtex": "@InProceedings{pmlr-v238-hu24c,\n  title = \t {Extragradient Type Methods for {R}iemannian Variational Inequality Problems},\n  author =       {Hu, Zihao and Wang, Guanghui and Wang, Xi and Wibisono, Andre and D Abernethy, Jacob and Tao, Molei},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2080--2088},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hu24c/hu24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hu24c.html},\n  abstract = \t {In this work, we consider monotone Riemannian Variational Inequality Problems (RVIPs), which encompass both Riemannian convex optimization and minimax optimization as particular cases. In Euclidean space, the last-iterates of both the extragradient (EG) and past extragradient (PEG) methods converge to the solution of monotone variational inequality problems at a rate of $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ (Cai et al., 2022). However, analogous behavior on Riemannian manifolds remains open. To bridge this gap, we introduce the Riemannian extragradient (REG) and Riemannian past extragradient (RPEG) methods. We demonstrate that both exhibit $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ last-iterate convergence and $O\\left(\\frac{1}{{T}}\\right)$ average-iterate convergence, aligning with observations in the Euclidean case. These results are enabled by judiciously addressing the holonomy effect so that additional complications in Riemannian cases can be reduced and the Euclidean proof inspired by the performance estimation problem (PEP) technique or the sum-of-squares (SOS) technique can be applied again.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hu24c/hu24c.pdf",
        "supp": "",
        "pdf_size": 332569,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10105663588800658657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Georgia Tech; Georgia Tech; AMSS, China; Yale University; Georgia Tech; Google Research+Georgia Tech",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0;3+0",
        "aff_unique_norm": "Georgia Institute of Technology;Academy of Mathematics and Systems Science;Yale University;Google",
        "aff_unique_dep": ";;;Google Research",
        "aff_unique_url": "https://www.gatech.edu;http://amss.cas.cn;https://www.yale.edu;https://research.google",
        "aff_unique_abbr": "Georgia Tech;AMSS;Yale;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;0;0;0+0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "0973dadfd6",
        "title": "FALCON: FLOP-Aware Combinatorial Optimization for Neural Network Pruning",
        "site": "https://proceedings.mlr.press/v238/meng24a.html",
        "author": "Xiang Meng; Wenyu Chen; Riade Benbaki; Rahul Mazumder",
        "abstract": "The increasing computational demands of modern neural networks present deployment challenges on resource-constrained devices. Network pruning offers a solution to reduce model size and computational cost while maintaining performance. However, current pruning methods focus primarily on improving sparsity by reducing the number of nonzero parameters, often neglecting other deployment costs such as inference time, which are closely related to the number of floating-point operations (FLOPs). In this paper, we propose {FALCON}, a novel combinatorial-optimization-based framework for network pruning that jointly takes into account model accuracy (fidelity), FLOPs, and sparsity constraints. A main building block of our approach is an integer linear program (ILP) that simultaneously handles FLOP and sparsity constraints. We present a novel algorithm to approximately solve the ILP. We propose a novel first-order method for our optimization framework which makes use of our ILP solver. Using problem structure (e.g., the low-rank structure of approx. Hessian), we can address instances with millions of parameters. Our experiments demonstrate that {FALCON}\u00a0achieves superior accuracy compared to other pruning approaches within a fixed FLOP budget. For instance, for ResNet50 with 20% of the total FLOPs retained, our approach improves the accuracy by 48% relative to state-of-the-art. Furthermore, in gradual pruning settings with re-training between pruning steps, our framework outperforms existing pruning methods, emphasizing the significance of incorporating both FLOP and sparsity constraints for effective network pruning.",
        "bibtex": "@InProceedings{pmlr-v238-meng24a,\n  title = \t {{FALCON}: {FLOP}-Aware Combinatorial Optimization for Neural Network Pruning},\n  author =       {Meng, Xiang and Chen, Wenyu and Benbaki, Riade and Mazumder, Rahul},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4384--4392},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/meng24a/meng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/meng24a.html},\n  abstract = \t {The increasing computational demands of modern neural networks present deployment challenges on resource-constrained devices. Network pruning offers a solution to reduce model size and computational cost while maintaining performance. However, current pruning methods focus primarily on improving sparsity by reducing the number of nonzero parameters, often neglecting other deployment costs such as inference time, which are closely related to the number of floating-point operations (FLOPs). In this paper, we propose {FALCON}, a novel combinatorial-optimization-based framework for network pruning that jointly takes into account model accuracy (fidelity), FLOPs, and sparsity constraints. A main building block of our approach is an integer linear program (ILP) that simultaneously handles FLOP and sparsity constraints. We present a novel algorithm to approximately solve the ILP. We propose a novel first-order method for our optimization framework which makes use of our ILP solver. Using problem structure (e.g., the low-rank structure of approx. Hessian), we can address instances with millions of parameters. Our experiments demonstrate that {FALCON}\u00a0achieves superior accuracy compared to other pruning approaches within a fixed FLOP budget. For instance, for ResNet50 with 20% of the total FLOPs retained, our approach improves the accuracy by 48% relative to state-of-the-art. Furthermore, in gradual pruning settings with re-training between pruning steps, our framework outperforms existing pruning methods, emphasizing the significance of incorporating both FLOP and sparsity constraints for effective network pruning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/meng24a/meng24a.pdf",
        "supp": "",
        "pdf_size": 757258,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15251150046280065524&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c2c6627abf",
        "title": "Failures and Successes of Cross-Validation for Early-Stopped Gradient Descent",
        "site": "https://proceedings.mlr.press/v238/patil24a.html",
        "author": "Pratik Patil; Yuchen Wu; Ryan Tibshirani",
        "abstract": "We analyze the statistical properties of generalized cross-validation (GCV) and leave-one-out cross-validation (LOOCV) applied to early-stopped gradient descent (GD) in high-dimensional least squares regression. We prove that GCV is generically inconsistent as an estimator of the prediction risk of early-stopped GD, even for a well-specified linear model with isotropic features. In contrast, we show that LOOCV converges uniformly along the GD trajectory to the prediction risk. Our theory requires only mild assumptions on the data distribution and does not require the underlying regression function to be linear. Furthermore, by leveraging the individual LOOCV errors, we construct consistent estimators for the entire prediction error distribution along the GD trajectory and consistent estimators for a wide class of error functionals. This in particular enables the construction of pathwise prediction intervals based on GD iterates that have asymptotically correct nominal coverage conditional on the training data.",
        "bibtex": "@InProceedings{pmlr-v238-patil24a,\n  title = \t {Failures and Successes of Cross-Validation for Early-Stopped Gradient Descent},\n  author =       {Patil, Pratik and Wu, Yuchen and Tibshirani, Ryan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2260--2268},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/patil24a/patil24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/patil24a.html},\n  abstract = \t {We analyze the statistical properties of generalized cross-validation (GCV) and leave-one-out cross-validation (LOOCV) applied to early-stopped gradient descent (GD) in high-dimensional least squares regression. We prove that GCV is generically inconsistent as an estimator of the prediction risk of early-stopped GD, even for a well-specified linear model with isotropic features. In contrast, we show that LOOCV converges uniformly along the GD trajectory to the prediction risk. Our theory requires only mild assumptions on the data distribution and does not require the underlying regression function to be linear. Furthermore, by leveraging the individual LOOCV errors, we construct consistent estimators for the entire prediction error distribution along the GD trajectory and consistent estimators for a wide class of error functionals. This in particular enables the construction of pathwise prediction intervals based on GD iterates that have asymptotically correct nominal coverage conditional on the training data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/patil24a/patil24a.pdf",
        "supp": "",
        "pdf_size": 1049125,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8846922715791134404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53a8a73a3a",
        "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities",
        "site": "https://proceedings.mlr.press/v238/oesterling24a.html",
        "author": "Alex Oesterling; Jiaqi Ma; Flavio Calmon; Himabindu Lakkaraju",
        "abstract": "The Right to be Forgotten is a core principle outlined by regulatory frameworks such as the EU\u2019s General Data Protection Regulation (GDPR). This principle allows individuals to request that their personal data be deleted from deployed machine learning models. While \"forgetting\" can be naively achieved by retraining on the remaining dataset, it is computationally expensive to do to so with each new request. As such, several machine unlearning methods have been proposed as efficient alternatives to retraining. These methods aim to approximate the predictive performance of retraining, but fail to consider how unlearning impacts other properties critical to real-world applications such as fairness. In this work, we demonstrate that most efficient unlearning methods cannot accommodate popular fairness interventions, and we propose the first fair machine unlearning method that can efficiently unlearn data instances from a fair objective. We derive theoretical results which demonstrate that our method can provably unlearn data and provably maintain fairness performance. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness. Code is provided at https://github.com/AI4LIFE-GROUP/fair-unlearning.",
        "bibtex": "@InProceedings{pmlr-v238-oesterling24a,\n  title = \t {Fair Machine Unlearning: Data Removal while Mitigating Disparities},\n  author =       {Oesterling, Alex and Ma, Jiaqi and Calmon, Flavio and Lakkaraju, Himabindu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3736--3744},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/oesterling24a/oesterling24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/oesterling24a.html},\n  abstract = \t {The Right to be Forgotten is a core principle outlined by regulatory frameworks such as the EU\u2019s General Data Protection Regulation (GDPR). This principle allows individuals to request that their personal data be deleted from deployed machine learning models. While \"forgetting\" can be naively achieved by retraining on the remaining dataset, it is computationally expensive to do to so with each new request. As such, several machine unlearning methods have been proposed as efficient alternatives to retraining. These methods aim to approximate the predictive performance of retraining, but fail to consider how unlearning impacts other properties critical to real-world applications such as fairness. In this work, we demonstrate that most efficient unlearning methods cannot accommodate popular fairness interventions, and we propose the first fair machine unlearning method that can efficiently unlearn data instances from a fair objective. We derive theoretical results which demonstrate that our method can provably unlearn data and provably maintain fairness performance. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness. Code is provided at https://github.com/AI4LIFE-GROUP/fair-unlearning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/oesterling24a/oesterling24a.pdf",
        "supp": "",
        "pdf_size": 1845057,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10109545193780977731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Harvard University; UIUC; Harvard University; Harvard University",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/AI4LIFE-GROUP/fair-unlearning",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Harvard University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.harvard.edu;https://www illinois.edu",
        "aff_unique_abbr": "Harvard;UIUC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3efcf60cc7",
        "title": "Fair Soft Clustering",
        "site": "https://proceedings.mlr.press/v238/kjaersgaard24a.html",
        "author": "Rune D. Kj\u00e6rsgaard; Pekka Parviainen; Saket Saurabh; Madhumita Kundu; Line Clemmensen",
        "abstract": "Scholars in the machine learning community have recently focused on analyzing the fairness of learning models, including clustering algorithms. In this work we study fair clustering in a probabilistic (soft) setting, where observations may belong to several clusters determined by probabilities. We introduce new probabilistic fairness metrics, which generalize and extend existing non-probabilistic fairness frameworks and propose an algorithm for obtaining a fair probabilistic cluster solution from a data representation known as a fairlet decomposition. Finally, we demonstrate our proposed fairness metrics and algorithm by constructing a fair Gaussian mixture model on three real-world datasets. We achieve this by identifying balanced micro-clusters which minimize the distances induced by the model, and on which traditional clustering can be performed while ensuring the fairness of the solution.",
        "bibtex": "@InProceedings{pmlr-v238-kjaersgaard24a,\n  title = \t {Fair Soft Clustering},\n  author =       {Kj{\\ae}rsgaard, Rune D. and Parviainen, Pekka and Saurabh, Saket and Kundu, Madhumita and Clemmensen, Line},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1270--1278},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kjaersgaard24a/kjaersgaard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kjaersgaard24a.html},\n  abstract = \t {Scholars in the machine learning community have recently focused on analyzing the fairness of learning models, including clustering algorithms. In this work we study fair clustering in a probabilistic (soft) setting, where observations may belong to several clusters determined by probabilities. We introduce new probabilistic fairness metrics, which generalize and extend existing non-probabilistic fairness frameworks and propose an algorithm for obtaining a fair probabilistic cluster solution from a data representation known as a fairlet decomposition. Finally, we demonstrate our proposed fairness metrics and algorithm by constructing a fair Gaussian mixture model on three real-world datasets. We achieve this by identifying balanced micro-clusters which minimize the distances induced by the model, and on which traditional clustering can be performed while ensuring the fairness of the solution.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kjaersgaard24a/kjaersgaard24a.pdf",
        "supp": "",
        "pdf_size": 7113951,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14610246787193328330&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "DTU Compute, Technical University of Denmark, Denmark; Department of Informatics, University of Bergen, Norway; Theoretical Computer Science Group, The Institute of Mathematical Sciences, India + Department of Informatics, University of Bergen, Norway; Department of Informatics, University of Bergen, Norway; DTU Compute, Technical University of Denmark, Denmark",
        "aff_domain": "dtu.dk; ; ; ; ",
        "email": "dtu.dk; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+1;1;0",
        "aff_unique_norm": "Technical University of Denmark;University of Bergen;Institute of Mathematical Sciences",
        "aff_unique_dep": "DTU Compute;Department of Informatics;Theoretical Computer Science Group",
        "aff_unique_url": "https://www.dtu.dk;https://www.uib.no;",
        "aff_unique_abbr": "DTU;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2+1;1;0",
        "aff_country_unique": "Denmark;Norway;India"
    },
    {
        "id": "dbdb302634",
        "title": "Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes",
        "site": "https://proceedings.mlr.press/v238/sohn24a.html",
        "author": "Jinwon Sohn; Qifan Song; Guang Lin",
        "abstract": "As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of utility of the proposed neural-penalized risk minimization problem.",
        "bibtex": "@InProceedings{pmlr-v238-sohn24a,\n  title = \t {Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes},\n  author =       {Sohn, Jinwon and Song, Qifan and Lin, Guang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1594--1602},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sohn24a/sohn24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sohn24a.html},\n  abstract = \t {As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of utility of the proposed neural-penalized risk minimization problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sohn24a/sohn24a.pdf",
        "supp": "",
        "pdf_size": 4474215,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10656866799208563409&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "056caaad07",
        "title": "Fair k-center Clustering with Outliers",
        "site": "https://proceedings.mlr.press/v238/amagata24a.html",
        "author": "Daichi Amagata",
        "abstract": "The importance of dealing with big data is further increasing, as machine learning (ML) systems obtain useful knowledge from big datasets. However, using all data is practically prohibitive because of the massive sizes of the datasets, so summarizing them by centers obtained from k-center clustering is a promising approach. We have two concerns here. One is fairness, because if the summary does not have some specific groups, subsequent applications may provide unfair results for the groups. The other is the presence of outliers, and if outliers dominate the summary, it cannot be useful. To overcome these concerns, we address the problem of fair k-center clustering with outliers. Although prior works studied the fair k-center clustering problem, they do not consider outliers. This paper yields a linear time algorithm that satisfies the fairness constraint of our problem and probabilistically guarantees the almost 3-approximation bound. Its empirical efficiency and effectiveness are also reported.",
        "bibtex": "@InProceedings{pmlr-v238-amagata24a,\n  title = \t {Fair k-center Clustering with Outliers},\n  author =       {Amagata, Daichi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10--18},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/amagata24a/amagata24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/amagata24a.html},\n  abstract = \t {The importance of dealing with big data is further increasing, as machine learning (ML) systems obtain useful knowledge from big datasets. However, using all data is practically prohibitive because of the massive sizes of the datasets, so summarizing them by centers obtained from k-center clustering is a promising approach. We have two concerns here. One is fairness, because if the summary does not have some specific groups, subsequent applications may provide unfair results for the groups. The other is the presence of outliers, and if outliers dominate the summary, it cannot be useful. To overcome these concerns, we address the problem of fair k-center clustering with outliers. Although prior works studied the fair k-center clustering problem, they do not consider outliers. This paper yields a linear time algorithm that satisfies the fairness constraint of our problem and probabilistically guarantees the almost 3-approximation bound. Its empirical efficiency and effectiveness are also reported.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/amagata24a/amagata24a.pdf",
        "supp": "",
        "pdf_size": 1339147,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5459173288554794469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Osaka University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "f48a33c4a2",
        "title": "FairRR: Pre-Processing for Group Fairness through Randomized Response",
        "site": "https://proceedings.mlr.press/v238/john-ward24a.html",
        "author": "Joshua John Ward; Xianli Zeng; Guang Cheng",
        "abstract": "The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper extends recent fair statistical learning results and proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.",
        "bibtex": "@InProceedings{pmlr-v238-john-ward24a,\n  title = \t {{F}air{RR}: Pre-Processing for Group Fairness through Randomized Response},\n  author =       {John Ward, Joshua and Zeng, Xianli and Cheng, Guang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3826--3834},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/john-ward24a/john-ward24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/john-ward24a.html},\n  abstract = \t {The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper extends recent fair statistical learning results and proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/john-ward24a/john-ward24a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7017510240613401213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f12895cae",
        "title": "Fairness in Submodular Maximization over a Matroid Constraint",
        "site": "https://proceedings.mlr.press/v238/el-halabi24a.html",
        "author": "Marwa El Halabi; Jakub Tarnawski; Ashkan Norouzi-Fard; Thuy-Duong Vuong",
        "abstract": "Submodular maximization over a matroid constraint is a fundamental problem with various applications in machine learning. Some of these applications involve decision-making over datapoints with sensitive attributes such as gender or race. In such settings, it is crucial to guarantee that the selected solution is fairly distributed with respect to this attribute. Recently, fairness has been investigated in submodular maximization under a cardinality constraint in both the streaming and offline settings, however the more general problem with matroid constraint has only been considered in the streaming setting and only for monotone objectives. This work fills this gap. We propose various algorithms and impossibility results offering different trade-offs between quality, fairness, and generality.",
        "bibtex": "@InProceedings{pmlr-v238-el-halabi24a,\n  title = \t {Fairness in Submodular Maximization over a Matroid Constraint},\n  author =       {El Halabi, Marwa and Tarnawski, Jakub and Norouzi-Fard, Ashkan and Vuong, Thuy-Duong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1027--1035},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/el-halabi24a/el-halabi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/el-halabi24a.html},\n  abstract = \t {Submodular maximization over a matroid constraint is a fundamental problem with various applications in machine learning. Some of these applications involve decision-making over datapoints with sensitive attributes such as gender or race. In such settings, it is crucial to guarantee that the selected solution is fairly distributed with respect to this attribute. Recently, fairness has been investigated in submodular maximization under a cardinality constraint in both the streaming and offline settings, however the more general problem with matroid constraint has only been considered in the streaming setting and only for monotone objectives. This work fills this gap. We propose various algorithms and impossibility results offering different trade-offs between quality, fairness, and generality.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/el-halabi24a/el-halabi24a.pdf",
        "supp": "",
        "pdf_size": 462025,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1731403622277675138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "722c555bcf",
        "title": "Faithful graphical representations of local independence",
        "site": "https://proceedings.mlr.press/v238/mogensen24a.html",
        "author": "S\u00f8ren W. Mogensen",
        "abstract": "Graphical models use graphs to represent conditional independence structure in the distribution of a random vector. In stochastic processes, graphs may represent so-called local independence or conditional Granger causality. Under some regularity conditions, a local independence graph implies a set of independences using a graphical criterion known as delta-separation, or using its generalization, mu-separation. This is a stochastic process analogue of d-separation in DAGs. However, there may be more independences than implied by this graph and this is a violation of so-called faithfulness. We characterize faithfulness in local independence graphs and give a method to construct a faithful graph from any local independence model such that the output equals the true graph when Markov and faithfulness assumptions hold. We discuss various assumptions that are weaker than faithfulness, and we explore different structure learning algorithms and their properties under varying assumptions.",
        "bibtex": "@InProceedings{pmlr-v238-mogensen24a,\n  title = \t {Faithful graphical representations of local independence},\n  author =       {Mogensen, S\\o{}ren W.},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2989--2997},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mogensen24a/mogensen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mogensen24a.html},\n  abstract = \t {Graphical models use graphs to represent conditional independence structure in the distribution of a random vector. In stochastic processes, graphs may represent so-called local independence or conditional Granger causality. Under some regularity conditions, a local independence graph implies a set of independences using a graphical criterion known as delta-separation, or using its generalization, mu-separation. This is a stochastic process analogue of d-separation in DAGs. However, there may be more independences than implied by this graph and this is a violation of so-called faithfulness. We characterize faithfulness in local independence graphs and give a method to construct a faithful graph from any local independence model such that the output equals the true graph when Markov and faithfulness assumptions hold. We discuss various assumptions that are weaker than faithfulness, and we explore different structure learning algorithms and their properties under varying assumptions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mogensen24a/mogensen24a.pdf",
        "supp": "",
        "pdf_size": 415081,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15545792889625054383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Automatic Control, Lund University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Lund University",
        "aff_unique_dep": "Department of Automatic Control",
        "aff_unique_url": "https://www.lunduniversity.lu.se",
        "aff_unique_abbr": "LU",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "d3315633be",
        "title": "Fast 1-Wasserstein distance approximations using greedy strategies",
        "site": "https://proceedings.mlr.press/v238/houry24a.html",
        "author": "Guillaume Houry; Han Bao; Han Zhao; Makoto Yamada",
        "abstract": "Among numerous linear approximation methods proposed for optimal transport (OT), tree-based methods appear to be fairly reliable, notably for language processing applications. Inspired by these tree methods, we introduce several greedy heuristics aiming to compute even faster approximations of OT. We first explicitly establish the equivalence between greedy matching and optimal transport for tree metrics, and then we show that tree greedy matching can be reduced to greedy matching on a one-dimensional line. Next, we propose two new greedy-based algorithms in one dimension: the $k$-Greedy and 1D-ICT algorithms. This novel approach provides Wasserstein approximations with accuracy similar to the original tree methods on text datasets while being faster in practice. Finally, these algorithms are applicable beyond tree approximations: using sliced projections of the original data still provides fairly good accuracy while eliminating the need for embedding the data in a fixed and rigid tree structure. This property makes these approaches even more versatile than the original tree OT methods.",
        "bibtex": "@InProceedings{pmlr-v238-houry24a,\n  title = \t {Fast 1-{W}asserstein distance approximations using greedy strategies},\n  author =       {Houry, Guillaume and Bao, Han and Zhao, Han and Yamada, Makoto},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {325--333},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/houry24a/houry24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/houry24a.html},\n  abstract = \t {Among numerous linear approximation methods proposed for optimal transport (OT), tree-based methods appear to be fairly reliable, notably for language processing applications. Inspired by these tree methods, we introduce several greedy heuristics aiming to compute even faster approximations of OT. We first explicitly establish the equivalence between greedy matching and optimal transport for tree metrics, and then we show that tree greedy matching can be reduced to greedy matching on a one-dimensional line. Next, we propose two new greedy-based algorithms in one dimension: the $k$-Greedy and 1D-ICT algorithms. This novel approach provides Wasserstein approximations with accuracy similar to the original tree methods on text datasets while being faster in practice. Finally, these algorithms are applicable beyond tree approximations: using sliced projections of the original data still provides fairly good accuracy while eliminating the need for embedding the data in a fixed and rigid tree structure. This property makes these approaches even more versatile than the original tree OT methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/houry24a/houry24a.pdf",
        "supp": "",
        "pdf_size": 958419,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18026036887364753078&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2522f631b6",
        "title": "Fast Dynamic Sampling for Determinantal Point Processes",
        "site": "https://proceedings.mlr.press/v238/song24b.html",
        "author": "Zhao Song; Junze Yin; Lichen Zhang; Ruizhe Zhang",
        "abstract": "n this work, we provide fast dynamic algorithms for repeatedly sampling from distributions characterized by Determinantal Point Processes (DPPs) and Nonsymmetric Determinantal Point Processes (NDPPs). DPPs are a very well-studied class of distributions on subsets of items drawn from a ground set of cardinality $n$ characterized by a symmetric $n \\times n$ kernel matrix $L$ such that the probability of any subset is proportional to the determinant of its corresponding principal submatrix. Recent work has shown that the kernel symmetry constraint can be relaxed, leading to NDPPs, which can better model data in several machine learning applications. Given a low-rank kernel matrix ${\\cal L}=L+L^\\top\\in \\mathbb{R}^{n\\times n}$ and its corresponding eigendecomposition specified by $\\{\\lambda_i, u_i \\}_{i=1}^d$ where $d\\leq n$ is the rank, we design a data structure that uses $O(nd)$ space and preprocesses data in $O(nd^{\\omega-1})$ time where $\\omega\\approx 2.37$ is the exponent of matrix multiplication. The data structure can generate a sample according to DPP distribution in time $O(|E|^3\\log n+|E|^{\\omega-1}d^2)$ or according to NDPP distribution in time $O((|E|^3 \\log n+ |E|^{\\omega-1}d^2)(1+w)^d)$ for $E$ being the sampled indices and $w$ is a data-dependent parameter. This improves upon the space and preprocessing time over prior works, and achieves a state-of-the-art sampling time when the sampling set is relatively dense. At the heart of our data structure is an efficient sampling tree that can leverage batch initialization and fast inner product query simultaneously.",
        "bibtex": "@InProceedings{pmlr-v238-song24b,\n  title = \t {Fast Dynamic Sampling for Determinantal Point Processes},\n  author =       {Song, Zhao and Yin, Junze and Zhang, Lichen and Zhang, Ruizhe},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {244--252},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/song24b/song24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/song24b.html},\n  abstract = \t {n this work, we provide fast dynamic algorithms for repeatedly sampling from distributions characterized by Determinantal Point Processes (DPPs) and Nonsymmetric Determinantal Point Processes (NDPPs). DPPs are a very well-studied class of distributions on subsets of items drawn from a ground set of cardinality $n$ characterized by a symmetric $n \\times n$ kernel matrix $L$ such that the probability of any subset is proportional to the determinant of its corresponding principal submatrix. Recent work has shown that the kernel symmetry constraint can be relaxed, leading to NDPPs, which can better model data in several machine learning applications. Given a low-rank kernel matrix ${\\cal L}=L+L^\\top\\in \\mathbb{R}^{n\\times n}$ and its corresponding eigendecomposition specified by $\\{\\lambda_i, u_i \\}_{i=1}^d$ where $d\\leq n$ is the rank, we design a data structure that uses $O(nd)$ space and preprocesses data in $O(nd^{\\omega-1})$ time where $\\omega\\approx 2.37$ is the exponent of matrix multiplication. The data structure can generate a sample according to DPP distribution in time $O(|E|^3\\log n+|E|^{\\omega-1}d^2)$ or according to NDPP distribution in time $O((|E|^3 \\log n+ |E|^{\\omega-1}d^2)(1+w)^d)$ for $E$ being the sampled indices and $w$ is a data-dependent parameter. This improves upon the space and preprocessing time over prior works, and achieves a state-of-the-art sampling time when the sampling set is relatively dense. At the heart of our data structure is an efficient sampling tree that can leverage batch initialization and fast inner product query simultaneously.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/song24b/song24b.pdf",
        "supp": "",
        "pdf_size": 439442,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14251815913953677314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bc180a6691",
        "title": "Fast Fourier Bayesian Quadrature",
        "site": "https://proceedings.mlr.press/v238/warren24a.html",
        "author": "Houston Warren; Fabio Ramos",
        "abstract": "In numerical integration, Bayesian quadrature (BQ) excels at producing estimates with quantified uncertainties, particularly in sparse data settings. However, its computational scalability and kernel learning capabilities have lagged behind modern advances in Gaussian process research. To bridge this gap, we recast the BQ posterior integral as a convolution operation, which enables efficient computation via fast Fourier transform of low-rank matrices. We introduce two new methods enabled by recasting BQ as a convolution: fast Fourier Bayesian quadrature and sparse spectrum Bayesian quadrature. These methods enhance the computational scalability of BQ and expand kernel flexibility, enabling the use of \\textit{any} stationary kernel in the BQ setting. We empirically validate the efficacy of our approach through a range of integration tasks, substantiating the benefits of the proposed methodology.",
        "bibtex": "@InProceedings{pmlr-v238-warren24a,\n  title = \t {Fast {F}ourier {B}ayesian Quadrature},\n  author =       {Warren, Houston and Ramos, Fabio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4555--4563},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/warren24a/warren24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/warren24a.html},\n  abstract = \t {In numerical integration, Bayesian quadrature (BQ) excels at producing estimates with quantified uncertainties, particularly in sparse data settings. However, its computational scalability and kernel learning capabilities have lagged behind modern advances in Gaussian process research. To bridge this gap, we recast the BQ posterior integral as a convolution operation, which enables efficient computation via fast Fourier transform of low-rank matrices. We introduce two new methods enabled by recasting BQ as a convolution: fast Fourier Bayesian quadrature and sparse spectrum Bayesian quadrature. These methods enhance the computational scalability of BQ and expand kernel flexibility, enabling the use of \\textit{any} stationary kernel in the BQ setting. We empirically validate the efficacy of our approach through a range of integration tasks, substantiating the benefits of the proposed methodology.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/warren24a/warren24a.pdf",
        "supp": "",
        "pdf_size": 1332811,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6730007065406324104&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "The University of Sydney; The University of Sydney & NVIDIA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sydney",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "f0c91ef080",
        "title": "Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging",
        "site": "https://proceedings.mlr.press/v238/tsai24a.html",
        "author": "Chung-En Tsai; Hao-Chung Cheng; Yen-Huan Li",
        "abstract": "Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem includes tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function. In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^2/\\varepsilon^2)$ time, matching the state of the art, where $d$ denotes the dimension. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^3/\\varepsilon^2)$ time. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\\omega-2}$ and those of batch methods by a factor of $d^2$, where $\\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees.",
        "bibtex": "@InProceedings{pmlr-v238-tsai24a,\n  title = \t {Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging},\n  author =       {Tsai, Chung-En and Cheng, Hao-Chung and Li, Yen-Huan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2908--2916},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tsai24a/tsai24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tsai24a.html},\n  abstract = \t {Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem includes tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function. In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^2/\\varepsilon^2)$ time, matching the state of the art, where $d$ denotes the dimension. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^3/\\varepsilon^2)$ time. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\\omega-2}$ and those of batch methods by a factor of $d^2$, where $\\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tsai24a/tsai24a.pdf",
        "supp": "",
        "pdf_size": 998582,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14474676391479655269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "85cdb57d09",
        "title": "Fast and Accurate Estimation of Low-Rank Matrices from Noisy Measurements via Preconditioned Non-Convex Gradient Descent",
        "site": "https://proceedings.mlr.press/v238/zhang24j.html",
        "author": "Jialun Zhang; Richard Y Zhang; Hong-Ming Chiu",
        "abstract": "Non-convex gradient descent is a common approach for estimating a low-rank $n\\times n$ ground truth matrix from noisy measurements, because it has per-iteration costs as low as $O(n)$ time, and is in theory capable of converging to a minimax optimal estimate. However, the practitioner is often constrained to just tens to hundreds of iterations, and the slow and/or inconsistent convergence of non-convex gradient descent can prevent a high-quality estimate from being obtained. Recently, the technique of \\emph{preconditioning} was shown to be highly effective at accelerating the local convergence of non-convex gradient descent when the measurements are noiseless. In this paper, we describe how preconditioning should be done for noisy measurements to accelerate local convergence to minimax optimality. For the symmetric matrix sensing problem, our proposed preconditioned method is guaranteed to locally converge to minimax error at a linear rate that is immune to ill-conditioning and/or over-parameterization. Using our proposed preconditioned method, we perform a 60 megapixel medical image denoising task, and observe significantly reduced noise levels compared to previous approaches.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24j,\n  title = \t {Fast and Accurate Estimation of Low-Rank Matrices from Noisy Measurements via Preconditioned Non-Convex Gradient Descent},\n  author =       {Zhang, Jialun and Y Zhang, Richard and Chiu, Hong-Ming},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3772--3780},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24j/zhang24j.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24j.html},\n  abstract = \t {Non-convex gradient descent is a common approach for estimating a low-rank $n\\times n$ ground truth matrix from noisy measurements, because it has per-iteration costs as low as $O(n)$ time, and is in theory capable of converging to a minimax optimal estimate. However, the practitioner is often constrained to just tens to hundreds of iterations, and the slow and/or inconsistent convergence of non-convex gradient descent can prevent a high-quality estimate from being obtained. Recently, the technique of \\emph{preconditioning} was shown to be highly effective at accelerating the local convergence of non-convex gradient descent when the measurements are noiseless. In this paper, we describe how preconditioning should be done for noisy measurements to accelerate local convergence to minimax optimality. For the symmetric matrix sensing problem, our proposed preconditioned method is guaranteed to locally converge to minimax error at a linear rate that is immune to ill-conditioning and/or over-parameterization. Using our proposed preconditioned method, we perform a 60 megapixel medical image denoising task, and observe significantly reduced noise levels compared to previous approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24j/zhang24j.pdf",
        "supp": "",
        "pdf_size": 3732292,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16718828191842374456&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ed5456769b",
        "title": "Fast and Adversarial Robust Kernelized SDU Learning",
        "site": "https://proceedings.mlr.press/v238/fan24a.html",
        "author": "Yajing Fan; wanli shi; Yi Chang; Bin Gu",
        "abstract": "SDU learning, a weakly supervised learning problem with only pairwise similarities, dissimilarities data points and unlabeled data available, has many practical applications. However, it is still lacking in defense against adversarial samples, and its learning process can be expensive. To address this gap, we propose a novel adversarial training framework for SDU learning. Our approach reformulates the conventional minimax problem as an equivalent minimization problem based on the kernel perspective, departing from traditional confrontational training methods. Additionally, we employ the random gradient method and random features to accelerate the training process. Theoretical analysis shows that our method can converge to a stationary point at a rate of $\\mathcal{O}(1/T^{1/4})$. Our experimental results show that our algorithm is superior to other adversarial training methods in terms of generalization, efficiency and scalability against various adversarial attacks.",
        "bibtex": "@InProceedings{pmlr-v238-fan24a,\n  title = \t {Fast and Adversarial Robust Kernelized SDU Learning},\n  author =       {Fan, Yajing and shi, wanli and Chang, Yi and Gu, Bin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1153--1161},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fan24a/fan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fan24a.html},\n  abstract = \t {SDU learning, a weakly supervised learning problem with only pairwise similarities, dissimilarities data points and unlabeled data available, has many practical applications. However, it is still lacking in defense against adversarial samples, and its learning process can be expensive. To address this gap, we propose a novel adversarial training framework for SDU learning. Our approach reformulates the conventional minimax problem as an equivalent minimization problem based on the kernel perspective, departing from traditional confrontational training methods. Additionally, we employ the random gradient method and random features to accelerate the training process. Theoretical analysis shows that our method can converge to a stationary point at a rate of $\\mathcal{O}(1/T^{1/4})$. Our experimental results show that our algorithm is superior to other adversarial training methods in terms of generalization, efficiency and scalability against various adversarial attacks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fan24a/fan24a.pdf",
        "supp": "",
        "pdf_size": 1059779,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dSn7xsoHttsJ:scholar.google.com/&scioq=Fast+and+Adversarial+Robust+Kernelized+SDU+Learning&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6bcf754c91",
        "title": "Faster Convergence with MultiWay Preferences",
        "site": "https://proceedings.mlr.press/v238/saha24a.html",
        "author": "Aadirupa Saha; Vitaly Feldman; Yishay Mansour; Tomer Koren",
        "abstract": "We address the problem of convex optimization with preference feedback, where the goal is to minimize a convex function given a weaker form of comparison queries. Each query consists of two points and the dueling feedback returns a (noisy) single-bit binary comparison of the function values of the two queried points. Here we consider the sign-function-based comparison feedback model and analyze the convergence rates with batched and multiway (argmin of a set queried points) comparisons. Our main goal is to understand the improved convergence rates owing to parallelization in sign-feedback-based optimization problems. Our work is the first to study the problem of convex optimization with multiway preferences and analyze the optimal convergence rates. Our first contribution lies in designing efficient algorithms with a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{\\min\\{m,d\\} \\epsilon})$ for $m$-batched preference feedback where the learner can query $m$-pairs in parallel. We next study a $m$-multiway comparison (\u2018battling\u2019) feedback, where the learner can get to see the argmin feedback of $m$-subset of queried points and show a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{ \\min\\{\\log m,d\\}\\epsilon })$. We show further improved convergence rates with an additional assumption of strong convexity. Finally, we also study the convergence lower bounds for batched preferences and multiway feedback optimization showing the optimality of our convergence rates w.r.t. $m$.",
        "bibtex": "@InProceedings{pmlr-v238-saha24a,\n  title = \t {Faster Convergence with MultiWay Preferences},\n  author =       {Saha, Aadirupa and Feldman, Vitaly and Mansour, Yishay and Koren, Tomer},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {433--441},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/saha24a/saha24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/saha24a.html},\n  abstract = \t {We address the problem of convex optimization with preference feedback, where the goal is to minimize a convex function given a weaker form of comparison queries. Each query consists of two points and the dueling feedback returns a (noisy) single-bit binary comparison of the function values of the two queried points. Here we consider the sign-function-based comparison feedback model and analyze the convergence rates with batched and multiway (argmin of a set queried points) comparisons. Our main goal is to understand the improved convergence rates owing to parallelization in sign-feedback-based optimization problems. Our work is the first to study the problem of convex optimization with multiway preferences and analyze the optimal convergence rates. Our first contribution lies in designing efficient algorithms with a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{\\min\\{m,d\\} \\epsilon})$ for $m$-batched preference feedback where the learner can query $m$-pairs in parallel. We next study a $m$-multiway comparison (\u2018battling\u2019) feedback, where the learner can get to see the argmin feedback of $m$-subset of queried points and show a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{ \\min\\{\\log m,d\\}\\epsilon })$. We show further improved convergence rates with an additional assumption of strong convexity. Finally, we also study the convergence lower bounds for batched preferences and multiway feedback optimization showing the optimality of our convergence rates w.r.t. $m$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/saha24a/saha24a.pdf",
        "supp": "",
        "pdf_size": 1095888,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4980733555060297871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "996f8aeec0",
        "title": "Faster Recalibration of an Online Predictor via Approachability",
        "site": "https://proceedings.mlr.press/v238/okoroafor24a.html",
        "author": "Princewill Okoroafor; Bobby Kleinberg; Wen Sun",
        "abstract": "Predictive models in ML need to be trustworthy and reliable, which often at the very least means outputting calibrated probabilities. This can be particularly difficult to guarantee in the online prediction setting when the outcome sequence can be generated adversarially. In this paper we introduce a technique using Blackwell\u2019s approachability theorem for taking an online predictive model which might not be calibrated and transforming its predictions to calibrated predictions without much increase to the loss of the original model. Our proposed algorithm achieves calibration and accuracy at a faster rate than existing techniques (Kuleshov and Ermon, 2017) and is the first algorithm to offer a flexible tradeoff between calibration error and accuracy in the online setting. We demonstrate this by characterizing the space of jointly achievable calibration and regret using our technique.",
        "bibtex": "@InProceedings{pmlr-v238-okoroafor24a,\n  title = \t {Faster Recalibration of an Online Predictor via Approachability},\n  author =       {Okoroafor, Princewill and Kleinberg, Bobby and Sun, Wen},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4690--4698},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/okoroafor24a/okoroafor24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/okoroafor24a.html},\n  abstract = \t {Predictive models in ML need to be trustworthy and reliable, which often at the very least means outputting calibrated probabilities. This can be particularly difficult to guarantee in the online prediction setting when the outcome sequence can be generated adversarially. In this paper we introduce a technique using Blackwell\u2019s approachability theorem for taking an online predictive model which might not be calibrated and transforming its predictions to calibrated predictions without much increase to the loss of the original model. Our proposed algorithm achieves calibration and accuracy at a faster rate than existing techniques (Kuleshov and Ermon, 2017) and is the first algorithm to offer a flexible tradeoff between calibration error and accuracy in the online setting. We demonstrate this by characterizing the space of jointly achievable calibration and regret using our technique.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/okoroafor24a/okoroafor24a.pdf",
        "supp": "",
        "pdf_size": 682932,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5867352332943916623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5fa1f59089",
        "title": "Feasible $Q$-Learning for Average Reward Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/jin24b.html",
        "author": "Ying Jin; Ramki Gummadi; Zhengyuan Zhou; Jose Blanchet",
        "abstract": "Average reward reinforcement learning (RL) provides a suitable framework for capturing the objective (i.e. long-run average reward) for continuing tasks, where there is often no natural way to identify a discount factor. However, existing average reward RL algorithms with sample complexity guarantees are not feasible, as they take as input the (unknown) mixing time of the Markov decision process (MDP). In this paper, we make initial progress towards addressing this open problem. We design a feasible average-reward $Q$-learning framework that requires no knowledge of any problem parameter as input. Our framework is based on discounted $Q$-learning, while we dynamically adapt the discount factor (and hence the effective horizon) to progressively approximate the average reward. In the synchronous setting, we solve three tasks: (i) learn a policy that is $\\epsilon$-close to optimal, (ii) estimate optimal average reward with $\\epsilon$-accuracy, and (iii) estimate the bias function (similar to $Q$-function in discounted case) with $\\epsilon$-accuracy. We show that with carefully designed adaptation schemes, (i) can be achieved with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^{8}}{\\epsilon^{8}})$ samples, (ii) with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^5}{\\epsilon^5})$ samples, and (iii) with $\\tilde{O}(\\frac{SA B}{\\epsilon^9})$ samples, where $t_\\mathrm{mix}$ is the mixing time, and $B > 0$ is an MDP-dependent constant. To our knowledge, we provide the first finite-sample guarantees that are polynomial in $S, A, t_{\\mathrm{mix}}, \\epsilon$ for a feasible variant of $Q$-learning. That said, the sample complexity bounds have tremendous room for improvement, which we leave for the community\u2019s best minds. Preliminary simulations verify that our framework is effective without prior knowledge of parameters as input.",
        "bibtex": "@InProceedings{pmlr-v238-jin24b,\n  title = \t {Feasible $Q$-Learning for Average Reward Reinforcement Learning},\n  author =       {Jin, Ying and Gummadi, Ramki and Zhou, Zhengyuan and Blanchet, Jose},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1630--1638},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jin24b/jin24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jin24b.html},\n  abstract = \t {Average reward reinforcement learning (RL) provides a suitable framework for capturing the objective (i.e. long-run average reward) for continuing tasks, where there is often no natural way to identify a discount factor. However, existing average reward RL algorithms with sample complexity guarantees are not feasible, as they take as input the (unknown) mixing time of the Markov decision process (MDP). In this paper, we make initial progress towards addressing this open problem. We design a feasible average-reward $Q$-learning framework that requires no knowledge of any problem parameter as input. Our framework is based on discounted $Q$-learning, while we dynamically adapt the discount factor (and hence the effective horizon) to progressively approximate the average reward. In the synchronous setting, we solve three tasks: (i) learn a policy that is $\\epsilon$-close to optimal, (ii) estimate optimal average reward with $\\epsilon$-accuracy, and (iii) estimate the bias function (similar to $Q$-function in discounted case) with $\\epsilon$-accuracy. We show that with carefully designed adaptation schemes, (i) can be achieved with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^{8}}{\\epsilon^{8}})$ samples, (ii) with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^5}{\\epsilon^5})$ samples, and (iii) with $\\tilde{O}(\\frac{SA B}{\\epsilon^9})$ samples, where $t_\\mathrm{mix}$ is the mixing time, and $B > 0$ is an MDP-dependent constant. To our knowledge, we provide the first finite-sample guarantees that are polynomial in $S, A, t_{\\mathrm{mix}}, \\epsilon$ for a feasible variant of $Q$-learning. That said, the sample complexity bounds have tremendous room for improvement, which we leave for the community\u2019s best minds. Preliminary simulations verify that our framework is effective without prior knowledge of parameters as input.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jin24b/jin24b.pdf",
        "supp": "",
        "pdf_size": 593975,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4030181840528448380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Stanford University; Stanford University; Google; New York University",
        "aff_domain": "stanford.edu; ; ;nyu.edu",
        "email": "stanford.edu; ; ;nyu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Stanford University;Google;New York University",
        "aff_unique_dep": ";Google;",
        "aff_unique_url": "https://www.stanford.edu;https://www.google.com;https://www.nyu.edu",
        "aff_unique_abbr": "Stanford;Google;NYU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Stanford;Mountain View;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e9b70db8bf",
        "title": "FedFisher: Leveraging Fisher Information for One-Shot Federated Learning",
        "site": "https://proceedings.mlr.press/v238/jhunjhunwala24a.html",
        "author": "Divyansh Jhunjhunwala; Shiqiang Wang; Gauri Joshi",
        "abstract": "Standard federated learning (FL) algorithms typically require multiple rounds of communication between the server and the clients, which has several drawbacks, including requiring constant network connectivity, repeated investment of computational resources, and susceptibility to privacy attacks. One-Shot FL is a new paradigm that aims to address this challenge by enabling the server to train a global model in a single round of communication. In this work, we present FedFisher, a novel algorithm for one-shot FL that makes use of Fisher information matrices computed on local client models, motivated by a Bayesian perspective of FL. First, we theoretically analyze FedFisher for two-layer over-parameterized ReLU neural networks and show that the error of our one-shot FedFisher global model becomes vanishingly small as the width of the neural networks and amount of local training at clients increases. Next, we propose practical variants of FedFisher using the diagonal Fisher and K-FAC approximation for the full Fisher and highlight their communication and compute efficiency for FL. Finally, we conduct extensive experiments on various datasets, which show that these variants of FedFisher consistently improve over competing baselines.",
        "bibtex": "@InProceedings{pmlr-v238-jhunjhunwala24a,\n  title = \t {{FedFisher}: Leveraging {F}isher Information for One-Shot Federated Learning},\n  author =       {Jhunjhunwala, Divyansh and Wang, Shiqiang and Joshi, Gauri},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1612--1620},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jhunjhunwala24a/jhunjhunwala24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jhunjhunwala24a.html},\n  abstract = \t {Standard federated learning (FL) algorithms typically require multiple rounds of communication between the server and the clients, which has several drawbacks, including requiring constant network connectivity, repeated investment of computational resources, and susceptibility to privacy attacks. One-Shot FL is a new paradigm that aims to address this challenge by enabling the server to train a global model in a single round of communication. In this work, we present FedFisher, a novel algorithm for one-shot FL that makes use of Fisher information matrices computed on local client models, motivated by a Bayesian perspective of FL. First, we theoretically analyze FedFisher for two-layer over-parameterized ReLU neural networks and show that the error of our one-shot FedFisher global model becomes vanishingly small as the width of the neural networks and amount of local training at clients increases. Next, we propose practical variants of FedFisher using the diagonal Fisher and K-FAC approximation for the full Fisher and highlight their communication and compute efficiency for FL. Finally, we conduct extensive experiments on various datasets, which show that these variants of FedFisher consistently improve over competing baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jhunjhunwala24a/jhunjhunwala24a.pdf",
        "supp": "",
        "pdf_size": 1073977,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8305597618872887177&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "93b1abe525",
        "title": "Federated Experiment Design under Distributed Differential Privacy",
        "site": "https://proceedings.mlr.press/v238/chen24c.html",
        "author": "Wei-Ning Chen; Graham Cormode; Akash Bharadwaj; Peter Romov; Ayfer Ozgur",
        "abstract": "Experiment design has a rich history dating back over a century and has found many critical applications across various fields since then. The use and collection of users\u2019 data in experiments often involve sensitive personal information, so additional measures to protect individual privacy are required during data collection, storage, and usage. In this work, we focus on the rigorous protection of users\u2019 privacy (under the notion of differential privacy (DP)) while minimizing the trust toward service providers. Specifically, we consider the estimation of the average treatment effect (ATE) under DP, while only allowing the analyst to collect population-level statistics via secure aggregation, a distributed protocol enabling a service provider to aggregate information without accessing individual data. Although a vital component in modern A/B testing workflows, private distributed experimentation has not previously been studied. To achieve DP, we design local privatization mechanisms that are compatible with secure aggregation and analyze the utility, in terms of the width of confidence intervals, both asymptotically and non-asymptotically. We show how these mechanisms can be scaled up to handle the very large number of participants commonly found in practice. In addition, when introducing DP noise, it is imperative to cleverly split privacy budgets to estimate both the mean and variance of the outcomes and carefully calibrate the confidence intervals according to the DP noise. Last, we present comprehensive experimental evaluations of our proposed schemes and show the privacy-utility trade-offs in experiment design.",
        "bibtex": "@InProceedings{pmlr-v238-chen24c,\n  title = \t {Federated Experiment Design under Distributed Differential Privacy},\n  author =       {Chen, Wei-Ning and Cormode, Graham and Bharadwaj, Akash and Romov, Peter and Ozgur, Ayfer},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2458--2466},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24c/chen24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24c.html},\n  abstract = \t {Experiment design has a rich history dating back over a century and has found many critical applications across various fields since then. The use and collection of users\u2019 data in experiments often involve sensitive personal information, so additional measures to protect individual privacy are required during data collection, storage, and usage. In this work, we focus on the rigorous protection of users\u2019 privacy (under the notion of differential privacy (DP)) while minimizing the trust toward service providers. Specifically, we consider the estimation of the average treatment effect (ATE) under DP, while only allowing the analyst to collect population-level statistics via secure aggregation, a distributed protocol enabling a service provider to aggregate information without accessing individual data. Although a vital component in modern A/B testing workflows, private distributed experimentation has not previously been studied. To achieve DP, we design local privatization mechanisms that are compatible with secure aggregation and analyze the utility, in terms of the width of confidence intervals, both asymptotically and non-asymptotically. We show how these mechanisms can be scaled up to handle the very large number of participants commonly found in practice. In addition, when introducing DP noise, it is imperative to cleverly split privacy budgets to estimate both the mean and variance of the outcomes and carefully calibrate the confidence intervals according to the DP noise. Last, we present comprehensive experimental evaluations of our proposed schemes and show the privacy-utility trade-offs in experiment design.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24c/chen24c.pdf",
        "supp": "",
        "pdf_size": 622148,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=756637172779950323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Stanford University1+Meta2; Meta2+University of Warwick3; Meta2+ByteDance4; Meta2; Stanford University1",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;2;3;0",
        "aff_unique_norm": "Stanford University;;University of Warwick;ByteDance",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.stanford.edu;;https://warwick.ac.uk;https://www.bytedance.com",
        "aff_unique_abbr": "Stanford;;Warwick;ByteDance",
        "aff_campus_unique_index": "0;;;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;2;3;0",
        "aff_country_unique": "United States;;United Kingdom;China"
    },
    {
        "id": "12ea5bd131",
        "title": "Federated Learning For Heterogeneous Electronic Health Records Utilising Augmented Temporal Graph Attention Networks",
        "site": "https://proceedings.mlr.press/v238/molaei24a.html",
        "author": "Soheila Molaei; Anshul Thakur; Ghazaleh Niknam; Andrew Soltan; Hadi Zare; David A Clifton",
        "abstract": "The proliferation of decentralised electronic healthcare records (EHRs) across medical institutions requires innovative federated learning strategies for collaborative data analysis and global model training, prioritising data privacy. A prevalent issue during decentralised model training is the data-view discrepancies across medical institutions that arises from differences or availability of healthcare services, such as blood test panels. The prevailing way to handle this issue is to select a common subset of features across institutions to make data-views consistent. This approach, however, constrains some institutions to shed some critical features that may play a significant role in improving the model performance. This paper introduces a federated learning framework that relies on augmented graph attention networks to address data-view heterogeneity. The proposed framework utilises an alignment augmentation layer over self-attention mechanisms to weigh the importance of neighbouring nodes when updating a node\u2019s embedding irrespective of the data-views. Furthermore, our framework adeptly addresses both the temporal nuances and structural intricacies of EHR datasets. This dual capability not only offers deeper insights but also effectively encapsulates EHR graphs\u2019 time-evolving nature. Using diverse real-world datasets, we show that the proposed framework significantly outperforms conventional FL methodology for dealing with heterogeneous data-views.",
        "bibtex": "@InProceedings{pmlr-v238-molaei24a,\n  title = \t {Federated Learning For Heterogeneous Electronic Health Records Utilising Augmented Temporal Graph Attention Networks},\n  author =       {Molaei, Soheila and Thakur, Anshul and Niknam, Ghazaleh and Soltan, Andrew and Zare, Hadi and A Clifton, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1342--1350},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/molaei24a/molaei24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/molaei24a.html},\n  abstract = \t {The proliferation of decentralised electronic healthcare records (EHRs) across medical institutions requires innovative federated learning strategies for collaborative data analysis and global model training, prioritising data privacy. A prevalent issue during decentralised model training is the data-view discrepancies across medical institutions that arises from differences or availability of healthcare services, such as blood test panels. The prevailing way to handle this issue is to select a common subset of features across institutions to make data-views consistent. This approach, however, constrains some institutions to shed some critical features that may play a significant role in improving the model performance. This paper introduces a federated learning framework that relies on augmented graph attention networks to address data-view heterogeneity. The proposed framework utilises an alignment augmentation layer over self-attention mechanisms to weigh the importance of neighbouring nodes when updating a node\u2019s embedding irrespective of the data-views. Furthermore, our framework adeptly addresses both the temporal nuances and structural intricacies of EHR datasets. This dual capability not only offers deeper insights but also effectively encapsulates EHR graphs\u2019 time-evolving nature. Using diverse real-world datasets, we show that the proposed framework significantly outperforms conventional FL methodology for dealing with heterogeneous data-views.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/molaei24a/molaei24a.pdf",
        "supp": "",
        "pdf_size": 4377636,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15004727721164129795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b3fb0bfe6d",
        "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
        "site": "https://proceedings.mlr.press/v238/blaser24a.html",
        "author": "Ethan Blaser; Chuanhao Li; Hongning Wang",
        "abstract": "The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model can be shared by the server.",
        "bibtex": "@InProceedings{pmlr-v238-blaser24a,\n  title = \t {Federated Linear Contextual Bandits with Heterogeneous Clients},\n  author =       {Blaser, Ethan and Li, Chuanhao and Wang, Hongning},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {631--639},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/blaser24a/blaser24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/blaser24a.html},\n  abstract = \t {The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model can be shared by the server.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/blaser24a/blaser24a.pdf",
        "supp": "",
        "pdf_size": 945525,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3526190893643010775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef57b15a20",
        "title": "Filter, Rank, and Prune: Learning Linear Cyclic Gaussian Graphical Models",
        "site": "https://proceedings.mlr.press/v238/yi24a.html",
        "author": "Soheun Yi; Sanghack Lee",
        "abstract": "Causal structures in the real world often exhibit cycles naturally due to equilibrium, homeostasis, or feedback. However, causal discovery from observational studies regarding cyclic models has not been investigated extensively because the underlying structure of a linear cyclic structural equation model (SEM) cannot be determined solely from observational data. Inspired by the Bayesian information Criterion (BIC), we construct a score function that assesses both accuracy and sparsity of the structure to determine which linear Gaussian SEM is the best when only observational data is given. Then, we formulate a causal discovery problem as an optimization problem of the measure and propose the Filter, Rank, and Prune (FRP) method for solving it. We empirically demonstrate that our method outperforms competitive cyclic causal discovery baselines.",
        "bibtex": "@InProceedings{pmlr-v238-yi24a,\n  title = \t {Filter, Rank, and Prune: Learning Linear Cyclic {G}aussian Graphical Models},\n  author =       {Yi, Soheun and Lee, Sanghack},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1135--1143},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yi24a/yi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yi24a.html},\n  abstract = \t {Causal structures in the real world often exhibit cycles naturally due to equilibrium, homeostasis, or feedback. However, causal discovery from observational studies regarding cyclic models has not been investigated extensively because the underlying structure of a linear cyclic structural equation model (SEM) cannot be determined solely from observational data. Inspired by the Bayesian information Criterion (BIC), we construct a score function that assesses both accuracy and sparsity of the structure to determine which linear Gaussian SEM is the best when only observational data is given. Then, we formulate a causal discovery problem as an optimization problem of the measure and propose the Filter, Rank, and Prune (FRP) method for solving it. We empirically demonstrate that our method outperforms competitive cyclic causal discovery baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yi24a/yi24a.pdf",
        "supp": "",
        "pdf_size": 653883,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:E7eCVPBeGRMJ:scholar.google.com/&scioq=Filter,+Rank,+and+Prune:+Learning+Linear+Cyclic+Gaussian+Graphical+Models&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Department of Statistics & Data Science, Carnegie Mellon University; Graduate School of Data Science, Seoul National University",
        "aff_domain": "cmu.edu;snu.ac.kr",
        "email": "cmu.edu;snu.ac.kr",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;Seoul National University",
        "aff_unique_dep": "Department of Statistics & Data Science;Graduate School of Data Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.snu.ac.kr",
        "aff_unique_abbr": "CMU;SNU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9f78c08122",
        "title": "First Passage Percolation with Queried Hints",
        "site": "https://proceedings.mlr.press/v238/karntikoon24a.html",
        "author": "Kritkorn Karntikoon; Yiheng Shen; Sreenivas Gollapudi; Kostas Kollias; Aaron Schild; Ali K Sinop",
        "abstract": "Solving optimization problems leads to elegant and practical solutions in a wide variety of real-world applications. In many of those real-world applications, some of the information required to specify the relevant optimization problem is noisy, uncertain, and expensive to obtain. In this work, we study how much of that information needs to be queried in order to obtain an approximately optimal solution to the relevant problem. In particular, we focus on the shortest path problem in graphs with dynamic edge costs. We adopt the {\\em first passage percolation} model from probability theory wherein a graph $G\u2019$ is derived from a weighted base graph $G$ by multiplying each edge weight by an independently chosen, random number in $[1, \\rho]$. Mathematicians have studied this model extensively when $G$ is a $d$-dimensional grid graph, but the behavior of shortest paths in this model is still poorly understood in general graphs. We make progress in this direction for a class of graphs that resemble real-world road networks. Specifically, we prove that if $G$ has a constant continuous doubling dimension, then for a given $s-t$ pair, we only need to probe the weights on $((\\rho \\log n )/ \\epsilon)^{O(1)}$ edges in $G\u2019$ in order to obtain a $(1 + \\epsilon)$-approximation to the $s-t$ distance in $G\u2019$. We also generalize the result to a correlated setting and demonstrate experimentally that probing improves accuracy in estimating $s-t$ distances.",
        "bibtex": "@InProceedings{pmlr-v238-karntikoon24a,\n  title = \t {First Passage Percolation with Queried Hints},\n  author =       {Karntikoon, Kritkorn and Shen, Yiheng and Gollapudi, Sreenivas and Kollias, Kostas and Schild, Aaron and K Sinop, Ali},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4231--4239},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/karntikoon24a/karntikoon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/karntikoon24a.html},\n  abstract = \t {Solving optimization problems leads to elegant and practical solutions in a wide variety of real-world applications. In many of those real-world applications, some of the information required to specify the relevant optimization problem is noisy, uncertain, and expensive to obtain. In this work, we study how much of that information needs to be queried in order to obtain an approximately optimal solution to the relevant problem. In particular, we focus on the shortest path problem in graphs with dynamic edge costs. We adopt the {\\em first passage percolation} model from probability theory wherein a graph $G\u2019$ is derived from a weighted base graph $G$ by multiplying each edge weight by an independently chosen, random number in $[1, \\rho]$. Mathematicians have studied this model extensively when $G$ is a $d$-dimensional grid graph, but the behavior of shortest paths in this model is still poorly understood in general graphs. We make progress in this direction for a class of graphs that resemble real-world road networks. Specifically, we prove that if $G$ has a constant continuous doubling dimension, then for a given $s-t$ pair, we only need to probe the weights on $((\\rho \\log n )/ \\epsilon)^{O(1)}$ edges in $G\u2019$ in order to obtain a $(1 + \\epsilon)$-approximation to the $s-t$ distance in $G\u2019$. We also generalize the result to a correlated setting and demonstrate experimentally that probing improves accuracy in estimating $s-t$ distances.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/karntikoon24a/karntikoon24a.pdf",
        "supp": "",
        "pdf_size": 483660,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12226568072506678457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a0e6332056",
        "title": "Fitting ARMA Time Series Models without Identification: A Proximal Approach",
        "site": "https://proceedings.mlr.press/v238/liu24e.html",
        "author": "Yin Liu; Sam Davanloo Tajbakhsh",
        "abstract": "Fitting autoregressive moving average (ARMA) time series models requires model identification before parameter estimation. Model identification involves determining the order of the autoregressive and moving average components which is generally performed by inspection of the autocorrelation and partial autocorrelation functions or other offline methods. In this work, we regularize the parameter estimation optimization problem with a non-smooth hierarchical sparsity-inducing penalty based on two path graphs that allow performing model identification and parameter estimation simultaneously. A proximal block coordinate descent algorithm is then proposed to solve the underlying optimization problem efficiently. The resulting model satisfies the required stationarity and invertibility conditions for ARMA models. Numerical results supporting the proposed method are also presented.",
        "bibtex": "@InProceedings{pmlr-v238-liu24e,\n  title = \t {Fitting {ARMA} Time Series Models without Identification: A Proximal Approach},\n  author =       {Liu, Yin and Davanloo Tajbakhsh, Sam},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3835--3843},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24e/liu24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24e.html},\n  abstract = \t {Fitting autoregressive moving average (ARMA) time series models requires model identification before parameter estimation. Model identification involves determining the order of the autoregressive and moving average components which is generally performed by inspection of the autocorrelation and partial autocorrelation functions or other offline methods. In this work, we regularize the parameter estimation optimization problem with a non-smooth hierarchical sparsity-inducing penalty based on two path graphs that allow performing model identification and parameter estimation simultaneously. A proximal block coordinate descent algorithm is then proposed to solve the underlying optimization problem efficiently. The resulting model satisfies the required stationarity and invertibility conditions for ARMA models. Numerical results supporting the proposed method are also presented.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24e/liu24e.pdf",
        "supp": "",
        "pdf_size": 752253,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7202390716893785427&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Integrated Systems Engineering, The Ohio State University, OH, US; Department of Integrated Systems Engineering, The Ohio State University, OH, US",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Department of Integrated Systems Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "OH",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ffde75a3f0",
        "title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit",
        "site": "https://proceedings.mlr.press/v238/nakamura24a.html",
        "author": "Shintaro Nakamura; Masashi Sugiyama",
        "abstract": "We study the real-valued combinatorial pure exploration of the multi-armed bandit in the fixed-budget setting. We first introduce an algorithm named the Combinatorial Successive Asign (CSA) algorithm, which is the first algorithm that can identify the best action even when the size of the action class is exponentially large with respect to the number of arms. We show that the upper bound of the probability of error of the CSA algorithm matches a lower bound up to a logarithmic factor in the exponent. Then, we introduce another algorithm named the Minimax Combinatorial Successive Accepts and Rejects (Minimax-CombSAR) algorithm for the case where the size of the action class is polynomial, and show that it is optimal, which matches a lower bound. Finally, we experimentally compare the algorithms with previous methods and show that our algorithm performs better.",
        "bibtex": "@InProceedings{pmlr-v238-nakamura24a,\n  title = \t {Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit},\n  author =       {Nakamura, Shintaro and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1225--1233},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nakamura24a/nakamura24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nakamura24a.html},\n  abstract = \t {We study the real-valued combinatorial pure exploration of the multi-armed bandit in the fixed-budget setting. We first introduce an algorithm named the Combinatorial Successive Asign (CSA) algorithm, which is the first algorithm that can identify the best action even when the size of the action class is exponentially large with respect to the number of arms. We show that the upper bound of the probability of error of the CSA algorithm matches a lower bound up to a logarithmic factor in the exponent. Then, we introduce another algorithm named the Minimax Combinatorial Successive Accepts and Rejects (Minimax-CombSAR) algorithm for the case where the size of the action class is polynomial, and show that it is optimal, which matches a lower bound. Finally, we experimentally compare the algorithms with previous methods and show that our algorithm performs better.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nakamura24a/nakamura24a.pdf",
        "supp": "",
        "pdf_size": 839999,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11540416073180694381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Tokyo; RIKEN AIP+University of Tokyo",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";Advanced Institute for Computational Science",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.aip.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN AIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "1bc65dce05",
        "title": "Fixed-kinetic Neural Hamiltonian Flows for enhanced interpretability and reduced complexity",
        "site": "https://proceedings.mlr.press/v238/souveton24a.html",
        "author": "Vincent Souveton; Arnaud Guillin; Jens Jasche; Guilhem Lavaux; Manon Michel",
        "abstract": "Normalizing Flows (NF) are Generative models which transform a simple prior distribution into the desired target. They however require the design of an invertible mapping whose Jacobian determinant has to be computable. Recently introduced, Neural Hamiltonian Flows (NHF) are Hamiltonian dynamics-based flows, which are continuous, volume-preserving and invertible and thus make for natural candidates for robust NF architectures. In particular, their similarity to classical Mechanics could lead to easier interpretability of the learned mapping. In this paper, we show that the current NHF architecture may still pose a challenge to interpretability. Inspired by Physics, we introduce a fixed-kinetic energy version of the model. This approach improves interpretability and robustness while requiring fewer parameters than the original model. We illustrate that on a 2D Gaussian mixture and on the MNIST and Fashion-MNIST datasets. Finally, we show how to adapt NHF to the context of Bayesian inference and illustrate the method on an example from cosmology.",
        "bibtex": "@InProceedings{pmlr-v238-souveton24a,\n  title = \t {Fixed-kinetic Neural {H}amiltonian Flows for enhanced interpretability and reduced complexity},\n  author =       {Souveton, Vincent and Guillin, Arnaud and Jasche, Jens and Lavaux, Guilhem and Michel, Manon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3178--3186},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/souveton24a/souveton24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/souveton24a.html},\n  abstract = \t {Normalizing Flows (NF) are Generative models which transform a simple prior distribution into the desired target. They however require the design of an invertible mapping whose Jacobian determinant has to be computable. Recently introduced, Neural Hamiltonian Flows (NHF) are Hamiltonian dynamics-based flows, which are continuous, volume-preserving and invertible and thus make for natural candidates for robust NF architectures. In particular, their similarity to classical Mechanics could lead to easier interpretability of the learned mapping. In this paper, we show that the current NHF architecture may still pose a challenge to interpretability. Inspired by Physics, we introduce a fixed-kinetic energy version of the model. This approach improves interpretability and robustness while requiring fewer parameters than the original model. We illustrate that on a 2D Gaussian mixture and on the MNIST and Fashion-MNIST datasets. Finally, we show how to adapt NHF to the context of Bayesian inference and illustrate the method on an example from cosmology.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/souveton24a/souveton24a.pdf",
        "supp": "",
        "pdf_size": 3286769,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=81666364269079042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "LMBP, CNRS, Universit\u00e9 Clermont-Auvergne; LMBP, IUF, Universit\u00e9 Clermont-Auvergne; Stockholm University; IAP, CNRS, Sorbonne Universit\u00e9; LMBP, CNRS, Universit\u00e9 Clermont-Auvergne",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Universit\u00e9 Clermont-Auvergne;Stockholm University;Sorbonne Universit\u00e9",
        "aff_unique_dep": "LMBP;;Institut d'Astrophysique de Paris (IAP)",
        "aff_unique_url": "https://www.uca.fr;https://www.su.se;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "UCA;SU;Sorbonne U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "France;Sweden"
    },
    {
        "id": "74b5330cec",
        "title": "Formal Verification of Unknown Stochastic Systems via Non-parametric Estimation",
        "site": "https://proceedings.mlr.press/v238/zhang24i.html",
        "author": "Zhi Zhang; Chenyu Ma; Saleh Soudijani; Sadegh Soudjani",
        "abstract": "A novel data-driven method for formal verification is proposed to study complex systems operating in safety-critical domains. The proposed approach is able to formally verify discrete-time stochastic dynamical systems against temporal logic specifications only using observation samples and without the knowledge of the model, and provide a probabilistic guarantee on the satisfaction of the specification. We first propose the theoretical results for using non-parametric estimation to estimate an asymptotic upper bound for the \\emph{Lipschitz constant} of the stochastic system, which can determine a finite abstraction of the system. Our results prove that the asymptotic convergence rate of the estimation is $O(n^{-\\frac{1}{3+d}})$, where $d$ is the dimension of the system and n is the data scale. We then construct interval Markov decision processes using two different data-driven methods, namely non-parametric estimation and empirical estimation of transition probabilities, to perform formal verification against a given temporal logic specification. Multiple case studies are presented to validate the effectiveness of the proposed methods.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24i,\n  title = \t {Formal Verification of Unknown Stochastic Systems via Non-parametric Estimation},\n  author =       {Zhang, Zhi and Ma, Chenyu and Soudijani, Saleh and Soudjani, Sadegh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3277--3285},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24i/zhang24i.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24i.html},\n  abstract = \t {A novel data-driven method for formal verification is proposed to study complex systems operating in safety-critical domains. The proposed approach is able to formally verify discrete-time stochastic dynamical systems against temporal logic specifications only using observation samples and without the knowledge of the model, and provide a probabilistic guarantee on the satisfaction of the specification. We first propose the theoretical results for using non-parametric estimation to estimate an asymptotic upper bound for the \\emph{Lipschitz constant} of the stochastic system, which can determine a finite abstraction of the system. Our results prove that the asymptotic convergence rate of the estimation is $O(n^{-\\frac{1}{3+d}})$, where $d$ is the dimension of the system and n is the data scale. We then construct interval Markov decision processes using two different data-driven methods, namely non-parametric estimation and empirical estimation of transition probabilities, to perform formal verification against a given temporal logic specification. Multiple case studies are presented to validate the effectiveness of the proposed methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24i/zhang24i.pdf",
        "supp": "",
        "pdf_size": 4923515,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5080597068383477097&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3351497aa0",
        "title": "Free-form Flows: Make Any Architecture a Normalizing Flow",
        "site": "https://proceedings.mlr.press/v238/draxler24a.html",
        "author": "Felix Draxler; Peter Sorrenson; Lea Zimmermann; Armand Rousselot; Ullrich K\u00f6the",
        "abstract": "Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing E(n)-equivariant networks at greatly improved sampling speed. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures. We publish our code at https://github.com/vislearn/FFF.",
        "bibtex": "@InProceedings{pmlr-v238-draxler24a,\n  title = \t {Free-form Flows: Make Any Architecture a Normalizing Flow},\n  author =       {Draxler, Felix and Sorrenson, Peter and Zimmermann, Lea and Rousselot, Armand and K\\\"{o}the, Ullrich},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2197--2205},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/draxler24a/draxler24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/draxler24a.html},\n  abstract = \t {Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing E(n)-equivariant networks at greatly improved sampling speed. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures. We publish our code at https://github.com/vislearn/FFF.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/draxler24a/draxler24a.pdf",
        "supp": "",
        "pdf_size": 1975484,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14767591394775408318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Computer Vision and Learning Lab, Heidelberg University; Computer Vision and Learning Lab, Heidelberg University; Computer Vision and Learning Lab, Heidelberg University; Computer Vision and Learning Lab, Heidelberg University; Computer Vision and Learning Lab, Heidelberg University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/vislearn/FFF",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Heidelberg University",
        "aff_unique_dep": "Computer Vision and Learning Lab",
        "aff_unique_url": "https://www.uni-heidelberg.de",
        "aff_unique_abbr": "Uni HD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Heidelberg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "a6b307c566",
        "title": "From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach",
        "site": "https://proceedings.mlr.press/v238/nguyen24c.html",
        "author": "Tuan Nguyen; Hirotada Honda; Takashi Sano; Vinh Nguyen; Shugo Nakamura; Tan Minh Nguyen",
        "abstract": "We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to still reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.",
        "bibtex": "@InProceedings{pmlr-v238-nguyen24c,\n  title = \t {From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a {K}uramoto Model-based Approach},\n  author =       {Nguyen, Tuan and Honda, Hirotada and Sano, Takashi and Nguyen, Vinh and Nakamura, Shugo and Minh Nguyen, Tan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2710--2718},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nguyen24c/nguyen24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nguyen24c.html},\n  abstract = \t {We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to still reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nguyen24c/nguyen24c.pdf",
        "supp": "",
        "pdf_size": 881281,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9752587597515904695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "FPT Software AI Center+Toyo University; Toyo University; Toyo University; FPT Software AI Center; Toyo University; National University of Singapore",
        "aff_domain": "gmail.com; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;0;1;2",
        "aff_unique_norm": "FPT Software;Toyo University;National University of Singapore",
        "aff_unique_dep": "AI Center;;",
        "aff_unique_url": "https://www.fpt-software.com;https://www.toyo-u.ac.jp;https://www.nus.edu.sg",
        "aff_unique_abbr": ";Toyo U;NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;1;1;0;1;2",
        "aff_country_unique": "Vietnam;Japan;Singapore"
    },
    {
        "id": "c49c1180f0",
        "title": "From Data Imputation to Data Cleaning \u2014 Automated Cleaning of Tabular Data Improves Downstream Predictive Performance",
        "site": "https://proceedings.mlr.press/v238/jager24a.html",
        "author": "Sebastian J\u00e4ger; Felix Biessmann",
        "abstract": "The translation of Machine Learning (ML) research innovations to real-world applications and the maintenance of ML components are hindered by reoccurring challenges, such as reaching high predictive performance, robustness, complying with regulatory constraints, or meeting ethical standards. Many of these challenges are related to data quality and, in particular, to the lack of automation in data pipelines upstream of ML components. Automated data cleaning remains challenging since many approaches neglect the dependency structure of the data errors and require task-specific heuristics or human input for calibration. In this study, we develop and evaluate an application-agnostic ML-based data cleaning approach using well-established imputation techniques for automated detection and cleaning of erroneous values. To improve the degree of automation, we combine imputation techniques with conformal prediction (CP), a model-agnostic and distribution-free method to quantify and calibrate the uncertainty of ML models. Extensive empirical evaluations demonstrate that Conformal Data Cleaning (CDC) improves predictive performance in downstream ML tasks in the majority of cases. Our code is available on GitHub: \\url{https://github.com/se-jaeger/conformal-data-cleaning}.",
        "bibtex": "@InProceedings{pmlr-v238-jager24a,\n  title = \t {From Data Imputation to Data Cleaning \u2014 Automated Cleaning of Tabular Data Improves Downstream Predictive Performance},\n  author =       {J\\\"{a}ger, Sebastian and Biessmann, Felix},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3394--3402},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jager24a/jager24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jager24a.html},\n  abstract = \t {The translation of Machine Learning (ML) research innovations to real-world applications and the maintenance of ML components are hindered by reoccurring challenges, such as reaching high predictive performance, robustness, complying with regulatory constraints, or meeting ethical standards. Many of these challenges are related to data quality and, in particular, to the lack of automation in data pipelines upstream of ML components. Automated data cleaning remains challenging since many approaches neglect the dependency structure of the data errors and require task-specific heuristics or human input for calibration. In this study, we develop and evaluate an application-agnostic ML-based data cleaning approach using well-established imputation techniques for automated detection and cleaning of erroneous values. To improve the degree of automation, we combine imputation techniques with conformal prediction (CP), a model-agnostic and distribution-free method to quantify and calibrate the uncertainty of ML models. Extensive empirical evaluations demonstrate that Conformal Data Cleaning (CDC) improves predictive performance in downstream ML tasks in the majority of cases. Our code is available on GitHub: \\url{https://github.com/se-jaeger/conformal-data-cleaning}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jager24a/jager24a.pdf",
        "supp": "",
        "pdf_size": 472260,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13304637327949998921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Berlin University of Applied Sciences and Technology (BHT), Germany; Berlin University of Applied Sciences and Technology (BHT), Germany + Einstein Center Digital Future, Berlin, Germany",
        "aff_domain": "bht-berlin.de; ",
        "email": "bht-berlin.de; ",
        "github": "https://github.com/se-jaeger/conformal-data-cleaning",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Berlin University of Applied Sciences and Technology;Einstein Center Digital Future",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bht-berlin.de/;",
        "aff_unique_abbr": "BHT;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "3f1022da8a",
        "title": "Functional Flow Matching",
        "site": "https://proceedings.mlr.press/v238/kerrigan24a.html",
        "author": "Gavin Kerrigan; Giosue Migliorini; Padhraic Smyth",
        "abstract": "We propose Functional Flow Matching (FFM), a function-space generative model that generalizes the recently-introduced Flow Matching model to operate directly in infinite-dimensional spaces. Our approach works by first defining a path of probability measures that interpolates between a fixed Gaussian measure and the data distribution, followed by learning a vector field on the underlying space of functions that generates this path of measures. Our method does not rely on likelihoods or simulations, making it well-suited to the function space setting. We provide both a theoretical framework for building such models and an empirical evaluation of our techniques. We demonstrate through experiments on synthetic and real-world benchmarks that our proposed FFM method outperforms several recently proposed function-space generative models.",
        "bibtex": "@InProceedings{pmlr-v238-kerrigan24a,\n  title = \t {Functional Flow Matching},\n  author =       {Kerrigan, Gavin and Migliorini, Giosue and Smyth, Padhraic},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3934--3942},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kerrigan24a/kerrigan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kerrigan24a.html},\n  abstract = \t {We propose Functional Flow Matching (FFM), a function-space generative model that generalizes the recently-introduced Flow Matching model to operate directly in infinite-dimensional spaces. Our approach works by first defining a path of probability measures that interpolates between a fixed Gaussian measure and the data distribution, followed by learning a vector field on the underlying space of functions that generates this path of measures. Our method does not rely on likelihoods or simulations, making it well-suited to the function space setting. We provide both a theoretical framework for building such models and an empirical evaluation of our techniques. We demonstrate through experiments on synthetic and real-world benchmarks that our proposed FFM method outperforms several recently proposed function-space generative models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kerrigan24a/kerrigan24a.pdf",
        "supp": "",
        "pdf_size": 20175212,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7851812750613679306&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of California, Irvine; Department of Statistics, University of California, Irvine + Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine",
        "aff_domain": "uci.edu;uci.edu;ics.uci.edu",
        "email": "uci.edu;uci.edu;ics.uci.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0;0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0;0+0;0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3e2a6b8fc6",
        "title": "Functional Graphical Models: Structure Enables Offline Data-Driven Optimization",
        "site": "https://proceedings.mlr.press/v238/grudzien24a.html",
        "author": "Kuba Grudzien; Masatoshi Uehara; Sergey Levine; Pieter Abbeel",
        "abstract": "While machine learning models are typically trained to solve prediction problems, we might often want to use them for optimization problems. For example, given a dataset of proteins and their corresponding fluorescence levels, we might want to optimize for a new protein with the highest possible fluorescence. This kind of data-driven optimization (DDO) presents a range of challenges beyond those in standard prediction problems, since we need models that successfully predict the performance of new designs that are better than the best designs seen in the training set. It is not clear theoretically when existing approaches can even perform better than the na \u00efve approach that simply selects the best design in the dataset. In this paper, we study how structure can enable sample-efficient data-driven optimization. To formalize the notion of structure, we introduce functional graphical models (FGMs) and show theoretically how they can provide for principled data-driven optimization by decomposing the original high-dimensional optimization problem into smaller sub-problems. This allows us to derive much more practical regret bounds for DDO, and the result implies that DDO with FGMs can achieve nearly optimal designs in situations where na\u00efve approaches fail due to insufficient coverage of the offline data. We further present a data-driven optimization algorithm that inferes the FGM structure itself, either over the original input variables or a latent variable representation of the inputs.",
        "bibtex": "@InProceedings{pmlr-v238-grudzien24a,\n  title = \t {Functional Graphical Models: Structure Enables Offline Data-Driven Optimization},\n  author =       {Grudzien, Kuba and Uehara, Masatoshi and Levine, Sergey and Abbeel, Pieter},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2449--2457},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/grudzien24a/grudzien24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/grudzien24a.html},\n  abstract = \t {While machine learning models are typically trained to solve prediction problems, we might often want to use them for optimization problems. For example, given a dataset of proteins and their corresponding fluorescence levels, we might want to optimize for a new protein with the highest possible fluorescence. This kind of data-driven optimization (DDO) presents a range of challenges beyond those in standard prediction problems, since we need models that successfully predict the performance of new designs that are better than the best designs seen in the training set. It is not clear theoretically when existing approaches can even perform better than the na \u00efve approach that simply selects the best design in the dataset. In this paper, we study how structure can enable sample-efficient data-driven optimization. To formalize the notion of structure, we introduce functional graphical models (FGMs) and show theoretically how they can provide for principled data-driven optimization by decomposing the original high-dimensional optimization problem into smaller sub-problems. This allows us to derive much more practical regret bounds for DDO, and the result implies that DDO with FGMs can achieve nearly optimal designs in situations where na\u00efve approaches fail due to insufficient coverage of the offline data. We further present a data-driven optimization algorithm that inferes the FGM structure itself, either over the original input variables or a latent variable representation of the inputs.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/grudzien24a/grudzien24a.pdf",
        "supp": "",
        "pdf_size": 886563,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3177781988475876286&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b599d704cd",
        "title": "Fusing Individualized Treatment Rules Using Secondary Outcomes",
        "site": "https://proceedings.mlr.press/v238/gao24a.html",
        "author": "Daiqi Gao; Yuanjia Wang; Donglin Zeng",
        "abstract": "An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the non-asymptotic properties of the value function and misclassification rate for the proposed method. Finally, simulation studies and a real data example are used to demonstrate the finite-sample performance of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v238-gao24a,\n  title = \t {Fusing Individualized Treatment Rules Using Secondary Outcomes},\n  author =       {Gao, Daiqi and Wang, Yuanjia and Zeng, Donglin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {712--720},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gao24a/gao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gao24a.html},\n  abstract = \t {An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the non-asymptotic properties of the value function and misclassification rate for the proposed method. Finally, simulation studies and a real data example are used to demonstrate the finite-sample performance of the proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gao24a/gao24a.pdf",
        "supp": "",
        "pdf_size": 1029159,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6508320319470918030&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "101364ed1b",
        "title": "GRAWA: Gradient-based Weighted Averaging for Distributed Training of Deep Learning Models",
        "site": "https://proceedings.mlr.press/v238/dimlioglu24a.html",
        "author": "Tolga Dimlioglu; Anna Choromanska",
        "abstract": "We study distributed training of deep learning models in time-constrained environments. We propose a new algorithm that periodically pulls workers towards the center variable computed as a weighted average of workers, where the weights are inversely proportional to the gradient norms of the workers such that recovering the flat regions in the optimization landscape is prioritized. We develop two asynchronous variants of the proposed algorithm that we call Model-level and Layer-level Gradient-based Weighted Averaging (resp. MGRAWA and LGRAWA), which differ in terms of the weighting scheme that is either done with respect to the entire model or is applied layer-wise. On the theoretical front, we prove the convergence guarantee for the proposed approach in both convex and non-convex settings. We then experimentally demonstrate that our algorithms outperform the competitor methods by achieving faster convergence and recovering better quality and flatter local optima. We also carry out an ablation study to analyze the scalability of the proposed algorithms in more crowded distributed training environments. Finally, we report that our approach requires less frequent communication and fewer distributed updates compared to the state-of-the-art baselines.",
        "bibtex": "@InProceedings{pmlr-v238-dimlioglu24a,\n  title = \t {GRAWA: Gradient-based Weighted Averaging for Distributed Training of Deep Learning Models},\n  author =       {Dimlioglu, Tolga and Choromanska, Anna},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2251--2259},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dimlioglu24a/dimlioglu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dimlioglu24a.html},\n  abstract = \t {We study distributed training of deep learning models in time-constrained environments. We propose a new algorithm that periodically pulls workers towards the center variable computed as a weighted average of workers, where the weights are inversely proportional to the gradient norms of the workers such that recovering the flat regions in the optimization landscape is prioritized. We develop two asynchronous variants of the proposed algorithm that we call Model-level and Layer-level Gradient-based Weighted Averaging (resp. MGRAWA and LGRAWA), which differ in terms of the weighting scheme that is either done with respect to the entire model or is applied layer-wise. On the theoretical front, we prove the convergence guarantee for the proposed approach in both convex and non-convex settings. We then experimentally demonstrate that our algorithms outperform the competitor methods by achieving faster convergence and recovering better quality and flatter local optima. We also carry out an ablation study to analyze the scalability of the proposed algorithms in more crowded distributed training environments. Finally, we report that our approach requires less frequent communication and fewer distributed updates compared to the state-of-the-art baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dimlioglu24a/dimlioglu24a.pdf",
        "supp": "",
        "pdf_size": 2447277,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17231001827682625586&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "New York University; New York University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "445defb861",
        "title": "Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels",
        "site": "https://proceedings.mlr.press/v238/carpintero-perez24a.html",
        "author": "Rapha\u00ebl Carpintero Perez; S\u00e9bastien Da Veiga; Josselin Garnier; Brian Staber",
        "abstract": "Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molecular datasets, where the input graphs have a few tens of nodes. The efficiency of the SWWL kernel is then illustrated on graph regression in computational fluid dynamics and solid mechanics, where the input graphs are made up of tens of thousands of nodes.",
        "bibtex": "@InProceedings{pmlr-v238-carpintero-perez24a,\n  title = \t {{G}aussian process regression with Sliced {W}asserstein {W}eisfeiler-{L}ehman graph kernels},\n  author =       {Carpintero Perez, Rapha\\\"{e}l and Da Veiga, S\\'{e}bastien and Garnier, Josselin and Staber, Brian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1297--1305},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/carpintero-perez24a/carpintero-perez24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/carpintero-perez24a.html},\n  abstract = \t {Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molecular datasets, where the input graphs have a few tens of nodes. The efficiency of the SWWL kernel is then illustrated on graph regression in computational fluid dynamics and solid mechanics, where the input graphs are made up of tens of thousands of nodes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/carpintero-perez24a/carpintero-perez24a.pdf",
        "supp": "",
        "pdf_size": 3278801,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6433958040063331472&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1d3643f80d",
        "title": "General Identifiability and Achievability for Causal Representation Learning",
        "site": "https://proceedings.mlr.press/v238/varici24a.html",
        "author": "Burak Varici; Emre Acart\u00fcrk; Karthikeyan Shanmugam; Ali Tajer",
        "abstract": "This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.",
        "bibtex": "@InProceedings{pmlr-v238-varici24a,\n  title = \t {General Identifiability and Achievability for Causal Representation Learning},\n  author =       {Varici, Burak and Acart\\\"{u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2314--2322},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/varici24a/varici24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/varici24a.html},\n  abstract = \t {This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/varici24a/varici24a.pdf",
        "supp": "",
        "pdf_size": 646740,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9970743355600037245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2e50a45aad",
        "title": "General Tail Bounds for Non-Smooth Stochastic Mirror Descent",
        "site": "https://proceedings.mlr.press/v238/eldowa24a.html",
        "author": "Khaled Eldowa; Andrea Paudice",
        "abstract": "In this paper, we provide novel tail bounds on the optimization error of Stochastic Mirror Descent for convex and Lipschitz objectives. Our analysis extends the existing tail bounds from the classical light-tailed Sub-Gaussian noise case to heavier-tailed noise regimes. We study the optimization error of the last iterate as well as the average of the iterates. We instantiate our results in two important cases: a class of noise with exponential tails and one with polynomial tails. A remarkable feature of our results is that they do not require an upper bound on the diameter of the domain. Finally, we support our theory with illustrative experiments that compare the behavior of the average of the iterates with that of the last iterate in heavy-tailed noise regimes.",
        "bibtex": "@InProceedings{pmlr-v238-eldowa24a,\n  title = \t {General Tail Bounds for Non-Smooth Stochastic Mirror Descent},\n  author =       {Eldowa, Khaled and Paudice, Andrea},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3205--3213},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/eldowa24a/eldowa24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/eldowa24a.html},\n  abstract = \t {In this paper, we provide novel tail bounds on the optimization error of Stochastic Mirror Descent for convex and Lipschitz objectives. Our analysis extends the existing tail bounds from the classical light-tailed Sub-Gaussian noise case to heavier-tailed noise regimes. We study the optimization error of the last iterate as well as the average of the iterates. We instantiate our results in two important cases: a class of noise with exponential tails and one with polynomial tails. A remarkable feature of our results is that they do not require an upper bound on the diameter of the domain. Finally, we support our theory with illustrative experiments that compare the behavior of the average of the iterates with that of the last iterate in heavy-tailed noise regimes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/eldowa24a/eldowa24a.pdf",
        "supp": "",
        "pdf_size": 949057,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18406136976927081897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Universit\u00e0 degli Studi di Milano, Milan, Italy; Universit\u00e0 degli Studi di Milano, Milan, Italy",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unimi.it",
        "aff_unique_abbr": "UniMi",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Milan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "3540169e0c",
        "title": "Generalization Bounds for Label Noise Stochastic Gradient Descent",
        "site": "https://proceedings.mlr.press/v238/eun-huh24a.html",
        "author": "Jung Eun Huh; Patrick Rebeschini",
        "abstract": "We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD)\u2014which employs parameter-independent Gaussian noise\u2014under similar conditions. Our analysis offers quantitative insights into the effect of label noise.",
        "bibtex": "@InProceedings{pmlr-v238-eun-huh24a,\n  title = \t {Generalization Bounds for Label Noise Stochastic Gradient Descent},\n  author =       {Eun Huh, Jung and Rebeschini, Patrick},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1360--1368},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/eun-huh24a/eun-huh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/eun-huh24a.html},\n  abstract = \t {We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD)\u2014which employs parameter-independent Gaussian noise\u2014under similar conditions. Our analysis offers quantitative insights into the effect of label noise.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/eun-huh24a/eun-huh24a.pdf",
        "supp": "",
        "pdf_size": 430914,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14877439343918467030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, University of Oxford; Department of Statistics, University of Oxford",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c4078c7aab",
        "title": "Generalization Bounds of Nonconvex-(Strongly)-Concave Stochastic Minimax Optimization",
        "site": "https://proceedings.mlr.press/v238/zhang24c.html",
        "author": "Siqi Zhang; Yifan Hu; Liang Zhang; Niao He",
        "abstract": "This paper studies the generalization performance of algorithms for solving nonconvex-(strongly)-concave (NC-SC/NC-C) stochastic minimax optimization measured by the stationarity of primal functions. We first establish algorithm-agnostic generalization bounds via uniform convergence between the empirical minimax problem and the population minimax problem. The sample complexities for achieving $\\epsilon$-generalization are $\\tilde{\\mathcal{O}}(d\\kappa^2\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d\\epsilon^{-4})$ for NC-SC and NC-C settings, respectively, where $d$ is the dimension of the primal variable and $\\kappa$ is the condition number. We further study the algorithm-dependent generalization bounds via stability arguments of algorithms. In particular, we introduce a novel stability notion for minimax problems and build a connection between stability and generalization. As a result, we establish algorithm-dependent generalization bounds for stochastic gradient descent ascent (SGDA) and the more general sampling-determined algorithms (SDA).",
        "bibtex": "@InProceedings{pmlr-v238-zhang24c,\n  title = \t {Generalization Bounds of Nonconvex-(Strongly)-Concave Stochastic Minimax Optimization},\n  author =       {Zhang, Siqi and Hu, Yifan and Zhang, Liang and He, Niao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {694--702},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24c/zhang24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24c.html},\n  abstract = \t {This paper studies the generalization performance of algorithms for solving nonconvex-(strongly)-concave (NC-SC/NC-C) stochastic minimax optimization measured by the stationarity of primal functions. We first establish algorithm-agnostic generalization bounds via uniform convergence between the empirical minimax problem and the population minimax problem. The sample complexities for achieving $\\epsilon$-generalization are $\\tilde{\\mathcal{O}}(d\\kappa^2\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d\\epsilon^{-4})$ for NC-SC and NC-C settings, respectively, where $d$ is the dimension of the primal variable and $\\kappa$ is the condition number. We further study the algorithm-dependent generalization bounds via stability arguments of algorithms. In particular, we introduce a novel stability notion for minimax problems and build a connection between stability and generalization. As a result, we establish algorithm-dependent generalization bounds for stochastic gradient descent ascent (SGDA) and the more general sampling-determined algorithms (SDA).}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24c/zhang24c.pdf",
        "supp": "",
        "pdf_size": 508281,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13074670388167566476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "02f8e4ef73",
        "title": "Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees",
        "site": "https://proceedings.mlr.press/v238/jolicoeur-martineau24a.html",
        "author": "Alexia Jolicoeur-Martineau; Kilian Fatras; Tal Kachman",
        "abstract": "Tabular data is hard to acquire and is subject to missing values. This paper introduces a novel approach for generating and imputing mixed-type (continuous and categorical) tabular data utilizing score-based diffusion and conditional flow matching. In contrast to prior methods that rely on neural networks to learn the score function or the vector field, we adopt XGBoost, a widely used Gradient-Boosted Tree (GBT) technique. To test our method, we build one of the most extensive benchmarks for tabular data generation and imputation, containing 27 diverse datasets and 9 metrics. Through empirical evaluation across the benchmark, we demonstrate that our approach outperforms deep-learning generation methods in data generation tasks and remains competitive in data imputation. Notably, it can be trained in parallel using CPUs without requiring a GPU. Our Python and R code is available at \\url{https://github.com/SamsungSAILMontreal/ForestDiffusion}.",
        "bibtex": "@InProceedings{pmlr-v238-jolicoeur-martineau24a,\n  title = \t {Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees},\n  author =       {Jolicoeur-Martineau, Alexia and Fatras, Kilian and Kachman, Tal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1288--1296},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jolicoeur-martineau24a/jolicoeur-martineau24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jolicoeur-martineau24a.html},\n  abstract = \t {Tabular data is hard to acquire and is subject to missing values. This paper introduces a novel approach for generating and imputing mixed-type (continuous and categorical) tabular data utilizing score-based diffusion and conditional flow matching. In contrast to prior methods that rely on neural networks to learn the score function or the vector field, we adopt XGBoost, a widely used Gradient-Boosted Tree (GBT) technique. To test our method, we build one of the most extensive benchmarks for tabular data generation and imputation, containing 27 diverse datasets and 9 metrics. Through empirical evaluation across the benchmark, we demonstrate that our approach outperforms deep-learning generation methods in data generation tasks and remains competitive in data imputation. Notably, it can be trained in parallel using CPUs without requiring a GPU. Our Python and R code is available at \\url{https://github.com/SamsungSAILMontreal/ForestDiffusion}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jolicoeur-martineau24a/jolicoeur-martineau24a.pdf",
        "supp": "",
        "pdf_size": 4921057,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15012533652376898558&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "94500c1777",
        "title": "Generative Flow Networks as Entropy-Regularized RL",
        "site": "https://proceedings.mlr.press/v238/tiapkin24a.html",
        "author": "Daniil Tiapkin; Nikita Morozov; Alexey Naumov; Dmitry P Vetrov",
        "abstract": "The recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions. GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL). Our work extends the connection between RL and GFlowNets to a general case. We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure. Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks. Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods. This perspective opens a direct path for integrating RL principles into the realm of generative flow networks.",
        "bibtex": "@InProceedings{pmlr-v238-tiapkin24a,\n  title = \t {Generative Flow Networks as Entropy-Regularized {RL}},\n  author =       {Tiapkin, Daniil and Morozov, Nikita and Naumov, Alexey and P Vetrov, Dmitry},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4213--4221},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tiapkin24a/tiapkin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tiapkin24a.html},\n  abstract = \t {The recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions. GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL). Our work extends the connection between RL and GFlowNets to a general case. We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure. Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks. Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods. This perspective opens a direct path for integrating RL principles into the realm of generative flow networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tiapkin24a/tiapkin24a.pdf",
        "supp": "",
        "pdf_size": 1942838,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3674327601815006510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "CMAP - CNRS - \u00c9cole polytechnique - Institut Polytechnique de Paris + LMO, CNRS, Universit\u00e9 Paris-Saclay + HSE University; HSE University + Steklov Mathematical Institute, Russian Academy of Sciences; HSE University; Constructor University, Bremen",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;2+3;2;4",
        "aff_unique_norm": "Institut Polytechnique de Paris;Universit\u00e9 Paris-Saclay;Higher School of Economics;Steklov Mathematical Institute;Constructor University",
        "aff_unique_dep": "CMAP;LMO;;Mathematics;",
        "aff_unique_url": "https://www.ipparis.fr;https://www.universite-paris-saclay.fr;https://hse.ru;http://www.ras.ru/index.php?;",
        "aff_unique_abbr": "IP Paris;UPS;HSE;RAS;",
        "aff_campus_unique_index": ";;1",
        "aff_campus_unique": ";Bremen",
        "aff_country_unique_index": "0+0+1;1+1;1;2",
        "aff_country_unique": "France;Russian Federation;Germany"
    },
    {
        "id": "69b4057b15",
        "title": "Gibbs-Based Information Criteria and the Over-Parameterized Regime",
        "site": "https://proceedings.mlr.press/v238/chen24g.html",
        "author": "Haobo Chen; Gregory W Wornell; Yuheng Bu",
        "abstract": "Double-descent refers to the unexpected drop in test loss of a learning algorithm beyond an interpolating threshold with over-parameterization, which is not predicted by information criteria in their classical forms due to the limitations in the standard asymptotic approach. We update these analyses using the information risk minimization framework and provide Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for models learned by the Gibbs algorithm. Notably, the penalty terms for the Gibbs-based AIC and BIC correspond to specific information measures, i.e., symmetrized KL information and KL divergence. We extend this information-theoretic analysis to over-parameterized models by providing two different Gibbs-based BICs to compute the marginal likelihood of random feature models in the regime where the number of parameters $p$ and the number of samples $n$ tend to infinity, with $p/n$ fixed. Our experiments demonstrate that the Gibbs-based BIC can select the high-dimensional model and reveal the mismatch between marginal likelihood and population risk in the over-parameterized regime, providing new insights to understand double-descent.",
        "bibtex": "@InProceedings{pmlr-v238-chen24g,\n  title = \t {Gibbs-Based Information Criteria and the Over-Parameterized Regime},\n  author =       {Chen, Haobo and W Wornell, Gregory and Bu, Yuheng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4501--4509},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24g/chen24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24g.html},\n  abstract = \t {Double-descent refers to the unexpected drop in test loss of a learning algorithm beyond an interpolating threshold with over-parameterization, which is not predicted by information criteria in their classical forms due to the limitations in the standard asymptotic approach. We update these analyses using the information risk minimization framework and provide Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for models learned by the Gibbs algorithm. Notably, the penalty terms for the Gibbs-based AIC and BIC correspond to specific information measures, i.e., symmetrized KL information and KL divergence. We extend this information-theoretic analysis to over-parameterized models by providing two different Gibbs-based BICs to compute the marginal likelihood of random feature models in the regime where the number of parameters $p$ and the number of samples $n$ tend to infinity, with $p/n$ fixed. Our experiments demonstrate that the Gibbs-based BIC can select the high-dimensional model and reveal the mismatch between marginal likelihood and population risk in the over-parameterized regime, providing new insights to understand double-descent.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24g/chen24g.pdf",
        "supp": "",
        "pdf_size": 1370036,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8040093430225566181&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Florida; Massachusetts Institute of Technology; University of Florida",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Florida;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ufl.edu;https://web.mit.edu",
        "aff_unique_abbr": "UF;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "787615167e",
        "title": "GmGM: a fast multi-axis Gaussian graphical model",
        "site": "https://proceedings.mlr.press/v238/andrew24a.html",
        "author": "Ethan B. Andrew; David Westhead; Luisa Cutillo",
        "abstract": "This paper introduces the Gaussian multi-Graphical Model, a model to construct sparse graph representations of matrix- and tensor-variate data. We generalize prior work in this area by simultaneously learning this representation across several tensors that share axes, which is necessary to allow the analysis of multimodal datasets such as those encountered in multi-omics. Our algorithm uses only a single eigendecomposition per axis, achieving an order of magnitude speedup over prior work in the ungeneralized case. This allows the use of our methodology on large multi-modal datasets such as single-cell multi-omics data, which was challenging with previous approaches. We validate our model on synthetic data and five real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-andrew24a,\n  title = \t {{GmGM}: a fast multi-axis {G}aussian graphical model},\n  author =       {Andrew, Ethan B. and Westhead, David and Cutillo, Luisa},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2053--2061},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/andrew24a/andrew24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/andrew24a.html},\n  abstract = \t {This paper introduces the Gaussian multi-Graphical Model, a model to construct sparse graph representations of matrix- and tensor-variate data. We generalize prior work in this area by simultaneously learning this representation across several tensors that share axes, which is necessary to allow the analysis of multimodal datasets such as those encountered in multi-omics. Our algorithm uses only a single eigendecomposition per axis, achieving an order of magnitude speedup over prior work in the ungeneralized case. This allows the use of our methodology on large multi-modal datasets such as single-cell multi-omics data, which was challenging with previous approaches. We validate our model on synthetic data and five real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/andrew24a/andrew24a.pdf",
        "supp": "",
        "pdf_size": 9368695,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3728772625642412464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "343f5aaaf5",
        "title": "Graph Machine Learning through the Lens of Bilevel Optimization",
        "site": "https://proceedings.mlr.press/v238/yijia-zheng24a.html",
        "author": "Amber Yijia Zheng; Tong He; Yixuan Qiu; Minjie Wang; David Wipf",
        "abstract": "Bilevel optimization refers to scenarios whereby the optimal solution of a lower-level energy function serves as input features to an upper-level objective of interest. These optimal features typically depend on tunable parameters of the lower-level energy in such a way that the entire bilevel pipeline can be trained end-to-end. Although not generally presented as such, this paper demonstrates how a variety of graph learning techniques can be recast as special cases of bilevel optimization or simplifications thereof. In brief, building on prior work we first derive a more flexible class of energy functions that, when paired with various descent steps (e.g., gradient descent, proximal methods, momentum, etc.), form graph neural network (GNN) message-passing layers; critically, we also carefully unpack where any residual approximation error lies with respect to the underlying constituent message-passing functions. We then probe several simplifications of this framework to derive close connections with non-GNN-based graph learning approaches, including knowledge graph embeddings, various forms of label propagation, and efficient graph-regularized MLP models. And finally, we present supporting empirical results that demonstrate the versatility of the proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel Optimization Offers More Graph Machine Learning. Our code is available at \\url{https://github.com/amberyzheng/BloomGML}. Let graph ML bloom.",
        "bibtex": "@InProceedings{pmlr-v238-yijia-zheng24a,\n  title = \t {Graph Machine Learning through the Lens of Bilevel Optimization},\n  author =       {Yijia Zheng, Amber and He, Tong and Qiu, Yixuan and Wang, Minjie and Wipf, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {982--990},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yijia-zheng24a/yijia-zheng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yijia-zheng24a.html},\n  abstract = \t {Bilevel optimization refers to scenarios whereby the optimal solution of a lower-level energy function serves as input features to an upper-level objective of interest. These optimal features typically depend on tunable parameters of the lower-level energy in such a way that the entire bilevel pipeline can be trained end-to-end. Although not generally presented as such, this paper demonstrates how a variety of graph learning techniques can be recast as special cases of bilevel optimization or simplifications thereof. In brief, building on prior work we first derive a more flexible class of energy functions that, when paired with various descent steps (e.g., gradient descent, proximal methods, momentum, etc.), form graph neural network (GNN) message-passing layers; critically, we also carefully unpack where any residual approximation error lies with respect to the underlying constituent message-passing functions. We then probe several simplifications of this framework to derive close connections with non-GNN-based graph learning approaches, including knowledge graph embeddings, various forms of label propagation, and efficient graph-regularized MLP models. And finally, we present supporting empirical results that demonstrate the versatility of the proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel Optimization Offers More Graph Machine Learning. Our code is available at \\url{https://github.com/amberyzheng/BloomGML}. Let graph ML bloom.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yijia-zheng24a/yijia-zheng24a.pdf",
        "supp": "",
        "pdf_size": 857569,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1100443361201116127&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Purdue University; Amazon Web Services; Shanghai University of Finance and Economics; Amazon Web Services; Amazon Web Services",
        "aff_domain": "purdue.edu;amazon.com;shufe.edu.cn;amazon.com;amazon.com",
        "email": "purdue.edu;amazon.com;shufe.edu.cn;amazon.com;amazon.com",
        "github": "https://github.com/amberyzheng/BloomGML",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Purdue University;Amazon;Shanghai University of Finance and Economics",
        "aff_unique_dep": ";Amazon Web Services;",
        "aff_unique_url": "https://www.purdue.edu;https://aws.amazon.com;http://www.sufe.edu.cn",
        "aff_unique_abbr": "Purdue;AWS;SUFE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "4ab69adb6b",
        "title": "Graph Partitioning with a Move Budget",
        "site": "https://proceedings.mlr.press/v238/dalirrooyfard24a.html",
        "author": "Mina Dalirrooyfard; Elaheh Fata; Majid Behbahani; Yuriy Nevmyvaka",
        "abstract": "In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, for such networks, one aims to find a $k$-partitioning with a smaller cut value by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning\u00a0problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning\u00a0problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant.",
        "bibtex": "@InProceedings{pmlr-v238-dalirrooyfard24a,\n  title = \t {Graph Partitioning with a Move Budget},\n  author =       {Dalirrooyfard, Mina and Fata, Elaheh and Behbahani, Majid and Nevmyvaka, Yuriy},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {568--576},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dalirrooyfard24a/dalirrooyfard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dalirrooyfard24a.html},\n  abstract = \t {In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, for such networks, one aims to find a $k$-partitioning with a smaller cut value by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning\u00a0problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning\u00a0problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dalirrooyfard24a/dalirrooyfard24a.pdf",
        "supp": "",
        "pdf_size": 439905,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15224126044268319405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2a796ee0d1",
        "title": "Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets",
        "site": "https://proceedings.mlr.press/v238/lymperopoulos24a.html",
        "author": "Panagiotis Lymperopoulos; Liping Liu",
        "abstract": "Finding Minimal Unsatisfiable Subsets (MUSes) of boolean constraints is a common problem in infeasibility analysis of over-constrained systems. However, because of the exponential search space of the problem, enumerating MUSes is extremely time-consuming in real applications. In this work, we propose to prune formulas using a learned model to speed up MUS enumeration. We represent formulas as graphs and then develop a graph-based learning model to predict which part of the formula should be pruned. Importantly, the training of our model does not require labeled data. It does not even require training data from the target application because it extrapolates to data with different distributions. In our experiments we combine our model with existing MUS enumerators and validate its effectiveness in multiple benchmarks including a set of real-world problems outside our training distribution. The experiment results show that our method significantly accelerates MUS enumeration on average on these benchmark problems.",
        "bibtex": "@InProceedings{pmlr-v238-lymperopoulos24a,\n  title = \t {Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets},\n  author =       {Lymperopoulos, Panagiotis and Liu, Liping},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2647--2655},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lymperopoulos24a/lymperopoulos24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lymperopoulos24a.html},\n  abstract = \t {Finding Minimal Unsatisfiable Subsets (MUSes) of boolean constraints is a common problem in infeasibility analysis of over-constrained systems. However, because of the exponential search space of the problem, enumerating MUSes is extremely time-consuming in real applications. In this work, we propose to prune formulas using a learned model to speed up MUS enumeration. We represent formulas as graphs and then develop a graph-based learning model to predict which part of the formula should be pruned. Importantly, the training of our model does not require labeled data. It does not even require training data from the target application because it extrapolates to data with different distributions. In our experiments we combine our model with existing MUS enumerators and validate its effectiveness in multiple benchmarks including a set of real-world problems outside our training distribution. The experiment results show that our method significantly accelerates MUS enumeration on average on these benchmark problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lymperopoulos24a/lymperopoulos24a.pdf",
        "supp": "",
        "pdf_size": 756585,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5862594432572412461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Tufts University; Tufts University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1bf487c7ed",
        "title": "Graph fission and cross-validation",
        "site": "https://proceedings.mlr.press/v238/leiner24a.html",
        "author": "James Leiner; Aaditya Ramdas",
        "abstract": "We introduce a technique called graph fission which takes in a graph which potentially contains only one observation per node (whose distribution lies in a known class) and produces two (or more) independent graphs with the same node/edge set in a way that splits the original graph\u2019s information amongst them in any desired proportion. Our proposal builds on data fission/thinning, a method that uses external randomization to create independent copies of an unstructured dataset. We extend this idea to the graph setting where there may be latent structure between observations. We demonstrate the utility of this framework via two applications: inference after structural trend estimation on graphs and a model selection procedure we term \"graph cross-validation\"\u2019.",
        "bibtex": "@InProceedings{pmlr-v238-leiner24a,\n  title = \t {Graph fission and cross-validation},\n  author =       {Leiner, James and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2638--2646},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/leiner24a/leiner24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/leiner24a.html},\n  abstract = \t {We introduce a technique called graph fission which takes in a graph which potentially contains only one observation per node (whose distribution lies in a known class) and produces two (or more) independent graphs with the same node/edge set in a way that splits the original graph\u2019s information amongst them in any desired proportion. Our proposal builds on data fission/thinning, a method that uses external randomization to create independent copies of an unstructured dataset. We extend this idea to the graph setting where there may be latent structure between observations. We demonstrate the utility of this framework via two applications: inference after structural trend estimation on graphs and a model selection procedure we term \"graph cross-validation\"\u2019.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/leiner24a/leiner24a.pdf",
        "supp": "",
        "pdf_size": 2267252,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:McX532XmjRUJ:scholar.google.com/&scioq=Graph+fission+and+cross-validation&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "stat.cmu.edu;stat.cmu.edu",
        "email": "stat.cmu.edu;stat.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "44a1a4cc42",
        "title": "Hidden yet quantifiable: A lower bound for confounding strength using randomized trials",
        "site": "https://proceedings.mlr.press/v238/de-bartolomeis24a.html",
        "author": "Piersilvio De Bartolomeis; Javier Abad Martinez; Konstantin Donhauser; Fanny Yang",
        "abstract": "In the era of fast-paced precision medicine, observational studies play a major role in properly evaluating new treatments in clinical practice. Yet, unobserved confounding can significantly compromise causal conclusions drawn from non-randomized data. We propose a novel strategy that leverages randomized trials to quantify unobserved confounding. First, we design a statistical test to detect unobserved confounding above a certain strength. Then, we use the test to estimate an asymptotically valid lower bound on the unobserved confounding strength. We evaluate the power and validity of our statistical test on several synthetic and semi-synthetic datasets. Further, we show how our lower bound can correctly identify the absence and presence of unobserved confounding in a real-world example.",
        "bibtex": "@InProceedings{pmlr-v238-de-bartolomeis24a,\n  title = \t {Hidden yet quantifiable: A lower bound for confounding strength using randomized trials},\n  author =       {De Bartolomeis, Piersilvio and Abad Martinez, Javier and Donhauser, Konstantin and Yang, Fanny},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1045--1053},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/de-bartolomeis24a/de-bartolomeis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/de-bartolomeis24a.html},\n  abstract = \t {In the era of fast-paced precision medicine, observational studies play a major role in properly evaluating new treatments in clinical practice. Yet, unobserved confounding can significantly compromise causal conclusions drawn from non-randomized data. We propose a novel strategy that leverages randomized trials to quantify unobserved confounding. First, we design a statistical test to detect unobserved confounding above a certain strength. Then, we use the test to estimate an asymptotically valid lower bound on the unobserved confounding strength. We evaluate the power and validity of our statistical test on several synthetic and semi-synthetic datasets. Further, we show how our lower bound can correctly identify the absence and presence of unobserved confounding in a real-world example.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/de-bartolomeis24a/de-bartolomeis24a.pdf",
        "supp": "",
        "pdf_size": 807550,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15983902224100738797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2869498503",
        "title": "HintMiner: Automatic Question Hints Mining From Q&A Web Posts with Language Model via Self-Supervised Learning",
        "site": "https://proceedings.mlr.press/v238/zhang24a.html",
        "author": "Zhenyu Zhang; JiuDong Yang",
        "abstract": "Users often need ask questions and seek answers online. The Question - Answering (QA) forums such as Stack Overflow cannot always respond to the questions timely and properly. In this paper, we propose HintMiner, a novel automatic question hints mining tool for users to help them find answers. HintMiner leverages the machine comprehension and sequence generation techniques to automatically generate hints for users\u2019 questions. It firstly retrieve many web Q&A posts and then extract some hints from the posts using MiningNet that is built via a language model. Using the huge amount of online Q&A posts, we design a self-supervised objective to train the MiningNet that is a neural encoder-decoder model based on the transformer and copying mechanisms. We have evaluated HintMiner on 60,000 Stack Overflow questions. The experiment results show that the proposed approach is effective. For example, HintMiner achieves an average BLEU score of 36.17% and an average ROUGE-2 score of 36.29%. Our tool and experimental data are publicly available at \\url{https://github.com/zhangzhenyu13/HintMiner}.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24a,\n  title = \t {{H}int{M}iner: Automatic Question Hints Mining From {Q}&{A} Web Posts with Language Model via Self-Supervised Learning},\n  author =       {Zhang, Zhenyu and Yang, JiuDong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {271--279},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24a/zhang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24a.html},\n  abstract = \t {Users often need ask questions and seek answers online. The Question - Answering (QA) forums such as Stack Overflow cannot always respond to the questions timely and properly. In this paper, we propose HintMiner, a novel automatic question hints mining tool for users to help them find answers. HintMiner leverages the machine comprehension and sequence generation techniques to automatically generate hints for users\u2019 questions. It firstly retrieve many web Q&A posts and then extract some hints from the posts using MiningNet that is built via a language model. Using the huge amount of online Q&A posts, we design a self-supervised objective to train the MiningNet that is a neural encoder-decoder model based on the transformer and copying mechanisms. We have evaluated HintMiner on 60,000 Stack Overflow questions. The experiment results show that the proposed approach is effective. For example, HintMiner achieves an average BLEU score of 36.17% and an average ROUGE-2 score of 36.29%. Our tool and experimental data are publicly available at \\url{https://github.com/zhangzhenyu13/HintMiner}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24a/zhang24a.pdf",
        "supp": "",
        "pdf_size": 838359,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10005787864300518036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "JD AI; JD AI",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/zhangzhenyu13/HintMiner",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "JD",
        "aff_unique_dep": "JD AI",
        "aff_unique_url": "https://www.jd.com",
        "aff_unique_abbr": "JD AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "686bb71a0e",
        "title": "Hodge-Compositional Edge Gaussian Processes",
        "site": "https://proceedings.mlr.press/v238/yang24e.html",
        "author": "Maosheng Yang; Viacheslav Borovitskiy; Elvin Isufi",
        "abstract": "We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create Hodge-compositional edge GPs that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean currents and water supply networks, comparing them to alternative models.",
        "bibtex": "@InProceedings{pmlr-v238-yang24e,\n  title = \t {Hodge-Compositional Edge {G}aussian Processes},\n  author =       {Yang, Maosheng and Borovitskiy, Viacheslav and Isufi, Elvin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3754--3762},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yang24e/yang24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yang24e.html},\n  abstract = \t {We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create Hodge-compositional edge GPs that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean currents and water supply networks, comparing them to alternative models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yang24e/yang24e.pdf",
        "supp": "",
        "pdf_size": 8034167,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5653039305625207692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "TU Delft, Netherlands; ETH Z\u00fcrich, Switzerland; TU Delft, Netherlands",
        "aff_domain": "tudelft.nl; ; ",
        "email": "tudelft.nl; ; ",
        "github": "https://github.com/cookbook-ms/Hodge-Edge-GP",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Delft University of Technology;ETH Zurich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ethz.ch",
        "aff_unique_abbr": "TU Delft;ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Delft;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;Switzerland"
    },
    {
        "id": "36278bb3f8",
        "title": "Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection",
        "site": "https://proceedings.mlr.press/v238/mahmudul-alam24a.html",
        "author": "Mohammad Mahmudul Alam; Edward Raff; Stella R Biderman; Tim Oates; James Holt",
        "abstract": "Malware detection is an interesting and valuable domain to work in because it has significant real-world impact and unique machine-learning challenges. We investigate existing long-range techniques and benchmarks and find that they\u2019re not very suitable in this problem area. In this paper, we introduce Holographic Global Convolutional Networks (HGConv) that utilize the properties of Holographic Reduced Representations (HRR) to encode and decode features from sequence elements. Unlike other global convolutional methods, our method does not require any intricate kernel computation or crafted kernel design. HGConv kernels are defined as simple parameters learned through backpropagation. The proposed method has achieved new SOTA results on Microsoft Malware Classification Challenge, Drebin, and EMBER malware benchmarks. With log-linear complexity in sequence length, the empirical results demonstrate substantially faster run-time by HGConv compared to other methods achieving far more efficient scaling even with sequence length $\\geq 100,000$.",
        "bibtex": "@InProceedings{pmlr-v238-mahmudul-alam24a,\n  title = \t {Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection},\n  author =       {Mahmudul Alam, Mohammad and Raff, Edward and R Biderman, Stella and Oates, Tim and Holt, James},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4042--4050},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mahmudul-alam24a/mahmudul-alam24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mahmudul-alam24a.html},\n  abstract = \t {Malware detection is an interesting and valuable domain to work in because it has significant real-world impact and unique machine-learning challenges. We investigate existing long-range techniques and benchmarks and find that they\u2019re not very suitable in this problem area. In this paper, we introduce Holographic Global Convolutional Networks (HGConv) that utilize the properties of Holographic Reduced Representations (HRR) to encode and decode features from sequence elements. Unlike other global convolutional methods, our method does not require any intricate kernel computation or crafted kernel design. HGConv kernels are defined as simple parameters learned through backpropagation. The proposed method has achieved new SOTA results on Microsoft Malware Classification Challenge, Drebin, and EMBER malware benchmarks. With log-linear complexity in sequence length, the empirical results demonstrate substantially faster run-time by HGConv compared to other methods achieving far more efficient scaling even with sequence length $\\geq 100,000$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mahmudul-alam24a/mahmudul-alam24a.pdf",
        "supp": "",
        "pdf_size": 5955153,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15832686982299153685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Maryland, Baltimore County; University of Maryland, Baltimore County+Booz Allen Hamilton; Booz Allen Hamilton; University of Maryland, Baltimore County; Laboratory for Physical Sciences",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;1;0;2",
        "aff_unique_norm": "University of Maryland, Baltimore County;Booz Allen Hamilton;Laboratory for Physical Sciences",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.umbc.edu;https://www.boozallen.com;",
        "aff_unique_abbr": "UMBC;BAH;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore County;",
        "aff_country_unique_index": "0;0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4b04e20a5e",
        "title": "Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation",
        "site": "https://proceedings.mlr.press/v238/huang24b.html",
        "author": "Jiayi Huang; Han Zhong; Liwei Wang; Lin Yang",
        "abstract": "To tackle long planning horizon problems in reinforcement learning with general function approximation, we propose the first algorithm, termed as UCRL-WVTR, that achieves both \\emph{horizon-free} and \\emph{instance-dependent}, since it eliminates the polynomial dependency on the planning horizon. The derived regret bound is deemed \\emph{sharp}, as it matches the minimax lower bound when specialized to linear mixture MDPs up to logarithmic factors. Furthermore, UCRL-WVTR is \\emph{computationally efficient} with access to a regression oracle. The achievement of such a horizon-free, instance-dependent, and sharp regret bound hinges upon (i) novel algorithm designs: weighted value-targeted regression and a high-order moment estimator in the context of general function approximation; and (ii) fine-grained analysis: a novel concentration bound of weighted non-linear least squares and a refined analysis which leads to the tight instance-dependent bound. We also conduct comprehensive experiments to corroborate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-huang24b,\n  title = \t {Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation},\n  author =       {Huang, Jiayi and Zhong, Han and Wang, Liwei and Yang, Lin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3673--3681},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/huang24b/huang24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/huang24b.html},\n  abstract = \t {To tackle long planning horizon problems in reinforcement learning with general function approximation, we propose the first algorithm, termed as UCRL-WVTR, that achieves both \\emph{horizon-free} and \\emph{instance-dependent}, since it eliminates the polynomial dependency on the planning horizon. The derived regret bound is deemed \\emph{sharp}, as it matches the minimax lower bound when specialized to linear mixture MDPs up to logarithmic factors. Furthermore, UCRL-WVTR is \\emph{computationally efficient} with access to a regression oracle. The achievement of such a horizon-free, instance-dependent, and sharp regret bound hinges upon (i) novel algorithm designs: weighted value-targeted regression and a high-order moment estimator in the context of general function approximation; and (ii) fine-grained analysis: a novel concentration bound of weighted non-linear least squares and a refined analysis which leads to the tight instance-dependent bound. We also conduct comprehensive experiments to corroborate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/huang24b/huang24b.pdf",
        "supp": "",
        "pdf_size": 1091074,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1843167079327880826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "83a5ef604a",
        "title": "How Good is a Single Basin?",
        "site": "https://proceedings.mlr.press/v238/lion24a.html",
        "author": "Kai Lion; Lorenzo Noci; Thomas Hofmann; Gregor Bachmann",
        "abstract": "The multi-modal nature of neural loss landscapes is often considered to be the main driver behind the empirical success of deep ensembles. In this work, we probe this belief by constructing various \"connected\" ensembles which are restricted to lie in the same basin. Through our experiments, we demonstrate that increased connectivity indeed negatively impacts performance. However, when incorporating the knowledge from other basins implicitly through distillation, we show that the gap in performance can be mitigated by re-discovering (multi-basin) deep ensembles within a single basin. Thus, we conjecture that while the extra-basin knowledge is at least partially present in any given basin, it cannot be easily harnessed without learning it from other basins.",
        "bibtex": "@InProceedings{pmlr-v238-lion24a,\n  title = \t {How Good is a Single Basin?},\n  author =       {Lion, Kai and Noci, Lorenzo and Hofmann, Thomas and Bachmann, Gregor},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4015--4023},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lion24a/lion24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lion24a.html},\n  abstract = \t {The multi-modal nature of neural loss landscapes is often considered to be the main driver behind the empirical success of deep ensembles. In this work, we probe this belief by constructing various \"connected\" ensembles which are restricted to lie in the same basin. Through our experiments, we demonstrate that increased connectivity indeed negatively impacts performance. However, when incorporating the knowledge from other basins implicitly through distillation, we show that the gap in performance can be mitigated by re-discovering (multi-basin) deep ensembles within a single basin. Thus, we conjecture that while the extra-basin knowledge is at least partially present in any given basin, it cannot be easily harnessed without learning it from other basins.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lion24a/lion24a.pdf",
        "supp": "",
        "pdf_size": 780386,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b7b7256afb",
        "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability",
        "site": "https://proceedings.mlr.press/v238/garcia-carrasco24a.html",
        "author": "Jorge Garc\u00eda-Carrasco; Alejandro Mat\u00e9; Juan Carlos Trujillo",
        "abstract": "Transformer-based language models are treated as black-boxes because of their large number of parameters and complex internal interactions, which is a serious safety concern. Mechanistic Interpretability (MI) intends to reverse-engineer neural network behaviors in terms of human-understandable components. In this work, we focus on understanding how GPT-2 Small performs the task of predicting three-letter acronyms. Previous works in the MI field have focused so far on tasks that predict a single token. To the best of our knowledge, this is the first work that tries to mechanistically understand a behavior involving the prediction of multiple consecutive tokens. We discover that the prediction is performed by a circuit composed of 8 attention heads (${\\sim}5%$ of the total heads) which we classified in three groups according to their role. We also demonstrate that these heads concentrate the acronym prediction functionality. In addition, we mechanistically interpret the most relevant heads of the circuit and find out that they use positional information which is propagated via the causal mask mechanism. We expect this work to lay the foundation for understanding more complex behaviors involving multiple-token predictions.",
        "bibtex": "@InProceedings{pmlr-v238-garcia-carrasco24a,\n  title = \t {How does {GPT-2} Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability},\n  author =       {Garc\\'{i}a-Carrasco, Jorge and Mat\\'{e}, Alejandro and Carlos Trujillo, Juan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3322--3330},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/garcia-carrasco24a/garcia-carrasco24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/garcia-carrasco24a.html},\n  abstract = \t {Transformer-based language models are treated as black-boxes because of their large number of parameters and complex internal interactions, which is a serious safety concern. Mechanistic Interpretability (MI) intends to reverse-engineer neural network behaviors in terms of human-understandable components. In this work, we focus on understanding how GPT-2 Small performs the task of predicting three-letter acronyms. Previous works in the MI field have focused so far on tasks that predict a single token. To the best of our knowledge, this is the first work that tries to mechanistically understand a behavior involving the prediction of multiple consecutive tokens. We discover that the prediction is performed by a circuit composed of 8 attention heads (${\\sim}5%$ of the total heads) which we classified in three groups according to their role. We also demonstrate that these heads concentrate the acronym prediction functionality. In addition, we mechanistically interpret the most relevant heads of the circuit and find out that they use positional information which is propagated via the causal mask mechanism. We expect this work to lay the foundation for understanding more complex behaviors involving multiple-token predictions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/garcia-carrasco24a/garcia-carrasco24a.pdf",
        "supp": "",
        "pdf_size": 865314,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=601528287834252082&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bf6631d351",
        "title": "Identifiability of Product of Experts Models",
        "site": "https://proceedings.mlr.press/v238/kant24a.html",
        "author": "Manav Kant; Eric Y Ma; Andrei Staicu; Leonard J Schulman; Spencer Gordon",
        "abstract": "Product of experts (PoE) are layered networks in which the value at each node is an AND (or product) of the values (possibly negated) at its inputs. These were introduced as a neural network architecture that can efficiently learn to generate high-dimensional data which satisfy many low-dimensional constraints-thereby allowing each individual expert to perform a simple task. PoEs have found a variety of applications in learning. We study the problem of identifiability of a product of experts model having a layer of binary latent variables, and a layer of binary observables that are iid conditional on the latents. The previous best upper bound on the number of observables needed to identify the model was exponential in the number of parameters. We show: (a) When the latents are uniformly distributed, the model is identifiable with a number of observables equal to the number of parameters (and hence best possible). (b) In the more general case of arbitrarily distributed latents, the model is identifiable for a number of observables that is still linear in the number of parameters (and within a factor of two of best-possible). The proofs rely on root interlacing phenomena for some special three-term recurrences.",
        "bibtex": "@InProceedings{pmlr-v238-kant24a,\n  title = \t {Identifiability of Product of Experts Models},\n  author =       {Kant, Manav and Y Ma, Eric and Staicu, Andrei and J Schulman, Leonard and Gordon, Spencer},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4492--4500},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kant24a/kant24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kant24a.html},\n  abstract = \t {Product of experts (PoE) are layered networks in which the value at each node is an AND (or product) of the values (possibly negated) at its inputs. These were introduced as a neural network architecture that can efficiently learn to generate high-dimensional data which satisfy many low-dimensional constraints-thereby allowing each individual expert to perform a simple task. PoEs have found a variety of applications in learning. We study the problem of identifiability of a product of experts model having a layer of binary latent variables, and a layer of binary observables that are iid conditional on the latents. The previous best upper bound on the number of observables needed to identify the model was exponential in the number of parameters. We show: (a) When the latents are uniformly distributed, the model is identifiable with a number of observables equal to the number of parameters (and hence best possible). (b) In the more general case of arbitrarily distributed latents, the model is identifiable for a number of observables that is still linear in the number of parameters (and within a factor of two of best-possible). The proofs rely on root interlacing phenomena for some special three-term recurrences.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kant24a/kant24a.pdf",
        "supp": "",
        "pdf_size": 428424,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7233882415344192662&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "U. of Liverpool; Caltech; Caltech; Caltech; Caltech",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Liverpool;California Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.caltech.edu",
        "aff_unique_abbr": "Liv Uni;Caltech",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "d1a9d1d986",
        "title": "Identifiable Feature Learning for Spatial Data with Nonlinear ICA",
        "site": "https://proceedings.mlr.press/v238/halva24a.html",
        "author": "Hermanni H\u00e4lv\u00e4; Jonathan So; Richard E. Turner; Aapo Hyv\u00e4rinen",
        "abstract": "Recently, nonlinear ICA has surfaced as a popular alternative to the many heuristic models used in deep representation learning and disentanglement. An advantage of nonlinear ICA is that a sophisticated identifiability theory has been developed; in particular, it has been proven that the original components can be recovered under sufficiently strong latent dependencies. Despite this general theory, practical nonlinear ICA algorithms have so far been mainly limited to data with one-dimensional latent dependencies, especially time-series data. In this paper, we introduce a new nonlinear ICA framework that employs $t$-process (TP) latent components which apply naturally to data with higher-dimensional dependency structures, such as spatial and spatio-temporal data. In particular, we develop a new learning and inference algorithm that extends variational inference methods to handle the combination of a deep neural network mixing function with the TP prior, and employs the method of inducing points for computational efficacy. On the theoretical side, we show that such TP independent components are identifiable under very general conditions. Further, Gaussian Process (GP) nonlinear ICA is established as a limit of the TP Nonlinear ICA model, and we prove that the identifiability of the latent components at this GP limit is more restricted. Namely, those components are identifiable if and only if they have distinctly different covariance kernels. Our algorithm and identifiability theorems are explored on simulated spatial data and real world spatio-temporal data.",
        "bibtex": "@InProceedings{pmlr-v238-halva24a,\n  title = \t {Identifiable Feature Learning for Spatial Data with Nonlinear {ICA}},\n  author =       {H\\\"{a}lv\\\"{a}, Hermanni and So, Jonathan and Turner, Richard E. and Hyv\\\"{a}rinen, Aapo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3331--3339},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/halva24a/halva24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/halva24a.html},\n  abstract = \t {Recently, nonlinear ICA has surfaced as a popular alternative to the many heuristic models used in deep representation learning and disentanglement. An advantage of nonlinear ICA is that a sophisticated identifiability theory has been developed; in particular, it has been proven that the original components can be recovered under sufficiently strong latent dependencies. Despite this general theory, practical nonlinear ICA algorithms have so far been mainly limited to data with one-dimensional latent dependencies, especially time-series data. In this paper, we introduce a new nonlinear ICA framework that employs $t$-process (TP) latent components which apply naturally to data with higher-dimensional dependency structures, such as spatial and spatio-temporal data. In particular, we develop a new learning and inference algorithm that extends variational inference methods to handle the combination of a deep neural network mixing function with the TP prior, and employs the method of inducing points for computational efficacy. On the theoretical side, we show that such TP independent components are identifiable under very general conditions. Further, Gaussian Process (GP) nonlinear ICA is established as a limit of the TP Nonlinear ICA model, and we prove that the identifiability of the latent components at this GP limit is more restricted. Namely, those components are identifiable if and only if they have distinctly different covariance kernels. Our algorithm and identifiability theorems are explored on simulated spatial data and real world spatio-temporal data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/halva24a/halva24a.pdf",
        "supp": "",
        "pdf_size": 1456125,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16750744925921447823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "91846bcdb2",
        "title": "Identification and Estimation of \u201cCauses of Effects\u201d using Covariate-Mediator Information",
        "site": "https://proceedings.mlr.press/v238/shingaki24a.html",
        "author": "Ryusei Shingaki; Manabu Kuroki",
        "abstract": "In this paper, we deal with the evaluation problem of \"causes of effects\" (CoE), which focuses on the likelihood that one event was the cause of another. To assess this likelihood, three types of probabilities of causation have been utilized: probability of necessity, probability of sufficiency, and probability of necessity and sufficiency. However, these usually cannot be estimated, even if \"effects of causes\" (EoC) is estimable from statistical data, regardless of how large the data is. To solve this problem, we propose novel identification conditions for CoE, using an intermediate variable together with covariate information. Additionally, we also propose a new method for estimating CoE that is applicable whenever they are identifiable through the proposed identification conditions.",
        "bibtex": "@InProceedings{pmlr-v238-shingaki24a,\n  title = \t {Identification and Estimation of \u201cCauses of Effects\u201d using Covariate-Mediator Information},\n  author =       {Shingaki, Ryusei and Kuroki, Manabu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3574--3582},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shingaki24a/shingaki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shingaki24a.html},\n  abstract = \t {In this paper, we deal with the evaluation problem of \"causes of effects\" (CoE), which focuses on the likelihood that one event was the cause of another. To assess this likelihood, three types of probabilities of causation have been utilized: probability of necessity, probability of sufficiency, and probability of necessity and sufficiency. However, these usually cannot be estimated, even if \"effects of causes\" (EoC) is estimable from statistical data, regardless of how large the data is. To solve this problem, we propose novel identification conditions for CoE, using an intermediate variable together with covariate information. Additionally, we also propose a new method for estimating CoE that is applicable whenever they are identifiable through the proposed identification conditions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shingaki24a/shingaki24a.pdf",
        "supp": "",
        "pdf_size": 468776,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9543865270325270835&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bc62970184",
        "title": "Identifying Confounding from Causal Mechanism Shifts",
        "site": "https://proceedings.mlr.press/v238/mameche24a.html",
        "author": "Sarah Mameche; Jilles Vreeken; David Kaltenpoth",
        "abstract": "Causal discovery methods commonly assume that all data is independently and identically distributed (i.i.d.) and that there are no unmeasured confounding variables. In practice, neither is likely to hold, and detecting confounding in non-i.i.d. settings poses a significant challenge. Motivated by this, we explore how to discover confounders from data in multiple environments with causal mechanism shifts. We show that the mechanism changes of observed variables can reveal which variable sets are confounded. Based on this idea, we propose an empirically testable criterion based on mutual information, show under which conditions it can identify confounding, and introduce CoCo to discover confounders from data in multiple contexts. In our experiments, we show that CoCo works well on synthetic and real-world data.",
        "bibtex": "@InProceedings{pmlr-v238-mameche24a,\n  title = \t {Identifying Confounding from Causal Mechanism Shifts},\n  author =       {Mameche, Sarah and Vreeken, Jilles and Kaltenpoth, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4897--4905},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mameche24a/mameche24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mameche24a.html},\n  abstract = \t {Causal discovery methods commonly assume that all data is independently and identically distributed (i.i.d.) and that there are no unmeasured confounding variables. In practice, neither is likely to hold, and detecting confounding in non-i.i.d. settings poses a significant challenge. Motivated by this, we explore how to discover confounders from data in multiple environments with causal mechanism shifts. We show that the mechanism changes of observed variables can reveal which variable sets are confounded. Based on this idea, we propose an empirically testable criterion based on mutual information, show under which conditions it can identify confounding, and introduce CoCo to discover confounders from data in multiple contexts. In our experiments, we show that CoCo works well on synthetic and real-world data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mameche24a/mameche24a.pdf",
        "supp": "",
        "pdf_size": 883794,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16032345453053075429&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ca3e377ce5",
        "title": "Identifying Copeland Winners in Dueling Bandits with Indifferences",
        "site": "https://proceedings.mlr.press/v238/bengs24a.html",
        "author": "Viktor Bengs; Bj\u00f6rn Haddenhorst; Eyke H\u00fcllermeier",
        "abstract": "We consider the task of identifying the Copeland winner(s) in a dueling bandits problem with ternary feedback. This is an underexplored but practically relevant variant of the conventional dueling bandits problem, in which, in addition to strict preference between two arms, one may observe feedback in the form of an indifference. We provide a lower bound on the sample complexity for any learning algorithm finding the Copeland winner(s) with a fixed error probability. Moreover, we propose POCOWISTA, an algorithm with a sample complexity that almost matches this lower bound, and which shows excellent empirical performance, even for the conventional dueling bandits problem. For the case where the preference probabilities satisfy a specific type of stochastic transitivity, we provide a refined version with an improved worst case sample complexity.",
        "bibtex": "@InProceedings{pmlr-v238-bengs24a,\n  title = \t {Identifying {C}opeland Winners in Dueling Bandits with Indifferences},\n  author =       {Bengs, Viktor and Haddenhorst, Bj\\\"{o}rn and H\\\"{u}llermeier, Eyke},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {226--234},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bengs24a/bengs24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bengs24a.html},\n  abstract = \t {We consider the task of identifying the Copeland winner(s) in a dueling bandits problem with ternary feedback. This is an underexplored but practically relevant variant of the conventional dueling bandits problem, in which, in addition to strict preference between two arms, one may observe feedback in the form of an indifference. We provide a lower bound on the sample complexity for any learning algorithm finding the Copeland winner(s) with a fixed error probability. Moreover, we propose POCOWISTA, an algorithm with a sample complexity that almost matches this lower bound, and which shows excellent empirical performance, even for the conventional dueling bandits problem. For the case where the preference probabilities satisfy a specific type of stochastic transitivity, we provide a refined version with an improved worst case sample complexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bengs24a/bengs24a.pdf",
        "supp": "",
        "pdf_size": 522583,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11147963308598431069&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "62059a08e5",
        "title": "Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias",
        "site": "https://proceedings.mlr.press/v238/yang24c.html",
        "author": "Yu Yang; Eric Gan; Gintare Karolina Dziugaite; Baharan Mirzasoleiman",
        "abstract": "Neural networks trained with (stochastic) gradient descent have an inductive bias towards learning simpler solutions. This makes them highly prone to learning spurious correlations in the training data, that may not hold at test time. In this work, we provide the first theoretical analysis of the effect of simplicity bias on learning spurious correlations. Notably, we show that examples with spurious features are provably separable based on the model\u2019s output early in training. We further illustrate that if spurious features have a small enough noise-to-signal ratio, the network\u2019s output on majority of examples is almost exclusively determined by the spurious features, leading to poor worst-group test accuracy. Finally, we propose SPARE, which identifies spurious correlations early in training, and utilizes importance sampling to alleviate their effect. Empirically, we demonstrate that SPARE outperforms state-of-the-art methods by up to 21.1% in worst-group accuracy, while being up to 12x faster. We also show the applicability of SPARE, as a highly effective but lightweight method, to discover spurious correlations.",
        "bibtex": "@InProceedings{pmlr-v238-yang24c,\n  title = \t {Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias},\n  author =       {Yang, Yu and Gan, Eric and Karolina Dziugaite, Gintare and Mirzasoleiman, Baharan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2953--2961},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yang24c/yang24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yang24c.html},\n  abstract = \t {Neural networks trained with (stochastic) gradient descent have an inductive bias towards learning simpler solutions. This makes them highly prone to learning spurious correlations in the training data, that may not hold at test time. In this work, we provide the first theoretical analysis of the effect of simplicity bias on learning spurious correlations. Notably, we show that examples with spurious features are provably separable based on the model\u2019s output early in training. We further illustrate that if spurious features have a small enough noise-to-signal ratio, the network\u2019s output on majority of examples is almost exclusively determined by the spurious features, leading to poor worst-group test accuracy. Finally, we propose SPARE, which identifies spurious correlations early in training, and utilizes importance sampling to alleviate their effect. Empirically, we demonstrate that SPARE outperforms state-of-the-art methods by up to 21.1% in worst-group accuracy, while being up to 12x faster. We also show the applicability of SPARE, as a highly effective but lightweight method, to discover spurious correlations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yang24c/yang24c.pdf",
        "supp": "",
        "pdf_size": 2376099,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4718830017672141356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Los Angeles; University of California, Los Angeles; Google Deepmind; University of California, Los Angeles",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/BigML-CS-UCLA/SPARE",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;DeepMind",
        "aff_unique_dep": ";DeepMind",
        "aff_unique_url": "https://www.ucla.edu;https://deepmind.com",
        "aff_unique_abbr": "UCLA;DeepMind",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "da7c61859b",
        "title": "Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training",
        "site": "https://proceedings.mlr.press/v238/sander24a.html",
        "author": "Tom Sander; Maxime Sylvestre; Alain Durmus",
        "abstract": "Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) often results in superior test performance compared to larger batches. This implicit bias is attributed to the specific noise structure inherent to SGD. When ensuring Differential Privacy (DP) in DNNs\u2019 training, DP-SGD adds Gaussian noise to the clipped gradients. However, large-batch training still leads to a significant performance decrease, posing a challenge as strong DP guarantees necessitate the use of massive batches. Our study first demonstrates that this phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity, not the clipping, is responsible for this implicit bias, even with additional isotropic Gaussian noise. We then theoretically analyze the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings. Our analysis reveals that the additional noise indeed amplifies the implicit bias. It suggests that the performance issues of private training stem from the same underlying principles as SGD, offering hope for improvements in large batch training strategies.",
        "bibtex": "@InProceedings{pmlr-v238-sander24a,\n  title = \t {Implicit Bias in Noisy-{SGD}: With Applications to Differentially Private Training},\n  author =       {Sander, Tom and Sylvestre, Maxime and Durmus, Alain},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3295--3303},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sander24a/sander24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sander24a.html},\n  abstract = \t {Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) often results in superior test performance compared to larger batches. This implicit bias is attributed to the specific noise structure inherent to SGD. When ensuring Differential Privacy (DP) in DNNs\u2019 training, DP-SGD adds Gaussian noise to the clipped gradients. However, large-batch training still leads to a significant performance decrease, posing a challenge as strong DP guarantees necessitate the use of massive batches. Our study first demonstrates that this phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity, not the clipping, is responsible for this implicit bias, even with additional isotropic Gaussian noise. We then theoretically analyze the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings. Our analysis reveals that the additional noise indeed amplifies the implicit bias. It suggests that the performance issues of private training stem from the same underlying principles as SGD, offering hope for improvements in large batch training strategies.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sander24a/sander24a.pdf",
        "supp": "",
        "pdf_size": 2019278,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1668563030334964427&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Meta AI (FAIR) & \u00b4Ecole polytechnique; Universit\u00b4e Paris Dauphine; \u00b4Ecole polytechnique",
        "aff_domain": "meta.com; ; ",
        "email": "meta.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Meta;Universit\u00e9 Paris Dauphine;Ecole Polytechnique",
        "aff_unique_dep": "Meta AI;;",
        "aff_unique_url": "https://meta.ai;https://www.univ-paris-dauphine.fr;https://www.polytechnique.edu",
        "aff_unique_abbr": "Meta AI;UPD;X",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "8dd221af9c",
        "title": "Implicit Regularization in Deep Tucker Factorization: Low-Rankness via Structured Sparsity",
        "site": "https://proceedings.mlr.press/v238/hariz24a.html",
        "author": "Kais Hariz; Hachem Kadri; St\u00e9phane Ayache; Maher Moakher; Thierry Arti\u00e8res",
        "abstract": "We theoretically analyze the implicit regularization of deep learning for tensor completion. We show that deep Tucker factorization trained by gradient descent induces a structured sparse regularization. This leads to a characterization of the effect of the depth of the neural network on the implicit regularization and provides a potential explanation for the bias of gradient descent towards solutions with low multilinear rank. Numerical experiments confirm our theoretical findings and give insights into the behavior of gradient descent in deep tensor factorization.",
        "bibtex": "@InProceedings{pmlr-v238-hariz24a,\n  title = \t {Implicit Regularization in Deep {T}ucker Factorization: Low-Rankness via Structured Sparsity},\n  author =       {Hariz, Kais and Kadri, Hachem and Ayache, St\\'{e}phane and Moakher, Maher and Arti\\`{e}res, Thierry},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2359--2367},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hariz24a/hariz24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hariz24a.html},\n  abstract = \t {We theoretically analyze the implicit regularization of deep learning for tensor completion. We show that deep Tucker factorization trained by gradient descent induces a structured sparse regularization. This leads to a characterization of the effect of the depth of the neural network on the implicit regularization and provides a potential explanation for the bias of gradient descent towards solutions with low multilinear rank. Numerical experiments confirm our theoretical findings and give insights into the behavior of gradient descent in deep tensor factorization.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hariz24a/hariz24a.pdf",
        "supp": "",
        "pdf_size": 1463110,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18295629950417573258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Aix Marseille University, CNRS, LIS, Marseille, France+LAMSIN, National Engineering School of Tunis, University of Tunis El Manar, Tunis, Tunisia; Aix Marseille University, CNRS, LIS, Marseille, France; Aix Marseille University, CNRS, LIS, Marseille, France; LAMSIN, National Engineering School of Tunis, University of Tunis El Manar, Tunis, Tunisia; Aix Marseille University, CNRS, LIS, Marseille, France+Ecole Centrale de Marseille, Marseille, France",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;1;0+2",
        "aff_unique_norm": "Aix Marseille University;University of Tunis El Manar;Ecole Centrale de Marseille",
        "aff_unique_dep": "CNRS, LIS;National Engineering School of Tunis;",
        "aff_unique_url": "https://www.univ-amu.fr;;https://www.ecm.fr",
        "aff_unique_abbr": "AMU;;ECM",
        "aff_campus_unique_index": "0+1;0;0;1;0+0",
        "aff_campus_unique": "Marseille;Tunis",
        "aff_country_unique_index": "0+1;0;0;1;0+0",
        "aff_country_unique": "France;Tunisia"
    },
    {
        "id": "04d1886f00",
        "title": "Importance Matching Lemma for Lossy Compression with Side Information",
        "site": "https://proceedings.mlr.press/v238/phan24a.html",
        "author": "Buu Phan; Ashish Khisti; Christos Louizos",
        "abstract": "We propose two extensions to existing importance sampling based methods for lossy compression. First, we introduce an importance sampling based compression scheme that is a variant of ordered random coding (Theis and Ahmed, 2022) and is amenable to direct evaluation of the achievable compression rate for a finite number of samples. Our second and major contribution is the \\emph{importance matching lemma}, which is a finite proposal counterpart of the recently introduced {Poisson matching lemma} (Li and Anantharam, 2021). By integrating with deep learning, we provide a new coding scheme for distributed lossy compression with side information at the decoder. We demonstrate the effectiveness of the proposed scheme through experiments involving synthetic Gaussian sources, distributed image compression with MNIST and vertical federated learning with CIFAR-10.",
        "bibtex": "@InProceedings{pmlr-v238-phan24a,\n  title = \t {Importance Matching Lemma for Lossy Compression with Side Information},\n  author =       {Phan, Buu and Khisti, Ashish and Louizos, Christos},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1387--1395},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/phan24a/phan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/phan24a.html},\n  abstract = \t {We propose two extensions to existing importance sampling based methods for lossy compression. First, we introduce an importance sampling based compression scheme that is a variant of ordered random coding (Theis and Ahmed, 2022) and is amenable to direct evaluation of the achievable compression rate for a finite number of samples. Our second and major contribution is the \\emph{importance matching lemma}, which is a finite proposal counterpart of the recently introduced {Poisson matching lemma} (Li and Anantharam, 2021). By integrating with deep learning, we provide a new coding scheme for distributed lossy compression with side information at the decoder. We demonstrate the effectiveness of the proposed scheme through experiments involving synthetic Gaussian sources, distributed image compression with MNIST and vertical federated learning with CIFAR-10.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/phan24a/phan24a.pdf",
        "supp": "",
        "pdf_size": 1970420,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16107110904403397989&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "aff": "University of Toronto; University of Toronto; Qualcomm AI Research\u2020",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Toronto;Qualcomm AI Research",
        "aff_unique_dep": ";AI Research",
        "aff_unique_url": "https://www.utoronto.ca;https://www.qualcomm.com/research",
        "aff_unique_abbr": "U of T;QAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "3c13557d16",
        "title": "Imposing Fairness Constraints in Synthetic Data Generation",
        "site": "https://proceedings.mlr.press/v238/abroshan24a.html",
        "author": "Mahed Abroshan; Andrew Elliott; Mohammad Mahdi Khalili",
        "abstract": "In several real-world applications (e.g., online advertising, item recommendations, etc.) it may not be possible to release and share the real dataset due to privacy concerns. As a result, synthetic data generation (SDG) has emerged as a promising solution for data sharing. While the main goal of private SDG is to create a dataset that preserves the privacy of individuals contributing to the dataset, the use of synthetic data also creates an opportunity to improve fairness. Since there often exist historical biases in the datasets, using the original real data for training can lead to an unfair model. Using synthetic data, we can attempt to remove such biases from the dataset before releasing the data. In this work, we formalize the definition of fairness in synthetic data generation and provide a general framework to achieve fairness. Then we consider two notions of counterfactual fairness and information filtering fairness and show how our framework can be used for these definitions.",
        "bibtex": "@InProceedings{pmlr-v238-abroshan24a,\n  title = \t {Imposing Fairness Constraints in Synthetic Data Generation},\n  author =       {Abroshan, Mahed and Elliott, Andrew and Mahdi Khalili, Mohammad},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2269--2277},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/abroshan24a/abroshan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/abroshan24a.html},\n  abstract = \t {In several real-world applications (e.g., online advertising, item recommendations, etc.) it may not be possible to release and share the real dataset due to privacy concerns. As a result, synthetic data generation (SDG) has emerged as a promising solution for data sharing. While the main goal of private SDG is to create a dataset that preserves the privacy of individuals contributing to the dataset, the use of synthetic data also creates an opportunity to improve fairness. Since there often exist historical biases in the datasets, using the original real data for training can lead to an unfair model. Using synthetic data, we can attempt to remove such biases from the dataset before releasing the data. In this work, we formalize the definition of fairness in synthetic data generation and provide a general framework to achieve fairness. Then we consider two notions of counterfactual fairness and information filtering fairness and show how our framework can be used for these definitions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/abroshan24a/abroshan24a.pdf",
        "supp": "",
        "pdf_size": 1014353,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14234735992127078553&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "The Alan Turing Institute; The University of Glasgow + The Alan Turing Institute; The Ohio State University + Yahoo Research",
        "aff_domain": "gmail.com;turing.ac.uk;osu.edu",
        "email": "gmail.com;turing.ac.uk;osu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;2+3",
        "aff_unique_norm": "Alan Turing Institute;University of Glasgow;Ohio State University;Yahoo",
        "aff_unique_dep": ";;;Yahoo Research",
        "aff_unique_url": "https://www.turing.ac.uk;https://www.gla.ac.uk;https://www.osu.edu;https://research.yahoo.com",
        "aff_unique_abbr": "ATI;Glasgow;OSU;Yahoo Research",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;1+1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "220a25f5ce",
        "title": "Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition",
        "site": "https://proceedings.mlr.press/v238/li24n.html",
        "author": "Long-Fei Li; Peng Zhao; Zhi-Hua Zhou",
        "abstract": "We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\\tilde{\\mathcal{O}}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\\tilde{\\mathcal{O}}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (\\romannumeral1) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (\\romannumeral2) a new self-normalized concentration tailored specifically to handle non-independent noises, originally proposed in the dynamic assortment area and firstly applied in reinforcement learning to handle correlations between different states.",
        "bibtex": "@InProceedings{pmlr-v238-li24n,\n  title = \t {Improved Algorithm for Adversarial Linear Mixture {MDPs} with Bandit Feedback and Unknown Transition},\n  author =       {Li, Long-Fei and Zhao, Peng and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3061--3069},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24n/li24n.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24n.html},\n  abstract = \t {We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\\tilde{\\mathcal{O}}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\\tilde{\\mathcal{O}}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (\\romannumeral1) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (\\romannumeral2) a new self-normalized concentration tailored specifically to handle non-independent noises, originally proposed in the dynamic assortment area and firstly applied in reinforcement learning to handle correlations between different states.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24n/li24n.pdf",
        "supp": "",
        "pdf_size": 443674,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10155740432080754857&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, China; School of Artificial Intelligence, Nanjing University, China; National Key Laboratory for Novel Software Technology, Nanjing University, China + School of Artificial Intelligence, Nanjing University, China",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "397695000c",
        "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion",
        "site": "https://proceedings.mlr.press/v238/lee24d.html",
        "author": "Junghyun Lee; Se-Young Yun; Kwang-Sung Jun",
        "abstract": "Logistic bandit is a ubiquitous framework of modeling users\u2019 choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \\geq \\Vert \\theta_\\star \\Vert_2$, where $\\theta_\\star \\in \\mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \\geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \\textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor of $S$. We then extend this analysis to multinomial logistic bandits and obtain similar improvements in the regret, showing the efficacy of R2CS. While we applied R2CS to the (multinomial) logistic model, R2CS is a generic approach for developing confidence sets that can be used for various models, which can be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v238-lee24d,\n  title = \t {Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion},\n  author =       {Lee, Junghyun and Yun, Se-Young and Jun, Kwang-Sung},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4474--4482},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lee24d/lee24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lee24d.html},\n  abstract = \t {Logistic bandit is a ubiquitous framework of modeling users\u2019 choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \\geq \\Vert \\theta_\\star \\Vert_2$, where $\\theta_\\star \\in \\mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \\geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \\textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor of $S$. We then extend this analysis to multinomial logistic bandits and obtain similar improvements in the regret, showing the efficacy of R2CS. While we applied R2CS to the (multinomial) logistic model, R2CS is a generic approach for developing confidence sets that can be used for various models, which can be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lee24d/lee24d.pdf",
        "supp": "",
        "pdf_size": 1937139,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16544223061074122831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea; Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea; Department of Computer Science, University of Arizona, Tucson AZ, USA",
        "aff_domain": "kaist.ac.kr;kaist.ac.kr;cs.arizona.edu",
        "email": "kaist.ac.kr;kaist.ac.kr;cs.arizona.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "KAIST;University of Arizona",
        "aff_unique_dep": "Kim Jaechul Graduate School of AI;Department of Computer Science",
        "aff_unique_url": "https://www.kaist.edu;https://www.arizona.edu",
        "aff_unique_abbr": "KAIST;UArizona",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Seoul;Tucson",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "c9b6e499ba",
        "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes",
        "site": "https://proceedings.mlr.press/v238/mondal24a.html",
        "author": "Washim U. Mondal; Vaneet Aggarwal",
        "abstract": "We consider the problem of designing sample efficient learning algorithms for infinite horizon discounted reward Markov Decision Process. Specifically, we propose the Accelerated Natural Policy Gradient (ANPG) algorithm that utilizes an accelerated stochastic gradient descent process to obtain the natural policy gradient. ANPG achieves $\\mathcal{O}({\\epsilon^{-2}})$ sample complexity and $\\mathcal{O}(\\epsilon^{-1})$ iteration complexity with general parameterization where $\\epsilon$ defines the optimality error. This improves the state-of-the-art sample complexity by a $\\log(\\frac{1}{\\epsilon})$ factor. ANPG is a first-order algorithm and unlike some existing literature, does not require the unverifiable assumption that the variance of importance sampling (IS) weights is upper bounded. In the class of Hessian-free and IS-free algorithms, ANPG beats the best-known sample complexity by a factor of $\\mathcal{O}(\\epsilon^{-\\frac{1}{2}})$ and simultaneously matches their state-of-the-art iteration complexity.",
        "bibtex": "@InProceedings{pmlr-v238-mondal24a,\n  title = \t {Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward {M}arkov Decision Processes},\n  author =       {Mondal, Washim U. and Aggarwal, Vaneet},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3097--3105},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mondal24a/mondal24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mondal24a.html},\n  abstract = \t {We consider the problem of designing sample efficient learning algorithms for infinite horizon discounted reward Markov Decision Process. Specifically, we propose the Accelerated Natural Policy Gradient (ANPG) algorithm that utilizes an accelerated stochastic gradient descent process to obtain the natural policy gradient. ANPG achieves $\\mathcal{O}({\\epsilon^{-2}})$ sample complexity and $\\mathcal{O}(\\epsilon^{-1})$ iteration complexity with general parameterization where $\\epsilon$ defines the optimality error. This improves the state-of-the-art sample complexity by a $\\log(\\frac{1}{\\epsilon})$ factor. ANPG is a first-order algorithm and unlike some existing literature, does not require the unverifiable assumption that the variance of importance sampling (IS) weights is upper bounded. In the class of Hessian-free and IS-free algorithms, ANPG beats the best-known sample complexity by a factor of $\\mathcal{O}(\\epsilon^{-\\frac{1}{2}})$ and simultaneously matches their state-of-the-art iteration complexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mondal24a/mondal24a.pdf",
        "supp": "",
        "pdf_size": 358351,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15817537252550565946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Purdue University, USA; Purdue University, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c7795adde5",
        "title": "Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective",
        "site": "https://proceedings.mlr.press/v238/puranik24a.html",
        "author": "Bhagyashree Puranik; Ahmad Beirami; Yao Qin; Upamanyu Madhow",
        "abstract": "State-of-the-art techniques for enhancing robustness of deep networks mostly rely on empirical risk minimization with suitable data augmentation. In this paper, we propose a complementary approach motivated by communication theory, aimed at enhancing the signal-to-noise ratio at the output of a neural network layer via neural competition during learning and inference. In addition to standard empirical risk minimization, neurons compete to sparsely represent layer inputs by maximization of a tilted exponential (TEXP) objective function for the layer. TEXP learning can be interpreted as maximum likelihood estimation of matched filters under a Gaussian model for data noise. Inference in a TEXP layer is accomplished by replacing batch norm by a tilted softmax, which can be interpreted as computation of posterior probabilities for the competing signaling hypotheses represented by each neuron. After providing insights via simplified models, we show, by experimentation on standard image datasets, that TEXP learning and inference enhances robustness against noise and other common corruptions, without requiring data augmentation. Further cumulative gains in robustness against this array of distortions can be obtained by appropriately combining TEXP with data augmentation techniques. The code for all our experiments is available at \\url{https://github.com/bhagyapuranik/texp_for_robustness}.",
        "bibtex": "@InProceedings{pmlr-v238-puranik24a,\n  title = \t {Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective},\n  author =       {Puranik, Bhagyashree and Beirami, Ahmad and Qin, Yao and Madhow, Upamanyu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4510--4518},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/puranik24a/puranik24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/puranik24a.html},\n  abstract = \t {State-of-the-art techniques for enhancing robustness of deep networks mostly rely on empirical risk minimization with suitable data augmentation. In this paper, we propose a complementary approach motivated by communication theory, aimed at enhancing the signal-to-noise ratio at the output of a neural network layer via neural competition during learning and inference. In addition to standard empirical risk minimization, neurons compete to sparsely represent layer inputs by maximization of a tilted exponential (TEXP) objective function for the layer. TEXP learning can be interpreted as maximum likelihood estimation of matched filters under a Gaussian model for data noise. Inference in a TEXP layer is accomplished by replacing batch norm by a tilted softmax, which can be interpreted as computation of posterior probabilities for the competing signaling hypotheses represented by each neuron. After providing insights via simplified models, we show, by experimentation on standard image datasets, that TEXP learning and inference enhances robustness against noise and other common corruptions, without requiring data augmentation. Further cumulative gains in robustness against this array of distortions can be obtained by appropriately combining TEXP with data augmentation techniques. The code for all our experiments is available at \\url{https://github.com/bhagyapuranik/texp_for_robustness}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/puranik24a/puranik24a.pdf",
        "supp": "",
        "pdf_size": 1279910,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14478073373796424199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "33a3ecd5b3",
        "title": "Inconsistency of Cross-Validation for Structure Learning in Gaussian Graphical Models",
        "site": "https://proceedings.mlr.press/v238/lyu24a.html",
        "author": "Zhao Lyu; Wai Ming Tai; Mladen Kolar; Bryon Aragam",
        "abstract": "Despite numerous years of research into the merits and trade-offs of various model selection criteria, obtaining robust results that elucidate the behavior of cross-validation remains a challenging endeavor. In this paper, we highlight the inherent limitations of cross-validation when employed to discern the structure of a Gaussian graphical model. We provide finite-sample bounds on the probability that the Lasso estimator for the neighborhood of a node within a Gaussian graphical model, optimized using a prediction oracle, misidentifies the neighborhood. Our results pertain to both undirected and directed acyclic graphs, encompassing general, sparse covariance structures. To support our theoretical findings, we conduct an empirical investigation of this inconsistency by contrasting our outcomes with other commonly used information criteria through an extensive simulation study. Given that many algorithms designed to learn the structure of graphical models require hyperparameter selection, the precise calibration of this hyperparameter is paramount for accurately estimating the inherent structure. Consequently, our observations shed light on this widely recognized practical challenge.",
        "bibtex": "@InProceedings{pmlr-v238-lyu24a,\n  title = \t {Inconsistency of Cross-Validation for Structure Learning in {G}aussian Graphical Models},\n  author =       {Lyu, Zhao and Ming Tai, Wai and Kolar, Mladen and Aragam, Bryon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3691--3699},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lyu24a/lyu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lyu24a.html},\n  abstract = \t {Despite numerous years of research into the merits and trade-offs of various model selection criteria, obtaining robust results that elucidate the behavior of cross-validation remains a challenging endeavor. In this paper, we highlight the inherent limitations of cross-validation when employed to discern the structure of a Gaussian graphical model. We provide finite-sample bounds on the probability that the Lasso estimator for the neighborhood of a node within a Gaussian graphical model, optimized using a prediction oracle, misidentifies the neighborhood. Our results pertain to both undirected and directed acyclic graphs, encompassing general, sparse covariance structures. To support our theoretical findings, we conduct an empirical investigation of this inconsistency by contrasting our outcomes with other commonly used information criteria through an extensive simulation study. Given that many algorithms designed to learn the structure of graphical models require hyperparameter selection, the precise calibration of this hyperparameter is paramount for accurately estimating the inherent structure. Consequently, our observations shed light on this widely recognized practical challenge.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lyu24a/lyu24a.pdf",
        "supp": "",
        "pdf_size": 1520073,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:9GHudfixBTUJ:scholar.google.com/&scioq=Inconsistency+of+Cross-Validation+for+Structure+Learning+in+Gaussian+Graphical+Models&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b58858b14e",
        "title": "Independent Learning in Constrained Markov Potential Games",
        "site": "https://proceedings.mlr.press/v238/jordan24a.html",
        "author": "Philip Jordan; Anas Barakat; Niao He",
        "abstract": "Constrained Markov games offer a formal mathematical framework for modeling multi-agent reinforcement learning problems where the behavior of the agents is subject to constraints. In this work, we focus on the recently introduced class of constrained Markov Potential Games. While centralized algorithms have been proposed for solving such constrained games, the design of converging independent learning algorithms tailored for the constrained setting remains an open question. We propose an independent policy gradient algorithm for learning approximate constrained Nash equilibria: Each agent observes their own actions and rewards, along with a shared state. Inspired by the optimization literature, our algorithm performs proximal-point-like updates augmented with a regularized constraint set. Each proximal step is solved inexactly using a stochastic switching gradient algorithm. Notably, our algorithm can be implemented independently without a centralized coordination mechanism requiring turn-based agent updates. Under some technical constraint qualification conditions, we establish convergence guarantees towards constrained approximate Nash equilibria. We perform simulations to illustrate our results.",
        "bibtex": "@InProceedings{pmlr-v238-jordan24a,\n  title = \t {Independent Learning in Constrained {M}arkov Potential Games},\n  author =       {Jordan, Philip and Barakat, Anas and He, Niao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4024--4032},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jordan24a/jordan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jordan24a.html},\n  abstract = \t {Constrained Markov games offer a formal mathematical framework for modeling multi-agent reinforcement learning problems where the behavior of the agents is subject to constraints. In this work, we focus on the recently introduced class of constrained Markov Potential Games. While centralized algorithms have been proposed for solving such constrained games, the design of converging independent learning algorithms tailored for the constrained setting remains an open question. We propose an independent policy gradient algorithm for learning approximate constrained Nash equilibria: Each agent observes their own actions and rewards, along with a shared state. Inspired by the optimization literature, our algorithm performs proximal-point-like updates augmented with a regularized constraint set. Each proximal step is solved inexactly using a stochastic switching gradient algorithm. Notably, our algorithm can be implemented independently without a centralized coordination mechanism requiring turn-based agent updates. Under some technical constraint qualification conditions, we establish convergence guarantees towards constrained approximate Nash equilibria. We perform simulations to illustrate our results.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jordan24a/jordan24a.pdf",
        "supp": "",
        "pdf_size": 790887,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=179006417172718634&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c5343afc7f",
        "title": "Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs",
        "site": "https://proceedings.mlr.press/v238/shaikh-veedu24a.html",
        "author": "Mishfad Shaikh Veedu; Deepjyoti Deka; Murti Salapaka",
        "abstract": "In this article, the optimal sample complexity of learning the underlying interactions or dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. We call such a DAG underlying an LDS as dynamical DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same power spectral density (PSD). Inspired by the static DAG setting, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. It is shown that the optimal sample complexity (or length of state trajectory) needed to learn the DDAG is $n=\\Theta(q\\log(p/q))$, where $p$ is the number of nodes and $q$ is the maximum number of parents per node. To prove the sample complexity upper bound, a concentration bound for the PSD estimation is derived, under two different sampling strategies. A matching min-max lower bound using generalized Fano\u2019s inequality also is provided, thus showing the order optimality of the proposed algorithm. The codes used in the paper are available at \\url{https://github.com/Mishfad/Learning-Dynamical-DAGs}",
        "bibtex": "@InProceedings{pmlr-v238-shaikh-veedu24a,\n  title = \t {Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs},\n  author =       {Shaikh Veedu, Mishfad and Deka, Deepjyoti and Salapaka, Murti},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4636--4644},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shaikh-veedu24a/shaikh-veedu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shaikh-veedu24a.html},\n  abstract = \t {In this article, the optimal sample complexity of learning the underlying interactions or dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. We call such a DAG underlying an LDS as dynamical DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same power spectral density (PSD). Inspired by the static DAG setting, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. It is shown that the optimal sample complexity (or length of state trajectory) needed to learn the DDAG is $n=\\Theta(q\\log(p/q))$, where $p$ is the number of nodes and $q$ is the maximum number of parents per node. To prove the sample complexity upper bound, a concentration bound for the PSD estimation is derived, under two different sampling strategies. A matching min-max lower bound using generalized Fano\u2019s inequality also is provided, thus showing the order optimality of the proposed algorithm. The codes used in the paper are available at \\url{https://github.com/Mishfad/Learning-Dynamical-DAGs}}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shaikh-veedu24a/shaikh-veedu24a.pdf",
        "supp": "",
        "pdf_size": 719293,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7089373306490898916&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Minnesota, Twin Cities; Los Alamos National Laboratory; University of Minnesota, Twin Cities",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/Mishfad/Learning-Dynamical-DAGs",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Minnesota;Los Alamos National Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.minnesota.edu;https://www.lanl.gov",
        "aff_unique_abbr": "UMN;LANL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Twin Cities;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "910886dcad",
        "title": "Information-theoretic Analysis of Bayesian Test Data Sensitivity",
        "site": "https://proceedings.mlr.press/v238/futami24a.html",
        "author": "Futoshi Futami; Tomoharu Iwata",
        "abstract": "Bayesian inference is often used to quantify uncertainty. Several recent analyses have rigorously decomposed uncertainty in prediction by Bayesian inference into two types: the inherent randomness in the data generation process and the variability due to lack of data respectively. Existing studies have analyzed these uncertainties from an information-theoretic perspective, assuming the model is well-specified and treating the model parameters as latent variables. However, such information-theoretic uncertainty analysis fails to account for a widely believed property of uncertainty known as sensitivity between test and training data. This means that if the test data is similar to the training data in some sense, the uncertainty will be smaller. In this study, we study such sensitivity using a new decomposition of uncertainty. Our analysis successfully defines such sensitivity using information-theoretic quantities. Furthermore, we extend the existing analysis of Bayesian meta-learning and show the novel sensitivities among tasks for the first time.",
        "bibtex": "@InProceedings{pmlr-v238-futami24a,\n  title = \t {Information-theoretic Analysis of {B}ayesian Test Data Sensitivity},\n  author =       {Futami, Futoshi and Iwata, Tomoharu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1099--1107},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/futami24a/futami24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/futami24a.html},\n  abstract = \t {Bayesian inference is often used to quantify uncertainty. Several recent analyses have rigorously decomposed uncertainty in prediction by Bayesian inference into two types: the inherent randomness in the data generation process and the variability due to lack of data respectively. Existing studies have analyzed these uncertainties from an information-theoretic perspective, assuming the model is well-specified and treating the model parameters as latent variables. However, such information-theoretic uncertainty analysis fails to account for a widely believed property of uncertainty known as sensitivity between test and training data. This means that if the test data is similar to the training data in some sense, the uncertainty will be smaller. In this study, we study such sensitivity using a new decomposition of uncertainty. Our analysis successfully defines such sensitivity using information-theoretic quantities. Furthermore, we extend the existing analysis of Bayesian meta-learning and show the novel sensitivities among tasks for the first time.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/futami24a/futami24a.pdf",
        "supp": "",
        "pdf_size": 554074,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9879489229733778249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Osaka University / RIKEN AIP; NTT Corporation",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Osaka University;NTT Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.ntt.co.jp",
        "aff_unique_abbr": "Osaka U;NTT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "443d17a2c3",
        "title": "Informative Path Planning with Limited Adaptivity",
        "site": "https://proceedings.mlr.press/v238/tan24a.html",
        "author": "Rayen Tan; Rohan Ghuge; Viswanath Nagarajan",
        "abstract": "We consider the informative path planning (IPP) problem in which a robot interacts with an uncertain environment and gathers information by visiting locations. The goal is to minimize its expected travel cost to cover a given submodular function. Adaptive solutions, where the robot incorporates all available information to select the next location to visit, achieve the best objective. However, such a solution is resource-intensive as it entails recomputing after every visited location. A more practical approach is to design solutions with a small number of adaptive \"rounds\", where the robot recomputes only once at the start of each round. In this paper, we design an algorithm for IPP parameterized by the number k of adaptive rounds, and prove a smooth tradeoff between k and the solution quality (relative to fully adaptive solutions). We validate our theoretical results by experiments on a real road network, where we observe that a few rounds of adaptivity suffice to obtain solutions of cost almost as good as fully-adaptive ones.",
        "bibtex": "@InProceedings{pmlr-v238-tan24a,\n  title = \t {Informative Path Planning with Limited Adaptivity},\n  author =       {Tan, Rayen and Ghuge, Rohan and Nagarajan, Viswanath},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4006--4014},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tan24a/tan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tan24a.html},\n  abstract = \t {We consider the informative path planning (IPP) problem in which a robot interacts with an uncertain environment and gathers information by visiting locations. The goal is to minimize its expected travel cost to cover a given submodular function. Adaptive solutions, where the robot incorporates all available information to select the next location to visit, achieve the best objective. However, such a solution is resource-intensive as it entails recomputing after every visited location. A more practical approach is to design solutions with a small number of adaptive \"rounds\", where the robot recomputes only once at the start of each round. In this paper, we design an algorithm for IPP parameterized by the number k of adaptive rounds, and prove a smooth tradeoff between k and the solution quality (relative to fully adaptive solutions). We validate our theoretical results by experiments on a real road network, where we observe that a few rounds of adaptivity suffice to obtain solutions of cost almost as good as fully-adaptive ones.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tan24a/tan24a.pdf",
        "supp": "",
        "pdf_size": 2399250,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7vuoc0O7lz0J:scholar.google.com/&scioq=Informative+Path+Planning+with+Limited+Adaptivity&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f3ad059cf0",
        "title": "Integrating Uncertainty Awareness into Conformalized Quantile Regression",
        "site": "https://proceedings.mlr.press/v238/rossellini24a.html",
        "author": "Raphael Rossellini; Rina Foygel Barber; Rebecca Willett",
        "abstract": "Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to intervals that are overly narrow in regions where epistemic uncertainty is high. To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertainty to adjust quantile regressors differentially across the feature space. Compared to CQR, our methods enjoy the same distribution-free theoretical coverage guarantees, while demonstrating in our experiments stronger conditional coverage properties in simulated settings and real-world data sets alike.",
        "bibtex": "@InProceedings{pmlr-v238-rossellini24a,\n  title = \t {Integrating Uncertainty Awareness into Conformalized Quantile Regression},\n  author =       {Rossellini, Raphael and Foygel Barber, Rina and Willett, Rebecca},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1540--1548},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rossellini24a/rossellini24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rossellini24a.html},\n  abstract = \t {Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to intervals that are overly narrow in regions where epistemic uncertainty is high. To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertainty to adjust quantile regressors differentially across the feature space. Compared to CQR, our methods enjoy the same distribution-free theoretical coverage guarantees, while demonstrating in our experiments stronger conditional coverage properties in simulated settings and real-world data sets alike.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rossellini24a/rossellini24a.pdf",
        "supp": "",
        "pdf_size": 566303,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10633737142468245550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2c154e7706",
        "title": "Interpretability Guarantees with Merlin-Arthur Classifiers",
        "site": "https://proceedings.mlr.press/v238/waldchen24a.html",
        "author": "Stephan W\u00e4ldchen; Kartikey Sharma; Berkant Turan; Max Zimmer; Sebastian Pokutta",
        "abstract": "We propose an interactive multi-agent classifier that provides provable interpretability guarantees even for complex agents such as neural networks. These guarantees consist of lower bounds on the mutual information between selected features and the classification decision. Our results are inspired by the Merlin-Arthur protocol from Interactive Proof Systems and express these bounds in terms of measurable metrics such as soundness and completeness. Compared to existing interactive setups, we rely neither on optimal agents nor on the assumption that features are distributed independently. Instead, we use the relative strength of the agents as well as the new concept of Asymmetric Feature Correlation which captures the precise kind of correlations that make interpretability guarantees difficult. We evaluate our results on two small-scale datasets where high mutual information can be verified explicitly.",
        "bibtex": "@InProceedings{pmlr-v238-waldchen24a,\n  title = \t {Interpretability Guarantees with {M}erlin-{A}rthur Classifiers},\n  author =       {W\\\"{a}ldchen, Stephan and Sharma, Kartikey and Turan, Berkant and Zimmer, Max and Pokutta, Sebastian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1963--1971},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/waldchen24a/waldchen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/waldchen24a.html},\n  abstract = \t {We propose an interactive multi-agent classifier that provides provable interpretability guarantees even for complex agents such as neural networks. These guarantees consist of lower bounds on the mutual information between selected features and the classification decision. Our results are inspired by the Merlin-Arthur protocol from Interactive Proof Systems and express these bounds in terms of measurable metrics such as soundness and completeness. Compared to existing interactive setups, we rely neither on optimal agents nor on the assumption that features are distributed independently. Instead, we use the relative strength of the agents as well as the new concept of Asymmetric Feature Correlation which captures the precise kind of correlations that make interpretability guarantees difficult. We evaluate our results on two small-scale datasets where high mutual information can be verified explicitly.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/waldchen24a/waldchen24a.pdf",
        "supp": "",
        "pdf_size": 2025434,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17716879603241148249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Zuse Institute Berlin; Zuse Institute Berlin; Zuse Institute Berlin + Technische Universit\u00a8at Berlin; Zuse Institute Berlin + Technische Universit\u00a8at Berlin; Zuse Institute Berlin + Technische Universit\u00a8at Berlin",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0+1;0+1",
        "aff_unique_norm": "Zuse Institute Berlin;Technische Universit\u00e4t Berlin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.zib.de;https://www.tu-berlin.de",
        "aff_unique_abbr": "ZIB;TU Berlin",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "df99699a96",
        "title": "Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data",
        "site": "https://proceedings.mlr.press/v238/katta24a.html",
        "author": "Srikar Katta; Harsh Parikh; Cynthia Rudin; Alexander Volfovsky",
        "abstract": "Many modern causal questions ask how treatments affect complex outcomes that are measured using wearable devices and sensors. Current analysis approaches require summarizing these data into scalar statistics (e.g., the mean), but these summaries can be misleading. For example, disparate distributions can have the same means, variances, and other statistics. Researchers can overcome the loss in information by instead representing the data as distributions. We develop an interpretable method for distributional data analysis that ensures trustworthy and robust decision making: Analyzing Distributional Data via Matching After Learning to Stretch (ADD MALTS). We (i) provide analytical guarantees of the correctness of our estimation strategy, (ii) demonstrate via simulation that ADD MALTS outperforms other distributional data analysis methods at estimating treatment effects, and (iii) illustrate ADD MALTS\u2019 ability to verify whether there is enough cohesion between treatment and control units within subpopulations to trustworthily estimate treatment effects. We demonstrate ADD MALTS\u2019 utility by studying the effectiveness of continuous glucose monitors in mitigating diabetes risks.",
        "bibtex": "@InProceedings{pmlr-v238-katta24a,\n  title = \t {Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data},\n  author =       {Katta, Srikar and Parikh, Harsh and Rudin, Cynthia and Volfovsky, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3340--3348},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/katta24a/katta24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/katta24a.html},\n  abstract = \t {Many modern causal questions ask how treatments affect complex outcomes that are measured using wearable devices and sensors. Current analysis approaches require summarizing these data into scalar statistics (e.g., the mean), but these summaries can be misleading. For example, disparate distributions can have the same means, variances, and other statistics. Researchers can overcome the loss in information by instead representing the data as distributions. We develop an interpretable method for distributional data analysis that ensures trustworthy and robust decision making: Analyzing Distributional Data via Matching After Learning to Stretch (ADD MALTS). We (i) provide analytical guarantees of the correctness of our estimation strategy, (ii) demonstrate via simulation that ADD MALTS outperforms other distributional data analysis methods at estimating treatment effects, and (iii) illustrate ADD MALTS\u2019 ability to verify whether there is enough cohesion between treatment and control units within subpopulations to trustworthily estimate treatment effects. We demonstrate ADD MALTS\u2019 utility by studying the effectiveness of continuous glucose monitors in mitigating diabetes risks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/katta24a/katta24a.pdf",
        "supp": "",
        "pdf_size": 3272103,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14675987626567796310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1bb9a25a4b",
        "title": "Intrinsic Gaussian Vector Fields on Manifolds",
        "site": "https://proceedings.mlr.press/v238/robert-nicoud24a.html",
        "author": "Daniel Robert-Nicoud; Andreas Krause; Viacheslav Borovitskiy",
        "abstract": "Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\u00e9rn Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before.",
        "bibtex": "@InProceedings{pmlr-v238-robert-nicoud24a,\n  title = \t {Intrinsic {G}aussian Vector Fields on Manifolds},\n  author =       {Robert-Nicoud, Daniel and Krause, Andreas and Borovitskiy, Viacheslav},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1306--1314},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/robert-nicoud24a/robert-nicoud24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/robert-nicoud24a.html},\n  abstract = \t {Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\u00e9rn Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/robert-nicoud24a/robert-nicoud24a.pdf",
        "supp": "",
        "pdf_size": 10457502,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17213554553613630208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland",
        "aff_domain": "gmail.com; ;gmail.com",
        "email": "gmail.com; ;gmail.com",
        "github": "https://github.com/DanielRobertNicoud/imv-gps",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "12c7c5645e",
        "title": "Invariant Aggregator for Defending against Federated Backdoor Attacks",
        "site": "https://proceedings.mlr.press/v238/wang24f.html",
        "author": "Xiaoyang Wang; Dimitrios Dimitriadis; Sanmi Koyejo; Shruti Tople",
        "abstract": "Federated learning enables training high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Despite the theoretical and empirical success in defending against attacks that aim to degrade models\u2019 utility, defense against backdoor attacks that increase model accuracy on backdoor samples exclusively without hurting the utility on other samples remains challenging. To this end, we first analyze the failure modes of existing defenses over a flat loss landscape, which is common for well-designed neural networks such as Resnet (He et al., 2015) but is often overlooked by previous works. Then, we propose an invariant aggregator that redirects the aggregated update to invariant directions that are generally useful via selectively masking out the update elements that favor few and possibly malicious clients. Theoretical results suggest that our approach provably mitigates backdoor attacks and remains effective over flat loss landscapes. Empirical results on three datasets with different modalities and varying numbers of clients further demonstrate that our approach mitigates a broad class of backdoor attacks with a negligible cost on the model utility.",
        "bibtex": "@InProceedings{pmlr-v238-wang24f,\n  title = \t {Invariant Aggregator for Defending against Federated Backdoor Attacks},\n  author =       {Wang, Xiaoyang and Dimitriadis, Dimitrios and Koyejo, Sanmi and Tople, Shruti},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2728--2736},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24f/wang24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24f.html},\n  abstract = \t {Federated learning enables training high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Despite the theoretical and empirical success in defending against attacks that aim to degrade models\u2019 utility, defense against backdoor attacks that increase model accuracy on backdoor samples exclusively without hurting the utility on other samples remains challenging. To this end, we first analyze the failure modes of existing defenses over a flat loss landscape, which is common for well-designed neural networks such as Resnet (He et al., 2015) but is often overlooked by previous works. Then, we propose an invariant aggregator that redirects the aggregated update to invariant directions that are generally useful via selectively masking out the update elements that favor few and possibly malicious clients. Theoretical results suggest that our approach provably mitigates backdoor attacks and remains effective over flat loss landscapes. Empirical results on three datasets with different modalities and varying numbers of clients further demonstrate that our approach mitigates a broad class of backdoor attacks with a negligible cost on the model utility.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24f/wang24f.pdf",
        "supp": "",
        "pdf_size": 673513,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16256624720413343166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; Stanford University + Azure Research; Stanford University + Azure Research",
        "aff_domain": "illinois.edu;gmail.com;stanford.edu;microsoft.com",
        "email": "illinois.edu;gmail.com;stanford.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;1+2",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Stanford University;Azure Research",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://illinois.edu;https://www.stanford.edu;https://azure.microsoft.com",
        "aff_unique_abbr": "UIUC;Stanford;Azure",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Urbana-Champaign;Stanford;",
        "aff_country_unique_index": "0;0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "481cbf3330",
        "title": "Is this model reliable for everyone? Testing for strong calibration",
        "site": "https://proceedings.mlr.press/v238/feng24a.html",
        "author": "Jean Feng; Alexej Gossmann; Romain Pirracchio; Nicholas Petrick; Gene A Pennello; Berkman Sahiner",
        "abstract": "In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult\u2014particularly for machine learning (ML) algorithms\u2014due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in empirical analyses.",
        "bibtex": "@InProceedings{pmlr-v238-feng24a,\n  title = \t {Is this model reliable for everyone? Testing for strong calibration},\n  author =       {Feng, Jean and Gossmann, Alexej and Pirracchio, Romain and Petrick, Nicholas and A Pennello, Gene and Sahiner, Berkman},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {181--189},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/feng24a/feng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/feng24a.html},\n  abstract = \t {In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult\u2014particularly for machine learning (ML) algorithms\u2014due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in empirical analyses.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/feng24a/feng24a.pdf",
        "supp": "",
        "pdf_size": 1465271,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9359272230921610387&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dec5cb4ad5",
        "title": "Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data",
        "site": "https://proceedings.mlr.press/v238/fuentes24a.html",
        "author": "Miguel Fuentes; Brett C. Mullins; Ryan McKenna; Gerome Miklau; Daniel Sheldon",
        "abstract": "Mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. However, one limitation of these methods is their inability to incorporate public data. Initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. We develop the mechanism JAM-PGM, which expands the adaptive measurements framework to jointly select between measuring public data and private data. This technique allows for public data to be included in a graphical-model-based mechanism. We show that JAM-PGM is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased.",
        "bibtex": "@InProceedings{pmlr-v238-fuentes24a,\n  title = \t {Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data},\n  author =       {Fuentes, Miguel and Mullins, Brett C. and McKenna, Ryan and Miklau, Gerome and Sheldon, Daniel},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2404--2412},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fuentes24a/fuentes24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fuentes24a.html},\n  abstract = \t {Mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. However, one limitation of these methods is their inability to incorporate public data. Initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. We develop the mechanism JAM-PGM, which expands the adaptive measurements framework to jointly select between measuring public data and private data. This technique allows for public data to be included in a graphical-model-based mechanism. We show that JAM-PGM is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fuentes24a/fuentes24a.pdf",
        "supp": "",
        "pdf_size": 947937,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13576964207759333969&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst; Google Research; Tumult Labs; University of Massachusetts Amherst",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Massachusetts Amherst;Google;Tumult Labs",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://www.umass.edu;https://research.google;",
        "aff_unique_abbr": "UMass Amherst;Google Research;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Amherst;Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b869131341",
        "title": "Joint control variate for faster black-box variational inference",
        "site": "https://proceedings.mlr.press/v238/wang24c.html",
        "author": "Xi Wang; Tomas Geffner; Justin Domke",
        "abstract": "Black-box variational inference performance is sometimes hindered by the use of gradient estimators with high variance. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. While existing control variates only address Monte Carlo noise, and incremental gradient methods typically only address data subsampling, we propose a new \"joint\" control variate that jointly reduces variance from both sources of noise. This significantly reduces gradient variance, leading to faster optimization in several applications.",
        "bibtex": "@InProceedings{pmlr-v238-wang24c,\n  title = \t {Joint control variate for faster black-box variational inference},\n  author =       {Wang, Xi and Geffner, Tomas and Domke, Justin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1639--1647},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24c/wang24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24c.html},\n  abstract = \t {Black-box variational inference performance is sometimes hindered by the use of gradient estimators with high variance. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. While existing control variates only address Monte Carlo noise, and incremental gradient methods typically only address data subsampling, we propose a new \"joint\" control variate that jointly reduces variance from both sources of noise. This significantly reduces gradient variance, leading to faster optimization in several applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24c/wang24c.pdf",
        "supp": "",
        "pdf_size": 10552263,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17857762019652510553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Manning College of Information and Computer Sciences, University of Massachusetts Amherst; Manning College of Information and Computer Sciences, University of Massachusetts Amherst; Manning College of Information and Computer Sciences, University of Massachusetts Amherst",
        "aff_domain": "cs.umass.edu;cs.umass.edu;cs.umass.edu",
        "email": "cs.umass.edu;cs.umass.edu;cs.umass.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "Manning College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "682aeda9be",
        "title": "Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free Convergence Rate",
        "site": "https://proceedings.mlr.press/v238/jiang24a.html",
        "author": "Ruichen Jiang; Parameswaran Raman; Shoham Sabach; Aryan Mokhtari; Mingyi Hong; Volkan Cevher",
        "abstract": "Second-order optimization methods, such as cubic regularized Newton methods, are known for their rapid convergence rates; nevertheless, they become impractical in high-dimensional problems due to their substantial memory requirements and computational costs. One promising approach is to execute second-order updates within a lower-dimensional subspace, giving rise to subspace second-order methods. However, the majority of existing subspace second-order methods randomly select subspaces, consequently resulting in slower convergence rates depending on the problem\u2019s dimension $d$. In this paper, we introduce a novel subspace cubic regularized Newton method that achieves a dimension-independent global convergence rate of $\\mathcal{O}\\left(\\frac{1}{mk}+\\frac{1}{k^2}\\right)$ for solving convex optimization problems. Here, $m$ represents the subspace dimension, which can be significantly smaller than $d$. Instead of adopting a random subspace, our primary innovation involves performing the cubic regularized Newton update within the \\emph{Krylov subspace} associated with the Hessian and the gradient of the objective function. This result marks the first instance of a dimension-independent convergence rate for a subspace second-order method. Furthermore, when specific spectral conditions of the Hessian are met, our method recovers the convergence rate of a full-dimensional cubic regularized Newton method. Numerical experiments show our method converges faster than existing random subspace methods, especially for high-dimensional problems.",
        "bibtex": "@InProceedings{pmlr-v238-jiang24a,\n  title = \t {Krylov Cubic Regularized {N}ewton: A Subspace Second-Order Method with Dimension-Free Convergence Rate},\n  author =       {Jiang, Ruichen and Raman, Parameswaran and Sabach, Shoham and Mokhtari, Aryan and Hong, Mingyi and Cevher, Volkan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4411--4419},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jiang24a/jiang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jiang24a.html},\n  abstract = \t {Second-order optimization methods, such as cubic regularized Newton methods, are known for their rapid convergence rates; nevertheless, they become impractical in high-dimensional problems due to their substantial memory requirements and computational costs. One promising approach is to execute second-order updates within a lower-dimensional subspace, giving rise to subspace second-order methods. However, the majority of existing subspace second-order methods randomly select subspaces, consequently resulting in slower convergence rates depending on the problem\u2019s dimension $d$. In this paper, we introduce a novel subspace cubic regularized Newton method that achieves a dimension-independent global convergence rate of $\\mathcal{O}\\left(\\frac{1}{mk}+\\frac{1}{k^2}\\right)$ for solving convex optimization problems. Here, $m$ represents the subspace dimension, which can be significantly smaller than $d$. Instead of adopting a random subspace, our primary innovation involves performing the cubic regularized Newton update within the \\emph{Krylov subspace} associated with the Hessian and the gradient of the objective function. This result marks the first instance of a dimension-independent convergence rate for a subspace second-order method. Furthermore, when specific spectral conditions of the Hessian are met, our method recovers the convergence rate of a full-dimensional cubic regularized Newton method. Numerical experiments show our method converges faster than existing random subspace methods, especially for high-dimensional problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jiang24a/jiang24a.pdf",
        "supp": "",
        "pdf_size": 636893,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11395910019702942611&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "UT Austin; Amazon Web Services; Technion; UT Austin; University of Minnesota; EPFL",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;3;4",
        "aff_unique_norm": "University of Texas at Austin;Amazon;Technion - Israel Institute of Technology;University of Minnesota;EPFL",
        "aff_unique_dep": ";Amazon Web Services;;;",
        "aff_unique_url": "https://www.utexas.edu;https://aws.amazon.com;https://www.technion.ac.il/en/;https://www.minnesota.edu;https://www.epfl.ch",
        "aff_unique_abbr": "UT Austin;AWS;Technion;UMN;EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1;0;0;2",
        "aff_country_unique": "United States;Israel;Switzerland"
    },
    {
        "id": "0b09ec059d",
        "title": "LEDetection: A Simple Framework for Semi-Supervised Few-Shot Object Detection",
        "site": "https://proceedings.mlr.press/v238/vu-tran24a.html",
        "author": "Phi Vu Tran",
        "abstract": "Few-shot object detection (FSOD) is a challenging problem aimed at detecting novel concepts from few exemplars. Existing approaches to FSOD all assume abundant base labels to adapt to novel objects. This paper studies the new task of semi-supervised FSOD by considering a realistic scenario in which both base and novel labels are simultaneously scarce. We explore the utility of unlabeled data within our proposed label-efficient detection framework and discover its remarkable ability to boost semi-supervised FSOD by way of region proposals. Motivated by this finding, we introduce SoftER Teacher, a robust detector combining pseudo-labeling with consistency learning on region proposals, to harness unlabeled data for improved FSOD without relying on abundant labels. Rigorous experiments show that SoftER Teacher surpasses the novel performance of a strong supervised detector using only 10% of required base labels, without catastrophic forgetting observed in prior approaches. Our work also sheds light on a potential relationship between semi-supervised and few-shot detection suggesting that a stronger semi-supervised detector leads to a more effective few-shot detector.",
        "bibtex": "@InProceedings{pmlr-v238-vu-tran24a,\n  title = \t {{LEDetection}: A Simple Framework for Semi-Supervised Few-Shot Object Detection},\n  author =       {Vu Tran, Phi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {640--648},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vu-tran24a/vu-tran24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vu-tran24a.html},\n  abstract = \t {Few-shot object detection (FSOD) is a challenging problem aimed at detecting novel concepts from few exemplars. Existing approaches to FSOD all assume abundant base labels to adapt to novel objects. This paper studies the new task of semi-supervised FSOD by considering a realistic scenario in which both base and novel labels are simultaneously scarce. We explore the utility of unlabeled data within our proposed label-efficient detection framework and discover its remarkable ability to boost semi-supervised FSOD by way of region proposals. Motivated by this finding, we introduce SoftER Teacher, a robust detector combining pseudo-labeling with consistency learning on region proposals, to harness unlabeled data for improved FSOD without relying on abundant labels. Rigorous experiments show that SoftER Teacher surpasses the novel performance of a strong supervised detector using only 10% of required base labels, without catastrophic forgetting observed in prior approaches. Our work also sheds light on a potential relationship between semi-supervised and few-shot detection suggesting that a stronger semi-supervised detector leads to a more effective few-shot detector.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vu-tran24a/vu-tran24a.pdf",
        "supp": "",
        "pdf_size": 7086230,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11555441847577468935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "LexisNexis Risk Solutions",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "LexisNexis Risk Solutions",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lexisnexis.com/risk-solutions",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "56501b879a",
        "title": "LP-based Construction of DC Decompositions for Efficient Inference of Markov Random Fields",
        "site": "https://proceedings.mlr.press/v238/murti24a.html",
        "author": "Chaitanya Murti; Dhruva Kashyap; Chiranjib Bhattacharyya",
        "abstract": "The success of the convex-concave procedure (CCCP), a widely used technique for non-convex optimization, crucially depends on finding a decomposition of the objective function as a difference of convex functions (dcds). Despite the widespread applicability of CCCP, finding such dcds has attracted little attention in machine learning. For graphical models with polynomial potentials, existing methods for finding dcds require solving a Sum-of-Squares (SOS) program, which is often prohibitively expensive. In this work, we leverage tools from algebraic geometry certifying the positivity of polynomials, to derive LP-based constructions of dcds of polynomials which are particularly suited for graphical model inference. Our experiments demonstrate that using our LP-based technique constructs dcds for polynomial potentials of Markov random fields significantly faster compared to SOS-based approaches used in previous works.",
        "bibtex": "@InProceedings{pmlr-v238-murti24a,\n  title = \t {{LP}-based Construction of {DC} Decompositions for Efficient Inference of {M}arkov Random Fields},\n  author =       {Murti, Chaitanya and Kashyap, Dhruva and Bhattacharyya, Chiranjib},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3781--3789},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/murti24a/murti24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/murti24a.html},\n  abstract = \t {The success of the convex-concave procedure (CCCP), a widely used technique for non-convex optimization, crucially depends on finding a decomposition of the objective function as a difference of convex functions (dcds). Despite the widespread applicability of CCCP, finding such dcds has attracted little attention in machine learning. For graphical models with polynomial potentials, existing methods for finding dcds require solving a Sum-of-Squares (SOS) program, which is often prohibitively expensive. In this work, we leverage tools from algebraic geometry certifying the positivity of polynomials, to derive LP-based constructions of dcds of polynomials which are particularly suited for graphical model inference. Our experiments demonstrate that using our LP-based technique constructs dcds for polynomial potentials of Markov random fields significantly faster compared to SOS-based approaches used in previous works.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/murti24a/murti24a.pdf",
        "supp": "",
        "pdf_size": 5852170,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:HwnGCiHrZbgJ:scholar.google.com/&scioq=LP-based+Construction+of+DC+Decompositions+for+Efficient+Inference+of+Markov+Random+Fields&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "51fb2f15da",
        "title": "Large-Scale Gaussian Processes via Alternating Projection",
        "site": "https://proceedings.mlr.press/v238/wu24d.html",
        "author": "Kaiwen Wu; Jonathan Wenger; Haydn T Jones; Geoff Pleiss; Jacob Gardner",
        "abstract": "Training and inference in Gaussian processes (GPs) require solving linear systems with $n\\times n$ kernel matrices. To address the prohibitive $\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the kernel matrices become increasingly ill-conditioned and still require $\\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling mini-batching. Our algorithm, based on alternating projection, has $\\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove the method enjoys linear convergence. Empirically, we demonstrate its fast convergence in practice and robustness to ill-conditioning. On large-scale benchmark datasets with up to four million data points, our approach accelerates GP training and inference by speed-up factors up to $27\\times$ and $72 \\times$, respectively, compared to CG.",
        "bibtex": "@InProceedings{pmlr-v238-wu24d,\n  title = \t {Large-Scale {G}aussian Processes via Alternating Projection},\n  author =       {Wu, Kaiwen and Wenger, Jonathan and T Jones, Haydn and Pleiss, Geoff and Gardner, Jacob},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2620--2628},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24d/wu24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24d.html},\n  abstract = \t {Training and inference in Gaussian processes (GPs) require solving linear systems with $n\\times n$ kernel matrices. To address the prohibitive $\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the kernel matrices become increasingly ill-conditioned and still require $\\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling mini-batching. Our algorithm, based on alternating projection, has $\\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove the method enjoys linear convergence. Empirically, we demonstrate its fast convergence in practice and robustness to ill-conditioning. On large-scale benchmark datasets with up to four million data points, our approach accelerates GP training and inference by speed-up factors up to $27\\times$ and $72 \\times$, respectively, compared to CG.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24d/wu24d.pdf",
        "supp": "",
        "pdf_size": 862724,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4738476650818059438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Pennsylvania; Columbia University; University of Pennsylvania; University of British Columbia + Vector Institute; University of Pennsylvania",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2+3;0",
        "aff_unique_norm": "University of Pennsylvania;Columbia University;University of British Columbia;Vector Institute",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.upenn.edu;https://www.columbia.edu;https://www.ubc.ca;https://vectorinstitute.ai/",
        "aff_unique_abbr": "UPenn;Columbia;UBC;Vector Institute",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1+1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "61083ba915",
        "title": "Learning Adaptive Kernels for Statistical Independence Tests",
        "site": "https://proceedings.mlr.press/v238/ren24a.html",
        "author": "Yixin Ren; Yewei Xia; Hao Zhang; Jihong Guan; Shuigeng Zhou",
        "abstract": "We propose a novel framework for kernel-based statistical independence tests that enable adaptatively learning parameterized kernels to maximize test power. Our framework can effectively address the pitfall inherent in the existing signal-to-noise ratio criterion by modeling the change of the null distribution during the learning process. Based on the proposed framework, we design a new class of kernels that can adaptatively focus on the significant dimensions of variables to judge independence, which makes the tests more flexible than using simple kernels that are adaptive only in length-scale, and especially suitable for high-dimensional complex data. Theoretically, we demonstrate the consistency of our independence tests, and show that the non-convex objective function used for learning fits the L-smoothing condition, thus benefiting the optimization. Experimental results on both synthetic and real data show the superiority of our method. The source code and datasets are available at \\url{https://github.com/renyixin666/HSIC-LK.git}.",
        "bibtex": "@InProceedings{pmlr-v238-ren24a,\n  title = \t {Learning Adaptive Kernels for Statistical Independence Tests},\n  author =       {Ren, Yixin and Xia, Yewei and Zhang, Hao and Guan, Jihong and Zhou, Shuigeng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2494--2502},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ren24a/ren24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ren24a.html},\n  abstract = \t {We propose a novel framework for kernel-based statistical independence tests that enable adaptatively learning parameterized kernels to maximize test power. Our framework can effectively address the pitfall inherent in the existing signal-to-noise ratio criterion by modeling the change of the null distribution during the learning process. Based on the proposed framework, we design a new class of kernels that can adaptatively focus on the significant dimensions of variables to judge independence, which makes the tests more flexible than using simple kernels that are adaptive only in length-scale, and especially suitable for high-dimensional complex data. Theoretically, we demonstrate the consistency of our independence tests, and show that the non-convex objective function used for learning fits the L-smoothing condition, thus benefiting the optimization. Experimental results on both synthetic and real data show the superiority of our method. The source code and datasets are available at \\url{https://github.com/renyixin666/HSIC-LK.git}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ren24a/ren24a.pdf",
        "supp": "",
        "pdf_size": 2284155,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11615267079379085352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Fudan University; Fudan University; SIAT, CAS; Tongji University; Fudan University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/renyixin666/HSIC-LK.git",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Fudan University;Shanghai Institute of Advanced Technology;Tongji University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.fudan.edu.cn;http://www.siat.ac.cn;https://www.tongji.edu.cn",
        "aff_unique_abbr": "Fudan;SIAT;Tongji",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "d21cce3d15",
        "title": "Learning Cartesian Product Graphs with Laplacian Constraints",
        "site": "https://proceedings.mlr.press/v238/shi24a.html",
        "author": "Changhao Shi; Gal Mishne",
        "abstract": "Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our method is superior to previous GSP and GM methods.",
        "bibtex": "@InProceedings{pmlr-v238-shi24a,\n  title = \t {Learning {C}artesian Product Graphs with {L}aplacian Constraints},\n  author =       {Shi, Changhao and Mishne, Gal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2521--2529},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shi24a/shi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shi24a.html},\n  abstract = \t {Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our method is superior to previous GSP and GM methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shi24a/shi24a.pdf",
        "supp": "",
        "pdf_size": 5440790,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2238112022811708162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California San Diego; University of California San Diego",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2b27476194",
        "title": "Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing",
        "site": "https://proceedings.mlr.press/v238/ichikawa24a.html",
        "author": "Yuma Ichikawa; Koji Hukushima",
        "abstract": "Variational autoencoders (VAEs) face a notorious problem wherein the variational posterior often aligns closely with the prior, a phenomenon known as posterior collapse, which hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter $\\beta$ and a strategy for annealing this parameter, called KL annealing, are proposed. This study presents a theoretical analysis of the learning dynamics in a minimal VAE. It is rigorously proved that the dynamics converge to a deterministic process within the limit of large input dimensions, thereby enabling a detailed dynamical analysis of the generalization error. Furthermore, the analysis shows that the VAE initially learns entangled representations and gradually acquires disentangled representations. A fixed-point analysis of the deterministic process reveals that when $\\beta$ exceeds a certain threshold, posterior collapse becomes inevitable regardless of the learning period. Additionally, the superfluous latent variables for the data-generative factors lead to overfitting of the background noise; this adversely affects both generalization and learning convergence. The analysis further unveiled that appropriately tuned KL annealing can accelerate convergence.",
        "bibtex": "@InProceedings{pmlr-v238-ichikawa24a,\n  title = \t {Learning Dynamics in Linear {VAE}: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with {KL} Annealing},\n  author =       {Ichikawa, Yuma and Hukushima, Koji},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1936--1944},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ichikawa24a/ichikawa24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ichikawa24a.html},\n  abstract = \t {Variational autoencoders (VAEs) face a notorious problem wherein the variational posterior often aligns closely with the prior, a phenomenon known as posterior collapse, which hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter $\\beta$ and a strategy for annealing this parameter, called KL annealing, are proposed. This study presents a theoretical analysis of the learning dynamics in a minimal VAE. It is rigorously proved that the dynamics converge to a deterministic process within the limit of large input dimensions, thereby enabling a detailed dynamical analysis of the generalization error. Furthermore, the analysis shows that the VAE initially learns entangled representations and gradually acquires disentangled representations. A fixed-point analysis of the deterministic process reveals that when $\\beta$ exceeds a certain threshold, posterior collapse becomes inevitable regardless of the learning period. Additionally, the superfluous latent variables for the data-generative factors lead to overfitting of the background noise; this adversely affects both generalization and learning convergence. The analysis further unveiled that appropriately tuned KL annealing can accelerate convergence.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ichikawa24a/ichikawa24a.pdf",
        "supp": "",
        "pdf_size": 1184288,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16590622058193654050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "05d5506086",
        "title": "Learning Extensive-Form Perfect Equilibria in Two-Player Zero-Sum Sequential Games",
        "site": "https://proceedings.mlr.press/v238/bernasconi24a.html",
        "author": "Martino Bernasconi; Alberto Marchesi; Francesco Trov\u00f2",
        "abstract": "Designing efficient algorithms for computing refinements of the Nash equilibrium (NE) in two-player zero-sum sequential games is of paramount importance, since the NE may prescribe sub-optimal actions off the equilibrium path. The extensive-form perfect equilibrium (EFPE) amends such a weakness by accounting for the possibility that players may make mistakes. This is crucial in the real world, which involves humans with bounded rationality, and it is also key in boosting superhuman agents for games like Poker. Nevertheless, there are only few algorithms for computing NE refinements, which either lack convergence guarantees to exact equilibria or do not scale to large games. We provide the first efficient iterative algorithm that provably converges to an EFPE in two-player zero-sum sequential games. Our algorithm works by tracking a sequence of equilibria of regularized-perturbed games, by using a procedure that is specifically tailored to converge last iterate to such equilibria. The procedure can be implemented efficiently by visiting the game tree, making our method computationally appealing. We also empirically evaluate our algorithm, showing that its strategies are much more robust to players\u2019 mistakes than those of state-of-the-art algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-bernasconi24a,\n  title = \t {Learning Extensive-Form Perfect Equilibria in Two-Player Zero-Sum Sequential Games},\n  author =       {Bernasconi, Martino and Marchesi, Alberto and Trov\\`{o}, Francesco},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2152--2160},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bernasconi24a/bernasconi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bernasconi24a.html},\n  abstract = \t {Designing efficient algorithms for computing refinements of the Nash equilibrium (NE) in two-player zero-sum sequential games is of paramount importance, since the NE may prescribe sub-optimal actions off the equilibrium path. The extensive-form perfect equilibrium (EFPE) amends such a weakness by accounting for the possibility that players may make mistakes. This is crucial in the real world, which involves humans with bounded rationality, and it is also key in boosting superhuman agents for games like Poker. Nevertheless, there are only few algorithms for computing NE refinements, which either lack convergence guarantees to exact equilibria or do not scale to large games. We provide the first efficient iterative algorithm that provably converges to an EFPE in two-player zero-sum sequential games. Our algorithm works by tracking a sequence of equilibria of regularized-perturbed games, by using a procedure that is specifically tailored to converge last iterate to such equilibria. The procedure can be implemented efficiently by visiting the game tree, making our method computationally appealing. We also empirically evaluate our algorithm, showing that its strategies are much more robust to players\u2019 mistakes than those of state-of-the-art algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bernasconi24a/bernasconi24a.pdf",
        "supp": "",
        "pdf_size": 1126218,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11328230022400686120&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "825e79e2bf",
        "title": "Learning Fair Division from Bandit Feedback",
        "site": "https://proceedings.mlr.press/v238/yamada24a.html",
        "author": "Hakuei Yamada; Junpei Komiyama; Kenshi Abe; Atsushi Iwasaki",
        "abstract": "This work addresses learning online fair division under uncertainty, where a central planner sequentially allocates items without precise knowledge of agents\u2019 values or utilities. Departing from conventional online algorithms, the planner here relies on noisy, estimated values obtained after allocating items. We introduce wrapper algorithms utilizing dual averaging, enabling gradual learning of both the type distribution of arriving items and agents\u2019 values through bandit feedback. This approach enables the algorithms to asymptotically achieve optimal Nash social welfare in linear Fisher markets with agents having additive utilities. We also empirically verify the performance of the proposed algorithms across synthetic and empirical datasets.",
        "bibtex": "@InProceedings{pmlr-v238-yamada24a,\n  title = \t {Learning Fair Division from Bandit Feedback},\n  author =       {Yamada, Hakuei and Komiyama, Junpei and Abe, Kenshi and Iwasaki, Atsushi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3106--3114},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yamada24a/yamada24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yamada24a.html},\n  abstract = \t {This work addresses learning online fair division under uncertainty, where a central planner sequentially allocates items without precise knowledge of agents\u2019 values or utilities. Departing from conventional online algorithms, the planner here relies on noisy, estimated values obtained after allocating items. We introduce wrapper algorithms utilizing dual averaging, enabling gradual learning of both the type distribution of arriving items and agents\u2019 values through bandit feedback. This approach enables the algorithms to asymptotically achieve optimal Nash social welfare in linear Fisher markets with agents having additive utilities. We also empirically verify the performance of the proposed algorithms across synthetic and empirical datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yamada24a/yamada24a.pdf",
        "supp": "",
        "pdf_size": 763595,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10528752548403343433&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "64aab2b00f",
        "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
        "site": "https://proceedings.mlr.press/v238/wu24a.html",
        "author": "Dongxia Wu; Tsuyoshi Ide; Georgios Kollias; Jiri Navratil; Aurelie Lozano; Naoki Abe; Yian Ma; Rose Yu",
        "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.",
        "bibtex": "@InProceedings{pmlr-v238-wu24a,\n  title = \t {Learning {G}ranger Causality from Instance-wise Self-attentive {H}awkes Processes},\n  author =       {Wu, Dongxia and Ide, Tsuyoshi and Kollias, Georgios and Navratil, Jiri and Lozano, Aurelie and Abe, Naoki and Ma, Yian and Yu, Rose},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {415--423},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24a/wu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24a.html},\n  abstract = \t {We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24a/wu24a.pdf",
        "supp": "",
        "pdf_size": 920183,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9552996426768919494&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of California, San Diego; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; University of California, San Diego; University of California, San Diego",
        "aff_domain": "ucsd.edu;us.ibm.com;us.ibm.com;us.ibm.com;us.ibm.com;us.ibm.com;ucsd.edu;ucsd.edu",
        "email": "ucsd.edu;us.ibm.com;us.ibm.com;us.ibm.com;us.ibm.com;us.ibm.com;ucsd.edu;ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1;1;0;0",
        "aff_unique_norm": "University of California, San Diego;IBM",
        "aff_unique_dep": ";IBM",
        "aff_unique_url": "https://www.ucsd.edu;https://www.ibm.com/research/watson",
        "aff_unique_abbr": "UCSD;IBM",
        "aff_campus_unique_index": "0;1;1;1;1;1;0;0",
        "aff_campus_unique": "San Diego;T. J. Watson",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b389f6626f",
        "title": "Learning Latent Partial Matchings with Gumbel-IPF Networks",
        "site": "https://proceedings.mlr.press/v238/cohen-indelman24a.html",
        "author": "Hedda Cohen Indelman; Tamir Hazan",
        "abstract": "Learning to match discrete objects has been a central task in machine learning, often facilitated by a continuous relaxation of the matching structure. However, practical problems entail partial matchings due to missing correspondences, which pose difficulties to the one-to-one matching learning techniques that dominate the state-of-the-art. This paper introduces Gumbel-IPF networks for learning latent partial matchings. At the core of our method is the differentiable Iterative Proportional Fitting (IPF) procedure that biproportionally projects onto the transportation polytope of target marginals. Our theoretical framework also allows drawing samples from the temperature-dependent partial matching distribution. We investigate the properties of common-practice relaxations through the lens of biproportional fitting and introduce a new metric, the empirical prediction shift. Our method\u2019s advantages are demonstrated in experimental results on the semantic keypoints partial matching task on the Pascal VOC, IMC-PT-SparseGM, and CUB2001 datasets.",
        "bibtex": "@InProceedings{pmlr-v238-cohen-indelman24a,\n  title = \t {Learning Latent Partial Matchings with {G}umbel-{IPF} Networks},\n  author =       {Cohen Indelman, Hedda and Hazan, Tamir},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1513--1521},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cohen-indelman24a/cohen-indelman24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cohen-indelman24a.html},\n  abstract = \t {Learning to match discrete objects has been a central task in machine learning, often facilitated by a continuous relaxation of the matching structure. However, practical problems entail partial matchings due to missing correspondences, which pose difficulties to the one-to-one matching learning techniques that dominate the state-of-the-art. This paper introduces Gumbel-IPF networks for learning latent partial matchings. At the core of our method is the differentiable Iterative Proportional Fitting (IPF) procedure that biproportionally projects onto the transportation polytope of target marginals. Our theoretical framework also allows drawing samples from the temperature-dependent partial matching distribution. We investigate the properties of common-practice relaxations through the lens of biproportional fitting and introduce a new metric, the empirical prediction shift. Our method\u2019s advantages are demonstrated in experimental results on the semantic keypoints partial matching task on the Pascal VOC, IMC-PT-SparseGM, and CUB2001 datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cohen-indelman24a/cohen-indelman24a.pdf",
        "supp": "",
        "pdf_size": 5264426,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8278372220001549735&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Technion; Technion",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "3532ac41ac",
        "title": "Learning Populations of Preferences via Pairwise Comparison Queries",
        "site": "https://proceedings.mlr.press/v238/tatli24a.html",
        "author": "Gokcan Tatli; Yi Chen; Ramya Korlakai Vinayak",
        "abstract": "Ideal point based preference learning using pairwise comparisons of type \"Do you prefer a or b?\" has emerged as a powerful tool for understanding how we make preferences. Existing preference learning approaches assume homogeneity and focus on learning preference on average over the population or require a large number of queries per individual to localize individual preferences. However, in practical scenarios with heterogeneous preferences and limited availability of responses, these approaches are impractical. Therefore, we introduce the problem of learning the distribution of preferences over a population via pairwise comparisons using only one response per individual. Due to binary answers from comparison queries, we focus on learning the mass of the underlying distribution in the regions created by the intersection of bisecting hyperplanes between queried item pairs. We investigate this fundamental question in both 1-D and higher dimensional settings with noiseless response to comparison queries. We show that the problem is identifiable in 1-D setting and provide recovery guarantees. We show that the problem is not identifiable for higher dimensional settings in general and establish sufficient condition for identifiability. We propose using a regularized recovery, and provide guarantees on the total variation distance between the true mass and the learned distribution. We validate our findings through simulations and experiments on real datasets. We also introduce a new dataset for this task collected on a real crowdsourcing platform.",
        "bibtex": "@InProceedings{pmlr-v238-tatli24a,\n  title = \t {Learning Populations of Preferences via Pairwise Comparison Queries},\n  author =       {Tatli, Gokcan and Chen, Yi and Korlakai Vinayak, Ramya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1720--1728},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tatli24a/tatli24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tatli24a.html},\n  abstract = \t {Ideal point based preference learning using pairwise comparisons of type \"Do you prefer a or b?\" has emerged as a powerful tool for understanding how we make preferences. Existing preference learning approaches assume homogeneity and focus on learning preference on average over the population or require a large number of queries per individual to localize individual preferences. However, in practical scenarios with heterogeneous preferences and limited availability of responses, these approaches are impractical. Therefore, we introduce the problem of learning the distribution of preferences over a population via pairwise comparisons using only one response per individual. Due to binary answers from comparison queries, we focus on learning the mass of the underlying distribution in the regions created by the intersection of bisecting hyperplanes between queried item pairs. We investigate this fundamental question in both 1-D and higher dimensional settings with noiseless response to comparison queries. We show that the problem is identifiable in 1-D setting and provide recovery guarantees. We show that the problem is not identifiable for higher dimensional settings in general and establish sufficient condition for identifiability. We propose using a regularized recovery, and provide guarantees on the total variation distance between the true mass and the learned distribution. We validate our findings through simulations and experiments on real datasets. We also introduce a new dataset for this task collected on a real crowdsourcing platform.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tatli24a/tatli24a.pdf",
        "supp": "",
        "pdf_size": 4001108,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17459363181118711265&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8ba469b13a",
        "title": "Learning Safety Constraints from Demonstrations with Unknown Rewards",
        "site": "https://proceedings.mlr.press/v238/lindner24a.html",
        "author": "David Lindner; Xin Chen; Sebastian Tschiatschek; Katja Hofmann; Andreas Krause",
        "abstract": "We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies.",
        "bibtex": "@InProceedings{pmlr-v238-lindner24a,\n  title = \t {Learning Safety Constraints from Demonstrations with Unknown Rewards},\n  author =       {Lindner, David and Chen, Xin and Tschiatschek, Sebastian and Hofmann, Katja and Krause, Andreas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2386--2394},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lindner24a/lindner24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lindner24a.html},\n  abstract = \t {We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lindner24a/lindner24a.pdf",
        "supp": "",
        "pdf_size": 982989,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11116447483772192711&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "ETH Zurich; ETH Zurich; University of Vienna; Microsoft Research, Cambridge; ETH Zurich",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "ETH Zurich;University of Vienna;Microsoft",
        "aff_unique_dep": ";;Microsoft Research",
        "aff_unique_url": "https://www.ethz.ch;https://univie.ac.at;https://www.microsoft.com/en-us/research/group/cambridge",
        "aff_unique_abbr": "ETHZ;UV;MSR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "Switzerland;Austria;United Kingdom"
    },
    {
        "id": "f6a5c00608",
        "title": "Learning Sampling Policy to Achieve Fewer Queries for Zeroth-Order Optimization",
        "site": "https://proceedings.mlr.press/v238/zhai24a.html",
        "author": "Zhou Zhai; Wanli Shi; Heng Huang; Yi Chang; Bin Gu",
        "abstract": "Zeroth-order (ZO) methods, which use the finite difference of two function evaluations (also called ZO gradient) to approximate first-order gradient, have attracted much attention recently in machine learning because of their broad applications. The accuracy of the ZO gradient highly depends on how many finite differences are averaged, which are intrinsically determined by the number of perturbations randomly drawn from a distribution. Existing ZO methods try to learn a data-driven distribution for sampling the perturbations to improve the efficiency of ZO optimization (ZOO) algorithms. In this paper, we explore a new and parallel direction, \\textit{i.e.}, learn an optimal sampling policy instead of using a totally random strategy to generate perturbations based on the techniques of reinforcement learning (RL), which makes it possible to approximate the gradient with only two function evaluations. Specifically, we first formulate the problem of learning a sampling policy as a Markov decision process. Then, we propose our ZO-RL algorithm, \\textit{i.e.}, using deep deterministic policy gradient, an actor-critic RL algorithm to learn a sampling policy that can guide the generation of perturbed vectors in getting ZO gradients as accurately as possible. Importantly, the existing ZOO algorithms for learning a distribution can be plugged in to improve the exploration of ZO-RL. Experimental results with different ZO estimators show that our ZO-RL algorithm can effectively reduce the query complexity of ZOO algorithms and converge faster than existing ZOO algorithms, especially in the later stage of the optimization process.",
        "bibtex": "@InProceedings{pmlr-v238-zhai24a,\n  title = \t {Learning Sampling Policy to Achieve Fewer Queries for Zeroth-Order Optimization},\n  author =       {Zhai, Zhou and Shi, Wanli and Huang, Heng and Chang, Yi and Gu, Bin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1162--1170},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhai24a/zhai24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhai24a.html},\n  abstract = \t {Zeroth-order (ZO) methods, which use the finite difference of two function evaluations (also called ZO gradient) to approximate first-order gradient, have attracted much attention recently in machine learning because of their broad applications. The accuracy of the ZO gradient highly depends on how many finite differences are averaged, which are intrinsically determined by the number of perturbations randomly drawn from a distribution. Existing ZO methods try to learn a data-driven distribution for sampling the perturbations to improve the efficiency of ZO optimization (ZOO) algorithms. In this paper, we explore a new and parallel direction, \\textit{i.e.}, learn an optimal sampling policy instead of using a totally random strategy to generate perturbations based on the techniques of reinforcement learning (RL), which makes it possible to approximate the gradient with only two function evaluations. Specifically, we first formulate the problem of learning a sampling policy as a Markov decision process. Then, we propose our ZO-RL algorithm, \\textit{i.e.}, using deep deterministic policy gradient, an actor-critic RL algorithm to learn a sampling policy that can guide the generation of perturbed vectors in getting ZO gradients as accurately as possible. Importantly, the existing ZOO algorithms for learning a distribution can be plugged in to improve the exploration of ZO-RL. Experimental results with different ZO estimators show that our ZO-RL algorithm can effectively reduce the query complexity of ZOO algorithms and converge faster than existing ZOO algorithms, especially in the later stage of the optimization process.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhai24a/zhai24a.pdf",
        "supp": "",
        "pdf_size": 5655707,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:6p-YQpxrkTcJ:scholar.google.com/&scioq=Learning+Sampling+Policy+to+Achieve+Fewer+Queries+for+Zeroth-Order+Optimization&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "Nanjing University of Information Science & Technology, China; Mohamed bin Zayed University of Artificial Intelligence, UAE; University of Maryland, College Park, USA; School of Artificial Intelligence, Jilin University, China; Mohamed bin Zayed University of Artificial Intelligence, UAE+School of Artificial Intelligence, Jilin University, China",
        "aff_domain": "gmail.com; ; ; ;gmail.com",
        "email": "gmail.com; ; ; ;gmail.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;1+3",
        "aff_unique_norm": "Nanjing University of Information Science & Technology;Mohamed bin Zayed University of Artificial Intelligence;University of Maryland;Jilin University",
        "aff_unique_dep": ";;;School of Artificial Intelligence",
        "aff_unique_url": "http://www.nuist.edu.cn;https://mbzuai.ac.ae;https://www/umd.edu;http://www.jlu.edu.cn",
        "aff_unique_abbr": "NUIST;MBZUAI;UMD;JLU",
        "aff_campus_unique_index": "1;",
        "aff_campus_unique": ";College Park",
        "aff_country_unique_index": "0;1;2;0;1+0",
        "aff_country_unique": "China;United Arab Emirates;United States"
    },
    {
        "id": "f8b221c6a9",
        "title": "Learning Sparse Codes with Entropy-Based ELBOs",
        "site": "https://proceedings.mlr.press/v238/velychko24a.html",
        "author": "Dmytro Velychko; Simon Damm; Asja Fischer; J\u00f6rg L\u00fccke",
        "abstract": "Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) the novel objective is fully analytic; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytic solutions, which leads to the fully analytic objective. Numerical experiments are used to demonstrate the feasibility of learning with such entropy-based ELBOs. We investigate different posterior approximations including Gaussians with correlated latents and deep amortized approximations. Furthermore, we numerically investigate entropy-based annealing which results in improved learning. Our main contributions are theoretical, however, and they are twofold: (1) we provide the first demonstration on how a recently shown convergence of the ELBO to entropy sums can be used for learning; and (2) using the entropy objective, we derive a fully analytic ELBO objective for the standard sparse coding generative model.",
        "bibtex": "@InProceedings{pmlr-v238-velychko24a,\n  title = \t {Learning Sparse Codes with Entropy-Based {ELBOs}},\n  author =       {Velychko, Dmytro and Damm, Simon and Fischer, Asja and L\\\"{u}cke, J\\\"{o}rg},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2089--2097},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/velychko24a/velychko24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/velychko24a.html},\n  abstract = \t {Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) the novel objective is fully analytic; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytic solutions, which leads to the fully analytic objective. Numerical experiments are used to demonstrate the feasibility of learning with such entropy-based ELBOs. We investigate different posterior approximations including Gaussians with correlated latents and deep amortized approximations. Furthermore, we numerically investigate entropy-based annealing which results in improved learning. Our main contributions are theoretical, however, and they are twofold: (1) we provide the first demonstration on how a recently shown convergence of the ELBO to entropy sums can be used for learning; and (2) using the entropy objective, we derive a fully analytic ELBO objective for the standard sparse coding generative model.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/velychko24a/velychko24a.pdf",
        "supp": "",
        "pdf_size": 2943891,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10084470623591968806&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ec1ee7a38d",
        "title": "Learning Under Random Distributional Shifts",
        "site": "https://proceedings.mlr.press/v238/bansak24a.html",
        "author": "Kirk C. Bansak; Elisabeth Paulson; Dominik Rothenhaeusler",
        "abstract": "Many existing approaches for generating predictions in settings with distribution shift model distribution shifts as adversarial or low-rank in suitable representations. In various real-world settings, however, we might expect shifts to arise through the superposition of many small and random changes in the population and environment. Thus, we consider a class of random distribution shift models that capture arbitrary changes in the underlying covariate space, and dense, random shocks to the relationship between the covariates and the outcomes. In this setting, we characterize the benefits and drawbacks of several alternative prediction strategies: the standard approach that directly predicts the long-term outcomes of interest, the proxy approach that directly predicts shorter-term proxy outcomes, and a hybrid approach that utilizes both the long-term policy outcome and (shorter-term) proxy outcome(s). We show that the hybrid approach is robust to the strength of the distribution shift and the proxy relationship. We apply this method to datasets in two high-impact domains: asylum-seeker placement and early childhood education. In both settings, we find that the proposed approach results in substantially lower mean-squared error than current approaches.",
        "bibtex": "@InProceedings{pmlr-v238-bansak24a,\n  title = \t {Learning Under Random Distributional Shifts},\n  author =       {Bansak, Kirk C. and Paulson, Elisabeth and Rothenhaeusler, Dominik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3943--3951},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bansak24a/bansak24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bansak24a.html},\n  abstract = \t {Many existing approaches for generating predictions in settings with distribution shift model distribution shifts as adversarial or low-rank in suitable representations. In various real-world settings, however, we might expect shifts to arise through the superposition of many small and random changes in the population and environment. Thus, we consider a class of random distribution shift models that capture arbitrary changes in the underlying covariate space, and dense, random shocks to the relationship between the covariates and the outcomes. In this setting, we characterize the benefits and drawbacks of several alternative prediction strategies: the standard approach that directly predicts the long-term outcomes of interest, the proxy approach that directly predicts shorter-term proxy outcomes, and a hybrid approach that utilizes both the long-term policy outcome and (shorter-term) proxy outcome(s). We show that the hybrid approach is robust to the strength of the distribution shift and the proxy relationship. We apply this method to datasets in two high-impact domains: asylum-seeker placement and early childhood education. In both settings, we find that the proposed approach results in substantially lower mean-squared error than current approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bansak24a/bansak24a.pdf",
        "supp": "",
        "pdf_size": 654817,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3691237436169490988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e81cdd8145",
        "title": "Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data",
        "site": "https://proceedings.mlr.press/v238/yang24d.html",
        "author": "Yuqin Yang; Saber Salehkaleybar; Negar Kiyavash",
        "abstract": "We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the intervention targets among the observed variables cannot be determined uniquely. We provide a candidate intervention target set which is a superset of the true intervention targets. Our approach improves upon the state of the art as the returned candidate set is always a subset of the target set returned by previous work. Moreover, we do not require restrictive assumptions such as linearity of the causal model or performing invariance tests to learn whether a distribution is changing across environments which could be highly sample inefficient. Our experimental results show the effectiveness of our proposed algorithm in practice.",
        "bibtex": "@InProceedings{pmlr-v238-yang24d,\n  title = \t {Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data},\n  author =       {Yang, Yuqin and Salehkaleybar, Saber and Kiyavash, Negar},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3187--3195},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yang24d/yang24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yang24d.html},\n  abstract = \t {We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the intervention targets among the observed variables cannot be determined uniquely. We provide a candidate intervention target set which is a superset of the true intervention targets. Our approach improves upon the state of the art as the returned candidate set is always a subset of the target set returned by previous work. Moreover, we do not require restrictive assumptions such as linearity of the causal model or performing invariance tests to learn whether a distribution is changing across environments which could be highly sample inefficient. Our experimental results show the effectiveness of our proposed algorithm in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yang24d/yang24d.pdf",
        "supp": "",
        "pdf_size": 873416,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11384211732323522428&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Georgia Tech; Leiden University; EPFL",
        "aff_domain": "gatech.edu; ; ",
        "email": "gatech.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;Leiden University;EPFL",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.gatech.edu;https://www.leidenuniv.nl;https://www.epfl.ch",
        "aff_unique_abbr": "Georgia Tech;LU;EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "United States;Netherlands;Switzerland"
    },
    {
        "id": "893c28fedb",
        "title": "Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers",
        "site": "https://proceedings.mlr.press/v238/choromanski24a.html",
        "author": "Krzysztof Choromanski; Shanda Li; Valerii Likhosherstov; Kumar Avinava Dubey; Shengjie Luo; Di He; Yiming Yang; Tamas Sarlos; Thomas Weingarten; Adrian Weller",
        "abstract": "We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for sequential data, as well as novel RPEs operating on geometric data embedded in higher-dimensional Euclidean spaces. FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE mask. Besides, FLTs allow for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and give accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly test FLTs on other data modalities and tasks, such as image classification, 3D molecular modeling, and learnable optimizers. To the best of our knowledge, for 3D molecular data, FLTs are the first Transformer architectures providing linear attention and incorporating RPE masking.",
        "bibtex": "@InProceedings{pmlr-v238-choromanski24a,\n  title = \t {Learning a {F}ourier Transform for Linear Relative Positional Encodings in Transformers},\n  author =       {Choromanski, Krzysztof and Li, Shanda and Likhosherstov, Valerii and Avinava Dubey, Kumar and Luo, Shengjie and He, Di and Yang, Yiming and Sarlos, Tamas and Weingarten, Thomas and Weller, Adrian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2278--2286},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/choromanski24a/choromanski24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/choromanski24a.html},\n  abstract = \t {We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for sequential data, as well as novel RPEs operating on geometric data embedded in higher-dimensional Euclidean spaces. FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE mask. Besides, FLTs allow for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and give accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly test FLTs on other data modalities and tasks, such as image classification, 3D molecular modeling, and learnable optimizers. To the best of our knowledge, for 3D molecular data, FLTs are the first Transformer architectures providing linear attention and incorporating RPE masking.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/choromanski24a/choromanski24a.pdf",
        "supp": "",
        "pdf_size": 2722801,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12019686601638306679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Google Research; Columbia University; Carnegie Mellon University; Waymo; Peking University; University of Cambridge; Alan Turing Institute; Google Research; Google Research; University of Cambridge + Alan Turing Institute",
        "aff_domain": "google.com;cs.cmu.edu; ;google.com; ; ; ; ; ;eng.cam.ac.uk",
        "email": "google.com;cs.cmu.edu; ;google.com; ; ; ; ; ;eng.cam.ac.uk",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4;5;6;0;0;5+6",
        "aff_unique_norm": "Google;Columbia University;Carnegie Mellon University;Waymo;Peking University;University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": "Google Research;;;;;;",
        "aff_unique_url": "https://research.google;https://www.columbia.edu;https://www.cmu.edu;https://www.waymo.com;http://www.pku.edu.cn;https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Google Research;Columbia;CMU;Waymo;Peking U;Cambridge;ATI",
        "aff_campus_unique_index": "0;2;0;0;2",
        "aff_campus_unique": "Mountain View;;Cambridge",
        "aff_country_unique_index": "0;0;0;0;1;2;2;0;0;2+2",
        "aff_country_unique": "United States;China;United Kingdom"
    },
    {
        "id": "19fdabf6a8",
        "title": "Learning multivariate temporal point processes via the time-change theorem",
        "site": "https://proceedings.mlr.press/v238/augusto-zagatti24a.html",
        "author": "Guilherme Augusto Zagatti; See Kiong Ng; St\u00e9phane Bressan",
        "abstract": "Marked temporal point processes (TPPs) are a class of stochastic processes that describe the occurrence of a countable number of marked events over continuous time. In machine learning, the most common representation of marked TPPs is the univariate TPP coupled with a conditional mark distribution. Alternatively, we can represent marked TPPs as a multivariate temporal point process in which we model each sequence of marks interdependently. We introduce a learning framework for multivariate TPPs leveraging recent progress on learning univariate TPPs via time-change theorems to propose a deep-learning, invertible model for the conditional intensity. We rely neither on Monte Carlo approximation for the compensator nor on thinning for sampling. Therefore, we have a generative model that can efficiently sample the next event given a history of past events. Our models show strong alignment between the percentiles of the distribution expected from theory and the empirical ones.",
        "bibtex": "@InProceedings{pmlr-v238-augusto-zagatti24a,\n  title = \t {Learning multivariate temporal point processes via the time-change theorem},\n  author =       {Augusto Zagatti, Guilherme and Kiong Ng, See and Bressan, St\\'{e}phane},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3241--3249},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/augusto-zagatti24a/augusto-zagatti24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/augusto-zagatti24a.html},\n  abstract = \t {Marked temporal point processes (TPPs) are a class of stochastic processes that describe the occurrence of a countable number of marked events over continuous time. In machine learning, the most common representation of marked TPPs is the univariate TPP coupled with a conditional mark distribution. Alternatively, we can represent marked TPPs as a multivariate temporal point process in which we model each sequence of marks interdependently. We introduce a learning framework for multivariate TPPs leveraging recent progress on learning univariate TPPs via time-change theorems to propose a deep-learning, invertible model for the conditional intensity. We rely neither on Monte Carlo approximation for the compensator nor on thinning for sampling. Therefore, we have a generative model that can efficiently sample the next event given a history of past events. Our models show strong alignment between the percentiles of the distribution expected from theory and the empirical ones.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/augusto-zagatti24a/augusto-zagatti24a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10814116442395529827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f7c1c45c27",
        "title": "Learning the Pareto Set Under Incomplete Preferences: Pure Exploration in Vector Bandits",
        "site": "https://proceedings.mlr.press/v238/karagozlu24a.html",
        "author": "Efe Mert Karag\u00f6zl\u00fc; Ya\u015far Cahit Y\u0131ld\u0131r\u0131m; Ca\u011f\u0131n Ararat; Cem Tekin",
        "abstract": "We study pure exploration in bandit problems with vector-valued rewards, where the goal is to (approximately) identify the Pareto set of arms given incomplete preferences induced by a polyhedral convex cone. We address the open problem of designing sample-efficient learning algorithms for such problems. We propose Pareto Vector Bandits (PaVeBa), an adaptive elimination algorithm that nearly matches the gap-dependent and worst-case lower bounds on the sample complexity of $(\\epsilon, \\delta)$-PAC Pareto set identification. Finally, we provide an in-depth numerical investigation of PaVeBa and its heuristic variants by comparing them with the state-of-the-art multi-objective and vector optimization algorithms on several real-world datasets with conflicting objectives.",
        "bibtex": "@InProceedings{pmlr-v238-karagozlu24a,\n  title = \t {Learning the {P}areto Set Under Incomplete Preferences: Pure Exploration in Vector Bandits},\n  author =       {Karag{\\\"o}zl{\\\"u}, Efe Mert and Y{\\i}ld{\\i}r{\\i}m, Ya{\\c{s}}ar Cahit and Ararat, Ca\\u{g}{\\i}n and Tekin, Cem},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3070--3078},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/karagozlu24a/karagozlu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/karagozlu24a.html},\n  abstract = \t {We study pure exploration in bandit problems with vector-valued rewards, where the goal is to (approximately) identify the Pareto set of arms given incomplete preferences induced by a polyhedral convex cone. We address the open problem of designing sample-efficient learning algorithms for such problems. We propose Pareto Vector Bandits (PaVeBa), an adaptive elimination algorithm that nearly matches the gap-dependent and worst-case lower bounds on the sample complexity of $(\\epsilon, \\delta)$-PAC Pareto set identification. Finally, we provide an in-depth numerical investigation of PaVeBa and its heuristic variants by comparing them with the state-of-the-art multi-objective and vector optimization algorithms on several real-world datasets with conflicting objectives.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/karagozlu24a/karagozlu24a.pdf",
        "supp": "",
        "pdf_size": 6481074,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2812617463441005498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "60d5e3305f",
        "title": "Learning to Defer to a Population: A Meta-Learning Approach",
        "site": "https://proceedings.mlr.press/v238/tailor24a.html",
        "author": "Dharmesh Tailor; Aditya Patra; Rajeev Verma; Putra Manggala; Eric Nalisnick",
        "abstract": "The learning to defer (L2D) framework allows autonomous systems to be safe and robust by allocating difficult decisions to a human expert. All existing work on L2D assumes that each expert is well-identified, and if any expert were to change, the system should be re-trained. In this work, we alleviate this constraint, formulating an L2D system that can cope with never-before-seen experts at test-time. We accomplish this by using meta-learning, considering both optimization- and model-based variants. Given a small context set to characterize the currently available expert, our framework can quickly adapt its deferral policy. For the model-based approach, we employ an attention mechanism that is able to look for points in the context set that are similar to a given test point, leading to an even more precise assessment of the expert\u2019s abilities. In the experiments, we validate our methods on image recognition, traffic sign detection, and skin lesion diagnosis benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-tailor24a,\n  title = \t {Learning to Defer to a Population: A Meta-Learning Approach},\n  author =       {Tailor, Dharmesh and Patra, Aditya and Verma, Rajeev and Manggala, Putra and Nalisnick, Eric},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3475--3483},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tailor24a/tailor24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tailor24a.html},\n  abstract = \t {The learning to defer (L2D) framework allows autonomous systems to be safe and robust by allocating difficult decisions to a human expert. All existing work on L2D assumes that each expert is well-identified, and if any expert were to change, the system should be re-trained. In this work, we alleviate this constraint, formulating an L2D system that can cope with never-before-seen experts at test-time. We accomplish this by using meta-learning, considering both optimization- and model-based variants. Given a small context set to characterize the currently available expert, our framework can quickly adapt its deferral policy. For the model-based approach, we employ an attention mechanism that is able to look for points in the context set that are similar to a given test point, leading to an even more precise assessment of the expert\u2019s abilities. In the experiments, we validate our methods on image recognition, traffic sign detection, and skin lesion diagnosis benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tailor24a/tailor24a.pdf",
        "supp": "",
        "pdf_size": 1763212,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12108956337047370300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Amsterdam; University of Amsterdam; University of Amsterdam; University of Amsterdam; University of Amsterdam",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Amsterdam",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uva.nl",
        "aff_unique_abbr": "UvA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "bd158b29dd",
        "title": "Learning to Rank for Optimal Treatment Allocation Under Resource Constraints",
        "site": "https://proceedings.mlr.press/v238/kamran24a.html",
        "author": "Fahad Kamran; Maggie Makar; Jenna Wiens",
        "abstract": "Current causal inference approaches for estimating conditional average treatment effects (CATEs) often prioritize accuracy. However, in resource constrained settings, decision makers may only need a ranking of individuals based on their estimated CATE. In these scenarios, exact CATE estimation may be an unnecessarily challenging task, particularly when the underlying function is difficult to learn. In this work, we study the relationship between CATE estimation and optimizing for CATE ranking, demonstrating that optimizing for ranking may be more appropriate than optimizing for accuracy in certain settings. Guided by our analysis, we propose an approach to directly optimize for rankings of individuals to inform treatment assignment that aims to maximize benefit. Our tree-based approach maximizes the expected benefit of the treatment assignment using a novel splitting criteria. In an empirical case-study across synthetic datasets, our approach leads to better treatment assignments compared to CATE estimation methods as measured by expected total benefit. By providing a practical and efficient approach to learning a CATE ranking, this work offers an important step towards bridging the gap between CATE estimation techniques and their downstream applications.",
        "bibtex": "@InProceedings{pmlr-v238-kamran24a,\n  title = \t {Learning to Rank for Optimal Treatment Allocation Under Resource Constraints},\n  author =       {Kamran, Fahad and Makar, Maggie and Wiens, Jenna},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3727--3735},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kamran24a/kamran24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kamran24a.html},\n  abstract = \t {Current causal inference approaches for estimating conditional average treatment effects (CATEs) often prioritize accuracy. However, in resource constrained settings, decision makers may only need a ranking of individuals based on their estimated CATE. In these scenarios, exact CATE estimation may be an unnecessarily challenging task, particularly when the underlying function is difficult to learn. In this work, we study the relationship between CATE estimation and optimizing for CATE ranking, demonstrating that optimizing for ranking may be more appropriate than optimizing for accuracy in certain settings. Guided by our analysis, we propose an approach to directly optimize for rankings of individuals to inform treatment assignment that aims to maximize benefit. Our tree-based approach maximizes the expected benefit of the treatment assignment using a novel splitting criteria. In an empirical case-study across synthetic datasets, our approach leads to better treatment assignments compared to CATE estimation methods as measured by expected total benefit. By providing a practical and efficient approach to learning a CATE ranking, this work offers an important step towards bridging the gap between CATE estimation techniques and their downstream applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kamran24a/kamran24a.pdf",
        "supp": "",
        "pdf_size": 6074946,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7802632930374107030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c32d04a6fc",
        "title": "Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models",
        "site": "https://proceedings.mlr.press/v238/arya24b.html",
        "author": "Shivvrat Arya; Tahrima Rahman; Vibhav Gogate",
        "abstract": "We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks. Let $f$ and $g$ be two log-linear models defined over the sets $X$ and $Y$ of random variables. Given an assignment $x$ to all variables in $X$ (evidence or observations) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $y$ to all variables in $Y$ such that $f(x, y)$ is maximized and $g(x, y) \\leq q$. In our proposed self-supervised approach, given assignments $x$ to $X$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions. The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones. We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems.",
        "bibtex": "@InProceedings{pmlr-v238-arya24b,\n  title = \t {Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models},\n  author =       {Arya, Shivvrat and Rahman, Tahrima and Gogate, Vibhav},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2791--2799},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/arya24b/arya24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/arya24b.html},\n  abstract = \t {We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks. Let $f$ and $g$ be two log-linear models defined over the sets $X$ and $Y$ of random variables. Given an assignment $x$ to all variables in $X$ (evidence or observations) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $y$ to all variables in $Y$ such that $f(x, y)$ is maximized and $g(x, y) \\leq q$. In our proposed self-supervised approach, given assignments $x$ to $X$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions. The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones. We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/arya24b/arya24b.pdf",
        "supp": "",
        "pdf_size": 2817321,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11074989614836242248&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Dallas",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utdallas.edu",
        "aff_unique_abbr": "UT Dallas",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Dallas",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "646adc91d9",
        "title": "Learning-Based Algorithms for Graph Searching Problems",
        "site": "https://proceedings.mlr.press/v238/depavia24a.html",
        "author": "Adela F. DePavia; Erasmo Tani; Ali Vakilian",
        "abstract": "We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2023). In this problem, an agent starting at some vertex r has to traverse a (potentially unknown) graph G to find a hidden goal node g while minimizing the total distance traveled. We study a setting in which at any node v, the agent receives a noisy estimate of the distance from v to g. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide simpler performance bounds on the algorithms of Banerjee et al. (2023) for the case of searching on a known graph and establish new lower bounds for this setting.",
        "bibtex": "@InProceedings{pmlr-v238-depavia24a,\n  title = \t {Learning-Based Algorithms for Graph Searching Problems},\n  author =       {DePavia, Adela F. and Tani, Erasmo and Vakilian, Ali},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {928--936},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/depavia24a/depavia24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/depavia24a.html},\n  abstract = \t {We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2023). In this problem, an agent starting at some vertex r has to traverse a (potentially unknown) graph G to find a hidden goal node g while minimizing the total distance traveled. We study a setting in which at any node v, the agent receives a noisy estimate of the distance from v to g. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide simpler performance bounds on the algorithms of Banerjee et al. (2023) for the case of searching on a known graph and establish new lower bounds for this setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/depavia24a/depavia24a.pdf",
        "supp": "",
        "pdf_size": 1619495,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16136133204624372284&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Chicago; University of Chicago; TTIC",
        "aff_domain": "uchicago.edu;uchicago.edu;ttic.edu",
        "email": "uchicago.edu;uchicago.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Chicago;Toyota Technological Institute at Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uchicago.edu;https://www.ttic.edu",
        "aff_unique_abbr": "UChicago;TTIC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Chicago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a5ce0f17ca",
        "title": "Length independent PAC-Bayes bounds for Simple RNNs",
        "site": "https://proceedings.mlr.press/v238/mitarchuk24a.html",
        "author": "Volodimir Mitarchuk; Clara Lacroce; R\u00e9mi Eyraud; R\u00e9mi Emonet; Amaury Habrard; Guillaume Rabusseau",
        "abstract": "While the practical interest of Recurrent neural networks (RNNs) is attested, much remains to be done to develop a thorough theoretical understanding of their abilities, particularly in what concerns their learning capacities. A powerful framework to tackle this question is the one of PAC-Bayes theory, which allows one to derive bounds providing guarantees on the expected performance of learning models on unseen data. In this paper, we provide an extensive study on the conditions leading to PAC-Bayes bounds for non-linear RNNs that are independent of the length of the data. The derivation of our results relies on a perturbation analysis on the weights of the network. We prove bounds that hold for \\emph{$\\beta$-saturated} and \\emph{DS $\\beta$-saturated} SRNs, classes of RNNs we introduce to formalize saturation regimes of RNNs. The first regime corresponds to the case where the values of the hidden state of the SRN are always close to the boundaries of the activation functions. The second one, closely related to practical observations, only requires that it happens at least once in each component of the hidden state on a sliding window of a given size.",
        "bibtex": "@InProceedings{pmlr-v238-mitarchuk24a,\n  title = \t {Length independent {PAC}-{B}ayes bounds for Simple {RNNs}},\n  author =       {Mitarchuk, Volodimir and Lacroce, Clara and Eyraud, R\\'{e}mi and Emonet, R\\'{e}mi and Habrard, Amaury and Rabusseau, Guillaume},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3547--3555},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mitarchuk24a/mitarchuk24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mitarchuk24a.html},\n  abstract = \t {While the practical interest of Recurrent neural networks (RNNs) is attested, much remains to be done to develop a thorough theoretical understanding of their abilities, particularly in what concerns their learning capacities. A powerful framework to tackle this question is the one of PAC-Bayes theory, which allows one to derive bounds providing guarantees on the expected performance of learning models on unseen data. In this paper, we provide an extensive study on the conditions leading to PAC-Bayes bounds for non-linear RNNs that are independent of the length of the data. The derivation of our results relies on a perturbation analysis on the weights of the network. We prove bounds that hold for \\emph{$\\beta$-saturated} and \\emph{DS $\\beta$-saturated} SRNs, classes of RNNs we introduce to formalize saturation regimes of RNNs. The first regime corresponds to the case where the values of the hidden state of the SRN are always close to the boundaries of the activation functions. The second one, closely related to practical observations, only requires that it happens at least once in each component of the hidden state on a sliding window of a given size.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mitarchuk24a/mitarchuk24a.pdf",
        "supp": "",
        "pdf_size": 3683928,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5876039457669939892&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "UJM-Saint-Etienne-LabHC1; UJM-Saint-Etienne-LabHC1+McGill University, Mila, Montr\u00e9al, Canada; UJM-Saint-Etienne-LabHC1; UJM-Saint-Etienne-LabHC1; UJM-Saint-Etienne-LabHC1+Institut Universitaire de France; UJM-Saint-Etienne-LabHC1+Institut Universitaire de France+Universit\u00e9 de Montr\u00e9al, Mila, DIRO, CIFAR AI Chair",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;0;0+2;0+2+3",
        "aff_unique_norm": "Universit\u00e9 Jean Monnet;McGill University;Institut Universitaire de France;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": "LabHC1;Mila;;DIRO",
        "aff_unique_url": "https://www.univ-jean-monnet.fr;https://www.mcgill.ca;https://www.iuf.cnrs.fr;https://www.umontreal.ca",
        "aff_unique_abbr": "UJM;McGill;IUF;UdeM",
        "aff_campus_unique_index": "0;0+1;0;0;0;0",
        "aff_campus_unique": "Saint-Etienne;Montr\u00e9al;",
        "aff_country_unique_index": "0;0+1;0;0;0+0;0+0+1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "01ca782df5",
        "title": "Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks",
        "site": "https://proceedings.mlr.press/v238/papazov24a.html",
        "author": "Hristo Papazov; Scott Pesme; Nicolas Flammarion",
        "abstract": "In this work, we investigate the effect of momentum on the optimisation trajectory of gradient descent. We leverage a continuous-time approach in the analysis of momentum gradient descent with step size $\\gamma$ and momentum parameter $\\beta$ that allows us to identify an intrinsic quantity $\\lambda = \\frac{ \\gamma }{ (1 - \\beta)^2 }$ which uniquely defines the optimisation path and provides a simple acceleration rule. When training a $2$-layer diagonal linear network in an overparametrised regression setting, we characterise the recovered solution through an implicit regularisation problem. We then prove that small values of $\\lambda$ help to recover sparse solutions. Finally, we give similar but weaker results for stochastic momentum gradient descent. We provide numerical experiments which support our claims.",
        "bibtex": "@InProceedings{pmlr-v238-papazov24a,\n  title = \t {Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks},\n  author =       {Papazov, Hristo and Pesme, Scott and Flammarion, Nicolas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3556--3564},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/papazov24a/papazov24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/papazov24a.html},\n  abstract = \t {In this work, we investigate the effect of momentum on the optimisation trajectory of gradient descent. We leverage a continuous-time approach in the analysis of momentum gradient descent with step size $\\gamma$ and momentum parameter $\\beta$ that allows us to identify an intrinsic quantity $\\lambda = \\frac{ \\gamma }{ (1 - \\beta)^2 }$ which uniquely defines the optimisation path and provides a simple acceleration rule. When training a $2$-layer diagonal linear network in an overparametrised regression setting, we characterise the recovered solution through an implicit regularisation problem. We then prove that small values of $\\lambda$ help to recover sparse solutions. Finally, we give similar but weaker results for stochastic momentum gradient descent. We provide numerical experiments which support our claims.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/papazov24a/papazov24a.pdf",
        "supp": "",
        "pdf_size": 5450648,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17443476940400861117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "EPFL; EPFL; EPFL",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "59c2f5f13f",
        "title": "Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias",
        "site": "https://proceedings.mlr.press/v238/odonnat24a.html",
        "author": "Ambroise Odonnat; Vasilii Feofanov; Ievgen Redko",
        "abstract": "Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, \\texttt{softmax} prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraints. To address this issue, we propose a novel confidence measure, called $\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim.",
        "bibtex": "@InProceedings{pmlr-v238-odonnat24a,\n  title = \t {Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias},\n  author =       {Odonnat, Ambroise and Feofanov, Vasilii and Redko, Ievgen},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {595--603},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/odonnat24a/odonnat24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/odonnat24a.html},\n  abstract = \t {Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, \\texttt{softmax} prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraints. To address this issue, we propose a novel confidence measure, called $\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/odonnat24a/odonnat24a.pdf",
        "supp": "",
        "pdf_size": 2206247,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16528873436724243722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab + \u00b4Ecole des Ponts ParisTech + ENS Paris-Saclay",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "https://github.com/ambroiseodt/tsim",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1+2",
        "aff_unique_norm": "Huawei;Ecole des Ponts ParisTech;\u00c9cole Normale Sup\u00e9rieure Paris-Saclay",
        "aff_unique_dep": "Noah\u2019s Ark Lab;;",
        "aff_unique_url": "https://www.huawei.com;https://www.ponts.org;https://www.ensparis-saclay.fr",
        "aff_unique_abbr": "Huawei;ENPC;ENS Paris-Saclay",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris-Saclay",
        "aff_country_unique_index": "0;0;0+1+1",
        "aff_country_unique": "China;France"
    },
    {
        "id": "9a8eed7eb1",
        "title": "Leveraging PAC-Bayes Theory and Gibbs Distributions for Generalization Bounds with Complexity Measures",
        "site": "https://proceedings.mlr.press/v238/viallard24a.html",
        "author": "Paul Viallard; R\u00e9mi Emonet; Amaury Habrard; Emilie Morvant; Valentina Zantedeschi",
        "abstract": "In statistical learning theory, a generalization bound usually involves a complexity measure imposed by the considered theoretical framework. This limits the scope of such bounds, as other forms of capacity measures or regularizations are used in algorithms. In this paper, we leverage the framework of disintegrated PAC-Bayes bounds to derive a general generalization bound instantiable with arbitrary complexity measures. One trick to prove such a result involves considering a commonly used family of distributions: the Gibbs distributions. Our bound stands in probability jointly over the hypothesis and the learning sample, which allows the complexity to be adapted to the generalization gap as it can be customized to fit both the hypothesis class and the task.",
        "bibtex": "@InProceedings{pmlr-v238-viallard24a,\n  title = \t {Leveraging {PAC}-{B}ayes Theory and {G}ibbs Distributions for Generalization Bounds with Complexity Measures},\n  author =       {Viallard, Paul and Emonet, R\\'{e}mi and Habrard, Amaury and Morvant, Emilie and Zantedeschi, Valentina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3007--3015},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/viallard24a/viallard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/viallard24a.html},\n  abstract = \t {In statistical learning theory, a generalization bound usually involves a complexity measure imposed by the considered theoretical framework. This limits the scope of such bounds, as other forms of capacity measures or regularizations are used in algorithms. In this paper, we leverage the framework of disintegrated PAC-Bayes bounds to derive a general generalization bound instantiable with arbitrary complexity measures. One trick to prove such a result involves considering a commonly used family of distributions: the Gibbs distributions. Our bound stands in probability jointly over the hypothesis and the learning sample, which allows the complexity to be adapted to the generalization gap as it can be customized to fit both the hypothesis class and the task.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/viallard24a/viallard24a.pdf",
        "supp": "",
        "pdf_size": 872436,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6059322164921709214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Univ Rennes, Inria, CNRS IRISA - UMR 6074, F35000 Rennes, France; Universit\u00b4e Jean Monnet Saint-Etienne, CNRS, Institut d Optique Graduate School, Inria\u22c4, Laboratoire Hubert Curien UMR 5516, F-42023, SAINT-ETIENNE, FRANCE+Institut Universitaire de France (IUF); Universit\u00b4e Jean Monnet Saint-Etienne, CNRS, Institut d Optique Graduate School, Inria\u22c4, Laboratoire Hubert Curien UMR 5516, F-42023, SAINT-ETIENNE, FRANCE+Institut Universitaire de France (IUF); Universit\u00b4e Jean Monnet Saint-Etienne, CNRS, Institut d Optique Graduate School, Inria\u22c4, Laboratoire Hubert Curien UMR 5516, F-42023, SAINT-ETIENNE, FRANCE; ServiceNow Research",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;1+2;1;3",
        "aff_unique_norm": "University of Rennes;Universit\u00b4e Jean Monnet Saint-Etienne;Institut Universitaire de France;ServiceNow",
        "aff_unique_dep": "Inria, CNRS IRISA - UMR 6074;;;Research",
        "aff_unique_url": "https://www.univ-rennes1.fr;https://www.univ-st-etienne.fr;https://www.iuf.cnrs.fr;https://www.servicenow.com",
        "aff_unique_abbr": "Univ Rennes;UJM;IUF;ServiceNow",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Rennes;Saint-Etienne;",
        "aff_country_unique_index": "0;0+0;0+0;0;1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "894705ffcb",
        "title": "Lexicographic Optimization: Algorithms and Stability",
        "site": "https://proceedings.mlr.press/v238/abernethy24a.html",
        "author": "Jacob A. Abernethy; Robert Schapire; Umar Syed",
        "abstract": "A lexicographic maximum of a set $X \\subseteq R^n$ is a vector in $X$ whose smallest component is as large as possible, and subject to that requirement, whose second smallest component is as large as possible, and so on for the third smallest component, etc. Lexicographic maximization has numerous practical and theoretical applications, including fair resource allocation, analyzing the implicit regularization of learning algorithms, and characterizing refinements of game-theoretic equilibria. We prove that a minimizer in $X$ of the exponential loss function $L_c(x) = \\sum_i \\exp(-c x_i)$ converges to a lexicographic maximum of $X$ as $c \\to \\infty$, provided that $X$ is \\emph{stable} in the sense that a well-known iterative method for finding a lexicographic maximum of $X$ cannot be made to fail simply by reducing the required quality of each iterate by an arbitrarily tiny degree. Our result holds for both near and exact minimizers of the exponential loss, while earlier convergence results made much stronger assumptions about the set $X$ and only held for the exact minimizer. We are aware of no previous results showing a connection between the iterative method for computing a lexicographic maximum and exponential loss minimization. We show that every convex polytope is stable, but that there exist compact, convex sets that are not stable. We also provide the first analysis of the convergence rate of an exponential loss minimizer (near or exact) and discover a curious dichotomy: While the two smallest components of the vector converge to the lexicographically maximum values very quickly (at roughly the rate $\\frac{\\log n}{c}$), all other components can converge arbitrarily slowly.",
        "bibtex": "@InProceedings{pmlr-v238-abernethy24a,\n  title = \t {Lexicographic Optimization: Algorithms and Stability},\n  author =       {Abernethy, Jacob A. and Schapire, Robert and Syed, Umar},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2503--2511},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/abernethy24a/abernethy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/abernethy24a.html},\n  abstract = \t {A lexicographic maximum of a set $X \\subseteq R^n$ is a vector in $X$ whose smallest component is as large as possible, and subject to that requirement, whose second smallest component is as large as possible, and so on for the third smallest component, etc. Lexicographic maximization has numerous practical and theoretical applications, including fair resource allocation, analyzing the implicit regularization of learning algorithms, and characterizing refinements of game-theoretic equilibria. We prove that a minimizer in $X$ of the exponential loss function $L_c(x) = \\sum_i \\exp(-c x_i)$ converges to a lexicographic maximum of $X$ as $c \\to \\infty$, provided that $X$ is \\emph{stable} in the sense that a well-known iterative method for finding a lexicographic maximum of $X$ cannot be made to fail simply by reducing the required quality of each iterate by an arbitrarily tiny degree. Our result holds for both near and exact minimizers of the exponential loss, while earlier convergence results made much stronger assumptions about the set $X$ and only held for the exact minimizer. We are aware of no previous results showing a connection between the iterative method for computing a lexicographic maximum and exponential loss minimization. We show that every convex polytope is stable, but that there exist compact, convex sets that are not stable. We also provide the first analysis of the convergence rate of an exponential loss minimizer (near or exact) and discover a curious dichotomy: While the two smallest components of the vector converge to the lexicographically maximum values very quickly (at roughly the rate $\\frac{\\log n}{c}$), all other components can converge arbitrarily slowly.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/abernethy24a/abernethy24a.pdf",
        "supp": "",
        "pdf_size": 337171,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17347734923445295699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "25392246a7",
        "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?",
        "site": "https://proceedings.mlr.press/v238/kim24a.html",
        "author": "Kyurae Kim; Yian Ma; Jacob Gardner",
        "abstract": "We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called \u201clinear\u201d) rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. For the projection operator, we consider a domain with triangular scale matrices, which the projection onto is computable in $\\theta(d)$ time, where $d$ is the dimensionality of the target posterior. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator, providing explicit non-asymptotic complexity guarantees for both.",
        "bibtex": "@InProceedings{pmlr-v238-kim24a,\n  title = \t {Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?},\n  author =       {Kim, Kyurae and Ma, Yian and Gardner, Jacob},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {235--243},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kim24a/kim24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kim24a.html},\n  abstract = \t {We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called \u201clinear\u201d) rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. For the projection operator, we consider a domain with triangular scale matrices, which the projection onto is computable in $\\theta(d)$ time, where $d$ is the dimensionality of the target posterior. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator, providing explicit non-asymptotic complexity guarantees for both.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kim24a/kim24a.pdf",
        "supp": "",
        "pdf_size": 679472,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18086756706970079524&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "682b2ccba8",
        "title": "Local Causal Discovery with Linear non-Gaussian Cyclic Models",
        "site": "https://proceedings.mlr.press/v238/dai24a.html",
        "author": "Haoyue Dai; Ignavier Ng; Yujia Zheng; Zhengqing Gao; Kun Zhang",
        "abstract": "Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-dai24a,\n  title = \t {Local Causal Discovery with Linear non-{G}aussian Cyclic Models},\n  author =       {Dai, Haoyue and Ng, Ignavier and Zheng, Yujia and Gao, Zhengqing and Zhang, Kun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {154--162},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dai24a/dai24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dai24a.html},\n  abstract = \t {Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dai24a/dai24a.pdf",
        "supp": "",
        "pdf_size": 1916813,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8059344646897925726&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Mohamed bin Zayed University of Artificial Intelligence; Carnegie Mellon University+Mohamed bin Zayed University of Artificial Intelligence",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0+1",
        "aff_unique_norm": "Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://mbzuai.ac.ae",
        "aff_unique_abbr": "CMU;MBZUAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0+1",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "96f0e38102",
        "title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v238/adachi24a.html",
        "author": "Masaki Adachi; Brady Planden; David Howey; Michael A. Osborne; Sebastian Orbell; Natalia Ares; Krikamol Muandet; Siu Lun Chau",
        "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO\u2019s efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available https://github.com/ma921/CoExBO.",
        "bibtex": "@InProceedings{pmlr-v238-adachi24a,\n  title = \t {Looping in the Human: Collaborative and Explainable {B}ayesian Optimization},\n  author =       {Adachi, Masaki and Planden, Brady and Howey, David and A. Osborne, Michael and Orbell, Sebastian and Ares, Natalia and Muandet, Krikamol and Lun Chau, Siu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {505--513},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/adachi24a/adachi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/adachi24a.html},\n  abstract = \t {Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO\u2019s efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available https://github.com/ma921/CoExBO.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/adachi24a/adachi24a.pdf",
        "supp": "",
        "pdf_size": 11715287,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6255003152888427578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Machine Learning Research Group, University of Oxford; Department of engineering Science, University of Oxford + Toyota Motor Corporation; Department of engineering Science, University of Oxford + The Faraday Institution; Machine Learning Research Group, University of Oxford + Department of engineering Science, University of Oxford; Department of engineering Science, University of Oxford; Department of engineering Science, University of Oxford; CISPA Helmholtz Center for Information Security; CISPA Helmholtz Center for Information Security",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "https://github.com/ma921/CoExBO",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0+2;0+0;0;0;3;3",
        "aff_unique_norm": "University of Oxford;Toyota Motor Corporation;Faraday Institution;CISPA Helmholtz Center for Information Security",
        "aff_unique_dep": "Machine Learning Research Group;;;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.toyota-global.com;https://www.faraday.ac.uk;https://www.cispa.de/",
        "aff_unique_abbr": "Oxford;Toyota;Faraday Inst;CISPA",
        "aff_campus_unique_index": "0;0;0;0+0;0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;0+1;0+0;0+0;0;0;2;2",
        "aff_country_unique": "United Kingdom;Japan;Germany"
    },
    {
        "id": "6f0f9699f5",
        "title": "Low-rank MDPs with Continuous Action Spaces",
        "site": "https://proceedings.mlr.press/v238/oprescu24a.html",
        "author": "Miruna Oprescu; Andrew Bennett; Nathan Kallus",
        "abstract": "Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\\mathcal{A}| \\to \\infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain a similar PAC bound when actions are allowed to be continuous. Specifically, when the model for transition functions satisfies a H\u00f6lder smoothness condition w.r.t. actions, and either the policy class has a uniformly bounded minimum density or the reward function is also H\u00f6lder smooth, we obtain a polynomial PAC bound that depends on the order of smoothness.",
        "bibtex": "@InProceedings{pmlr-v238-oprescu24a,\n  title = \t {Low-rank {MDPs} with Continuous Action Spaces},\n  author =       {Oprescu, Miruna and Bennett, Andrew and Kallus, Nathan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4069--4077},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/oprescu24a/oprescu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/oprescu24a.html},\n  abstract = \t {Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\\mathcal{A}| \\to \\infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain a similar PAC bound when actions are allowed to be continuous. Specifically, when the model for transition functions satisfies a H\u00f6lder smoothness condition w.r.t. actions, and either the policy class has a uniformly bounded minimum density or the reward function is also H\u00f6lder smooth, we obtain a polynomial PAC bound that depends on the order of smoothness.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/oprescu24a/oprescu24a.pdf",
        "supp": "",
        "pdf_size": 487072,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6654348968503731858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Morgan Stanley; Cornell Tech; Cornell Tech",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Morgan Stanley;Cornell University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.morganstanley.com;https://tech.cornell.edu",
        "aff_unique_abbr": "Morgan Stanley;Cornell Tech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";New York City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f59274b3d4",
        "title": "Lower-level Duality Based Reformulation and Majorization Minimization Algorithm for Hyperparameter Optimization",
        "site": "https://proceedings.mlr.press/v238/chen24a.html",
        "author": "He Chen; Haochen Xu; Rujun Jiang; Anthony Man-Cho So",
        "abstract": "Hyperparameter tuning is an important task of machine learning, which can be formulated as a bilevel program (BLP). However, most existing algorithms are not applicable for BLP with non-smooth lower-level problems. To address this, we propose a single-level reformulation of the BLP based on lower-level duality without involving any implicit value function. To solve the reformulation, we propose a majorization minimization algorithm that marjorizes the constraint in each iteration. Furthermore, we show that the subproblems of the proposed algorithm for several widely-used hyperparameter turning models can be reformulated into conic programs that can be efficiently solved by the off-the-shelf solvers. We theoretically prove the convergence of the proposed algorithm and demonstrate its superiority through numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-chen24a,\n  title = \t {Lower-level Duality Based Reformulation and Majorization Minimization Algorithm for Hyperparameter Optimization},\n  author =       {Chen, He and Xu, Haochen and Jiang, Rujun and Man-Cho So, Anthony},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {784--792},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24a/chen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24a.html},\n  abstract = \t {Hyperparameter tuning is an important task of machine learning, which can be formulated as a bilevel program (BLP). However, most existing algorithms are not applicable for BLP with non-smooth lower-level problems. To address this, we propose a single-level reformulation of the BLP based on lower-level duality without involving any implicit value function. To solve the reformulation, we propose a majorization minimization algorithm that marjorizes the constraint in each iteration. Furthermore, we show that the subproblems of the proposed algorithm for several widely-used hyperparameter turning models can be reformulated into conic programs that can be efficiently solved by the off-the-shelf solvers. We theoretically prove the convergence of the proposed algorithm and demonstrate its superiority through numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24a/chen24a.pdf",
        "supp": "",
        "pdf_size": 793931,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11247120782171681362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c31bd35825",
        "title": "MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization",
        "site": "https://proceedings.mlr.press/v238/hoang-khoi-do24a.html",
        "author": "Nguyen Hoang Khoi Do; Tanmoy Chowdhury; Chen Ling; Liang Zhao; My T. Thai",
        "abstract": "Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as well as conduct extensive analyses on both synthetic and real-world datasets to validate our MIM-Reasoner\u2019s performance.",
        "bibtex": "@InProceedings{pmlr-v238-hoang-khoi-do24a,\n  title = \t {MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization},\n  author =       {Hoang Khoi Do, Nguyen and Chowdhury, Tanmoy and Ling, Chen and Zhao, Liang and T. Thai, My},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2296--2304},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hoang-khoi-do24a/hoang-khoi-do24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hoang-khoi-do24a.html},\n  abstract = \t {Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as well as conduct extensive analyses on both synthetic and real-world datasets to validate our MIM-Reasoner\u2019s performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hoang-khoi-do24a/hoang-khoi-do24a.pdf",
        "supp": "",
        "pdf_size": 10585070,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2364326032580924865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Posts and Telecommunications Institute of Technology, Ha Noi, Viet Nam; Emory University, Atlanta, USA; Emory University, Atlanta, USA; Emory University, Atlanta, USA; University of Florida, Gainesville, USA",
        "aff_domain": "ptit.edu.vn;emory.edu;emory.edu;emory.edu;cise.ufl.edu",
        "email": "ptit.edu.vn;emory.edu;emory.edu;emory.edu;cise.ufl.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Posts and Telecommunications Institute of Technology;Emory University;University of Florida",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.emory.edu;https://www.ufl.edu",
        "aff_unique_abbr": ";Emory;UF",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Ha Noi;Atlanta;Gainesville",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Vietnam;United States"
    },
    {
        "id": "25993eddbe",
        "title": "MINTY: Rule-based models that minimize the need for imputing features with missing values",
        "site": "https://proceedings.mlr.press/v238/stempfle24a.html",
        "author": "Lena Stempfle; Fredrik Johansson",
        "abstract": "Rule models are often preferred in prediction tasks with tabular inputs as they can be easily interpreted using natural language and provide predictive performance on par with more complex models. However, most rule models\u2019 predictions are undefined or ambiguous when some inputs are missing, forcing users to rely on statistical imputation models or heuristics like zero imputation, undermining the interpretability of the models. In this work, we propose fitting concise yet precise rule models that learn to avoid relying on features with missing values and, therefore, limit their reliance on imputation at test time. We develop MINTY, a method that learns rules in the form of disjunctions between variables that act as replacements for each other when one or more is missing. This results in a sparse linear rule model, regularized to have small dependence on features with missing values, that allows a trade-off between goodness of fit, interpretability, and robustness to missing values at test time. We demonstrate the value of MINTY in experiments using synthetic and real-world data sets and find its predictive performance comparable or favorable to baselines, with smaller reliance on features with missing values.",
        "bibtex": "@InProceedings{pmlr-v238-stempfle24a,\n  title = \t {{MINTY}: Rule-based models that minimize the need for imputing features with missing values},\n  author =       {Stempfle, Lena and Johansson, Fredrik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {964--972},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/stempfle24a/stempfle24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/stempfle24a.html},\n  abstract = \t {Rule models are often preferred in prediction tasks with tabular inputs as they can be easily interpreted using natural language and provide predictive performance on par with more complex models. However, most rule models\u2019 predictions are undefined or ambiguous when some inputs are missing, forcing users to rely on statistical imputation models or heuristics like zero imputation, undermining the interpretability of the models. In this work, we propose fitting concise yet precise rule models that learn to avoid relying on features with missing values and, therefore, limit their reliance on imputation at test time. We develop MINTY, a method that learns rules in the form of disjunctions between variables that act as replacements for each other when one or more is missing. This results in a sparse linear rule model, regularized to have small dependence on features with missing values, that allows a trade-off between goodness of fit, interpretability, and robustness to missing values at test time. We demonstrate the value of MINTY in experiments using synthetic and real-world data sets and find its predictive performance comparable or favorable to baselines, with smaller reliance on features with missing values.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/stempfle24a/stempfle24a.pdf",
        "supp": "",
        "pdf_size": 564287,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1219633105291621302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Computer Science & Engineering, Chalmers University of Technology; Computer Science & Engineering, Chalmers University of Technology",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chalmers University of Technology",
        "aff_unique_dep": "Computer Science & Engineering",
        "aff_unique_url": "https://www.chalmers.se",
        "aff_unique_abbr": "Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "6bdf2452b2",
        "title": "MMD-based Variable Importance for Distributional Random Forest",
        "site": "https://proceedings.mlr.press/v238/benard24a.html",
        "author": "Cl\u00e9ment B\u00e9nard; Jeffrey N\u00e4f; Julie Josse",
        "abstract": "Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions.",
        "bibtex": "@InProceedings{pmlr-v238-benard24a,\n  title = \t {{MMD}-based Variable Importance for Distributional Random Forest},\n  author =       {B\\'{e}nard, Cl\\'{e}ment and N\\\"{a}f, Jeffrey and Josse, Julie},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1324--1332},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/benard24a/benard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/benard24a.html},\n  abstract = \t {Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/benard24a/benard24a.pdf",
        "supp": "",
        "pdf_size": 1342261,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1919683922107887337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "12505c6d4a",
        "title": "Making Better Use of Unlabelled Data in Bayesian Active Learning",
        "site": "https://proceedings.mlr.press/v238/bickford-smith24a.html",
        "author": "Freddie Bickford Smith; Adam Foster; Tom Rainforth",
        "abstract": "Fully supervised models are predominant in Bayesian active learning. We argue that their neglect of the information present in unlabelled data harms not just predictive performance but also decisions about what data to acquire. Our proposed solution is a simple framework for semi-supervised Bayesian active learning. We find it produces better-performing models than either conventional Bayesian active learning or semi-supervised learning with randomly acquired data. It is also easier to scale up than the conventional approach. As well as supporting a shift towards semi-supervised models, our findings highlight the importance of studying models and acquisition methods in conjunction.",
        "bibtex": "@InProceedings{pmlr-v238-bickford-smith24a,\n  title = \t {Making Better Use of Unlabelled Data in {B}ayesian Active Learning},\n  author =       {Bickford Smith, Freddie and Foster, Adam and Rainforth, Tom},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {847--855},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bickford-smith24a/bickford-smith24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bickford-smith24a.html},\n  abstract = \t {Fully supervised models are predominant in Bayesian active learning. We argue that their neglect of the information present in unlabelled data harms not just predictive performance but also decisions about what data to acquire. Our proposed solution is a simple framework for semi-supervised Bayesian active learning. We find it produces better-performing models than either conventional Bayesian active learning or semi-supervised learning with randomly acquired data. It is also easier to scale up than the conventional approach. As well as supporting a shift towards semi-supervised models, our findings highlight the importance of studying models and acquisition methods in conjunction.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bickford-smith24a/bickford-smith24a.pdf",
        "supp": "",
        "pdf_size": 3325269,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6936411490562727636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "14c31dd8b4",
        "title": "Manifold-Aligned Counterfactual Explanations for Neural Networks",
        "site": "https://proceedings.mlr.press/v238/tsiourvas24a.html",
        "author": "Asterios Tsiourvas; Wei Sun; Georgia Perakis",
        "abstract": "We study the problem of finding optimal manifold-aligned counterfactual explanations for neural networks. Existing approaches that involve solving a complex mixed-integer optimization (MIP) problem frequently suffer from scalability issues, limiting their practical usefulness. Furthermore, the solutions are not guaranteed to follow the data manifold, resulting in unrealistic counterfactual explanations. To address these challenges, we first present a MIP formulation where we explicitly enforce manifold alignment by reformulating the highly nonlinear Local Outlier Factor (LOF) metric as mixed-integer constraints. To address the computational challenge, we leverage the geometry of a trained neural network and propose an efficient decomposition scheme that reduces the initial large, hard-to-solve optimization problem into a series of significantly smaller, easier-to-solve problems by constraining the search space to \u201clive\u201d polytopes, i.e., regions that contain at least one actual data point. Experiments on real-world datasets demonstrate the efficacy of our approach in producing both optimal and realistic counterfactual explanations, and computational traceability.",
        "bibtex": "@InProceedings{pmlr-v238-tsiourvas24a,\n  title = \t {Manifold-Aligned Counterfactual Explanations for Neural Networks},\n  author =       {Tsiourvas, Asterios and Sun, Wei and Perakis, Georgia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3763--3771},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tsiourvas24a/tsiourvas24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tsiourvas24a.html},\n  abstract = \t {We study the problem of finding optimal manifold-aligned counterfactual explanations for neural networks. Existing approaches that involve solving a complex mixed-integer optimization (MIP) problem frequently suffer from scalability issues, limiting their practical usefulness. Furthermore, the solutions are not guaranteed to follow the data manifold, resulting in unrealistic counterfactual explanations. To address these challenges, we first present a MIP formulation where we explicitly enforce manifold alignment by reformulating the highly nonlinear Local Outlier Factor (LOF) metric as mixed-integer constraints. To address the computational challenge, we leverage the geometry of a trained neural network and propose an efficient decomposition scheme that reduces the initial large, hard-to-solve optimization problem into a series of significantly smaller, easier-to-solve problems by constraining the search space to \u201clive\u201d polytopes, i.e., regions that contain at least one actual data point. Experiments on real-world datasets demonstrate the efficacy of our approach in producing both optimal and realistic counterfactual explanations, and computational traceability.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tsiourvas24a/tsiourvas24a.pdf",
        "supp": "",
        "pdf_size": 1488390,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2667252454166872157&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "MIT; IBM Research; MIT",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/asterios-tsiourvas/relu_cfx",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;IBM",
        "aff_unique_dep": ";IBM Research",
        "aff_unique_url": "https://web.mit.edu;https://www.ibm.com/research",
        "aff_unique_abbr": "MIT;IBM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "85794c6ccb",
        "title": "Maximum entropy GFlowNets with soft Q-learning",
        "site": "https://proceedings.mlr.press/v238/mohammadpour24a.html",
        "author": "Sobhan Mohammadpour; Emmanuel Bengio; Emma Frejinger; Pierre-Luc Bacon",
        "abstract": "Generative Flow Networks (GFNs) have emerged as a powerful tool for sampling discrete objects from unnormalized distributions, offering a scalable alternative to Markov Chain Monte Carlo (MCMC) methods. While GFNs draw inspiration from maximum entropy reinforcement learning (RL), the connection between the two has largely been unclear and seemingly applicable only in specific cases. This paper addresses the connection by constructing an appropriate reward function, thereby establishing an exact relationship between GFNs and maximum entropy RL. This construction allows us to introduce maximum entropy GFNs, which achieve the maximum entropy attainable by GFNs without constraints on the state space, in contrast to GFNs with uniform backward policy.",
        "bibtex": "@InProceedings{pmlr-v238-mohammadpour24a,\n  title = \t {Maximum entropy {GFlowNets} with soft {Q}-learning},\n  author =       {Mohammadpour, Sobhan and Bengio, Emmanuel and Frejinger, Emma and Bacon, Pierre-Luc},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2593--2601},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mohammadpour24a/mohammadpour24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mohammadpour24a.html},\n  abstract = \t {Generative Flow Networks (GFNs) have emerged as a powerful tool for sampling discrete objects from unnormalized distributions, offering a scalable alternative to Markov Chain Monte Carlo (MCMC) methods. While GFNs draw inspiration from maximum entropy reinforcement learning (RL), the connection between the two has largely been unclear and seemingly applicable only in specific cases. This paper addresses the connection by constructing an appropriate reward function, thereby establishing an exact relationship between GFNs and maximum entropy RL. This construction allows us to introduce maximum entropy GFNs, which achieve the maximum entropy attainable by GFNs without constraints on the state space, in contrast to GFNs with uniform backward policy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mohammadpour24a/mohammadpour24a.pdf",
        "supp": "",
        "pdf_size": 1514043,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2908088054133849336&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a7a92ec65d",
        "title": "Mechanics of Next Token Prediction with Self-Attention",
        "site": "https://proceedings.mlr.press/v238/li24f.html",
        "author": "Yingcong Li; Yixiao Huang; Muhammed E. Ildiz; Ankit Singh Rawat; Samet Oymak",
        "abstract": "Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: What does a single self-attention layer learn from next-token prediction? We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: (1) Hard retrieval: Given input sequence, self-attention precisely selects the high-priority input tokens associated with the last input token. (2) Soft composition: It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures.",
        "bibtex": "@InProceedings{pmlr-v238-li24f,\n  title = \t {Mechanics of Next Token Prediction with Self-Attention},\n  author =       {Li, Yingcong and Huang, Yixiao and Ildiz, Muhammed E. and Singh Rawat, Ankit and Oymak, Samet},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {685--693},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24f/li24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24f.html},\n  abstract = \t {Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: What does a single self-attention layer learn from next-token prediction? We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: (1) Hard retrieval: Given input sequence, self-attention precisely selects the high-priority input tokens associated with the last input token. (2) Soft composition: It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24f/li24f.pdf",
        "supp": "",
        "pdf_size": 1552957,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11464634687168603876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; Google Research NYC; University of Michigan, Ann Arbor",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Michigan;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.umich.edu;https://research.google",
        "aff_unique_abbr": "UM;Google Research",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Ann Arbor;New York City",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9df2e04e66",
        "title": "Membership Testing in Markov Equivalence Classes via Independence Queries",
        "site": "https://proceedings.mlr.press/v238/zhang24k.html",
        "author": "Jiaqi Zhang; Kirankumar Shiragur; Caroline Uhler",
        "abstract": "Understanding causal relationships between variables is a fundamental problem with broad impact in numerous scientific fields. While extensive research has been dedicated to \\emph{learning} causal graphs from data, its complementary concept of \\emph{testing} causal relationships has remained largely unexplored. While \\emph{learning} involves the task of recovering the Markov equivalence class (MEC) of the underlying causal graph from observational data, the \\emph{testing} counterpart addresses the following critical question: \\emph{Given a specific MEC and observational data from some causal graph, can we determine if the data-generating causal graph belongs to the given MEC?} We explore constraint-based testing methods by establishing bounds on the required number of conditional independence tests. Our bounds are in terms of the size of the maximum undirected clique ($s$) of the given MEC. In the worst case, we show a lower bound of $\\exp(\\Omega(s))$ independence tests. We then give an algorithm that resolves the task with $\\exp(O(s))$ tests, matching our lower bound. Compared to the \\emph{learning} problem, where algorithms often use a number of independence tests that is exponential in the maximum in-degree, this shows that \\emph{testing} is relatively easier. In particular, it requires exponentially less independence tests in graphs featuring high in-degrees and small clique sizes. Additionally, using the DAG associahedron, we provide a geometric interpretation of testing versus learning and discuss how our testing result can aid learning.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24k,\n  title = \t {Membership Testing in {M}arkov Equivalence Classes via Independence Queries},\n  author =       {Zhang, Jiaqi and Shiragur, Kirankumar and Uhler, Caroline},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3925--3933},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24k/zhang24k.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24k.html},\n  abstract = \t {Understanding causal relationships between variables is a fundamental problem with broad impact in numerous scientific fields. While extensive research has been dedicated to \\emph{learning} causal graphs from data, its complementary concept of \\emph{testing} causal relationships has remained largely unexplored. While \\emph{learning} involves the task of recovering the Markov equivalence class (MEC) of the underlying causal graph from observational data, the \\emph{testing} counterpart addresses the following critical question: \\emph{Given a specific MEC and observational data from some causal graph, can we determine if the data-generating causal graph belongs to the given MEC?} We explore constraint-based testing methods by establishing bounds on the required number of conditional independence tests. Our bounds are in terms of the size of the maximum undirected clique ($s$) of the given MEC. In the worst case, we show a lower bound of $\\exp(\\Omega(s))$ independence tests. We then give an algorithm that resolves the task with $\\exp(O(s))$ tests, matching our lower bound. Compared to the \\emph{learning} problem, where algorithms often use a number of independence tests that is exponential in the maximum in-degree, this shows that \\emph{testing} is relatively easier. In particular, it requires exponentially less independence tests in graphs featuring high in-degrees and small clique sizes. Additionally, using the DAG associahedron, we provide a geometric interpretation of testing versus learning and discuss how our testing result can aid learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24k/zhang24k.pdf",
        "supp": "",
        "pdf_size": 1472828,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6820016660236171495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "LIDS, MIT, and Broad Institute; Eric and Wendy Schmidt Center, Broad Institute; LIDS, MIT, and Broad Institute",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Broad Institute",
        "aff_unique_dep": "Laboratory for Information and Decision Systems;Eric and Wendy Schmidt Center",
        "aff_unique_url": "https://web.mit.edu;https://www.broadinstitute.org",
        "aff_unique_abbr": "MIT;Broad",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d9eefa210f",
        "title": "Meta Learning in Bandits within shared affine Subspaces",
        "site": "https://proceedings.mlr.press/v238/bilaj24a.html",
        "author": "Steven Bilaj; Sofien Dhouib; Setareh Maghsudi",
        "abstract": "We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks.",
        "bibtex": "@InProceedings{pmlr-v238-bilaj24a,\n  title = \t {Meta Learning in Bandits within shared affine Subspaces},\n  author =       {Bilaj, Steven and Dhouib, Sofien and Maghsudi, Setareh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {523--531},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/bilaj24a/bilaj24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/bilaj24a.html},\n  abstract = \t {We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/bilaj24a/bilaj24a.pdf",
        "supp": "",
        "pdf_size": 730600,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9596927312333922063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b5ddc52fcb",
        "title": "Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors",
        "site": "https://proceedings.mlr.press/v238/rudner24a.html",
        "author": "Tim G. J. Rudner; Ya Shi Zhang; Andrew Gordon Wilson; Julia Kempe",
        "abstract": "Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance\u2014even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts.",
        "bibtex": "@InProceedings{pmlr-v238-rudner24a,\n  title = \t {Mind the {GAP}: Improving Robustness to Subpopulation Shifts with Group-Aware Priors},\n  author =       {Rudner, Tim G. J. and Shi Zhang, Ya and Wilson, Andrew Gordon and Kempe, Julia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {127--135},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rudner24a/rudner24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rudner24a.html},\n  abstract = \t {Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance\u2014even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rudner24a/rudner24a.pdf",
        "supp": "",
        "pdf_size": 958234,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9284109921929094966&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fab3ab09b5",
        "title": "Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles",
        "site": "https://proceedings.mlr.press/v238/scaman24a.html",
        "author": "Kevin Scaman; Mathieu Even; Batiste Le Bars; Laurent Massoulie",
        "abstract": "In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.",
        "bibtex": "@InProceedings{pmlr-v238-scaman24a,\n  title = \t {Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles},\n  author =       {Scaman, Kevin and Even, Mathieu and Le Bars, Batiste and Massoulie, Laurent},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3709--3717},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/scaman24a/scaman24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/scaman24a.html},\n  abstract = \t {In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/scaman24a/scaman24a.pdf",
        "supp": "",
        "pdf_size": 514902,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3335419203275818278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e5d43130ca",
        "title": "Minimax optimal density estimation using a shallow generative model with a one-dimensional latent variable",
        "site": "https://proceedings.mlr.press/v238/kyu-kwon24a.html",
        "author": "Hyeok Kyu Kwon; Minwoo Chae",
        "abstract": "A deep generative model yields an implicit estimator for the unknown distribution or density function of the observation. This paper investigates some statistical properties of the implicit density estimator pursued by VAE-type methods from a nonparametric density estimation framework. More specifically, we obtain convergence rates of the VAE-type density estimator under the assumption that the underlying true density function belongs to a locally Holder class. Remarkably, a near minimax optimal rate with respect to the Hellinger metric can be achieved by the simplest network architecture, a shallow generative model with a one-dimensional latent variable.",
        "bibtex": "@InProceedings{pmlr-v238-kyu-kwon24a,\n  title = \t {Minimax optimal density estimation using a shallow generative model with a one-dimensional latent variable},\n  author =       {Kwon, Hyeok Kyu and Chae, Minwoo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {469--477},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kyu-kwon24a/kyu-kwon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kyu-kwon24a.html},\n  abstract = \t {A deep generative model yields an implicit estimator for the unknown distribution or density function of the observation. This paper investigates some statistical properties of the implicit density estimator pursued by VAE-type methods from a nonparametric density estimation framework. More specifically, we obtain convergence rates of the VAE-type density estimator under the assumption that the underlying true density function belongs to a locally Holder class. Remarkably, a near minimax optimal rate with respect to the Hellinger metric can be achieved by the simplest network architecture, a shallow generative model with a one-dimensional latent variable.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kyu-kwon24a/kyu-kwon24a.pdf",
        "supp": "",
        "pdf_size": 1053338,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8354332600070658326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Industrial and Management Engineering, Pohang University of Science and Technology; Department of Industrial and Management Engineering, Pohang University of Science and Technology",
        "aff_domain": ";postech.ac.kr",
        "email": ";postech.ac.kr",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Industrial and Management Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "c44ffb2ae9",
        "title": "Minimizing Convex Functionals over Space of Probability Measures via KL Divergence Gradient Flow",
        "site": "https://proceedings.mlr.press/v238/yao24a.html",
        "author": "Rentian Yao; Linjun Huang; Yun Yang",
        "abstract": "Motivated by the computation of the non-parametric maximum likelihood estimator (NPMLE) and the Bayesian posterior in statistics, this paper explores the problem of convex optimization over the space of all probability distributions. We introduce an implicit scheme, called the implicit KL proximal descent (IKLPD) algorithm, for discretizing a continuous-time gradient flow relative to the Kullback\u2013Leibler (KL) divergence for minimizing a convex target functional. We show that IKLPD converges to a global optimum at a polynomial rate from any initialization; moreover, if the objective functional is strongly convex relative to the KL divergence, for example, when the target functional itself is a KL divergence as in the context of Bayesian posterior computation, IKLPD exhibits globally exponential convergence. Computationally, we propose a numerical method based on normalizing flow to realize IKLPD. Conversely, our numerical method can also be viewed as a new approach that sequentially trains a normalizing flow for minimizing a convex functional with a strong theoretical guarantee.",
        "bibtex": "@InProceedings{pmlr-v238-yao24a,\n  title = \t {Minimizing Convex Functionals over Space of Probability Measures via {KL} Divergence Gradient Flow},\n  author =       {Yao, Rentian and Huang, Linjun and Yang, Yun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2530--2538},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yao24a/yao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yao24a.html},\n  abstract = \t {Motivated by the computation of the non-parametric maximum likelihood estimator (NPMLE) and the Bayesian posterior in statistics, this paper explores the problem of convex optimization over the space of all probability distributions. We introduce an implicit scheme, called the implicit KL proximal descent (IKLPD) algorithm, for discretizing a continuous-time gradient flow relative to the Kullback\u2013Leibler (KL) divergence for minimizing a convex target functional. We show that IKLPD converges to a global optimum at a polynomial rate from any initialization; moreover, if the objective functional is strongly convex relative to the KL divergence, for example, when the target functional itself is a KL divergence as in the context of Bayesian posterior computation, IKLPD exhibits globally exponential convergence. Computationally, we propose a numerical method based on normalizing flow to realize IKLPD. Conversely, our numerical method can also be viewed as a new approach that sequentially trains a normalizing flow for minimizing a convex functional with a strong theoretical guarantee.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yao24a/yao24a.pdf",
        "supp": "",
        "pdf_size": 1748247,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7120003528850873723&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "78a54f8f0c",
        "title": "Mitigating Underfitting in Learning to Defer with Consistent Losses",
        "site": "https://proceedings.mlr.press/v238/liu24h.html",
        "author": "Shuqi Liu; Yuzhou Cao; Qiaozhen Zhang; Lei Feng; Bo An",
        "abstract": "Learning to defer (L2D) allows the classifier to defer its prediction to an expert for safer predictions, by balancing the system\u2019s accuracy and extra costs incurred by consulting the expert. Various loss functions have been proposed for L2D, but they were shown to cause the underfitting of trained classifiers when extra consulting costs exist, resulting in degraded performance. In this paper, we propose a novel loss formulation that can mitigate the underfitting issue while remaining the statistical consistency. We first show that our formulation can avoid a common characteristic shared by most existing losses, which has been shown to be a cause of underfitting, and show that it can be combined with the representative losses for L2D to enhance their performance and yield consistent losses. We further study the regret transfer bounds of the proposed losses and experimentally validate its improvements over existing methods.",
        "bibtex": "@InProceedings{pmlr-v238-liu24h,\n  title = \t {Mitigating Underfitting in Learning to Defer with Consistent Losses},\n  author =       {Liu, Shuqi and Cao, Yuzhou and Zhang, Qiaozhen and Feng, Lei and An, Bo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4816--4824},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24h/liu24h.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24h.html},\n  abstract = \t {Learning to defer (L2D) allows the classifier to defer its prediction to an expert for safer predictions, by balancing the system\u2019s accuracy and extra costs incurred by consulting the expert. Various loss functions have been proposed for L2D, but they were shown to cause the underfitting of trained classifiers when extra consulting costs exist, resulting in degraded performance. In this paper, we propose a novel loss formulation that can mitigate the underfitting issue while remaining the statistical consistency. We first show that our formulation can avoid a common characteristic shared by most existing losses, which has been shown to be a cause of underfitting, and show that it can be combined with the representative losses for L2D to enhance their performance and yield consistent losses. We further study the regret transfer bounds of the proposed losses and experimentally validate its improvements over existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24h/liu24h.pdf",
        "supp": "",
        "pdf_size": 960662,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6123509081278826807&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Statistics and Data Science, KLMDASR, LEBPS, and LPMC, Nankai University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Statistics and Data Science, KLMDASR, LEBPS, and LPMC, Nankai University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore + Skywork AI, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore + Skywork AI, Singapore",
        "aff_domain": "nankai.edu.cn; ; ; ; ",
        "email": "nankai.edu.cn; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1+2;1+2",
        "aff_unique_norm": "Nankai University;Nanyang Technological University;Skywork AI",
        "aff_unique_dep": "School of Statistics and Data Science;School of Computer Science and Engineering;",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.ntu.edu.sg;",
        "aff_unique_abbr": "Nankai U;NTU;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;1;0;1+1;1+1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "39c917822e",
        "title": "Mixed Models with Multiple Instance Learning",
        "site": "https://proceedings.mlr.press/v238/engelmann24a.html",
        "author": "Jan P. Engelmann; Alessandro Palma; Jakub M. Tomczak; Fabian Theis; Francesco Paolo Casale",
        "abstract": "Predicting patient features from single-cell data can help identify cellular states implicated in health and disease. Linear models and average cell type expressions are typically favored for this task for their efficiency and robustness, but they overlook the rich cell heterogeneity inherent in single-cell data. To address this gap, we introduce MixMIL, a framework integrating Generalized Linear Mixed Models (GLMM) and Multiple Instance Learning (MIL), upholding the advantages of linear models while modeling cell state heterogeneity. By leveraging predefined cell embeddings, MixMIL enhances computational efficiency and aligns with recent advancements in single-cell representation learning. Our empirical results reveal that MixMIL outperforms existing MIL models in single-cell datasets, uncovering new associations and elucidating biological mechanisms across different domains.",
        "bibtex": "@InProceedings{pmlr-v238-engelmann24a,\n  title = \t {Mixed Models with Multiple Instance Learning},\n  author =       {Engelmann, Jan P. and Palma, Alessandro and Tomczak, Jakub M. and Theis, Fabian and Casale, Francesco Paolo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3664--3672},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/engelmann24a/engelmann24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/engelmann24a.html},\n  abstract = \t {Predicting patient features from single-cell data can help identify cellular states implicated in health and disease. Linear models and average cell type expressions are typically favored for this task for their efficiency and robustness, but they overlook the rich cell heterogeneity inherent in single-cell data. To address this gap, we introduce MixMIL, a framework integrating Generalized Linear Mixed Models (GLMM) and Multiple Instance Learning (MIL), upholding the advantages of linear models while modeling cell state heterogeneity. By leveraging predefined cell embeddings, MixMIL enhances computational efficiency and aligns with recent advancements in single-cell representation learning. Our empirical results reveal that MixMIL outperforms existing MIL models in single-cell datasets, uncovering new associations and elucidating biological mechanisms across different domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/engelmann24a/engelmann24a.pdf",
        "supp": "",
        "pdf_size": 8708380,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11043453653974386270&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Helmholtz Munich; Helmholtz Munich; Eindhoven University of Technology; Helmholtz Munich; Helmholtz Munich",
        "aff_domain": "helmholtz-munich.de;helmholtz-munich.de;tue.nl;helmholtz-munich.de;helmholtz-munich.de",
        "email": "helmholtz-munich.de;helmholtz-munich.de;tue.nl;helmholtz-munich.de;helmholtz-munich.de",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Helmholtz Zentrum M\u00fcnchen;Eindhoven University of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.helmholtz-muenchen.de;https://www.tue.nl",
        "aff_unique_abbr": "HMGU;TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "6961ec6b7b",
        "title": "Mixed variational flows for discrete variables",
        "site": "https://proceedings.mlr.press/v238/diluvi24a.html",
        "author": "Gian C. Diluvi; Benjamin Bloem-Reddy; Trevor Campbell",
        "abstract": "Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space\u2014usually via continuous relaxation or dequantization\u2014and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. Our family provides access to i.i.d. sampling and density evaluation with virtually no tuning effort. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while requiring orders of magnitude less compute.",
        "bibtex": "@InProceedings{pmlr-v238-diluvi24a,\n  title = \t {Mixed variational flows for discrete variables},\n  author =       {Diluvi, Gian C. and Bloem-Reddy, Benjamin and Campbell, Trevor},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2431--2439},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/diluvi24a/diluvi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/diluvi24a.html},\n  abstract = \t {Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space\u2014usually via continuous relaxation or dequantization\u2014and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. Our family provides access to i.i.d. sampling and density evaluation with virtually no tuning effort. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while requiring orders of magnitude less compute.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/diluvi24a/diluvi24a.pdf",
        "supp": "",
        "pdf_size": 718413,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:2eGVGF0CJgUJ:scholar.google.com/&scioq=Mixed+variational+flows+for+discrete+variables&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "Department of Statistics, University of British Columbia; Department of Statistics, University of British Columbia; Department of Statistics, University of British Columbia",
        "aff_domain": "stat.ubc.ca;stat.ubc.ca;stat.ubc.ca",
        "email": "stat.ubc.ca;stat.ubc.ca;stat.ubc.ca",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Vancouver",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "52411f71ca",
        "title": "Mixture-of-Linear-Experts for Long-term Time Series Forecasting",
        "site": "https://proceedings.mlr.press/v238/ni24a.html",
        "author": "Ronghao Ni; Zinan Lin; Shuaiqi Wang; Giulia Fanti",
        "abstract": "Long-term time series forecasting (LTSF) aims to predict future values of a time series given the past values. The current state-of-the-art (SOTA) on this problem is attained in some cases by linear-centric models, which primarily feature a linear mapping layer. However, due to their inherent simplicity, they are not able to adapt their prediction rules to periodic changes in time series patterns. To address this challenge, we propose a Mixture-of-Experts-style augmentation for linear-centric models and propose Mixture-of-Linear-Experts (MoLE). Instead of training a single model, MoLE trains multiple linear-centric models (i.e., experts) and a router model that weighs and mixes their outputs. While the entire framework is trained end-to-end, each expert learns to specialize in a specific temporal pattern, and the router model learns to compose the experts adaptively. Experiments show that MoLE reduces forecasting error of linear-centric models, including DLinear, RLinear, and RMLP, in over 78% of the datasets and settings we evaluated. By using MoLE existing linear-centric models can achieve SOTA LTSF results in 68% of the experiments that PatchTST reports and we compare to, whereas existing single-head linear-centric models achieve SOTA results in only 25% of cases.",
        "bibtex": "@InProceedings{pmlr-v238-ni24a,\n  title = \t {Mixture-of-Linear-Experts for Long-term Time Series Forecasting},\n  author =       {Ni, Ronghao and Lin, Zinan and Wang, Shuaiqi and Fanti, Giulia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4672--4680},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ni24a/ni24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ni24a.html},\n  abstract = \t {Long-term time series forecasting (LTSF) aims to predict future values of a time series given the past values. The current state-of-the-art (SOTA) on this problem is attained in some cases by linear-centric models, which primarily feature a linear mapping layer. However, due to their inherent simplicity, they are not able to adapt their prediction rules to periodic changes in time series patterns. To address this challenge, we propose a Mixture-of-Experts-style augmentation for linear-centric models and propose Mixture-of-Linear-Experts (MoLE). Instead of training a single model, MoLE trains multiple linear-centric models (i.e., experts) and a router model that weighs and mixes their outputs. While the entire framework is trained end-to-end, each expert learns to specialize in a specific temporal pattern, and the router model learns to compose the experts adaptively. Experiments show that MoLE reduces forecasting error of linear-centric models, including DLinear, RLinear, and RMLP, in over 78% of the datasets and settings we evaluated. By using MoLE existing linear-centric models can achieve SOTA LTSF results in 68% of the experiments that PatchTST reports and we compare to, whereas existing single-head linear-centric models achieve SOTA results in only 25% of cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ni24a/ni24a.pdf",
        "supp": "",
        "pdf_size": 3019910,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16350648182184710261&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Carnegie Mellon University; Microsoft Research; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "andrew.cmu.edu;microsoft.com;andrew.cmu.edu;andrew.cmu.edu",
        "email": "andrew.cmu.edu;microsoft.com;andrew.cmu.edu;andrew.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "CMU;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2fcf6818b1",
        "title": "Model-Based Best Arm Identification for Decreasing Bandits",
        "site": "https://proceedings.mlr.press/v238/takemori24a.html",
        "author": "Sho Takemori; Yuhei Umeda; Aditya Gopalan",
        "abstract": "We study the problem of reliably identifying the best (lowest loss) arm in a stochastic multi-armed bandit when the expected loss of each arm is monotone decreasing as a function of its pull count. This models, for instance, scenarios where each arm itself represents an optimization algorithm for finding the minimizer of a common function, and there is a limited time available to test the algorithms before committing to one of them. We assume that the decreasing expected loss of each arm depends on the number of its pulls as a (inverse) polynomial with unknown coefficients. We propose two fixed-budget best arm identification algorithms \u2013 one for the case of sparse polynomial decay models and the other for general polynomial models \u2013 along with bounds on the identification error probability. We also derive algorithm-independent lower bounds on the error probability. These bounds are seen to be factored into the product of the usual problem complexity and the model complexity that only depends on the parameters of the model. This indicates that our methods can identify the best arm even when the budget is smaller. We conduct empirical studies of our algorithms to complement our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-takemori24a,\n  title = \t {Model-Based Best Arm Identification for Decreasing Bandits},\n  author =       {Takemori, Sho and Umeda, Yuhei and Gopalan, Aditya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1567--1575},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/takemori24a/takemori24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/takemori24a.html},\n  abstract = \t {We study the problem of reliably identifying the best (lowest loss) arm in a stochastic multi-armed bandit when the expected loss of each arm is monotone decreasing as a function of its pull count. This models, for instance, scenarios where each arm itself represents an optimization algorithm for finding the minimizer of a common function, and there is a limited time available to test the algorithms before committing to one of them. We assume that the decreasing expected loss of each arm depends on the number of its pulls as a (inverse) polynomial with unknown coefficients. We propose two fixed-budget best arm identification algorithms \u2013 one for the case of sparse polynomial decay models and the other for general polynomial models \u2013 along with bounds on the identification error probability. We also derive algorithm-independent lower bounds on the error probability. These bounds are seen to be factored into the product of the usual problem complexity and the model complexity that only depends on the parameters of the model. This indicates that our methods can identify the best arm even when the budget is smaller. We conduct empirical studies of our algorithms to complement our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/takemori24a/takemori24a.pdf",
        "supp": "",
        "pdf_size": 583334,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12435039791137793632&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Fujitsu Limited; Fujitsu Limited; Indian Institute of Science",
        "aff_domain": "fujitsu.com;fujitsu.com;iisc.ac.in",
        "email": "fujitsu.com;fujitsu.com;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Fujitsu Limited;Indian Institute of Science",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.fujitsu.com;https://www.iisc.ac.in",
        "aff_unique_abbr": "Fujitsu;IISc",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Japan;India"
    },
    {
        "id": "bb56cbad99",
        "title": "Model-based Policy Optimization under Approximate Bayesian Inference",
        "site": "https://proceedings.mlr.press/v238/wang24g.html",
        "author": "Chaoqi Wang; Yuxin Chen; Kevin Murphy",
        "abstract": "Model-based reinforcement learning algorithms\u00a0(MBRL) present an exceptional potential to enhance sample efficiency within the realm of online reinforcement learning (RL). Nevertheless, a substantial proportion of prevalent MBRL algorithms fail to adequately address the dichotomy of exploration and exploitation. Posterior sampling reinforcement learning (PSRL) emerges as an innovative strategy adept at balancing exploration and exploitation, albeit its theoretical assurances are contingent upon exact inference. In this paper, we show that adopting the same methodology as in exact PSRL can be suboptimal under approximate inference. Motivated by the analysis, we propose an improved factorization for the posterior distribution of polices by removing the conditional independence between the policy and data given the model. By adopting such a posterior factorization, we further propose a general algorithmic framework for PSRL under approximate inference and a practical instantiation of it. Empirically, our algorithm can surpass baseline methods by a significant margin on both dense rewards and sparse rewards tasks from the Deepmind control suite, OpenAI Gym and Metaworld benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-wang24g,\n  title = \t {Model-based Policy Optimization under Approximate {B}ayesian Inference},\n  author =       {Wang, Chaoqi and Chen, Yuxin and Murphy, Kevin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3250--3258},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24g/wang24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24g.html},\n  abstract = \t {Model-based reinforcement learning algorithms\u00a0(MBRL) present an exceptional potential to enhance sample efficiency within the realm of online reinforcement learning (RL). Nevertheless, a substantial proportion of prevalent MBRL algorithms fail to adequately address the dichotomy of exploration and exploitation. Posterior sampling reinforcement learning (PSRL) emerges as an innovative strategy adept at balancing exploration and exploitation, albeit its theoretical assurances are contingent upon exact inference. In this paper, we show that adopting the same methodology as in exact PSRL can be suboptimal under approximate inference. Motivated by the analysis, we propose an improved factorization for the posterior distribution of polices by removing the conditional independence between the policy and data given the model. By adopting such a posterior factorization, we further propose a general algorithmic framework for PSRL under approximate inference and a practical instantiation of it. Empirically, our algorithm can surpass baseline methods by a significant margin on both dense rewards and sparse rewards tasks from the Deepmind control suite, OpenAI Gym and Metaworld benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24g/wang24g.pdf",
        "supp": "",
        "pdf_size": 8141548,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "University of Chicago; University of Chicago; Google DeepMind",
        "aff_domain": "uchicago.edu; ; ",
        "email": "uchicago.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Chicago;Google",
        "aff_unique_dep": ";Google DeepMind",
        "aff_unique_url": "https://www.uchicago.edu;https://deepmind.com",
        "aff_unique_abbr": "UChicago;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9876822a03",
        "title": "Monitoring machine learning-based risk prediction algorithms in the presence of performativity",
        "site": "https://proceedings.mlr.press/v238/feng24b.html",
        "author": "Jean Feng; Alexej Gossmann; Gene A Pennello; Nicholas Petrick; Berkman Sahiner; Romain Pirracchio",
        "abstract": "Performance monitoring of machine learning (ML)-based risk prediction models in healthcare is complicated by the issue of performativity: when an algorithm predicts a patient to be at high risk for an adverse event, clinicians are more likely to administer prophylactic treatment and alter the very target that the algorithm aims to predict. A simple approach is to ignore performativity and monitor only the untreated patients, whose outcomes remain unaltered. In general, ignoring performativity may inflate Type I error because (i) untreated patients disproportionally represent those with low predicted risk, and (ii) changes in the clinician\u2019s trust in the ML algorithm and the algorithm itself can induce complex dependencies that violate standard assumptions. Nevertheless, we show that valid inference is still possible when monitoring \\textit{conditional} rather than marginal performance measures under either the assumption of conditional exchangeability or time-constant selection bias. Finally, performativity can vary over time and induce nonstationarity in the data, which presents challenges for monitoring. To this end, we introduce a new score-based cumulative sum (CUSUM) monitoring procedure with dynamic control limits. Through extensive simulation studies, we study applications of the score-based CUSUM and how it is affected by various factors, including the efficiency of model updating procedures and the level of clinician trust. Finally, we apply the procedure to detect calibration decay of a risk model during the COVID-19 pandemic.",
        "bibtex": "@InProceedings{pmlr-v238-feng24b,\n  title = \t {Monitoring machine learning-based risk prediction algorithms in the presence of performativity},\n  author =       {Feng, Jean and Gossmann, Alexej and A Pennello, Gene and Petrick, Nicholas and Sahiner, Berkman and Pirracchio, Romain},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {919--927},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/feng24b/feng24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/feng24b.html},\n  abstract = \t {Performance monitoring of machine learning (ML)-based risk prediction models in healthcare is complicated by the issue of performativity: when an algorithm predicts a patient to be at high risk for an adverse event, clinicians are more likely to administer prophylactic treatment and alter the very target that the algorithm aims to predict. A simple approach is to ignore performativity and monitor only the untreated patients, whose outcomes remain unaltered. In general, ignoring performativity may inflate Type I error because (i) untreated patients disproportionally represent those with low predicted risk, and (ii) changes in the clinician\u2019s trust in the ML algorithm and the algorithm itself can induce complex dependencies that violate standard assumptions. Nevertheless, we show that valid inference is still possible when monitoring \\textit{conditional} rather than marginal performance measures under either the assumption of conditional exchangeability or time-constant selection bias. Finally, performativity can vary over time and induce nonstationarity in the data, which presents challenges for monitoring. To this end, we introduce a new score-based cumulative sum (CUSUM) monitoring procedure with dynamic control limits. Through extensive simulation studies, we study applications of the score-based CUSUM and how it is affected by various factors, including the efficiency of model updating procedures and the level of clinician trust. Finally, we apply the procedure to detect calibration decay of a risk model during the COVID-19 pandemic.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/feng24b/feng24b.pdf",
        "supp": "",
        "pdf_size": 2299418,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13508275993790345635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "University of California, San Francisco; U.S. Food and Drug Administration, Center for Devices and Radiological Health; U.S. Food and Drug Administration, Center for Devices and Radiological Health; U.S. Food and Drug Administration, Center for Devices and Radiological Health; U.S. Food and Drug Administration, Center for Devices and Radiological Health; University of California, San Francisco",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "University of California, San Francisco;U.S. Food and Drug Administration",
        "aff_unique_dep": ";Center for Devices and Radiological Health",
        "aff_unique_url": "https://www.ucsf.edu;https://www.fda.gov",
        "aff_unique_abbr": "UCSF;FDA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Francisco;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d564ee1431",
        "title": "Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs",
        "site": "https://proceedings.mlr.press/v238/baker24a.html",
        "author": "Justin M. Baker; Qingsong Wang; Martin Berzins; Thomas Strohmer; Bao Wang",
        "abstract": "Learning long-range interactions (LRI) between distant nodes is crucial for many graph learning tasks. Predominant graph neural networks (GNNs) rely on local message passing and struggle to learn LRI. In this paper, we propose DRGNN to learn LRI leveraging monotone operator theory. DRGNN contains two key components: (1) we use a full node similarity matrix beyond adjacency matrix \u2013 drawing inspiration from the personalized PageRank matrix \u2013 as the aggregation matrix for message passing, and (2) we implement message-passing on graphs using Douglas-Rachford splitting to circumvent prohibitive matrix inversion. We demonstrate that DRGNN surpasses various advanced GNNs, including Transformer-based models, on several benchmark LRI learning tasks arising from different application domains, highlighting its efficacy in learning LRI. Code is available at \\url{https://github.com/Utah-Math-Data-Science/PR-inspired-aggregation}.",
        "bibtex": "@InProceedings{pmlr-v238-baker24a,\n  title = \t {Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs},\n  author =       {Baker, Justin M. and Wang, Qingsong and Berzins, Martin and Strohmer, Thomas and Wang, Bao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2233--2241},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/baker24a/baker24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/baker24a.html},\n  abstract = \t {Learning long-range interactions (LRI) between distant nodes is crucial for many graph learning tasks. Predominant graph neural networks (GNNs) rely on local message passing and struggle to learn LRI. In this paper, we propose DRGNN to learn LRI leveraging monotone operator theory. DRGNN contains two key components: (1) we use a full node similarity matrix beyond adjacency matrix \u2013 drawing inspiration from the personalized PageRank matrix \u2013 as the aggregation matrix for message passing, and (2) we implement message-passing on graphs using Douglas-Rachford splitting to circumvent prohibitive matrix inversion. We demonstrate that DRGNN surpasses various advanced GNNs, including Transformer-based models, on several benchmark LRI learning tasks arising from different application domains, highlighting its efficacy in learning LRI. Code is available at \\url{https://github.com/Utah-Math-Data-Science/PR-inspired-aggregation}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/baker24a/baker24a.pdf",
        "supp": "",
        "pdf_size": 1908846,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13028373989118351600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Utah; University of Utah; University of Utah; UC Davis; University of Utah",
        "aff_domain": "gmail.com; ; ; ; ",
        "email": "gmail.com; ; ; ; ",
        "github": "https://github.com/Utah-Math-Data-Science/PR-inspired-aggregation",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Utah;University of California, Davis",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utah.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "Utah;UC Davis",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Davis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "754ea7b03e",
        "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels",
        "site": "https://proceedings.mlr.press/v238/hanna24a.html",
        "author": "Osama A Hanna; Merve Karakas; Lin Yang; Christina Fragouli",
        "abstract": "Multi-Armed Bandit (MAB) systems are witnessing an upswing in applications within multi-agent distributed environments, leading to the advancement of collaborative MAB algorithms. In such settings, communication between agents executing actions and the primary learner making decisions can hinder the learning process. A prevalent challenge in distributed learning is action erasure, often induced by communication delays and/or channel noise. This results in agents possibly not receiving the intended action from the learner, subsequently leading to misguided feedback. In this paper, we introduce novel algorithms that enable learners to interact concurrently with distributed agents across heterogeneous action erasure channels with different action erasure probabilities. We illustrate that, in contrast to existing bandit algorithms, which experience linear regret, our algorithms assure sub-linear regret guarantees. Our proposed solutions are founded on a meticulously crafted repetition protocol and scheduling of learning across heterogeneous channels. To our knowledge, these are the first algorithms capable of effectively learning through heterogeneous action erasure channels. We substantiate the superior performance of our algorithm through numerical experiments, emphasizing their practical significance in addressing issues related to communication constraints and delays in multi-agent environments.",
        "bibtex": "@InProceedings{pmlr-v238-hanna24a,\n  title = \t {Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels},\n  author =       {A Hanna, Osama and Karakas, Merve and Yang, Lin and Fragouli, Christina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3898--3906},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hanna24a/hanna24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hanna24a.html},\n  abstract = \t {Multi-Armed Bandit (MAB) systems are witnessing an upswing in applications within multi-agent distributed environments, leading to the advancement of collaborative MAB algorithms. In such settings, communication between agents executing actions and the primary learner making decisions can hinder the learning process. A prevalent challenge in distributed learning is action erasure, often induced by communication delays and/or channel noise. This results in agents possibly not receiving the intended action from the learner, subsequently leading to misguided feedback. In this paper, we introduce novel algorithms that enable learners to interact concurrently with distributed agents across heterogeneous action erasure channels with different action erasure probabilities. We illustrate that, in contrast to existing bandit algorithms, which experience linear regret, our algorithms assure sub-linear regret guarantees. Our proposed solutions are founded on a meticulously crafted repetition protocol and scheduling of learning across heterogeneous channels. To our knowledge, these are the first algorithms capable of effectively learning through heterogeneous action erasure channels. We substantiate the superior performance of our algorithm through numerical experiments, emphasizing their practical significance in addressing issues related to communication constraints and delays in multi-agent environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hanna24a/hanna24a.pdf",
        "supp": "",
        "pdf_size": 771115,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1591804015680901195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "798453900f",
        "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
        "site": "https://proceedings.mlr.press/v238/maddux24a.html",
        "author": "Anna M. Maddux; Maryam Kamgarpour",
        "abstract": "We consider the problem of learning to play a repeated contextual game with unknown reward and unknown constraints functions. Such games arise in applications where each agent\u2019s action needs to belong to a feasible set, but the feasible set is a priori unknown. For example, in constrained multi-agent reinforcement learning, the constraints on the agents\u2019 policies are a function of the unknown dynamics and hence, are themselves unknown. Under kernel-based regularity assumptions on the unknown functions, we develop a no-regret, no-violation approach that exploits similarities among different reward and constraint outcomes. The no-violation property ensures that the time-averaged sum of constraint violations converges to zero as the game is repeated. We show that our algorithm referred to as c.z.AdaNormalGP, obtains kernel-dependent regret bounds, and the cumulative constraint violations have sublinear kernel-dependent upper bounds. In addition, we introduce the notion of constrained contextual coarse correlated equilibria (c.z.CCE) and show that $\\epsilon$-c.z.CCEs can be approached whenever players follow a no-regret no-violation strategy. Finally, we experimentally demonstrate the effectiveness of c.z.AdaNormalGP on an instance of multi-agent reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v238-maddux24a,\n  title = \t {Multi-Agent Learning in Contextual Games under Unknown Constraints},\n  author =       {Maddux, Anna M. and Kamgarpour, Maryam},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3142--3150},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/maddux24a/maddux24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/maddux24a.html},\n  abstract = \t {We consider the problem of learning to play a repeated contextual game with unknown reward and unknown constraints functions. Such games arise in applications where each agent\u2019s action needs to belong to a feasible set, but the feasible set is a priori unknown. For example, in constrained multi-agent reinforcement learning, the constraints on the agents\u2019 policies are a function of the unknown dynamics and hence, are themselves unknown. Under kernel-based regularity assumptions on the unknown functions, we develop a no-regret, no-violation approach that exploits similarities among different reward and constraint outcomes. The no-violation property ensures that the time-averaged sum of constraint violations converges to zero as the game is repeated. We show that our algorithm referred to as c.z.AdaNormalGP, obtains kernel-dependent regret bounds, and the cumulative constraint violations have sublinear kernel-dependent upper bounds. In addition, we introduce the notion of constrained contextual coarse correlated equilibria (c.z.CCE) and show that $\\epsilon$-c.z.CCEs can be approached whenever players follow a no-regret no-violation strategy. Finally, we experimentally demonstrate the effectiveness of c.z.AdaNormalGP on an instance of multi-agent reinforcement learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/maddux24a/maddux24a.pdf",
        "supp": "",
        "pdf_size": 678447,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1889794081972924081&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "EPFL Lausanne; EPFL Lausanne",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "3e0a488ddc",
        "title": "Multi-Dimensional Hyena for Spatial Inductive Bias",
        "site": "https://proceedings.mlr.press/v238/zimerman24a.html",
        "author": "Itamar Zimerman; Lior Wolf",
        "abstract": "The advantage of Vision Transformers over CNNs is only fully manifested when trained over a large dataset, mainly due to the reduced inductive bias towards spatial locality within the transformer\u2019s self-attention mechanism. In this work, we present a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We propose several alternative approaches for obtaining this generalization and delve into their unique distinctions and considerations from both empirical and theoretical perspectives. The proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT is favorable to ViT variants from the recent literature that are specifically designed for solving the same challenge. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures. Our code is attached as supplementary.",
        "bibtex": "@InProceedings{pmlr-v238-zimerman24a,\n  title = \t {Multi-Dimensional {H}yena for Spatial Inductive Bias},\n  author =       {Zimerman, Itamar and Wolf, Lior},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {973--981},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zimerman24a/zimerman24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zimerman24a.html},\n  abstract = \t {The advantage of Vision Transformers over CNNs is only fully manifested when trained over a large dataset, mainly due to the reduced inductive bias towards spatial locality within the transformer\u2019s self-attention mechanism. In this work, we present a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We propose several alternative approaches for obtaining this generalization and delve into their unique distinctions and considerations from both empirical and theoretical perspectives. The proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT is favorable to ViT variants from the recent literature that are specifically designed for solving the same challenge. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures. Our code is attached as supplementary.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zimerman24a/zimerman24a.pdf",
        "supp": "",
        "pdf_size": 2896815,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16511540462953583762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Tel Aviv University; Tel Aviv University",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/your-repo",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tel Aviv University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tau.ac.il",
        "aff_unique_abbr": "TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "edf5d3061e",
        "title": "Multi-Domain Causal Representation Learning via Weak Distributional Invariances",
        "site": "https://proceedings.mlr.press/v238/ahuja24a.html",
        "author": "Kartik Ahuja; Amin Mansouri; Yixin Wang",
        "abstract": "Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set of latents from the rest across different settings.",
        "bibtex": "@InProceedings{pmlr-v238-ahuja24a,\n  title = \t {Multi-Domain Causal Representation Learning via Weak Distributional Invariances},\n  author =       {Ahuja, Kartik and Mansouri, Amin and Wang, Yixin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {865--873},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ahuja24a/ahuja24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ahuja24a.html},\n  abstract = \t {Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set of latents from the rest across different settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ahuja24a/ahuja24a.pdf",
        "supp": "",
        "pdf_size": 942173,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7942148372502786470&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b7f8630012",
        "title": "Multi-Level Symbolic Regression: Function Structure Learning for Multi-Level Data",
        "site": "https://proceedings.mlr.press/v238/sen-fong24a.html",
        "author": "Kei Sen Fong; Mehul Motani",
        "abstract": "Symbolic Regression (SR) is an approach which learns a closed-form function relating the predictors to the outcome in a dataset. Datasets are often multi-level (MuL), meaning that certain features can be used to split data into groups for analysis (we refer to these features as levels). The advantage of viewing datasets as MuL is that we can exploit the high similarity of data within a group. SR is well-suited for MuL datasets, in which the learnt function structure serves as \u2018shared information\u2019 between the groups while the learnt parameter values capture the unique relationships within each group. In this context, this paper makes three contributions: (i) We design an algorithm, Multi-level Symbolic Regression (MSR), which runs multiple parallel SR processes for each group and merges them to produce a single function structure. (ii) To tackle datasets that are not explicitly MuL, we develop a metric termed MLICC to select the best feature to serve as a level. (iii) We also release MSRBench, a database of MuL datasets (synthetic and real-world) which we developed and collated, that can be used to evaluate MSR. Our results and ablation studies demonstrate that MSR achieves a higher recovery rate and lower error on MSRBench compared to SOTA methods for SR and MuL datasets.",
        "bibtex": "@InProceedings{pmlr-v238-sen-fong24a,\n  title = \t {Multi-Level Symbolic Regression: Function Structure Learning for Multi-Level Data},\n  author =       {Sen Fong, Kei and Motani, Mehul},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2890--2898},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sen-fong24a/sen-fong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sen-fong24a.html},\n  abstract = \t {Symbolic Regression (SR) is an approach which learns a closed-form function relating the predictors to the outcome in a dataset. Datasets are often multi-level (MuL), meaning that certain features can be used to split data into groups for analysis (we refer to these features as levels). The advantage of viewing datasets as MuL is that we can exploit the high similarity of data within a group. SR is well-suited for MuL datasets, in which the learnt function structure serves as \u2018shared information\u2019 between the groups while the learnt parameter values capture the unique relationships within each group. In this context, this paper makes three contributions: (i) We design an algorithm, Multi-level Symbolic Regression (MSR), which runs multiple parallel SR processes for each group and merges them to produce a single function structure. (ii) To tackle datasets that are not explicitly MuL, we develop a metric termed MLICC to select the best feature to serve as a level. (iii) We also release MSRBench, a database of MuL datasets (synthetic and real-world) which we developed and collated, that can be used to evaluate MSR. Our results and ablation studies demonstrate that MSR achieves a higher recovery rate and lower error on MSRBench compared to SOTA methods for SR and MuL datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sen-fong24a/sen-fong24a.pdf",
        "supp": "",
        "pdf_size": 4423156,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16043751195583177962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "National University of Singapore; National University of Singapore",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "990648cea1",
        "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
        "site": "https://proceedings.mlr.press/v238/li24k.html",
        "author": "Shibo Li; Xin Yu; Wei Xing; Robert Kirby; Akil Narayan; Shandian Zhe",
        "abstract": "Fourier Neural Operator (FNO) is a popular operator learning framework. It not only achieves the state-of-the-art performance in many tasks, but also is efficient in training and prediction. However, collecting training data for the FNO can be a costly bottleneck in practice, because it often demands expensive physical simulations. To overcome this problem, we propose Multi-Resolution Active Learning of FNO (MRA-FNO), which can dynamically select the input functions and resolutions to lower the data cost as much as possible while optimizing the learning efficiency. Specifically, we propose a probabilistic multi-resolution FNO and use ensemble Monte-Carlo to develop an effective posterior inference algorithm. To conduct active learning, we maximize a utility-cost ratio as the acquisition function to acquire new examples and resolutions at each step. We use moment matching and the matrix determinant lemma to enable tractable, efficient utility computation. Furthermore, we develop a cost annealing framework to avoid over-penalizing high-resolution queries at the early stage. The over-penalization is severe when the cost difference is significant between the resolutions, which renders active learning often stuck at low-resolution queries and inferior performance. Our method overcomes this problem and applies to general multi-fidelity active learning and optimization problems. We have shown the advantage of our method in several benchmark operator learning tasks. The code is available at https://github.com/shib0li/MRA-FNO.",
        "bibtex": "@InProceedings{pmlr-v238-li24k,\n  title = \t {Multi-Resolution Active Learning of {F}ourier Neural Operators},\n  author =       {Li, Shibo and Yu, Xin and Xing, Wei and Kirby, Robert and Narayan, Akil and Zhe, Shandian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2440--2448},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24k/li24k.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24k.html},\n  abstract = \t {Fourier Neural Operator (FNO) is a popular operator learning framework. It not only achieves the state-of-the-art performance in many tasks, but also is efficient in training and prediction. However, collecting training data for the FNO can be a costly bottleneck in practice, because it often demands expensive physical simulations. To overcome this problem, we propose Multi-Resolution Active Learning of FNO (MRA-FNO), which can dynamically select the input functions and resolutions to lower the data cost as much as possible while optimizing the learning efficiency. Specifically, we propose a probabilistic multi-resolution FNO and use ensemble Monte-Carlo to develop an effective posterior inference algorithm. To conduct active learning, we maximize a utility-cost ratio as the acquisition function to acquire new examples and resolutions at each step. We use moment matching and the matrix determinant lemma to enable tractable, efficient utility computation. Furthermore, we develop a cost annealing framework to avoid over-penalizing high-resolution queries at the early stage. The over-penalization is severe when the cost difference is significant between the resolutions, which renders active learning often stuck at low-resolution queries and inferior performance. Our method overcomes this problem and applies to general multi-fidelity active learning and optimization problems. We have shown the advantage of our method in several benchmark operator learning tasks. The code is available at https://github.com/shib0li/MRA-FNO.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24k/li24k.pdf",
        "supp": "",
        "pdf_size": 1914751,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14848188861694877100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Kahlert School of Computing, University of Utah; Kahlert School of Computing, University of Utah; School of Mathematics and Statistics, University of Shef\ufb01eld; Kahlert School of Computing, University of Utah + Scienti\ufb01c Computing and Imaging (SCI) Institute, University of Utah + Department of Mathematics, University of Utah; Scienti\ufb01c Computing and Imaging (SCI) Institute, University of Utah + Department of Mathematics, University of Utah; Kahlert School of Computing, University of Utah",
        "aff_domain": "cs.utah.edu;cs.utah.edu;sheffield.ac.uk;cs.utah.edu;sci.utah.edu;cs.utah.edu",
        "email": "cs.utah.edu;cs.utah.edu;sheffield.ac.uk;cs.utah.edu;sci.utah.edu;cs.utah.edu",
        "github": "https://github.com/shib0li/MRA-FNO",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0+0+0;0+0;0",
        "aff_unique_norm": "University of Utah;University of Sheffield",
        "aff_unique_dep": "Kahlert School of Computing;School of Mathematics and Statistics",
        "aff_unique_url": "https://www.utah.edu;https://www.sheffield.ac.uk",
        "aff_unique_abbr": "U of U;Sheffield",
        "aff_campus_unique_index": "0;0;0+0;0;0",
        "aff_campus_unique": "Salt Lake City;",
        "aff_country_unique_index": "0;0;1;0+0+0;0+0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "b5e0e4ba34",
        "title": "Multi-armed bandits with guaranteed revenue per arm",
        "site": "https://proceedings.mlr.press/v238/baudry24a.html",
        "author": "Dorian Baudry; Nadav Merlis; Mathieu Benjamin Molina; Hugo Richard; Vianney Perchet",
        "abstract": "We consider a Multi-Armed Bandit problem with covering constraints, where the primary goal is to ensure that each arm receives a minimum expected reward while maximizing the total cumulative reward. In this scenario, the optimal policy then belongs to some unknown feasible set. Unlike much of the existing literature, we do not assume the presence of a safe policy or a feasibility margin, which hinders the exclusive use of conservative approaches. Consequently, we propose and analyze an algorithm that switches between pessimism and optimism in the face of uncertainty. We prove both precise problem-dependent and problem-independent bounds, demonstrating that our algorithm achieves the best of the two approaches\u2014depending on the presence or absence of a feasibility margin\u2014in terms of constraint violation guarantees. Furthermore, our results indicate that playing greedily on the constraints actually outperforms pessimism when considering long-term violations rather than violations on a per-round basis.",
        "bibtex": "@InProceedings{pmlr-v238-baudry24a,\n  title = \t {Multi-armed bandits with guaranteed revenue per arm},\n  author =       {Baudry, Dorian and Merlis, Nadav and Benjamin Molina, Mathieu and Richard, Hugo and Perchet, Vianney},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {379--387},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/baudry24a/baudry24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/baudry24a.html},\n  abstract = \t {We consider a Multi-Armed Bandit problem with covering constraints, where the primary goal is to ensure that each arm receives a minimum expected reward while maximizing the total cumulative reward. In this scenario, the optimal policy then belongs to some unknown feasible set. Unlike much of the existing literature, we do not assume the presence of a safe policy or a feasibility margin, which hinders the exclusive use of conservative approaches. Consequently, we propose and analyze an algorithm that switches between pessimism and optimism in the face of uncertainty. We prove both precise problem-dependent and problem-independent bounds, demonstrating that our algorithm achieves the best of the two approaches\u2014depending on the presence or absence of a feasibility margin\u2014in terms of constraint violation guarantees. Furthermore, our results indicate that playing greedily on the constraints actually outperforms pessimism when considering long-term violations rather than violations on a per-round basis.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/baudry24a/baudry24a.pdf",
        "supp": "",
        "pdf_size": 1136801,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9896247109152565492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "ENSAE, FAIRPLAY joint team, CREST, Palaiseau, France+Institut Polytechnique de Paris, Palaiseau, France; ENSAE, FAIRPLAY joint team, CREST, Palaiseau, France; Criteo AI Lab, FAIRPLAY joint team, Paris, France; Inria, FAIRPLAY joint team, Palaiseau, France; ENSAE, FAIRPLAY joint team, CREST, Palaiseau, France+Criteo AI Lab, FAIRPLAY joint team, Paris, France",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;2;3;0+2",
        "aff_unique_norm": "ENSAE;Institut Polytechnique de Paris;Criteo;INRIA",
        "aff_unique_dep": "FAIRPLAY joint team;;Criteo AI Lab;FAIRPLAY joint team",
        "aff_unique_url": "https://www.ensae.fr;https://www.ipparis.fr;https://www.criteo.com;https://www.inria.fr",
        "aff_unique_abbr": "ENSAE;IP Paris;Criteo;Inria",
        "aff_campus_unique_index": "0+0;0;1;0;0+1",
        "aff_campus_unique": "Palaiseau;Paris",
        "aff_country_unique_index": "0+0;0;0;0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "dce91da16d",
        "title": "Multi-objective Optimization via Wasserstein-Fisher-Rao Gradient Flow",
        "site": "https://proceedings.mlr.press/v238/ren24b.html",
        "author": "Yinuo Ren; Tesi Xiao; Tanmay Gangwani; Anshuka Rangi; Holakou Rahmanian; Lexing Ying; Subhajit Sanyal",
        "abstract": "Multi-objective optimization (MOO) aims to optimize multiple, possibly conflicting objectives with widespread applications. We introduce a novel interacting particle method for MOO inspired by molecular dynamics simulations. Our approach combines overdamped Langevin and birth-death dynamics, incorporating a \u201cdominance potential\u201d to steer particles toward global Pareto optimality. In contrast to previous methods, our method is able to relocate dominated particles, making it particularly adept at managing Pareto fronts of complicated geometries. Our method is also theoretically grounded as a Wasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive experiments confirm that our approach outperforms state-of-the-art methods on challenging synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v238-ren24b,\n  title = \t {Multi-objective Optimization via {W}asserstein-{F}isher-{R}ao Gradient Flow},\n  author =       {Ren, Yinuo and Xiao, Tesi and Gangwani, Tanmay and Rangi, Anshuka and Rahmanian, Holakou and Ying, Lexing and Sanyal, Subhajit},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3862--3870},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ren24b/ren24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ren24b.html},\n  abstract = \t {Multi-objective optimization (MOO) aims to optimize multiple, possibly conflicting objectives with widespread applications. We introduce a novel interacting particle method for MOO inspired by molecular dynamics simulations. Our approach combines overdamped Langevin and birth-death dynamics, incorporating a \u201cdominance potential\u201d to steer particles toward global Pareto optimality. In contrast to previous methods, our method is able to relocate dominated particles, making it particularly adept at managing Pareto fronts of complicated geometries. Our method is also theoretically grounded as a Wasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive experiments confirm that our approach outperforms state-of-the-art methods on challenging synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ren24b/ren24b.pdf",
        "supp": "",
        "pdf_size": 6329177,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ZYZU7sazuHEJ:scholar.google.com/&scioq=Multi-objective+Optimization+via+Wasserstein-Fisher-Rao+Gradient+Flow&hl=en&as_sdt=0,33",
        "gs_version_total": 8,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "51467ccc82",
        "title": "Multi-resolution Time-Series Transformer for Long-term Forecasting",
        "site": "https://proceedings.mlr.press/v238/zhang24l.html",
        "author": "Yitian Zhang; Liheng Ma; Soumyasundar Pal; Yingxue Zhang; Mark Coates",
        "abstract": "The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24l,\n  title = \t {Multi-resolution Time-Series Transformer for Long-term Forecasting},\n  author =       {Zhang, Yitian and Ma, Liheng and Pal, Soumyasundar and Zhang, Yingxue and Coates, Mark},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4222--4230},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24l/zhang24l.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24l.html},\n  abstract = \t {The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24l/zhang24l.pdf",
        "supp": "",
        "pdf_size": 2274323,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3075018903466128359&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "McGill University, Mila, and ILLS; McGill University, Mila, and ILLS; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; McGill University, Mila, and ILLS",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/networkslab/MTST",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "McGill University;Huawei",
        "aff_unique_dep": ";Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.mcgill.ca;https://www.huawei.com",
        "aff_unique_abbr": "McGill;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "430bd44e98",
        "title": "Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures",
        "site": "https://proceedings.mlr.press/v238/zhang24e.html",
        "author": "Mingyuan Zhang; Shivani Agarwal",
        "abstract": "There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro F1 in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds for our algorithms, establishing that even though they are trained on noisy data, they are Bayes consistent in the sense that their performance converges to the optimal performance w.r.t. the clean (non-noisy) distribution. Our experiments demonstrate the effectiveness of our algorithms in handling label noise.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24e,\n  title = \t {Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures},\n  author =       {Zhang, Mingyuan and Agarwal, Shivani},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2170--2178},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24e/zhang24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24e.html},\n  abstract = \t {There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro F1 in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds for our algorithms, establishing that even though they are trained on noisy data, they are Bayes consistent in the sense that their performance converges to the optimal performance w.r.t. the clean (non-noisy) distribution. Our experiments demonstrate the effectiveness of our algorithms in handling label noise.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24e/zhang24e.pdf",
        "supp": "",
        "pdf_size": 663233,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11696860327280869857&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;seas.upenn.edu",
        "email": "seas.upenn.edu;seas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4b77fef5c2",
        "title": "Multitask Online Learning: Listen to the Neighborhood Buzz",
        "site": "https://proceedings.mlr.press/v238/achddou24a.html",
        "author": "Juliette Achddou; Nicol\u00f2 Cesa-Bianchi; Pierre Laforgue",
        "abstract": "We study multitask online learning in a setting where agents can only exchange information with their neighbors on an arbitrary communication network. We introduce MT-CO\\textsubscript{2}OL, a decentralized algorithm for this setting whose regret depends on the interplay between the task similarities and the network structure. Our analysis shows that the regret of MT-CO\\textsubscript{2}OL is never worse (up to constants) than the bound obtained when agents do not share information. On the other hand, our bounds significantly improve when neighboring agents operate on similar tasks. In addition, we prove that our algorithm can be made differentially private with a negligible impact on the regret. Finally, we provide experimental support for our theory.",
        "bibtex": "@InProceedings{pmlr-v238-achddou24a,\n  title = \t {Multitask Online Learning: Listen to the Neighborhood Buzz},\n  author =       {Achddou, Juliette and Cesa-Bianchi, Nicol\\`{o} and Laforgue, Pierre},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1846--1854},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/achddou24a/achddou24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/achddou24a.html},\n  abstract = \t {We study multitask online learning in a setting where agents can only exchange information with their neighbors on an arbitrary communication network. We introduce MT-CO\\textsubscript{2}OL, a decentralized algorithm for this setting whose regret depends on the interplay between the task similarities and the network structure. Our analysis shows that the regret of MT-CO\\textsubscript{2}OL is never worse (up to constants) than the bound obtained when agents do not share information. On the other hand, our bounds significantly improve when neighboring agents operate on similar tasks. In addition, we prove that our algorithm can be made differentially private with a negligible impact on the regret. Finally, we provide experimental support for our theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/achddou24a/achddou24a.pdf",
        "supp": "",
        "pdf_size": 7492158,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ab48289f86",
        "title": "Multivariate Time Series Forecasting By Graph Attention Networks With Theoretical Guarantees",
        "site": "https://proceedings.mlr.press/v238/zhang24g.html",
        "author": "Zhi Zhang; Weijian Li; Han Liu",
        "abstract": "Multivariate time series forecasting (MTSF) aims to predict future values of multiple variables based on past values of multivariate time series, and has been applied in fields including traffic flow prediction, stock price forecasting, and anomaly detection. Capturing the inter-dependencies among multiple series poses one significant challenge to MTSF. Recent works have considered modeling the correlated series as graph nodes and using graph neural network (GNN)-based approaches with attention mechanisms added to improve the test prediction accuracy, however, none of them have theoretical guarantees regarding the generalization error. In this paper, we develop a new norm-bounded graph attention network (GAT) for MTSF by upper-bounding the Frobenius norm of weights in each layer of the GAT model to enhance performance. We theoretically establish that the generalization error bound for our model is associated with various components of GAT models: the number of attention heads, the maximum number of neighbors, the upper bound of the Frobenius norm of the weight matrix in each layer, and the norm of the input features. Empirically, we investigate the impact of different components of GAT models on the generalization performance of MTSF on real data. Our experiment verifies our theoretical findings. We compare with multiple prior frequently cited graph-based methods for MTSF using real data sets and the experiment results show our method can achieve the best performance for MTSF. Our method provides novel perspectives for improving the generalization performance of MTSF, and our theoretical guarantees give substantial implications for designing graph-based methods with attention mechanisms for MTSF.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24g,\n  title = \t {Multivariate Time Series Forecasting By Graph Attention Networks With Theoretical Guarantees},\n  author =       {Zhang, Zhi and Li, Weijian and Liu, Han},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2845--2853},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24g/zhang24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24g.html},\n  abstract = \t {Multivariate time series forecasting (MTSF) aims to predict future values of multiple variables based on past values of multivariate time series, and has been applied in fields including traffic flow prediction, stock price forecasting, and anomaly detection. Capturing the inter-dependencies among multiple series poses one significant challenge to MTSF. Recent works have considered modeling the correlated series as graph nodes and using graph neural network (GNN)-based approaches with attention mechanisms added to improve the test prediction accuracy, however, none of them have theoretical guarantees regarding the generalization error. In this paper, we develop a new norm-bounded graph attention network (GAT) for MTSF by upper-bounding the Frobenius norm of weights in each layer of the GAT model to enhance performance. We theoretically establish that the generalization error bound for our model is associated with various components of GAT models: the number of attention heads, the maximum number of neighbors, the upper bound of the Frobenius norm of the weight matrix in each layer, and the norm of the input features. Empirically, we investigate the impact of different components of GAT models on the generalization performance of MTSF on real data. Our experiment verifies our theoretical findings. We compare with multiple prior frequently cited graph-based methods for MTSF using real data sets and the experiment results show our method can achieve the best performance for MTSF. Our method provides novel perspectives for improving the generalization performance of MTSF, and our theoretical guarantees give substantial implications for designing graph-based methods with attention mechanisms for MTSF.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24g/zhang24g.pdf",
        "supp": "",
        "pdf_size": 750929,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17406799252238061966&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Los Angeles; Northwestern University; Northwestern University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Los Angeles;Northwestern University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucla.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "UCLA;NU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c5d2339b93",
        "title": "Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with Smoothed Responses",
        "site": "https://proceedings.mlr.press/v238/zuo24a.html",
        "author": "Shiliang Zuo",
        "abstract": "I study adversarial attacks against stochastic bandit algorithms. At each round, the learner chooses an arm, and a stochastic reward is generated. The adversary strategically adds corruption to the reward, and the learner is only able to observe the corrupted reward at each round. Two sets of results are presented in this paper. The first set studies the optimal attack strategies for the adversary. The adversary has a target arm he wishes to promote, and his goal is to manipulate the learner into choosing this target arm $T - o(T)$ times. I design attack strategies against UCB and Thompson Sampling that only spends $\\widehat{O}(\\sqrt{\\log T})$ cost. Matching lower bounds are presented, and the vulnerability of UCB, Thompson sampling and $\\varepsilon$-greedy are exactly characterized. The second set studies how the learner can defend against the adversary. Inspired by literature on smoothed analysis and behavioral economics, I present two simple algorithms that achieve a competitive ratio arbitrarily close to 1.",
        "bibtex": "@InProceedings{pmlr-v238-zuo24a,\n  title = \t {Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with Smoothed Responses},\n  author =       {Zuo, Shiliang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2098--2106},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zuo24a/zuo24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zuo24a.html},\n  abstract = \t {I study adversarial attacks against stochastic bandit algorithms. At each round, the learner chooses an arm, and a stochastic reward is generated. The adversary strategically adds corruption to the reward, and the learner is only able to observe the corrupted reward at each round. Two sets of results are presented in this paper. The first set studies the optimal attack strategies for the adversary. The adversary has a target arm he wishes to promote, and his goal is to manipulate the learner into choosing this target arm $T - o(T)$ times. I design attack strategies against UCB and Thompson Sampling that only spends $\\widehat{O}(\\sqrt{\\log T})$ cost. Matching lower bounds are presented, and the vulnerability of UCB, Thompson sampling and $\\varepsilon$-greedy are exactly characterized. The second set studies how the learner can defend against the adversary. Inspired by literature on smoothed analysis and behavioral economics, I present two simple algorithms that achieve a competitive ratio arbitrarily close to 1.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zuo24a/zuo24a.pdf",
        "supp": "",
        "pdf_size": 512690,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1464505804169018835&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Illinois Urbana-Champaign",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "23dd664986",
        "title": "Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization",
        "site": "https://proceedings.mlr.press/v238/wang24l.html",
        "author": "Yutong Wang; Rishi Sonthalia; Wei Hu",
        "abstract": "We study the generalization capability of nearly-interpolating linear regressors: ${\\beta}$\u2019s whose training error $\\tau$ is positive but small, i.e., below the noise floor. Under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix ${\\Sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\\tau$ fixed, ${\\beta}$ has squared $\\ell_2$-norm $\\mathbb{E}[\\|{{\\beta}}\\|_{2}^{2}] = \\Omega(n^{\\alpha})$ where $n$ is the number of samples and $\\alpha >1$ is the exponent of the eigendecay, i.e., $\\lambda_i({\\Sigma}) \\sim i^{-\\alpha}$. This implies that existing data-independent norm-based bounds are necessarily loose. On the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. Our characterization reveals that larger norm scaling exponents $\\alpha$ correspond to worse trade-offs between interpolation and generalization. We verify empirically that a similar phenomenon holds for nearly-interpolating shallow neural networks.",
        "bibtex": "@InProceedings{pmlr-v238-wang24l,\n  title = \t {Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization},\n  author =       {Wang, Yutong and Sonthalia, Rishi and Hu, Wei},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4483--4491},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24l/wang24l.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24l.html},\n  abstract = \t {We study the generalization capability of nearly-interpolating linear regressors: ${\\beta}$\u2019s whose training error $\\tau$ is positive but small, i.e., below the noise floor. Under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix ${\\Sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\\tau$ fixed, ${\\beta}$ has squared $\\ell_2$-norm $\\mathbb{E}[\\|{{\\beta}}\\|_{2}^{2}] = \\Omega(n^{\\alpha})$ where $n$ is the number of samples and $\\alpha >1$ is the exponent of the eigendecay, i.e., $\\lambda_i({\\Sigma}) \\sim i^{-\\alpha}$. This implies that existing data-independent norm-based bounds are necessarily loose. On the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. Our characterization reveals that larger norm scaling exponents $\\alpha$ correspond to worse trade-offs between interpolation and generalization. We verify empirically that a similar phenomenon holds for nearly-interpolating shallow neural networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24l/wang24l.pdf",
        "supp": "",
        "pdf_size": 1843785,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4137322524693093174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cd3002049b",
        "title": "Near-Optimal Convex Simple Bilevel Optimization with a Bisection Method",
        "site": "https://proceedings.mlr.press/v238/wang24d.html",
        "author": "Jiulin Wang; Xu Shi; Rujun Jiang",
        "abstract": "This paper studies a class of simple bilevel optimization problems where we minimize a composite convex function at the upper-level subject to a composite convex lower-level problem. Existing methods either provide asymptotic guarantees for the upper-level objective or attain slow sublinear convergence rates. We propose a bisection algorithm to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. In each iteration, the binary search narrows the interval by assessing inequality system feasibility. Under mild conditions, the total operation complexity of our method is ${{\\mathcal{O}}}\\left(\\max\\{\\sqrt{L_{f_1}/\\epsilon_f},\\sqrt{L_{g_1}/\\epsilon_g}\\} \\right)$. Here, a unit operation can be a function evaluation, gradient evaluation, or the invocation of the proximal mapping, $L_{f_1}$ and $L_{g_1}$ are the Lipschitz constants of the upper- and lower-level objectives\u2019 smooth components, and ${\\mathcal{O}}$ hides logarithmic terms. Our approach achieves a near-optimal rate in unconstrained smooth or composite convex optimization when disregarding logarithmic terms. Numerical experiments demonstrate the effectiveness of our method.",
        "bibtex": "@InProceedings{pmlr-v238-wang24d,\n  title = \t {Near-Optimal Convex Simple Bilevel Optimization with a Bisection Method},\n  author =       {Wang, Jiulin and Shi, Xu and Jiang, Rujun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2008--2016},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24d/wang24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24d.html},\n  abstract = \t {This paper studies a class of simple bilevel optimization problems where we minimize a composite convex function at the upper-level subject to a composite convex lower-level problem. Existing methods either provide asymptotic guarantees for the upper-level objective or attain slow sublinear convergence rates. We propose a bisection algorithm to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. In each iteration, the binary search narrows the interval by assessing inequality system feasibility. Under mild conditions, the total operation complexity of our method is ${{\\mathcal{O}}}\\left(\\max\\{\\sqrt{L_{f_1}/\\epsilon_f},\\sqrt{L_{g_1}/\\epsilon_g}\\} \\right)$. Here, a unit operation can be a function evaluation, gradient evaluation, or the invocation of the proximal mapping, $L_{f_1}$ and $L_{g_1}$ are the Lipschitz constants of the upper- and lower-level objectives\u2019 smooth components, and ${\\mathcal{O}}$ hides logarithmic terms. Our approach achieves a near-optimal rate in unconstrained smooth or composite convex optimization when disregarding logarithmic terms. Numerical experiments demonstrate the effectiveness of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24d/wang24d.pdf",
        "supp": "",
        "pdf_size": 1302555,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14245570746993289132&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "School of Data Science, Fudan University; School of Data Science, Fudan University; School of Data Science, Fudan University\u2020",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "School of Data Science",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "b6f38eb273",
        "title": "Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games",
        "site": "https://proceedings.mlr.press/v238/cai24a.html",
        "author": "Yang Cai; Haipeng Luo; Chen-Yu Wei; Weiqiang Zheng",
        "abstract": "We study policy optimization algorithms for computing correlated equilibria in multi-player general-sum Markov Games. Previous results achieve $\\tilde{O}(T^{-1/2})$ convergence rate to a correlated equilibrium and an accelerated $\\tilde{O}(T^{-3/4})$ convergence rate to the weaker notion of coarse correlated equilibrium. In this paper, we improve both results significantly by providing an uncoupled policy optimization algorithm that attains a near-optimal $\\tilde{O}(T^{-1})$ convergence rate for computing a correlated equilibrium. Our algorithm is constructed by combining two main elements (i) smooth value updates and (ii) the \\emph{optimistic-follow-the-regularized-leader} algorithm with the log barrier regularizer.",
        "bibtex": "@InProceedings{pmlr-v238-cai24a,\n  title = \t {Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum {M}arkov Games},\n  author =       {Cai, Yang and Luo, Haipeng and Wei, Chen-Yu and Zheng, Weiqiang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3889--3897},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cai24a/cai24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cai24a.html},\n  abstract = \t {We study policy optimization algorithms for computing correlated equilibria in multi-player general-sum Markov Games. Previous results achieve $\\tilde{O}(T^{-1/2})$ convergence rate to a correlated equilibrium and an accelerated $\\tilde{O}(T^{-3/4})$ convergence rate to the weaker notion of coarse correlated equilibrium. In this paper, we improve both results significantly by providing an uncoupled policy optimization algorithm that attains a near-optimal $\\tilde{O}(T^{-1})$ convergence rate for computing a correlated equilibrium. Our algorithm is constructed by combining two main elements (i) smooth value updates and (ii) the \\emph{optimistic-follow-the-regularized-leader} algorithm with the log barrier regularizer.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cai24a/cai24a.pdf",
        "supp": "",
        "pdf_size": 402365,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5480373652998690687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2d829170d5",
        "title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits",
        "site": "https://proceedings.mlr.press/v238/maiti24a.html",
        "author": "Arnab Maiti; Ross Boczar; Kevin Jamieson; Lillian Ratliff",
        "abstract": "We study the sample complexity of identifying the pure strategy Nash equilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally, we are given a stochastic model where any learner can sample an entry $(i,j)$ of the input matrix $A\\in [-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where $\\eta$ is a zero-mean $1$-sub-Gaussian noise. The aim of the learner is to identify the PSNE of $A$, whenever it exists, with high probability while taking as few samples as possible. Zhou et al., (2017) presents an instance-dependent sample complexity lower bound that depends only on the entries in the row and column in which the PSNE lies. We design a near-optimal algorithm whose sample complexity matches the lower bound, up to log factors. The problem of identifying the PSNE also generalizes the problem of pure exploration in stochastic multi-armed bandits and dueling bandits, and our result matches the optimal bounds, up to log factors, in both the settings.",
        "bibtex": "@InProceedings{pmlr-v238-maiti24a,\n  title = \t {Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits},\n  author =       {Maiti, Arnab and Boczar, Ross and Jamieson, Kevin and Ratliff, Lillian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2602--2610},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/maiti24a/maiti24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/maiti24a.html},\n  abstract = \t {We study the sample complexity of identifying the pure strategy Nash equilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally, we are given a stochastic model where any learner can sample an entry $(i,j)$ of the input matrix $A\\in [-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where $\\eta$ is a zero-mean $1$-sub-Gaussian noise. The aim of the learner is to identify the PSNE of $A$, whenever it exists, with high probability while taking as few samples as possible. Zhou et al., (2017) presents an instance-dependent sample complexity lower bound that depends only on the entries in the row and column in which the PSNE lies. We design a near-optimal algorithm whose sample complexity matches the lower bound, up to log factors. The problem of identifying the PSNE also generalizes the problem of pure exploration in stochastic multi-armed bandits and dueling bandits, and our result matches the optimal bounds, up to log factors, in both the settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/maiti24a/maiti24a.pdf",
        "supp": "",
        "pdf_size": 1241483,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1824525788482605027&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Washington; University of Washington; University of Washington; University of Washington",
        "aff_domain": "uw.edu;uw.edu;cs.washington.edu;uw.edu",
        "email": "uw.edu;uw.edu;cs.washington.edu;uw.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "eca166fe4e",
        "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
        "site": "https://proceedings.mlr.press/v238/nguyen24d.html",
        "author": "Quan M. Nguyen; Nishant Mehta",
        "abstract": "We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits. Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts\u2019 confidences. We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds.",
        "bibtex": "@InProceedings{pmlr-v238-nguyen24d,\n  title = \t {Near-optimal Per-Action Regret Bounds for Sleeping Bandits},\n  author =       {Nguyen, Quan M. and Mehta, Nishant},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2827--2835},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nguyen24d/nguyen24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nguyen24d.html},\n  abstract = \t {We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits. Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts\u2019 confidences. We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nguyen24d/nguyen24d.pdf",
        "supp": "",
        "pdf_size": 494135,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2371141129558993717&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Victoria; Department of Computer Science, University of Victoria",
        "aff_domain": "gmail.com;uvic.ca",
        "email": "gmail.com;uvic.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Victoria",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uvic.ca",
        "aff_unique_abbr": "UVic",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Victoria",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "2212ae19dc",
        "title": "Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean",
        "site": "https://proceedings.mlr.press/v238/frederik-thielmann24a.html",
        "author": "Anton Frederik Thielmann; Ren\u00e9-Marcel Kruse; Thomas Kneib; Benjamin S\u00e4fken",
        "abstract": "Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while maintaining the interpretability of additive models. The code is available at the following link: \\url{https://github.com/AnFreTh/NAMpy}",
        "bibtex": "@InProceedings{pmlr-v238-frederik-thielmann24a,\n  title = \t {Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean},\n  author =       {Frederik Thielmann, Anton and Kruse, Ren\\'{e}-Marcel and Kneib, Thomas and S\\\"{a}fken, Benjamin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1783--1791},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/frederik-thielmann24a/frederik-thielmann24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/frederik-thielmann24a.html},\n  abstract = \t {Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while maintaining the interpretability of additive models. The code is available at the following link: \\url{https://github.com/AnFreTh/NAMpy}}\n}",
        "pdf": "https://proceedings.mlr.press/v238/frederik-thielmann24a/frederik-thielmann24a.pdf",
        "supp": "",
        "pdf_size": 1716440,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10006764193155025399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Clausthal University of Technology + University of G\u00f6ttingen; Clausthal University of Technology + University of G\u00f6ttingen; University of G\u00f6ttingen; Clausthal University of Technology",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/AnFreTh/NAMpy",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;1;0",
        "aff_unique_norm": "Clausthal University of Technology;University of G\u00f6ttingen",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tu-clausthal.de;https://www.uni-goettingen.de",
        "aff_unique_abbr": "TUC;Georg-August-Universit\u00e4t G\u00f6ttingen",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "185a1a5def",
        "title": "Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes",
        "site": "https://proceedings.mlr.press/v238/yang24a.html",
        "author": "Haoming Yang; Ali Hasan; Yuting Ng; Vahid Tarokh",
        "abstract": "McKean-Vlasov stochastic differential equations (MV-SDEs) provide a mathematical description of the behavior of an infinite number of interacting particles by imposing a dependence on the particle density. We study the influence of explicitly including distributional information in the parameterization of the SDE. We propose a series of semi-parametric methods for representing MV-SDEs, and corresponding estimators for inferring parameters from data based on the properties of the MV-SDE. We analyze the characteristics of the different architectures and estimators, and consider their applicability in relevant machine learning problems. We empirically compare the performance of the different architectures and estimators on real and synthetic datasets for time series and probabilistic modeling. The results suggest that explicitly including distributional dependence in the parameterization of the SDE is effective in modeling temporal data with interaction under an exchangeability assumption while maintaining strong performance for standard It\u00f4-SDEs due to the richer class of probability flows associated with MV-SDEs.",
        "bibtex": "@InProceedings{pmlr-v238-yang24a,\n  title = \t {Neural {McKean}-{V}lasov Processes: Distributional Dependence in Diffusion Processes},\n  author =       {Yang, Haoming and Hasan, Ali and Ng, Yuting and Tarokh, Vahid},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {262--270},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yang24a/yang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yang24a.html},\n  abstract = \t {McKean-Vlasov stochastic differential equations (MV-SDEs) provide a mathematical description of the behavior of an infinite number of interacting particles by imposing a dependence on the particle density. We study the influence of explicitly including distributional information in the parameterization of the SDE. We propose a series of semi-parametric methods for representing MV-SDEs, and corresponding estimators for inferring parameters from data based on the properties of the MV-SDE. We analyze the characteristics of the different architectures and estimators, and consider their applicability in relevant machine learning problems. We empirically compare the performance of the different architectures and estimators on real and synthetic datasets for time series and probabilistic modeling. The results suggest that explicitly including distributional dependence in the parameterization of the SDE is effective in modeling temporal data with interaction under an exchangeability assumption while maintaining strong performance for standard It\u00f4-SDEs due to the richer class of probability flows associated with MV-SDEs.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yang24a/yang24a.pdf",
        "supp": "",
        "pdf_size": 6339413,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1660568357910387140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Duke University; Duke University; Duke University; Duke University",
        "aff_domain": "duke.edu;duke.edu;duke.edu;duke.edu",
        "email": "duke.edu;duke.edu;duke.edu;duke.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "584f5eed1a",
        "title": "No-Regret Algorithms for Safe Bayesian Optimization with Monotonicity Constraints",
        "site": "https://proceedings.mlr.press/v238/losalka24a.html",
        "author": "Arpan Losalka; Jonathan Scarlett",
        "abstract": "We consider the problem of sequentially maximizing an unknown function $f$ over a set of actions of the form $(s, x)$, where the selected actions must satisfy a safety constraint with respect to an unknown safety function $g$. We model $f$ and $g$ as lying in a reproducing kernel Hilbert space (RKHS), which facilitates the use of Gaussian process methods. While existing works for this setting have provided algorithms that are guaranteed to identify a near-optimal safe action, the problem of attaining low cumulative regret has remained largely unexplored, with a key challenge being that expanding the safe region can incur high regret. To address this challenge, we show that if $g$ is monotone with respect to just the single variable $s$ (with no such constraint on $f$), sublinear regret becomes achievable with our proposed algorithm. In addition, we show that a modified version of our algorithm is able to attain sublinear regret (for suitably defined notions of regret) for the task of finding a near-optimal $s$ corresponding to every $x$, as opposed to only finding the global safe optimum. Our findings are supported with empirical evaluations on various objective and safety functions.",
        "bibtex": "@InProceedings{pmlr-v238-losalka24a,\n  title = \t {No-Regret Algorithms for Safe {B}ayesian Optimization with Monotonicity Constraints},\n  author =       {Losalka, Arpan and Scarlett, Jonathan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3232--3240},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/losalka24a/losalka24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/losalka24a.html},\n  abstract = \t {We consider the problem of sequentially maximizing an unknown function $f$ over a set of actions of the form $(s, x)$, where the selected actions must satisfy a safety constraint with respect to an unknown safety function $g$. We model $f$ and $g$ as lying in a reproducing kernel Hilbert space (RKHS), which facilitates the use of Gaussian process methods. While existing works for this setting have provided algorithms that are guaranteed to identify a near-optimal safe action, the problem of attaining low cumulative regret has remained largely unexplored, with a key challenge being that expanding the safe region can incur high regret. To address this challenge, we show that if $g$ is monotone with respect to just the single variable $s$ (with no such constraint on $f$), sublinear regret becomes achievable with our proposed algorithm. In addition, we show that a modified version of our algorithm is able to attain sublinear regret (for suitably defined notions of regret) for the task of finding a near-optimal $s$ corresponding to every $x$, as opposed to only finding the global safe optimum. Our findings are supported with empirical evaluations on various objective and safety functions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/losalka24a/losalka24a.pdf",
        "supp": "",
        "pdf_size": 4330699,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8487588112606450354&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "National University of Singapore; National University of Singapore",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "5567a5c562",
        "title": "NoisyMix: Boosting Model Robustness to Common Corruptions",
        "site": "https://proceedings.mlr.press/v238/erichson24a.html",
        "author": "Benjamin Erichson; Soon Hoe Lim; Winnie Xu; Francisco Utrera; Ziang Cao; Michael Mahoney",
        "abstract": "The robustness of neural networks has become increasingly important in real-world applications where stable and reliable performance is valued over simply achieving high predictive accuracy. To address this, data augmentation techniques have been shown to improve robustness against input perturbations and domain shifts. In this paper, we propose a new training scheme called NoisyMix that leverages noisy augmentations in both input and feature space to improve model robustness and in-domain accuracy. We demonstrate the effectiveness of NoisyMix on several benchmark datasets, including ImageNet-C, ImageNet-R, and ImageNet-P. Additionally, we provide theoretical analysis to better understand the implicit regularization and robustness properties of NoisyMix.",
        "bibtex": "@InProceedings{pmlr-v238-erichson24a,\n  title = \t {{NoisyMix}: Boosting Model Robustness to Common Corruptions},\n  author =       {Erichson, Benjamin and Hoe Lim, Soon and Xu, Winnie and Utrera, Francisco and Cao, Ziang and Mahoney, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4033--4041},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/erichson24a/erichson24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/erichson24a.html},\n  abstract = \t {The robustness of neural networks has become increasingly important in real-world applications where stable and reliable performance is valued over simply achieving high predictive accuracy. To address this, data augmentation techniques have been shown to improve robustness against input perturbations and domain shifts. In this paper, we propose a new training scheme called NoisyMix that leverages noisy augmentations in both input and feature space to improve model robustness and in-domain accuracy. We demonstrate the effectiveness of NoisyMix on several benchmark datasets, including ImageNet-C, ImageNet-R, and ImageNet-P. Additionally, we provide theoretical analysis to better understand the implicit regularization and robustness properties of NoisyMix.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/erichson24a/erichson24a.pdf",
        "supp": "",
        "pdf_size": 2226627,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13777201528053288612&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "ICSI, LBNL; Nordita, KTH, Stockholm University; University of Toronto; ICSI; Stanford University; ICSI, UC Berkeley, LBNL",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;3;4",
        "aff_unique_norm": "International Computer Science Institute;KTH - Royal Institute of Technology;University of Toronto;Stanford University;University of California, Berkeley",
        "aff_unique_dep": ";Nordita;;;International Computer Science Institute",
        "aff_unique_url": "https://www.icsi.berkeley.edu;https://www.kth.se;https://www.utoronto.ca;https://www.stanford.edu;https://www.icsi.berkeley.edu",
        "aff_unique_abbr": "ICSI;KTH;U of T;Stanford;UC Berkeley",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stanford;Berkeley",
        "aff_country_unique_index": "0;1;2;0;0;0",
        "aff_country_unique": "United States;Sweden;Canada"
    },
    {
        "id": "9ea9466295",
        "title": "Non-Convex Joint Community Detection and Group Synchronization via Generalized Power Method",
        "site": "https://proceedings.mlr.press/v238/chen24e.html",
        "author": "Sijin Chen; Xiwei Cheng; Anthony Man-Cho So",
        "abstract": "This paper proposes a Generalized Power Method (GPM) to simultaneously solve the joint problem of community detection and group synchronization in a direct non-convex manner, in contrast to the existing method of semidefinite programming (SDP). Under a natural extension of stochastic block model (SBM), our theoretical analysis proves that the proposed algorithm is able to exactly recover the ground truth in $O(n\\log^2 n)$ time for problems of size $n$, sharply outperforming the $O(n^{3.5})$ runtime of SDP. Moreover, we give a lower bound of model parameters as a sufficient condition for the exact recovery of GPM. The new bound breaches the information-theoretic limit for pure community detection under SBM, thus demonstrating the superiority of our simultaneous optimization algorithm over any two-stage method that performs the two tasks in succession. We also conduct numerical experiments on GPM and SDP to corroborate our theoretical analysis.",
        "bibtex": "@InProceedings{pmlr-v238-chen24e,\n  title = \t {Non-Convex Joint Community Detection and Group Synchronization via Generalized Power Method},\n  author =       {Chen, Sijin and Cheng, Xiwei and Man-Cho So, Anthony},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2899--2907},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chen24e/chen24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chen24e.html},\n  abstract = \t {This paper proposes a Generalized Power Method (GPM) to simultaneously solve the joint problem of community detection and group synchronization in a direct non-convex manner, in contrast to the existing method of semidefinite programming (SDP). Under a natural extension of stochastic block model (SBM), our theoretical analysis proves that the proposed algorithm is able to exactly recover the ground truth in $O(n\\log^2 n)$ time for problems of size $n$, sharply outperforming the $O(n^{3.5})$ runtime of SDP. Moreover, we give a lower bound of model parameters as a sufficient condition for the exact recovery of GPM. The new bound breaches the information-theoretic limit for pure community detection under SBM, thus demonstrating the superiority of our simultaneous optimization algorithm over any two-stage method that performs the two tasks in succession. We also conduct numerical experiments on GPM and SDP to corroborate our theoretical analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chen24e/chen24e.pdf",
        "supp": "",
        "pdf_size": 1788743,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3032422199903183069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "744b03132b",
        "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
        "site": "https://proceedings.mlr.press/v238/li24b.html",
        "author": "Zhishuai Li; Yunhao Nie; Ziyue Li; Lei Bai; Yisheng Lv; Rui Zhao",
        "abstract": "Kriging aims to estimate the attributes of unseen geo-locations from observations in the spatial vicinity or physical connections. Existing works assume that neighbors\u2019 information offers the basis for estimating the unobserved target while ignoring non-neighbors. However, neighbors could also be quite different or even misleading, and the non-neighbors could still offer constructive information. To this end, we propose \"Contrastive-Prototypical\" self-supervised learning for Kriging (KCP): (1) The neighboring contrastive module coarsely pushes neighbors together and non-neighbors apart. (2) In parallel, the prototypical module identifies similar representations via exchanged prediction, such that it refines the misleading neighbors and recycles the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. (3) To learn general and robust representations, we design an adaptive augmentation module that encourages data diversity. Theoretical bound is derived for the proposed augmentation. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness.",
        "bibtex": "@InProceedings{pmlr-v238-li24b,\n  title = \t {Non-Neighbors Also Matter to {K}riging: A New Contrastive-Prototypical Learning},\n  author =       {Li, Zhishuai and Nie, Yunhao and Li, Ziyue and Bai, Lei and Lv, Yisheng and Zhao, Rui},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {46--54},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24b/li24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24b.html},\n  abstract = \t {Kriging aims to estimate the attributes of unseen geo-locations from observations in the spatial vicinity or physical connections. Existing works assume that neighbors\u2019 information offers the basis for estimating the unobserved target while ignoring non-neighbors. However, neighbors could also be quite different or even misleading, and the non-neighbors could still offer constructive information. To this end, we propose \"Contrastive-Prototypical\" self-supervised learning for Kriging (KCP): (1) The neighboring contrastive module coarsely pushes neighbors together and non-neighbors apart. (2) In parallel, the prototypical module identifies similar representations via exchanged prediction, such that it refines the misleading neighbors and recycles the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. (3) To learn general and robust representations, we design an adaptive augmentation module that encourages data diversity. Theoretical bound is derived for the proposed augmentation. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24b/li24b.pdf",
        "supp": "",
        "pdf_size": 8069287,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17219211731731120684&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "SenseTime Research; SenseTime Research + Chinese Academy of Sciences; University of Cologne; Shanghai AI Laboratory; Chinese Academy of Sciences; SenseTime Research",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;2;3;1;0",
        "aff_unique_norm": "SenseTime;Chinese Academy of Sciences;University of Cologne;Shanghai AI Laboratory",
        "aff_unique_dep": "SenseTime Research;;;",
        "aff_unique_url": "https://www.sensetime.com;https://www.cas.cn;https://www.uni-koeln.de/;https://www.shanghai-ai-lab.com",
        "aff_unique_abbr": "SenseTime;CAS;UC;SAIL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;1;0;0;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "73bd95b470",
        "title": "Non-vacuous Generalization Bounds for Adversarial Risk in Stochastic Neural Networks",
        "site": "https://proceedings.mlr.press/v238/mustafa24a.html",
        "author": "Waleed Mustafa; Philipp Liznerski; Antoine Ledent; Dennis Wagner; Puyu Wang; Marius Kloft",
        "abstract": "Adversarial examples are manipulated samples used to deceive machine learning models, posing a serious threat in safety-critical applications. Existing safety certificates for machine learning models are limited to individual input examples, failing to capture generalization to unseen data. To address this limitation, we propose novel generalization bounds based on the PAC-Bayesian and randomized smoothing frameworks, providing certificates that predict the model\u2019s performance and robustness on unseen test samples based solely on the training data. We present an effective procedure to train and compute the first non-vacuous generalization bounds for neural networks in adversarial settings. Experimental results on the widely recognized MNIST and CIFAR-10 datasets demonstrate the efficacy of our approach, yielding the first robust risk certificates for stochastic convolutional neural networks under the $L_2$ threat model. Our method offers valuable tools for evaluating model susceptibility to real-world adversarial risks.",
        "bibtex": "@InProceedings{pmlr-v238-mustafa24a,\n  title = \t {Non-vacuous Generalization Bounds for Adversarial Risk in Stochastic Neural Networks},\n  author =       {Mustafa, Waleed and Liznerski, Philipp and Ledent, Antoine and Wagner, Dennis and Wang, Puyu and Kloft, Marius},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4528--4536},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mustafa24a/mustafa24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mustafa24a.html},\n  abstract = \t {Adversarial examples are manipulated samples used to deceive machine learning models, posing a serious threat in safety-critical applications. Existing safety certificates for machine learning models are limited to individual input examples, failing to capture generalization to unseen data. To address this limitation, we propose novel generalization bounds based on the PAC-Bayesian and randomized smoothing frameworks, providing certificates that predict the model\u2019s performance and robustness on unseen test samples based solely on the training data. We present an effective procedure to train and compute the first non-vacuous generalization bounds for neural networks in adversarial settings. Experimental results on the widely recognized MNIST and CIFAR-10 datasets demonstrate the efficacy of our approach, yielding the first robust risk certificates for stochastic convolutional neural networks under the $L_2$ threat model. Our method offers valuable tools for evaluating model susceptibility to real-world adversarial risks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mustafa24a/mustafa24a.pdf",
        "supp": "",
        "pdf_size": 948731,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1375093529710271212&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "RPTU, Kaiserslautern, Germany; RPTU, Kaiserslautern, Germany; Singapore Management University, Singapore; RPTU, Kaiserslautern, Germany; Hong Kong Baptist University, Hong Kong, China; RPTU, Kaiserslautern, Germany",
        "aff_domain": "; ;smu.edu.sg; ; ; ",
        "email": "; ;smu.edu.sg; ; ; ",
        "github": "https://github.com/waleedamustafa/nonadvgenaistats",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2;0",
        "aff_unique_norm": "Technische Universit\u00e4t Kaiserslautern;Singapore Management University;Hong Kong Baptist University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.rptu.de;https://www.smu.edu.sg;https://www.hkbu.edu.hk",
        "aff_unique_abbr": "TU Kaiserslautern;SMU;HKBU",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Kaiserslautern;;Hong Kong",
        "aff_country_unique_index": "0;0;1;0;2;0",
        "aff_country_unique": "Germany;Singapore;China"
    },
    {
        "id": "e0b156b781",
        "title": "Nonparametric Automatic Differentiation Variational Inference with Spline Approximation",
        "site": "https://proceedings.mlr.press/v238/shao24a.html",
        "author": "Yuda Shao; Shan N Yu; Tianshu Feng",
        "abstract": "Automatic Differentiation Variational Inference (ADVI) is efficient in learning probabilistic models. Classic ADVI relies on the parametric approach to approximate the posterior. In this paper, we develop a spline-based nonparametric approximation approach that enables flexible posterior approximation for distributions with complicated structures, such as skewness, multimodality, and bounded support. Compared with widely-used nonparametric variational inference methods, the proposed method is easy to implement and adaptive to various data structures. By adopting the spline approximation, we derive a lower bound of the importance weighted autoencoder and establish the asymptotic consistency. Experiments demonstrate the efficiency of the proposed method in approximating complex posterior distributions and improving the performance of generative models with incomplete data.",
        "bibtex": "@InProceedings{pmlr-v238-shao24a,\n  title = \t {Nonparametric Automatic Differentiation Variational Inference with Spline Approximation},\n  author =       {Shao, Yuda and N Yu, Shan and Feng, Tianshu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2656--2664},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shao24a/shao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shao24a.html},\n  abstract = \t {Automatic Differentiation Variational Inference (ADVI) is efficient in learning probabilistic models. Classic ADVI relies on the parametric approach to approximate the posterior. In this paper, we develop a spline-based nonparametric approximation approach that enables flexible posterior approximation for distributions with complicated structures, such as skewness, multimodality, and bounded support. Compared with widely-used nonparametric variational inference methods, the proposed method is easy to implement and adaptive to various data structures. By adopting the spline approximation, we derive a lower bound of the importance weighted autoencoder and establish the asymptotic consistency. Experiments demonstrate the efficiency of the proposed method in approximating complex posterior distributions and improving the performance of generative models with incomplete data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shao24a/shao24a.pdf",
        "supp": "",
        "pdf_size": 9833507,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9137104615229126285&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Virginia; University of Virginia; George Mason University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Virginia;George Mason University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.virginia.edu;https://www.gmu.edu",
        "aff_unique_abbr": "UVA;GMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "df72199b60",
        "title": "Offline Policy Evaluation and Optimization Under Confounding",
        "site": "https://proceedings.mlr.press/v238/kausik24a.html",
        "author": "Chinmaya Kausik; Yangyi Lu; Kevin Tan; Maggie Makar; Yixin Wang; Ambuj Tewari",
        "abstract": "Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on whether they are memoryless and on their effect on the data-collection policies. We characterize settings where consistent value estimates are provably not achievable, and provide algorithms with guarantees to instead estimate lower bounds on the value. When consistent estimates are achievable, we provide algorithms for value estimation with sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on both a gridworld environment and a simulated healthcare setting of managing sepsis patients. In gridworld, our model-based method provides tighter lower bounds than existing methods, while in the sepsis simulator, we demonstrate the effectiveness of our method and investigate the importance of a clustering sub-routine.",
        "bibtex": "@InProceedings{pmlr-v238-kausik24a,\n  title = \t {Offline Policy Evaluation and Optimization Under Confounding},\n  author =       {Kausik, Chinmaya and Lu, Yangyi and Tan, Kevin and Makar, Maggie and Wang, Yixin and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1459--1467},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kausik24a/kausik24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kausik24a.html},\n  abstract = \t {Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on whether they are memoryless and on their effect on the data-collection policies. We characterize settings where consistent value estimates are provably not achievable, and provide algorithms with guarantees to instead estimate lower bounds on the value. When consistent estimates are achievable, we provide algorithms for value estimation with sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on both a gridworld environment and a simulated healthcare setting of managing sepsis patients. In gridworld, our model-based method provides tighter lower bounds than existing methods, while in the sepsis simulator, we demonstrate the effectiveness of our method and investigate the importance of a clustering sub-routine.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kausik24a/kausik24a.pdf",
        "supp": "",
        "pdf_size": 888293,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10161303624672689633&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Michigan; Pinterest; University of Pennsylvania; University of Michigan; University of Michigan; University of Michigan",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "University of Michigan;Pinterest;University of Pennsylvania",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.umich.edu;https://www.pinterest.com;https://www.upenn.edu",
        "aff_unique_abbr": "UM;Pinterest;UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f8210dfa3c",
        "title": "Offline Primal-Dual Reinforcement Learning for Linear MDPs",
        "site": "https://proceedings.mlr.press/v238/gabbianelli24a.html",
        "author": "Germano Gabbianelli; Gergely Neu; Matteo Papini; Nneka M Okolo",
        "abstract": "Offline Reinforcement Learning (RL) aims to learn a near-optimal policy from a fixed dataset of transitions collected by another policy. This problem has attracted a lot of attention recently, but most existing methods with strong theoretical guarantees are restricted to finite-horizon or tabular settings. In contrast, few algorithms for infinite-horizon settings with function approximation and minimal assumptions on the dataset are both sample and computationally efficient. Another gap in the current literature is the lack of theoretical analysis for the average-reward setting, which is more challenging than the discounted setting. In this paper, we address both of these issues by proposing a primal-dual optimization method based on the linear programming formulation of RL. Our key contribution is a new reparametrization that allows us to derive low-variance gradient estimators that can be used in a stochastic optimization scheme using only samples from the behavior policy. Our method finds an $\\varepsilon$-optimal policy with $O(\\varepsilon^{-4})$ samples, while being computationally efficient for infinite-horizon discounted and average-reward MDPs with realizable linear function approximation and partial coverage. Moreover, to the best of our knowledge, this is the first theoretical result for average-reward offline RL.",
        "bibtex": "@InProceedings{pmlr-v238-gabbianelli24a,\n  title = \t {Offline Primal-Dual Reinforcement Learning for Linear {MDPs}},\n  author =       {Gabbianelli, Germano and Neu, Gergely and Papini, Matteo and M Okolo, Nneka},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3169--3177},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gabbianelli24a/gabbianelli24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gabbianelli24a.html},\n  abstract = \t {Offline Reinforcement Learning (RL) aims to learn a near-optimal policy from a fixed dataset of transitions collected by another policy. This problem has attracted a lot of attention recently, but most existing methods with strong theoretical guarantees are restricted to finite-horizon or tabular settings. In contrast, few algorithms for infinite-horizon settings with function approximation and minimal assumptions on the dataset are both sample and computationally efficient. Another gap in the current literature is the lack of theoretical analysis for the average-reward setting, which is more challenging than the discounted setting. In this paper, we address both of these issues by proposing a primal-dual optimization method based on the linear programming formulation of RL. Our key contribution is a new reparametrization that allows us to derive low-variance gradient estimators that can be used in a stochastic optimization scheme using only samples from the behavior policy. Our method finds an $\\varepsilon$-optimal policy with $O(\\varepsilon^{-4})$ samples, while being computationally efficient for infinite-horizon discounted and average-reward MDPs with realizable linear function approximation and partial coverage. Moreover, to the best of our knowledge, this is the first theoretical result for average-reward offline RL.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gabbianelli24a/gabbianelli24a.pdf",
        "supp": "",
        "pdf_size": 847792,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10789280168597606094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "123c143266",
        "title": "On Convergence in Wasserstein Distance and f-divergence Minimization Problems",
        "site": "https://proceedings.mlr.press/v238/ting-li24a.html",
        "author": "Cheuk Ting Li; Jingwei Zhang; Farzan Farnia",
        "abstract": "The zero-sum game in generative adversarial networks (GANs) for learning the distribution of observed data is known to reduce to the minimization of a divergence measure between the underlying and generative models. However, the current theoretical understanding of the role of the target divergence in the characteristics of GANs\u2019 generated samples remains largely inadequate. In this work, we aim to analyze the influence of the divergence measure on the local optima and convergence properties of divergence minimization problems in learning a multi-modal data distribution. We show a mode-seeking f-divergence, e.g. the Jensen-Shannon (JS) divergence in the vanilla GAN, could lead to poor locally optimal solutions missing some underlying modes. On the other hand, we demonstrate that the optimization landscape of 1-Wasserstein distance in Wasserstein GANs does not suffer from such suboptimal local minima. Furthermore, we prove that a randomly-initialized gradient-based optimization of the Wasserstein distance will, with high probability, capture all the existing modes. We present numerical results on standard image datasets, revealing the success of Wasserstein GANs compared to JS-GANs in avoiding suboptimal local optima under a mixture model.",
        "bibtex": "@InProceedings{pmlr-v238-ting-li24a,\n  title = \t {On Convergence in {W}asserstein Distance and f-divergence Minimization Problems},\n  author =       {Ting Li, Cheuk and Zhang, Jingwei and Farnia, Farzan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2062--2070},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ting-li24a/ting-li24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ting-li24a.html},\n  abstract = \t {The zero-sum game in generative adversarial networks (GANs) for learning the distribution of observed data is known to reduce to the minimization of a divergence measure between the underlying and generative models. However, the current theoretical understanding of the role of the target divergence in the characteristics of GANs\u2019 generated samples remains largely inadequate. In this work, we aim to analyze the influence of the divergence measure on the local optima and convergence properties of divergence minimization problems in learning a multi-modal data distribution. We show a mode-seeking f-divergence, e.g. the Jensen-Shannon (JS) divergence in the vanilla GAN, could lead to poor locally optimal solutions missing some underlying modes. On the other hand, we demonstrate that the optimization landscape of 1-Wasserstein distance in Wasserstein GANs does not suffer from such suboptimal local minima. Furthermore, we prove that a randomly-initialized gradient-based optimization of the Wasserstein distance will, with high probability, capture all the existing modes. We present numerical results on standard image datasets, revealing the success of Wasserstein GANs compared to JS-GANs in avoiding suboptimal local optima under a mixture model.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ting-li24a/ting-li24a.pdf",
        "supp": "",
        "pdf_size": 3348820,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11101138717061713690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1f8be4d565",
        "title": "On Counterfactual Metrics for Social Welfare: Incentives, Ranking, and Information Asymmetry",
        "site": "https://proceedings.mlr.press/v238/wang24b.html",
        "author": "Serena Wang; Stephen Bates; P Aronow; Michael Jordan",
        "abstract": "From the social sciences to machine learning, it is well documented that metrics do not always align with social welfare. In healthcare, Dranove et al. (2003) showed that publishing surgery mortality metrics actually harmed sicker patients by increasing provider selection behavior. Using a principal-agent model, we analyze the incentive misalignments that arise from such average treated outcome metrics, and show that the incentives driving treatment decisions would align with maximizing total patient welfare if the metrics (i) accounted for counterfactual untreated outcomes and (ii) considered total welfare instead of averaging over treated patients. Operationalizing this, we show how counterfactual metrics can be modified to behave reasonably in patient-facing ranking systems. Extending to realistic settings when providers observe more about patients than the regulatory agencies do, we bound the decay in performance by the degree of information asymmetry between principal and agent. In doing so, our model connects principal-agent information asymmetry with unobserved heterogeneity in causal inference.",
        "bibtex": "@InProceedings{pmlr-v238-wang24b,\n  title = \t {On Counterfactual Metrics for Social Welfare: Incentives, Ranking, and Information Asymmetry},\n  author =       {Wang, Serena and Bates, Stephen and Aronow, P and Jordan, Michael},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1522--1530},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24b/wang24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24b.html},\n  abstract = \t {From the social sciences to machine learning, it is well documented that metrics do not always align with social welfare. In healthcare, Dranove et al. (2003) showed that publishing surgery mortality metrics actually harmed sicker patients by increasing provider selection behavior. Using a principal-agent model, we analyze the incentive misalignments that arise from such average treated outcome metrics, and show that the incentives driving treatment decisions would align with maximizing total patient welfare if the metrics (i) accounted for counterfactual untreated outcomes and (ii) considered total welfare instead of averaging over treated patients. Operationalizing this, we show how counterfactual metrics can be modified to behave reasonably in patient-facing ranking systems. Extending to realistic settings when providers observe more about patients than the regulatory agencies do, we bound the decay in performance by the degree of information asymmetry between principal and agent. In doing so, our model connects principal-agent information asymmetry with unobserved heterogeneity in causal inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24b/wang24b.pdf",
        "supp": "",
        "pdf_size": 598642,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=971449653927948667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7ed73ced66",
        "title": "On Feynman-Kac training of partial Bayesian neural networks",
        "site": "https://proceedings.mlr.press/v238/zhao24b.html",
        "author": "Zheng Zhao; Sebastian Mair; Thomas B. Sch\u00f6n; Jens Sj\u00f6lund",
        "abstract": "Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman-Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. Using various synthetic and real-world datasets we show that our proposed training scheme outperforms the state of the art in terms of predictive performance.",
        "bibtex": "@InProceedings{pmlr-v238-zhao24b,\n  title = \t {On {F}eynman-{K}ac training of partial {B}ayesian neural networks},\n  author =       {Zhao, Zheng and Mair, Sebastian and B. Sch\\\"{o}n, Thomas and Sj\\\"{o}lund, Jens},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3223--3231},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhao24b/zhao24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhao24b.html},\n  abstract = \t {Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman-Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. Using various synthetic and real-world datasets we show that our proposed training scheme outperforms the state of the art in terms of predictive performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhao24b/zhao24b.pdf",
        "supp": "",
        "pdf_size": 2063201,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18084592364011704584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f6f432ebe",
        "title": "On Parameter Estimation in Deviated Gaussian Mixture of Experts",
        "site": "https://proceedings.mlr.press/v238/nguyen24a.html",
        "author": "Huy Nguyen; Khai Nguyen; Nhat Ho",
        "abstract": "We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \\lambda^{\\ast}) g_0(Y| X)+ \\lambda^{\\ast} \\sum_{i = 1}^{k_{\\ast}} p_{i}^{\\ast} f(Y|(a_{i}^{\\ast})^{\\top}X+b_i^{\\ast},\\sigma_{i}^{\\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\\lambda^{\\ast} \\in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\\ast}, a_{i}^{\\ast}, b_{i}^{\\ast}, \\sigma_{i}^{\\ast})$ for $1 \\leq i \\leq k^{\\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the convergence rates of maximum likelihood estimation (MLE) for our models. We further demonstrate that our proposed loss functions characterize the local convergence rates of parameter estimation more accurately than the generalized Wasserstein, a loss function being commonly used for estimating parameters in the Gaussian mixture of experts.",
        "bibtex": "@InProceedings{pmlr-v238-nguyen24a,\n  title = \t {On Parameter Estimation in Deviated {G}aussian Mixture of Experts},\n  author =       {Nguyen, Huy and Nguyen, Khai and Ho, Nhat},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2674--2682},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nguyen24a/nguyen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nguyen24a.html},\n  abstract = \t {We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \\lambda^{\\ast}) g_0(Y| X)+ \\lambda^{\\ast} \\sum_{i = 1}^{k_{\\ast}} p_{i}^{\\ast} f(Y|(a_{i}^{\\ast})^{\\top}X+b_i^{\\ast},\\sigma_{i}^{\\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\\lambda^{\\ast} \\in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\\ast}, a_{i}^{\\ast}, b_{i}^{\\ast}, \\sigma_{i}^{\\ast})$ for $1 \\leq i \\leq k^{\\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the convergence rates of maximum likelihood estimation (MLE) for our models. We further demonstrate that our proposed loss functions characterize the local convergence rates of parameter estimation more accurately than the generalized Wasserstein, a loss function being commonly used for estimating parameters in the Gaussian mixture of experts.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nguyen24a/nguyen24a.pdf",
        "supp": "",
        "pdf_size": 1121420,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12268358042787441243&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "36dd8a5862",
        "title": "On Ranking-based Tests of Independence",
        "site": "https://proceedings.mlr.press/v238/limnios24a.html",
        "author": "Myrto Limnios; St\u00e9phan Cl\u00e9men\u00e7on",
        "abstract": "In this paper we develop a novel nonparametric framework to test the independence of two random variables $X$ and $Y$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dxdy)$, based on Receiver Operating Characteristic (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\\mathcal{H}_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\\otimes G,;{F})$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square. We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two types of testing errors are established. From an empirical perspective, the novel procedure we promote in this paper exhibits a remarkable ability to detect small departures, of various types, from the null assumption $\\mathcal{H}_0$, even in high dimension, as supported by the numerical experiments presented here.",
        "bibtex": "@InProceedings{pmlr-v238-limnios24a,\n  title = \t {On Ranking-based Tests of Independence},\n  author =       {Limnios, Myrto and Cl\\'{e}men\\c{c}on, St\\'{e}phan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {577--585},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/limnios24a/limnios24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/limnios24a.html},\n  abstract = \t {In this paper we develop a novel nonparametric framework to test the independence of two random variables $X$ and $Y$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dxdy)$, based on Receiver Operating Characteristic (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\\mathcal{H}_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\\otimes G,;{F})$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square. We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two types of testing errors are established. From an empirical perspective, the novel procedure we promote in this paper exhibits a remarkable ability to detect small departures, of various types, from the null assumption $\\mathcal{H}_0$, even in high dimension, as supported by the numerical experiments presented here.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/limnios24a/limnios24a.pdf",
        "supp": "",
        "pdf_size": 1055443,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13788241614987392196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mathematical Sciences, University of Copenhagen, Copenhagen, Denmark; Telecom Paris, LTCI, Institut Polytechnique de Paris, Palaiseau, France",
        "aff_domain": "math.ku.dk;telecom-paris.fr",
        "email": "math.ku.dk;telecom-paris.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Copenhagen;Telecom Paris",
        "aff_unique_dep": "Department of Mathematical Sciences;LTCI",
        "aff_unique_url": "https://www.ku.dk;https://www.telecom-paris.fr",
        "aff_unique_abbr": "UCPH;Telecom Paris",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Copenhagen;Palaiseau",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Denmark;France"
    },
    {
        "id": "f1ff4fda0a",
        "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural Networks",
        "site": "https://proceedings.mlr.press/v238/eliasof24a.html",
        "author": "Moshe Eliasof; Eldad Haber; Eran Treister; Carola-Bibiane B Sch\u00f6nlieb",
        "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling complex relationships in graph-structured data. A recent innovation in this field is the family of Differential Equation-Inspired Graph Neural Networks (DE-GNNs), which leverage principles from continuous dynamical systems to model information flow on graphs with built-in properties such as feature smoothing or preservation. However, existing DE-GNNs rely on first or second-order temporal dependencies. In this paper, we propose a neural extension to those pre-defined temporal dependencies. We show that our model, called TDE-GNN, can capture a wide range of temporal dynamics that go beyond typical first or second-order methods, and provide use cases where existing temporal models are challenged. We demonstrate the benefit of learning the temporal dependencies using our method rather than using pre-defined temporal dynamics on several graph benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-eliasof24a,\n  title = \t {On The Temporal Domain of Differential Equation Inspired Graph Neural Networks},\n  author =       {Eliasof, Moshe and Haber, Eldad and Treister, Eran and B Sch\\\"{o}nlieb, Carola-Bibiane},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1792--1800},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/eliasof24a/eliasof24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/eliasof24a.html},\n  abstract = \t {Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling complex relationships in graph-structured data. A recent innovation in this field is the family of Differential Equation-Inspired Graph Neural Networks (DE-GNNs), which leverage principles from continuous dynamical systems to model information flow on graphs with built-in properties such as feature smoothing or preservation. However, existing DE-GNNs rely on first or second-order temporal dependencies. In this paper, we propose a neural extension to those pre-defined temporal dependencies. We show that our model, called TDE-GNN, can capture a wide range of temporal dynamics that go beyond typical first or second-order methods, and provide use cases where existing temporal models are challenged. We demonstrate the benefit of learning the temporal dependencies using our method rather than using pre-defined temporal dynamics on several graph benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/eliasof24a/eliasof24a.pdf",
        "supp": "",
        "pdf_size": 1576816,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3905255412622940761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f22127081b",
        "title": "On cyclical MCMC sampling",
        "site": "https://proceedings.mlr.press/v238/wang24k.html",
        "author": "Liwei Wang; Xinru Liu; Aaron Smith; Aguemon Y Atchade",
        "abstract": "Cyclical MCMC is a novel MCMC framework recently proposed by Zhang et al. (2019) to address the challenge posed by high- dimensional multimodal posterior distributions like those arising in deep learning. The algorithm works by generating a nonhomogeneous Markov chain that tracks \u2014cyclically in time\u2014 tempered versions of the target distribution. We show in this work that cyclical MCMC converges to the desired probability distribution in settings where the Markov kernels used are fast mixing, and sufficiently long cycles are employed. However in the far more common settings of slow mixing kernels, the algorithm may fail to produce samples from the desired distribution. In particular, in a simple mixture example with unequal variance we show by simulation that cyclical MCMC fails to converge to the desired limit. Finally, we show that cyclical MCMC typically estimates well the local shape of the target distribution around each mode, even when we do not have convergence to the target.",
        "bibtex": "@InProceedings{pmlr-v238-wang24k,\n  title = \t {On cyclical {MCMC} sampling},\n  author =       {Wang, Liwei and Liu, Xinru and Smith, Aaron and Y Atchade, Aguemon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3817--3825},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24k/wang24k.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24k.html},\n  abstract = \t {Cyclical MCMC is a novel MCMC framework recently proposed by Zhang et al. (2019) to address the challenge posed by high- dimensional multimodal posterior distributions like those arising in deep learning. The algorithm works by generating a nonhomogeneous Markov chain that tracks \u2014cyclically in time\u2014 tempered versions of the target distribution. We show in this work that cyclical MCMC converges to the desired probability distribution in settings where the Markov kernels used are fast mixing, and sufficiently long cycles are employed. However in the far more common settings of slow mixing kernels, the algorithm may fail to produce samples from the desired distribution. In particular, in a simple mixture example with unequal variance we show by simulation that cyclical MCMC fails to converge to the desired limit. Finally, we show that cyclical MCMC typically estimates well the local shape of the target distribution around each mode, even when we do not have convergence to the target.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24k/wang24k.pdf",
        "supp": "",
        "pdf_size": 528755,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3366434678899322232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0bc191dbb3",
        "title": "On learning history-based policies for controlling Markov decision processes",
        "site": "https://proceedings.mlr.press/v238/patil24b.html",
        "author": "Gandharv Patil; Aditya Mahajan; Doina Precup",
        "abstract": "Reinforcement learning (RL) folklore suggests that methods of function approximation based on history, such as recurrent neural networks or state abstractions that include past information, outperform those without memory, because function approximation in Markov decision processes (MDP) can lead to a scenario akin to dealing with a partially observable MDP (POMDP). However, formal analysis of history-based algorithms has been limited, with most existing frameworks concentrating on features without historical context. In this paper, we introduce a theoretical framework to examine the behaviour of RL algorithms that control an MDP using feature abstraction mappings based on historical data. Additionally, we leverage this framework to develop a practical RL algorithm and assess its performance across various continuous control tasks.",
        "bibtex": "@InProceedings{pmlr-v238-patil24b,\n  title = \t {On learning history-based policies for controlling {M}arkov decision processes},\n  author =       {Patil, Gandharv and Mahajan, Aditya and Precup, Doina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3511--3519},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/patil24b/patil24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/patil24b.html},\n  abstract = \t {Reinforcement learning (RL) folklore suggests that methods of function approximation based on history, such as recurrent neural networks or state abstractions that include past information, outperform those without memory, because function approximation in Markov decision processes (MDP) can lead to a scenario akin to dealing with a partially observable MDP (POMDP). However, formal analysis of history-based algorithms has been limited, with most existing frameworks concentrating on features without historical context. In this paper, we introduce a theoretical framework to examine the behaviour of RL algorithms that control an MDP using feature abstraction mappings based on historical data. Additionally, we leverage this framework to develop a practical RL algorithm and assess its performance across various continuous control tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/patil24b/patil24b.pdf",
        "supp": "",
        "pdf_size": 3093589,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8631103190848540956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a70231fad4",
        "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem",
        "site": "https://proceedings.mlr.press/v238/pichler24a.html",
        "author": "Georg Pichler; Marco Romanelli; Divya Prakash Manivannan; Prashanth Krishnamurthy; Farshad khorrami; Siddharth Garg",
        "abstract": "We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.",
        "bibtex": "@InProceedings{pmlr-v238-pichler24a,\n  title = \t {On the (In)feasibility of {ML} Backdoor Detection as an Hypothesis Testing Problem},\n  author =       {Pichler, Georg and Romanelli, Marco and Prakash Manivannan, Divya and Krishnamurthy, Prashanth and khorrami, Farshad and Garg, Siddharth},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4051--4059},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pichler24a/pichler24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pichler24a.html},\n  abstract = \t {We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pichler24a/pichler24a.pdf",
        "supp": "",
        "pdf_size": 440026,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10364590315068467017&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "05968eb247",
        "title": "On the Effect of Key Factors in Spurious Correlation: A theoretical Perspective",
        "site": "https://proceedings.mlr.press/v238/wang24j.html",
        "author": "Yipei Wang; Xiaoqian Wang",
        "abstract": "Spurious correlations arise when irrelevant patterns in input data are mistakenly associated with labels, compromising the generalizability of machine learning models. While these models may be confident during the training stage, they often falter in real-world testing scenarios due to the shift of these misleading correlations. Current solutions to this problem typically involve altering the correlations or regularizing latent representations. However, while these methods show promise in experiments, a rigorous theoretical understanding of their effectiveness and the underlying factors of spurious correlations is lacking. In this work, we provide a comprehensive theoretical analysis, supported by empirical evidence, to understand the intricacies of spurious correlations. Drawing on our proposed theorems, we investigate the behaviors of classifiers when confronted with spurious features, and present our findings on how various factors influence these correlations and their impact on model performances, including the Mahalanobis distance of groups, and training/testing spurious correlation ratios. Additionally, by aligning empirical outcomes with our theoretical discoveries, we highlight the feasibility of assessing the degree of separability of intertwined real-world features. This research paves the way for a nuanced comprehension of spurious correlations, laying a solid theoretical groundwork that promises to steer future endeavors toward crafting more potent mitigation techniques.",
        "bibtex": "@InProceedings{pmlr-v238-wang24j,\n  title = \t {On the Effect of Key Factors in Spurious Correlation: A theoretical Perspective},\n  author =       {Wang, Yipei and Wang, Xiaoqian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3745--3753},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24j/wang24j.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24j.html},\n  abstract = \t {Spurious correlations arise when irrelevant patterns in input data are mistakenly associated with labels, compromising the generalizability of machine learning models. While these models may be confident during the training stage, they often falter in real-world testing scenarios due to the shift of these misleading correlations. Current solutions to this problem typically involve altering the correlations or regularizing latent representations. However, while these methods show promise in experiments, a rigorous theoretical understanding of their effectiveness and the underlying factors of spurious correlations is lacking. In this work, we provide a comprehensive theoretical analysis, supported by empirical evidence, to understand the intricacies of spurious correlations. Drawing on our proposed theorems, we investigate the behaviors of classifiers when confronted with spurious features, and present our findings on how various factors influence these correlations and their impact on model performances, including the Mahalanobis distance of groups, and training/testing spurious correlation ratios. Additionally, by aligning empirical outcomes with our theoretical discoveries, we highlight the feasibility of assessing the degree of separability of intertwined real-world features. This research paves the way for a nuanced comprehension of spurious correlations, laying a solid theoretical groundwork that promises to steer future endeavors toward crafting more potent mitigation techniques.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24j/wang24j.pdf",
        "supp": "",
        "pdf_size": 9060863,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17769087816076895397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Elmore Family School of Electrical and Computer Engineering, Purdue University; Elmore Family School of Electrical and Computer Engineering, Purdue University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Elmore Family School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5264e7499d",
        "title": "On the Expected Size of Conformal Prediction Sets",
        "site": "https://proceedings.mlr.press/v238/dhillon24a.html",
        "author": "Guneet S. Dhillon; George Deligiannidis; Tom Rainforth",
        "abstract": "While conformal predictors reap the benefits of rigorous statistical guarantees on their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction sets under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high-probability interval bounds that can be empirically computed, providing a practical method for characterizing the expected set size. We corroborate the efficacy of our results with experiments on real-world datasets for both regression and classification problems.",
        "bibtex": "@InProceedings{pmlr-v238-dhillon24a,\n  title = \t {On the Expected Size of Conformal Prediction Sets},\n  author =       {Dhillon, Guneet S. and Deligiannidis, George and Rainforth, Tom},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1549--1557},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dhillon24a/dhillon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dhillon24a.html},\n  abstract = \t {While conformal predictors reap the benefits of rigorous statistical guarantees on their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction sets under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high-probability interval bounds that can be empirically computed, providing a practical method for characterizing the expected set size. We corroborate the efficacy of our results with experiments on real-world datasets for both regression and classification problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dhillon24a/dhillon24a.pdf",
        "supp": "",
        "pdf_size": 874907,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15088151420790513867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, University of Oxford; Department of Statistics, University of Oxford; Department of Statistics, University of Oxford",
        "aff_domain": "stats.ox.ac.uk;stats.ox.ac.uk;stats.ox.ac.uk",
        "email": "stats.ox.ac.uk;stats.ox.ac.uk;stats.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "5cb6407ab1",
        "title": "On the Generalization Ability of Unsupervised Pretraining",
        "site": "https://proceedings.mlr.press/v238/deng24b.html",
        "author": "Yuyang Deng; Junyuan Hong; Jiayu Zhou; Mehrdad Mahdavi",
        "abstract": "Recent advances in unsupervised learning have shown that unsupervised pre-training, followed by fine-tuning, can improve model generalization. However, a rigorous understanding of how the representation function learned on an unlabeled dataset affects the generalization of the fine-tuned model is lacking. Existing theoretical research does not adequately account for the heterogeneity of the distribution and tasks in pre-training and fine-tuning stage. To bridge this gap, this paper introduces a novel theoretical framework that illuminates the critical factor influencing the transferability of knowledge acquired during unsupervised pre-training to the subsequent fine-tuning phase, ultimately affecting the generalization capabilities of the fine-tuned model on downstream tasks. We apply our theoretical framework to analyze generalization bound of two distinct scenarios: Context Encoder pre-training with deep neural networks and Masked Autoencoder pre-training with deep transformers, followed by fine-tuning on a binary classification task. Finally, inspired by our findings, we propose a novel regularization method during pre-training to further enhances the generalization of fine-tuned model. Overall, our results contribute to a better understanding of unsupervised pre-training and fine-tuning paradigm, and can shed light on the design of more effective pre-training algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-deng24b,\n  title = \t {On the Generalization Ability of Unsupervised Pretraining},\n  author =       {Deng, Yuyang and Hong, Junyuan and Zhou, Jiayu and Mahdavi, Mehrdad},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4519--4527},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/deng24b/deng24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/deng24b.html},\n  abstract = \t {Recent advances in unsupervised learning have shown that unsupervised pre-training, followed by fine-tuning, can improve model generalization. However, a rigorous understanding of how the representation function learned on an unlabeled dataset affects the generalization of the fine-tuned model is lacking. Existing theoretical research does not adequately account for the heterogeneity of the distribution and tasks in pre-training and fine-tuning stage. To bridge this gap, this paper introduces a novel theoretical framework that illuminates the critical factor influencing the transferability of knowledge acquired during unsupervised pre-training to the subsequent fine-tuning phase, ultimately affecting the generalization capabilities of the fine-tuned model on downstream tasks. We apply our theoretical framework to analyze generalization bound of two distinct scenarios: Context Encoder pre-training with deep neural networks and Masked Autoencoder pre-training with deep transformers, followed by fine-tuning on a binary classification task. Finally, inspired by our findings, we propose a novel regularization method during pre-training to further enhances the generalization of fine-tuned model. Overall, our results contribute to a better understanding of unsupervised pre-training and fine-tuning paradigm, and can shed light on the design of more effective pre-training algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/deng24b/deng24b.pdf",
        "supp": "",
        "pdf_size": 839980,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=565441928762491548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "36487ce8c5",
        "title": "On the Impact of Overparameterization on the Training of a Shallow Neural Network in High Dimensions",
        "site": "https://proceedings.mlr.press/v238/martin24a.html",
        "author": "Simon Martin; Francis Bach; Giulio Biroli",
        "abstract": "We study the training dynamics of a shallow neural network with quadratic activation functions and quadratic cost in a teacher-student setup. In line with previous works on the same neural architecture, the optimization is performed following the gradient flow on the population risk, where the average over data points is replaced by the expectation over their distribution, assumed to be Gaussian. We first derive convergence properties for the gradient flow and quantify the overparameterization that is necessary to achieve a strong signal recovery. Then, assuming that the teachers and the students at initialization form independent orthonormal families, we derive a high-dimensional limit for the flow and show that the minimal overparameterization is sufficient for strong recovery. We verify by numerical experiments that these results hold for more general initializations.",
        "bibtex": "@InProceedings{pmlr-v238-martin24a,\n  title = \t {On the Impact of Overparameterization on the Training of a Shallow Neural Network in High Dimensions},\n  author =       {Martin, Simon and Bach, Francis and Biroli, Giulio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3655--3663},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/martin24a/martin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/martin24a.html},\n  abstract = \t {We study the training dynamics of a shallow neural network with quadratic activation functions and quadratic cost in a teacher-student setup. In line with previous works on the same neural architecture, the optimization is performed following the gradient flow on the population risk, where the average over data points is replaced by the expectation over their distribution, assumed to be Gaussian. We first derive convergence properties for the gradient flow and quantify the overparameterization that is necessary to achieve a strong signal recovery. Then, assuming that the teachers and the students at initialization form independent orthonormal families, we derive a high-dimensional limit for the flow and show that the minimal overparameterization is sufficient for strong recovery. We verify by numerical experiments that these results hold for more general initializations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/martin24a/martin24a.pdf",
        "supp": "",
        "pdf_size": 931493,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2813764899723572765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0f654a2e88",
        "title": "On the Misspecification of Linear Assumptions in Synthetic Controls",
        "site": "https://proceedings.mlr.press/v238/nazaret24a.html",
        "author": "Achille O. R. Nazaret; Claudia Shi; David Blei",
        "abstract": "The synthetic control (SC) method is popular for estimating causal effects from observational panel data. It rests on a crucial assumption that we can write the treated unit as a linear combination of the untreated units. In practice, this assumption may not hold, and when violated, the resulting SC estimates are incorrect. This paper examines two questions: (1) How large can the misspecification error be? (2) How can we minimize it? First, we provide theoretical bounds to quantify the misspecification error. The bounds are comforting: small misspecifications induce small errors. With these bounds in hand, we develop new SC estimators specially designed to minimize misspecification error. The estimators are based on additional data about each unit. (E.g., if the units are countries, it might be demographic information about each.) We study our estimators on synthetic data; we find they produce more accurate causal estimates than standard SC. We then re-analyze the California tobacco program data of the original SC paper, now including additional data from the US census about per-state demographics. Our estimators show that the observations in the pre-treatment period lie within the bounds of misspecification error and that observations post-treatment lie outside of those bounds. This is evidence that our SC methods have uncovered a true effect.",
        "bibtex": "@InProceedings{pmlr-v238-nazaret24a,\n  title = \t {On the Misspecification of Linear Assumptions in Synthetic Controls},\n  author =       {Nazaret, Achille O. R. and Shi, Claudia and Blei, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3790--3798},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nazaret24a/nazaret24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nazaret24a.html},\n  abstract = \t {The synthetic control (SC) method is popular for estimating causal effects from observational panel data. It rests on a crucial assumption that we can write the treated unit as a linear combination of the untreated units. In practice, this assumption may not hold, and when violated, the resulting SC estimates are incorrect. This paper examines two questions: (1) How large can the misspecification error be? (2) How can we minimize it? First, we provide theoretical bounds to quantify the misspecification error. The bounds are comforting: small misspecifications induce small errors. With these bounds in hand, we develop new SC estimators specially designed to minimize misspecification error. The estimators are based on additional data about each unit. (E.g., if the units are countries, it might be demographic information about each.) We study our estimators on synthetic data; we find they produce more accurate causal estimates than standard SC. We then re-analyze the California tobacco program data of the original SC paper, now including additional data from the US census about per-state demographics. Our estimators show that the observations in the pre-treatment period lie within the bounds of misspecification error and that observations post-treatment lie outside of those bounds. This is evidence that our SC methods have uncovered a true effect.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nazaret24a/nazaret24a.pdf",
        "supp": "",
        "pdf_size": 2217071,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13698372400858420886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8f68ede9fd",
        "title": "On the Model-Misspecification in Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/li24m.html",
        "author": "Yunfan Li; Lin Yang",
        "abstract": "The success of reinforcement learning (RL) crucially depends on effective function approximation when dealing with complex ground-truth models. Existing sample-efficient RL algorithms primarily employ three approaches to function approximation: policy-based, value-based, and model-based methods. However, in the face of model misspecification\u2014a disparity between the ground-truth and optimal function approximators\u2014it is shown that policy-based approaches can be robust even when the policy function approximation is under a large \\emph{locally-bounded} misspecification error, with which the function class may exhibit a $\\Omega(1)$ approximation error in specific states and actions, but remains small on average within a policy-induced state distribution. Yet it remains an open question whether similar robustness can be achieved with value-based and model-based approaches, especially with general function approximation. To bridge this gap, in this paper we present a unified theoretical framework for addressing model misspecification in RL. We demonstrate that, through meticulous algorithm design and sophisticated analysis, value-based and model-based methods employing general function approximation can achieve robustness under local misspecification error bounds. In particular, they can attain a regret bound of $\\widetilde{O}\\left(\\mathrm{poly}(dH)\\cdot(\\sqrt{K} + K\\cdot\\zeta) \\right)$, where $d$ represents the complexity of the function class, $H$ is the episode length, $K$ is the total number of episodes, and $\\zeta$ denotes the local bound for misspecification error. Furthermore, we propose an algorithmic framework that can achieve the same order of regret bound without prior knowledge of $\\zeta$, thereby enhancing its practical applicability.",
        "bibtex": "@InProceedings{pmlr-v238-li24m,\n  title = \t {On the Model-Misspecification in Reinforcement Learning},\n  author =       {Li, Yunfan and Yang, Lin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2764--2772},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24m/li24m.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24m.html},\n  abstract = \t {The success of reinforcement learning (RL) crucially depends on effective function approximation when dealing with complex ground-truth models. Existing sample-efficient RL algorithms primarily employ three approaches to function approximation: policy-based, value-based, and model-based methods. However, in the face of model misspecification\u2014a disparity between the ground-truth and optimal function approximators\u2014it is shown that policy-based approaches can be robust even when the policy function approximation is under a large \\emph{locally-bounded} misspecification error, with which the function class may exhibit a $\\Omega(1)$ approximation error in specific states and actions, but remains small on average within a policy-induced state distribution. Yet it remains an open question whether similar robustness can be achieved with value-based and model-based approaches, especially with general function approximation. To bridge this gap, in this paper we present a unified theoretical framework for addressing model misspecification in RL. We demonstrate that, through meticulous algorithm design and sophisticated analysis, value-based and model-based methods employing general function approximation can achieve robustness under local misspecification error bounds. In particular, they can attain a regret bound of $\\widetilde{O}\\left(\\mathrm{poly}(dH)\\cdot(\\sqrt{K} + K\\cdot\\zeta) \\right)$, where $d$ represents the complexity of the function class, $H$ is the episode length, $K$ is the total number of episodes, and $\\zeta$ denotes the local bound for misspecification error. Furthermore, we propose an algorithmic framework that can achieve the same order of regret bound without prior knowledge of $\\zeta$, thereby enhancing its practical applicability.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24m/li24m.pdf",
        "supp": "",
        "pdf_size": 806793,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5175301682086523530&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Los Angeles; University of California, Los Angeles",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0fb3451fad",
        "title": "On the Nystr\u00f6m Approximation for Preconditioning in Kernel Machines",
        "site": "https://proceedings.mlr.press/v238/abedsoltan24a.html",
        "author": "Amirhesam Abedsoltan; Parthe Pandit; Luis Rademacher; Mikhail Belkin",
        "abstract": "Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystr\u00f6m-based approximated preconditioner to accelerate gradient descent nearly as well as the exact preconditioner, while also reducing the computational and storage overheads.",
        "bibtex": "@InProceedings{pmlr-v238-abedsoltan24a,\n  title = \t {On the {N}ystr\u00f6m Approximation for Preconditioning in Kernel Machines},\n  author =       {Abedsoltan, Amirhesam and Pandit, Parthe and Rademacher, Luis and Belkin, Mikhail},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3718--3726},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/abedsoltan24a/abedsoltan24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/abedsoltan24a.html},\n  abstract = \t {Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystr\u00f6m-based approximated preconditioner to accelerate gradient descent nearly as well as the exact preconditioner, while also reducing the computational and storage overheads.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/abedsoltan24a/abedsoltan24a.pdf",
        "supp": "",
        "pdf_size": 462136,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9899149155786416523&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c1d842cb9",
        "title": "On the Privacy of Selection Mechanisms with Gaussian Noise",
        "site": "https://proceedings.mlr.press/v238/lebensold24a.html",
        "author": "Jonathan Lebensold; Doina Precup; Borja Balle",
        "abstract": "Report Noisy Max and Above Threshold are two classical differentially private (DP) selection mechanisms. Their output is obtained by adding noise to a sequence of low-sensitivity queries and reporting the identity of the query whose (noisy) answer satisfies a certain condition. Pure DP guarantees for these mechanisms are easy to obtain when Laplace noise is added to the queries. On the other hand, when instantiated using Gaussian noise, standard analyses only yield approximate DP guarantees despite the fact that the outputs of these mechanisms lie in a discrete space. In this work, we revisit the analysis of Report Noisy Max and Above Threshold with Gaussian noise and show that, under the additional assumption that the underlying queries are bounded, it is possible to provide pure ex-ante DP bounds for Report Noisy Max and pure ex-post DP bounds for Above Threshold. The resulting bounds are tight and depend on closed-form expressions that can be numerically evaluated using standard methods. Empirically we find these lead to tighter privacy accounting in the high privacy, low data regime. Further, we propose a simple privacy filter for composing pure ex-post DP guarantees, and use it to derive a fully adaptive Gaussian Sparse Vector Technique mechanism. Finally, we provide experiments on mobility and energy consumption datasets demonstrating that our Sparse Vector Technique is practically competitive with previous approaches and requires less hyper-parameter tuning.",
        "bibtex": "@InProceedings{pmlr-v238-lebensold24a,\n  title = \t {On the Privacy of Selection Mechanisms with {G}aussian Noise},\n  author =       {Lebensold, Jonathan and Precup, Doina and Balle, Borja},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1495--1503},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lebensold24a/lebensold24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lebensold24a.html},\n  abstract = \t {Report Noisy Max and Above Threshold are two classical differentially private (DP) selection mechanisms. Their output is obtained by adding noise to a sequence of low-sensitivity queries and reporting the identity of the query whose (noisy) answer satisfies a certain condition. Pure DP guarantees for these mechanisms are easy to obtain when Laplace noise is added to the queries. On the other hand, when instantiated using Gaussian noise, standard analyses only yield approximate DP guarantees despite the fact that the outputs of these mechanisms lie in a discrete space. In this work, we revisit the analysis of Report Noisy Max and Above Threshold with Gaussian noise and show that, under the additional assumption that the underlying queries are bounded, it is possible to provide pure ex-ante DP bounds for Report Noisy Max and pure ex-post DP bounds for Above Threshold. The resulting bounds are tight and depend on closed-form expressions that can be numerically evaluated using standard methods. Empirically we find these lead to tighter privacy accounting in the high privacy, low data regime. Further, we propose a simple privacy filter for composing pure ex-post DP guarantees, and use it to derive a fully adaptive Gaussian Sparse Vector Technique mechanism. Finally, we provide experiments on mobility and energy consumption datasets demonstrating that our Sparse Vector Technique is practically competitive with previous approaches and requires less hyper-parameter tuning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lebensold24a/lebensold24a.pdf",
        "supp": "",
        "pdf_size": 893934,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3308035559470130786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "73fb98220b",
        "title": "On the Statistical Efficiency of Mean-Field Reinforcement Learning with General Function Approximation",
        "site": "https://proceedings.mlr.press/v238/huang24a.html",
        "author": "Jiawei Huang; Batuhan Yardim; Niao He",
        "abstract": "In this paper, we study the fundamental statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general model-based function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MF-MBED), which characterizes the inherent complexity of mean-field model classes. We show that a rich family of Mean-Field RL problems exhibits low MF-MBED. Additionally, we propose algorithms based on maximal likelihood estimation, which can return an $\\epsilon$-optimal policy for MFC or an $\\epsilon$-Nash Equilibrium policy for MFG. The overall sample complexity depends only polynomially on MF-MBED, which is potentially much lower than the size of state-action space. Compared with previous works, our results only require the minimal assumptions including realizability and Lipschitz continuity.",
        "bibtex": "@InProceedings{pmlr-v238-huang24a,\n  title = \t {On the Statistical Efficiency of Mean-Field Reinforcement Learning with General Function Approximation},\n  author =       {Huang, Jiawei and Yardim, Batuhan and He, Niao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {289--297},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/huang24a/huang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/huang24a.html},\n  abstract = \t {In this paper, we study the fundamental statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general model-based function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MF-MBED), which characterizes the inherent complexity of mean-field model classes. We show that a rich family of Mean-Field RL problems exhibits low MF-MBED. Additionally, we propose algorithms based on maximal likelihood estimation, which can return an $\\epsilon$-optimal policy for MFC or an $\\epsilon$-Nash Equilibrium policy for MFG. The overall sample complexity depends only polynomially on MF-MBED, which is potentially much lower than the size of state-action space. Compared with previous works, our results only require the minimal assumptions including realizability and Lipschitz continuity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/huang24a/huang24a.pdf",
        "supp": "",
        "pdf_size": 631962,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4122418537033662782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich",
        "aff_domain": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "email": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "576d1866d6",
        "title": "On the Theoretical Expressive Power and the Design Space of Higher-Order Graph Transformers",
        "site": "https://proceedings.mlr.press/v238/zhou24a.html",
        "author": "Cai Zhou; Rose Yu; Yusu Wang",
        "abstract": "Graph transformers have recently received significant attention in graph learning, partly due to their ability to capture more global interaction via self-attention. Nevertheless, while higher-order graph neural networks have been reasonably well studied, the exploration of extending graph transformers to higher-order variants is just starting. Both theoretical understanding and empirical results are limited. In this paper, we provide a systematic study of the theoretical expressive power of order-$k$ graph transformers and sparse variants. We first show that, an order-$k$ graph transformer without additional structural information is less expressive than the $k$-Weisfeiler Lehman ($k$-WL) test despite its high computational cost. We then explore strategies to both sparsify and enhance the higher-order graph transformers, aiming to improve both their efficiency and expressiveness. Indeed, sparsification based on neighborhood information can enhance the expressive power, as it provides additional information about input graph structures. In particular, we show that a natural neighborhood-based sparse order-$k$ transformer model is not only computationally efficient, but also expressive \u2013 as expressive as $k$-WL test. We further study several other sparse graph attention models that are computationally efficient and provide their expressiveness analysis. Finally, we provide experimental results to show the effectiveness of the different sparsification strategies.",
        "bibtex": "@InProceedings{pmlr-v238-zhou24a,\n  title = \t {On the Theoretical Expressive Power and the Design Space of Higher-Order Graph Transformers},\n  author =       {Zhou, Cai and Yu, Rose and Wang, Yusu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2179--2187},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhou24a/zhou24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhou24a.html},\n  abstract = \t {Graph transformers have recently received significant attention in graph learning, partly due to their ability to capture more global interaction via self-attention. Nevertheless, while higher-order graph neural networks have been reasonably well studied, the exploration of extending graph transformers to higher-order variants is just starting. Both theoretical understanding and empirical results are limited. In this paper, we provide a systematic study of the theoretical expressive power of order-$k$ graph transformers and sparse variants. We first show that, an order-$k$ graph transformer without additional structural information is less expressive than the $k$-Weisfeiler Lehman ($k$-WL) test despite its high computational cost. We then explore strategies to both sparsify and enhance the higher-order graph transformers, aiming to improve both their efficiency and expressiveness. Indeed, sparsification based on neighborhood information can enhance the expressive power, as it provides additional information about input graph structures. In particular, we show that a natural neighborhood-based sparse order-$k$ transformer model is not only computationally efficient, but also expressive \u2013 as expressive as $k$-WL test. We further study several other sparse graph attention models that are computationally efficient and provide their expressiveness analysis. Finally, we provide experimental results to show the effectiveness of the different sparsification strategies.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhou24a/zhou24a.pdf",
        "supp": "",
        "pdf_size": 785923,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4767171127446625386&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Tsinghua University; University of California, San Diego; University of California, San Diego",
        "aff_domain": "mails.tsinghua.edu.cn;ucsd.edu;ucsd.edu",
        "email": "mails.tsinghua.edu.cn;ucsd.edu;ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tsinghua University;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ucsd.edu",
        "aff_unique_abbr": "THU;UCSD",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "1a5f1717fb",
        "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise",
        "site": "https://proceedings.mlr.press/v238/blum24a.html",
        "author": "Avrim Blum; Princewill Okoroafor; Aadirupa Saha; Kevin M. Stangl",
        "abstract": "We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. [Konstantinov and Lampert, 2021] initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in accuracy, where $\\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\\sqrt{\\alpha})$ loss, and give a matching $\\Omega(\\sqrt{\\alpha})$ lower bound. In contrast, [Konstantinov and Lampert, 2021] showed for proper learners the loss in accuracy for both notions is $\\Omega(1)$. The key technical novelty of our work is how randomization can bypass simple \"tricks\" an adversary can use to amplify his power. We also consider additional fairness notions including Equalized Odds and Calibration. For these fairness notions, the excess accuracy clusters into three natural regimes $O(\\alpha)$, $O(\\sqrt{\\alpha})$, and $O(1)$. These results provide a more fine-grained view of the sensitivity of fairness-constrained learning to adversarial noise in training data.",
        "bibtex": "@InProceedings{pmlr-v238-blum24a,\n  title = \t {On the Vulnerability of Fairness Constrained Learning to Malicious Noise},\n  author =       {Blum, Avrim and Okoroafor, Princewill and Saha, Aadirupa and Stangl, Kevin M.},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4096--4104},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/blum24a/blum24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/blum24a.html},\n  abstract = \t {We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. [Konstantinov and Lampert, 2021] initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in accuracy, where $\\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\\sqrt{\\alpha})$ loss, and give a matching $\\Omega(\\sqrt{\\alpha})$ lower bound. In contrast, [Konstantinov and Lampert, 2021] showed for proper learners the loss in accuracy for both notions is $\\Omega(1)$. The key technical novelty of our work is how randomization can bypass simple \"tricks\" an adversary can use to amplify his power. We also consider additional fairness notions including Equalized Odds and Calibration. For these fairness notions, the excess accuracy clusters into three natural regimes $O(\\alpha)$, $O(\\sqrt{\\alpha})$, and $O(1)$. These results provide a more fine-grained view of the sensitivity of fairness-constrained learning to adversarial noise in training data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/blum24a/blum24a.pdf",
        "supp": "",
        "pdf_size": 458541,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2768355459241221679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7d6ef24d41",
        "title": "On the connection between Noise-Contrastive Estimation and Contrastive Divergence",
        "site": "https://proceedings.mlr.press/v238/olmin24a.html",
        "author": "Amanda Olmin; Jakob Lindqvist; Lennart Svensson; Fredrik Lindsten",
        "abstract": "Noise-contrastive estimation (NCE) is a popular method for estimating unnormalised probabilistic models, such as energy-based models, which are effective for modelling complex data distributions. Unlike classical maximum likelihood (ML) estimation that relies on importance sampling (resulting in ML-IS) or MCMC (resulting in contrastive divergence, CD), NCE uses a proxy criterion to avoid the need for evaluating an often intractable normalisation constant. Despite apparent conceptual differences, we show that two NCE criteria, ranking NCE (RNCE) and conditional NCE (CNCE), can be viewed as ML estimation methods. Specifically, RNCE is equivalent to ML estimation combined with conditional importance sampling, and both RNCE and CNCE are special cases of CD. These findings bridge the gap between the two method classes and allow us to apply techniques from the ML-IS and CD literature to NCE, offering several advantageous extensions.",
        "bibtex": "@InProceedings{pmlr-v238-olmin24a,\n  title = \t {On the connection between Noise-Contrastive Estimation and Contrastive Divergence},\n  author =       {Olmin, Amanda and Lindqvist, Jakob and Svensson, Lennart and Lindsten, Fredrik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3016--3024},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/olmin24a/olmin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/olmin24a.html},\n  abstract = \t {Noise-contrastive estimation (NCE) is a popular method for estimating unnormalised probabilistic models, such as energy-based models, which are effective for modelling complex data distributions. Unlike classical maximum likelihood (ML) estimation that relies on importance sampling (resulting in ML-IS) or MCMC (resulting in contrastive divergence, CD), NCE uses a proxy criterion to avoid the need for evaluating an often intractable normalisation constant. Despite apparent conceptual differences, we show that two NCE criteria, ranking NCE (RNCE) and conditional NCE (CNCE), can be viewed as ML estimation methods. Specifically, RNCE is equivalent to ML estimation combined with conditional importance sampling, and both RNCE and CNCE are special cases of CD. These findings bridge the gap between the two method classes and allow us to apply techniques from the ML-IS and CD literature to NCE, offering several advantageous extensions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/olmin24a/olmin24a.pdf",
        "supp": "",
        "pdf_size": 966270,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1162077166208883051&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bf73fa25b0",
        "title": "On the estimation of persistence intensity functions and linear representations of persistence diagrams",
        "site": "https://proceedings.mlr.press/v238/wu24f.html",
        "author": "Weichen Wu; Jisu Kim; Alessandro Rinaldo",
        "abstract": "Persistence diagrams are one of the most popular types of data summaries used in Topological Data Analysis. The prevailing statistical approach to analyzing persistence diagrams is concerned with filtering out topological noise. In this paper, we adopt a different viewpoint and aim at estimating the actual distribution of a random persistence diagram, which captures both topological signal and noise. To that effect, Chazel et al., (2018) proved that, under general conditions, the expected value of a random persistence diagram is a measure admitting a Lebesgue density, called the persistence intensity function. In this paper, we are concerned with estimating the persistence intensity function and a novel, normalized version of it \u2013 called the persistence density function. We present a class of kernel-based estimators based on an i.i.d. sample of persistence diagrams and derive estimation rates in the supremum norm. As a direct corollary, we obtain uniform consistency rates for estimating linear representations of persistence diagrams, including Betti numbers and persistence surfaces. Interestingly, the persistence density function delivers stronger statistical guarantees.",
        "bibtex": "@InProceedings{pmlr-v238-wu24f,\n  title = \t {On the estimation of persistence intensity functions and linear representations of persistence diagrams},\n  author =       {Wu, Weichen and Kim, Jisu and Rinaldo, Alessandro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3610--3618},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24f/wu24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24f.html},\n  abstract = \t {Persistence diagrams are one of the most popular types of data summaries used in Topological Data Analysis. The prevailing statistical approach to analyzing persistence diagrams is concerned with filtering out topological noise. In this paper, we adopt a different viewpoint and aim at estimating the actual distribution of a random persistence diagram, which captures both topological signal and noise. To that effect, Chazel et al., (2018) proved that, under general conditions, the expected value of a random persistence diagram is a measure admitting a Lebesgue density, called the persistence intensity function. In this paper, we are concerned with estimating the persistence intensity function and a novel, normalized version of it \u2013 called the persistence density function. We present a class of kernel-based estimators based on an i.i.d. sample of persistence diagrams and derive estimation rates in the supremum norm. As a direct corollary, we obtain uniform consistency rates for estimating linear representations of persistence diagrams, including Betti numbers and persistence surfaces. Interestingly, the persistence density function delivers stronger statistical guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24f/wu24f.pdf",
        "supp": "",
        "pdf_size": 1495134,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13989818241577172798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "17bcd5e408",
        "title": "On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: a regret lower bound for WSU-UX",
        "site": "https://proceedings.mlr.press/v238/mortazavi24a.html",
        "author": "Ali Mortazavi; Junhao Lin; Nishant Mehta",
        "abstract": "In one view of the classical game of prediction with expert advice with binary outcomes, in each round, each expert maintains an adversarially chosen belief and honestly reports this belief. We consider a recently introduced, strategic variant of this problem with selfish (reputation-seeking) experts, where each expert strategically reports in order to maximize their expected future reputation based on their belief. In this work, our goal is to design an algorithm for the selfish experts problem that is incentive-compatible (IC, or \\emph{truthful}), meaning each expert\u2019s best strategy is to report truthfully, while also ensuring the algorithm enjoys sublinear regret with respect to the expert with the best belief. Freeman et al. (2020) recently studied this problem in the full information and bandit settings and obtained truthful, no-regret algorithms by leveraging prior work on wagering mechanisms. While their results under full information match the minimax rate for the classical (\"honest experts\") problem, the best-known regret for their bandit algorithm WSU-UX is $O(T^{2/3})$, which does not match the minimax rate for the classical (\"honest bandits\") setting. It was unclear whether the higher regret was an artifact of their analysis or a limitation of WSU-UX. We show, via explicit construction of loss sequences, that the algorithm suffers a worst-case $\\Omega(T^{2/3})$ lower bound. Left open is the possibility that a different IC algorithm obtains $O(\\sqrt{T})$ regret. Yet, WSU-UX was a natural choice for such an algorithm owing to the limited design room for IC algorithms in this setting.",
        "bibtex": "@InProceedings{pmlr-v238-mortazavi24a,\n  title = \t {On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: a regret lower bound for {WSU-UX}},\n  author =       {Mortazavi, Ali and Lin, Junhao and Mehta, Nishant},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4681--4689},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mortazavi24a/mortazavi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mortazavi24a.html},\n  abstract = \t {In one view of the classical game of prediction with expert advice with binary outcomes, in each round, each expert maintains an adversarially chosen belief and honestly reports this belief. We consider a recently introduced, strategic variant of this problem with selfish (reputation-seeking) experts, where each expert strategically reports in order to maximize their expected future reputation based on their belief. In this work, our goal is to design an algorithm for the selfish experts problem that is incentive-compatible (IC, or \\emph{truthful}), meaning each expert\u2019s best strategy is to report truthfully, while also ensuring the algorithm enjoys sublinear regret with respect to the expert with the best belief. Freeman et al. (2020) recently studied this problem in the full information and bandit settings and obtained truthful, no-regret algorithms by leveraging prior work on wagering mechanisms. While their results under full information match the minimax rate for the classical (\"honest experts\") problem, the best-known regret for their bandit algorithm WSU-UX is $O(T^{2/3})$, which does not match the minimax rate for the classical (\"honest bandits\") setting. It was unclear whether the higher regret was an artifact of their analysis or a limitation of WSU-UX. We show, via explicit construction of loss sequences, that the algorithm suffers a worst-case $\\Omega(T^{2/3})$ lower bound. Left open is the possibility that a different IC algorithm obtains $O(\\sqrt{T})$ regret. Yet, WSU-UX was a natural choice for such an algorithm owing to the limited design room for IC algorithms in this setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mortazavi24a/mortazavi24a.pdf",
        "supp": "",
        "pdf_size": 557234,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15727525561121325649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Victoria; University of Waterloo + University of Victoria; University of Victoria",
        "aff_domain": "gmail.com;gmail.com;uvic.ca",
        "email": "gmail.com;gmail.com;uvic.ca",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "University of Victoria;University of Waterloo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uvic.ca;https://uwaterloo.ca",
        "aff_unique_abbr": "UVic;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9ae871e3a4",
        "title": "On-Demand Federated Learning for Arbitrary Target Class Distributions",
        "site": "https://proceedings.mlr.press/v238/jeong24a.html",
        "author": "Isu Jeong; Seulki Lee",
        "abstract": "We introduce On-Demand Federated Learning (On-Demand FL), which enables on-demand federated learning of a deep model for an arbitrary target data distribution of interest by making the best use of the heterogeneity (non-IID-ness) of local client data, unlike existing approaches trying to circumvent the non-IID nature of federated learning. On-Demand FL composes a dataset of the target distribution, which we call the composite dataset, from a selected subset of local clients whose aggregate distribution is expected to emulate the target distribution as a whole. As the composite dataset consists of a precise yet diverse subset of clients reflecting the target distribution, the on-demand model trained with exactly enough selected clients becomes able to improve the model performance on the target distribution compared when trained with off-target and/or unknown distributions while reducing the number of participating clients and federating rounds. We model the target data distribution in terms of class and estimate the class distribution of each local client from the weight gradient of its local model. Our experiment results show that On-Demand FL achieves up to 5% higher classification accuracy on various target distributions just involving 9${\\times}$ fewer clients with FashionMNIST, CIFAR-10, and CIFAR-100.",
        "bibtex": "@InProceedings{pmlr-v238-jeong24a,\n  title = \t {On-Demand Federated Learning for Arbitrary Target Class Distributions},\n  author =       {Jeong, Isu and Lee, Seulki},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3421--3429},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jeong24a/jeong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jeong24a.html},\n  abstract = \t {We introduce On-Demand Federated Learning (On-Demand FL), which enables on-demand federated learning of a deep model for an arbitrary target data distribution of interest by making the best use of the heterogeneity (non-IID-ness) of local client data, unlike existing approaches trying to circumvent the non-IID nature of federated learning. On-Demand FL composes a dataset of the target distribution, which we call the composite dataset, from a selected subset of local clients whose aggregate distribution is expected to emulate the target distribution as a whole. As the composite dataset consists of a precise yet diverse subset of clients reflecting the target distribution, the on-demand model trained with exactly enough selected clients becomes able to improve the model performance on the target distribution compared when trained with off-target and/or unknown distributions while reducing the number of participating clients and federating rounds. We model the target data distribution in terms of class and estimate the class distribution of each local client from the weight gradient of its local model. Our experiment results show that On-Demand FL achieves up to 5% higher classification accuracy on various target distributions just involving 9${\\times}$ fewer clients with FashionMNIST, CIFAR-10, and CIFAR-100.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jeong24a/jeong24a.pdf",
        "supp": "",
        "pdf_size": 821347,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:IfoV2TyTcosJ:scholar.google.com/&scioq=On-Demand+Federated+Learning+for+Arbitrary+Target+Class+Distributions&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": "UNIST (Ulsan National Institute of Science and Technology); UNIST (Ulsan National Institute of Science and Technology)",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ulsan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8c9a9d1afa",
        "title": "Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods",
        "site": "https://proceedings.mlr.press/v238/ataee-tarzanagh24a.html",
        "author": "Davoud Ataee Tarzanagh; Parvin Nazari; Bojian Hou; Li Shen; Laura Balzano",
        "abstract": "This paper introduces \\textit{online bilevel optimization} in which a sequence of time-varying bilevel problems is revealed one after the other. We extend the known regret bounds for single-level online algorithms to the bilevel setting. Specifically, we provide new notions of \\textit{bilevel regret}, develop an online alternating time-averaged gradient method that is capable of leveraging smoothness, and give regret bounds in terms of the path-length of the inner and outer minimizer sequences.",
        "bibtex": "@InProceedings{pmlr-v238-ataee-tarzanagh24a,\n  title = \t {Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods},\n  author =       {Ataee Tarzanagh, Davoud and Nazari, Parvin and Hou, Bojian and Shen, Li and Balzano, Laura},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2854--2862},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ataee-tarzanagh24a/ataee-tarzanagh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ataee-tarzanagh24a.html},\n  abstract = \t {This paper introduces \\textit{online bilevel optimization} in which a sequence of time-varying bilevel problems is revealed one after the other. We extend the known regret bounds for single-level online algorithms to the bilevel setting. Specifically, we provide new notions of \\textit{bilevel regret}, develop an online alternating time-averaged gradient method that is capable of leveraging smoothness, and give regret bounds in terms of the path-length of the inner and outer minimizer sequences.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ataee-tarzanagh24a/ataee-tarzanagh24a.pdf",
        "supp": "",
        "pdf_size": 1557165,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17915063302353976170&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Pennsylvania; Amirkabir University of Technology; University of Pennsylvania; University of Pennsylvania; University of Michigan",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "University of Pennsylvania;Amirkabir University of Technology;University of Michigan",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.upenn.edu;https://www.aut.ac.ir;https://www.umich.edu",
        "aff_unique_abbr": "UPenn;AUT;UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Iran"
    },
    {
        "id": "ecd1c3a8a0",
        "title": "Online Calibrated and Conformal Prediction Improves Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v238/deshpande24a.html",
        "author": "Shachi Deshpande; Charles Marx; Volodymyr Kuleshov",
        "abstract": "Accurate uncertainty estimates are important in sequential model-based decision-making tasks such as Bayesian optimization. However, these estimates can be imperfect if the data violates assumptions made by the model (e.g., Gaussianity). This paper studies which uncertainties are needed in model-based decision-making and in Bayesian optimization, and argues that uncertainties can benefit from calibration\u2014i.e., an 80% predictive interval should contain the true outcome 80% of the time. Maintaining calibration, however, can be challenging when the data is non-stationary and depends on our actions. We propose using simple algorithms based on online learning to provably maintain calibration on non-i.i.d. data, and we show how to integrate these algorithms in Bayesian optimization with minimal overhead. Empirically, we find that calibrated Bayesian optimization converges to better optima in fewer steps, and we demonstrate improved performance on standard benchmark functions and hyperparameter optimization tasks.",
        "bibtex": "@InProceedings{pmlr-v238-deshpande24a,\n  title = \t {Online Calibrated and Conformal Prediction Improves {B}ayesian Optimization},\n  author =       {Deshpande, Shachi and Marx, Charles and Kuleshov, Volodymyr},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1450--1458},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/deshpande24a/deshpande24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/deshpande24a.html},\n  abstract = \t {Accurate uncertainty estimates are important in sequential model-based decision-making tasks such as Bayesian optimization. However, these estimates can be imperfect if the data violates assumptions made by the model (e.g., Gaussianity). This paper studies which uncertainties are needed in model-based decision-making and in Bayesian optimization, and argues that uncertainties can benefit from calibration\u2014i.e., an 80% predictive interval should contain the true outcome 80% of the time. Maintaining calibration, however, can be challenging when the data is non-stationary and depends on our actions. We propose using simple algorithms based on online learning to provably maintain calibration on non-i.i.d. data, and we show how to integrate these algorithms in Bayesian optimization with minimal overhead. Empirically, we find that calibrated Bayesian optimization converges to better optima in fewer steps, and we demonstrate improved performance on standard benchmark functions and hyperparameter optimization tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/deshpande24a/deshpande24a.pdf",
        "supp": "",
        "pdf_size": 1549737,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18038723693911035906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e661fd2c2d",
        "title": "Online Distribution Learning with Local Privacy Constraints",
        "site": "https://proceedings.mlr.press/v238/sima24a.html",
        "author": "Jin Sima; Changlong Wu; Olgica Milenkovic; Wojciech Szpankowski",
        "abstract": "We study the problem of online conditional distribution estimation with \\emph{unbounded} label sets under local differential privacy. The problem may be succinctly stated as follows. Let $\\mathcal{F}$ be a distribution-valued function class with an unbounded label set. Our aim is to estimate an \\emph{unknown} function $f\\in \\mathcal{F}$ in an online fashion. More precisely, at time $t$, given a sample ${\\mathbf{x}}_t$, we generate an estimate of $f({\\mathbf{x}}_t)$ using only a \\emph{privatized} version of the true \\emph{labels} sampled from $f({\\mathbf{x}}_t)$. The objective is to minimize the cumulative KL-risk of a finite horizon $T$. We show that under $(\\epsilon,0)$-local differential privacy for the labels, the KL-risk equals $\\tilde{\\Theta}(\\frac{1}{\\epsilon}\\sqrt{KT}),$ up to poly-logarithmic factors, where $K=|\\mathcal{F}|$. This result significantly differs from the $\\tilde{\\Theta}(\\sqrt{T\\log K})$ bound derived in Wu et al., (2023a) for \\emph{bounded} label sets. As a side-result, our approach recovers a nearly tight upper bound for the hypothesis selection problem of Gopi et al., (2020), which has only been established for the \\emph{batch} setting.",
        "bibtex": "@InProceedings{pmlr-v238-sima24a,\n  title = \t {Online Distribution Learning with Local Privacy Constraints},\n  author =       {Sima, Jin and Wu, Changlong and Milenkovic, Olgica and Szpankowski, Wojciech},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {460--468},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sima24a/sima24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sima24a.html},\n  abstract = \t {We study the problem of online conditional distribution estimation with \\emph{unbounded} label sets under local differential privacy. The problem may be succinctly stated as follows. Let $\\mathcal{F}$ be a distribution-valued function class with an unbounded label set. Our aim is to estimate an \\emph{unknown} function $f\\in \\mathcal{F}$ in an online fashion. More precisely, at time $t$, given a sample ${\\mathbf{x}}_t$, we generate an estimate of $f({\\mathbf{x}}_t)$ using only a \\emph{privatized} version of the true \\emph{labels} sampled from $f({\\mathbf{x}}_t)$. The objective is to minimize the cumulative KL-risk of a finite horizon $T$. We show that under $(\\epsilon,0)$-local differential privacy for the labels, the KL-risk equals $\\tilde{\\Theta}(\\frac{1}{\\epsilon}\\sqrt{KT}),$ up to poly-logarithmic factors, where $K=|\\mathcal{F}|$. This result significantly differs from the $\\tilde{\\Theta}(\\sqrt{T\\log K})$ bound derived in Wu et al., (2023a) for \\emph{bounded} label sets. As a side-result, our approach recovers a nearly tight upper bound for the hypothesis selection problem of Gopi et al., (2020), which has only been established for the \\emph{batch} setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sima24a/sima24a.pdf",
        "supp": "",
        "pdf_size": 549670,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15070879412238647166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c2d68d170",
        "title": "Online Learning in Contextual Second-Price Pay-Per-Click Auctions",
        "site": "https://proceedings.mlr.press/v238/zhang24f.html",
        "author": "Mengxiao Zhang; Haipeng Luo",
        "abstract": "We study online learning in contextual pay-per-click auctions where at each of the $T$ rounds, the learner receives some context along with a set of ads and needs to make an estimate on their click-through rate (CTR) in order to run a second-price pay-per-click auction. The learner\u2019s goal is to minimize her regret, defined as the gap between her total revenue and that of an oracle strategy that always makes perfect CTR predictions. We first show that $\\sqrt{T}$-regret is obtainable via a computationally inefficient algorithm and that it is unavoidable since our algorithm is no easier than the classical multi-armed bandit problem. A by-product of our results is a $\\sqrt{T}$-regret bound for the simpler non-contextual setting, improving upon a recent work of [Feng et al., 2023] by removing the inverse CTR dependency that could be arbitrarily large. Then, borrowing ideas from recent advances on efficient contextual bandit algorithms, we develop two practically efficient contextual auction algorithms: the first one uses the exponential weight scheme with optimistic square errors and maintains the same $\\sqrt{T}$-regret bound, while the second one reduces the problem to online regression via a simple epsilon-greedy strategy, albeit with a worse regret bound. Finally, we conduct experiments on a synthetic dataset to showcase the effectiveness and superior performance of our algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24f,\n  title = \t {Online Learning in Contextual Second-Price Pay-Per-Click Auctions},\n  author =       {Zhang, Mengxiao and Luo, Haipeng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2395--2403},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24f/zhang24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24f.html},\n  abstract = \t {We study online learning in contextual pay-per-click auctions where at each of the $T$ rounds, the learner receives some context along with a set of ads and needs to make an estimate on their click-through rate (CTR) in order to run a second-price pay-per-click auction. The learner\u2019s goal is to minimize her regret, defined as the gap between her total revenue and that of an oracle strategy that always makes perfect CTR predictions. We first show that $\\sqrt{T}$-regret is obtainable via a computationally inefficient algorithm and that it is unavoidable since our algorithm is no easier than the classical multi-armed bandit problem. A by-product of our results is a $\\sqrt{T}$-regret bound for the simpler non-contextual setting, improving upon a recent work of [Feng et al., 2023] by removing the inverse CTR dependency that could be arbitrarily large. Then, borrowing ideas from recent advances on efficient contextual bandit algorithms, we develop two practically efficient contextual auction algorithms: the first one uses the exponential weight scheme with optimistic square errors and maintains the same $\\sqrt{T}$-regret bound, while the second one reduces the problem to online regression via a simple epsilon-greedy strategy, albeit with a worse regret bound. Finally, we conduct experiments on a synthetic dataset to showcase the effectiveness and superior performance of our algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24f/zhang24f.pdf",
        "supp": "",
        "pdf_size": 1089938,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18370008282437628061&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Southern California; University of Southern California",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4c0a024793",
        "title": "Online Learning of Decision Trees with Thompson Sampling",
        "site": "https://proceedings.mlr.press/v238/chaouki24a.html",
        "author": "Ayman Chaouki; Jesse Read; Albert Bifet",
        "abstract": "Decision Trees are prominent prediction models for interpretable Machine Learning. They have been thoroughly researched, mostly in the batch setting with a fixed labelled dataset, leading to popular algorithms such as C4.5, ID3 and CART. Unfortunately, these methods are of heuristic nature, they rely on greedy splits offering no guarantees of global optimality and often leading to unnecessarily complex and hard-to-interpret Decision Trees. Recent breakthroughs addressed this suboptimality issue in the batch setting, but no such work has considered the online setting with data arriving in a stream. To this end, we devise a new Monte Carlo Tree Search algorithm, Thompson Sampling Decision Trees (TSDT), able to produce optimal Decision Trees in an online setting. We analyse our algorithm and prove its almost sure convergence to the optimal tree. Furthermore, we conduct extensive experiments to validate our findings empirically. The proposed TSDT outperforms existing algorithms on several benchmarks, all while presenting the practical advantage of being tailored to the online setting.",
        "bibtex": "@InProceedings{pmlr-v238-chaouki24a,\n  title = \t {Online Learning of Decision Trees with {T}hompson Sampling},\n  author =       {Chaouki, Ayman and Read, Jesse and Bifet, Albert},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2944--2952},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chaouki24a/chaouki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chaouki24a.html},\n  abstract = \t {Decision Trees are prominent prediction models for interpretable Machine Learning. They have been thoroughly researched, mostly in the batch setting with a fixed labelled dataset, leading to popular algorithms such as C4.5, ID3 and CART. Unfortunately, these methods are of heuristic nature, they rely on greedy splits offering no guarantees of global optimality and often leading to unnecessarily complex and hard-to-interpret Decision Trees. Recent breakthroughs addressed this suboptimality issue in the batch setting, but no such work has considered the online setting with data arriving in a stream. To this end, we devise a new Monte Carlo Tree Search algorithm, Thompson Sampling Decision Trees (TSDT), able to produce optimal Decision Trees in an online setting. We analyse our algorithm and prove its almost sure convergence to the optimal tree. Furthermore, we conduct extensive experiments to validate our findings empirically. The proposed TSDT outperforms existing algorithms on several benchmarks, all while presenting the practical advantage of being tailored to the online setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chaouki24a/chaouki24a.pdf",
        "supp": "",
        "pdf_size": 2814990,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17551223509940251869&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5c5713159a",
        "title": "Online learning in bandits with predicted context",
        "site": "https://proceedings.mlr.press/v238/guo24b.html",
        "author": "Yongyi Guo; Ziping Xu; Susan Murphy",
        "abstract": "We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-vanishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret guarantees under mild conditions. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations. We further demonstrate the benefits of the proposed approach in simulation environments based on synthetic and real digital intervention datasets.",
        "bibtex": "@InProceedings{pmlr-v238-guo24b,\n  title = \t {Online learning in bandits with predicted context},\n  author =       {Guo, Yongyi and Xu, Ziping and Murphy, Susan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2215--2223},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/guo24b/guo24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/guo24b.html},\n  abstract = \t {We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-vanishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret guarantees under mild conditions. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations. We further demonstrate the benefits of the proposed approach in simulation environments based on synthetic and real digital intervention datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/guo24b/guo24b.pdf",
        "supp": "",
        "pdf_size": 1954357,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1177781084477677679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of Wisconsin-Madison; Harvard University; Harvard University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Wisconsin-Madison;Harvard University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.harvard.edu",
        "aff_unique_abbr": "UW-Madison;Harvard",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2653e95b10",
        "title": "Online multiple testing with e-values",
        "site": "https://proceedings.mlr.press/v238/xu24a.html",
        "author": "Ziyu Xu; Aaditya Ramdas",
        "abstract": "A scientist tests a continuous stream of hypotheses over time in the course of her investigation \u2014 she does not test a predetermined, fixed number of hypotheses. The scientist wishes to make as many discoveries as possible while ensuring the number of false discoveries is controlled \u2014 a well recognized way for accomplishing this is to control the false discovery rate (FDR). Prior methods for FDR control in the online setting have focused on formulating algorithms when specific dependency structures are assumed to exist between the test statistics of each hypothesis. However, in practice, these dependencies often cannot be known beforehand or tested after the fact. Our algorithm, e-LOND, provides FDR control under arbitrary, possibly unknown, dependence. We show that our method is more powerful than existing approaches to this problem through simulations. We also formulate extensions of this algorithm to utilize randomization for increased power and for constructing confidence intervals in online selective inference.",
        "bibtex": "@InProceedings{pmlr-v238-xu24a,\n  title = \t {Online multiple testing with e-values},\n  author =       {Xu, Ziyu and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3997--4005},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xu24a/xu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xu24a.html},\n  abstract = \t {A scientist tests a continuous stream of hypotheses over time in the course of her investigation \u2014 she does not test a predetermined, fixed number of hypotheses. The scientist wishes to make as many discoveries as possible while ensuring the number of false discoveries is controlled \u2014 a well recognized way for accomplishing this is to control the false discovery rate (FDR). Prior methods for FDR control in the online setting have focused on formulating algorithms when specific dependency structures are assumed to exist between the test statistics of each hypothesis. However, in practice, these dependencies often cannot be known beforehand or tested after the fact. Our algorithm, e-LOND, provides FDR control under arbitrary, possibly unknown, dependence. We show that our method is more powerful than existing approaches to this problem through simulations. We also formulate extensions of this algorithm to utilize randomization for increased power and for constructing confidence intervals in online selective inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xu24a/xu24a.pdf",
        "supp": "",
        "pdf_size": 5035727,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17521619630394624243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f96a66fb6c",
        "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization",
        "site": "https://proceedings.mlr.press/v238/concha-duarte24a.html",
        "author": "Alejandro D. de la Concha Duarte; Nicolas Vayatis; Argyris Kalogeratos",
        "abstract": "Quantifying the difference between two probability density functions, $p$ and $q$, using available data, is a fundamental problem in Statistics and Machine Learning. A usual approach for addressing this problem is the likelihood-ratio estimation (LRE) between $p$ and $q$, which -to our best knowledge- has been investigated mainly for the offline case. This paper contributes by introducing a new framework for online non-parametric LRE (OLRE) for the setting where pairs of iid observations $(x_t \\sim p, x\u2019_t \\sim q)$ are observed over time. The non-parametric nature of our approach has the advantage of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the recent advances in Kernel Methods and functional minimization to develop an estimator that can be efficiently updated at every iteration. We provide theoretical guarantees for the performance of the OLRE method along with empirical validation in synthetic experiments.",
        "bibtex": "@InProceedings{pmlr-v238-concha-duarte24a,\n  title = \t {Online non-parametric likelihood-ratio estimation by {P}earson-divergence functional minimization},\n  author =       {de la Concha Duarte, Alejandro D. and Vayatis, Nicolas and Kalogeratos, Argyris},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1189--1197},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/concha-duarte24a/concha-duarte24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/concha-duarte24a.html},\n  abstract = \t {Quantifying the difference between two probability density functions, $p$ and $q$, using available data, is a fundamental problem in Statistics and Machine Learning. A usual approach for addressing this problem is the likelihood-ratio estimation (LRE) between $p$ and $q$, which -to our best knowledge- has been investigated mainly for the offline case. This paper contributes by introducing a new framework for online non-parametric LRE (OLRE) for the setting where pairs of iid observations $(x_t \\sim p, x\u2019_t \\sim q)$ are observed over time. The non-parametric nature of our approach has the advantage of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the recent advances in Kernel Methods and functional minimization to develop an estimator that can be efficiently updated at every iteration. We provide theoretical guarantees for the performance of the OLRE method along with empirical validation in synthetic experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/concha-duarte24a/concha-duarte24a.pdf",
        "supp": "",
        "pdf_size": 7449957,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:w8fMAgbwhBUJ:scholar.google.com/&scioq=Online+non-parametric+likelihood-ratio+estimation+by+Pearson-divergence+functional+minimization&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cfdccb725b",
        "title": "Optimal Budgeted Rejection Sampling for Generative Models",
        "site": "https://proceedings.mlr.press/v238/verine24a.html",
        "author": "Alexandre Verine; Muni Sreenivas Pydi; Benjamin Negrevergne; Yann Chevaleyre",
        "abstract": "Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \\textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model\u2019s overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.",
        "bibtex": "@InProceedings{pmlr-v238-verine24a,\n  title = \t {Optimal Budgeted Rejection Sampling for Generative Models},\n  author =       {Verine, Alexandre and Sreenivas Pydi, Muni and Negrevergne, Benjamin and Chevaleyre, Yann},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3367--3375},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/verine24a/verine24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/verine24a.html},\n  abstract = \t {Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \\textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model\u2019s overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/verine24a/verine24a.pdf",
        "supp": "",
        "pdf_size": 4056589,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4113401769171717877&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bca78c18e6",
        "title": "Optimal Exploration is no harder than Thompson Sampling",
        "site": "https://proceedings.mlr.press/v238/li24h.html",
        "author": "Zhaoqi Li; Kevin Jamieson; Lalit Jain",
        "abstract": "Given a set of arms $\\mathcal{Z}\\subset \\mathbb{R}^d$ and an unknown parameter vector $\\theta_\\ast\\in\\mathbb{R}^d$, the pure exploration linear bandits problem aims to return $\\arg\\max_{z\\in \\mathcal{Z}} z^{\\top}\\theta_{\\ast}$, with high probability through noisy measurements of $x^{\\top}\\theta_{\\ast}$ with $x\\in \\mathcal{X}\\subset \\mathbb{R}^d$. Existing (asymptotically) optimal methods require either a) potentially costly projections for each arm $z\\in \\mathcal{Z}$ or b) explicitly maintaining a subset of $\\mathcal{Z}$ under consideration at each time. This complexity is at odds with the popular and simple Thompson Sampling algorithm for regret minimization, which just requires access to a posterior sampling and argmax oracle, and does not need to enumerate $\\mathcal{Z}$ at any point. Unfortunately, Thompson sampling is known to be sub-optimal for pure exploration. In this work, we pose a natural question: is there an algorithm that can explore optimally and only needs the same computational primitives as Thompson Sampling? We answer the question in the affirmative. We provide an algorithm that leverages only sampling and argmax oracles and achieves an exponential convergence rate, with the exponent equal to the exponent of the optimal fixed allocation asymptotically. In addition, we show that our algorithm can be easily implemented and performs as well empirically as existing asymptotically optimal methods.",
        "bibtex": "@InProceedings{pmlr-v238-li24h,\n  title = \t {Optimal Exploration is no harder than {T}hompson Sampling},\n  author =       {Li, Zhaoqi and Jamieson, Kevin and Jain, Lalit},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1684--1692},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24h/li24h.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24h.html},\n  abstract = \t {Given a set of arms $\\mathcal{Z}\\subset \\mathbb{R}^d$ and an unknown parameter vector $\\theta_\\ast\\in\\mathbb{R}^d$, the pure exploration linear bandits problem aims to return $\\arg\\max_{z\\in \\mathcal{Z}} z^{\\top}\\theta_{\\ast}$, with high probability through noisy measurements of $x^{\\top}\\theta_{\\ast}$ with $x\\in \\mathcal{X}\\subset \\mathbb{R}^d$. Existing (asymptotically) optimal methods require either a) potentially costly projections for each arm $z\\in \\mathcal{Z}$ or b) explicitly maintaining a subset of $\\mathcal{Z}$ under consideration at each time. This complexity is at odds with the popular and simple Thompson Sampling algorithm for regret minimization, which just requires access to a posterior sampling and argmax oracle, and does not need to enumerate $\\mathcal{Z}$ at any point. Unfortunately, Thompson sampling is known to be sub-optimal for pure exploration. In this work, we pose a natural question: is there an algorithm that can explore optimally and only needs the same computational primitives as Thompson Sampling? We answer the question in the affirmative. We provide an algorithm that leverages only sampling and argmax oracles and achieves an exponential convergence rate, with the exponent equal to the exponent of the optimal fixed allocation asymptotically. In addition, we show that our algorithm can be easily implemented and performs as well empirically as existing asymptotically optimal methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24h/li24h.pdf",
        "supp": "",
        "pdf_size": 2068625,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17826699675499258985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "04a2bd54a3",
        "title": "Optimal Sparse Survival Trees",
        "site": "https://proceedings.mlr.press/v238/zhang24b.html",
        "author": "Rui Zhang; Rui Xin; Margo Seltzer; Cynthia Rudin",
        "abstract": "Interpretability is crucial for doctors, hospitals, pharmaceutical companies and biotechnology corporations to analyze and make decisions for high stakes problems that involve human health. Tree-based methods have been widely adopted for survival analysis due to their appealing interpretablility and their ability to capture complex relationships. However, most existing methods to produce survival trees rely on heuristic (or greedy) algorithms, which risk producing sub-optimal models. We present a dynamic-programming-with-bounds approach that finds provably-optimal sparse survival tree models, frequently in only a few seconds.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24b,\n  title = \t {Optimal Sparse Survival Trees},\n  author =       {Zhang, Rui and Xin, Rui and Seltzer, Margo and Rudin, Cynthia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {352--360},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24b/zhang24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24b.html},\n  abstract = \t {Interpretability is crucial for doctors, hospitals, pharmaceutical companies and biotechnology corporations to analyze and make decisions for high stakes problems that involve human health. Tree-based methods have been widely adopted for survival analysis due to their appealing interpretablility and their ability to capture complex relationships. However, most existing methods to produce survival trees rely on heuristic (or greedy) algorithms, which risk producing sub-optimal models. We present a dynamic-programming-with-bounds approach that finds provably-optimal sparse survival tree models, frequently in only a few seconds.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24b/zhang24b.pdf",
        "supp": "",
        "pdf_size": 7764327,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=389470096313311661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "60ffe0a07d",
        "title": "Optimal Transport for Measures with Noisy Tree Metric",
        "site": "https://proceedings.mlr.press/v238/le24a.html",
        "author": "Tam Le; Truyen Nguyen; Kenji Fukumizu",
        "abstract": "We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. To mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in one-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose novel uncertainty sets of tree metrics from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, by building upon the proposed uncertainty sets, and leveraging the tree structure over supports, we show that the robust OT also admits a closed-form expression for a fast computation as its counterpart standard OT (i.e., TW). Furthermore, we demonstrate that the robust OT satisfies the metric property and is negative definite. We then exploit its negative definiteness to propose positive definite kernels and test them in several simulations on various real-world datasets on document classification and topological data analysis.",
        "bibtex": "@InProceedings{pmlr-v238-le24a,\n  title = \t {Optimal Transport for Measures with Noisy Tree Metric},\n  author =       {Le, Tam and Nguyen, Truyen and Fukumizu, Kenji},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3115--3123},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/le24a/le24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/le24a.html},\n  abstract = \t {We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. To mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in one-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose novel uncertainty sets of tree metrics from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, by building upon the proposed uncertainty sets, and leveraging the tree structure over supports, we show that the robust OT also admits a closed-form expression for a fast computation as its counterpart standard OT (i.e., TW). Furthermore, we demonstrate that the robust OT satisfies the metric property and is negative definite. We then exploit its negative definiteness to propose positive definite kernels and test them in several simulations on various real-world datasets on document classification and topological data analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/le24a/le24a.pdf",
        "supp": "",
        "pdf_size": 1902469,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=849166262244938836&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "The Institute of Statistical Mathematics\u2020; The University of Akron\u22c4; RIKEN AIP\u2021",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Institute of Statistical Mathematics;University of Akron;RIKEN",
        "aff_unique_dep": ";;Advanced Institute for Computational Science",
        "aff_unique_url": "https://www.ism.ac.jp;https://www.uakron.edu;https://www.aip.riken.jp",
        "aff_unique_abbr": "ISM;UA;RIKEN AIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "5a8b620a1b",
        "title": "Optimal Zero-Shot Detector for Multi-Armed Attacks",
        "site": "https://proceedings.mlr.press/v238/granese24a.html",
        "author": "Federica Granese; Marco Romanelli; Pablo Piantanida",
        "abstract": "This research delves into a scenario where a malicious actor can manipulate data samples using a multi-armed attack strategy, providing them with multiple ways to introduce noise into the data sample. Our central objective is to protect the data by detecting any alterations to the input. We approach this defensive strategy with utmost caution, operating in an environment where the defender possesses significantly less information compared to the attacker. Specifically, the defender is unable to utilize any data samples for training a defense model or verifying the integrity of the channel. Instead, the defender relies exclusively on a set of pre-existing detectors readily available \"off the shelf.\" To tackle this challenge, we derive an innovative information-theoretic defense approach that optimally aggregates the decisions made by these detectors, eliminating the need for any training data. We further explore a practical use-case scenario for empirical evaluation, where the attacker possesses a pre-trained classifier and launches well-known adversarial attacks against it. Our experiments highlight the effectiveness of our proposed solution, even in scenarios that deviate from the optimal setup.",
        "bibtex": "@InProceedings{pmlr-v238-granese24a,\n  title = \t {Optimal Zero-Shot Detector for Multi-Armed Attacks},\n  author =       {Granese, Federica and Romanelli, Marco and Piantanida, Pablo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2467--2475},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/granese24a/granese24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/granese24a.html},\n  abstract = \t {This research delves into a scenario where a malicious actor can manipulate data samples using a multi-armed attack strategy, providing them with multiple ways to introduce noise into the data sample. Our central objective is to protect the data by detecting any alterations to the input. We approach this defensive strategy with utmost caution, operating in an environment where the defender possesses significantly less information compared to the attacker. Specifically, the defender is unable to utilize any data samples for training a defense model or verifying the integrity of the channel. Instead, the defender relies exclusively on a set of pre-existing detectors readily available \"off the shelf.\" To tackle this challenge, we derive an innovative information-theoretic defense approach that optimally aggregates the decisions made by these detectors, eliminating the need for any training data. We further explore a practical use-case scenario for empirical evaluation, where the attacker possesses a pre-trained classifier and launches well-known adversarial attacks against it. Our experiments highlight the effectiveness of our proposed solution, even in scenarios that deviate from the optimal setup.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/granese24a/granese24a.pdf",
        "supp": "",
        "pdf_size": 2969538,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15545106869039440150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "UMMISCO, IRD, Sorbonne Universit\u00e9 + New York University; UMMISCO, IRD, Sorbonne Universit\u00e9 + New York University; International Laboratory on Learning Systems (ILLS), Quebec AI Institute (MILA) + CNRS, CentraleSup\u00e9lec - Universit\u00e9 Paris-Saclay",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;2+3",
        "aff_unique_norm": "Sorbonne Universit\u00e9;New York University;Quebec AI Institute;CNRS",
        "aff_unique_dep": "UMMISCO, IRD;;Quebec AI Institute;",
        "aff_unique_url": "https://www.sorbonne-universite.fr;https://www.nyu.edu;https://mila.quebec;https://www.cnrs.fr",
        "aff_unique_abbr": "SU;NYU;MILA;CNRS",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;0+1;2+0",
        "aff_country_unique": "France;United States;Canada"
    },
    {
        "id": "ed56cd8a69",
        "title": "Optimal estimation of Gaussian (poly)trees",
        "site": "https://proceedings.mlr.press/v238/wang24i.html",
        "author": "Yuhao Wang; Ming Gao; Wai Ming Tai; Bryon Aragam; Arnab Bhattacharyya",
        "abstract": "We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data. We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery). The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently. The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning. We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds. Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence.",
        "bibtex": "@InProceedings{pmlr-v238-wang24i,\n  title = \t {Optimal estimation of {G}aussian (poly)trees},\n  author =       {Wang, Yuhao and Gao, Ming and Ming Tai, Wai and Aragam, Bryon and Bhattacharyya, Arnab},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3619--3627},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24i/wang24i.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24i.html},\n  abstract = \t {We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data. We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery). The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently. The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning. We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds. Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24i/wang24i.pdf",
        "supp": "",
        "pdf_size": 1052061,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8280170573208730020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "National University of Singapore; University of Chicago; Nanyang Technological University; University of Chicago; National University of Singapore",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "National University of Singapore;University of Chicago;Nanyang Technological University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.uchicago.edu;https://www.ntu.edu.sg",
        "aff_unique_abbr": "NUS;UChicago;NTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "59b2af8cd8",
        "title": "Optimising Distributions with Natural Gradient Surrogates",
        "site": "https://proceedings.mlr.press/v238/so24a.html",
        "author": "Jonathan So; Richard E. Turner",
        "abstract": "Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and variational inference tasks.",
        "bibtex": "@InProceedings{pmlr-v238-so24a,\n  title = \t {Optimising Distributions with Natural Gradient Surrogates},\n  author =       {So, Jonathan and E. Turner, Richard},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2224--2232},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/so24a/so24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/so24a.html},\n  abstract = \t {Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and variational inference tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/so24a/so24a.pdf",
        "supp": "",
        "pdf_size": 6572856,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1862253598991264551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; University of Cambridge",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "63cf29da96",
        "title": "Oracle-Efficient Pessimism: Offline Policy Optimization In Contextual Bandits",
        "site": "https://proceedings.mlr.press/v238/wang24a.html",
        "author": "Lequn Wang; Akshay Krishnamurthy; Alex Slivkins",
        "abstract": "We consider offline policy optimization (OPO) in contextual bandits, where one is given a fixed dataset of logged interactions. While pessimistic regularizers are typically used to mitigate distribution shift, prior implementations thereof are either specialized or computationally inefficient. We present the first \\emph{general} oracle-efficient algorithm for pessimistic OPO: it reduces to supervised learning, leading to broad applicability. We obtain statistical guarantees analogous to those for prior pessimistic approaches. We instantiate our approach for both discrete and continuous actions and perform experiments in both settings, showing advantage over unregularized OPO across a wide range of configurations.",
        "bibtex": "@InProceedings{pmlr-v238-wang24a,\n  title = \t {Oracle-Efficient Pessimism: Offline Policy Optimization In Contextual Bandits},\n  author =       {Wang, Lequn and Krishnamurthy, Akshay and Slivkins, Alex},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {766--774},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wang24a/wang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wang24a.html},\n  abstract = \t {We consider offline policy optimization (OPO) in contextual bandits, where one is given a fixed dataset of logged interactions. While pessimistic regularizers are typically used to mitigate distribution shift, prior implementations thereof are either specialized or computationally inefficient. We present the first \\emph{general} oracle-efficient algorithm for pessimistic OPO: it reduces to supervised learning, leading to broad applicability. We obtain statistical guarantees analogous to those for prior pessimistic approaches. We instantiate our approach for both discrete and continuous actions and perform experiments in both settings, showing advantage over unregularized OPO across a wide range of configurations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wang24a/wang24a.pdf",
        "supp": "",
        "pdf_size": 703691,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12304484936514897867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Netflix; Microsoft Research NYC; Microsoft Research NYC",
        "aff_domain": "netflix.com;microsoft.com;microsoft.com",
        "email": "netflix.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Netflix;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.netflix.com;https://www.microsoft.com/en-us/research/group/microsoft-research-new-york-city",
        "aff_unique_abbr": "Netflix;MSR NYC",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";New York City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1240a2ac0e",
        "title": "Ordinal Potential-based Player Rating",
        "site": "https://proceedings.mlr.press/v238/vadori24a.html",
        "author": "Nelson Vadori; Rahul Savani",
        "abstract": "It was recently observed that Elo ratings fail at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. We provide a characterization of transitive games as a weak variant of ordinal potential games and show that Elo ratings actually do preserve transitivity when computed in the right space, using suitable invertible mappings. Leveraging this insight, we introduce a new game decomposition of an arbitrary game into transitive and cyclic components that is learnt using a neural network-based architecture and that prioritises capturing the sign pattern of the game, namely transitive and cyclic relations among strategies. We link our approach to the known concept of sign-rank, and evaluate our methodology using both toy examples and empirical data from real-world games.",
        "bibtex": "@InProceedings{pmlr-v238-vadori24a,\n  title = \t {Ordinal Potential-based Player Rating},\n  author =       {Vadori, Nelson and Savani, Rahul},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {118--126},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vadori24a/vadori24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vadori24a.html},\n  abstract = \t {It was recently observed that Elo ratings fail at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. We provide a characterization of transitive games as a weak variant of ordinal potential games and show that Elo ratings actually do preserve transitivity when computed in the right space, using suitable invertible mappings. Leveraging this insight, we introduce a new game decomposition of an arbitrary game into transitive and cyclic components that is learnt using a neural network-based architecture and that prioritises capturing the sign pattern of the game, namely transitive and cyclic relations among strategies. We link our approach to the known concept of sign-rank, and evaluate our methodology using both toy examples and empirical data from real-world games.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vadori24a/vadori24a.pdf",
        "supp": "",
        "pdf_size": 2561452,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14802911379277971725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "J.P. Morgan AI Research+The Alan Turing Institute; University of Liverpool",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "J.P. Morgan;Alan Turing Institute;University of Liverpool",
        "aff_unique_dep": "AI Research;;",
        "aff_unique_url": "https://www.jpmorgan.com;https://www.turing.ac.uk;https://www.liverpool.ac.uk",
        "aff_unique_abbr": "JPM;ATI;Liv Uni",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9f0c2b61f9",
        "title": "Orthogonal Gradient Boosting for Simpler Additive Rule Ensembles",
        "site": "https://proceedings.mlr.press/v238/yang24b.html",
        "author": "Fan Yang; Pierre Le Bodic; Michael Kamp; Mario Boley",
        "abstract": "Gradient boosting of prediction rules is an efficient approach to learn potentially interpretable yet accurate probabilistic models. However, actual interpretability requires to limit the number and size of the generated rules, and existing boosting variants are not designed for this purpose. Though corrective boosting refits all rule weights in each iteration to minimise prediction risk, the included rule conditions tend to be sub-optimal, because commonly used objective functions fail to anticipate this refitting. Here, we address this issue by a new objective function that measures the angle between the risk gradient vector and the projection of the condition output vector onto the orthogonal complement of the already selected conditions. This approach correctly approximates the ideal update of adding the risk gradient itself to the model and favours the inclusion of more general and thus shorter rules. As we demonstrate using a wide range of prediction tasks, this significantly improves the comprehensibility/accuracy trade-off of the fitted ensemble. Additionally, we show how objective values for related rule conditions can be computed incrementally to avoid any substantial computational overhead of the new method.",
        "bibtex": "@InProceedings{pmlr-v238-yang24b,\n  title = \t {Orthogonal Gradient Boosting for Simpler Additive Rule Ensembles},\n  author =       {Yang, Fan and Le Bodic, Pierre and Kamp, Michael and Boley, Mario},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1117--1125},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yang24b/yang24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yang24b.html},\n  abstract = \t {Gradient boosting of prediction rules is an efficient approach to learn potentially interpretable yet accurate probabilistic models. However, actual interpretability requires to limit the number and size of the generated rules, and existing boosting variants are not designed for this purpose. Though corrective boosting refits all rule weights in each iteration to minimise prediction risk, the included rule conditions tend to be sub-optimal, because commonly used objective functions fail to anticipate this refitting. Here, we address this issue by a new objective function that measures the angle between the risk gradient vector and the projection of the condition output vector onto the orthogonal complement of the already selected conditions. This approach correctly approximates the ideal update of adding the risk gradient itself to the model and favours the inclusion of more general and thus shorter rules. As we demonstrate using a wide range of prediction tasks, this significantly improves the comprehensibility/accuracy trade-off of the fitted ensemble. Additionally, we show how objective values for related rule conditions can be computed incrementally to avoid any substantial computational overhead of the new method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yang24b/yang24b.pdf",
        "supp": "",
        "pdf_size": 1031134,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18385491145619429002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3fb5946a81",
        "title": "P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks",
        "site": "https://proceedings.mlr.press/v238/hands24a.html",
        "author": "Andrew R. Hands; Tianyi Sun; Risi Kondor",
        "abstract": "Several recent papers have proposed increasing the expressiveness of graph neural networks by exploiting subgraphs or other topological structures. In parallel, researchers have investigated higher order permutation equivariant networks. In this paper we tie these two threads together by providing a general framework for higher order permutation equivariant message passing in subgraph neural networks. Our exposition hinges on so-called $P$-tensors, which provide a simple way to define the most general form of permutation equivariant message passing in this category of networks. We show that this paradigm can achieve state-of-the-art performance on benchmark molecular datasets.",
        "bibtex": "@InProceedings{pmlr-v238-hands24a,\n  title = \t {P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks},\n  author =       {Hands, Andrew R. and Sun, Tianyi and Kondor, Risi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {424--432},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hands24a/hands24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hands24a.html},\n  abstract = \t {Several recent papers have proposed increasing the expressiveness of graph neural networks by exploiting subgraphs or other topological structures. In parallel, researchers have investigated higher order permutation equivariant networks. In this paper we tie these two threads together by providing a general framework for higher order permutation equivariant message passing in subgraph neural networks. Our exposition hinges on so-called $P$-tensors, which provide a simple way to define the most general form of permutation equivariant message passing in this category of networks. We show that this paradigm can achieve state-of-the-art performance on benchmark molecular datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hands24a/hands24a.pdf",
        "supp": "",
        "pdf_size": 416266,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12245368865248213586&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Department of Computer Science, University of Chicago; Computational and Applied Math, Department of Statistics, University of Chicago; Department of Computer Science, Department of Statistics, University of Chicago",
        "aff_domain": "uchicago.edu;uchicago.edu;uchicago.edu",
        "email": "uchicago.edu;uchicago.edu;uchicago.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b0d0544022",
        "title": "Parameter-Agnostic Optimization under Relaxed Smoothness",
        "site": "https://proceedings.mlr.press/v238/hubler24a.html",
        "author": "Florian H\u00fcbler; Junchi Yang; Xiang Li; Niao He",
        "abstract": "Tuning hyperparameters, such as the stepsize, presents a major challenge of training machine learning models. To address this challenge, numerous adaptive optimization algorithms have been developed that achieve near-optimal complexities, even when stepsizes are independent of problem-specific parameters, provided that the loss function is $L$-smooth. However, as the assumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all existing convergence results still necessitate tuning of the stepsize. In this study, we demonstrate that Normalized Stochastic Gradient Descent with Momentum (NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge of any problem parameter, though this comes at the cost of introducing an exponential term dependent on $L_1$ in the complexity. We further establish that this exponential term is inevitable to such schemes by introducing a theoretical framework of lower bounds tailored explicitly for parameter-agnostic algorithms. Interestingly, in deterministic settings, the exponential factor can be neutralized by employing Gradient Descent with a Backtracking Line Search. To the best of our knowledge, these findings represent the first parameter-agnostic convergence results under the generalized smoothness condition. Our empirical experiments further confirm our theoretical insights.",
        "bibtex": "@InProceedings{pmlr-v238-hubler24a,\n  title = \t {Parameter-Agnostic Optimization under Relaxed Smoothness},\n  author =       {H\\\"{u}bler, Florian and Yang, Junchi and Li, Xiang and He, Niao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4861--4869},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hubler24a/hubler24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hubler24a.html},\n  abstract = \t {Tuning hyperparameters, such as the stepsize, presents a major challenge of training machine learning models. To address this challenge, numerous adaptive optimization algorithms have been developed that achieve near-optimal complexities, even when stepsizes are independent of problem-specific parameters, provided that the loss function is $L$-smooth. However, as the assumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all existing convergence results still necessitate tuning of the stepsize. In this study, we demonstrate that Normalized Stochastic Gradient Descent with Momentum (NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge of any problem parameter, though this comes at the cost of introducing an exponential term dependent on $L_1$ in the complexity. We further establish that this exponential term is inevitable to such schemes by introducing a theoretical framework of lower bounds tailored explicitly for parameter-agnostic algorithms. Interestingly, in deterministic settings, the exponential factor can be neutralized by employing Gradient Descent with a Backtracking Line Search. To the best of our knowledge, these findings represent the first parameter-agnostic convergence results under the generalized smoothness condition. Our empirical experiments further confirm our theoretical insights.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hubler24a/hubler24a.pdf",
        "supp": "",
        "pdf_size": 1086919,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14414590807938627025&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "397ac43f66",
        "title": "Pathwise Explanation of ReLU Neural Networks",
        "site": "https://proceedings.mlr.press/v238/lim24a.html",
        "author": "Seongwoo Lim; Won Jo; Joohyung Lee; Jaesik Choi",
        "abstract": "Neural networks have demonstrated a wide range of successes, but their \u201cblack box\" nature raises concerns about transparency and reliability. Previous research on ReLU networks has sought to unwrap these networks into linear models based on activation states of all hidden units. In this paper, we introduce a novel approach that considers subsets of the hidden units involved in the decision making path. This pathwise explanation provides a clearer and more consistent understanding of the relationship between the input and the decision-making process. Our method also offers flexibility in adjusting the range of explanations within the input, i.e., from an overall attribution input to particular components within the input. Furthermore, it allows for the decomposition of explanations for a given input for more detailed explanations. Our experiments demonstrate that the proposed method outperforms existing methods both quantitatively and qualitatively.",
        "bibtex": "@InProceedings{pmlr-v238-lim24a,\n  title = \t {Pathwise Explanation of {ReLU} Neural Networks},\n  author =       {Lim, Seongwoo and Jo, Won and Lee, Joohyung and Choi, Jaesik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4645--4653},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lim24a/lim24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lim24a.html},\n  abstract = \t {Neural networks have demonstrated a wide range of successes, but their \u201cblack box\" nature raises concerns about transparency and reliability. Previous research on ReLU networks has sought to unwrap these networks into linear models based on activation states of all hidden units. In this paper, we introduce a novel approach that considers subsets of the hidden units involved in the decision making path. This pathwise explanation provides a clearer and more consistent understanding of the relationship between the input and the decision-making process. Our method also offers flexibility in adjusting the range of explanations within the input, i.e., from an overall attribution input to particular components within the input. Furthermore, it allows for the decomposition of explanations for a given input for more detailed explanations. Our experiments demonstrate that the proposed method outperforms existing methods both quantitatively and qualitatively.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lim24a/lim24a.pdf",
        "supp": "",
        "pdf_size": 2877733,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DLYNeWog-ywJ:scholar.google.com/&scioq=Pathwise+Explanation+of+ReLU+Neural+Networks&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "Ulsan National Institute of Science and Technology (UNIST); Korea Advanced Institute of Science and Technology (KAIST); Arizona State University+Samsung Research; INEEJI",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/Jo-won/PathwiseExplanation",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3;4",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Arizona State University;Samsung;Instituto de Estudios Economicos de Jujuy",
        "aff_unique_dep": ";;;Samsung Research;",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.kaist.ac.kr;https://www.asu.edu;https://research.samsung.com;",
        "aff_unique_abbr": "UNIST;KAIST;ASU;Samsung;",
        "aff_campus_unique_index": "0;",
        "aff_campus_unique": "Ulsan;",
        "aff_country_unique_index": "0;0;1+0;2",
        "aff_country_unique": "South Korea;United States;Argentina"
    },
    {
        "id": "56bed50104",
        "title": "Personalized Federated X-armed Bandit",
        "site": "https://proceedings.mlr.press/v238/li24a.html",
        "author": "Wenjie Li; Qifan Song; Jean Honorio",
        "abstract": "In this work, we study the personalized federated $\\mathcal{X}$-armed bandit problem, where the heterogeneous local objectives of the clients are optimized simultaneously in the federated learning paradigm. We propose the \\texttt{PF-PNE} algorithm with a unique double elimination strategy, which safely eliminates the non-optimal regions while encouraging federated collaboration through biased but effective evaluations of the local objectives. The proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives with arbitrary levels of heterogeneity, and its limited communications protects the confidentiality of the client-wise reward data. Our theoretical analysis shows the benefit of the proposed algorithm over single-client algorithms. Experimentally, \\texttt{PF-PNE} outperforms multiple baselines on both synthetic and real life datasets.",
        "bibtex": "@InProceedings{pmlr-v238-li24a,\n  title = \t {Personalized Federated {X}-armed Bandit},\n  author =       {Li, Wenjie and Song, Qifan and Honorio, Jean},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {37--45},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24a/li24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24a.html},\n  abstract = \t {In this work, we study the personalized federated $\\mathcal{X}$-armed bandit problem, where the heterogeneous local objectives of the clients are optimized simultaneously in the federated learning paradigm. We propose the \\texttt{PF-PNE} algorithm with a unique double elimination strategy, which safely eliminates the non-optimal regions while encouraging federated collaboration through biased but effective evaluations of the local objectives. The proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives with arbitrary levels of heterogeneity, and its limited communications protects the confidentiality of the client-wise reward data. Our theoretical analysis shows the benefit of the proposed algorithm over single-client algorithms. Experimentally, \\texttt{PF-PNE} outperforms multiple baselines on both synthetic and real life datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24a/li24a.pdf",
        "supp": "",
        "pdf_size": 1152282,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4227071440199724678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Purdue University; The University of Melbourne; Purdue University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Purdue University;University of Melbourne",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.purdue.edu;https://www.unimelb.edu.au",
        "aff_unique_abbr": "Purdue;UniMelb",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "a7a4a414ee",
        "title": "Pessimistic Off-Policy Multi-Objective Optimization",
        "site": "https://proceedings.mlr.press/v238/alizadeh24a.html",
        "author": "Shima Alizadeh; Aniruddha Bhargava; Karthick Gopalswamy; Lalit Jain; Branislav Kveton; Ge Liu",
        "abstract": "Multi-objective optimization is a class of optimization problems with multiple conflicting objectives. We study offline optimization of multi-objective policies from data collected by a previously deployed policy. We propose a pessimistic estimator for policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them.",
        "bibtex": "@InProceedings{pmlr-v238-alizadeh24a,\n  title = \t {Pessimistic Off-Policy Multi-Objective Optimization},\n  author =       {Alizadeh, Shima and Bhargava, Aniruddha and Gopalswamy, Karthick and Jain, Lalit and Kveton, Branislav and Liu, Ge},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2980--2988},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/alizadeh24a/alizadeh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/alizadeh24a.html},\n  abstract = \t {Multi-objective optimization is a class of optimization problems with multiple conflicting objectives. We study offline optimization of multi-objective policies from data collected by a previously deployed policy. We propose a pessimistic estimator for policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/alizadeh24a/alizadeh24a.pdf",
        "supp": "",
        "pdf_size": 618364,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:SpOimDA1XC0J:scholar.google.com/&scioq=Pessimistic+Off-Policy+Multi-Objective+Optimization&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "AWS AI Labs; Amazon; AWS AI Labs; Amazon; Visiting Scholar; AWS AI Labs",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Amazon;",
        "aff_unique_dep": "AWS AI Labs;",
        "aff_unique_url": "https://aws.amazon.com;",
        "aff_unique_abbr": "AWS;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "71898214cc",
        "title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations",
        "site": "https://proceedings.mlr.press/v238/hu24a.html",
        "author": "Hanjiang Hu; Zuxin Liu; Linyi Li; Jiacheng Zhu; Ding Zhao",
        "abstract": "Deep learning-based visual perception models lack robustness when faced with camera motion perturbations in practice. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D-pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames.",
        "bibtex": "@InProceedings{pmlr-v238-hu24a,\n  title = \t {Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations},\n  author =       {Hu, Hanjiang and Liu, Zuxin and Li, Linyi and Zhu, Jiacheng and Zhao, Ding},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {217--225},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hu24a/hu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hu24a.html},\n  abstract = \t {Deep learning-based visual perception models lack robustness when faced with camera motion perturbations in practice. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D-pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hu24a/hu24a.pdf",
        "supp": "",
        "pdf_size": 791848,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:pzS05LOfBsAJ:scholar.google.com/&scioq=Pixel-wise+Smoothing+for+Certified+Robustness+against+Camera+Motion+Perturbations&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "Machine Learning Department, Carnegie Mellon University; Mechanical Engineering, Carnegie Mellon University; Computer Science, University of Illinois at Urbana-Champaign; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Mechanical Engineering, Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Illinois Urbana-Champaign;Massachusetts Institute of Technology",
        "aff_unique_dep": "Machine Learning Department;Computer Science;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.cmu.edu;https://illinois.edu;https://www.csail.mit.edu",
        "aff_unique_abbr": "CMU;UIUC;MIT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Urbana-Champaign;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5f630d48f9",
        "title": "Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample Complexity Analysis",
        "site": "https://proceedings.mlr.press/v238/li24l.html",
        "author": "Zihao Li; Xiang Ji; Minshuo Chen; Mengdi Wang",
        "abstract": "A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understandings and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE with learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Under the assumption of high reward smoothness, our results almost align with the classical OPE results with observable reward data. To the best of our knowledge, this is the first result that establishes a provably efficient guarantee for off-policy evaluation with RLHF.",
        "bibtex": "@InProceedings{pmlr-v238-li24l,\n  title = \t {Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample Complexity Analysis},\n  author =       {Li, Zihao and Ji, Xiang and Chen, Minshuo and Wang, Mengdi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2737--2745},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24l/li24l.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24l.html},\n  abstract = \t {A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understandings and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE with learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Under the assumption of high reward smoothness, our results almost align with the classical OPE results with observable reward data. To the best of our knowledge, this is the first result that establishes a provably efficient guarantee for off-policy evaluation with RLHF.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24l/li24l.pdf",
        "supp": "",
        "pdf_size": 567224,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1090765661187635513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53a3b262b5",
        "title": "Policy Learning for Localized Interventions from Observational Data",
        "site": "https://proceedings.mlr.press/v238/marmarelis24a.html",
        "author": "Myrl G. Marmarelis; Fred Morstatter; Aram Galstyan; Greg Ver Steeg",
        "abstract": "A largely unaddressed problem in causal inference is that of learning reliable policies in continuous, high-dimensional treatment variables from observational data. Especially in the presence of strong confounding, it can be infeasible to learn the entire heterogeneous response surface from treatment to outcome. It is also not particularly useful, when there are practical constraints on the size of the interventions altering the observational treatments. Since it tends to be easier to learn the outcome for treatments near existing observations, we propose a new framework for evaluating and optimizing the effect of small, tailored, and localized interventions that nudge the observed treatment assignments. Our doubly robust effect estimator plugs into a policy learner that stays within the interventional scope by optimal transport. Consequently, the error of the total policy effect is restricted to prediction errors nearby the observational distribution, rather than the whole response surface.",
        "bibtex": "@InProceedings{pmlr-v238-marmarelis24a,\n  title = \t {Policy Learning for Localized Interventions from Observational Data},\n  author =       {Marmarelis, Myrl G. and Morstatter, Fred and Galstyan, Aram and Ver Steeg, Greg},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4456--4464},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/marmarelis24a/marmarelis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/marmarelis24a.html},\n  abstract = \t {A largely unaddressed problem in causal inference is that of learning reliable policies in continuous, high-dimensional treatment variables from observational data. Especially in the presence of strong confounding, it can be infeasible to learn the entire heterogeneous response surface from treatment to outcome. It is also not particularly useful, when there are practical constraints on the size of the interventions altering the observational treatments. Since it tends to be easier to learn the outcome for treatments near existing observations, we propose a new framework for evaluating and optimizing the effect of small, tailored, and localized interventions that nudge the observed treatment assignments. Our doubly robust effect estimator plugs into a policy learner that stays within the interventional scope by optimal transport. Consequently, the error of the total policy effect is restricted to prediction errors nearby the observational distribution, rather than the whole response surface.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/marmarelis24a/marmarelis24a.pdf",
        "supp": "",
        "pdf_size": 1047062,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7625110818229926846&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bf42b7c46f",
        "title": "Positivity-free Policy Learning with Observational Data",
        "site": "https://proceedings.mlr.press/v238/zhao24a.html",
        "author": "Pan Zhao; Antoine Chambaz; Julie Josse; Shu Yang",
        "abstract": "Policy learning utilizing observational data is pivotal across various domains, with the objective of learning the optimal treatment assignment policy while adhering to specific constraints such as fairness, budget, and simplicity. This study introduces a novel positivity-free (stochastic) policy learning framework designed to address the challenges posed by the impracticality of the positivity assumption in real-world scenarios. This framework leverages incremental propensity score policies to adjust propensity score values instead of assigning fixed values to treatments. We characterize these incremental propensity score policies and establish identification conditions, employing semiparametric efficiency theory to propose efficient estimators capable of achieving rapid convergence rates, even when integrated with advanced machine learning algorithms. This paper provides a thorough exploration of the theoretical guarantees associated with policy learning and validates the proposed framework\u2019s finite-sample performance through comprehensive numerical experiments, ensuring the identification of causal effects from observational data is both robust and reliable.",
        "bibtex": "@InProceedings{pmlr-v238-zhao24a,\n  title = \t {Positivity-free Policy Learning with Observational Data},\n  author =       {Zhao, Pan and Chambaz, Antoine and Josse, Julie and Yang, Shu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1918--1926},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhao24a/zhao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhao24a.html},\n  abstract = \t {Policy learning utilizing observational data is pivotal across various domains, with the objective of learning the optimal treatment assignment policy while adhering to specific constraints such as fairness, budget, and simplicity. This study introduces a novel positivity-free (stochastic) policy learning framework designed to address the challenges posed by the impracticality of the positivity assumption in real-world scenarios. This framework leverages incremental propensity score policies to adjust propensity score values instead of assigning fixed values to treatments. We characterize these incremental propensity score policies and establish identification conditions, employing semiparametric efficiency theory to propose efficient estimators capable of achieving rapid convergence rates, even when integrated with advanced machine learning algorithms. This paper provides a thorough exploration of the theoretical guarantees associated with policy learning and validates the proposed framework\u2019s finite-sample performance through comprehensive numerical experiments, ensuring the identification of causal effects from observational data is both robust and reliable.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhao24a/zhao24a.pdf",
        "supp": "",
        "pdf_size": 490499,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9891551620275835411&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "42448b50fe",
        "title": "Posterior Uncertainty Quantification in Neural Networks using Data Augmentation",
        "site": "https://proceedings.mlr.press/v238/wu24e.html",
        "author": "Luhuan Wu; Sinead A Williamson",
        "abstract": "In this paper, we approach the problem of uncertainty quantification in deep learning through a predictive framework, which captures uncertainty in model parameters by specifying our assumptions about the predictive distribution of unseen future data. Under this view, we show that deep ensembling (Lakshminarayanan et al., 2017) is a fundamentally mis-specified model class, since it assumes that future data are supported on existing observations only\u2014a situation rarely encountered in practice. To address this limitation, we propose MixupMP, a method that constructs a more realistic predictive distribution using popular data augmentation techniques. MixupMP operates as a drop-in replacement for deep ensembles, where each ensemble member is trained on a random simulation from this predictive distribution. Grounded in the recently-proposed framework of Martingale posteriors (Fong et al., 2023), MixupMP returns samples from an implicitly defined Bayesian posterior. Our empirical analysis showcases that MixupMP achieves superior predictive per- formance and uncertainty quantification on various image classification datasets, when compared with existing Bayesian and non-Bayesian approaches.",
        "bibtex": "@InProceedings{pmlr-v238-wu24e,\n  title = \t {Posterior Uncertainty Quantification in Neural Networks using Data Augmentation},\n  author =       {Wu, Luhuan and A Williamson, Sinead},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3376--3384},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24e/wu24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24e.html},\n  abstract = \t {In this paper, we approach the problem of uncertainty quantification in deep learning through a predictive framework, which captures uncertainty in model parameters by specifying our assumptions about the predictive distribution of unseen future data. Under this view, we show that deep ensembling (Lakshminarayanan et al., 2017) is a fundamentally mis-specified model class, since it assumes that future data are supported on existing observations only\u2014a situation rarely encountered in practice. To address this limitation, we propose MixupMP, a method that constructs a more realistic predictive distribution using popular data augmentation techniques. MixupMP operates as a drop-in replacement for deep ensembles, where each ensemble member is trained on a random simulation from this predictive distribution. Grounded in the recently-proposed framework of Martingale posteriors (Fong et al., 2023), MixupMP returns samples from an implicitly defined Bayesian posterior. Our empirical analysis showcases that MixupMP achieves superior predictive per- formance and uncertainty quantification on various image classification datasets, when compared with existing Bayesian and non-Bayesian approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24e/wu24e.pdf",
        "supp": "",
        "pdf_size": 6382360,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10659229420090745256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Columbia University + Apple Machine Learning Research; ",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Columbia University;Apple",
        "aff_unique_dep": ";Machine Learning Research",
        "aff_unique_url": "https://www.columbia.edu;https://www.apple.com",
        "aff_unique_abbr": "Columbia;Apple MLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a273aeb607",
        "title": "PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model",
        "site": "https://proceedings.mlr.press/v238/chakraborty24a.html",
        "author": "Abhinav Chakraborty; Anirban Chatterjee; Abhinandan Dalal",
        "abstract": "The Ising model, originally developed as a spin-glass model for ferromagnetic elements, has gained popularity as a network-based model for capturing dependencies in agents\u2019 outputs. Its increasing adoption in healthcare and the social sciences has raised privacy concerns regarding the confidentiality of agents\u2019 responses. In this paper, we present a novel $(\\varepsilon,\\delta)$-differentially private algorithm specifically designed to protect the privacy of individual agents\u2019 outcomes. Our algorithm allows for precise estimation of the natural parameter using a single network through an objective perturbation technique. Furthermore, we establish regret bounds for this algorithm and assess its performance on synthetic datasets and two real-world networks: one involving HIV status in a social network and the other concerning the political leaning of online blogs.",
        "bibtex": "@InProceedings{pmlr-v238-chakraborty24a,\n  title = \t {Pr{I}sing: Privacy-Preserving Peer Effect Estimation via {I}sing Model},\n  author =       {Chakraborty, Abhinav and Chatterjee, Anirban and Dalal, Abhinandan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2692--2700},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chakraborty24a/chakraborty24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chakraborty24a.html},\n  abstract = \t {The Ising model, originally developed as a spin-glass model for ferromagnetic elements, has gained popularity as a network-based model for capturing dependencies in agents\u2019 outputs. Its increasing adoption in healthcare and the social sciences has raised privacy concerns regarding the confidentiality of agents\u2019 responses. In this paper, we present a novel $(\\varepsilon,\\delta)$-differentially private algorithm specifically designed to protect the privacy of individual agents\u2019 outcomes. Our algorithm allows for precise estimation of the natural parameter using a single network through an objective perturbation technique. Furthermore, we establish regret bounds for this algorithm and assess its performance on synthetic datasets and two real-world networks: one involving HIV status in a social network and the other concerning the political leaning of online blogs.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chakraborty24a/chakraborty24a.pdf",
        "supp": "",
        "pdf_size": 1992978,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:JOY1oNktERUJ:scholar.google.com/&scioq=PrIsing:+Privacy-Preserving+Peer+Effect+Estimation+via+Ising+Model&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "43455f55f2",
        "title": "Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks",
        "site": "https://proceedings.mlr.press/v238/rashid24a.html",
        "author": "Ahmad Rashid; Serena Hacker; Guojun Zhang; Agustinus Kristiadi; Pascal Poupart",
        "abstract": "Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks\u2014a popular class of neural network architectures\u2014have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data. This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance against competitive baselines on both far-away and realistic OOD data.",
        "bibtex": "@InProceedings{pmlr-v238-rashid24a,\n  title = \t {Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks},\n  author =       {Rashid, Ahmad and Hacker, Serena and Zhang, Guojun and Kristiadi, Agustinus and Poupart, Pascal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3034--3042},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rashid24a/rashid24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rashid24a.html},\n  abstract = \t {Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks\u2014a popular class of neural network architectures\u2014have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data. This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance against competitive baselines on both far-away and realistic OOD data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rashid24a/rashid24a.pdf",
        "supp": "",
        "pdf_size": 538223,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18106823993787679549&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Waterloo; University of Toronto; Huawei Noah\u2019s Ark Lab; Vector Institute; University of Waterloo",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Waterloo;University of Toronto;Huawei;Vector Institute",
        "aff_unique_dep": ";;Noah\u2019s Ark Lab;",
        "aff_unique_url": "https://uwaterloo.ca;https://www.utoronto.ca;https://www.huawei.com;https://vectorinstitute.ai/",
        "aff_unique_abbr": "UW;U of T;Huawei;Vector Institute",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "b1f2096ccc",
        "title": "Prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
        "site": "https://proceedings.mlr.press/v238/li24e.html",
        "author": "Yingru Li; Zhiquan Luo",
        "abstract": "This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of $\\tilde{\\mathcal{O}}(d\\sqrt{H^3 T \\log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\\mathcal{O}(\\sqrt{\\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to formalize Bayesian regret bounds more effectively.",
        "bibtex": "@InProceedings{pmlr-v238-li24e,\n  title = \t {Prior-dependent analysis of posterior sampling reinforcement learning with function approximation},\n  author =       {Li, Yingru and Luo, Zhiquan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {559--567},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24e/li24e.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24e.html},\n  abstract = \t {This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of $\\tilde{\\mathcal{O}}(d\\sqrt{H^3 T \\log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\\mathcal{O}(\\sqrt{\\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to formalize Bayesian regret bounds more effectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24e/li24e.pdf",
        "supp": "",
        "pdf_size": 532323,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16381855135238327246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Research Institute of Big Data",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen Research Institute of Big Data",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;http://www.sribd.cn",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "3d7d46e649",
        "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients",
        "site": "https://proceedings.mlr.press/v238/cundy24a.html",
        "author": "Chris J. Cundy; Rishi Desai; Stefano Ermon",
        "abstract": "As reinforcement learning techniques are increasingly applied to real-world decision problems, attention has turned to how these algorithms use potentially sensitive information. We consider the task of training a policy that maximizes reward while minimizing disclosure of certain sensitive state variables through the actions. We give examples of how this setting covers real-world problems in privacy for sequential decision-making. We solve this problem in the policy gradients framework by introducing a regularizer based on the mutual information (MI) between the sensitive state and the actions. We develop a model-based stochastic gradient estimator for optimization of privacy-constrained policies. We also discuss an alternative MI regularizer that serves as an upper bound to our main MI regularizer and can be optimized in a model-free setting, and a powerful direct estimator that can be used in an environment with differentiable dynamics. We contrast previous work in differentially-private RL to our mutual-information formulation of information disclosure. Experimental results show that our training method results in policies that hide the sensitive state, even in challenging high-dimensional tasks.",
        "bibtex": "@InProceedings{pmlr-v238-cundy24a,\n  title = \t {Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients},\n  author =       {Cundy, Chris J. and Desai, Rishi and Ermon, Stefano},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2809--2817},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cundy24a/cundy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cundy24a.html},\n  abstract = \t {As reinforcement learning techniques are increasingly applied to real-world decision problems, attention has turned to how these algorithms use potentially sensitive information. We consider the task of training a policy that maximizes reward while minimizing disclosure of certain sensitive state variables through the actions. We give examples of how this setting covers real-world problems in privacy for sequential decision-making. We solve this problem in the policy gradients framework by introducing a regularizer based on the mutual information (MI) between the sensitive state and the actions. We develop a model-based stochastic gradient estimator for optimization of privacy-constrained policies. We also discuss an alternative MI regularizer that serves as an upper bound to our main MI regularizer and can be optimized in a model-free setting, and a powerful direct estimator that can be used in an environment with differentiable dynamics. We contrast previous work in differentially-private RL to our mutual-information formulation of information disclosure. Experimental results show that our training method results in policies that hide the sensitive state, even in challenging high-dimensional tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cundy24a/cundy24a.pdf",
        "supp": "",
        "pdf_size": 5188280,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5183114762319281553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Stanford University; Stanford University; Stanford University",
        "aff_domain": "cs.stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "email": "cs.stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4998548ac1",
        "title": "Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/ahmed24a.html",
        "author": "Maheed H. Ahmed; Mahsa Ghasemi",
        "abstract": "Multi-agent reinforcement learning has a wide range of applications in cooperative settings, but ensuring data privacy among agents is a significant challenge. To address this challenge, we propose Privacy-Preserving Decentralized Actor-Critic (PPDAC), an algorithm that motivates agents to cooperate while maintaining their data privacy. Leveraging trajectory ranking, PPDAC enables the agents to learn a cooperation reward that encourages agents to account for other agents\u2019 preferences. Subsequently, each agent trains a policy that maximizes not only its local reward as in independent actor-critic (IAC) but also the cooperation reward, hence, increasing cooperation. Importantly, communication among agents is restricted to their ranking of trajectories that only include public identifiers without any private local data. Moreover, as an additional layer of privacy, the agents can perturb their rankings with the randomized response method. We evaluate PPDAC on the level-based foraging (LBF) environment and a coin-gathering environment. We compare with IAC and Shared Experience Actor-Critic (SEAC) which achieves SOTA results for the LBF environment. The results show that PPDAC consistently outperforms IAC. In addition, PPDAC outperforms SEAC in the coin-gathering environment and achieves similar performance in the LBF environment, all while providing better privacy.",
        "bibtex": "@InProceedings{pmlr-v238-ahmed24a,\n  title = \t {Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning},\n  author =       {Ahmed, Maheed H. and Ghasemi, Mahsa},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2755--2763},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ahmed24a/ahmed24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ahmed24a.html},\n  abstract = \t {Multi-agent reinforcement learning has a wide range of applications in cooperative settings, but ensuring data privacy among agents is a significant challenge. To address this challenge, we propose Privacy-Preserving Decentralized Actor-Critic (PPDAC), an algorithm that motivates agents to cooperate while maintaining their data privacy. Leveraging trajectory ranking, PPDAC enables the agents to learn a cooperation reward that encourages agents to account for other agents\u2019 preferences. Subsequently, each agent trains a policy that maximizes not only its local reward as in independent actor-critic (IAC) but also the cooperation reward, hence, increasing cooperation. Importantly, communication among agents is restricted to their ranking of trajectories that only include public identifiers without any private local data. Moreover, as an additional layer of privacy, the agents can perturb their rankings with the randomized response method. We evaluate PPDAC on the level-based foraging (LBF) environment and a coin-gathering environment. We compare with IAC and Shared Experience Actor-Critic (SEAC) which achieves SOTA results for the LBF environment. The results show that PPDAC consistently outperforms IAC. In addition, PPDAC outperforms SEAC in the coin-gathering environment and achieves similar performance in the LBF environment, all while providing better privacy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ahmed24a/ahmed24a.pdf",
        "supp": "",
        "pdf_size": 4463980,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6439127872079556787&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47906; Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47906",
        "aff_domain": "purdue.edu;purdue.edu",
        "email": "purdue.edu;purdue.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "36523a5a40",
        "title": "Private Learning with Public Features",
        "site": "https://proceedings.mlr.press/v238/krichene24a.html",
        "author": "Walid Krichene; Nicolas E Mayoraz; Steffen Rendle; Shuang Song; Abhradeep Thakurta; Li Zhang",
        "abstract": "We study a class of private learning problems in which the data is a join of private and public features. This is often the case in private personalization tasks such as recommendation or ad prediction, in which features related to individuals are sensitive, while features related to items (the movies or songs to be recommended, or the ads to be shown to users) are publicly available and do not require protection. A natural question is whether private algorithms can achieve higher utility in the presence of public features. We give a positive answer for multi-encoder models where one of the encoders operates on public features. We develop new algorithms that take advantage of this separation by only protecting certain sufficient statistics (instead of adding noise to the gradient). This method has a guaranteed utility improvement for linear regression, and importantly, achieves the state of the art on two standard private recommendation benchmarks, demonstrating the importance of methods that adapt to the private-public feature separation.",
        "bibtex": "@InProceedings{pmlr-v238-krichene24a,\n  title = \t {Private Learning with Public Features},\n  author =       {Krichene, Walid and E Mayoraz, Nicolas and Rendle, Steffen and Song, Shuang and Thakurta, Abhradeep and Zhang, Li},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4150--4158},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/krichene24a/krichene24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/krichene24a.html},\n  abstract = \t {We study a class of private learning problems in which the data is a join of private and public features. This is often the case in private personalization tasks such as recommendation or ad prediction, in which features related to individuals are sensitive, while features related to items (the movies or songs to be recommended, or the ads to be shown to users) are publicly available and do not require protection. A natural question is whether private algorithms can achieve higher utility in the presence of public features. We give a positive answer for multi-encoder models where one of the encoders operates on public features. We develop new algorithms that take advantage of this separation by only protecting certain sufficient statistics (instead of adding noise to the gradient). This method has a guaranteed utility improvement for linear regression, and importantly, achieves the state of the art on two standard private recommendation benchmarks, demonstrating the importance of methods that adapt to the private-public feature separation.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/krichene24a/krichene24a.pdf",
        "supp": "",
        "pdf_size": 1340862,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13597462421314271601&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Google; Google; Google; Google; Google; Google",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bce2e380f8",
        "title": "Probabilistic Calibration by Design for Neural Network Regression",
        "site": "https://proceedings.mlr.press/v238/dheur24a.html",
        "author": "Victor Dheur; Souhaib Ben Taieb",
        "abstract": "Generating calibrated and sharp neural network predictive distributions for regression problems is essential for optimal decision-making in many real-world applications. To address the miscalibration issue of neural networks, various methods have been proposed to improve calibration, including post-hoc methods that adjust predictions after training and regularization methods that act during training. While post-hoc methods have shown better improvement in calibration compared to regularization methods, the post-hoc step is completely independent of model training. We introduce a novel end-to-end model training procedure called Quantile Recalibration Training, integrating post-hoc calibration directly into the training process without additional parameters. We also present a unified algorithm that includes our method and other post-hoc and regularization methods, as particular cases. We demonstrate the performance of our method in a large-scale experiment involving 57 tabular regression datasets, showcasing improved predictive accuracy while maintaining calibration. We also conduct an ablation study to evaluate the significance of different components within our proposed method, as well as an in-depth analysis of the impact of the base model and different hyperparameters on predictive accuracy.",
        "bibtex": "@InProceedings{pmlr-v238-dheur24a,\n  title = \t {Probabilistic Calibration by Design for Neural Network Regression},\n  author =       {Dheur, Victor and Ben Taieb, Souhaib},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3133--3141},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dheur24a/dheur24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dheur24a.html},\n  abstract = \t {Generating calibrated and sharp neural network predictive distributions for regression problems is essential for optimal decision-making in many real-world applications. To address the miscalibration issue of neural networks, various methods have been proposed to improve calibration, including post-hoc methods that adjust predictions after training and regularization methods that act during training. While post-hoc methods have shown better improvement in calibration compared to regularization methods, the post-hoc step is completely independent of model training. We introduce a novel end-to-end model training procedure called Quantile Recalibration Training, integrating post-hoc calibration directly into the training process without additional parameters. We also present a unified algorithm that includes our method and other post-hoc and regularization methods, as particular cases. We demonstrate the performance of our method in a large-scale experiment involving 57 tabular regression datasets, showcasing improved predictive accuracy while maintaining calibration. We also conduct an ablation study to evaluate the significance of different components within our proposed method, as well as an in-depth analysis of the impact of the base model and different hyperparameters on predictive accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dheur24a/dheur24a.pdf",
        "supp": "",
        "pdf_size": 3239337,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6743079006038406522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Mons, Belgium; Department of Computer Science, University of Mons, Belgium",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Mons",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.umons.ac.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "03e5b29b35",
        "title": "Probabilistic Integral Circuits",
        "site": "https://proceedings.mlr.press/v238/gala24a.html",
        "author": "Gennaro Gala; Cassio de Campos; Robert Peharz; Antonio Vergari; Erik Quaeghebeur",
        "abstract": "Continuous latent variables (LVs) are a key ingredient of many generative models, as they allow modelling expressive mixtures with an uncountable number of components. In contrast, probabilistic circuits (PCs) are hierarchical discrete mixtures represented as computational graphs composed of input, sum and product units. Unlike continuous LV models, PCs provide tractable inference but are limited to discrete LVs with categorical (i.e. unordered) states. We bridge these model classes by introducing probabilistic integral circuits (PICs), a new language of computational graphs that extends PCs with integral units representing continuous LVs. In the first place, PICs are symbolic computational graphs and are fully tractable in simple cases where analytical integration is possible. In practice, we parameterise PICs with light-weight neural nets delivering an intractable hierarchical continuous mixture that can be approximated arbitrarily well with large PCs using numerical quadrature. On several distribution estimation benchmarks, we show that such PIC-approximating PCs systematically outperform PCs commonly learned via expectation-maximization or SGD.",
        "bibtex": "@InProceedings{pmlr-v238-gala24a,\n  title = \t {Probabilistic Integral Circuits},\n  author =       {Gala, Gennaro and de Campos, Cassio and Peharz, Robert and Vergari, Antonio and Quaeghebeur, Erik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2143--2151},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gala24a/gala24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gala24a.html},\n  abstract = \t {Continuous latent variables (LVs) are a key ingredient of many generative models, as they allow modelling expressive mixtures with an uncountable number of components. In contrast, probabilistic circuits (PCs) are hierarchical discrete mixtures represented as computational graphs composed of input, sum and product units. Unlike continuous LV models, PCs provide tractable inference but are limited to discrete LVs with categorical (i.e. unordered) states. We bridge these model classes by introducing probabilistic integral circuits (PICs), a new language of computational graphs that extends PCs with integral units representing continuous LVs. In the first place, PICs are symbolic computational graphs and are fully tractable in simple cases where analytical integration is possible. In practice, we parameterise PICs with light-weight neural nets delivering an intractable hierarchical continuous mixture that can be approximated arbitrarily well with large PCs using numerical quadrature. On several distribution estimation benchmarks, we show that such PIC-approximating PCs systematically outperform PCs commonly learned via expectation-maximization or SGD.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gala24a/gala24a.pdf",
        "supp": "",
        "pdf_size": 2026968,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1296442113479611020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Eindhoven University of Technology, NL; Eindhoven University of Technology, NL; Eindhoven University of Technology, NL+Graz University of Technology, AT; School of Informatics, University of Edinburgh, UK; Eindhoven University of Technology, NL",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;2;0",
        "aff_unique_norm": "Eindhoven University of Technology;Graz University of Technology;University of Edinburgh",
        "aff_unique_dep": ";;School of Informatics",
        "aff_unique_url": "https://www.tue.nl;https://www.tugraz.at;https://www.ed.ac.uk",
        "aff_unique_abbr": "TU/e;TUGraz;Edinburgh",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Edinburgh",
        "aff_country_unique_index": "0;0;0+1;2;0",
        "aff_country_unique": "Netherlands;Austria;United Kingdom"
    },
    {
        "id": "1bb69567b0",
        "title": "Probabilistic Modeling for Sequences of Sets in Continuous-Time",
        "site": "https://proceedings.mlr.press/v238/chang24a.html",
        "author": "Yuxin Chang; Alex J Boyd; Padhraic Smyth",
        "abstract": "Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a \u201cmark\u201d)\u2014but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as \u201cthe probability of item A being observed before item B,\u201d conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address this, we develop a class of importance sampling methods for querying with set-based sequences and demonstrate orders-of-magnitude improvements in efficiency over direct sampling via systematic experiments with four real-world datasets. We also illustrate how to use this framework to perform model selection using likelihoods that do not involve one-step-ahead prediction.",
        "bibtex": "@InProceedings{pmlr-v238-chang24a,\n  title = \t {Probabilistic Modeling for Sequences of Sets in Continuous-Time},\n  author =       {Chang, Yuxin and J Boyd, Alex and Smyth, Padhraic},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4357--4365},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chang24a/chang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chang24a.html},\n  abstract = \t {Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a \u201cmark\u201d)\u2014but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as \u201cthe probability of item A being observed before item B,\u201d conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address this, we develop a class of importance sampling methods for querying with set-based sequences and demonstrate orders-of-magnitude improvements in efficiency over direct sampling via systematic experiments with four real-world datasets. We also illustrate how to use this framework to perform model selection using likelihoods that do not involve one-step-ahead prediction.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chang24a/chang24a.pdf",
        "supp": "",
        "pdf_size": 8843063,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14307076013716745560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science; Department of Statistics; Department of Computer Science + Department of Statistics",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+1",
        "aff_unique_norm": "Unknown Institution;University Affiliation Not Specified",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "57db32bd74",
        "title": "Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains",
        "site": "https://proceedings.mlr.press/v238/tsoy24a.html",
        "author": "Nikita Tsoy; Anna Mihalkova; Teodora N Todorova; Nikola Konstantinov",
        "abstract": "Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients\u2019 utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.",
        "bibtex": "@InProceedings{pmlr-v238-tsoy24a,\n  title = \t {Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains},\n  author =       {Tsoy, Nikita and Mihalkova, Anna and N Todorova, Teodora and Konstantinov, Nikola},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4798--4806},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tsoy24a/tsoy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tsoy24a.html},\n  abstract = \t {Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients\u2019 utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tsoy24a/tsoy24a.pdf",
        "supp": "",
        "pdf_size": 557110,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=569379691544926594&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "44be7c08d2",
        "title": "Provable Policy Gradient Methods for Average-Reward Markov Potential Games",
        "site": "https://proceedings.mlr.press/v238/cheng24a.html",
        "author": "Min Cheng; Ruida Zhou; P. R. Kumar; Chao Tian",
        "abstract": "We study Markov potential games under the infinite horizon average reward criterion. Most previous studies have been for discounted rewards. We prove that both algorithms based on independent policy gradient and independent natural policy gradient converge globally to a Nash equilibrium for the average reward criterion. To set the stage for gradient-based methods, we first establish that the average reward is a smooth function of policies and provide sensitivity bounds for the differential value functions, under certain conditions on ergodicity and the second largest eigenvalue of the underlying Markov decision process (MDP). We prove that three algorithms, policy gradient, proximal-Q, and natural policy gradient (NPG), converge to an $\\epsilon$-Nash equilibrium with time complexity $O(\\frac{1}{\\epsilon^2})$, given a gradient/differential Q function oracle. When policy gradients have to be estimated, we propose an algorithm with $\\tilde{O}(\\frac{1}{\\min_{s,a}\\pi(a|s)\\delta})$ sample complexity to achieve $\\delta$ approximation error w.r.t\u00a0the $\\ell_2$ norm. Equipped with the estimator, we derive the first sample complexity analysis for a policy gradient ascent algorithm, featuring a sample complexity of $\\tilde{O}(1/\\epsilon^5)$. Simulation studies are presented.",
        "bibtex": "@InProceedings{pmlr-v238-cheng24a,\n  title = \t {Provable Policy Gradient Methods for Average-Reward {M}arkov Potential Games},\n  author =       {Cheng, Min and Zhou, Ruida and R. Kumar, P. and Tian, Chao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4699--4707},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cheng24a/cheng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cheng24a.html},\n  abstract = \t {We study Markov potential games under the infinite horizon average reward criterion. Most previous studies have been for discounted rewards. We prove that both algorithms based on independent policy gradient and independent natural policy gradient converge globally to a Nash equilibrium for the average reward criterion. To set the stage for gradient-based methods, we first establish that the average reward is a smooth function of policies and provide sensitivity bounds for the differential value functions, under certain conditions on ergodicity and the second largest eigenvalue of the underlying Markov decision process (MDP). We prove that three algorithms, policy gradient, proximal-Q, and natural policy gradient (NPG), converge to an $\\epsilon$-Nash equilibrium with time complexity $O(\\frac{1}{\\epsilon^2})$, given a gradient/differential Q function oracle. When policy gradients have to be estimated, we propose an algorithm with $\\tilde{O}(\\frac{1}{\\min_{s,a}\\pi(a|s)\\delta})$ sample complexity to achieve $\\delta$ approximation error w.r.t\u00a0the $\\ell_2$ norm. Equipped with the estimator, we derive the first sample complexity analysis for a policy gradient ascent algorithm, featuring a sample complexity of $\\tilde{O}(1/\\epsilon^5)$. Simulation studies are presented.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cheng24a/cheng24a.pdf",
        "supp": "",
        "pdf_size": 1195788,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7641719580512711052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "922c7c0591",
        "title": "Provable local learning rule by expert aggregation for a Hawkes network",
        "site": "https://proceedings.mlr.press/v238/jaffard24a.html",
        "author": "Sophie Jaffard; Samuel Vaiter; Alexandre Muzy; Patricia Reynaud-Bouret",
        "abstract": "We propose a simple network of Hawkes processes as a cognitive model capable of learning to classify objects. Our learning algorithm, named HAN for Hawkes Aggregation of Neurons, is based on a local synaptic learning rule based on spiking probabilities at each output node. We were able to use local regret bounds to prove mathematically that the network is able to learn on average and even asymptotically under more restrictive assumptions.",
        "bibtex": "@InProceedings{pmlr-v238-jaffard24a,\n  title = \t {Provable local learning rule by expert aggregation for a {H}awkes network},\n  author =       {Jaffard, Sophie and Vaiter, Samuel and Muzy, Alexandre and Reynaud-Bouret, Patricia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1837--1845},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jaffard24a/jaffard24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jaffard24a.html},\n  abstract = \t {We propose a simple network of Hawkes processes as a cognitive model capable of learning to classify objects. Our learning algorithm, named HAN for Hawkes Aggregation of Neurons, is based on a local synaptic learning rule based on spiking probabilities at each output node. We were able to use local regret bounds to prove mathematically that the network is able to learn on average and even asymptotically under more restrictive assumptions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jaffard24a/jaffard24a.pdf",
        "supp": "",
        "pdf_size": 736821,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14172083932026574736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "92803a9452",
        "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal Transport",
        "site": "https://proceedings.mlr.press/v238/ferbach24a.html",
        "author": "Damien Ferbach; Baptiste Goujaud; Gauthier Gidel; Aymeric Dieuleveut",
        "abstract": "The energy landscape of high-dimensional non-convex optimization problems is crucial to understanding the effectiveness of modern deep neural network architectures. Recent works have experimentally shown that two different solutions found after two runs of a stochastic training are often connected by very simple continuous paths (e.g., linear) modulo a permutation of the weights. In this paper, we provide a framework theoretically explaining this empirical observation. Based on convergence rates in Wasserstein distance of empirical measures, we show that, with high probability, two wide enough two-layer neural networks trained with stochastic gradient descent are linearly connected. Additionally, we express upper and lower bounds on the width of each layer of two deep neural networks with independent neuron weights to be linearly connected. Finally, we empirically demonstrate the validity of our approach by showing how the dimension of the support of the weight distribution of neurons, which dictates Wasserstein convergence rates is correlated with linear mode connectivity.",
        "bibtex": "@InProceedings{pmlr-v238-ferbach24a,\n  title = \t {Proving Linear Mode Connectivity of Neural Networks via Optimal Transport},\n  author =       {Ferbach, Damien and Goujaud, Baptiste and Gidel, Gauthier and Dieuleveut, Aymeric},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3853--3861},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ferbach24a/ferbach24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ferbach24a.html},\n  abstract = \t {The energy landscape of high-dimensional non-convex optimization problems is crucial to understanding the effectiveness of modern deep neural network architectures. Recent works have experimentally shown that two different solutions found after two runs of a stochastic training are often connected by very simple continuous paths (e.g., linear) modulo a permutation of the weights. In this paper, we provide a framework theoretically explaining this empirical observation. Based on convergence rates in Wasserstein distance of empirical measures, we show that, with high probability, two wide enough two-layer neural networks trained with stochastic gradient descent are linearly connected. Additionally, we express upper and lower bounds on the width of each layer of two deep neural networks with independent neuron weights to be linearly connected. Finally, we empirically demonstrate the validity of our approach by showing how the dimension of the support of the weight distribution of neurons, which dictates Wasserstein convergence rates is correlated with linear mode connectivity.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ferbach24a/ferbach24a.pdf",
        "supp": "",
        "pdf_size": 2572738,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16730854898223918673&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; CMAP, Ecole Polytechnique, IPP; Mila, Universit\u00e9 de Montr\u00e9al; ENS Paris, PSL",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Ecole Polytechnique;\u00c9cole Normale Sup\u00e9rieure, Paris",
        "aff_unique_dep": "Mila;CMAP;",
        "aff_unique_url": "https://umontreal.ca;https://www.polytechnique.edu;https://www.ens.psl.eu",
        "aff_unique_abbr": "UdeM;Polytechnique;ENS Paris",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Montr\u00e9al;;Paris",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Canada;France"
    },
    {
        "id": "a64dbf4dba",
        "title": "Proximal Causal Inference for Synthetic Control with Surrogates",
        "site": "https://proceedings.mlr.press/v238/liu24a.html",
        "author": "Jizhou Liu; Eric Tchetgen Tchetgen; Carlos Varj\u00e3o",
        "abstract": "The synthetic control method (SCM) has become a popular tool for estimating causal effects in policy evaluation, where a single treated unit is observed. However, SCM faces challenges in accurately predicting post-intervention potential outcomes had, contrary to fact, the treatment been withheld, when the pre-intervention period is short or the post-intervention period is long. To address these issues, we propose a novel method that leverages post-intervention information, specifically time-varying correlates of the causal effect called \"surrogates\", within the synthetic control framework. We establish conditions for identifying model parameters using the proximal inference framework and apply the generalized method of moments (GMM) approach for estimation and inference about the average treatment effect on the treated (ATT). Interestingly, we uncover specific conditions under which exclusively using post-intervention data suffices for estimation within our framework. Through a synthetic experiment and a real-world application, we demonstrate that our method can outperform other synthetic control methods in estimating both short-term and long-term effects, yielding more accurate inferences.",
        "bibtex": "@InProceedings{pmlr-v238-liu24a,\n  title = \t {Proximal Causal Inference for Synthetic Control with Surrogates},\n  author =       {Liu, Jizhou and Tchetgen Tchetgen, Eric and Varj\\~{a}o, Carlos},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {730--738},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24a/liu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24a.html},\n  abstract = \t {The synthetic control method (SCM) has become a popular tool for estimating causal effects in policy evaluation, where a single treated unit is observed. However, SCM faces challenges in accurately predicting post-intervention potential outcomes had, contrary to fact, the treatment been withheld, when the pre-intervention period is short or the post-intervention period is long. To address these issues, we propose a novel method that leverages post-intervention information, specifically time-varying correlates of the causal effect called \"surrogates\", within the synthetic control framework. We establish conditions for identifying model parameters using the proximal inference framework and apply the generalized method of moments (GMM) approach for estimation and inference about the average treatment effect on the treated (ATT). Interestingly, we uncover specific conditions under which exclusively using post-intervention data suffices for estimation within our framework. Through a synthetic experiment and a real-world application, we demonstrate that our method can outperform other synthetic control methods in estimating both short-term and long-term effects, yielding more accurate inferences.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24a/liu24a.pdf",
        "supp": "",
        "pdf_size": 425452,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15838049847221748463&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7662178daa",
        "title": "Proxy Methods for Domain Adaptation",
        "site": "https://proceedings.mlr.press/v238/tsai24b.html",
        "author": "Katherine Tsai; Stephen R Pfohl; Olawale Salaudeen; Nicole Chiou; Matt Kusner; Alexander D\u2019Amour; Sanmi Koyejo; Arthur Gretton",
        "abstract": "We study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. In this setting, neither the covariate shift nor the label shift assumptions apply. Our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. We demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. We consider two settings, (i) Concept Bottleneck: an additional \u201cconcept\u201d variable is observed that mediates the relationship between the covariates and labels; (ii) Multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. We develop a two-stage kernel estimation approach to adapt to complex distribution shifts in both settings. In our experiments, we show that our approach outperforms other methods, notably those which explicitly recover the latent confounder.",
        "bibtex": "@InProceedings{pmlr-v238-tsai24b,\n  title = \t {Proxy Methods for Domain Adaptation},\n  author =       {Tsai, Katherine and R Pfohl, Stephen and Salaudeen, Olawale and Chiou, Nicole and Kusner, Matt and D'Amour, Alexander and Koyejo, Sanmi and Gretton, Arthur},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3961--3969},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tsai24b/tsai24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tsai24b.html},\n  abstract = \t {We study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. In this setting, neither the covariate shift nor the label shift assumptions apply. Our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. We demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. We consider two settings, (i) Concept Bottleneck: an additional \u201cconcept\u201d variable is observed that mediates the relationship between the covariates and labels; (ii) Multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. We develop a two-stage kernel estimation approach to adapt to complex distribution shifts in both settings. In our experiments, we show that our approach outperforms other methods, notably those which explicitly recover the latent confounder.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tsai24b/tsai24b.pdf",
        "supp": "",
        "pdf_size": 707132,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15472054725311269196&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ee15850130",
        "title": "Pure Exploration in Bandits with Linear Constraints",
        "site": "https://proceedings.mlr.press/v238/carlsson24a.html",
        "author": "Emil Carlsson; Debabrota Basu; Fredrik Johansson; Devdatt Dubhashi",
        "abstract": "We address the problem of identifying the optimal policy with a fixed confidence level in a multi-armed bandit setup, when \\emph{the arms are subject to linear constraints}. Unlike the standard best-arm identification problem which is well studied, the optimal policy in this case may not be deterministic and could mix between several arms. This changes the geometry of the problem which we characterize via an information-theoretic lower bound. We introduce two asymptotically optimal algorithms for this setting, one based on the Track-and-Stop method and the other based on a game-theoretic approach. Both these algorithms try to track an optimal allocation based on the lower bound and computed by a weighted projection onto the boundary of a normal cone. Finally, we provide empirical results that validate our bounds and visualize how constraints change the hardness of the problem.",
        "bibtex": "@InProceedings{pmlr-v238-carlsson24a,\n  title = \t {Pure Exploration in Bandits with Linear Constraints},\n  author =       {Carlsson, Emil and Basu, Debabrota and Johansson, Fredrik and Dubhashi, Devdatt},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {334--342},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/carlsson24a/carlsson24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/carlsson24a.html},\n  abstract = \t {We address the problem of identifying the optimal policy with a fixed confidence level in a multi-armed bandit setup, when \\emph{the arms are subject to linear constraints}. Unlike the standard best-arm identification problem which is well studied, the optimal policy in this case may not be deterministic and could mix between several arms. This changes the geometry of the problem which we characterize via an information-theoretic lower bound. We introduce two asymptotically optimal algorithms for this setting, one based on the Track-and-Stop method and the other based on a game-theoretic approach. Both these algorithms try to track an optimal allocation based on the lower bound and computed by a weighted projection onto the boundary of a normal cone. Finally, we provide empirical results that validate our bounds and visualize how constraints change the hardness of the problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/carlsson24a/carlsson24a.pdf",
        "supp": "",
        "pdf_size": 1667575,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3901088785796756680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d5b8bc77ae",
        "title": "Quantifying Uncertainty in Natural Language Explanations of Large Language Models",
        "site": "https://proceedings.mlr.press/v238/harsha-tanneru24a.html",
        "author": "Sree Harsha Tanneru; Chirag Agarwal; Himabindu Lakkaraju",
        "abstract": "Large Language Models (LLMs) are increasingly used as powerful tools for several high-stakes natural language processing (NLP) applications. Recent prompting works claim to elicit intermediate reasoning steps and key tokens that serve as proxy explanations for LLM predictions. However, there is no certainty whether these explanations are reliable and reflect the LLM\u2019s behavior. In this work, we make one of the first attempts at quantifying the uncertainty in explanations of LLMs. To this end, we propose two novel metrics \u2014 Verbalized Uncertainty and Probing Uncertainty \u2014 to quantify the uncertainty of generated explanations. While verbalized uncertainty involves prompting the LLM to express its confidence in its explanations, probing uncertainty leverages sample and model perturbations as a means to quantify the uncertainty. Our empirical analysis of benchmark datasets reveals that verbalized uncertainty is not a reliable estimate of explanation confidence. Further, we show that the probing uncertainty estimates are correlated with the faithfulness of an explanation, with lower uncertainty corresponding to explanations with higher faithfulness. Our study provides insights into the challenges and opportunities of quantifying uncertainty in LLM explanations, contributing to the broader discussion of the trustworthiness of foundation models.",
        "bibtex": "@InProceedings{pmlr-v238-harsha-tanneru24a,\n  title = \t {Quantifying Uncertainty in Natural Language Explanations of Large Language Models},\n  author =       {Harsha Tanneru, Sree and Agarwal, Chirag and Lakkaraju, Himabindu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1072--1080},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/harsha-tanneru24a/harsha-tanneru24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/harsha-tanneru24a.html},\n  abstract = \t {Large Language Models (LLMs) are increasingly used as powerful tools for several high-stakes natural language processing (NLP) applications. Recent prompting works claim to elicit intermediate reasoning steps and key tokens that serve as proxy explanations for LLM predictions. However, there is no certainty whether these explanations are reliable and reflect the LLM\u2019s behavior. In this work, we make one of the first attempts at quantifying the uncertainty in explanations of LLMs. To this end, we propose two novel metrics \u2014 Verbalized Uncertainty and Probing Uncertainty \u2014 to quantify the uncertainty of generated explanations. While verbalized uncertainty involves prompting the LLM to express its confidence in its explanations, probing uncertainty leverages sample and model perturbations as a means to quantify the uncertainty. Our empirical analysis of benchmark datasets reveals that verbalized uncertainty is not a reliable estimate of explanation confidence. Further, we show that the probing uncertainty estimates are correlated with the faithfulness of an explanation, with lower uncertainty corresponding to explanations with higher faithfulness. Our study provides insights into the challenges and opportunities of quantifying uncertainty in LLM explanations, contributing to the broader discussion of the trustworthiness of foundation models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/harsha-tanneru24a/harsha-tanneru24a.pdf",
        "supp": "",
        "pdf_size": 1437022,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5425698440902501397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cf24822dd5",
        "title": "Quantifying intrinsic causal contributions via structure preserving interventions",
        "site": "https://proceedings.mlr.press/v238/janzing24a.html",
        "author": "Dominik Janzing; Patrick Bl\u00f6baum; Atalanti A Mastakouri; Philipp M Faller; Lenon Minorics; Kailash Budhathoki",
        "abstract": "We propose a notion of causal influence that describes the \u2018intrinsic\u2019 part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a causal contribution, we consider \u2018structure-preserving interventions\u2019 that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant across arbitrary orderings of nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously.",
        "bibtex": "@InProceedings{pmlr-v238-janzing24a,\n  title = \t {Quantifying intrinsic causal contributions via structure preserving interventions},\n  author =       {Janzing, Dominik and Bl\\\"{o}baum, Patrick and A Mastakouri, Atalanti and M Faller, Philipp and Minorics, Lenon and Budhathoki, Kailash},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2188--2196},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/janzing24a/janzing24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/janzing24a.html},\n  abstract = \t {We propose a notion of causal influence that describes the \u2018intrinsic\u2019 part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a causal contribution, we consider \u2018structure-preserving interventions\u2019 that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant across arbitrary orderings of nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/janzing24a/janzing24a.pdf",
        "supp": "",
        "pdf_size": 546306,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3527842252598712045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c25bab8f16",
        "title": "Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models",
        "site": "https://proceedings.mlr.press/v238/wesel24a.html",
        "author": "Frederiek Wesel; Kim Batselier",
        "abstract": "In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting quantized models have a higher bound on the VC-dimension as opposed to their non-quantized counterparts, at no additional computational cost while learning from identical features. We verify experimentally how this additional tensorization regularizes the learning problem by prioritizing the most salient features in the data and how it provides models with increased generalization capabilities. We finally benchmark our approach on large regression task, achieving state-of-the-art results on a laptop computer.",
        "bibtex": "@InProceedings{pmlr-v238-wesel24a,\n  title = \t {Quantized {F}ourier and Polynomial Features for more Expressive Tensor Network Models},\n  author =       {Wesel, Frederiek and Batselier, Kim},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1261--1269},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wesel24a/wesel24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wesel24a.html},\n  abstract = \t {In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting quantized models have a higher bound on the VC-dimension as opposed to their non-quantized counterparts, at no additional computational cost while learning from identical features. We verify experimentally how this additional tensorization regularizes the learning problem by prioritizing the most salient features in the data and how it provides models with increased generalization capabilities. We finally benchmark our approach on large regression task, achieving state-of-the-art results on a laptop computer.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wesel24a/wesel24a.pdf",
        "supp": "",
        "pdf_size": 2372982,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=701953607785490132&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Delft Center for Systems and Control, Delft University of Technology; Delft Center for Systems and Control, Delft University of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Delft Center for Systems and Control",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "159a533bb9",
        "title": "Queuing dynamics of asynchronous Federated Learning",
        "site": "https://proceedings.mlr.press/v238/leconte24a.html",
        "author": "Louis Leconte; Matthieu Jonckheere; Sergey Samsonov; Eric Moulines",
        "abstract": "We study asynchronous federated learning mechanisms with nodes having potentially different computational speeds. In such an environment, each node is allowed to work on models with potential delays and contribute to updates to the central server at its own pace. Existing analyses of such algorithms typically depend on intractable quantities such as the maximum node delay and do not consider the underlying queuing dynamics of the system. In this paper, we propose a non-uniform sampling scheme for the central server that allows for lower delays with better complexity, taking into account the closed Jackson network structure of the associated computational graph. Our experiments clearly show a significant improvement of our method over current state-of-the-art asynchronous algorithms on image classification problems.",
        "bibtex": "@InProceedings{pmlr-v238-leconte24a,\n  title = \t {Queuing dynamics of asynchronous Federated Learning},\n  author =       {Leconte, Louis and Jonckheere, Matthieu and Samsonov, Sergey and Moulines, Eric},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1711--1719},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/leconte24a/leconte24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/leconte24a.html},\n  abstract = \t {We study asynchronous federated learning mechanisms with nodes having potentially different computational speeds. In such an environment, each node is allowed to work on models with potential delays and contribute to updates to the central server at its own pace. Existing analyses of such algorithms typically depend on intractable quantities such as the maximum node delay and do not consider the underlying queuing dynamics of the system. In this paper, we propose a non-uniform sampling scheme for the central server that allows for lower delays with better complexity, taking into account the closed Jackson network structure of the associated computational graph. Our experiments clearly show a significant improvement of our method over current state-of-the-art asynchronous algorithms on image classification problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/leconte24a/leconte24a.pdf",
        "supp": "",
        "pdf_size": 1453140,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11194536781154216726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f5e6daf859",
        "title": "RL in Markov Games with Independent Function Approximation: Improved Sample Complexity Bound under the Local Access Model",
        "site": "https://proceedings.mlr.press/v238/fan24b.html",
        "author": "Junyi Fan; Yuxuan Han; Jialin Zeng; Jian-Feng Cai; Yang Wang; Yang Xiang; Jiheng Zhang",
        "abstract": "Efficiently learning equilibria with large state and action spaces in general-sum Markov games while overcoming the curse of multi-agency is a challenging problem. Recent works have attempted to solve this problem by employing independent linear function classes to approximate the marginal $Q$-value for each agent. However, existing sample complexity bounds under such a framework have a suboptimal dependency on the desired accuracy $\\varepsilon$ or the action space. In this work, we introduce a new algorithm, Lin-Confident-FTRL, for learning coarse correlated equilibria (CCE) with local access to the simulator, i.e., one can interact with the underlying environment on the visited states. Up to a logarithmic dependence on the size of the state space, Lin-Confident-FTRL learns $\\epsilon$-CCE with a provable optimal accuracy bound $O(\\epsilon^{-2})$ and gets rids of the linear dependency on the action space, while scaling polynomially with relevant problem parameters (such as the number of agents and time horizon). Moreover, our analysis of Linear-Confident-FTRL generalizes the virtual policy iteration technique in the single-agent local planning literature, which yields a new computationally efficient algorithm with a tighter sample complexity bound when assuming random access to the simulator.",
        "bibtex": "@InProceedings{pmlr-v238-fan24b,\n  title = \t {{RL} in {M}arkov Games with Independent Function Approximation: Improved Sample Complexity Bound under the Local Access Model},\n  author =       {Fan, Junyi and Han, Yuxuan and Zeng, Jialin and Cai, Jian-Feng and Wang, Yang and Xiang, Yang and Zhang, Jiheng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2035--2043},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fan24b/fan24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fan24b.html},\n  abstract = \t {Efficiently learning equilibria with large state and action spaces in general-sum Markov games while overcoming the curse of multi-agency is a challenging problem. Recent works have attempted to solve this problem by employing independent linear function classes to approximate the marginal $Q$-value for each agent. However, existing sample complexity bounds under such a framework have a suboptimal dependency on the desired accuracy $\\varepsilon$ or the action space. In this work, we introduce a new algorithm, Lin-Confident-FTRL, for learning coarse correlated equilibria (CCE) with local access to the simulator, i.e., one can interact with the underlying environment on the visited states. Up to a logarithmic dependence on the size of the state space, Lin-Confident-FTRL learns $\\epsilon$-CCE with a provable optimal accuracy bound $O(\\epsilon^{-2})$ and gets rids of the linear dependency on the action space, while scaling polynomially with relevant problem parameters (such as the number of agents and time horizon). Moreover, our analysis of Linear-Confident-FTRL generalizes the virtual policy iteration technique in the single-agent local planning literature, which yields a new computationally efficient algorithm with a tighter sample complexity bound when assuming random access to the simulator.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fan24b/fan24b.pdf",
        "supp": "",
        "pdf_size": 266458,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7624770556953747212&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST; Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST; Department of Mathematics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST",
        "aff_domain": "ust.hk;ust.hk;ust.hk; ;ust.hk;ust.hk;ust.hk",
        "email": "ust.hk;ust.hk;ust.hk; ;ust.hk;ust.hk;ust.hk",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0+0;0+0+0;0+0+0;0;0+0;0+0;0+0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.hkust.edu.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0+0+1;0+0+1;0+0+1;0;0+0;0+1;0+0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0+0+0;0+0+0;0+0+0;0;0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "aa947b696f",
        "title": "Random Oscillators Network for Time Series Processing",
        "site": "https://proceedings.mlr.press/v238/ceni24a.html",
        "author": "Andrea Ceni; Andrea Cossu; Maximilian W St\u00f6lzle; Jingyue Liu; Cosimo Della Santina; Davide Bacciu; Claudio Gallicchio",
        "abstract": "We introduce the Random Oscillators Network (RON), a physically-inspired recurrent model derived from a network of heterogeneous oscillators. Unlike traditional recurrent neural networks, RON keeps the connections between oscillators untrained by leveraging on smart random initialisations, leading to exceptional computational efficiency. A rigorous theoretical analysis finds the necessary and sufficient conditions for the stability of RON, highlighting the natural tendency of RON to lie at the edge of stability, a regime of configurations offering particularly powerful and expressive models. Through an extensive empirical evaluation on several benchmarks, we show four main advantages of RON. 1) RON shows excellent long-term memory and sequence classification ability, outperforming other randomised approaches. 2) RON outperforms fully-trained recurrent models and state-of-the-art randomised models in chaotic time series forecasting. 3) RON provides expressive internal representations even in a small parametrisation regime making it amenable to be deployed on low-powered devices and at the edge. 4) RON is up to two orders of magnitude faster than fully-trained models.",
        "bibtex": "@InProceedings{pmlr-v238-ceni24a,\n  title = \t {Random Oscillators Network for Time Series Processing},\n  author =       {Ceni, Andrea and Cossu, Andrea and W St\\\"{o}lzle, Maximilian and Liu, Jingyue and Della Santina, Cosimo and Bacciu, Davide and Gallicchio, Claudio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4807--4815},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ceni24a/ceni24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ceni24a.html},\n  abstract = \t {We introduce the Random Oscillators Network (RON), a physically-inspired recurrent model derived from a network of heterogeneous oscillators. Unlike traditional recurrent neural networks, RON keeps the connections between oscillators untrained by leveraging on smart random initialisations, leading to exceptional computational efficiency. A rigorous theoretical analysis finds the necessary and sufficient conditions for the stability of RON, highlighting the natural tendency of RON to lie at the edge of stability, a regime of configurations offering particularly powerful and expressive models. Through an extensive empirical evaluation on several benchmarks, we show four main advantages of RON. 1) RON shows excellent long-term memory and sequence classification ability, outperforming other randomised approaches. 2) RON outperforms fully-trained recurrent models and state-of-the-art randomised models in chaotic time series forecasting. 3) RON provides expressive internal representations even in a small parametrisation regime making it amenable to be deployed on low-powered devices and at the edge. 4) RON is up to two orders of magnitude faster than fully-trained models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ceni24a/ceni24a.pdf",
        "supp": "",
        "pdf_size": 8647553,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4730569943607722996&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3ef47570dc",
        "title": "Recovery Guarantees for Distributed-OMP",
        "site": "https://proceedings.mlr.press/v238/amiraz24a.html",
        "author": "Chen Amiraz; Robert Krauthgamer; Boaz Nadler",
        "abstract": "We study distributed schemes for high-dimensional sparse linear regression, based on orthogonal matching pursuit (OMP). Such schemes are particularly suited for settings where a central fusion center is connected to end machines, that have both computation and communication limitations. We prove that under suitable assumptions, distributed-OMP schemes recover the support of the regression vector with communication per machine linear in its sparsity and logarithmic in the dimension. Remarkably, this holds even at low signal-to-noise-ratios, where individual machines are unable to detect the support. Our simulations show that distributed-OMP schemes are competitive with more computationally intensive methods, and in some cases even outperform them.",
        "bibtex": "@InProceedings{pmlr-v238-amiraz24a,\n  title = \t {Recovery Guarantees for Distributed-{OMP}},\n  author =       {Amiraz, Chen and Krauthgamer, Robert and Nadler, Boaz},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {802--810},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/amiraz24a/amiraz24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/amiraz24a.html},\n  abstract = \t {We study distributed schemes for high-dimensional sparse linear regression, based on orthogonal matching pursuit (OMP). Such schemes are particularly suited for settings where a central fusion center is connected to end machines, that have both computation and communication limitations. We prove that under suitable assumptions, distributed-OMP schemes recover the support of the regression vector with communication per machine linear in its sparsity and logarithmic in the dimension. Remarkably, this holds even at low signal-to-noise-ratios, where individual machines are unable to detect the support. Our simulations show that distributed-OMP schemes are competitive with more computationally intensive methods, and in some cases even outperform them.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/amiraz24a/amiraz24a.pdf",
        "supp": "",
        "pdf_size": 423868,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13334799708811770988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ef8c193a4",
        "title": "Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures",
        "site": "https://proceedings.mlr.press/v238/liang24a.html",
        "author": "Hao Liang; Zhiquan Luo",
        "abstract": "We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \\emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, and distortion risk measures, among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes while reflecting the inherent trade-off between risk sensitivity and sample complexity. Our approach offers a unified framework that not only encompasses multiple existing formulations in the literature but also broadens the application spectrum.",
        "bibtex": "@InProceedings{pmlr-v238-liang24a,\n  title = \t {Regret Bounds for Risk-sensitive Reinforcement Learning with {L}ipschitz Dynamic Risk Measures},\n  author =       {Liang, Hao and Luo, Zhiquan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1774--1782},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liang24a/liang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liang24a.html},\n  abstract = \t {We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \\emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, and distortion risk measures, among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes while reflecting the inherent trade-off between risk sensitivity and sample complexity. Our approach offers a unified framework that not only encompasses multiple existing formulations in the literature but also broadens the application spectrum.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liang24a/liang24a.pdf",
        "supp": "",
        "pdf_size": 636115,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8205436358063295028&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "54f8c2d631",
        "title": "Reparameterized Variational Rejection Sampling",
        "site": "https://proceedings.mlr.press/v238/jankowiak24a.html",
        "author": "Martin Jankowiak; Du Phan",
        "abstract": "Traditional approaches to variational inference rely on parametric families of variational distributions, with the choice of family playing a critical role in determining the accuracy of the resulting posterior approximation. Simple mean-field families often lead to poor approximations, while rich families of distributions like normalizing flows can be difficult to optimize and usually do not incorporate the known structure of the target distribution due to their black-box nature. To expand the space of flexible variational families, we revisit Variational Rejection Sampling (VRS) [Grover et al., 2018], which combines a parametric proposal distribution with rejection sampling to define a rich non-parametric family of distributions that explicitly utilizes the known target distribution. By introducing a low-variance reparameterized gradient estimator for the parameters of the proposal distribution, we make VRS an attractive inference strategy for models with continuous latent variables. We argue theoretically and demonstrate empirically that the resulting method\u2013Reparameterized Variational Rejection Sampling (RVRS)\u2013offers an attractive trade-off between computational cost and inference fidelity. In experiments we show that our method performs well in practice and that it is well suited for black-box inference, especially for models with local latent variables.",
        "bibtex": "@InProceedings{pmlr-v238-jankowiak24a,\n  title = \t {Reparameterized Variational Rejection Sampling},\n  author =       {Jankowiak, Martin and Phan, Du},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {739--747},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jankowiak24a/jankowiak24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jankowiak24a.html},\n  abstract = \t {Traditional approaches to variational inference rely on parametric families of variational distributions, with the choice of family playing a critical role in determining the accuracy of the resulting posterior approximation. Simple mean-field families often lead to poor approximations, while rich families of distributions like normalizing flows can be difficult to optimize and usually do not incorporate the known structure of the target distribution due to their black-box nature. To expand the space of flexible variational families, we revisit Variational Rejection Sampling (VRS) [Grover et al., 2018], which combines a parametric proposal distribution with rejection sampling to define a rich non-parametric family of distributions that explicitly utilizes the known target distribution. By introducing a low-variance reparameterized gradient estimator for the parameters of the proposal distribution, we make VRS an attractive inference strategy for models with continuous latent variables. We argue theoretically and demonstrate empirically that the resulting method\u2013Reparameterized Variational Rejection Sampling (RVRS)\u2013offers an attractive trade-off between computational cost and inference fidelity. In experiments we show that our method performs well in practice and that it is well suited for black-box inference, especially for models with local latent variables.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jankowiak24a/jankowiak24a.pdf",
        "supp": "",
        "pdf_size": 9662079,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:nlo78DRaKtgJ:scholar.google.com/&scioq=Reparameterized+Variational+Rejection+Sampling&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "Generate Biomedicines; Google Research",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Generate Biomedicines;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": ";https://research.google",
        "aff_unique_abbr": ";Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "e95a130f9d",
        "title": "Resilient Constrained Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/ding24a.html",
        "author": "Dongsheng Ding; Zhengyan Huan; Alejandro Ribeiro",
        "abstract": "We study a class of constrained reinforcement learning (RL) problems in which multiple constraint specifications are not identified before training. It is challenging to identify appropriate constraint specifications due to the undefined trade-off between the reward maximization objective and the constraint satisfaction, which is ubiquitous in constrained decision-making. To tackle this issue, we propose a new constrained RL approach that searches for policy and constraint specifications together. This method features the adaptation of relaxing the constraint according to a relaxation cost introduced in the learning objective. Since this feature mimics how ecological systems adapt to disruptions by altering operation, our approach is termed as resilient constrained RL. Specifically, we provide a set of sufficient conditions that balance the constraint satisfaction and the reward maximization in notion of resilient equilibrium, propose a tractable formulation of resilient constrained policy optimization that takes this equilibrium as an optimal solution, and advocate two resilient constrained policy search algorithms with non-asymptotic convergence guarantees on the optimality gap and constraint satisfaction. Furthermore, we demonstrate the merits and the effectiveness of our approach in computational experiments.",
        "bibtex": "@InProceedings{pmlr-v238-ding24a,\n  title = \t {Resilient Constrained Reinforcement Learning},\n  author =       {Ding, Dongsheng and Huan, Zhengyan and Ribeiro, Alejandro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3412--3420},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ding24a/ding24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ding24a.html},\n  abstract = \t {We study a class of constrained reinforcement learning (RL) problems in which multiple constraint specifications are not identified before training. It is challenging to identify appropriate constraint specifications due to the undefined trade-off between the reward maximization objective and the constraint satisfaction, which is ubiquitous in constrained decision-making. To tackle this issue, we propose a new constrained RL approach that searches for policy and constraint specifications together. This method features the adaptation of relaxing the constraint according to a relaxation cost introduced in the learning objective. Since this feature mimics how ecological systems adapt to disruptions by altering operation, our approach is termed as resilient constrained RL. Specifically, we provide a set of sufficient conditions that balance the constraint satisfaction and the reward maximization in notion of resilient equilibrium, propose a tractable formulation of resilient constrained policy optimization that takes this equilibrium as an optimal solution, and advocate two resilient constrained policy search algorithms with non-asymptotic convergence guarantees on the optimality gap and constraint satisfaction. Furthermore, we demonstrate the merits and the effectiveness of our approach in computational experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ding24a/ding24a.pdf",
        "supp": "",
        "pdf_size": 5761857,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1809395223956990634&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Pennsylvania; University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu",
        "email": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "007c05b18b",
        "title": "Restricted Isometry Property of Rank-One Measurements with Random Unit-Modulus Vectors",
        "site": "https://proceedings.mlr.press/v238/zhang24d.html",
        "author": "Wei Zhang; Zhenni Wang",
        "abstract": "The restricted isometry property (RIP) is essential for the linear map to guarantee the successful recovery of low-rank matrices. The existing works show that the linear map generated by the measurement matrices with independent and identically distributed (i.i.d.) entries satisfies RIP with high probability. However, when dealing with non-i.i.d. measurement matrices, such as the rank-one measurements, the RIP compliance may not be guaranteed. In this paper, we show that the RIP can still be achieved with high probability, when the rank-one measurement matrix is constructed by the random unit-modulus vectors. Compared to the existing works, we first address the challenge of establishing RIP for the linear map in non-i.i.d. scenarios. As validated in the experiments, this linear map is memory-efficient, and not only satisfies the RIP but also exhibits similar recovery performance of the low-rank matrices to that of conventional i.i.d. measurement matrices.",
        "bibtex": "@InProceedings{pmlr-v238-zhang24d,\n  title = \t {Restricted Isometry Property of Rank-One Measurements with Random Unit-Modulus Vectors},\n  author =       {Zhang, Wei and Wang, Zhenni},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1900--1908},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhang24d/zhang24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhang24d.html},\n  abstract = \t {The restricted isometry property (RIP) is essential for the linear map to guarantee the successful recovery of low-rank matrices. The existing works show that the linear map generated by the measurement matrices with independent and identically distributed (i.i.d.) entries satisfies RIP with high probability. However, when dealing with non-i.i.d. measurement matrices, such as the rank-one measurements, the RIP compliance may not be guaranteed. In this paper, we show that the RIP can still be achieved with high probability, when the rank-one measurement matrix is constructed by the random unit-modulus vectors. Compared to the existing works, we first address the challenge of establishing RIP for the linear map in non-i.i.d. scenarios. As validated in the experiments, this linear map is memory-efficient, and not only satisfies the RIP but also exhibits similar recovery performance of the low-rank matrices to that of conventional i.i.d. measurement matrices.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhang24d/zhang24d.pdf",
        "supp": "",
        "pdf_size": 759920,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:9eVp-c9AF4kJ:scholar.google.com/&scioq=Restricted+Isometry+Property+of+Rank-One+Measurements+with+Random+Unit-Modulus+Vectors&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "aff": "Harbin Institute of Technology; Shenzhen City University of Hong Kong",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Shenzhen City University of Hong Kong",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.szu.edu.cn",
        "aff_unique_abbr": "HIT;SZUHK",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Harbin;Shenzhen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "fc7ba9a513",
        "title": "Revisiting the Noise Model of Stochastic Gradient Descent",
        "site": "https://proceedings.mlr.press/v238/battash24a.html",
        "author": "Barak Battash; Lior Wolf; Ofir Lindenbaum",
        "abstract": "The effectiveness of stochastic gradient descent (SGD) in neural network optimization is significantly influenced by stochastic gradient noise (SGN). Following the central limit theorem, SGN was initially described as Gaussian, but recently Simsekli et al (2019) demonstrated that the $S\\alpha S$ L\u00e9vy distribution provides a better fit for the SGN. This assertion was purportedly debunked and rebounded to the Gaussian noise model that had been previously proposed. This study provides robust, comprehensive empirical evidence that SGN is heavy-tailed and is better represented by the $S\\alpha S$ distribution. Our experiments include several datasets and multiple models, both discriminative and generative. Furthermore, we argue that different network parameters preserve distinct SGN properties. We develop a novel framework based on a L\u00e9vy-driven stochastic differential equation (SDE), where one-dimensional L\u00e9vy processes describe each parameter. This leads to a more accurate characterization of the dynamics of SGD around local minima. We use our framework to study SGD properties near local minima; these include the mean escape time and preferable exit directions.",
        "bibtex": "@InProceedings{pmlr-v238-battash24a,\n  title = \t {Revisiting the Noise Model of Stochastic Gradient Descent},\n  author =       {Battash, Barak and Wolf, Lior and Lindenbaum, Ofir},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4780--4788},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/battash24a/battash24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/battash24a.html},\n  abstract = \t {The effectiveness of stochastic gradient descent (SGD) in neural network optimization is significantly influenced by stochastic gradient noise (SGN). Following the central limit theorem, SGN was initially described as Gaussian, but recently Simsekli et al (2019) demonstrated that the $S\\alpha S$ L\u00e9vy distribution provides a better fit for the SGN. This assertion was purportedly debunked and rebounded to the Gaussian noise model that had been previously proposed. This study provides robust, comprehensive empirical evidence that SGN is heavy-tailed and is better represented by the $S\\alpha S$ distribution. Our experiments include several datasets and multiple models, both discriminative and generative. Furthermore, we argue that different network parameters preserve distinct SGN properties. We develop a novel framework based on a L\u00e9vy-driven stochastic differential equation (SDE), where one-dimensional L\u00e9vy processes describe each parameter. This leads to a more accurate characterization of the dynamics of SGD around local minima. We use our framework to study SGD properties near local minima; these include the mean escape time and preferable exit directions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/battash24a/battash24a.pdf",
        "supp": "",
        "pdf_size": 1870122,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6049790074177349783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d1d2fb23b8",
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v238/zhou24b.html",
        "author": "Angela Zhou",
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "bibtex": "@InProceedings{pmlr-v238-zhou24b,\n  title = \t {Reward-Relevance-Filtered Linear Offline Reinforcement Learning},\n  author =       {Zhou, Angela},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3025--3033},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhou24b/zhou24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhou24b.html},\n  abstract = \t {This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhou24b/zhou24b.pdf",
        "supp": "",
        "pdf_size": 439822,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9837856269823068393&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f6981d13cc",
        "title": "Riemannian Laplace Approximation with the Fisher Metric",
        "site": "https://proceedings.mlr.press/v238/yu24a.html",
        "author": "Hanlin Yu; Marcelo Hartmann; Bernardo Williams Moreno Sanchez; Mark Girolami; Arto Klami",
        "abstract": "Laplace\u2019s method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.",
        "bibtex": "@InProceedings{pmlr-v238-yu24a,\n  title = \t {Riemannian {L}aplace Approximation with the {F}isher Metric},\n  author =       {Yu, Hanlin and Hartmann, Marcelo and Williams Moreno Sanchez, Bernardo and Girolami, Mark and Klami, Arto},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {820--828},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yu24a/yu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yu24a.html},\n  abstract = \t {Laplace\u2019s method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yu24a/yu24a.pdf",
        "supp": "",
        "pdf_size": 9029497,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13306070088849702217&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Helsinki; Department of Computer Science, University of Helsinki; Department of Computer Science, University of Helsinki; Department of Engineering, University of Cambridge and The Alan Turing Institute; Department of Computer Science, University of Helsinki",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Helsinki;University of Cambridge",
        "aff_unique_dep": "Department of Computer Science;Department of Engineering",
        "aff_unique_url": "https://www.helsinki.fi;https://www.cam.ac.uk",
        "aff_unique_abbr": "UH;Cambridge",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Finland;United Kingdom"
    },
    {
        "id": "c722d6d0b0",
        "title": "Risk Seeking Bayesian Optimization under Uncertainty for Obtaining Extremum",
        "site": "https://proceedings.mlr.press/v238/iwazaki24a.html",
        "author": "Shogo Iwazaki; Tomohiko Tanabe; Mitsuru Irie; Shion Takeno; Yu Inatsu",
        "abstract": "Real-world black-box optimization tasks often focus on obtaining the best reward, which includes an intrinsic random quantity from uncontrollable environmental factors. For this problem, we formulate a novel risk-seeking optimization problem whose aim is to obtain the best possible reward within a fixed budget under uncontrollable factors. We consider two settings: (1) environmental model setting for the case that we can observe uncontrollable environmental variables that affect the observation as the input of a target function, and (2) heteroscedastic model setting for the case that any uncontrollable variables cannot be observed. We propose a novel Bayesian optimization method called kernel explore-then-commit (kernel-ETC) and provide the regret upper bound for both settings. We demonstrate the effectiveness of kernel-ETC through several numerical experiments, including the hyperparameter tuning task and the simulation function derived from polymer synthesis real data.",
        "bibtex": "@InProceedings{pmlr-v238-iwazaki24a,\n  title = \t {Risk Seeking {B}ayesian Optimization under Uncertainty for Obtaining Extremum},\n  author =       {Iwazaki, Shogo and Tanabe, Tomohiko and Irie, Mitsuru and Takeno, Shion and Inatsu, Yu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1252--1260},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/iwazaki24a/iwazaki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/iwazaki24a.html},\n  abstract = \t {Real-world black-box optimization tasks often focus on obtaining the best reward, which includes an intrinsic random quantity from uncontrollable environmental factors. For this problem, we formulate a novel risk-seeking optimization problem whose aim is to obtain the best possible reward within a fixed budget under uncontrollable factors. We consider two settings: (1) environmental model setting for the case that we can observe uncontrollable environmental variables that affect the observation as the input of a target function, and (2) heteroscedastic model setting for the case that any uncontrollable variables cannot be observed. We propose a novel Bayesian optimization method called kernel explore-then-commit (kernel-ETC) and provide the regret upper bound for both settings. We demonstrate the effectiveness of kernel-ETC through several numerical experiments, including the hyperparameter tuning task and the simulation function derived from polymer synthesis real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/iwazaki24a/iwazaki24a.pdf",
        "supp": "",
        "pdf_size": 765590,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2238418895989964363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "MI-6 Ltd.; MI-6 Ltd.; MI-6 Ltd.; RIKEN; Nagoya Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "MI-6;RIKEN;Nagoya Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.mi6.gov.uk;https://www.riken.jp;https://www.nitech.ac.jp",
        "aff_unique_abbr": "MI-6;RIKEN;NIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "United Kingdom;Japan"
    },
    {
        "id": "8e2b1b4d2a",
        "title": "Robust Approximate Sampling via Stochastic Gradient Barker Dynamics",
        "site": "https://proceedings.mlr.press/v238/mauri24a.html",
        "author": "Lorenzo Mauri; Giacomo Zanella",
        "abstract": "Stochastic Gradient (SG) Markov Chain Monte Carlo algorithms (MCMC) are popular algorithms for Bayesian sampling in the presence of large datasets. However, they come with little theoretical guarantees and assessing their empirical performances is non-trivial. In such context, it is crucial to develop algorithms that are robust to the choice of hyperparameters and to gradients heterogeneity since, in practice, both the choice of step-size and behaviour of target gradients induce hard-to-control biases in the invariant distribution. In this work we introduce the stochastic gradient Barker dynamics (SGBD) algorithm, extending the recently developed Barker MCMC scheme, a robust alternative to Langevin-based sampling algorithms, to the stochastic gradient framework. We characterize the impact of stochastic gradients on the Barker transition mechanism and develop a bias-corrected version that, under suitable assumptions, eliminates the error due to the gradient noise in the proposal. We illustrate the performance on a number of high-dimensional examples, showing that SGBD is more robust to hyperparameter tuning and to irregular behavior of the target gradients compared to the popular stochastic gradient Langevin dynamics algorithm.",
        "bibtex": "@InProceedings{pmlr-v238-mauri24a,\n  title = \t {Robust Approximate Sampling via Stochastic Gradient Barker Dynamics},\n  author =       {Mauri, Lorenzo and Zanella, Giacomo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2107--2115},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mauri24a/mauri24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mauri24a.html},\n  abstract = \t {Stochastic Gradient (SG) Markov Chain Monte Carlo algorithms (MCMC) are popular algorithms for Bayesian sampling in the presence of large datasets. However, they come with little theoretical guarantees and assessing their empirical performances is non-trivial. In such context, it is crucial to develop algorithms that are robust to the choice of hyperparameters and to gradients heterogeneity since, in practice, both the choice of step-size and behaviour of target gradients induce hard-to-control biases in the invariant distribution. In this work we introduce the stochastic gradient Barker dynamics (SGBD) algorithm, extending the recently developed Barker MCMC scheme, a robust alternative to Langevin-based sampling algorithms, to the stochastic gradient framework. We characterize the impact of stochastic gradients on the Barker transition mechanism and develop a bias-corrected version that, under suitable assumptions, eliminates the error due to the gradient noise in the proposal. We illustrate the performance on a number of high-dimensional examples, showing that SGBD is more robust to hyperparameter tuning and to irregular behavior of the target gradients compared to the popular stochastic gradient Langevin dynamics algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mauri24a/mauri24a.pdf",
        "supp": "",
        "pdf_size": 2665593,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=250853128958366743&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistical Science, Duke University; Department of Decision Sciences and BIDSA, Bocconi University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Duke University;Bocconi University",
        "aff_unique_dep": "Department of Statistical Science;Department of Decision Sciences and BIDSA",
        "aff_unique_url": "https://www.duke.edu;https://www.bocconi.edu",
        "aff_unique_abbr": "Duke;Bocconi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "94dba83841",
        "title": "Robust Data Clustering with Outliers via Transformed Tensor Low-Rank Representation",
        "site": "https://proceedings.mlr.press/v238/wu24c.html",
        "author": "Tong Wu",
        "abstract": "Recently, tensor low-rank representation (TLRR) has become a popular tool for tensor data recovery and clustering, due to its empirical success and theoretical guarantees. However, existing TLRR methods consider Gaussian or gross sparse noise, inevitably leading to performance degradation when the tensor data are contaminated by outliers or sample-specific corruptions. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method that provides outlier detection and tensor data clustering simultaneously based on the t-SVD framework. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is proposed to handle the case when parts of the data are missing. Finally, extensive experimental results on synthetic and real data demonstrate the effectiveness of the proposed algorithms. We release our code at \\url{https://github.com/twugithub/2024-AISTATS-ORTLRR}.",
        "bibtex": "@InProceedings{pmlr-v238-wu24c,\n  title = \t {Robust Data Clustering with Outliers via Transformed Tensor Low-Rank Representation},\n  author =       {Wu, Tong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1756--1764},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24c/wu24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24c.html},\n  abstract = \t {Recently, tensor low-rank representation (TLRR) has become a popular tool for tensor data recovery and clustering, due to its empirical success and theoretical guarantees. However, existing TLRR methods consider Gaussian or gross sparse noise, inevitably leading to performance degradation when the tensor data are contaminated by outliers or sample-specific corruptions. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method that provides outlier detection and tensor data clustering simultaneously based on the t-SVD framework. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is proposed to handle the case when parts of the data are missing. Finally, extensive experimental results on synthetic and real data demonstrate the effectiveness of the proposed algorithms. We release our code at \\url{https://github.com/twugithub/2024-AISTATS-ORTLRR}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24c/wu24c.pdf",
        "supp": "",
        "pdf_size": 1482664,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6427950206657339433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Beijing Institute for General Artificial Intelligence",
        "aff_domain": "bigai.ai",
        "email": "bigai.ai",
        "github": "https://github.com/twugithub/2024-AISTATS-ORTLRR",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Beijing Institute for General Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.bigaiai.org/",
        "aff_unique_abbr": "BIGAI",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "f0877ff022",
        "title": "Robust Non-linear Normalization of Heterogeneous Feature Distributions with Adaptive Tanh-Estimators",
        "site": "https://proceedings.mlr.press/v238/guimera-cuevas24a.html",
        "author": "Felip Guimer\u00e0 Cuevas; Helmut Schmid",
        "abstract": "Feature normalization is a crucial step in machine learning that scales numerical values to improve model effectiveness. Noisy or impure datasets can pose a challenge for traditional normalization methods as they may contain outliers that violate statistical assumptions, leading to reduced model performance and increased unpredictability. Non-linear Tanh-Estimators (TE) have been found to provide robust feature normalization, but their fixed scaling factor may not be appropriate for all distributions of feature values. This work presents a refinement to the TE that employs the Wasserstein distance to adaptively estimate the optimal scaling factor for each feature individually against a specified target distribution. The results demonstrate that this adaptive approach can outperform the current TE method in the literature in terms of convergence speed by enabling better initial training starts, thus reducing or eliminating the need to re-adjust model weights during early training phases due to inadequately scaled features. Empirical evaluation was done on synthetic data, standard toy computer vision datasets, and a real-world numeric tabular dataset.",
        "bibtex": "@InProceedings{pmlr-v238-guimera-cuevas24a,\n  title = \t {Robust Non-linear Normalization of Heterogeneous Feature Distributions with Adaptive Tanh-Estimators},\n  author =       {Guimer\\`{a} Cuevas, Felip and Schmid, Helmut},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {406--414},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/guimera-cuevas24a/guimera-cuevas24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/guimera-cuevas24a.html},\n  abstract = \t {Feature normalization is a crucial step in machine learning that scales numerical values to improve model effectiveness. Noisy or impure datasets can pose a challenge for traditional normalization methods as they may contain outliers that violate statistical assumptions, leading to reduced model performance and increased unpredictability. Non-linear Tanh-Estimators (TE) have been found to provide robust feature normalization, but their fixed scaling factor may not be appropriate for all distributions of feature values. This work presents a refinement to the TE that employs the Wasserstein distance to adaptively estimate the optimal scaling factor for each feature individually against a specified target distribution. The results demonstrate that this adaptive approach can outperform the current TE method in the literature in terms of convergence speed by enabling better initial training starts, thus reducing or eliminating the need to re-adjust model weights during early training phases due to inadequately scaled features. Empirical evaluation was done on synthetic data, standard toy computer vision datasets, and a real-world numeric tabular dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/guimera-cuevas24a/guimera-cuevas24a.pdf",
        "supp": "",
        "pdf_size": 912093,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4004607509362233413&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "BMW Group Munich, Germany + Center for Information and Language Processing, LMU Munich, Germany; Center for Information and Language Processing, LMU Munich, Germany",
        "aff_domain": "bmw.de;cis.lmu.de",
        "email": "bmw.de;cis.lmu.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "BMW Group;LMU Munich",
        "aff_unique_dep": ";Center for Information and Language Processing",
        "aff_unique_url": "https://www.bmwgroup.com;https://www.lmu.de",
        "aff_unique_abbr": "BMW;LMU",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "f4e7d3f842",
        "title": "Robust Offline Reinforcement Learning with Heavy-Tailed Rewards",
        "site": "https://proceedings.mlr.press/v238/zhu24a.html",
        "author": "Jin Zhu; Runzhe Wan; Zhengling Qi; Shikai Luo; Chengchun Shi",
        "abstract": "This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. The implementation of the proposal is available at \\url{https://github.com/Mamba413/ROOM}.",
        "bibtex": "@InProceedings{pmlr-v238-zhu24a,\n  title = \t {Robust Offline Reinforcement Learning with Heavy-Tailed Rewards},\n  author =       {Zhu, Jin and Wan, Runzhe and Qi, Zhengling and Luo, Shikai and Shi, Chengchun},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {541--549},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhu24a/zhu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhu24a.html},\n  abstract = \t {This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. The implementation of the proposal is available at \\url{https://github.com/Mamba413/ROOM}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhu24a/zhu24a.pdf",
        "supp": "",
        "pdf_size": 884894,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6504473970592043730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "LSE; Amazon; George Washington University; Bytedance; LSE",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/Mamba413/ROOM",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "London School of Economics and Political Science;Amazon;George Washington University;ByteDance",
        "aff_unique_dep": ";Amazon.com, Inc.;;",
        "aff_unique_url": "https://www.lse.ac.uk;https://www.amazon.com;https://www.gwu.edu;https://www.bytedance.com",
        "aff_unique_abbr": "LSE;Amazon;GWU;Bytedance",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;0",
        "aff_country_unique": "United Kingdom;United States;China"
    },
    {
        "id": "a5660e790f",
        "title": "Robust SVD Made Easy: A fast and reliable algorithm for large-scale data analysis",
        "site": "https://proceedings.mlr.press/v238/han24a.html",
        "author": "Sangil Han; Sungkyu Jung; Kyoowon Kim",
        "abstract": "The singular value decomposition (SVD) is a crucial tool in machine learning and statistical data analysis. However, it is highly susceptible to outliers in the data matrix. Existing robust SVD algorithms often sacrifice speed for robustness or fail in the presence of only a few outliers. This study introduces an efficient algorithm, called Spherically Normalized SVD, for robust SVD approximation that is highly insensitive to outliers, computationally scalable, and provides accurate approximations of singular vectors. The proposed algorithm achieves remarkable speed by utilizing only two applications of a standard reduced-rank SVD algorithm to appropriately scaled data, significantly outperforming competing algorithms in computation times. To assess the robustness of the approximated singular vectors and their subspaces against data contamination, we introduce new notions of breakdown points for matrix-valued input, including row-wise, column-wise, and block-wise breakdown points. Theoretical and empirical analyses demonstrate that our algorithm exhibits higher breakdown points compared to standard SVD and its modifications. We empirically validate the effectiveness of our approach in applications such as robust low-rank approximation and robust principal component analysis of high-dimensional microarray datasets. Overall, our study presents a highly efficient and robust solution for SVD approximation that overcomes the limitations of existing algorithms in the presence of outliers.",
        "bibtex": "@InProceedings{pmlr-v238-han24a,\n  title = \t {Robust {SVD} Made Easy: A fast and reliable algorithm for large-scale data analysis},\n  author =       {Han, Sangil and Jung, Sungkyu and Kim, Kyoowon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1765--1773},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/han24a/han24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/han24a.html},\n  abstract = \t {The singular value decomposition (SVD) is a crucial tool in machine learning and statistical data analysis. However, it is highly susceptible to outliers in the data matrix. Existing robust SVD algorithms often sacrifice speed for robustness or fail in the presence of only a few outliers. This study introduces an efficient algorithm, called Spherically Normalized SVD, for robust SVD approximation that is highly insensitive to outliers, computationally scalable, and provides accurate approximations of singular vectors. The proposed algorithm achieves remarkable speed by utilizing only two applications of a standard reduced-rank SVD algorithm to appropriately scaled data, significantly outperforming competing algorithms in computation times. To assess the robustness of the approximated singular vectors and their subspaces against data contamination, we introduce new notions of breakdown points for matrix-valued input, including row-wise, column-wise, and block-wise breakdown points. Theoretical and empirical analyses demonstrate that our algorithm exhibits higher breakdown points compared to standard SVD and its modifications. We empirically validate the effectiveness of our approach in applications such as robust low-rank approximation and robust principal component analysis of high-dimensional microarray datasets. Overall, our study presents a highly efficient and robust solution for SVD approximation that overcomes the limitations of existing algorithms in the presence of outliers.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/han24a/han24a.pdf",
        "supp": "",
        "pdf_size": 1062999,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12541028301308212407&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9013e1cec1",
        "title": "Robust Sparse Voting",
        "site": "https://proceedings.mlr.press/v238/allouah24a.html",
        "author": "Youssef Allouah; Rachid Guerraoui; L\u00ea-Nguy\u00ean Hoang; Oscar Villemaud",
        "abstract": "Many applications, such as content moderation and recommendation, require reviewing and scoring a large number of alternatives. Doing so robustly is however very challenging. Indeed, voters\u2019 inputs are inevitably sparse: most alternatives are only scored by a small fraction of voters. This sparsity amplifies the effects of biased voters introducing unfairness, and of malicious voters seeking to hack the voting process by reporting dishonest scores. We give a precise definition of the problem of robust sparse voting, highlight its underlying technical challenges, and present a novel voting mechanism addressing the problem. We prove that, using this mechanism, no voter can have more than a small parameterizable effect on each alternative\u2019s score; a property we call Lipschitz resilience. We also identify conditions of voters comparability under which any unanimous preferences can be recovered, even when each voter provides sparse scores, on a scale that is potentially very different from any other voter\u2019s score scale. Proving these properties required us to introduce, analyze and carefully compose novel aggregation primitives which could be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v238-allouah24a,\n  title = \t {Robust Sparse Voting},\n  author =       {Allouah, Youssef and Guerraoui, Rachid and Hoang, L\\^{e}-Nguy\\^{e}n and Villemaud, Oscar},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {991--999},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/allouah24a/allouah24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/allouah24a.html},\n  abstract = \t {Many applications, such as content moderation and recommendation, require reviewing and scoring a large number of alternatives. Doing so robustly is however very challenging. Indeed, voters\u2019 inputs are inevitably sparse: most alternatives are only scored by a small fraction of voters. This sparsity amplifies the effects of biased voters introducing unfairness, and of malicious voters seeking to hack the voting process by reporting dishonest scores. We give a precise definition of the problem of robust sparse voting, highlight its underlying technical challenges, and present a novel voting mechanism addressing the problem. We prove that, using this mechanism, no voter can have more than a small parameterizable effect on each alternative\u2019s score; a property we call Lipschitz resilience. We also identify conditions of voters comparability under which any unanimous preferences can be recovered, even when each voter provides sparse scores, on a scale that is potentially very different from any other voter\u2019s score scale. Proving these properties required us to introduce, analyze and carefully compose novel aggregation primitives which could be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/allouah24a/allouah24a.pdf",
        "supp": "",
        "pdf_size": 1148042,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14238700647311400910&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "EPFL; EPFL; Calicarpa, Tournesol Association; EPFL",
        "aff_domain": "epfl.ch;epfl.ch;tournesol.app;epfl.ch",
        "email": "epfl.ch;epfl.ch;tournesol.app;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "EPFL;Tournesol Association",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.epfl.ch;",
        "aff_unique_abbr": "EPFL;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland;"
    },
    {
        "id": "5c01ee04fe",
        "title": "Robust variance-regularized risk minimization with concomitant scaling",
        "site": "https://proceedings.mlr.press/v238/holland24a.html",
        "author": "Matthew J. Holland",
        "abstract": "Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets.",
        "bibtex": "@InProceedings{pmlr-v238-holland24a,\n  title = \t {Robust variance-regularized risk minimization with concomitant scaling},\n  author =       {Holland, Matthew J.},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1144--1152},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/holland24a/holland24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/holland24a.html},\n  abstract = \t {Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/holland24a/holland24a.pdf",
        "supp": "",
        "pdf_size": 353475,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9313657278343772685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Osaka University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "91b183da01",
        "title": "SADI: Similarity-Aware Diffusion Model-Based Imputation for Incomplete Temporal EHR Data",
        "site": "https://proceedings.mlr.press/v238/dai24c.html",
        "author": "Zongyu Dai; Emily Getzen; Qi Long",
        "abstract": "Missing values are prevalent in temporal electronic health records (EHR) data and are known to complicate data analysis and lead to biased results. The current state-of-the-art (SOTA) models for imputing missing values in EHR primarily leverage correlations across time points and across features, which perform well when data have strong correlation across time points, such as in ICU data where high-frequency time series data are collected. However, this is often insufficient for temporal EHR data from non-ICU settings (e.g., outpatient visits for primary care or specialty care), where data are collected at substantially sparser time points, resulting in much weaker correlation across time points. To address this methodological gap, we propose the Similarity-Aware Diffusion Model-Based Imputation (SADI), a novel imputation method that leverages the diffusion model and utilizes information across dependent variables. We apply SADI to impute incomplete temporal EHR data and propose a similarity-aware denoising function, which includes a self-attention mechanism to model the correlations between time points, features, and similar patients. To the best of our knowledge, this is the first time that the information of similar patients is directly used to construct imputation for incomplete temporal EHR data. Our extensive experiments on two datasets, the Critical Path For Alzheimer\u2019s Disease (CPAD) data and the PhysioNet Challenge 2012 data, show that SADI outperforms the current SOTA under various missing data mechanisms, including missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).",
        "bibtex": "@InProceedings{pmlr-v238-dai24c,\n  title = \t {{SADI}: Similarity-Aware Diffusion Model-Based Imputation for Incomplete Temporal {EHR} Data},\n  author =       {Dai, Zongyu and Getzen, Emily and Long, Qi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4195--4203},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dai24c/dai24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dai24c.html},\n  abstract = \t {Missing values are prevalent in temporal electronic health records (EHR) data and are known to complicate data analysis and lead to biased results. The current state-of-the-art (SOTA) models for imputing missing values in EHR primarily leverage correlations across time points and across features, which perform well when data have strong correlation across time points, such as in ICU data where high-frequency time series data are collected. However, this is often insufficient for temporal EHR data from non-ICU settings (e.g., outpatient visits for primary care or specialty care), where data are collected at substantially sparser time points, resulting in much weaker correlation across time points. To address this methodological gap, we propose the Similarity-Aware Diffusion Model-Based Imputation (SADI), a novel imputation method that leverages the diffusion model and utilizes information across dependent variables. We apply SADI to impute incomplete temporal EHR data and propose a similarity-aware denoising function, which includes a self-attention mechanism to model the correlations between time points, features, and similar patients. To the best of our knowledge, this is the first time that the information of similar patients is directly used to construct imputation for incomplete temporal EHR data. Our extensive experiments on two datasets, the Critical Path For Alzheimer\u2019s Disease (CPAD) data and the PhysioNet Challenge 2012 data, show that SADI outperforms the current SOTA under various missing data mechanisms, including missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dai24c/dai24c.pdf",
        "supp": "",
        "pdf_size": 614753,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3316679800747100652&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Pennsylvania; University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "sas.upenn.edu;pennmedicine.upenn.edu;upenn.edu",
        "email": "sas.upenn.edu;pennmedicine.upenn.edu;upenn.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "20d297aa51",
        "title": "SDEs for Minimax Optimization",
        "site": "https://proceedings.mlr.press/v238/monzio-compagnoni24a.html",
        "author": "Enea Monzio Compagnoni; Antonio Orvieto; Hans Kersting; Frank Proske; Aurelien Lucchi",
        "abstract": "Minimax optimization problems have attracted a lot of attention over the past few years, with applications ranging from economics to machine learning. While advanced optimization methods exist for such problems, characterizing their dynamics in stochastic scenarios remains notably challenging. In this paper, we pioneer the use of stochastic differential equations (SDEs) to analyze and compare Minimax optimizers. Our SDE models for Stochastic Gradient Descent-Ascent, Stochastic Extragradient, and Stochastic Hamiltonian Gradient Descent are provable approximations of their algorithmic counterparts, clearly showcasing the interplay between hyperparameters, implicit regularization, and implicit curvature-induced noise. This perspective also allows for a unified and simplified analysis strategy based on the principles of It\u00f4 calculus. Finally, our approach facilitates the derivation of convergence conditions and closed-form solutions for the dynamics in simplified settings, unveiling further insights into the behavior of different optimizers.",
        "bibtex": "@InProceedings{pmlr-v238-monzio-compagnoni24a,\n  title = \t {{SDE}s for Minimax Optimization},\n  author =       {Monzio Compagnoni, Enea and Orvieto, Antonio and Kersting, Hans and Proske, Frank and Lucchi, Aurelien},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4834--4842},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/monzio-compagnoni24a/monzio-compagnoni24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/monzio-compagnoni24a.html},\n  abstract = \t {Minimax optimization problems have attracted a lot of attention over the past few years, with applications ranging from economics to machine learning. While advanced optimization methods exist for such problems, characterizing their dynamics in stochastic scenarios remains notably challenging. In this paper, we pioneer the use of stochastic differential equations (SDEs) to analyze and compare Minimax optimizers. Our SDE models for Stochastic Gradient Descent-Ascent, Stochastic Extragradient, and Stochastic Hamiltonian Gradient Descent are provable approximations of their algorithmic counterparts, clearly showcasing the interplay between hyperparameters, implicit regularization, and implicit curvature-induced noise. This perspective also allows for a unified and simplified analysis strategy based on the principles of It\u00f4 calculus. Finally, our approach facilitates the derivation of convergence conditions and closed-form solutions for the dynamics in simplified settings, unveiling further insights into the behavior of different optimizers.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/monzio-compagnoni24a/monzio-compagnoni24a.pdf",
        "supp": "",
        "pdf_size": 3166620,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11002452191738067937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics and Computer Science, University of Basel+ELLIS Institute T\u00fcbingen+MPI for Intelligent Systems+T\u00fcbingen AI Center+Yahoo! Research; Department of Mathematics and Computer Science, University of Basel+ELLIS Institute T\u00fcbingen+MPI for Intelligent Systems+T\u00fcbingen AI Center+Yahoo! Research; Department of Mathematics and Computer Science, University of Basel+ELLIS Institute T\u00fcbingen+MPI for Intelligent Systems+T\u00fcbingen AI Center+Yahoo! Research; Department of Mathematics, University of Oslo; Department of Mathematics and Computer Science, University of Basel",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2+3+4;0+1+2+3+4;0+1+2+3+4;5;0",
        "aff_unique_norm": "University of Basel;ELLIS Institute;Max Planck Institute for Intelligent Systems;University of T\u00fcbingen;Yahoo!;University of Oslo",
        "aff_unique_dep": "Department of Mathematics and Computer Science;;;AI Center;Yahoo! Research;Department of Mathematics",
        "aff_unique_url": "https://www.unibas.ch;https://ellis.eu/;https://www.mpi-is.mpg.de;https://www.uni-tuebingen.de/;https://research.yahoo.com;https://www.uio.no",
        "aff_unique_abbr": "UniBas;ELLIS;MPI-IS;Uni T\u00fcbingen;Yahoo!;UiO",
        "aff_campus_unique_index": "1+1;1+1;1+1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0+1+1+1+2;0+1+1+1+2;0+1+1+1+2;3;0",
        "aff_country_unique": "Switzerland;Germany;United States;Norway"
    },
    {
        "id": "13ee5dced8",
        "title": "SDMTR: A Brain-inspired Transformer for Relation Inference",
        "site": "https://proceedings.mlr.press/v238/zeng24a.html",
        "author": "Xiangyu Zeng; Jie Lin; Piao Hu; Zhihao Li; Tianxi Huang",
        "abstract": "Deep learning has seen a movement towards the concepts of modularity, module coordination and sparse interactions to fit the working principles of biological systems. Inspired by Global Workspace Theory and long-term memory system in human brain, both are instrumental in constructing biologically plausible artificial intelligence systems, we introduce the shared dual-memory Transformers (SDMTR)\u2014 a model that builds upon Transformers. The proposed approach includes the shared long-term memory and workspace with finite capacity in which different specialized modules compete to write information. Later, crucial information from shared workspace is inscribed into long-term memory through outer product attention mechanism to reduce information conflict and build a knowledge reservoir, thereby facilitating subsequent inference, learning and problem-solving. We apply SDMTR to multi-modality question-answering and reasoning challenges, including text-based bAbI-20k, visual Sort-of-CLEVR and triangle relations detection tasks. The results demonstrate that our SDMTR significantly outperforms the vanilla Transformer and its recent improvements. Additionally, visualization analyses indicate that the presence of memory positively correlates with model effectiveness on inference tasks. This research provides novel insights and empirical support to advance biologically plausible deep learning frameworks.",
        "bibtex": "@InProceedings{pmlr-v238-zeng24a,\n  title = \t {{SDMTR}: A Brain-inspired Transformer for Relation Inference},\n  author =       {Zeng, Xiangyu and Lin, Jie and Hu, Piao and Li, Zhihao and Huang, Tianxi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3259--3267},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zeng24a/zeng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zeng24a.html},\n  abstract = \t {Deep learning has seen a movement towards the concepts of modularity, module coordination and sparse interactions to fit the working principles of biological systems. Inspired by Global Workspace Theory and long-term memory system in human brain, both are instrumental in constructing biologically plausible artificial intelligence systems, we introduce the shared dual-memory Transformers (SDMTR)\u2014 a model that builds upon Transformers. The proposed approach includes the shared long-term memory and workspace with finite capacity in which different specialized modules compete to write information. Later, crucial information from shared workspace is inscribed into long-term memory through outer product attention mechanism to reduce information conflict and build a knowledge reservoir, thereby facilitating subsequent inference, learning and problem-solving. We apply SDMTR to multi-modality question-answering and reasoning challenges, including text-based bAbI-20k, visual Sort-of-CLEVR and triangle relations detection tasks. The results demonstrate that our SDMTR significantly outperforms the vanilla Transformer and its recent improvements. Additionally, visualization analyses indicate that the presence of memory positively correlates with model effectiveness on inference tasks. This research provides novel insights and empirical support to advance biologically plausible deep learning frameworks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zeng24a/zeng24a.pdf",
        "supp": "",
        "pdf_size": 2463131,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:SAvcy2qFuuQJ:scholar.google.com/&scioq=SDMTR:+A+Brain-inspired+Transformer+for+Relation+Inference&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Department of Fundamental Courses, Chengdu Textile College",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;ctc.edu.cn",
        "email": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;ctc.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Chengdu Textile College",
        "aff_unique_dep": ";Department of Fundamental Courses",
        "aff_unique_url": "https://www.uestc.edu.cn;",
        "aff_unique_abbr": "UESTC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "a996b2d4d4",
        "title": "SIFU: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization",
        "site": "https://proceedings.mlr.press/v238/fraboni24a.html",
        "author": "Yann Fraboni; Martin Van Waerebeke; Kevin Scaman; Richard Vidal; Laetitia Kameni; Marco Lorenzi",
        "abstract": "Machine Unlearning (MU) is an increasingly important topic in machine learning safety, aiming at removing the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client\u2019s contribution from a federated training routine. While several FU methods have been proposed, we currently lack a general approach providing formal unlearning guarantees to the FedAvg routine, while ensuring scalability and generalization beyond the convex assumption on the clients\u2019 loss functions. We aim at filling this gap by proposing SIFU (Sequential Informed Federated Unlearning), a new FU method applying to both convex and non-convex optimization regimes. SIFU naturally applies to FedAvg without additional computational cost for the clients and provides formal guarantees on the quality of the unlearning task. We provide a theoretical analysis of the unlearning properties of SIFU, and practically demonstrate its effectiveness as compared to a panel of unlearning methods from the state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v238-fraboni24a,\n  title = \t {{SIFU}: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization},\n  author =       {Fraboni, Yann and Van Waerebeke, Martin and Scaman, Kevin and Vidal, Richard and Kameni, Laetitia and Lorenzi, Marco},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3457--3465},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fraboni24a/fraboni24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fraboni24a.html},\n  abstract = \t {Machine Unlearning (MU) is an increasingly important topic in machine learning safety, aiming at removing the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client\u2019s contribution from a federated training routine. While several FU methods have been proposed, we currently lack a general approach providing formal unlearning guarantees to the FedAvg routine, while ensuring scalability and generalization beyond the convex assumption on the clients\u2019 loss functions. We aim at filling this gap by proposing SIFU (Sequential Informed Federated Unlearning), a new FU method applying to both convex and non-convex optimization regimes. SIFU naturally applies to FedAvg without additional computational cost for the clients and provides formal guarantees on the quality of the unlearning task. We provide a theoretical analysis of the unlearning properties of SIFU, and practically demonstrate its effectiveness as compared to a panel of unlearning methods from the state-of-the-art.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fraboni24a/fraboni24a.pdf",
        "supp": "",
        "pdf_size": 1189521,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8741260982116136074&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f018dc24f6",
        "title": "SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits",
        "site": "https://proceedings.mlr.press/v238/mukherjee24a.html",
        "author": "Subhojyoti Mukherjee; Qiaomin Xie; Josiah P Hanna; Robert Nowak",
        "abstract": "In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a \\textit{target} policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such an optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting with the knowledge of noise variances. This design minimizes the mean squared error (MSE) of the estimated value of the target policy and is termed the oracle design. Since the noise variance is typically unknown, we then introduce a novel algorithm, SPEED (\\textbf{S}tructured \\textbf{P}olicy \\textbf{E}valuation \\textbf{E}xperimental \\textbf{D}esign), that tracks the oracle design and derive its regret with respect to the oracle design. We show that regret scales as $\\widetilde{O}_{}(d^3 n^{-3/2})$ and prove a matching lower bound of $\\Omega(d^2 n^{-3/2})$. Finally, we evaluate SPEED on a set of policy evaluation tasks and demonstrate that it achieves MSE comparable to an optimal oracle and much lower than simply running the target policy.",
        "bibtex": "@InProceedings{pmlr-v238-mukherjee24a,\n  title = \t {SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits},\n  author =       {Mukherjee, Subhojyoti and Xie, Qiaomin and P Hanna, Josiah and Nowak, Robert},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2962--2970},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mukherjee24a/mukherjee24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mukherjee24a.html},\n  abstract = \t {In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a \\textit{target} policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such an optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting with the knowledge of noise variances. This design minimizes the mean squared error (MSE) of the estimated value of the target policy and is termed the oracle design. Since the noise variance is typically unknown, we then introduce a novel algorithm, SPEED (\\textbf{S}tructured \\textbf{P}olicy \\textbf{E}valuation \\textbf{E}xperimental \\textbf{D}esign), that tracks the oracle design and derive its regret with respect to the oracle design. We show that regret scales as $\\widetilde{O}_{}(d^3 n^{-3/2})$ and prove a matching lower bound of $\\Omega(d^2 n^{-3/2})$. Finally, we evaluate SPEED on a set of policy evaluation tasks and demonstrate that it achieves MSE comparable to an optimal oracle and much lower than simply running the target policy.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mukherjee24a/mukherjee24a.pdf",
        "supp": "",
        "pdf_size": 1359068,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18413741079627589949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3e0a301dd3",
        "title": "SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification",
        "site": "https://proceedings.mlr.press/v238/kolpaczki24a.html",
        "author": "Patrick Kolpaczki; Maximilian Muschalik; Fabian Fumagalli; Barbara Hammer; Eyke H\u00fcllermeier",
        "abstract": "Addressing the limitations of individual attribution scores via the Shapley value (SV), the field of explainable AI (XAI) has recently explored intricate interactions of features or data points. In particular, extensions of the SV, such as the Shapley Interaction Index (SII), have been proposed as a measure to still benefit from the axiomatic basis of the SV. However, similar to the SV, their exact computation remains computationally prohibitive. Hence, we propose with SVARM-IQ a sampling-based approach to efficiently approximate Shapley-based interaction indices of any order. SVARM-IQ can be applied to a broad class of interaction indices, including the SII, by leveraging a novel stratified representation. We provide non-asymptotic theoretical guarantees on its approximation quality and empirically demonstrate that SVARM-IQ achieves state-of-the-art estimation results in practical XAI scenarios on different model classes and application domains.",
        "bibtex": "@InProceedings{pmlr-v238-kolpaczki24a,\n  title = \t {{SVARM-IQ}: Efficient Approximation of Any-order {S}hapley Interactions through Stratification},\n  author =       {Kolpaczki, Patrick and Muschalik, Maximilian and Fumagalli, Fabian and Hammer, Barbara and H\\\"{u}llermeier, Eyke},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3520--3528},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kolpaczki24a/kolpaczki24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kolpaczki24a.html},\n  abstract = \t {Addressing the limitations of individual attribution scores via the Shapley value (SV), the field of explainable AI (XAI) has recently explored intricate interactions of features or data points. In particular, extensions of the SV, such as the Shapley Interaction Index (SII), have been proposed as a measure to still benefit from the axiomatic basis of the SV. However, similar to the SV, their exact computation remains computationally prohibitive. Hence, we propose with SVARM-IQ a sampling-based approach to efficiently approximate Shapley-based interaction indices of any order. SVARM-IQ can be applied to a broad class of interaction indices, including the SII, by leveraging a novel stratified representation. We provide non-asymptotic theoretical guarantees on its approximation quality and empirically demonstrate that SVARM-IQ achieves state-of-the-art estimation results in practical XAI scenarios on different model classes and application domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kolpaczki24a/kolpaczki24a.pdf",
        "supp": "",
        "pdf_size": 8061230,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7981131484476969618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Paderborn University; University of Munich (LMU) + Munich Center for Machine Learning; CITEC + Bielefeld University; CITEC + Bielefeld University; University of Munich (LMU) + Munich Center for Machine Learning",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3+4;3+4;1+2",
        "aff_unique_norm": "Paderborn University;Ludwig Maximilian University of Munich;Munich Center for Machine Learning;CITEC;Bielefeld University",
        "aff_unique_dep": ";;Center for Machine Learning;;",
        "aff_unique_url": "https://www.upb.de/;https://www.lmu.de;https://www.munich-center-for-machine-learning.de;;https://www.uni-bielefeld.de/",
        "aff_unique_abbr": "UPB;LMU;;;Uni Bielefeld",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0;0;0+0",
        "aff_country_unique": "Germany;"
    },
    {
        "id": "79af819984",
        "title": "Safe and Interpretable Estimation of Optimal Treatment Regimes",
        "site": "https://proceedings.mlr.press/v238/parikh24a.html",
        "author": "Harsh Parikh; Quinn M Lanners; Zade Akras; Sahar Zafar; M Brandon Westover; Cynthia Rudin; Alexander Volfovsky",
        "abstract": "Recent advancements in statistical and reinforcement learning methods have contributed to superior patient care strategies. However, these methods face substantial challenges in high-stakes contexts, including missing data, stochasticity, and the need for interpretability and patient safety. Our work operationalizes a safe and interpretable approach for optimizing treatment regimes by matching patients with similar medical and pharmacological profiles. This allows us to construct optimal policies via interpolation. Our comprehensive simulation study demonstrates our method\u2019s effectiveness in complex scenarios. We use this approach to study seizure treatment in critically ill patients, advocating for personalized strategies based on medical history and pharmacological features. Our findings recommend reducing medication doses for mild, brief seizure episodes and adopting aggressive treatment strategies for severe cases, leading to improved outcomes.",
        "bibtex": "@InProceedings{pmlr-v238-parikh24a,\n  title = \t {Safe and Interpretable Estimation of Optimal Treatment Regimes},\n  author =       {Parikh, Harsh and M Lanners, Quinn and Akras, Zade and Zafar, Sahar and Brandon Westover, M and Rudin, Cynthia and Volfovsky, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2134--2142},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/parikh24a/parikh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/parikh24a.html},\n  abstract = \t {Recent advancements in statistical and reinforcement learning methods have contributed to superior patient care strategies. However, these methods face substantial challenges in high-stakes contexts, including missing data, stochasticity, and the need for interpretability and patient safety. Our work operationalizes a safe and interpretable approach for optimizing treatment regimes by matching patients with similar medical and pharmacological profiles. This allows us to construct optimal policies via interpolation. Our comprehensive simulation study demonstrates our method\u2019s effectiveness in complex scenarios. We use this approach to study seizure treatment in critically ill patients, advocating for personalized strategies based on medical history and pharmacological features. Our findings recommend reducing medication doses for mild, brief seizure episodes and adopting aggressive treatment strategies for severe cases, leading to improved outcomes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/parikh24a/parikh24a.pdf",
        "supp": "",
        "pdf_size": 1165888,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10217279138388269186&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Johns Hopkins University; Duke University; Harvard Medical School; Massachusetts General Hospital; Beth Israel Deaconess Medical Center; Duke University; Duke University",
        "aff_domain": "; ; ; ; ; ; ",
        "email": "; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4;1;1",
        "aff_unique_norm": "Johns Hopkins University;Duke University;Harvard University;Massachusetts General Hospital;Beth Israel Deaconess Medical Center",
        "aff_unique_dep": ";;Medical School;;",
        "aff_unique_url": "https://www.jhu.edu;https://www.duke.edu;https://hms.harvard.edu;https://www.massgeneral.org;https://www.bethisraeldeaconess.org",
        "aff_unique_abbr": "JHU;Duke;HMS;MGH;BIDMC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Boston",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "25b0b9f31e",
        "title": "Sample Complexity Characterization for Linear Contextual MDPs",
        "site": "https://proceedings.mlr.press/v238/deng24a.html",
        "author": "Junze Deng; Yuan Cheng; Shaofeng Zou; Yingbin Liang",
        "abstract": "Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second model is the first-known result for such a type of function approximation models. Comparison between our results for the two models further indicates that having context-varying features leads to much better sample efficiency than having common representations for all contexts under linear CMDPs.",
        "bibtex": "@InProceedings{pmlr-v238-deng24a,\n  title = \t {Sample Complexity Characterization for Linear Contextual {MDP}s},\n  author =       {Deng, Junze and Cheng, Yuan and Zou, Shaofeng and Liang, Yingbin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1693--1701},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/deng24a/deng24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/deng24a.html},\n  abstract = \t {Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second model is the first-known result for such a type of function approximation models. Comparison between our results for the two models further indicates that having context-varying features leads to much better sample efficiency than having common representations for all contexts under linear CMDPs.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/deng24a/deng24a.pdf",
        "supp": "",
        "pdf_size": 470221,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9401498189426006521&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "be2c8acb9a",
        "title": "Sample Efficient Learning of Factored Embeddings of Tensor Fields",
        "site": "https://proceedings.mlr.press/v238/heo24a.html",
        "author": "Taemin Heo; Chandrajit Bajaj",
        "abstract": "Data tensors of orders 2 and greater are now routinely being generated. These data collections are increasingly huge and growing. Many scientific and medical data tensors are tensor fields (e.g., images, videos, geographic data) in which the spatial neighborhood contains important information. Directly accessing such large data tensor collections for information has become increasingly prohibitive. We learn approximate full-rank and compact tensor sketches with decompositive representations providing compact space, time and spectral embeddings of tensor fields. All information querying and post-processing on the original tensor field can now be achieved more efficiently and with customizable accuracy as they are performed on these compact factored sketches in latent generative space. We produce optimal rank-r sketchy Tucker decomposition of arbitrary order data tensors by building compact factor matrices from a sample-efficient sub-sampling of tensor slices. Our sample efficient policy is learned via an adaptable stochastic Thompson sampling using Dirichlet distributions with conjugate priors.",
        "bibtex": "@InProceedings{pmlr-v238-heo24a,\n  title = \t {Sample Efficient Learning of Factored Embeddings of Tensor Fields},\n  author =       {Heo, Taemin and Bajaj, Chandrajit},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4591--4599},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/heo24a/heo24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/heo24a.html},\n  abstract = \t {Data tensors of orders 2 and greater are now routinely being generated. These data collections are increasingly huge and growing. Many scientific and medical data tensors are tensor fields (e.g., images, videos, geographic data) in which the spatial neighborhood contains important information. Directly accessing such large data tensor collections for information has become increasingly prohibitive. We learn approximate full-rank and compact tensor sketches with decompositive representations providing compact space, time and spectral embeddings of tensor fields. All information querying and post-processing on the original tensor field can now be achieved more efficiently and with customizable accuracy as they are performed on these compact factored sketches in latent generative space. We produce optimal rank-r sketchy Tucker decomposition of arbitrary order data tensors by building compact factor matrices from a sample-efficient sub-sampling of tensor slices. Our sample efficient policy is learned via an adaptable stochastic Thompson sampling using Dirichlet distributions with conjugate priors.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/heo24a/heo24a.pdf",
        "supp": "",
        "pdf_size": 9887295,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:HTT55mhY0BUJ:scholar.google.com/&scioq=Sample+Efficient+Learning+of+Factored+Embeddings+of+Tensor+Fields&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Oden Institute of Computational Engineering and Sciences, University of Texas at Austin, Texas, USA; Department of Computer Science and Oden Institute of Computational Engineering and Sciences, University of Texas at Austin, Texas, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science and Oden Institute of Computational Engineering and Sciences",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "218167d12a",
        "title": "Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components",
        "site": "https://proceedings.mlr.press/v238/pal24a.html",
        "author": "Soumyabrata Pal; Prateek Varshney; Gagan Madan; Prateek Jain; Abhradeep Thakurta; Gaurav Aggarwal; Pradeep Shenoy; Gaurav Srivastava",
        "abstract": "Personalization of machine learning (ML) predictions for individual users/domains/enterprises is critical for practical recommendation systems. Standard personalization approaches involve learning a user/domain specific \\emph{embedding} that is fed into a fixed global model which can be limiting. On the other hand, personalizing/fine-tuning model itself for each user/domain \u2014 a.k.a meta-learning \u2014 has high storage/infrastructure cost. Moreover, rigorous theoretical studies of scalable personalization approaches have been very limited. To address the above issues, we propose a novel meta-learning style approach that models network weights as a sum of low-rank and sparse components. This captures common information from multiple individuals/users together in the low-rank part while sparse part captures user-specific idiosyncrasies. We then study the framework in the linear setting, where the problem reduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse matrix using a small number of linear measurements. We propose a computationally efficient alternating minimization method with iterative hard thresholding \u2014 AMHT-LRS \u2014 to learn the low-rank and sparse part. Theoretically, for the realizable Gaussian data setting, we show that AMHT-LRS solves the problem efficiently with nearly optimal sample complexity. Finally, a significant challenge in personalization is ensuring privacy of each user\u2019s sensitive data. We alleviate this problem by proposing a differentially private variant of our method that also is equipped with strong generalization guarantees.",
        "bibtex": "@InProceedings{pmlr-v238-pal24a,\n  title = \t {Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components},\n  author =       {Pal, Soumyabrata and Varshney, Prateek and Madan, Gagan and Jain, Prateek and Thakurta, Abhradeep and Aggarwal, Gaurav and Shenoy, Pradeep and Srivastava, Gaurav},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1702--1710},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pal24a/pal24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pal24a.html},\n  abstract = \t {Personalization of machine learning (ML) predictions for individual users/domains/enterprises is critical for practical recommendation systems. Standard personalization approaches involve learning a user/domain specific \\emph{embedding} that is fed into a fixed global model which can be limiting. On the other hand, personalizing/fine-tuning model itself for each user/domain \u2014 a.k.a meta-learning \u2014 has high storage/infrastructure cost. Moreover, rigorous theoretical studies of scalable personalization approaches have been very limited. To address the above issues, we propose a novel meta-learning style approach that models network weights as a sum of low-rank and sparse components. This captures common information from multiple individuals/users together in the low-rank part while sparse part captures user-specific idiosyncrasies. We then study the framework in the linear setting, where the problem reduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse matrix using a small number of linear measurements. We propose a computationally efficient alternating minimization method with iterative hard thresholding \u2014 AMHT-LRS \u2014 to learn the low-rank and sparse part. Theoretically, for the realizable Gaussian data setting, we show that AMHT-LRS solves the problem efficiently with nearly optimal sample complexity. Finally, a significant challenge in personalization is ensuring privacy of each user\u2019s sensitive data. We alleviate this problem by proposing a differentially private variant of our method that also is equipped with strong generalization guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pal24a/pal24a.pdf",
        "supp": "",
        "pdf_size": 1499793,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=923310537281386888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "612c004638",
        "title": "Sample-efficient neural likelihood-free Bayesian inference of implicit HMMs",
        "site": "https://proceedings.mlr.press/v238/ghosh24b.html",
        "author": "Sanmitra Ghosh; Paul Birrell; Daniela De Angelis",
        "abstract": "Likelihood-free inference methods based on neural conditional density estimation were shown to drastically reduce the simulation burden in comparison to classical methods such as ABC. When applied in the context of any latent variable model, such as a Hidden Markov model (HMM), these methods are designed to only estimate the parameters, rather than the joint distribution of the parameters and the hidden states. Naive application of these methods to a HMM, ignoring the inference of this joint posterior distribution, will thus produce an inaccurate estimate of the posterior predictive distribution, in turn hampering the assessment of goodness-of-fit. To rectify this problem, we propose a novel, sample-efficient likelihood-free method for estimating the high-dimensional hidden states of an implicit HMM. Our approach relies on learning directly the intractable posterior distribution of the hidden states, using an autoregressive-flow, by exploiting the Markov property. Upon evaluating our approach on some implicit HMMs, we found that the quality of the estimates retrieved using our method is comparable to what can be achieved using a much more computationally expensive SMC algorithm.",
        "bibtex": "@InProceedings{pmlr-v238-ghosh24b,\n  title = \t {Sample-efficient neural likelihood-free {B}ayesian inference of implicit {HMMs}},\n  author =       {Ghosh, Sanmitra and Birrell, Paul and De Angelis, Daniela},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4888--4896},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ghosh24b/ghosh24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ghosh24b.html},\n  abstract = \t {Likelihood-free inference methods based on neural conditional density estimation were shown to drastically reduce the simulation burden in comparison to classical methods such as ABC. When applied in the context of any latent variable model, such as a Hidden Markov model (HMM), these methods are designed to only estimate the parameters, rather than the joint distribution of the parameters and the hidden states. Naive application of these methods to a HMM, ignoring the inference of this joint posterior distribution, will thus produce an inaccurate estimate of the posterior predictive distribution, in turn hampering the assessment of goodness-of-fit. To rectify this problem, we propose a novel, sample-efficient likelihood-free method for estimating the high-dimensional hidden states of an implicit HMM. Our approach relies on learning directly the intractable posterior distribution of the hidden states, using an autoregressive-flow, by exploiting the Markov property. Upon evaluating our approach on some implicit HMMs, we found that the quality of the estimates retrieved using our method is comparable to what can be achieved using a much more computationally expensive SMC algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ghosh24b/ghosh24b.pdf",
        "supp": "",
        "pdf_size": 5137769,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16591883440181499392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "PhysicsX, London+MRC Biostatistics Unit, University of Cambridge+UK Health Security Agency; MRC Biostatistics Unit, University of Cambridge+UK Health Security Agency; MRC Biostatistics Unit, University of Cambridge+UK Health Security Agency",
        "aff_domain": "mrc-bsu.cam.ac.uk;mrc-bsu.cam.ac.uk;mrc-bsu.cam.ac.uk",
        "email": "mrc-bsu.cam.ac.uk;mrc-bsu.cam.ac.uk;mrc-bsu.cam.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;1+2;1+2",
        "aff_unique_norm": "PhysicsX;University of Cambridge;UK Health Security Agency",
        "aff_unique_dep": ";MRC Biostatistics Unit;",
        "aff_unique_url": ";https://www.cam.ac.uk;https://www.ukhsa.gov.uk",
        "aff_unique_abbr": ";Cambridge;UKHSA",
        "aff_campus_unique_index": "0+1;1;1",
        "aff_campus_unique": "London;Cambridge;",
        "aff_country_unique_index": "0+0+0;0+0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "b091a91416",
        "title": "Sampling-based Safe Reinforcement Learning for Nonlinear Dynamical Systems",
        "site": "https://proceedings.mlr.press/v238/suttle24a.html",
        "author": "Wesley Suttle; Vipul Kumar Sharma; Krishna Chaitanya Kosaraju; Sivaranjani Seetharaman; Ji Liu; Vijay Gupta; Brian M Sadler",
        "abstract": "We develop provably safe and convergent reinforcement learning (RL) algorithms for control of nonlinear dynamical systems, bridging the gap between the hard safety guarantees of control theory and the convergence guarantees of RL theory. Recent advances at the intersection of control and RL follow a two-stage, safety filter approach to enforcing hard safety constraints: model-free RL is used to learn a potentially unsafe controller, whose actions are projected onto safe sets prescribed, for example, by a control barrier function. Though safe, such approaches lose any convergence guarantees enjoyed by the underlying RL methods. In this paper, we develop a single-stage, sampling-based approach to hard constraint satisfaction that learns RL controllers enjoying classical convergence guarantees while satisfying hard safety constraints throughout training and deployment. We validate the efficacy of our approach in simulation, including safe control of a quadcopter in a challenging obstacle avoidance problem, and demonstrate that it outperforms existing benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-suttle24a,\n  title = \t {Sampling-based Safe Reinforcement Learning for Nonlinear Dynamical Systems},\n  author =       {Suttle, Wesley and Kumar Sharma, Vipul and Chaitanya Kosaraju, Krishna and Seetharaman, Sivaranjani and Liu, Ji and Gupta, Vijay and M Sadler, Brian},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4420--4428},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/suttle24a/suttle24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/suttle24a.html},\n  abstract = \t {We develop provably safe and convergent reinforcement learning (RL) algorithms for control of nonlinear dynamical systems, bridging the gap between the hard safety guarantees of control theory and the convergence guarantees of RL theory. Recent advances at the intersection of control and RL follow a two-stage, safety filter approach to enforcing hard safety constraints: model-free RL is used to learn a potentially unsafe controller, whose actions are projected onto safe sets prescribed, for example, by a control barrier function. Though safe, such approaches lose any convergence guarantees enjoyed by the underlying RL methods. In this paper, we develop a single-stage, sampling-based approach to hard constraint satisfaction that learns RL controllers enjoying classical convergence guarantees while satisfying hard safety constraints throughout training and deployment. We validate the efficacy of our approach in simulation, including safe control of a quadcopter in a challenging obstacle avoidance problem, and demonstrate that it outperforms existing benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/suttle24a/suttle24a.pdf",
        "supp": "",
        "pdf_size": 1879826,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12400704583859361590&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "U.S. Army Research Laboratory; Purdue University; Clemson University; Purdue University; Stony Brook University; Purdue University; U.S. Army Research Laboratory",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;3;1;0",
        "aff_unique_norm": "U.S. Army Research Laboratory;Purdue University;Clemson University;Stony Brook University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.arl.army.mil;https://www.purdue.edu;https://www.clemson.edu;https://www.stonybrook.edu",
        "aff_unique_abbr": "ARL;Purdue;Clemson;SBU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "622b9d7115",
        "title": "Scalable Algorithms for Individual Preference Stable Clustering",
        "site": "https://proceedings.mlr.press/v238/mosenzon24a.html",
        "author": "Ron Mosenzon; Ali Vakilian",
        "abstract": "In this paper, we study the individual preference (IP) stability, which is an notion capturing individual fairness and stability in clustering. Within this setting, a clustering is $\\alpha$-IP stable when each data point\u2019s average distance to its cluster is no more than $\\alpha$ times its average distance to any other cluster. In this paper, we study the natural local search algorithm for IP stable clustering. Our analysis confirms a $O(\\log n)$-IP stability guarantee for this algorithm, where $n$ denotes the number of points in the input. Furthermore, by refining the local search approach, we show it runs in an almost linear time, $\\tilde{O}(nk)$.",
        "bibtex": "@InProceedings{pmlr-v238-mosenzon24a,\n  title = \t {Scalable Algorithms for Individual Preference Stable Clustering},\n  author =       {Mosenzon, Ron and Vakilian, Ali},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1108--1116},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mosenzon24a/mosenzon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mosenzon24a.html},\n  abstract = \t {In this paper, we study the individual preference (IP) stability, which is an notion capturing individual fairness and stability in clustering. Within this setting, a clustering is $\\alpha$-IP stable when each data point\u2019s average distance to its cluster is no more than $\\alpha$ times its average distance to any other cluster. In this paper, we study the natural local search algorithm for IP stable clustering. Our analysis confirms a $O(\\log n)$-IP stability guarantee for this algorithm, where $n$ denotes the number of points in the input. Furthermore, by refining the local search approach, we show it runs in an almost linear time, $\\tilde{O}(nk)$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mosenzon24a/mosenzon24a.pdf",
        "supp": "",
        "pdf_size": 682596,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8108719249659539370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "TTIC; TTIC",
        "aff_domain": "ttic.edu;ttic.edu",
        "email": "ttic.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Technological Institute at Chicago",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ttic.edu",
        "aff_unique_abbr": "TTIC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bb16b397aa",
        "title": "Scalable Higher-Order Tensor Product Spline Models",
        "site": "https://proceedings.mlr.press/v238/ruegamer24a.html",
        "author": "David Ruegamer",
        "abstract": "In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme and examine the induced optimization problem. We conclude by evaluating the predictive and estimation performance of our method.",
        "bibtex": "@InProceedings{pmlr-v238-ruegamer24a,\n  title = \t {Scalable Higher-Order Tensor Product Spline Models},\n  author =       {Ruegamer, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1--9},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ruegamer24a/ruegamer24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ruegamer24a.html},\n  abstract = \t {In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme and examine the induced optimization problem. We conclude by evaluating the predictive and estimation performance of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ruegamer24a/ruegamer24a.pdf",
        "supp": "",
        "pdf_size": 776716,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16142801733081326866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, LMU Munich+Munich Center for Machine Learning",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "LMU Munich;Munich Center for Machine Learning",
        "aff_unique_dep": "Department of Statistics;Center for Machine Learning",
        "aff_unique_url": "https://www.lmu.de;https://www.munich-center-for-machine-learning.de",
        "aff_unique_abbr": "LMU;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "cd5a1c3fa6",
        "title": "Scalable Learning of Item Response Theory Models",
        "site": "https://proceedings.mlr.press/v238/frick24a.html",
        "author": "Susanne Frick; Amer Krivosija; Alexander Munteanu",
        "abstract": "Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using small weighted subsets called coresets. We develop coresets for their use in alternating IRT training algorithms, facilitating scalable learning from large data.",
        "bibtex": "@InProceedings{pmlr-v238-frick24a,\n  title = \t {Scalable Learning of Item Response Theory Models},\n  author =       {Frick, Susanne and Krivosija, Amer and Munteanu, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1234--1242},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/frick24a/frick24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/frick24a.html},\n  abstract = \t {Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using small weighted subsets called coresets. We develop coresets for their use in alternating IRT training algorithms, facilitating scalable learning from large data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/frick24a/frick24a.pdf",
        "supp": "",
        "pdf_size": 1212118,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14176711196918586590&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0b7ce3cd53",
        "title": "Scalable Meta-Learning with Gaussian Processes",
        "site": "https://proceedings.mlr.press/v238/tighineanu24a.html",
        "author": "Petru Tighineanu; Lukas Grossberger; Paul Baireuther; Kathrin Skubch; Stefan Falkner; Julia Vinogradska; Felix Berkenkamp",
        "abstract": "Meta-learning is a powerful approach that exploits historical data to quickly solve new tasks from the same distribution. In the low-data regime, methods based on the closed-form posterior of Gaussian processes (GP) together with Bayesian optimization have achieved high performance. However, these methods are either computationally expensive or introduce assumptions that hinder a principled propagation of uncertainty between task models. This may disrupt the balance between exploration and exploitation during optimization. In this paper, we develop ScaML-GP, a modular GP model for meta-learning that is scalable in the number of tasks. Our core contribution is carefully designed multi-task kernel that enables hierarchical training and task scalability. Conditioning ScaML-GP on the meta-data exposes its modular nature yielding a test-task prior that combines the posteriors of meta-task GPs. In synthetic and real-world meta-learning experiments, we demonstrate that ScaML-GP can learn efficiently both with few and many meta-tasks.",
        "bibtex": "@InProceedings{pmlr-v238-tighineanu24a,\n  title = \t {Scalable Meta-Learning with {G}aussian Processes},\n  author =       {Tighineanu, Petru and Grossberger, Lukas and Baireuther, Paul and Skubch, Kathrin and Falkner, Stefan and Vinogradska, Julia and Berkenkamp, Felix},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1981--1989},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tighineanu24a/tighineanu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tighineanu24a.html},\n  abstract = \t {Meta-learning is a powerful approach that exploits historical data to quickly solve new tasks from the same distribution. In the low-data regime, methods based on the closed-form posterior of Gaussian processes (GP) together with Bayesian optimization have achieved high performance. However, these methods are either computationally expensive or introduce assumptions that hinder a principled propagation of uncertainty between task models. This may disrupt the balance between exploration and exploitation during optimization. In this paper, we develop ScaML-GP, a modular GP model for meta-learning that is scalable in the number of tasks. Our core contribution is carefully designed multi-task kernel that enables hierarchical training and task scalability. Conditioning ScaML-GP on the meta-data exposes its modular nature yielding a test-task prior that combines the posteriors of meta-task GPs. In synthetic and real-world meta-learning experiments, we demonstrate that ScaML-GP can learn efficiently both with few and many meta-tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tighineanu24a/tighineanu24a.pdf",
        "supp": "",
        "pdf_size": 1561483,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4228317094831769069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7658ab9d85",
        "title": "Score Operator Newton transport",
        "site": "https://proceedings.mlr.press/v238/chandramoorthy24a.html",
        "author": "Nisha Chandramoorthy; Florian T Schaefer; Youssef M Marzouk",
        "abstract": "We propose a new approach for sampling and Bayesian computation that uses the score of the target distribution to construct a transport from a given reference distribution to the target. Our approach is an infinite-dimensional Newton method, involving an elliptic PDE, for finding a zero of a \u201cscore-residual\u201d operator. We prove sufficient conditions for convergence to a valid transport map. Our Newton iterates can be computed by exploiting fast solvers for elliptic PDEs, resulting in new algorithms for Bayesian inference and other sampling tasks. We identify elementary settings where score-operator Newton transport achieves fast convergence while avoiding mode collapse.",
        "bibtex": "@InProceedings{pmlr-v238-chandramoorthy24a,\n  title = \t {Score Operator {N}ewton transport},\n  author =       {Chandramoorthy, Nisha and T Schaefer, Florian and M Marzouk, Youssef},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3349--3357},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chandramoorthy24a/chandramoorthy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chandramoorthy24a.html},\n  abstract = \t {We propose a new approach for sampling and Bayesian computation that uses the score of the target distribution to construct a transport from a given reference distribution to the target. Our approach is an infinite-dimensional Newton method, involving an elliptic PDE, for finding a zero of a \u201cscore-residual\u201d operator. We prove sufficient conditions for convergence to a valid transport map. Our Newton iterates can be computed by exploiting fast solvers for elliptic PDEs, resulting in new algorithms for Bayesian inference and other sampling tasks. We identify elementary settings where score-operator Newton transport achieves fast convergence while avoiding mode collapse.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chandramoorthy24a/chandramoorthy24a.pdf",
        "supp": "",
        "pdf_size": 1407655,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3667124066512270814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6d2efcab89",
        "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
        "site": "https://proceedings.mlr.press/v238/faller24a.html",
        "author": "Philipp M. Faller; Leena C. Vankadara; Atalanti A. Mastakouri; Francesco Locatello; Dominik Janzing",
        "abstract": "As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection.",
        "bibtex": "@InProceedings{pmlr-v238-faller24a,\n  title = \t {Self-Compatibility: Evaluating Causal Discovery without Ground Truth},\n  author =       {Faller, Philipp M. and Vankadara, Leena C. and Mastakouri, Atalanti A. and Locatello, Francesco and Janzing, Dominik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4132--4140},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/faller24a/faller24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/faller24a.html},\n  abstract = \t {As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/faller24a/faller24a.pdf",
        "supp": "",
        "pdf_size": 2245566,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2428489847113940342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Karlsruhe Institute of Technology, Germany + Amazon Research T\u00fcbingen, Germany; Amazon Research T\u00fcbingen, Germany; Amazon Research T\u00fcbingen, Germany; Institute of Science and Technology Austria; Amazon Research T\u00fcbingen, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;2;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Amazon;Institute of Science and Technology Austria",
        "aff_unique_dep": ";Amazon Research;",
        "aff_unique_url": "https://www.kit.edu;https://www.amazon.com;https://www.ist.ac.at",
        "aff_unique_abbr": "KIT;Amazon;IST Austria",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0+0;0;0;1;0",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "c9d1bc8d22",
        "title": "Self-Supervised Quantization-Aware Knowledge Distillation",
        "site": "https://proceedings.mlr.press/v238/zhao24d.html",
        "author": "Kaiqi Zhao; Ming Zhao",
        "abstract": "Quantization-aware training (QAT) and Knowledge Distillation (KD) are combined to achieve competitive performance in creating low-bit deep learning models. However, existing works applying KD to QAT require tedious hyper-parameter tuning to balance the weights of different loss terms, assume the availability of labeled training data, and require complex, computationally intensive training procedures for good performance. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation (SQAKD) framework. SQAKD first unifies the forward and backward dynamics of various quantization functions, making it flexible for incorporating various QAT works. Then it formulates QAT as a co-optimization problem that simultaneously minimizes the KL-Loss between the full-precision and low-bit models for KD and the discretization error for quantization, without supervision from labels. A comprehensive evaluation shows that SQAKD substantially outperforms the state-of-the-art QAT and KD works for a variety of model architectures. Our code is at: https://github.com/kaiqi123/SQAKD.git.",
        "bibtex": "@InProceedings{pmlr-v238-zhao24d,\n  title = \t {Self-Supervised Quantization-Aware Knowledge Distillation},\n  author =       {Zhao, Kaiqi and Zhao, Ming},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4375--4383},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhao24d/zhao24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhao24d.html},\n  abstract = \t {Quantization-aware training (QAT) and Knowledge Distillation (KD) are combined to achieve competitive performance in creating low-bit deep learning models. However, existing works applying KD to QAT require tedious hyper-parameter tuning to balance the weights of different loss terms, assume the availability of labeled training data, and require complex, computationally intensive training procedures for good performance. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation (SQAKD) framework. SQAKD first unifies the forward and backward dynamics of various quantization functions, making it flexible for incorporating various QAT works. Then it formulates QAT as a co-optimization problem that simultaneously minimizes the KL-Loss between the full-precision and low-bit models for KD and the discretization error for quantization, without supervision from labels. A comprehensive evaluation shows that SQAKD substantially outperforms the state-of-the-art QAT and KD works for a variety of model architectures. Our code is at: https://github.com/kaiqi123/SQAKD.git.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhao24d/zhao24d.pdf",
        "supp": "",
        "pdf_size": 7784848,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2958677957754365152&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Arizona State University; Arizona State University",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/kaiqi123/SQAKD.git",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "42d3c33bca",
        "title": "Sequence Length Independent Norm-Based Generalization Bounds for Transformers",
        "site": "https://proceedings.mlr.press/v238/trauger24a.html",
        "author": "Jacob Trauger; Ambuj Tewari",
        "abstract": "This paper provides norm-based generalization bounds for the Transformer architecture that do not depend on the input sequence length. We employ a covering number based approach to prove our bounds. We use three novel covering number bounds for the function class of bounded linear mappings to upper bound the Rademacher complexity of the Transformer. Furthermore, we show this generalization bound applies to the common Transformer training technique of masking and then predicting the masked word. We also run a simulated study on a sparse majority data set that empirically validates our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-trauger24a,\n  title = \t {Sequence Length Independent Norm-Based Generalization Bounds for Transformers},\n  author =       {Trauger, Jacob and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1405--1413},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/trauger24a/trauger24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/trauger24a.html},\n  abstract = \t {This paper provides norm-based generalization bounds for the Transformer architecture that do not depend on the input sequence length. We employ a covering number based approach to prove our bounds. We use three novel covering number bounds for the function class of bounded linear mappings to upper bound the Rademacher complexity of the Transformer. Furthermore, we show this generalization bound applies to the common Transformer training technique of masking and then predicting the masked word. We also run a simulated study on a sparse majority data set that empirically validates our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/trauger24a/trauger24a.pdf",
        "supp": "",
        "pdf_size": 499613,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15890414731092640578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Michigan; University of Michigan",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9909820b40",
        "title": "Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference",
        "site": "https://proceedings.mlr.press/v238/mcnamara24a.html",
        "author": "Declan McNamara; Jackson Loper; Jeffrey Regier",
        "abstract": "For training an encoder network to perform amortized variational inference, the Kullback-Leibler (KL) divergence from the exact posterior to its approximation, known as the inclusive or forward KL, is an increasingly popular choice of variational objective due to the mass-covering property of its minimizer. However, minimizing this objective is challenging. A popular existing approach, Reweighted Wake-Sleep (RWS), suffers from heavily biased gradients and a circular pathology that results in highly concentrated variational distributions. As an alternative, we propose SMC-Wake, a procedure for fitting an amortized variational approximation that uses likelihood-tempered sequential Monte Carlo samplers to estimate the gradient of the inclusive KL divergence. We propose three gradient estimators, all of which are asymptotically unbiased in the number of iterations and two of which are strongly consistent. Our method interleaves stochastic gradient updates, SMC samplers, and iterative improvement to an estimate of the normalizing constant to reduce bias from self-normalization. In experiments with both simulated and real datasets, SMC-Wake fits variational distributions that approximate the posterior more accurately than existing methods.",
        "bibtex": "@InProceedings{pmlr-v238-mcnamara24a,\n  title = \t {Sequential {M}onte {C}arlo for Inclusive {KL} Minimization in Amortized Variational Inference},\n  author =       {McNamara, Declan and Loper, Jackson and Regier, Jeffrey},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4312--4320},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mcnamara24a/mcnamara24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mcnamara24a.html},\n  abstract = \t {For training an encoder network to perform amortized variational inference, the Kullback-Leibler (KL) divergence from the exact posterior to its approximation, known as the inclusive or forward KL, is an increasingly popular choice of variational objective due to the mass-covering property of its minimizer. However, minimizing this objective is challenging. A popular existing approach, Reweighted Wake-Sleep (RWS), suffers from heavily biased gradients and a circular pathology that results in highly concentrated variational distributions. As an alternative, we propose SMC-Wake, a procedure for fitting an amortized variational approximation that uses likelihood-tempered sequential Monte Carlo samplers to estimate the gradient of the inclusive KL divergence. We propose three gradient estimators, all of which are asymptotically unbiased in the number of iterations and two of which are strongly consistent. Our method interleaves stochastic gradient updates, SMC samplers, and iterative improvement to an estimate of the normalizing constant to reduce bias from self-normalization. In experiments with both simulated and real datasets, SMC-Wake fits variational distributions that approximate the posterior more accurately than existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mcnamara24a/mcnamara24a.pdf",
        "supp": "",
        "pdf_size": 5277765,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2203449386542672924&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "94aeebf7bf",
        "title": "Sequential learning of the Pareto front for multi-objective bandits",
        "site": "https://proceedings.mlr.press/v238/crepon24a.html",
        "author": "\u00e9lise crepon; Aur\u00e9lien Garivier; Wouter M Koolen",
        "abstract": "We study the problem of sequential learning of the Pareto front in multi-objective multi-armed bandits. An agent is faced with $K$ possible arms to pull. At each turn she picks one, and receives a vector-valued reward. When she thinks she has enough information to identify the Pareto front of the different arm means, she stops the game and gives an answer. We are interested in designing algorithms such that the answer given is correct with probability at least $1-\\delta$. Our main contribution is an efficient implementation of an algorithm achieving the optimal sample complexity when the risk $\\delta$ is small. With $K$ arms in $d$ dimensions, $p$ of which are in the Pareto set, the algorithm runs in time $O(K p^d)$ per round.",
        "bibtex": "@InProceedings{pmlr-v238-crepon24a,\n  title = \t {Sequential learning of the {P}areto front for multi-objective bandits},\n  author =       {{c}repon, \\'{e}lise and Garivier, Aur\\'{e}lien and M Koolen, Wouter},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3583--3591},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/crepon24a/crepon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/crepon24a.html},\n  abstract = \t {We study the problem of sequential learning of the Pareto front in multi-objective multi-armed bandits. An agent is faced with $K$ possible arms to pull. At each turn she picks one, and receives a vector-valued reward. When she thinks she has enough information to identify the Pareto front of the different arm means, she stops the game and gives an answer. We are interested in designing algorithms such that the answer given is correct with probability at least $1-\\delta$. Our main contribution is an efficient implementation of an algorithm achieving the optimal sample complexity when the risk $\\delta$ is small. With $K$ arms in $d$ dimensions, $p$ of which are in the Pareto set, the algorithm runs in time $O(K p^d)$ per round.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/crepon24a/crepon24a.pdf",
        "supp": "",
        "pdf_size": 253956,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7592606770455441678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bc20398082",
        "title": "Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond Closed-Form Equations",
        "site": "https://proceedings.mlr.press/v238/kacprzyk24a.html",
        "author": "Krzysztof Kacprzyk; Mihaela van der Schaar",
        "abstract": "Symbolic regression has excelled in uncovering equations from physics, chemistry, biology, and related disciplines. However, its effectiveness becomes less certain when applied to experimental data lacking inherent closed-form expressions. Empirically derived relationships, such as entire stress-strain curves, may defy concise closed-form representation, compelling us to explore more adaptive modeling approaches that balance flexibility with interpretability. In our pursuit, we turn to Generalized Additive Models (GAMs), a widely used class of models known for their versatility across various domains. Although GAMs can capture non-linear relationships between variables and targets, they cannot capture intricate feature interactions. In this work, we investigate both of these challenges and propose a novel class of models, Shape Arithmetic Expressions (SHAREs), that fuses GAM\u2019s flexible shape functions with the complex feature interactions found in mathematical expressions. SHAREs also provide a unifying framework for both of these approaches. We also design a set of rules for constructing SHAREs that guarantee transparency of the found expressions beyond the standard constraints based on the model\u2019s size.",
        "bibtex": "@InProceedings{pmlr-v238-kacprzyk24a,\n  title = \t {Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond Closed-Form Equations},\n  author =       {Kacprzyk, Krzysztof and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3601--3609},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kacprzyk24a/kacprzyk24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kacprzyk24a.html},\n  abstract = \t {Symbolic regression has excelled in uncovering equations from physics, chemistry, biology, and related disciplines. However, its effectiveness becomes less certain when applied to experimental data lacking inherent closed-form expressions. Empirically derived relationships, such as entire stress-strain curves, may defy concise closed-form representation, compelling us to explore more adaptive modeling approaches that balance flexibility with interpretability. In our pursuit, we turn to Generalized Additive Models (GAMs), a widely used class of models known for their versatility across various domains. Although GAMs can capture non-linear relationships between variables and targets, they cannot capture intricate feature interactions. In this work, we investigate both of these challenges and propose a novel class of models, Shape Arithmetic Expressions (SHAREs), that fuses GAM\u2019s flexible shape functions with the complex feature interactions found in mathematical expressions. SHAREs also provide a unifying framework for both of these approaches. We also design a set of rules for constructing SHAREs that guarantee transparency of the found expressions beyond the standard constraints based on the model\u2019s size.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kacprzyk24a/kacprzyk24a.pdf",
        "supp": "",
        "pdf_size": 753843,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=937178362576449403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; University of Cambridge + The Alan Turing Institute",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;ATI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "3827e2a54c",
        "title": "Sharp error bounds for imbalanced classification: how many examples in the minority class?",
        "site": "https://proceedings.mlr.press/v238/aghbalou24a.html",
        "author": "Anass Aghbalou; Anne Sabourin; Fran\u00e7ois Portier",
        "abstract": "When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field.",
        "bibtex": "@InProceedings{pmlr-v238-aghbalou24a,\n  title = \t {Sharp error bounds for imbalanced classification: how many examples in the minority class?},\n  author =       {Aghbalou, Anass and Sabourin, Anne and Portier, Fran\\c{c}ois},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {838--846},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/aghbalou24a/aghbalou24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/aghbalou24a.html},\n  abstract = \t {When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/aghbalou24a/aghbalou24a.pdf",
        "supp": "",
        "pdf_size": 919643,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17200648112102505915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "edb76328df",
        "title": "Sharpened Lazy Incremental Quasi-Newton Method",
        "site": "https://proceedings.mlr.press/v238/sunil-lahoti24a.html",
        "author": "Aakash Sunil Lahoti; Spandan Senapati; Ketan Rajawat; Alec Koppel",
        "abstract": "The problem of minimizing the sum of $n$ functions in $d$ dimensions is ubiquitous in machine learning and statistics. In many applications where the number of observations $n$ is large, it is necessary to use incremental or stochastic methods, as their per-iteration cost is independent of $n$. Of these, Quasi-Newton (QN) methods strike a balance between the per-iteration cost and the convergence rate. Specifically, they exhibit a superlinear rate with $O(d^2)$ cost in contrast to the linear rate of first-order methods with $O(d)$ cost and the quadratic rate of second-order methods with $O(d^3)$ cost. However, existing incremental methods have notable shortcomings: Incremental Quasi-Newton (IQN) only exhibits asymptotic superlinear convergence. In contrast, Incremental Greedy BFGS (IGS) offers explicit superlinear convergence but suffers from poor empirical performance and has a per-iteration cost of $O(d^3)$. To address these issues, we introduce the Sharpened Lazy Incremental Quasi-Newton Method (SLIQN) that achieves the best of both worlds: an explicit superlinear convergence rate, and superior empirical performance at a per-iteration $O(d^2)$ cost. SLIQN features two key changes: first, it incorporates a hybrid strategy of using both classic and greedy BFGS updates, allowing it to empirically outperform both IQN and IGS. Second, it employs a clever constant multiplicative factor along with a lazy propagation strategy, which enables it to have a cost of $O(d^2)$. Additionally, our experiments demonstrate the superiority of SLIQN over other incremental and stochastic Quasi-Newton variants and establish its competitiveness with second-order incremental methods.",
        "bibtex": "@InProceedings{pmlr-v238-sunil-lahoti24a,\n  title = \t {Sharpened Lazy Incremental Quasi-{N}ewton Method},\n  author =       {Sunil Lahoti, Aakash and Senapati, Spandan and Rajawat, Ketan and Koppel, Alec},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4735--4743},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sunil-lahoti24a/sunil-lahoti24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sunil-lahoti24a.html},\n  abstract = \t {The problem of minimizing the sum of $n$ functions in $d$ dimensions is ubiquitous in machine learning and statistics. In many applications where the number of observations $n$ is large, it is necessary to use incremental or stochastic methods, as their per-iteration cost is independent of $n$. Of these, Quasi-Newton (QN) methods strike a balance between the per-iteration cost and the convergence rate. Specifically, they exhibit a superlinear rate with $O(d^2)$ cost in contrast to the linear rate of first-order methods with $O(d)$ cost and the quadratic rate of second-order methods with $O(d^3)$ cost. However, existing incremental methods have notable shortcomings: Incremental Quasi-Newton (IQN) only exhibits asymptotic superlinear convergence. In contrast, Incremental Greedy BFGS (IGS) offers explicit superlinear convergence but suffers from poor empirical performance and has a per-iteration cost of $O(d^3)$. To address these issues, we introduce the Sharpened Lazy Incremental Quasi-Newton Method (SLIQN) that achieves the best of both worlds: an explicit superlinear convergence rate, and superior empirical performance at a per-iteration $O(d^2)$ cost. SLIQN features two key changes: first, it incorporates a hybrid strategy of using both classic and greedy BFGS updates, allowing it to empirically outperform both IQN and IGS. Second, it employs a clever constant multiplicative factor along with a lazy propagation strategy, which enables it to have a cost of $O(d^2)$. Additionally, our experiments demonstrate the superiority of SLIQN over other incremental and stochastic Quasi-Newton variants and establish its competitiveness with second-order incremental methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sunil-lahoti24a/sunil-lahoti24a.pdf",
        "supp": "",
        "pdf_size": 1629265,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3568184180624751764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Carnegie Mellon University; University of Southern California; Indian Institute of Technology Kanpur; J.P. Morgan AI Research",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Carnegie Mellon University;University of Southern California;Indian Institute of Technology Kanpur;J.P. Morgan",
        "aff_unique_dep": ";;;AI Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.usc.edu;https://www.iitk.ac.in;https://www.jpmorgan.com",
        "aff_unique_abbr": "CMU;USC;IIT Kanpur;JPM",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Los Angeles;Kanpur",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "912c578be7",
        "title": "Simple and scalable algorithms for cluster-aware precision medicine",
        "site": "https://proceedings.mlr.press/v238/buch24a.html",
        "author": "Amanda M. Buch; Conor Liston; Logan Grosenick",
        "abstract": "AI-enabled precision medicine promises a transformational improvement in healthcare outcomes. However, training on biomedical data presents significant challenges as they are often high dimensional, clustered, and of limited sample size. To overcome these challenges, we propose a simple and scalable approach for cluster-aware embedding that combines latent factor methods with a convex clustering penalty in a modular way. Our novel approach overcomes the complexity and limitations of current joint embedding and clustering methods and enables hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through numerical experiments and real-world examples, we demonstrate that our approach outperforms fourteen clustering methods on highly underdetermined problems (e.g., with limited sample size) as well as on large sample datasets. Importantly, our approach does not require the user to choose the desired number of clusters, yields improved model selection if they do, and yields interpretable hierarchically clustered embedding dendrograms. Thus, our approach improves significantly on existing methods for identifying patient subgroups in multiomics and neuroimaging data and enables scalable and interpretable biomarkers for precision medicine.",
        "bibtex": "@InProceedings{pmlr-v238-buch24a,\n  title = \t {Simple and scalable algorithms for cluster-aware precision medicine},\n  author =       {Buch, Amanda M. and Liston, Conor and Grosenick, Logan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {136--144},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/buch24a/buch24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/buch24a.html},\n  abstract = \t {AI-enabled precision medicine promises a transformational improvement in healthcare outcomes. However, training on biomedical data presents significant challenges as they are often high dimensional, clustered, and of limited sample size. To overcome these challenges, we propose a simple and scalable approach for cluster-aware embedding that combines latent factor methods with a convex clustering penalty in a modular way. Our novel approach overcomes the complexity and limitations of current joint embedding and clustering methods and enables hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through numerical experiments and real-world examples, we demonstrate that our approach outperforms fourteen clustering methods on highly underdetermined problems (e.g., with limited sample size) as well as on large sample datasets. Importantly, our approach does not require the user to choose the desired number of clusters, yields improved model selection if they do, and yields interpretable hierarchically clustered embedding dendrograms. Thus, our approach improves significantly on existing methods for identifying patient subgroups in multiomics and neuroimaging data and enables scalable and interpretable biomarkers for precision medicine.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/buch24a/buch24a.pdf",
        "supp": "",
        "pdf_size": 13322161,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15666953600218358355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Dept. of Psychiatry & BMRI, Weill Cornell Medicine, Cornell University; Dept. of Psychiatry & BMRI, Weill Cornell Medicine, Cornell University; Dept. of Psychiatry & BMRI, Weill Cornell Medicine, Cornell University",
        "aff_domain": "med.cornell.edu;med.cornell.edu;med.cornell.edu",
        "email": "med.cornell.edu;med.cornell.edu;med.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Dept. of Psychiatry & BMRI",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Weill Cornell Medicine",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0e08a8a66c",
        "title": "Simulating weighted automata over sequences and trees with transformers",
        "site": "https://proceedings.mlr.press/v238/rizvi-martel24a.html",
        "author": "Michael Rizvi-Martel; Maude Lizaire; Clara Lacroce; Guillaume Rabusseau",
        "abstract": "Transformers are ubiquitous models in the natural language processing (NLP) community and have shown impressive empirical successes in the past few years. However, little is understood about how they reason and the limits of their computational capabilities. These models do not process data sequentially, and yet outperform sequential neural models such as RNNs. Recent work has shown that these models can compactly simulate the sequential reasoning abilities of deterministic finite automata (DFAs). This leads to the following question: can transformers simulate the reasoning of more complex finite state machines? In this work, we show that transformers can simulate weighted finite automata (WFAs), a class of models which subsumes DFAs, as well as weighted tree automata (WTA), a generalization of weighted automata to tree structured inputs. We prove these claims formally and provide upper bounds on the size of the transformer models needed as a function of the number of states of the target automata. Empirically, we perform synthetic experiments showing that transformers are able to learn these compact solutions via standard gradient-based training.",
        "bibtex": "@InProceedings{pmlr-v238-rizvi-martel24a,\n  title = \t {Simulating weighted automata over sequences and trees with transformers},\n  author =       {Rizvi-Martel, Michael and Lizaire, Maude and Lacroce, Clara and Rabusseau, Guillaume},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2368--2376},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/rizvi-martel24a/rizvi-martel24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/rizvi-martel24a.html},\n  abstract = \t {Transformers are ubiquitous models in the natural language processing (NLP) community and have shown impressive empirical successes in the past few years. However, little is understood about how they reason and the limits of their computational capabilities. These models do not process data sequentially, and yet outperform sequential neural models such as RNNs. Recent work has shown that these models can compactly simulate the sequential reasoning abilities of deterministic finite automata (DFAs). This leads to the following question: can transformers simulate the reasoning of more complex finite state machines? In this work, we show that transformers can simulate weighted finite automata (WFAs), a class of models which subsumes DFAs, as well as weighted tree automata (WTA), a generalization of weighted automata to tree structured inputs. We prove these claims formally and provide upper bounds on the size of the transformer models needed as a function of the number of states of the target automata. Empirically, we perform synthetic experiments showing that transformers are able to learn these compact solutions via standard gradient-based training.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/rizvi-martel24a/rizvi-martel24a.pdf",
        "supp": "",
        "pdf_size": 1200097,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:-MC_HpIY5GMJ:scholar.google.com/&scioq=Simulating+weighted+automata+over+sequences+and+trees+with+transformers&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a8a82682a3",
        "title": "Simulation-Based Stacking",
        "site": "https://proceedings.mlr.press/v238/yao24b.html",
        "author": "Yuling Yao; Bruno R\u00e9galdo-Saint Blancard; Justin Domke",
        "abstract": "Simulation-based inference has been popular for amortized Bayesian computation. It is typical to have more than one posterior approximation, from different inference algorithms, different architectures, or simply the randomness of initialization and stochastic gradients. With a consistency guarantee, we present a general posterior stacking framework to make use of all available approximations. Our stacking method is able to combine densities, simulation draws, confidence intervals, and moments, and address the overall precision, calibration, coverage, and bias of the posterior approximation at the same time. We illustrate our method on several benchmark simulations and a challenging cosmological inference task.",
        "bibtex": "@InProceedings{pmlr-v238-yao24b,\n  title = \t {Simulation-Based Stacking},\n  author =       {Yao, Yuling and R\\'{e}galdo-Saint Blancard, Bruno and Domke, Justin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4267--4275},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/yao24b/yao24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/yao24b.html},\n  abstract = \t {Simulation-based inference has been popular for amortized Bayesian computation. It is typical to have more than one posterior approximation, from different inference algorithms, different architectures, or simply the randomness of initialization and stochastic gradients. With a consistency guarantee, we present a general posterior stacking framework to make use of all available approximations. Our stacking method is able to combine densities, simulation draws, confidence intervals, and moments, and address the overall precision, calibration, coverage, and bias of the posterior approximation at the same time. We illustrate our method on several benchmark simulations and a challenging cosmological inference task.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/yao24b/yao24b.pdf",
        "supp": "",
        "pdf_size": 965414,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14517495568063773461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "eacd369f61",
        "title": "Simulation-Free Schr\u00f6dinger Bridges via Score and Flow Matching",
        "site": "https://proceedings.mlr.press/v238/tong24a.html",
        "author": "Alexander Y. Tong; Nikolay Malkin; Kilian Fatras; Lazar Atanackovic; Yanlei Zhang; Guillaume Huguet; Guy Wolf; Yoshua Bengio",
        "abstract": "We present simulation-free score and flow matching ([SF]$^2$M), a simulation-free objective for inferring stochastic dynamics given unpaired samples drawn from arbitrary source and target distributions. Our method generalizes both the score-matching loss used in the training of diffusion models and the recently proposed flow matching loss used in the training of continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic generative modeling as a Schr\u00f6dinger bridge problem. It relies on static entropy-regularized optimal transport, or a minibatch approximation, to efficiently learn the SB without simulating the learned stochastic process. We find that [SF]$^2$M is more efficient and gives more accurate solutions to the SB problem than simulation-based methods from prior work. Finally, we apply [SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably, [SF]$^2$M is the first method to accurately model cell dynamics in high dimensions and can recover known gene regulatory networks from simulated data. Our code is available in the TorchCFM package at \\url{https://github.com/atong01/conditional-flow-matching}.",
        "bibtex": "@InProceedings{pmlr-v238-tong24a,\n  title = \t {Simulation-Free {S}chr\u00f6dinger Bridges via Score and Flow Matching},\n  author =       {Tong, Alexander Y. and Malkin, Nikolay and Fatras, Kilian and Atanackovic, Lazar and Zhang, Yanlei and Huguet, Guillaume and Wolf, Guy and Bengio, Yoshua},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1279--1287},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tong24a/tong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tong24a.html},\n  abstract = \t {We present simulation-free score and flow matching ([SF]$^2$M), a simulation-free objective for inferring stochastic dynamics given unpaired samples drawn from arbitrary source and target distributions. Our method generalizes both the score-matching loss used in the training of diffusion models and the recently proposed flow matching loss used in the training of continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic generative modeling as a Schr\u00f6dinger bridge problem. It relies on static entropy-regularized optimal transport, or a minibatch approximation, to efficiently learn the SB without simulating the learned stochastic process. We find that [SF]$^2$M is more efficient and gives more accurate solutions to the SB problem than simulation-based methods from prior work. Finally, we apply [SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably, [SF]$^2$M is the first method to accurately model cell dynamics in high dimensions and can recover known gene regulatory networks from simulated data. Our code is available in the TorchCFM package at \\url{https://github.com/atong01/conditional-flow-matching}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tong24a/tong24a.pdf",
        "supp": "",
        "pdf_size": 8445168,
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3960635625777967714&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila \u2013 Qu\u00e9bec AI Institute+McGill University; University of Toronto+Vector Institute; Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al+Canada CIFAR AI Chair; Mila \u2013 Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al+CIFAR Senior Fellow",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "https://github.com/atong01/conditional-flow-matching",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+2;3+4;0+1;0+1;0+1+5;0+1+6",
        "aff_unique_norm": "Qu\u00e9bec AI Institute;Universit\u00e9 de Montr\u00e9al;McGill University;University of Toronto;Vector Institute;Canadian Institute for Advanced Research;CIFAR",
        "aff_unique_dep": "AI;;;;;AI Chair;Senior Fellow",
        "aff_unique_url": "https://mila.quebec;https://www.umontreal.ca;https://www.mcgill.ca;https://www.utoronto.ca;https://vectorinstitute.ai/;https://www.cifar.ca;https://www.cifar.ca",
        "aff_unique_abbr": "Mila;UdeM;McGill;U of T;Vector Institute;CIFAR;CIFAR",
        "aff_campus_unique_index": ";;;;;;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0;0+0;0+0;0+0+0;0+0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9c50373477",
        "title": "Sinkhorn Flow as Mirror Flow: A Continuous-Time Framework for Generalizing the Sinkhorn Algorithm",
        "site": "https://proceedings.mlr.press/v238/reza-karimi24a.html",
        "author": "Mohammad Reza Karimi; Ya-Ping Hsieh; Andreas Krause",
        "abstract": "Many problems in machine learning can be formulated as solving entropy-regularized optimal transport on the space of probability measures. The canonical approach involves the Sinkhorn iterates, renowned for their rich mathematical properties. Recently, the Sinkhorn algorithm has been recast within the mirror descent framework, thus benefiting from classical optimization theory insights. Here, we build upon this result by introducing a continuous-time analogue of the Sinkhorn algorithm. This perspective allows us to derive novel variants of Sinkhorn schemes that are robust to noise and bias. Moreover, our continuous-time dynamics offers a unified perspective on several recently discovered dynamics in machine learning and mathematics, such as the \"Wasserstein mirror flow\" of Deb et al. (2023) or the \"mean-field Schr\u00f6dinger equation\" of Claisse et al. (2023).",
        "bibtex": "@InProceedings{pmlr-v238-reza-karimi24a,\n  title = \t {Sinkhorn Flow as Mirror Flow: A Continuous-Time Framework for Generalizing the {S}inkhorn Algorithm},\n  author =       {Reza Karimi, Mohammad and Hsieh, Ya-Ping and Krause, Andreas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4186--4194},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/reza-karimi24a/reza-karimi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/reza-karimi24a.html},\n  abstract = \t {Many problems in machine learning can be formulated as solving entropy-regularized optimal transport on the space of probability measures. The canonical approach involves the Sinkhorn iterates, renowned for their rich mathematical properties. Recently, the Sinkhorn algorithm has been recast within the mirror descent framework, thus benefiting from classical optimization theory insights. Here, we build upon this result by introducing a continuous-time analogue of the Sinkhorn algorithm. This perspective allows us to derive novel variants of Sinkhorn schemes that are robust to noise and bias. Moreover, our continuous-time dynamics offers a unified perspective on several recently discovered dynamics in machine learning and mathematics, such as the \"Wasserstein mirror flow\" of Deb et al. (2023) or the \"mean-field Schr\u00f6dinger equation\" of Claisse et al. (2023).}\n}",
        "pdf": "https://proceedings.mlr.press/v238/reza-karimi24a/reza-karimi24a.pdf",
        "supp": "",
        "pdf_size": 542935,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15182037694327246284&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a0c9d95bdd",
        "title": "Sketch In, Sketch Out: Accelerating both Learning and Inference for Structured Prediction with Kernels",
        "site": "https://proceedings.mlr.press/v238/el-ahmad24a.html",
        "author": "Tamim El Ahmad; Luc Brogat-Motte; Pierre Laforgue; Florence d\u2019Alch\u00e9-Buc",
        "abstract": "Leveraging the kernel trick in both the input and output spaces, surrogate kernel methods are a flexible and theoretically grounded solution to structured output prediction. If they provide state-of-the-art performance on complex data sets of moderate size (e.g., in chemoinformatics), these approaches however fail to scale. We propose to equip surrogate kernel methods with sketching-based approximations, applied to both the input and output feature maps. We prove excess risk bounds on the original structured prediction problem, showing how to attain close-to-optimal rates with a reduced sketch size that depends on the eigendecay of the input/output covariance operators. From a computational perspective, we show that the two approximations have distinct but complementary impacts: sketching the input kernel mostly reduces training time, while sketching the output kernel decreases the inference time. Empirically, our approach is shown to scale, achieving state-of-the-art performance on benchmark data sets where non-sketched methods are intractable.",
        "bibtex": "@InProceedings{pmlr-v238-el-ahmad24a,\n  title = \t {Sketch In, Sketch Out: Accelerating both Learning and Inference for Structured Prediction with Kernels},\n  author =       {El Ahmad, Tamim and Brogat-Motte, Luc and Laforgue, Pierre and d'Alch\\'{e}-Buc, Florence},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {109--117},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/el-ahmad24a/el-ahmad24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/el-ahmad24a.html},\n  abstract = \t {Leveraging the kernel trick in both the input and output spaces, surrogate kernel methods are a flexible and theoretically grounded solution to structured output prediction. If they provide state-of-the-art performance on complex data sets of moderate size (e.g., in chemoinformatics), these approaches however fail to scale. We propose to equip surrogate kernel methods with sketching-based approximations, applied to both the input and output feature maps. We prove excess risk bounds on the original structured prediction problem, showing how to attain close-to-optimal rates with a reduced sketch size that depends on the eigendecay of the input/output covariance operators. From a computational perspective, we show that the two approximations have distinct but complementary impacts: sketching the input kernel mostly reduces training time, while sketching the output kernel decreases the inference time. Empirically, our approach is shown to scale, achieving state-of-the-art performance on benchmark data sets where non-sketched methods are intractable.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/el-ahmad24a/el-ahmad24a.pdf",
        "supp": "",
        "pdf_size": 804695,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9456101151721166999&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "953c7c476c",
        "title": "Smoothness-Adaptive Dynamic Pricing with Nonparametric Demand Learning",
        "site": "https://proceedings.mlr.press/v238/ye24b.html",
        "author": "Zeqi Ye; Hansheng Jiang",
        "abstract": "We study the dynamic pricing problem where the demand function is nonparametric and H\u00f6lder smooth, and we focus on adaptivity to the unknown H\u00f6lder smoothness parameter $\\beta$ of the demand function. Traditionally the optimal dynamic pricing algorithm heavily relies on the knowledge of $\\beta$ to achieve a minimax optimal regret of $\\widetilde{O}(T^{\\frac{\\beta+1}{2\\beta+1}})$. However, we highlight the challenge of adaptivity in this dynamic pricing problem by proving that no pricing policy can adaptively achieve this minimax optimal regret without knowledge of $\\beta$. Motivated by the impossibility result, we propose a self-similarity condition to enable adaptivity. Importantly, we show that the self-similarity condition does not compromise the problem\u2019s inherent complexity since it preserves the regret lower bound $\\Omega(T^{\\frac{\\beta+1}{2\\beta+1}})$. Furthermore, we develop a smoothness-adaptive dynamic pricing algorithm and theoretically prove that the algorithm achieves this minimax optimal regret bound without the prior knowledge $\\beta$.",
        "bibtex": "@InProceedings{pmlr-v238-ye24b,\n  title = \t {Smoothness-Adaptive Dynamic Pricing with Nonparametric Demand Learning},\n  author =       {Ye, Zeqi and Jiang, Hansheng},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1675--1683},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ye24b/ye24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ye24b.html},\n  abstract = \t {We study the dynamic pricing problem where the demand function is nonparametric and H\u00f6lder smooth, and we focus on adaptivity to the unknown H\u00f6lder smoothness parameter $\\beta$ of the demand function. Traditionally the optimal dynamic pricing algorithm heavily relies on the knowledge of $\\beta$ to achieve a minimax optimal regret of $\\widetilde{O}(T^{\\frac{\\beta+1}{2\\beta+1}})$. However, we highlight the challenge of adaptivity in this dynamic pricing problem by proving that no pricing policy can adaptively achieve this minimax optimal regret without knowledge of $\\beta$. Motivated by the impossibility result, we propose a self-similarity condition to enable adaptivity. Importantly, we show that the self-similarity condition does not compromise the problem\u2019s inherent complexity since it preserves the regret lower bound $\\Omega(T^{\\frac{\\beta+1}{2\\beta+1}})$. Furthermore, we develop a smoothness-adaptive dynamic pricing algorithm and theoretically prove that the algorithm achieves this minimax optimal regret bound without the prior knowledge $\\beta$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ye24b/ye24b.pdf",
        "supp": "",
        "pdf_size": 502659,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2883249028342365865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Nankai University; University of Toronto",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Nankai University;University of Toronto",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.utoronto.ca",
        "aff_unique_abbr": "NKU;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "089b5cd263",
        "title": "Soft-constrained Schr\u00f6dinger Bridge: a Stochastic Control Approach",
        "site": "https://proceedings.mlr.press/v238/garg24a.html",
        "author": "Jhanvi Garg; Xianyang Zhang; Quan Zhou",
        "abstract": "Schr\u00f6dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process whose terminal distribution coincides with a pre-specified target distribution. We propose to generalize this problem by allowing the terminal distribution to differ from the target but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\u00f6dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of the target and some other distribution. This result is further extended to a time series setting. One application is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its use via a numerical example for the MNIST data set.",
        "bibtex": "@InProceedings{pmlr-v238-garg24a,\n  title = \t {Soft-constrained {S}chr\u00f6dinger Bridge: a Stochastic Control Approach},\n  author =       {Garg, Jhanvi and Zhang, Xianyang and Zhou, Quan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4429--4437},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/garg24a/garg24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/garg24a.html},\n  abstract = \t {Schr\u00f6dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process whose terminal distribution coincides with a pre-specified target distribution. We propose to generalize this problem by allowing the terminal distribution to differ from the target but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\u00f6dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of the target and some other distribution. This result is further extended to a time series setting. One application is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its use via a numerical example for the MNIST data set.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/garg24a/garg24a.pdf",
        "supp": "",
        "pdf_size": 2234125,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4158497902211384397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "97ae866f27",
        "title": "Solving Attention Kernel Regression Problem via Pre-conditioner",
        "site": "https://proceedings.mlr.press/v238/song24a.html",
        "author": "Zhao Song; Junze Yin; Lichen Zhang",
        "abstract": "Attention mechanism is the key to large language models, and attention matrix serves as an algorithmic and computational bottleneck for such a scheme. In this paper, we define two problems, motivated by designing fast algorithms for \\emph{proxy} of attention matrix and solving regressions against them. Given an input matrix $A\\in \\mathbb{R}^{n\\times d}$ with $n\\gg d$ and a response vector $b$, we first consider the matrix exponential of the matrix $A^\\top A$ as a proxy, and we in turn design algorithms for two types of regression problems: $\\min_{x\\in \\mathbb{R}^d}\\|(A^\\top A)^jx-b\\|_2$ and $\\min_{x\\in \\mathbb{R}^d}\\|A(A^\\top A)^jx-b\\|_2$ for any positive integer $j$. Studying algorithms for these regressions is essential, as matrix exponential can be approximated term-by-term via these smaller problems. The second proxy is applying exponential entrywise to the Gram matrix, denoted by $\\exp(AA^\\top)$ and solving the regression $\\min_{x\\in \\mathbb{R}^n}\\|\\exp(AA^\\top)x-b \\|_2$. We call this problem the \\emph{attention kernel regression} problem, as the matrix $\\exp(AA^\\top)$ could be viewed as a kernel function with respect to $A$. We design fast algorithms for these regression problems, based on sketching and preconditioning. We hope these efforts will provide an alternative perspective of studying efficient approximation of attention matrices.",
        "bibtex": "@InProceedings{pmlr-v238-song24a,\n  title = \t {Solving Attention Kernel Regression Problem via Pre-conditioner},\n  author =       {Song, Zhao and Yin, Junze and Zhang, Lichen},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {208--216},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/song24a/song24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/song24a.html},\n  abstract = \t {Attention mechanism is the key to large language models, and attention matrix serves as an algorithmic and computational bottleneck for such a scheme. In this paper, we define two problems, motivated by designing fast algorithms for \\emph{proxy} of attention matrix and solving regressions against them. Given an input matrix $A\\in \\mathbb{R}^{n\\times d}$ with $n\\gg d$ and a response vector $b$, we first consider the matrix exponential of the matrix $A^\\top A$ as a proxy, and we in turn design algorithms for two types of regression problems: $\\min_{x\\in \\mathbb{R}^d}\\|(A^\\top A)^jx-b\\|_2$ and $\\min_{x\\in \\mathbb{R}^d}\\|A(A^\\top A)^jx-b\\|_2$ for any positive integer $j$. Studying algorithms for these regressions is essential, as matrix exponential can be approximated term-by-term via these smaller problems. The second proxy is applying exponential entrywise to the Gram matrix, denoted by $\\exp(AA^\\top)$ and solving the regression $\\min_{x\\in \\mathbb{R}^n}\\|\\exp(AA^\\top)x-b \\|_2$. We call this problem the \\emph{attention kernel regression} problem, as the matrix $\\exp(AA^\\top)$ could be viewed as a kernel function with respect to $A$. We design fast algorithms for these regression problems, based on sketching and preconditioning. We hope these efforts will provide an alternative perspective of studying efficient approximation of attention matrices.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/song24a/song24a.pdf",
        "supp": "",
        "pdf_size": 601582,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16802452123131014191&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f61029f27e",
        "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
        "site": "https://proceedings.mlr.press/v238/tang24b.html",
        "author": "Haoyue Tang; Tian Xie; Aosong Feng; Hanyu Wang; Chenyang Zhang; Yang Bai",
        "abstract": "Solving image inverse problems (e.g., super-resolution and inpainting) requires generating a high fidelity image that matches the given input (the low-resolution image or the masked image). By using the input image as guidance, we can leverage a pretrained diffusion generative model to solve a wide range of image inverse tasks without task specific model fine-tuning. To precisely estimate the guidance score function of the input image, we propose Diffusion Policy Gradient (DPG), a tractable computation method by viewing the intermediate noisy images as policies and the target image as the states selected by the policy. Experiments show that our method is robust to both Gaussian and Poisson noise degradation on multiple linear and non-linear inverse tasks, resulting into a higher image restoration quality on FFHQ, ImageNet and LSUN datasets.",
        "bibtex": "@InProceedings{pmlr-v238-tang24b,\n  title = \t {Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint},\n  author =       {Tang, Haoyue and Xie, Tian and Feng, Aosong and Wang, Hanyu and Zhang, Chenyang and Bai, Yang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2116--2124},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tang24b/tang24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tang24b.html},\n  abstract = \t {Solving image inverse problems (e.g., super-resolution and inpainting) requires generating a high fidelity image that matches the given input (the low-resolution image or the masked image). By using the input image as guidance, we can leverage a pretrained diffusion generative model to solve a wide range of image inverse tasks without task specific model fine-tuning. To precisely estimate the guidance score function of the input image, we propose Diffusion Policy Gradient (DPG), a tractable computation method by viewing the intermediate noisy images as policies and the target image as the states selected by the policy. Experiments show that our method is robust to both Gaussian and Poisson noise degradation on multiple linear and non-linear inverse tasks, resulting into a higher image restoration quality on FFHQ, ImageNet and LSUN datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tang24b/tang24b.pdf",
        "supp": "",
        "pdf_size": 13726972,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6963240226563355705&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Meta AI; Meta AI; Yale University; University of Maryland, College Park + Meta AI; Meta AI; Meta AI",
        "aff_domain": "tsinghua.org.cn; ; ; ; ; ",
        "email": "tsinghua.org.cn; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2+0;0;0",
        "aff_unique_norm": "Meta;Yale University;University of Maryland",
        "aff_unique_dep": "Meta AI;;",
        "aff_unique_url": "https://meta.com;https://www.yale.edu;https://www/umd.edu",
        "aff_unique_abbr": "Meta;Yale;UMD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";College Park",
        "aff_country_unique_index": "0;0;0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b30227ad2e",
        "title": "Sparse and Faithful Explanations Without Sparse Models",
        "site": "https://proceedings.mlr.press/v238/sun24b.html",
        "author": "Yiyang Sun; Zhi Chen; Vittorio Orlandi; Tong Wang; Cynthia Rudin",
        "abstract": "Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models \u2013 even if they are not sparse \u2013 actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflecting real-world constraints. Our algorithms reduce SEV without sacrificing accuracy, providing sparse and completely faithful explanations, even without globally sparse models.",
        "bibtex": "@InProceedings{pmlr-v238-sun24b,\n  title = \t {Sparse and Faithful Explanations Without Sparse Models},\n  author =       {Sun, Yiyang and Chen, Zhi and Orlandi, Vittorio and Wang, Tong and Rudin, Cynthia},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2071--2079},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sun24b/sun24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sun24b.html},\n  abstract = \t {Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models \u2013 even if they are not sparse \u2013 actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflecting real-world constraints. Our algorithms reduce SEV without sacrificing accuracy, providing sparse and completely faithful explanations, even without globally sparse models.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sun24b/sun24b.pdf",
        "supp": "",
        "pdf_size": 8890386,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2139635747123645990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Duke University; Duke University; Duke University; Yale University; Duke University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Duke University;Yale University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.duke.edu;https://www.yale.edu",
        "aff_unique_abbr": "Duke;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "774e9150a7",
        "title": "Spectrum Extraction and Clipping for Implicitly Linear Layers",
        "site": "https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a.html",
        "author": "Ali Ebrahimpour Boroojeny; Matus Telgarsky; Hari Sundaram",
        "abstract": "We show the effectiveness of automatic differentiation in efficiently and correctly computing and controlling the spectrum of implicitly linear operators, a rich family of layer types including all standard convolutional and dense layers. We provide the first clipping method which is correct for general convolution layers, and illuminate the representational limitation that caused correctness issues in prior work. We study the effect of the batch normalization layers when concatenated with convolutional layers and show how our clipping method can be applied to their composition. By comparing the accuracy and performance of our algorithms to the state-of-the-art methods, using various experiments, we show they are more precise and efficient and lead to better generalization and adversarial robustness. We provide the code for using our methods at https://github.com/Ali-E/FastClip.",
        "bibtex": "@InProceedings{pmlr-v238-ebrahimpour-boroojeny24a,\n  title = \t {Spectrum Extraction and Clipping for Implicitly Linear Layers},\n  author =       {Ebrahimpour Boroojeny, Ali and Telgarsky, Matus and Sundaram, Hari},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2971--2979},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a/ebrahimpour-boroojeny24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a.html},\n  abstract = \t {We show the effectiveness of automatic differentiation in efficiently and correctly computing and controlling the spectrum of implicitly linear operators, a rich family of layer types including all standard convolutional and dense layers. We provide the first clipping method which is correct for general convolution layers, and illuminate the representational limitation that caused correctness issues in prior work. We study the effect of the batch normalization layers when concatenated with convolutional layers and show how our clipping method can be applied to their composition. By comparing the accuracy and performance of our algorithms to the state-of-the-art methods, using various experiments, we show they are more precise and efficient and lead to better generalization and adversarial robustness. We provide the code for using our methods at https://github.com/Ali-E/FastClip.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a/ebrahimpour-boroojeny24a.pdf",
        "supp": "",
        "pdf_size": 831117,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16548892240766263385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9eb49f731f",
        "title": "Stochastic Approximation with Biased MCMC for Expectation Maximization",
        "site": "https://proceedings.mlr.press/v238/gruffaz24a.html",
        "author": "Samuel Gruffaz; Kyurae Kim; Alain Durmus; Jacob Gardner",
        "abstract": "The expectation maximization (EM) algorithm is a widespread method for empirical Bayesian inference, but its expectation step (E-step) is often intractable. Employing a stochastic approximation scheme with Markov chain Monte Carlo (MCMC) can circumvent this issue, resulting in an algorithm known as MCMC-SAEM. While theoretical guarantees for MCMC-SAEM have previously been established, these results are restricted to the case where asymptotically unbiased MCMC algorithms are used. In practice, MCMC-SAEM is often run with asymptotically biased MCMC, for which the consequences are theoretically less understood. In this work, we fill this gap by analyzing the asymptotics and non-asymptotics of SAEM with biased MCMC steps, particularly the effect of bias. We also provide numerical experiments comparing the Metropolis-adjusted Langevin algorithm (MALA), which is asymptotically unbiased, and the unadjusted Langevin algorithm (ULA), which is asymptotically biased, on synthetic and real datasets. Experimental results show that ULA is more stable with respect to the choice of Langevin stepsize and can sometimes result in faster convergence.",
        "bibtex": "@InProceedings{pmlr-v238-gruffaz24a,\n  title = \t {Stochastic Approximation with Biased {MCMC} for Expectation Maximization},\n  author =       {Gruffaz, Samuel and Kim, Kyurae and Durmus, Alain and Gardner, Jacob},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2332--2340},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gruffaz24a/gruffaz24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gruffaz24a.html},\n  abstract = \t {The expectation maximization (EM) algorithm is a widespread method for empirical Bayesian inference, but its expectation step (E-step) is often intractable. Employing a stochastic approximation scheme with Markov chain Monte Carlo (MCMC) can circumvent this issue, resulting in an algorithm known as MCMC-SAEM. While theoretical guarantees for MCMC-SAEM have previously been established, these results are restricted to the case where asymptotically unbiased MCMC algorithms are used. In practice, MCMC-SAEM is often run with asymptotically biased MCMC, for which the consequences are theoretically less understood. In this work, we fill this gap by analyzing the asymptotics and non-asymptotics of SAEM with biased MCMC steps, particularly the effect of bias. We also provide numerical experiments comparing the Metropolis-adjusted Langevin algorithm (MALA), which is asymptotically unbiased, and the unadjusted Langevin algorithm (ULA), which is asymptotically biased, on synthetic and real datasets. Experimental results show that ULA is more stable with respect to the choice of Langevin stepsize and can sometimes result in faster convergence.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gruffaz24a/gruffaz24a.pdf",
        "supp": "",
        "pdf_size": 709311,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6910070077450823408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b034c5ae24",
        "title": "Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling",
        "site": "https://proceedings.mlr.press/v238/adibi24a.html",
        "author": "Arman Adibi; Nicol\u00f2 Dal Fabbro; Luca Schenato; Sanjeev Kulkarni; H. Vincent Poor; George J. Pappas; Hamed Hassani; Aritra Mitra",
        "abstract": "Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \\emph{last iterate} to a ball around the SA operator\u2019s fixed point. Notably, our bound is \\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the mixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing uniform boundedness of the iterates. As such, our proof may be of independent interest. Next, to mitigate the impact of the maximum delay on the convergence rate, we provide the first finite-time analysis of a delay-adaptive SA scheme under Markovian sampling. In particular, we show that the exponent of convergence of this scheme gets scaled down by $\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here, $\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the adaptive scheme requires no prior knowledge of the delay sequence for step-size tuning. Our theoretical findings shed light on the finite-time effects of delays for a broad class of algorithms, including TD learning, Q-learning, and stochastic gradient descent under Markovian sampling.",
        "bibtex": "@InProceedings{pmlr-v238-adibi24a,\n  title = \t {Stochastic Approximation with Delayed Updates: Finite-Time Rates under {M}arkovian Sampling},\n  author =       {Adibi, Arman and {D}al Fabbro, Nicol\\`{o} and Schenato, Luca and Kulkarni, Sanjeev and Vincent Poor, H. and J. Pappas, George and Hassani, Hamed and Mitra, Aritra},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2746--2754},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/adibi24a/adibi24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/adibi24a.html},\n  abstract = \t {Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \\emph{last iterate} to a ball around the SA operator\u2019s fixed point. Notably, our bound is \\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the mixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing uniform boundedness of the iterates. As such, our proof may be of independent interest. Next, to mitigate the impact of the maximum delay on the convergence rate, we provide the first finite-time analysis of a delay-adaptive SA scheme under Markovian sampling. In particular, we show that the exponent of convergence of this scheme gets scaled down by $\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here, $\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the adaptive scheme requires no prior knowledge of the delay sequence for step-size tuning. Our theoretical findings shed light on the finite-time effects of delays for a broad class of algorithms, including TD learning, Q-learning, and stochastic gradient descent under Markovian sampling.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/adibi24a/adibi24a.pdf",
        "supp": "",
        "pdf_size": 369352,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3359973008830776906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Princeton University; University of Pennsylvania; University of Padova; Princeton University; Princeton University; University of Pennsylvania; University of Pennsylvania; NC State University",
        "aff_domain": "; ; ; ; ; ; ; ",
        "email": "; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0;1;1;3",
        "aff_unique_norm": "Princeton University;University of Pennsylvania;University of Padova;North Carolina State University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.princeton.edu;https://www.upenn.edu;https://www.unipd.it;https://www.ncsu.edu",
        "aff_unique_abbr": "Princeton;UPenn;UNIPD;NC State",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0;0;0",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "d0d47af0b5",
        "title": "Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities",
        "site": "https://proceedings.mlr.press/v238/emmanouilidis24a.html",
        "author": "Konstantinos Emmanouilidis; Rene Vidal; Nicolas Loizou",
        "abstract": "The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement SEG. As a byproduct of our results, we provide convergence guarantees for Shuffle Once SEG (shuffles the data only at the beginning of the algorithm) and the Incremental Extragradient (does not shuffle the data). We supplement our analysis with experiments validating empirically the superior performance of SEG-RR over the classical with-replacement sampling SEG.",
        "bibtex": "@InProceedings{pmlr-v238-emmanouilidis24a,\n  title = \t {Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities},\n  author =       {Emmanouilidis, Konstantinos and Vidal, Rene and Loizou, Nicolas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3682--3690},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/emmanouilidis24a/emmanouilidis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/emmanouilidis24a.html},\n  abstract = \t {The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement SEG. As a byproduct of our results, we provide convergence guarantees for Shuffle Once SEG (shuffles the data only at the beginning of the algorithm) and the Incremental Extragradient (does not shuffle the data). We supplement our analysis with experiments validating empirically the superior performance of SEG-RR over the classical with-replacement sampling SEG.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/emmanouilidis24a/emmanouilidis24a.pdf",
        "supp": "",
        "pdf_size": 975525,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3253846382753650556&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "CS & MINDS, Johns Hopkins University; ESE, Radiology & IDEAS, University of Pennsylvania; AMS & MINDS, Johns Hopkins University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Johns Hopkins University;University of Pennsylvania",
        "aff_unique_dep": "CS & MINDS;ESE, Radiology & IDEAS",
        "aff_unique_url": "https://www.jhu.edu;https://www.upenn.edu",
        "aff_unique_abbr": "JHU;UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a57077bbb6",
        "title": "Stochastic Frank-Wolfe: Unified Analysis and Zoo of Special Cases",
        "site": "https://proceedings.mlr.press/v238/nazykov24a.html",
        "author": "Ruslan Nazykov; Aleksandr Shestakov; Vladimir Solodkin; Aleksandr Beznosikov; Gauthier Gidel; Alexander Gasnikov",
        "abstract": "The Conditional Gradient (or Frank-Wolfe) method is one of the most well-known methods for solving constrained optimization problems appearing in various machine learning tasks. The simplicity of iteration and applicability to many practical problems helped the method to gain popularity in the community. In recent years, the Frank-Wolfe algorithm received many different extensions, including stochastic modifications with variance reduction and coordinate sampling for training of huge models or distributed variants for big data problems. In this paper, we present a unified convergence analysis of the Stochastic Frank-Wolfe method that covers a large number of particular practical cases that may have completely different nature of stochasticity, intuitions and application areas. Our analysis is based on a key parametric assumption on the variance of the stochastic gradients. But unlike most works on unified analysis of other methods, such as SGD, we do not assume an unbiasedness of the real gradient estimation. We conduct analysis for convex and non-convex problems due to the popularity of both cases in machine learning. With this general theoretical framework, we not only cover rates of many known methods, but also develop numerous new methods. This shows the flexibility of our approach in developing new algorithms based on the Conditional Gradient approach. We also demonstrate the properties of the new methods through numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-nazykov24a,\n  title = \t {Stochastic {F}rank-{W}olfe: Unified Analysis and Zoo of Special Cases},\n  author =       {Nazykov, Ruslan and Shestakov, Aleksandr and Solodkin, Vladimir and Beznosikov, Aleksandr and Gidel, Gauthier and Gasnikov, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4870--4878},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nazykov24a/nazykov24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nazykov24a.html},\n  abstract = \t {The Conditional Gradient (or Frank-Wolfe) method is one of the most well-known methods for solving constrained optimization problems appearing in various machine learning tasks. The simplicity of iteration and applicability to many practical problems helped the method to gain popularity in the community. In recent years, the Frank-Wolfe algorithm received many different extensions, including stochastic modifications with variance reduction and coordinate sampling for training of huge models or distributed variants for big data problems. In this paper, we present a unified convergence analysis of the Stochastic Frank-Wolfe method that covers a large number of particular practical cases that may have completely different nature of stochasticity, intuitions and application areas. Our analysis is based on a key parametric assumption on the variance of the stochastic gradients. But unlike most works on unified analysis of other methods, such as SGD, we do not assume an unbiasedness of the real gradient estimation. We conduct analysis for convex and non-convex problems due to the popularity of both cases in machine learning. With this general theoretical framework, we not only cover rates of many known methods, but also develop numerous new methods. This shows the flexibility of our approach in developing new algorithms based on the Conditional Gradient approach. We also demonstrate the properties of the new methods through numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nazykov24a/nazykov24a.pdf",
        "supp": "",
        "pdf_size": 2771745,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3657316840001110351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "71e22569ec",
        "title": "Stochastic Methods in Variational Inequalities: Ergodicity, Bias and Refinements",
        "site": "https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a.html",
        "author": "Emmanouil Vasileios Vlatakis-Gkaragkounis; Angeliki Giannou; Yudong Chen; Qiaomin Xie",
        "abstract": "For min-max optimization and variational inequalities problems (VIPs), Stochastic Extragradient (SEG) and Stochastic Gradient Descent Ascent (SGDA) have emerged as preeminent algorithms. Constant step-size versions of SEG/SGDA have gained popularity due to several appealing benefits, but their convergence behaviors are complicated even in rudimentary bilinear models. Our work elucidates the probabilistic behavior of these algorithms and their projected variants, for a wide range of monotone and non-monotone VIPs with potentially biased stochastic oracles. By recasting them as time-homogeneous Markov Chains, we establish geometric convergence to a unique invariant distribution and aymptotic normality. Specializing to min-max optimization, we characterize the relationship between the step-size and the induced bias with respect to the global solution, which in turns allows for bias refinement via the Richardson-Romberg scheme. Our theoretical analysis is corroborated by numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-vasileios-vlatakis-gkaragkounis24a,\n  title = \t {Stochastic Methods in Variational Inequalities: Ergodicity, Bias and Refinements},\n  author =       {Vasileios Vlatakis-Gkaragkounis, Emmanouil and Giannou, Angeliki and Chen, Yudong and Xie, Qiaomin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4123--4131},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a/vasileios-vlatakis-gkaragkounis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a.html},\n  abstract = \t {For min-max optimization and variational inequalities problems (VIPs), Stochastic Extragradient (SEG) and Stochastic Gradient Descent Ascent (SGDA) have emerged as preeminent algorithms. Constant step-size versions of SEG/SGDA have gained popularity due to several appealing benefits, but their convergence behaviors are complicated even in rudimentary bilinear models. Our work elucidates the probabilistic behavior of these algorithms and their projected variants, for a wide range of monotone and non-monotone VIPs with potentially biased stochastic oracles. By recasting them as time-homogeneous Markov Chains, we establish geometric convergence to a unique invariant distribution and aymptotic normality. Specializing to min-max optimization, we characterize the relationship between the step-size and the induced bias with respect to the global solution, which in turns allows for bias refinement via the Richardson-Romberg scheme. Our theoretical analysis is corroborated by numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a/vasileios-vlatakis-gkaragkounis24a.pdf",
        "supp": "",
        "pdf_size": 2718513,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3012660997859946818&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "808eed3249",
        "title": "Stochastic Multi-Armed Bandits with Strongly Reward-Dependent Delays",
        "site": "https://proceedings.mlr.press/v238/tang24c.html",
        "author": "Yifu Tang; Yingfei Wang; Zeyu Zheng",
        "abstract": "There has been increasing interest in applying multi-armed bandits to adaptive designs in clinical trials. However, most literature assumes that a previous patient\u2019s survival response of a treatment is known before the next patient is treated, which is unrealistic. The inability to account for response delays is cited frequently as one of the problems in using adaptive designs in clinical trials. More critically, the \u201cdelays\u201d in observing the survival response are the same as the rewards rather than being external stochastic noise. We formalize this problem as a novel stochastic multi-armed bandit (MAB) problem with reward-dependent delays, where the delay at each round depends on the reward generated on the same round. For general reward/delay distributions with finite expectation, our proposed censored-UCB algorithm achieves near-optimal regret in terms of both problem-dependent and problem-independent bounds. With bounded or sub-Gaussian reward distributions, the upper bounds are optimal with a matching lower bound. Our theoretical results and the algorithms\u2019 effectiveness are validated by empirical experiments.",
        "bibtex": "@InProceedings{pmlr-v238-tang24c,\n  title = \t {Stochastic Multi-Armed Bandits with Strongly Reward-Dependent Delays},\n  author =       {Tang, Yifu and Wang, Yingfei and Zheng, Zeyu},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3043--3051},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/tang24c/tang24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/tang24c.html},\n  abstract = \t {There has been increasing interest in applying multi-armed bandits to adaptive designs in clinical trials. However, most literature assumes that a previous patient\u2019s survival response of a treatment is known before the next patient is treated, which is unrealistic. The inability to account for response delays is cited frequently as one of the problems in using adaptive designs in clinical trials. More critically, the \u201cdelays\u201d in observing the survival response are the same as the rewards rather than being external stochastic noise. We formalize this problem as a novel stochastic multi-armed bandit (MAB) problem with reward-dependent delays, where the delay at each round depends on the reward generated on the same round. For general reward/delay distributions with finite expectation, our proposed censored-UCB algorithm achieves near-optimal regret in terms of both problem-dependent and problem-independent bounds. With bounded or sub-Gaussian reward distributions, the upper bounds are optimal with a matching lower bound. Our theoretical results and the algorithms\u2019 effectiveness are validated by empirical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/tang24c/tang24c.pdf",
        "supp": "",
        "pdf_size": 3435071,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2213369219384693708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Tsinghua University; University of Washington; University of California, Berkeley",
        "aff_domain": "uw.edu; ; ",
        "email": "uw.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Tsinghua University;University of Washington;University of California, Berkeley",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.washington.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "THU;UW;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "e4fc554207",
        "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization",
        "site": "https://proceedings.mlr.press/v238/shen24c.html",
        "author": "Wei Shen; Minhui Huang; Jiawei Zhang; Cong Shen",
        "abstract": "In recent years, federated minimax optimization has attracted growing interest due to its extensive applications in various machine learning tasks. While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved successful in centralized nonconvex minimax optimization, how and whether smoothing techniques could be helpful in a federated setting remains unexplored. In this paper, we propose a new algorithm termed Federated Stochastic Smoothed Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for federated minimax optimization. We prove that FESS-GDA can be uniformly applied to solve several classes of federated minimax problems and prove new or better analytical convergence results for these settings. We showcase the practical efficiency of FESS-GDA in practical federated learning tasks of training generative adversarial networks (GANs) and fair classification.",
        "bibtex": "@InProceedings{pmlr-v238-shen24c,\n  title = \t {Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization},\n  author =       {Shen, Wei and Huang, Minhui and Zhang, Jiawei and Shen, Cong},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3988--3996},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shen24c/shen24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shen24c.html},\n  abstract = \t {In recent years, federated minimax optimization has attracted growing interest due to its extensive applications in various machine learning tasks. While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved successful in centralized nonconvex minimax optimization, how and whether smoothing techniques could be helpful in a federated setting remains unexplored. In this paper, we propose a new algorithm termed Federated Stochastic Smoothed Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for federated minimax optimization. We prove that FESS-GDA can be uniformly applied to solve several classes of federated minimax problems and prove new or better analytical convergence results for these settings. We showcase the practical efficiency of FESS-GDA in practical federated learning tasks of training generative adversarial networks (GANs) and fair classification.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shen24c/shen24c.pdf",
        "supp": "",
        "pdf_size": 1069664,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11654379366425617356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b528f7a3b2",
        "title": "Strategic Usage in a Multi-Learner Setting",
        "site": "https://proceedings.mlr.press/v238/shekhtman24a.html",
        "author": "Eliot Shekhtman; Sarah Dean",
        "abstract": "Real-world systems often involve some pool of users choosing between a set of services. With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality. On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data. Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems. As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations. We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes. We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-shekhtman24a,\n  title = \t {Strategic Usage in a Multi-Learner Setting},\n  author =       {Shekhtman, Eliot and Dean, Sarah},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2665--2673},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shekhtman24a/shekhtman24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shekhtman24a.html},\n  abstract = \t {Real-world systems often involve some pool of users choosing between a set of services. With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality. On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data. Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems. As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations. We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes. We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shekhtman24a/shekhtman24a.pdf",
        "supp": "",
        "pdf_size": 2298757,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9002163015333789900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Cornell University; Cornell University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "23dcd0a176",
        "title": "Structural perspective on constraint-based learning of Markov networks",
        "site": "https://proceedings.mlr.press/v238/korhonen24a.html",
        "author": "Tuukka Korhonen; Fedor Fomin; Pekka Parviainen",
        "abstract": "Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary. On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph. When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound q on the sizes of the conditioning sets, there exist graphs with $O(nq)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2*\\kappa$.",
        "bibtex": "@InProceedings{pmlr-v238-korhonen24a,\n  title = \t {Structural perspective on constraint-based learning of {M}arkov networks},\n  author =       {Korhonen, Tuukka and Fomin, Fedor and Parviainen, Pekka},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1855--1863},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/korhonen24a/korhonen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/korhonen24a.html},\n  abstract = \t {Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary. On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph. When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound q on the sizes of the conditioning sets, there exist graphs with $O(nq)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2*\\kappa$.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/korhonen24a/korhonen24a.pdf",
        "supp": "",
        "pdf_size": 436685,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15214916424028034050&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "570691bb71",
        "title": "Structured Transforms Across Spaces with Cost-Regularized Optimal Transport",
        "site": "https://proceedings.mlr.press/v238/sebbouh24a.html",
        "author": "Othmane Sebbouh; Marco Cuturi; Gabriel Peyr\u00e9",
        "abstract": "Matching a source to a target probability measure is often solved by instantiating a linear optimal transport (OT) problem, parameterized by a ground cost function that quantifies discrepancy between points. When these measures live in the same metric space, the ground cost often defaults to its distance. When instantiated across two different spaces, however, choosing that cost in the absence of aligned data is a conundrum. As a result, practitioners often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We exploit in this work a parallel between GW and cost-regularized OT, the regularized minimization of a linear OT objective parameterized by a ground cost. We use this cost-regularized formulation to match measures across two different Euclidean spaces, where the cost is evaluated between transformed source points and target points. We show that several quadratic OT problems fall in this category, and consider enforcing structure in linear transform (e.g., sparsity), by introducing structure-inducing regularizers. We provide a proximal algorithm to extract such transforms from unaligned data, and demonstrate its applicability to single-cell spatial transcriptomics/multiomics matching tasks.",
        "bibtex": "@InProceedings{pmlr-v238-sebbouh24a,\n  title = \t {Structured Transforms Across Spaces with Cost-Regularized Optimal Transport},\n  author =       {Sebbouh, Othmane and Cuturi, Marco and Peyr\\'{e}, Gabriel},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {586--594},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sebbouh24a/sebbouh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sebbouh24a.html},\n  abstract = \t {Matching a source to a target probability measure is often solved by instantiating a linear optimal transport (OT) problem, parameterized by a ground cost function that quantifies discrepancy between points. When these measures live in the same metric space, the ground cost often defaults to its distance. When instantiated across two different spaces, however, choosing that cost in the absence of aligned data is a conundrum. As a result, practitioners often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We exploit in this work a parallel between GW and cost-regularized OT, the regularized minimization of a linear OT objective parameterized by a ground cost. We use this cost-regularized formulation to match measures across two different Euclidean spaces, where the cost is evaluated between transformed source points and target points. We show that several quadratic OT problems fall in this category, and consider enforcing structure in linear transform (e.g., sparsity), by introducing structure-inducing regularizers. We provide a proximal algorithm to extract such transforms from unaligned data, and demonstrate its applicability to single-cell spatial transcriptomics/multiomics matching tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sebbouh24a/sebbouh24a.pdf",
        "supp": "",
        "pdf_size": 2509300,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3492245652926105793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1e0049fa39",
        "title": "Submodular Minimax Optimization: Finding Effective Sets",
        "site": "https://proceedings.mlr.press/v238/raed-mualem24a.html",
        "author": "Loay Raed Mualem; Ethan R Elenberg; Moran Feldman; Amin Karbasi",
        "abstract": "Despite the rich existing literature about minimax optimization in continuous settings, only very partial results of this kind have been obtained for combinatorial settings. In this paper, we fill this gap by providing a characterization of submodular minimax optimization, the problem of finding a set (for either the min or the max player) that is effective against every possible response. We show when and under what conditions we can find such sets. We also demonstrate how minimax submodular optimization provides robust solutions for downstream machine learning applications such as (i) prompt engineering in large language models, (ii) identifying robust waiting locations for ride-sharing, (iii) kernelization of the difficulty of instances of the last setting, and (iv) finding adversarial images. Our experiments show that our proposed algorithms consistently outperform other baselines.",
        "bibtex": "@InProceedings{pmlr-v238-raed-mualem24a,\n  title = \t {Submodular Minimax Optimization: Finding Effective Sets},\n  author =       {Raed Mualem, Loay and R Elenberg, Ethan and Feldman, Moran and Karbasi, Amin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1081--1089},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/raed-mualem24a/raed-mualem24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/raed-mualem24a.html},\n  abstract = \t {Despite the rich existing literature about minimax optimization in continuous settings, only very partial results of this kind have been obtained for combinatorial settings. In this paper, we fill this gap by providing a characterization of submodular minimax optimization, the problem of finding a set (for either the min or the max player) that is effective against every possible response. We show when and under what conditions we can find such sets. We also demonstrate how minimax submodular optimization provides robust solutions for downstream machine learning applications such as (i) prompt engineering in large language models, (ii) identifying robust waiting locations for ride-sharing, (iii) kernelization of the difficulty of instances of the last setting, and (iv) finding adversarial images. Our experiments show that our proposed algorithms consistently outperform other baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/raed-mualem24a/raed-mualem24a.pdf",
        "supp": "",
        "pdf_size": 2564130,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12924917339259189161&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "05f6af7863",
        "title": "Subsampling Error in Stochastic Gradient Langevin Diffusions",
        "site": "https://proceedings.mlr.press/v238/jin24a.html",
        "author": "Kexin Jin; Chenguang Liu; Jonas Latz",
        "abstract": "The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler\u2013Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method\u2019s pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show the exponential ergodicity of SLGDiff and that the Wasserstein distance between the posterior and the limiting distribution of SGLDiff is bounded above by a fractional power of the mean waiting time. We bring our results into context with other analyses of SGLD.",
        "bibtex": "@InProceedings{pmlr-v238-jin24a,\n  title = \t {Subsampling Error in Stochastic Gradient {L}angevin Diffusions},\n  author =       {Jin, Kexin and Liu, Chenguang and Latz, Jonas},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1414--1422},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/jin24a/jin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/jin24a.html},\n  abstract = \t {The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler\u2013Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method\u2019s pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show the exponential ergodicity of SLGDiff and that the Wasserstein distance between the posterior and the limiting distribution of SGLDiff is bounded above by a fractional power of the mean waiting time. We bring our results into context with other analyses of SGLD.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/jin24a/jin24a.pdf",
        "supp": "",
        "pdf_size": 3543551,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Wb1bcqTQgBcJ:scholar.google.com/&scioq=Subsampling+Error+in+Stochastic+Gradient+Langevin+Diffusions&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "aff": "Princeton University; Delft University of Technology; University of Manchester",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Delft University of Technology;University of Manchester",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.princeton.edu;https://www.tudelft.nl;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Princeton;TU Delft;UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "United States;Netherlands;United Kingdom"
    },
    {
        "id": "854d9b31ca",
        "title": "Sum-max Submodular Bandits",
        "site": "https://proceedings.mlr.press/v238/pasteris24a.html",
        "author": "Stephen U. Pasteris; Alberto Rumi; Fabio Vitale; Nicol\u00f2 Cesa-Bianchi",
        "abstract": "Many online decision-making problems correspond to maximizing a sequence of submodular functions. In this work, we introduce sum-max functions, a subclass of monotone submodular functions capturing several interesting problems, including best-of-$K$-bandits, combinatorial bandits, and the bandit versions on $M$-medians and hitting sets. We show that all functions in this class satisfy a key property that we call pseudo-concavity. This allows us to prove $\\big(1 - \\frac{1}{e}\\big)$-regret bounds for bandit feedback in the nonstochastic setting of the order of $\\sqrt{MKT}$ (ignoring log factors), where $T$ is the time horizon and $M$ is a cardinality constraint. This bound, attained by a simple and efficient algorithm, significantly improves on the $\\widetilde{\\mathcal{O}}\\big(T^{2/3}\\big)$ regret bound for online monotone submodular maximization with bandit feedback. We also extend our results to a bandit version of the facility location problem.",
        "bibtex": "@InProceedings{pmlr-v238-pasteris24a,\n  title = \t {Sum-max Submodular Bandits},\n  author =       {Pasteris, Stephen U. and Rumi, Alberto and Vitale, Fabio and Cesa-Bianchi, Nicol\\`{o}},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2323--2331},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pasteris24a/pasteris24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pasteris24a.html},\n  abstract = \t {Many online decision-making problems correspond to maximizing a sequence of submodular functions. In this work, we introduce sum-max functions, a subclass of monotone submodular functions capturing several interesting problems, including best-of-$K$-bandits, combinatorial bandits, and the bandit versions on $M$-medians and hitting sets. We show that all functions in this class satisfy a key property that we call pseudo-concavity. This allows us to prove $\\big(1 - \\frac{1}{e}\\big)$-regret bounds for bandit feedback in the nonstochastic setting of the order of $\\sqrt{MKT}$ (ignoring log factors), where $T$ is the time horizon and $M$ is a cardinality constraint. This bound, attained by a simple and efficient algorithm, significantly improves on the $\\widetilde{\\mathcal{O}}\\big(T^{2/3}\\big)$ regret bound for online monotone submodular maximization with bandit feedback. We also extend our results to a bandit version of the facility location problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pasteris24a/pasteris24a.pdf",
        "supp": "",
        "pdf_size": 20147028,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9953011760157576471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d105a0086e",
        "title": "Supervised Feature Selection via Ensemble Gradient Information from Sparse Neural Networks",
        "site": "https://proceedings.mlr.press/v238/liu24f.html",
        "author": "Kaiting Liu; Zahra Atashgahi; Ghada Sokar; Mykola Pechenizkiy; Decebal Constantin Mocanu",
        "abstract": "Feature selection algorithms aim to select a subset of informative features from a dataset to reduce the data dimensionality, consequently saving resource consumption and improving the model\u2019s performance and interpretability. In recent years, feature selection based on neural networks has become a new trend, demonstrating superiority over traditional feature selection methods. However, most existing methods use dense neural networks to detect informative features, which requires significant computational and memory overhead. In this paper, taking inspiration from the successful application of local sensitivity analysis on neural networks, we propose a novel resource-efficient supervised feature selection algorithm based on sparse multi-layer perceptron called \u201cGradEnFS\". By utilizing the gradient information of various sparse models from different training iterations, our method successfully detects the informative feature subset. We performed extensive experiments on nine classification datasets spanning various domains to evaluate the effectiveness of our method. The results demonstrate that our proposed approach outperforms the state-of-the-art methods in terms of selecting informative features while saving resource consumption substantially. Moreover, we show that using a sparse neural network for feature selection not only alleviates resource consumption but also has a significant advantage over other methods when performing feature selection on noisy datasets.",
        "bibtex": "@InProceedings{pmlr-v238-liu24f,\n  title = \t {Supervised Feature Selection via Ensemble Gradient Information from Sparse Neural Networks},\n  author =       {Liu, Kaiting and Atashgahi, Zahra and Sokar, Ghada and Pechenizkiy, Mykola and Mocanu, Decebal Constantin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3952--3960},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24f/liu24f.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24f.html},\n  abstract = \t {Feature selection algorithms aim to select a subset of informative features from a dataset to reduce the data dimensionality, consequently saving resource consumption and improving the model\u2019s performance and interpretability. In recent years, feature selection based on neural networks has become a new trend, demonstrating superiority over traditional feature selection methods. However, most existing methods use dense neural networks to detect informative features, which requires significant computational and memory overhead. In this paper, taking inspiration from the successful application of local sensitivity analysis on neural networks, we propose a novel resource-efficient supervised feature selection algorithm based on sparse multi-layer perceptron called \u201cGradEnFS\". By utilizing the gradient information of various sparse models from different training iterations, our method successfully detects the informative feature subset. We performed extensive experiments on nine classification datasets spanning various domains to evaluate the effectiveness of our method. The results demonstrate that our proposed approach outperforms the state-of-the-art methods in terms of selecting informative features while saving resource consumption substantially. Moreover, we show that using a sparse neural network for feature selection not only alleviates resource consumption but also has a significant advantage over other methods when performing feature selection on noisy datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24f/liu24f.pdf",
        "supp": "",
        "pdf_size": 5053243,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17728037512371533636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Eindhoven University of Technology; University of Twente; Eindhoven University of Technology; Eindhoven University of Technology; University of Luxembourg+Eindhoven University of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;2+0",
        "aff_unique_norm": "Eindhoven University of Technology;University of Twente;University of Luxembourg",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tue.nl;https://www.utwente.nl;https://wwwen.uniluxembourg.lu",
        "aff_unique_abbr": "TU/e;UT;Uni Lu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1+0",
        "aff_country_unique": "Netherlands;Luxembourg"
    },
    {
        "id": "e2d1b0047e",
        "title": "Surrogate Active Subspaces for Jump-Discontinuous Functions",
        "site": "https://proceedings.mlr.press/v238/wycoff24a.html",
        "author": "Nathan Wycoff",
        "abstract": "Surrogate modeling and active subspaces have emerged as powerful paradigms in computational science and engineering. Porting such techniques to computational models in the social sciences brings into sharp relief their limitations in dealing with discontinuous simulators, such as Agent-Based Models, which have discrete outputs. Nevertheless, prior applied work has shown that surrogate estimates of active subspaces for such estimators can yield interesting results. But given that active subspaces are defined by way of gradients, it is not clear what quantity is being estimated when this methodology is applied to a discontinuous simulator. We begin this article by showing some pathologies that can arise when conducting such an analysis. This motivates an extension of active subspaces to discontinuous functions, clarifying what is actually being estimated in such analyses. We also conduct numerical experiments on synthetic test functions to compare Gaussian process estimates of active subspaces on continuous and discontinuous functions. Finally, we deploy our methodology on Flee, an agent-based model of refugee movement, yielding novel insights into which parameters of the simulation are most important across 8 displacement crises in Africa and the Middle East.",
        "bibtex": "@InProceedings{pmlr-v238-wycoff24a,\n  title = \t {Surrogate Active Subspaces for Jump-Discontinuous Functions},\n  author =       {Wycoff, Nathan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4618--4626},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wycoff24a/wycoff24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wycoff24a.html},\n  abstract = \t {Surrogate modeling and active subspaces have emerged as powerful paradigms in computational science and engineering. Porting such techniques to computational models in the social sciences brings into sharp relief their limitations in dealing with discontinuous simulators, such as Agent-Based Models, which have discrete outputs. Nevertheless, prior applied work has shown that surrogate estimates of active subspaces for such estimators can yield interesting results. But given that active subspaces are defined by way of gradients, it is not clear what quantity is being estimated when this methodology is applied to a discontinuous simulator. We begin this article by showing some pathologies that can arise when conducting such an analysis. This motivates an extension of active subspaces to discontinuous functions, clarifying what is actually being estimated in such analyses. We also conduct numerical experiments on synthetic test functions to compare Gaussian process estimates of active subspaces on continuous and discontinuous functions. Finally, we deploy our methodology on Flee, an agent-based model of refugee movement, yielding novel insights into which parameters of the simulation are most important across 8 displacement crises in Africa and the Middle East.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wycoff24a/wycoff24a.pdf",
        "supp": "",
        "pdf_size": 1691228,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18399923292483126914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "The McCourt School\u2019s Massive Data Institute, Georgetown University, Washington, D.C.",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Georgetown University",
        "aff_unique_dep": "The McCourt School\u2019s Massive Data Institute",
        "aff_unique_url": "https://www.georgetown.edu",
        "aff_unique_abbr": "Georgetown",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Washington, D.C.",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f3665c65d4",
        "title": "Surrogate Bayesian Networks for Approximating Evolutionary Games",
        "site": "https://proceedings.mlr.press/v238/hsiao24a.html",
        "author": "Vincent Hsiao; Dana S Nau; Bobak Pezeshki; Rina Dechter",
        "abstract": "Spatial evolutionary games are used to model large systems of interacting agents. In earlier work, a method was developed using Bayesian Networks to approximate the population dynamics in these games. One of the advantages of the Bayesian Network modeling approach is that it is possible to smoothly adjust the size of the network to get more accurate approximations. However, scaling the method up can be intractable if the number of strategies in the evolutionary game increases. In this paper, we propose a new method for computing more accurate approximations by using surrogate Bayesian Networks. Instead of computing inference on larger networks directly, we perform inference on a much smaller surrogate network extended with parameters that exploit the symmetry inherent to the domain. We learn the parameters on the surrogate network using KL-divergence as the loss function. We illustrate the value of this method empirically through a comparison on several evolutionary games.",
        "bibtex": "@InProceedings{pmlr-v238-hsiao24a,\n  title = \t {Surrogate {B}ayesian Networks for Approximating Evolutionary Games},\n  author =       {Hsiao, Vincent and S Nau, Dana and Pezeshki, Bobak and Dechter, Rina},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2566--2574},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hsiao24a/hsiao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hsiao24a.html},\n  abstract = \t {Spatial evolutionary games are used to model large systems of interacting agents. In earlier work, a method was developed using Bayesian Networks to approximate the population dynamics in these games. One of the advantages of the Bayesian Network modeling approach is that it is possible to smoothly adjust the size of the network to get more accurate approximations. However, scaling the method up can be intractable if the number of strategies in the evolutionary game increases. In this paper, we propose a new method for computing more accurate approximations by using surrogate Bayesian Networks. Instead of computing inference on larger networks directly, we perform inference on a much smaller surrogate network extended with parameters that exploit the symmetry inherent to the domain. We learn the parameters on the surrogate network using KL-divergence as the loss function. We illustrate the value of this method empirically through a comparison on several evolutionary games.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hsiao24a/hsiao24a.pdf",
        "supp": "",
        "pdf_size": 1057745,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11859131004553745919&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e375425a42",
        "title": "Symmetric Equilibrium Learning of VAEs",
        "site": "https://proceedings.mlr.press/v238/flach24a.html",
        "author": "Boris Flach; Dmitrij Schlesinger; Alexander Shekhovtsov",
        "abstract": "We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa. The standard learning approach for VAEs is the maximisation of the evidence lower bound (ELBO). It is asymmetric in that it aims at learning a latent variable model while using the encoder as an auxiliary means only. Moreover, it requires a closed form a-priori latent distribution. This limits its applicability in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors. We propose a Nash equilibrium learning approach, which is symmetric with respect to the encoder and decoder and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling. The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks.",
        "bibtex": "@InProceedings{pmlr-v238-flach24a,\n  title = \t {Symmetric Equilibrium Learning of {VAE}s},\n  author =       {Flach, Boris and Schlesinger, Dmitrij and Shekhovtsov, Alexander},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3214--3222},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/flach24a/flach24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/flach24a.html},\n  abstract = \t {We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa. The standard learning approach for VAEs is the maximisation of the evidence lower bound (ELBO). It is asymmetric in that it aims at learning a latent variable model while using the encoder as an auxiliary means only. Moreover, it requires a closed form a-priori latent distribution. This limits its applicability in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors. We propose a Nash equilibrium learning approach, which is symmetric with respect to the encoder and decoder and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling. The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/flach24a/flach24a.pdf",
        "supp": "",
        "pdf_size": 2600095,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10534493945576425992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2cccd8c2a8",
        "title": "Tackling the XAI Disagreement Problem with Regional Explanations",
        "site": "https://proceedings.mlr.press/v238/laberge24a.html",
        "author": "Gabriel Laberge; Yann Batiste Pequignot; Mario Marchand; Foutse Khomh",
        "abstract": "The XAI Disagreement Problem concerns the fact that various explainability methods yield different local/global insights on model behavior. Thus, given the lack of ground truth in explainability, practitioners are left wondering \u201cWhich explanation should I believe?\u201d. In this work, we approach the Disagreement Problem from the point of view of Functional Decomposition (FD). First, we demonstrate that many XAI techniques disagree because they handle feature interactions differently. Secondly, we reduce interactions locally by fitting a so-called FD-Tree, which partitions the input space into regions where the model is approximately additive. Thus instead of providing global explanations aggregated over the whole dataset, we advocate reporting the FD-Tree structure as well as the regional explanations extracted from its leaves. The beneficial effects of FD-Trees on the Disagreement Problem are demonstrated on toy and real datasets.",
        "bibtex": "@InProceedings{pmlr-v238-laberge24a,\n  title = \t {Tackling the {XAI} Disagreement Problem with Regional Explanations},\n  author =       {Laberge, Gabriel and Batiste Pequignot, Yann and Marchand, Mario and Khomh, Foutse},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2017--2025},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/laberge24a/laberge24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/laberge24a.html},\n  abstract = \t {The XAI Disagreement Problem concerns the fact that various explainability methods yield different local/global insights on model behavior. Thus, given the lack of ground truth in explainability, practitioners are left wondering \u201cWhich explanation should I believe?\u201d. In this work, we approach the Disagreement Problem from the point of view of Functional Decomposition (FD). First, we demonstrate that many XAI techniques disagree because they handle feature interactions differently. Secondly, we reduce interactions locally by fitting a so-called FD-Tree, which partitions the input space into regions where the model is approximately additive. Thus instead of providing global explanations aggregated over the whole dataset, we advocate reporting the FD-Tree structure as well as the regional explanations extracted from its leaves. The beneficial effects of FD-Trees on the Disagreement Problem are demonstrated on toy and real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/laberge24a/laberge24a.pdf",
        "supp": "",
        "pdf_size": 2250297,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2383309484414639365&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8b74eea775",
        "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback",
        "site": "https://proceedings.mlr.press/v238/vishwakarma24a.html",
        "author": "Harit Vishwakarma; Heguang Lin; Ramya Korlakai Vinayak",
        "abstract": "Robustness to out-of-distribution (OOD) samples is crucial for the safe deployment of machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96%, as observed in the Open-OOD benchmark. In safety critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \\emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5%$ while maximizing TPR.",
        "bibtex": "@InProceedings{pmlr-v238-vishwakarma24a,\n  title = \t {Taming False Positives in Out-of-Distribution Detection with Human Feedback},\n  author =       {Vishwakarma, Harit and Lin, Heguang and Korlakai Vinayak, Ramya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1486--1494},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/vishwakarma24a/vishwakarma24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/vishwakarma24a.html},\n  abstract = \t {Robustness to out-of-distribution (OOD) samples is crucial for the safe deployment of machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96%, as observed in the Open-OOD benchmark. In safety critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \\emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5%$ while maximizing TPR.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/vishwakarma24a/vishwakarma24a.pdf",
        "supp": "",
        "pdf_size": 13233882,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12670355050863495915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Wisconsin-Madison, WI; University of Pennsylvania, PA; University of Wisconsin-Madison, WI",
        "aff_domain": "cs.wisc.edu;seas.upenn.edu;ece.wisc.edu",
        "email": "cs.wisc.edu;seas.upenn.edu;ece.wisc.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Wisconsin-Madison;University of Pennsylvania",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.upenn.edu",
        "aff_unique_abbr": "UW-Madison;UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "57d75053f4",
        "title": "Taming Nonconvex Stochastic Mirror Descent with General Bregman Divergence",
        "site": "https://proceedings.mlr.press/v238/fatkhullin24a.html",
        "author": "Ilyas Fatkhullin; Niao He",
        "abstract": "This paper revisits the convergence of Stochastic Mirror Descent (SMD) in the contemporary nonconvex optimization setting. Existing results for batch-free nonconvex SMD restrict the choice of the distance generating function (DGF) to be differentiable with Lipschitz continuous gradients, thereby excluding important setups such as Shannon entropy. In this work, we present a new convergence analysis of nonconvex SMD supporting general DGF, that overcomes the above limitations and relies solely on the standard assumptions. Moreover, our convergence is established with respect to the Bregman Forward-Backward envelope, which is a stronger measure than the commonly used squared norm of gradient mapping. We further extend our results to guarantee high probability convergence under sub-Gaussian noise and global convergence under the generalized Bregman Proximal Polyak-{\u0141}ojasiewicz condition. Additionally, we illustrate the advantages of our improved SMD theory in various nonconvex machine learning tasks by harnessing nonsmooth DGFs. Notably, in the context of nonconvex differentially private (DP) learning, our theory yields a simple algorithm with a (nearly) dimension-independent utility bound. For the problem of training linear neural networks, we develop provably convergent stochastic algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-fatkhullin24a,\n  title = \t {Taming Nonconvex Stochastic Mirror Descent with General {B}regman Divergence},\n  author =       {Fatkhullin, Ilyas and He, Niao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3493--3501},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fatkhullin24a/fatkhullin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fatkhullin24a.html},\n  abstract = \t {This paper revisits the convergence of Stochastic Mirror Descent (SMD) in the contemporary nonconvex optimization setting. Existing results for batch-free nonconvex SMD restrict the choice of the distance generating function (DGF) to be differentiable with Lipschitz continuous gradients, thereby excluding important setups such as Shannon entropy. In this work, we present a new convergence analysis of nonconvex SMD supporting general DGF, that overcomes the above limitations and relies solely on the standard assumptions. Moreover, our convergence is established with respect to the Bregman Forward-Backward envelope, which is a stronger measure than the commonly used squared norm of gradient mapping. We further extend our results to guarantee high probability convergence under sub-Gaussian noise and global convergence under the generalized Bregman Proximal Polyak-{\u0141}ojasiewicz condition. Additionally, we illustrate the advantages of our improved SMD theory in various nonconvex machine learning tasks by harnessing nonsmooth DGFs. Notably, in the context of nonconvex differentially private (DP) learning, our theory yields a simple algorithm with a (nearly) dimension-independent utility bound. For the problem of training linear neural networks, we develop provably convergent stochastic algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fatkhullin24a/fatkhullin24a.pdf",
        "supp": "",
        "pdf_size": 590313,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1416800760799908268&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "972cb13cf3",
        "title": "TenGAN: Pure Transformer Encoders Make an Efficient Discrete GAN for De Novo Molecular Generation",
        "site": "https://proceedings.mlr.press/v238/li24d.html",
        "author": "Chen Li; Yoshihiro Yamanishi",
        "abstract": "Deep generative models for de novo molecular generation using discrete data, such as the simplified molecular-input line-entry system (SMILES) strings, have attracted widespread attention in drug design. However, training instability often plagues generative adversarial networks (GANs), leading to problems such as mode collapse and low diversity. This study proposes a pure transformer encoder-based GAN (TenGAN) to solve these issues. The generator and discriminator of TenGAN are variants of the transformer encoders and are combined with reinforcement learning (RL) to generate molecules with the desired chemical properties. Besides, data augmentation of the variant SMILES is leveraged for the TenGAN training to learn the semantics and syntax of SMILES strings. Additionally, we introduce an enhanced variant of TenGAN, named Ten(W)GAN, which incorporates mini-batch discrimination and Wasserstein GAN to improve the ability to generate molecules. The experimental results and ablation studies on the QM9 and ZINC datasets showed that the proposed models generated highly valid and novel molecules with the desired chemical properties in a computationally efficient manner.",
        "bibtex": "@InProceedings{pmlr-v238-li24d,\n  title = \t {{TenGAN}: Pure Transformer Encoders Make an Efficient Discrete {GAN} for De Novo Molecular Generation},\n  author =       {Li, Chen and Yamanishi, Yoshihiro},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {361--369},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24d/li24d.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24d.html},\n  abstract = \t {Deep generative models for de novo molecular generation using discrete data, such as the simplified molecular-input line-entry system (SMILES) strings, have attracted widespread attention in drug design. However, training instability often plagues generative adversarial networks (GANs), leading to problems such as mode collapse and low diversity. This study proposes a pure transformer encoder-based GAN (TenGAN) to solve these issues. The generator and discriminator of TenGAN are variants of the transformer encoders and are combined with reinforcement learning (RL) to generate molecules with the desired chemical properties. Besides, data augmentation of the variant SMILES is leveraged for the TenGAN training to learn the semantics and syntax of SMILES strings. Additionally, we introduce an enhanced variant of TenGAN, named Ten(W)GAN, which incorporates mini-batch discrimination and Wasserstein GAN to improve the ability to generate molecules. The experimental results and ablation studies on the QM9 and ZINC datasets showed that the proposed models generated highly valid and novel molecules with the desired chemical properties in a computationally efficient manner.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24d/li24d.pdf",
        "supp": "",
        "pdf_size": 3549836,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5377406323813607302&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Graduate School of Informatics, Nagoya University, Chikusa, Nagoya, 464-8602, Japan; Graduate School of Informatics, Nagoya University, Chikusa, Nagoya, 464-8602, Japan",
        "aff_domain": "a.mail.nagoya-u.ac.jp;i.nagoya-u.ac.jp",
        "email": "a.mail.nagoya-u.ac.jp;i.nagoya-u.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nagoya University",
        "aff_unique_dep": "Graduate School of Informatics",
        "aff_unique_url": "https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Nagoya U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chikusa, Nagoya",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "ca52e29b0f",
        "title": "Tensor-view Topological Graph Neural Network",
        "site": "https://proceedings.mlr.press/v238/wen24a.html",
        "author": "Tao Wen; Elynn Chen; Yuzhou Chen",
        "abstract": "Graph classification is an important learning task for graph-structured data. Graph neural networks (GNNs) have recently gained growing attention in graph learning and shown significant improvements on many important graph problems. Despite their state-of-the-art performances, existing GNNs only use local information from a very limited neighborhood around each node, suffering from loss of multi-modal information and overheads of excessive computation. To address these issues, we propose a novel Tensor-view Topological Graph Neural Network (TTG-NN), a class of simple yet effective topological deep learning built upon persistent homology, graph convolution, and tensor operations. This new method incorporates tensor learning to simultaneously capture {\\it Tensor-view Topological} (TT), as well as Tensor-view Graph (TG) structural information on both local and global levels. Computationally, to fully exploit graph topology and structure, we propose two flexible TT and TG representation learning modules which disentangles feature tensor aggregation and transformation, and learns to preserve multi-modal structure with less computation. Theoretically, we derive high probability bounds on both the out-of-sample and in-sample mean squared approximation errors for our proposed Tensor Transformation Layer (TTL). Real data experiments show that the proposed TTG-NN outperforms 20 state-of-the-art methods on various graph benchmarks.",
        "bibtex": "@InProceedings{pmlr-v238-wen24a,\n  title = \t {Tensor-view Topological Graph Neural Network},\n  author =       {Wen, Tao and Chen, Elynn and Chen, Yuzhou},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4330--4338},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wen24a/wen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wen24a.html},\n  abstract = \t {Graph classification is an important learning task for graph-structured data. Graph neural networks (GNNs) have recently gained growing attention in graph learning and shown significant improvements on many important graph problems. Despite their state-of-the-art performances, existing GNNs only use local information from a very limited neighborhood around each node, suffering from loss of multi-modal information and overheads of excessive computation. To address these issues, we propose a novel Tensor-view Topological Graph Neural Network (TTG-NN), a class of simple yet effective topological deep learning built upon persistent homology, graph convolution, and tensor operations. This new method incorporates tensor learning to simultaneously capture {\\it Tensor-view Topological} (TT), as well as Tensor-view Graph (TG) structural information on both local and global levels. Computationally, to fully exploit graph topology and structure, we propose two flexible TT and TG representation learning modules which disentangles feature tensor aggregation and transformation, and learns to preserve multi-modal structure with less computation. Theoretically, we derive high probability bounds on both the out-of-sample and in-sample mean squared approximation errors for our proposed Tensor Transformation Layer (TTL). Real data experiments show that the proposed TTG-NN outperforms 20 state-of-the-art methods on various graph benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wen24a/wen24a.pdf",
        "supp": "",
        "pdf_size": 932216,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15031073624507801265&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Center for Data Science, New York University; Stern School of Business, New York University; Computer and Information Sciences, Temple University",
        "aff_domain": "nyu.edu;stern.nyu.edu;temple.edu",
        "email": "nyu.edu;stern.nyu.edu;temple.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "New York University;Temple University",
        "aff_unique_dep": "Center for Data Science;Computer and Information Sciences",
        "aff_unique_url": "https://www.nyu.edu;https://www.temple.edu",
        "aff_unique_abbr": "NYU;Temple",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "82552a6a7a",
        "title": "Testing Generated Distributions in GANs to Penalize Mode Collapse",
        "site": "https://proceedings.mlr.press/v238/gong24a.html",
        "author": "Yanxiang Gong; Zhiwei Xie; Mei Xie; Xin Ma",
        "abstract": "Mode collapse remains the primary unresolved challenge within generative adversarial networks (GANs). In this work, we introduce an innovative approach that supplements the discriminator by additionally enforcing the similarity between the generated and real distributions. We implement a one-sample test on the generated samples and employ the resulting test statistic to penalize deviations from the real distribution. Our method encompasses a practical strategy to estimate distributions, compute the test statistic via a differentiable function, and seamlessly incorporate test outcomes into the training objective. Crucially, our approach preserves the convergence and theoretical integrity of GANs, as the introduced constraint represents a requisite condition for optimizing the generator training objective. Notably, our method circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Empirical evaluations on diverse public datasets validate the efficacy of our proposed approach.",
        "bibtex": "@InProceedings{pmlr-v238-gong24a,\n  title = \t {Testing Generated Distributions in GANs to Penalize Mode Collapse},\n  author =       {Gong, Yanxiang and Xie, Zhiwei and Xie, Mei and Ma, Xin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {442--450},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gong24a/gong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gong24a.html},\n  abstract = \t {Mode collapse remains the primary unresolved challenge within generative adversarial networks (GANs). In this work, we introduce an innovative approach that supplements the discriminator by additionally enforcing the similarity between the generated and real distributions. We implement a one-sample test on the generated samples and employ the resulting test statistic to penalize deviations from the real distribution. Our method encompasses a practical strategy to estimate distributions, compute the test statistic via a differentiable function, and seamlessly incorporate test outcomes into the training objective. Crucially, our approach preserves the convergence and theoretical integrity of GANs, as the introduced constraint represents a requisite condition for optimizing the generator training objective. Notably, our method circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Empirical evaluations on diverse public datasets validate the efficacy of our proposed approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gong24a/gong24a.pdf",
        "supp": "",
        "pdf_size": 25438871,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:85V__2iAzqYJ:scholar.google.com/&scioq=Testing+Generated+Distributions+in+GANs+to+Penalize+Mode+Collapse&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "School of Information and Communiaction Engineering, University of Electronic Science and Technology of China; School of Information and Communiaction Engineering, University of Electronic Science and Technology of China; School of Information and Communiaction Engineering, University of Electronic Science and Technology of China + School of Life Science and Technology, University of Electronic Science and Technology of China; School of Life Science and Technology, University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "email": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "School of Information and Communication Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "16fcbc7cca",
        "title": "Testing exchangeability by pairwise betting",
        "site": "https://proceedings.mlr.press/v238/saha24b.html",
        "author": "Aytijhya Saha; Aaditya Ramdas",
        "abstract": "In this paper, we address the problem of testing exchangeability of a sequence of random variables, $X_1, X_2,\\cdots$. This problem has been studied under the recently popular framework of \\emph{testing by betting}. But the mapping of testing problems to game is not one to one: many games can be designed for the same test. Past work established that it is futile to play single game betting on every observation: test martingales in the data filtration are powerless. Two avenues have been explored to circumvent this impossibility: betting in a reduced filtration (wealth is a test martingale in a coarsened filtration), or playing many games in parallel (wealth is an e-process in the data filtration). The former has proved to be difficult to theoretically analyze, while the latter only works for binary or discrete observation spaces. Here, we introduce a different approach that circumvents both drawbacks. We design a new (yet simple) game in which we observe the data sequence in pairs. Even though betting on individual observations is futile, we show that betting on pairs of observations is not. To elaborate, we prove that our game leads to a nontrivial test martingale, which is interesting because it has been obtained by shrinking the filtration very slightly. We show that our test controls type-1 error despite continuous monitoring, and is consistent for both binary and continuous observations, under a broad class of alternatives. Due to the shrunk filtration, optional stopping is only allowed at even stopping times: a relatively minor price. We provide a variety of simulations that align with our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v238-saha24b,\n  title = \t {Testing exchangeability by pairwise betting},\n  author =       {Saha, Aytijhya and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4915--4923},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/saha24b/saha24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/saha24b.html},\n  abstract = \t {In this paper, we address the problem of testing exchangeability of a sequence of random variables, $X_1, X_2,\\cdots$. This problem has been studied under the recently popular framework of \\emph{testing by betting}. But the mapping of testing problems to game is not one to one: many games can be designed for the same test. Past work established that it is futile to play single game betting on every observation: test martingales in the data filtration are powerless. Two avenues have been explored to circumvent this impossibility: betting in a reduced filtration (wealth is a test martingale in a coarsened filtration), or playing many games in parallel (wealth is an e-process in the data filtration). The former has proved to be difficult to theoretically analyze, while the latter only works for binary or discrete observation spaces. Here, we introduce a different approach that circumvents both drawbacks. We design a new (yet simple) game in which we observe the data sequence in pairs. Even though betting on individual observations is futile, we show that betting on pairs of observations is not. To elaborate, we prove that our game leads to a nontrivial test martingale, which is interesting because it has been obtained by shrinking the filtration very slightly. We show that our test controls type-1 error despite continuous monitoring, and is consistent for both binary and continuous observations, under a broad class of alternatives. Due to the shrunk filtration, optional stopping is only allowed at even stopping times: a relatively minor price. We provide a variety of simulations that align with our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/saha24b/saha24b.pdf",
        "supp": "",
        "pdf_size": 3295937,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17028914082228479321&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Indian Statistical Institute, Kolkata, India; Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "isical.ac.in;cmu.edu",
        "email": "isical.ac.in;cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Indian Statistical Institute;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.isical.ac.in;https://www.cmu.edu",
        "aff_unique_abbr": "ISI;CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Kolkata;Pittsburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "c54d49ab02",
        "title": "The AL$\\ell_0$CORE Tensor Decomposition for Sparse Count Data",
        "site": "https://proceedings.mlr.press/v238/hood24a.html",
        "author": "John Hood; Aaron J. Schein",
        "abstract": "This paper introduces AL$\\ell_0$CORE, a new form of probabilistic non-negative tensor decomposition. AL$\\ell_0$CORE is a Tucker decomposition that constrains the number of non-zero elements (i.e., the $\\ell_0$-norm) of the core tensor to be at most $Q$. While the user dictates the total budget $Q$, the locations and values of the non-zero elements are latent variables allocated across the core tensor during inference. AL$\\ell_0$CORE\u2014i.e., allocated $\\ell_0$-constrained core\u2014thus enjoys both the computational tractability of canonical polyadic (CP) decomposition and the qualitatively appealing latent structure of Tucker. In a suite of real-data experiments, we demonstrate that AL$\\ell_0$CORE typically requires only tiny fractions (e.g., 1%) of the core to achieve the same results as Tucker at a correspondingly small fraction of the cost.",
        "bibtex": "@InProceedings{pmlr-v238-hood24a,\n  title = \t {The {AL$\\ell_0$CORE} Tensor Decomposition for Sparse Count Data},\n  author =       {Hood, John and Schein, Aaron J.},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4654--4662},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hood24a/hood24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hood24a.html},\n  abstract = \t {This paper introduces AL$\\ell_0$CORE, a new form of probabilistic non-negative tensor decomposition. AL$\\ell_0$CORE is a Tucker decomposition that constrains the number of non-zero elements (i.e., the $\\ell_0$-norm) of the core tensor to be at most $Q$. While the user dictates the total budget $Q$, the locations and values of the non-zero elements are latent variables allocated across the core tensor during inference. AL$\\ell_0$CORE\u2014i.e., allocated $\\ell_0$-constrained core\u2014thus enjoys both the computational tractability of canonical polyadic (CP) decomposition and the qualitatively appealing latent structure of Tucker. In a suite of real-data experiments, we demonstrate that AL$\\ell_0$CORE typically requires only tiny fractions (e.g., 1%) of the core to achieve the same results as Tucker at a correspondingly small fraction of the cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hood24a/hood24a.pdf",
        "supp": "",
        "pdf_size": 4012137,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=549749633634967590&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Chicago; University of Chicago",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "90517cd169",
        "title": "The Effective Number of Shared Dimensions Between Paired Datasets",
        "site": "https://proceedings.mlr.press/v238/giaffar24a.html",
        "author": "Hamza Giaffar; Camille Rull\u00e1n Bux\u00f3; Mikio Aoi",
        "abstract": "A number of recent studies have sought to understand the behavior of both artificial and biological neural networks by comparing representations across layers, networks and brain areas. Increasingly prevalent, too, are comparisons across modalities of data, such as neural network activations and training data or behavioral data and neurophysiological recordings. One approach to such comparisons involves measuring the dimensionality of the space shared between the paired data matrices, where dimensionality serves as a proxy for computational or representational complexity. Established approaches, including CCA, can be used to measure the number of shared embedding dimensions, however they do not account for potentially unequal variance along shared dimensions and so cannot measure effective shared dimensionality. We present a candidate measure for shared dimensionality that we call the effective number of shared dimensions (ENSD). The ENSD is an interpretable and computationally efficient model-free measure of shared dimensionality that can be used to probe shared structure in a wide variety of data types. We demonstrate the relative robustness of the ENSD in cases where data is sparse or low rank and illustrate how the ENSD can be applied in a variety of analyses of representational similarities across layers in convolutional neural networks and between brain regions.",
        "bibtex": "@InProceedings{pmlr-v238-giaffar24a,\n  title = \t {The Effective Number of Shared Dimensions Between Paired Datasets},\n  author =       {Giaffar, Hamza and Rull\\'{a}n Bux\\'{o}, Camille and Aoi, Mikio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4249--4257},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/giaffar24a/giaffar24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/giaffar24a.html},\n  abstract = \t {A number of recent studies have sought to understand the behavior of both artificial and biological neural networks by comparing representations across layers, networks and brain areas. Increasingly prevalent, too, are comparisons across modalities of data, such as neural network activations and training data or behavioral data and neurophysiological recordings. One approach to such comparisons involves measuring the dimensionality of the space shared between the paired data matrices, where dimensionality serves as a proxy for computational or representational complexity. Established approaches, including CCA, can be used to measure the number of shared embedding dimensions, however they do not account for potentially unequal variance along shared dimensions and so cannot measure effective shared dimensionality. We present a candidate measure for shared dimensionality that we call the effective number of shared dimensions (ENSD). The ENSD is an interpretable and computationally efficient model-free measure of shared dimensionality that can be used to probe shared structure in a wide variety of data types. We demonstrate the relative robustness of the ENSD in cases where data is sparse or low rank and illustrate how the ENSD can be applied in a variety of analyses of representational similarities across layers in convolutional neural networks and between brain regions.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/giaffar24a/giaffar24a.pdf",
        "supp": "",
        "pdf_size": 7305112,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5265727498527874797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of California, San Diego; New York University; University of California, San Diego",
        "aff_domain": "ucsd.edu;nyu.edu;ucsd.edu",
        "email": "ucsd.edu;nyu.edu;ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, San Diego;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsd.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UCSD;NYU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f7af292d36",
        "title": "The Galerkin method beats Graph-Based Approaches for Spectral Algorithms",
        "site": "https://proceedings.mlr.press/v238/cabannes24a.html",
        "author": "Vivien A. Cabannes; Francis Bach",
        "abstract": "Historically, the machine learning community has derived spectral decompositions from graph-based approaches. We break with this approach and prove the statistical and computational superiority of the Galerkin method, which consists in restricting the study to a small set of test functions. In particular, we introduce implementation tricks to deal with differential operators in large dimensions with structured kernels. Finally, we extend on the core principles beyond our approach to apply them to non-linear spaces of functions, such as the ones parameterized by deep neural networks, through loss-based optimization procedures.",
        "bibtex": "@InProceedings{pmlr-v238-cabannes24a,\n  title = \t {The {G}alerkin method beats Graph-Based Approaches for Spectral Algorithms},\n  author =       {Cabannes, Vivien A. and Bach, Francis},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {451--459},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cabannes24a/cabannes24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cabannes24a.html},\n  abstract = \t {Historically, the machine learning community has derived spectral decompositions from graph-based approaches. We break with this approach and prove the statistical and computational superiority of the Galerkin method, which consists in restricting the study to a small set of test functions. In particular, we introduce implementation tricks to deal with differential operators in large dimensions with structured kernels. Finally, we extend on the core principles beyond our approach to apply them to non-linear spaces of functions, such as the ones parameterized by deep neural networks, through loss-based optimization procedures.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cabannes24a/cabannes24a.pdf",
        "supp": "",
        "pdf_size": 1416419,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9074917586543661158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Meta AI; INRIA, Ecole Normale Sup\u00e9rieure",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Meta;INRIA",
        "aff_unique_dep": "Meta AI;",
        "aff_unique_url": "https://meta.com;https://www.inria.fr",
        "aff_unique_abbr": "Meta;INRIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "54620fe355",
        "title": "The Relative Gaussian Mechanism and its Application to Private Gradient Descent",
        "site": "https://proceedings.mlr.press/v238/hendrikx24a.html",
        "author": "Hadrien Hendrikx; Paul Mangold; Aur\u00e9lien Bellet",
        "abstract": "The Gaussian Mechanism (GM), which consists in adding Gaussian noise to a vector-valued query before releasing it, is a standard privacy protection mechanism. In particular, given that the query respects some L2 sensitivity property (the L2 distance between outputs on any two neighboring inputs is bounded), GM guarantees R\u00e9nyi Differential Privacy (RDP). Unfortunately, precisely bounding the L2 sensitivity can be hard, thus leading to loose privacy bounds. In this work, we consider a Relative L2 sensitivity assumption, in which the bound on the distance between two query outputs may also depend on their norm. Leveraging this assumption, we introduce the Relative Gaussian Mechanism (RGM), in which the variance of the noise depends on the norm of the output. We prove tight bounds on the RDP parameters under relative L2 sensitivity, and characterize the privacy loss incurred by using output-dependent noise. In particular, we show that RGM naturally adapts to a latent variable that would control the norm of the output. Finally, we instantiate our framework to show tight guarantees for Private Gradient Descent, a problem that naturally fits our relative L2 sensitivity assumption.",
        "bibtex": "@InProceedings{pmlr-v238-hendrikx24a,\n  title = \t {The Relative {G}aussian Mechanism and its Application to Private Gradient Descent},\n  author =       {Hendrikx, Hadrien and Mangold, Paul and Bellet, Aur\\'{e}lien},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3079--3087},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/hendrikx24a/hendrikx24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/hendrikx24a.html},\n  abstract = \t {The Gaussian Mechanism (GM), which consists in adding Gaussian noise to a vector-valued query before releasing it, is a standard privacy protection mechanism. In particular, given that the query respects some L2 sensitivity property (the L2 distance between outputs on any two neighboring inputs is bounded), GM guarantees R\u00e9nyi Differential Privacy (RDP). Unfortunately, precisely bounding the L2 sensitivity can be hard, thus leading to loose privacy bounds. In this work, we consider a Relative L2 sensitivity assumption, in which the bound on the distance between two query outputs may also depend on their norm. Leveraging this assumption, we introduce the Relative Gaussian Mechanism (RGM), in which the variance of the noise depends on the norm of the output. We prove tight bounds on the RDP parameters under relative L2 sensitivity, and characterize the privacy loss incurred by using output-dependent noise. In particular, we show that RGM naturally adapts to a latent variable that would control the norm of the output. Finally, we instantiate our framework to show tight guarantees for Private Gradient Descent, a problem that naturally fits our relative L2 sensitivity assumption.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/hendrikx24a/hendrikx24a.pdf",
        "supp": "",
        "pdf_size": 718370,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16892629415527468870&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Centre Inria de l\u2019Univ. Grenoble Alpes; CMAP, UMR 7641, \u00c9cole Polytechnique; Inria, Universit\u00e9 de Montpellier, France",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "INRIA;Ecole Polytechnique",
        "aff_unique_dep": ";CMAP, UMR 7641",
        "aff_unique_url": "https://www.inria.fr;https://www.ensae.fr/",
        "aff_unique_abbr": "Inria;\u00c9cole Polytechnique",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Grenoble;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "4fc0840645",
        "title": "The Risks of Recourse in Binary Classification",
        "site": "https://proceedings.mlr.press/v238/fokkema24a.html",
        "author": "Hidde Fokkema; Damien Garreau; Tim van Erven",
        "abstract": "Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e., expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level. We confirm our theoretical findings in experiments on simulated and real-world data. All in all, we conclude that the current concept of algorithmic recourse is not reliably beneficial, and therefore requires rethinking.",
        "bibtex": "@InProceedings{pmlr-v238-fokkema24a,\n  title = \t {The Risks of Recourse in Binary Classification},\n  author =       {Fokkema, Hidde and Garreau, Damien and van Erven, Tim},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {550--558},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/fokkema24a/fokkema24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/fokkema24a.html},\n  abstract = \t {Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e., expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level. We confirm our theoretical findings in experiments on simulated and real-world data. All in all, we conclude that the current concept of algorithmic recourse is not reliably beneficial, and therefore requires rethinking.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/fokkema24a/fokkema24a.pdf",
        "supp": "",
        "pdf_size": 3432225,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4033648536129988036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Korteweg-de Vries Institute for Mathematics, University of Amsterdam; CAIDAS, University of W\u00fcrzburg; Korteweg-de Vries Institute for Mathematics, University of Amsterdam",
        "aff_domain": "uva.nl;uni-wuerzburg.de;timvanerven.nl",
        "email": "uva.nl;uni-wuerzburg.de;timvanerven.nl",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Amsterdam;University of W\u00fcrzburg",
        "aff_unique_dep": "Korteweg-de Vries Institute for Mathematics;CAIDAS",
        "aff_unique_url": "https://www.uva.nl;https://www.uni-wuerzburg.de",
        "aff_unique_abbr": "UvA;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;Germany"
    },
    {
        "id": "00273b2ce1",
        "title": "The Solution Path of SLOPE",
        "site": "https://proceedings.mlr.press/v238/dupuis24a.html",
        "author": "Xavier Dupuis; Patrick Tardivel",
        "abstract": "The SLOPE estimator has the particularity of having null components (sparsity) and components that are equal in absolute value (clustering). The number of clusters depends on the regularization parameter of the estimator. This parameter can be chosen as a trade-off between interpretability (with a small number of clusters) and accuracy (with a small mean squared error or a small prediction error). Finding such a compromise requires to compute the solution path, that is the function mapping the regularization parameter to the estimator. We provide in this article an algorithm to compute the solution path of SLOPE and show how it can be used to adjust the regularization parameter.",
        "bibtex": "@InProceedings{pmlr-v238-dupuis24a,\n  title = \t {The Solution Path of SLOPE},\n  author =       {Dupuis, Xavier and Tardivel, Patrick},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {775--783},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/dupuis24a/dupuis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/dupuis24a.html},\n  abstract = \t {The SLOPE estimator has the particularity of having null components (sparsity) and components that are equal in absolute value (clustering). The number of clusters depends on the regularization parameter of the estimator. This parameter can be chosen as a trade-off between interpretability (with a small number of clusters) and accuracy (with a small mean squared error or a small prediction error). Finding such a compromise requires to compute the solution path, that is the function mapping the regularization parameter to the estimator. We provide in this article an algorithm to compute the solution path of SLOPE and show how it can be used to adjust the regularization parameter.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/dupuis24a/dupuis24a.pdf",
        "supp": "",
        "pdf_size": 480470,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3230813989709772063&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII",
        "gs_version_total": 6,
        "aff": "Institut de Math\u00e9matiques de Bourgogne, UMR 5584 CNRS, Universit\u00e9 de Bourgogne, F-21000 Dijon, France; Institut de Math\u00e9matiques de Bourgogne, UMR 5584 CNRS, Universit\u00e9 de Bourgogne, F-21000 Dijon, France",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 de Bourgogne",
        "aff_unique_dep": "Institut de Math\u00e9matiques de Bourgogne",
        "aff_unique_url": "https://www.ubourgogne.fr",
        "aff_unique_abbr": "UB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Dijon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "732e050a53",
        "title": "The effect of Leaky ReLUs on the training and generalization of overparameterized networks",
        "site": "https://proceedings.mlr.press/v238/guo24c.html",
        "author": "Yinglong Guo; Shaohan Li; Gilad Lerman",
        "abstract": "We investigate the training and generalization errors of overparameterized neural networks (NNs) with a wide class of leaky rectified linear unit (ReLU) functions. More specifically, we carefully upper bound both the convergence rate of the training error and the generalization error of such NNs and investigate the dependence of these bounds on the Leaky ReLU parameter, $\\alpha$. We show that $\\alpha =-1$, which corresponds to the absolute value activation function, is optimal for the training error bound. Furthermore, in special settings, it is also optimal for the generalization error bound. Numerical experiments empirically support the practical choices guided by the theory.",
        "bibtex": "@InProceedings{pmlr-v238-guo24c,\n  title = \t {The effect of Leaky {ReLUs} on the training and generalization of overparameterized networks},\n  author =       {Guo, Yinglong and Li, Shaohan and Lerman, Gilad},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4393--4401},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/guo24c/guo24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/guo24c.html},\n  abstract = \t {We investigate the training and generalization errors of overparameterized neural networks (NNs) with a wide class of leaky rectified linear unit (ReLU) functions. More specifically, we carefully upper bound both the convergence rate of the training error and the generalization error of such NNs and investigate the dependence of these bounds on the Leaky ReLU parameter, $\\alpha$. We show that $\\alpha =-1$, which corresponds to the absolute value activation function, is optimal for the training error bound. Furthermore, in special settings, it is also optimal for the generalization error bound. Numerical experiments empirically support the practical choices guided by the theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/guo24c/guo24c.pdf",
        "supp": "",
        "pdf_size": 13642544,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9291334034540270774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c760b207a",
        "title": "The sample complexity of ERMs in stochastic convex optimization",
        "site": "https://proceedings.mlr.press/v238/carmon24a.html",
        "author": "Daniel Carmon; Amir Yehudayoff; Roi Livni",
        "abstract": "Stochastic convex optimization is one of the most well-studied models for learning in modern machine learning. Nevertheless, a central fundamental question in this setup remained unresolved: how many data points must be observed so that any empirical risk minimizer (ERM) shows good performance on the true population? This question was proposed by Feldman who proved that $\\Omega(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2} )$ data points are necessary (where $d$ is the dimension and $\\epsilon > 0$ the accuracy parameter). Proving an $\\omega(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2})$ lower bound was left as an open problem. In this work we show that in fact $\\tilde{O}(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2})$ data points are also sufficient. This settles the question and yields a new separation between ERMs and uniform convergence. This sample complexity holds for the classical setup of learning bounded convex Lipschitz functions over the Euclidean unit ball. We further generalize the result and show that a similar upper bound holds for all symmetric convex bodies. The general bound is composed of two terms: (i) a term of the form $\\tilde{O}(\\frac{d}{\\epsilon})$ with an inverse-linear dependence on the accuracy parameter, and (ii) a term that depends on the statistical complexity of the class of linear functions (captured by the Rademacher complexity). The proof builds a mechanism for controlling the behavior of stochastic convex optimization problems.",
        "bibtex": "@InProceedings{pmlr-v238-carmon24a,\n  title = \t {The sample complexity of {ERM}s in stochastic convex optimization},\n  author =       {Carmon, Daniel and Yehudayoff, Amir and Livni, Roi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3799--3807},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/carmon24a/carmon24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/carmon24a.html},\n  abstract = \t {Stochastic convex optimization is one of the most well-studied models for learning in modern machine learning. Nevertheless, a central fundamental question in this setup remained unresolved: how many data points must be observed so that any empirical risk minimizer (ERM) shows good performance on the true population? This question was proposed by Feldman who proved that $\\Omega(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2} )$ data points are necessary (where $d$ is the dimension and $\\epsilon > 0$ the accuracy parameter). Proving an $\\omega(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2})$ lower bound was left as an open problem. In this work we show that in fact $\\tilde{O}(\\frac{d}{\\epsilon} + \\frac{1}{\\epsilon^2})$ data points are also sufficient. This settles the question and yields a new separation between ERMs and uniform convergence. This sample complexity holds for the classical setup of learning bounded convex Lipschitz functions over the Euclidean unit ball. We further generalize the result and show that a similar upper bound holds for all symmetric convex bodies. The general bound is composed of two terms: (i) a term of the form $\\tilde{O}(\\frac{d}{\\epsilon})$ with an inverse-linear dependence on the accuracy parameter, and (ii) a term that depends on the statistical complexity of the class of linear functions (captured by the Rademacher complexity). The proof builds a mechanism for controlling the behavior of stochastic convex optimization problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/carmon24a/carmon24a.pdf",
        "supp": "",
        "pdf_size": 1045761,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=447088260057695493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8c9ec092bd",
        "title": "Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention",
        "site": "https://proceedings.mlr.press/v238/mao24a.html",
        "author": "Anqi Mao; Mehryar Mohri; Yutao Zhong",
        "abstract": "Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losses and two-stage abstention algorithms. Our results also show that the relative performance of the state-of-the-art score-based surrogate losses can vary across datasets.",
        "bibtex": "@InProceedings{pmlr-v238-mao24a,\n  title = \t {Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention},\n  author =       {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4753--4761},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/mao24a/mao24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/mao24a.html},\n  abstract = \t {Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losses and two-stage abstention algorithms. Our results also show that the relative performance of the state-of-the-art score-based surrogate losses can vary across datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/mao24a/mao24a.pdf",
        "supp": "",
        "pdf_size": 529202,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11497831969363757812&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a1598c43b6",
        "title": "Theory-guided Message Passing Neural Network for Probabilistic Inference",
        "site": "https://proceedings.mlr.press/v238/cui24a.html",
        "author": "Zijun Cui; Hanjing Wang; Tian Gao; Kartik Talamadupula; Qiang Ji",
        "abstract": "Probabilistic inference can be tackled by minimizing a variational free energy through message passing. To improve performance, neural networks are adopted for message computation. Neural message learning is heuristic and requires strong guidance to perform well. In this work, we propose a {\\em theory-guided message passing neural network} (TMPNN) for probabilistic inference. Inspired by existing work, we consider a generalized Bethe free energy which allows for a learnable variational assumption. Instead of using a black-box neural network for message computation, we utilize a general message equation and introduce a symbolic message function with semantically meaningful parameters. The analytically derived symbolic message function is seamlessly integrated into the MPNN framework, giving rise to the proposed TMPNN. TMPNN is trained using algorithmic supervision without requiring exact inference results. Leveraging the theory-guided symbolic function, TMPNN offers strengthened theoretical guarantees compared to conventional heuristic neural models. It presents a novel contribution by demonstrating its applicability to both MAP and marginal inference tasks, outperforming SOTAs in both cases. Furthermore, TMPNN provides improved generalizability across various graph structures and exhibits enhanced data efficiency.",
        "bibtex": "@InProceedings{pmlr-v238-cui24a,\n  title = \t {Theory-guided Message Passing Neural Network for Probabilistic Inference},\n  author =       {Cui, Zijun and Wang, Hanjing and Gao, Tian and Talamadupula, Kartik and Ji, Qiang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {667--675},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cui24a/cui24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cui24a.html},\n  abstract = \t {Probabilistic inference can be tackled by minimizing a variational free energy through message passing. To improve performance, neural networks are adopted for message computation. Neural message learning is heuristic and requires strong guidance to perform well. In this work, we propose a {\\em theory-guided message passing neural network} (TMPNN) for probabilistic inference. Inspired by existing work, we consider a generalized Bethe free energy which allows for a learnable variational assumption. Instead of using a black-box neural network for message computation, we utilize a general message equation and introduce a symbolic message function with semantically meaningful parameters. The analytically derived symbolic message function is seamlessly integrated into the MPNN framework, giving rise to the proposed TMPNN. TMPNN is trained using algorithmic supervision without requiring exact inference results. Leveraging the theory-guided symbolic function, TMPNN offers strengthened theoretical guarantees compared to conventional heuristic neural models. It presents a novel contribution by demonstrating its applicability to both MAP and marginal inference tasks, outperforming SOTAs in both cases. Furthermore, TMPNN provides improved generalizability across various graph structures and exhibits enhanced data efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cui24a/cui24a.pdf",
        "supp": "",
        "pdf_size": 1001339,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:2Om7Q0cY3o0J:scholar.google.com/&scioq=Theory-guided+Message+Passing+Neural+Network+for+Probabilistic+Inference&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f8c449952e",
        "title": "Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources",
        "site": "https://proceedings.mlr.press/v238/deb24a.html",
        "author": "Rohan Deb; Aadirupa Saha; Arindam Banerjee",
        "abstract": "We consider the problem of reward maximization in the dueling bandit setup along with constraints on resource consumption. As in the classic dueling bandits, at each round the learner has to choose a pair of items from a set of $K$ items and observe a relative feedback for the current pair. Additionally, for both items, the learner also observes a vector of resource consumptions. The objective of the learner is to maximize the cumulative reward, while ensuring that the total consumption of any resource is within the allocated budget. We show that due to the relative nature of the feedback, the problem is more difficult than its bandit counterpart and that without further assumptions the problem is not learnable from a regret minimization perspective. Thereafter, by exploiting assumptions on the available budget, we provide an EXP3 based dueling algorithm that also considers the associated consumptions and show that it achieves an $\\tilde{\\mathcal{O}}\\left(\\big({\\frac{OPT^{(b)}}{B}}+1\\big)K^{1/3}T^{2/3}\\right)$ regret, where $OPT^{(b)}$ is the optimal value and $B$ is the available budget. Finally, we provide numerical simulations to demonstrate the efficacy of our proposed method.",
        "bibtex": "@InProceedings{pmlr-v238-deb24a,\n  title = \t {Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources},\n  author =       {Deb, Rohan and Saha, Aadirupa and Banerjee, Arindam},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4546--4554},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/deb24a/deb24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/deb24a.html},\n  abstract = \t {We consider the problem of reward maximization in the dueling bandit setup along with constraints on resource consumption. As in the classic dueling bandits, at each round the learner has to choose a pair of items from a set of $K$ items and observe a relative feedback for the current pair. Additionally, for both items, the learner also observes a vector of resource consumptions. The objective of the learner is to maximize the cumulative reward, while ensuring that the total consumption of any resource is within the allocated budget. We show that due to the relative nature of the feedback, the problem is more difficult than its bandit counterpart and that without further assumptions the problem is not learnable from a regret minimization perspective. Thereafter, by exploiting assumptions on the available budget, we provide an EXP3 based dueling algorithm that also considers the associated consumptions and show that it achieves an $\\tilde{\\mathcal{O}}\\left(\\big({\\frac{OPT^{(b)}}{B}}+1\\big)K^{1/3}T^{2/3}\\right)$ regret, where $OPT^{(b)}$ is the optimal value and $B$ is the available budget. Finally, we provide numerical simulations to demonstrate the efficacy of our proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/deb24a/deb24a.pdf",
        "supp": "",
        "pdf_size": 4830601,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5025975675323835164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Illinois, Urbana Champaign; Apple; University of Illinois, Urbana Champaign",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Apple",
        "aff_unique_dep": ";Apple Inc.",
        "aff_unique_url": "https://illinois.edu;https://www.apple.com",
        "aff_unique_abbr": "UIUC;Apple",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "377262f5cd",
        "title": "Think Global, Adapt Local: Learning Locally Adaptive K-Nearest Neighbor Kernel Density Estimators",
        "site": "https://proceedings.mlr.press/v238/olsen24a.html",
        "author": "Kenny Olsen; Rasmus M. Hoeegh Lindrup; Morten M\u00f8rup",
        "abstract": "Kernel density estimation (KDE) is a powerful technique for non-parametric density estimation, yet practical use of KDE-based methods remains limited by insufficient representational flexibility, especially for higher-dimensional data. Contrary to KDE, K-nearest neighbor (KNN) density estimation procedures locally adapt the density based on the K-nearest neighborhood, but unfortunately only provide asymptotically correct density estimates. We present the KNN-KDE method introducing observation-specific kernels for KDE that are locally adapted through priors defined by the covariance of the K-nearest neighborhood, forming a fully Bayesian model with exact density estimates. We further derive a scalable inference procedure that infers parameters through variational inference by optimizing the predictive likelihood exploiting sparsity, batched optimization, and parallel computation for massive inference speedups. We find that KNN-KDE provides valid density estimates superior to conventional KDE and KNN density estimation on both synthetic and real data sets. We further observe that the bayesian KNN-KDE even outperforms recent neural density estimation procedures on two of the five considered real data sets. The KNN-KDE unifies conventional kernel and KNN density estimation providing a scalable, generic and accurate framework for density estimation.",
        "bibtex": "@InProceedings{pmlr-v238-olsen24a,\n  title = \t {Think Global, Adapt Local: Learning Locally Adaptive {K}-Nearest Neighbor Kernel Density Estimators},\n  author =       {Olsen, Kenny and M. Hoeegh Lindrup, Rasmus and M\\o{}rup, Morten},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4114--4122},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/olsen24a/olsen24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/olsen24a.html},\n  abstract = \t {Kernel density estimation (KDE) is a powerful technique for non-parametric density estimation, yet practical use of KDE-based methods remains limited by insufficient representational flexibility, especially for higher-dimensional data. Contrary to KDE, K-nearest neighbor (KNN) density estimation procedures locally adapt the density based on the K-nearest neighborhood, but unfortunately only provide asymptotically correct density estimates. We present the KNN-KDE method introducing observation-specific kernels for KDE that are locally adapted through priors defined by the covariance of the K-nearest neighborhood, forming a fully Bayesian model with exact density estimates. We further derive a scalable inference procedure that infers parameters through variational inference by optimizing the predictive likelihood exploiting sparsity, batched optimization, and parallel computation for massive inference speedups. We find that KNN-KDE provides valid density estimates superior to conventional KDE and KNN density estimation on both synthetic and real data sets. We further observe that the bayesian KNN-KDE even outperforms recent neural density estimation procedures on two of the five considered real data sets. The KNN-KDE unifies conventional kernel and KNN density estimation providing a scalable, generic and accurate framework for density estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/olsen24a/olsen24a.pdf",
        "supp": "",
        "pdf_size": 3282068,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15273345868757776309&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "48d3a39181",
        "title": "Thompson Sampling Itself is Differentially Private",
        "site": "https://proceedings.mlr.press/v238/ou24a.html",
        "author": "Tingting Ou; Rachel Cummings; Marco Avella Medina",
        "abstract": "In this work we first show that the classical Thompson sampling algorithm for multi-arm bandits is differentially private as-is, without any modification. We provide per-round privacy guarantees as a function of problem parameters and show composition over $T$ rounds; since the algorithm is unchanged, existing $O(\\sqrt{NT\\log N})$ regret bounds still hold and there is no loss in performance due to privacy. We then show that simple modifications \u2013 such as pre-pulling all arms a fixed number of times, increasing the sampling variance \u2013 can provide tighter privacy guarantees. We again provide privacy guarantees that now depend on the new parameters introduced in the modification, which allows the analyst to tune the privacy guarantee as desired. We also provide a novel regret analysis for this new algorithm, and show how the new parameters also impact expected regret. Finally, we empirically validate and illustrate our theoretical findings in two parameter regimes and demonstrate that tuning the new parameters substantially improve the privacy-regret tradeoff.",
        "bibtex": "@InProceedings{pmlr-v238-ou24a,\n  title = \t {Thompson Sampling Itself is Differentially Private},\n  author =       {Ou, Tingting and Cummings, Rachel and Avella Medina, Marco},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1576--1584},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ou24a/ou24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ou24a.html},\n  abstract = \t {In this work we first show that the classical Thompson sampling algorithm for multi-arm bandits is differentially private as-is, without any modification. We provide per-round privacy guarantees as a function of problem parameters and show composition over $T$ rounds; since the algorithm is unchanged, existing $O(\\sqrt{NT\\log N})$ regret bounds still hold and there is no loss in performance due to privacy. We then show that simple modifications \u2013 such as pre-pulling all arms a fixed number of times, increasing the sampling variance \u2013 can provide tighter privacy guarantees. We again provide privacy guarantees that now depend on the new parameters introduced in the modification, which allows the analyst to tune the privacy guarantee as desired. We also provide a novel regret analysis for this new algorithm, and show how the new parameters also impact expected regret. Finally, we empirically validate and illustrate our theoretical findings in two parameter regimes and demonstrate that tuning the new parameters substantially improve the privacy-regret tradeoff.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ou24a/ou24a.pdf",
        "supp": "",
        "pdf_size": 721748,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17347997663986552232&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6fe954cb03",
        "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
        "site": "https://proceedings.mlr.press/v238/batten24a.html",
        "author": "Ben Batten; Mehran Hosseini; Alessio Lomuscio",
        "abstract": "We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters\u2019 space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters\u2019 space for safe weights by using iterative expansion and the network\u2019s gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.",
        "bibtex": "@InProceedings{pmlr-v238-batten24a,\n  title = \t {Tight Verification of Probabilistic Robustness in {B}ayesian Neural Networks},\n  author =       {Batten, Ben and Hosseini, Mehran and Lomuscio, Alessio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4906--4914},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/batten24a/batten24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/batten24a.html},\n  abstract = \t {We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters\u2019 space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters\u2019 space for safe weights by using iterative expansion and the network\u2019s gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/batten24a/batten24a.pdf",
        "supp": "",
        "pdf_size": 583634,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14111065636771536214&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Imperial College London; King\u2019s College London; Imperial College London",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "https://github.com/benbatten/TightVerificationOfProbabilisticRobustnessInBNNs",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Imperial College London;King's College London",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "ICL;KCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "79ea812165",
        "title": "Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model",
        "site": "https://proceedings.mlr.press/v238/nakis24a.html",
        "author": "Nikolaos Nakis; Abdulkadir Celikkanat; Louis Boucherie; Sune Lehmann; Morten M\u00f8rup",
        "abstract": "Understanding the structure and dynamics of scientific research, i.e., the science of science (SciSci), has become an important area of research in order to address imminent questions including how scholars interact to advance science, how disciplines are related and evolve, and how research impact can be quantified and predicted. Central to the study of SciSci has been the analysis of citation networks. Here, two prominent modeling methodologies have been employed: one is to assess the citation impact dynamics of papers using parametric distributions, and the other is to embed the citation networks in a latent space optimal for characterizing the static relations between papers in terms of their citations. Interestingly, citation networks are a prominent example of single-event dynamic networks, i.e., networks for which each dyad only has a single event (i.e., the point in time of citation). We presently propose a novel likelihood function for the characterization of such single-event networks. Using this likelihood, we propose the Dynamic Impact Single-Event Embedding model (DISEE). The DISEE model characterizes the scientific interactions in terms of a latent distance model in which random effects account for citation heterogeneity while the time-varying impact is characterized using existing parametric representations for assessment of dynamic impact. We highlight the proposed approach on several real citation networks finding that DISEE well reconciles static latent distance network embedding approaches with classical dynamic impact assessments.",
        "bibtex": "@InProceedings{pmlr-v238-nakis24a,\n  title = \t {Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model},\n  author =       {Nakis, Nikolaos and Celikkanat, Abdulkadir and Boucherie, Louis and Lehmann, Sune and M\\o{}rup, Morten},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1882--1890},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nakis24a/nakis24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nakis24a.html},\n  abstract = \t {Understanding the structure and dynamics of scientific research, i.e., the science of science (SciSci), has become an important area of research in order to address imminent questions including how scholars interact to advance science, how disciplines are related and evolve, and how research impact can be quantified and predicted. Central to the study of SciSci has been the analysis of citation networks. Here, two prominent modeling methodologies have been employed: one is to assess the citation impact dynamics of papers using parametric distributions, and the other is to embed the citation networks in a latent space optimal for characterizing the static relations between papers in terms of their citations. Interestingly, citation networks are a prominent example of single-event dynamic networks, i.e., networks for which each dyad only has a single event (i.e., the point in time of citation). We presently propose a novel likelihood function for the characterization of such single-event networks. Using this likelihood, we propose the Dynamic Impact Single-Event Embedding model (DISEE). The DISEE model characterizes the scientific interactions in terms of a latent distance model in which random effects account for citation heterogeneity while the time-varying impact is characterized using existing parametric representations for assessment of dynamic impact. We highlight the proposed approach on several real citation networks finding that DISEE well reconciles static latent distance network embedding approaches with classical dynamic impact assessments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nakis24a/nakis24a.pdf",
        "supp": "",
        "pdf_size": 21583035,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:iHjoWzvvb-4J:scholar.google.com/&scioq=Time+to+Cite:+Modeling+Citation+Networks+using+the+Dynamic+Impact+Single-Event+Embedding+Model&hl=en&as_sdt=0,5",
        "gs_version_total": 8,
        "aff": "Technical University of Denmark; Technical University of Denmark; Technical University of Denmark; Technical University of Denmark; Technical University of Denmark",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tek.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "81b570eb19",
        "title": "Timing as an Action: Learning When to Observe and Act",
        "site": "https://proceedings.mlr.press/v238/zhou24c.html",
        "author": "Helen Zhou; Audrey Huang; Kamyar Azizzadenesheli; David Childers; Zachary Lipton",
        "abstract": "In standard reinforcement learning setups, the agent receives observations and performs actions at evenly spaced intervals. However, in many real-world settings, observations are expensive, forcing agents to commit to courses of action for designated periods of time. Consider that doctors, after each visit, typically set not only a treatment plan but also a follow-up date at which that plan might be revised. In this work, we formalize the setup of timing-as-an-action. Through theoretical analysis in the tabular setting, we show that while the choice of delay intervals could be naively folded in as part of a composite action, these actions have a special structure and handling them intelligently yields statistical advantages. Taking a model-based perspective, these gains owe to the fact that delay actions do not add any parameters to the underlying model. For model estimation, we provide provable sample-efficiency improvements, and our experiments demonstrate empirical improvements in both healthcare simulators and classical reinforcement learning environments.",
        "bibtex": "@InProceedings{pmlr-v238-zhou24c,\n  title = \t {Timing as an Action: Learning When to Observe and Act},\n  author =       {Zhou, Helen and Huang, Audrey and Azizzadenesheli, Kamyar and Childers, David and Lipton, Zachary},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3979--3987},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/zhou24c/zhou24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/zhou24c.html},\n  abstract = \t {In standard reinforcement learning setups, the agent receives observations and performs actions at evenly spaced intervals. However, in many real-world settings, observations are expensive, forcing agents to commit to courses of action for designated periods of time. Consider that doctors, after each visit, typically set not only a treatment plan but also a follow-up date at which that plan might be revised. In this work, we formalize the setup of timing-as-an-action. Through theoretical analysis in the tabular setting, we show that while the choice of delay intervals could be naively folded in as part of a composite action, these actions have a special structure and handling them intelligently yields statistical advantages. Taking a model-based perspective, these gains owe to the fact that delay actions do not add any parameters to the underlying model. For model estimation, we provide provable sample-efficiency improvements, and our experiments demonstrate empirical improvements in both healthcare simulators and classical reinforcement learning environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/zhou24c/zhou24c.pdf",
        "supp": "",
        "pdf_size": 4339649,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14353773391429662224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "CMU; UIUC; NVIDIA; CMU; CMU",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Illinois Urbana-Champaign;NVIDIA",
        "aff_unique_dep": ";;NVIDIA Corporation",
        "aff_unique_url": "https://www.cmu.edu;https://www illinois.edu;https://www.nvidia.com",
        "aff_unique_abbr": "CMU;UIUC;NVIDIA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "be7115e415",
        "title": "To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models",
        "site": "https://proceedings.mlr.press/v238/cousins24a.html",
        "author": "Cyrus Cousins; I. Elizabeth Kumar; Suresh Venkatasubramanian",
        "abstract": "In fair machine learning, one source of performance disparities between groups is overfitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a na\u00efve method, as expected by theory, with particularly significant improvement for smaller group sizes.",
        "bibtex": "@InProceedings{pmlr-v238-cousins24a,\n  title = \t {To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models},\n  author =       {Cousins, Cyrus and Elizabeth Kumar, I. and Venkatasubramanian, Suresh},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4573--4581},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/cousins24a/cousins24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/cousins24a.html},\n  abstract = \t {In fair machine learning, one source of performance disparities between groups is overfitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a na\u00efve method, as expected by theory, with particularly significant improvement for smaller group sizes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/cousins24a/cousins24a.pdf",
        "supp": "",
        "pdf_size": 1051991,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3451721434346262502&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1cd9ee3d52",
        "title": "Towards Achieving Sub-linear Regret and Hard Constraint Violation in Model-free RL",
        "site": "https://proceedings.mlr.press/v238/ghosh24a.html",
        "author": "Arnob Ghosh; Xingyu Zhou; Ness Shroff",
        "abstract": "We study the constrained Markov decision processes (CMDPs), in which an agent aims to maximize the expected cumulative reward subject to a constraint on the expected total value of a utility function. Existing approaches have primarily focused on \\emph{soft} constraint violation, which allows compensation across episodes, making it easier to satisfy the constraints. In contrast, we consider a stronger \\emph{hard} constraint violation metric, where only positive constraint violations are accumulated. Our main result is the development of the \\emph{first model-free}, \\emph{simulator-free} algorithm that achieves a sub-linear regret and a sub-linear hard constraint violation simultaneously, even in \\emph{large-scale} systems. In particular, we show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ regret and $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ hard constraint violation bounds can be achieved, where $K$ is the number of episodes, $d$ is the dimension of the feature mapping, $H$ is the length of the episode. Our results are achieved via novel adaptations of the primal-dual LSVI-UCB algorithm, i.e., it searches for the dual variable that balances between regret and constraint violation within every episode, rather than updating it at the end of each episode. This turns out to be crucial for our theoretical guarantees when dealing with hard constraint violations.",
        "bibtex": "@InProceedings{pmlr-v238-ghosh24a,\n  title = \t {Towards Achieving Sub-linear Regret and Hard Constraint Violation in Model-free {RL}},\n  author =       {Ghosh, Arnob and Zhou, Xingyu and Shroff, Ness},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1054--1062},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ghosh24a/ghosh24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ghosh24a.html},\n  abstract = \t {We study the constrained Markov decision processes (CMDPs), in which an agent aims to maximize the expected cumulative reward subject to a constraint on the expected total value of a utility function. Existing approaches have primarily focused on \\emph{soft} constraint violation, which allows compensation across episodes, making it easier to satisfy the constraints. In contrast, we consider a stronger \\emph{hard} constraint violation metric, where only positive constraint violations are accumulated. Our main result is the development of the \\emph{first model-free}, \\emph{simulator-free} algorithm that achieves a sub-linear regret and a sub-linear hard constraint violation simultaneously, even in \\emph{large-scale} systems. In particular, we show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ regret and $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ hard constraint violation bounds can be achieved, where $K$ is the number of episodes, $d$ is the dimension of the feature mapping, $H$ is the length of the episode. Our results are achieved via novel adaptations of the primal-dual LSVI-UCB algorithm, i.e., it searches for the dual variable that balances between regret and constraint violation within every episode, rather than updating it at the end of each episode. This turns out to be crucial for our theoretical guarantees when dealing with hard constraint violations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ghosh24a/ghosh24a.pdf",
        "supp": "",
        "pdf_size": 1383238,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5057578365183965610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bbe2e4b0e6",
        "title": "Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts",
        "site": "https://proceedings.mlr.press/v238/nguyen24b.html",
        "author": "Huy Nguyen; TrungTin Nguyen; Khai Nguyen; Nhat Ho",
        "abstract": "Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications of machine learning and statistics. Despite its popularity in practice, a satisfactory level of theoretical understanding of the MoE model is far from complete. To shed new light on this problem, we provide a convergence analysis for maximum likelihood estimation (MLE) in the Gaussian-gated MoE model. The main challenge of that analysis comes from the inclusion of covariates in the Gaussian gating functions and expert networks, which leads to their intrinsic interaction via some partial differential equations with respect to their parameters. We tackle these issues by designing novel Voronoi loss functions among parameters to accurately capture the heterogeneity of parameter estimation rates. Our findings reveal that the MLE has distinct behaviors under two complement settings of location parameters of the Gaussian gating functions, namely when all these parameters are non-zero versus when at least one among them vanishes. Notably, these behaviors can be characterized by the solvability of two different systems of polynomial equations. Finally, we conduct a simulation study to empirically verify our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v238-nguyen24b,\n  title = \t {Towards Convergence Rates for Parameter Estimation in {G}aussian-gated Mixture of Experts},\n  author =       {Nguyen, Huy and Nguyen, TrungTin and Nguyen, Khai and Ho, Nhat},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2683--2691},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nguyen24b/nguyen24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nguyen24b.html},\n  abstract = \t {Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications of machine learning and statistics. Despite its popularity in practice, a satisfactory level of theoretical understanding of the MoE model is far from complete. To shed new light on this problem, we provide a convergence analysis for maximum likelihood estimation (MLE) in the Gaussian-gated MoE model. The main challenge of that analysis comes from the inclusion of covariates in the Gaussian gating functions and expert networks, which leads to their intrinsic interaction via some partial differential equations with respect to their parameters. We tackle these issues by designing novel Voronoi loss functions among parameters to accurately capture the heterogeneity of parameter estimation rates. Our findings reveal that the MLE has distinct behaviors under two complement settings of location parameters of the Gaussian gating functions, namely when all these parameters are non-zero versus when at least one among them vanishes. Notably, these behaviors can be characterized by the solvability of two different systems of polynomial equations. Finally, we conduct a simulation study to empirically verify our theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nguyen24b/nguyen24b.pdf",
        "supp": "",
        "pdf_size": 1170715,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10641433421116775474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "72a296d022",
        "title": "Towards Costless Model Selection in Contextual Bandits: A Bias-Variance Perspective",
        "site": "https://proceedings.mlr.press/v238/kumar-krishnamurthy24a.html",
        "author": "Sanath Kumar Krishnamurthy; Adrienne M Propp; Susan Athey",
        "abstract": "Model selection in supervised learning provides costless guarantees as if the model that best balances bias and variance was known a priori. We study the feasibility of similar guarantees for cumulative regret minimization in the stochastic contextual bandit setting. Recent work [Marinov and Zimmert, 2021] identifies instances where no algorithm can guarantee costless regret bounds. Nevertheless, we identify benign conditions where costless model selection is feasible: gradually increasing class complexity, and diminishing marginal returns for best-in-class policy value with increasing class complexity. Our algorithm is based on a novel misspecification test, and our analysis demonstrates the benefits of using model selection for reward estimation. Unlike prior work on model selection in contextual bandits, our algorithm carefully adapts to the evolving bias-variance trade-off as more data is collected. In particular, our algorithm and analysis go beyond adapting to the complexity of the simplest realizable class and instead adapt to the complexity of the simplest class whose estimation variance dominates the bias. For short horizons, this provides improved regret guarantees that depend on the complexity of simpler classes.",
        "bibtex": "@InProceedings{pmlr-v238-kumar-krishnamurthy24a,\n  title = \t {Towards Costless Model Selection in Contextual Bandits: A Bias-Variance Perspective},\n  author =       {Kumar Krishnamurthy, Sanath and M Propp, Adrienne and Athey, Susan},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2476--2484},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kumar-krishnamurthy24a/kumar-krishnamurthy24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kumar-krishnamurthy24a.html},\n  abstract = \t {Model selection in supervised learning provides costless guarantees as if the model that best balances bias and variance was known a priori. We study the feasibility of similar guarantees for cumulative regret minimization in the stochastic contextual bandit setting. Recent work [Marinov and Zimmert, 2021] identifies instances where no algorithm can guarantee costless regret bounds. Nevertheless, we identify benign conditions where costless model selection is feasible: gradually increasing class complexity, and diminishing marginal returns for best-in-class policy value with increasing class complexity. Our algorithm is based on a novel misspecification test, and our analysis demonstrates the benefits of using model selection for reward estimation. Unlike prior work on model selection in contextual bandits, our algorithm carefully adapts to the evolving bias-variance trade-off as more data is collected. In particular, our algorithm and analysis go beyond adapting to the complexity of the simplest realizable class and instead adapt to the complexity of the simplest class whose estimation variance dominates the bias. For short horizons, this provides improved regret guarantees that depend on the complexity of simpler classes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kumar-krishnamurthy24a/kumar-krishnamurthy24a.pdf",
        "supp": "",
        "pdf_size": 557452,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15692482137623118815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; Stanford University; Stanford University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "86f3c1c95c",
        "title": "Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach",
        "site": "https://proceedings.mlr.press/v238/lu24a.html",
        "author": "Juanwu Lu; Wei Zhan; Masayoshi Tomizuka; Yeping Hu",
        "abstract": "Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents\u2019 histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achieve comparable performance to state-of-the-art results.",
        "bibtex": "@InProceedings{pmlr-v238-lu24a,\n  title = \t {Towards Generalizable and Interpretable Motion Prediction: A Deep Variational {B}ayes Approach},\n  author =       {Lu, Juanwu and Zhan, Wei and Tomizuka, Masayoshi and Hu, Yeping},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4717--4725},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lu24a/lu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lu24a.html},\n  abstract = \t {Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents\u2019 histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achieve comparable performance to state-of-the-art results.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lu24a/lu24a.pdf",
        "supp": "",
        "pdf_size": 6266265,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16433931798550055713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Purdue University; UC Berkeley; UC Berkeley + LLNL; UC Berkeley",
        "aff_domain": "purdue.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "purdue.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1+2;1",
        "aff_unique_norm": "Purdue University;University of California, Berkeley;Lawrence Livermore National Laboratory",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.purdue.edu;https://www.berkeley.edu;https://www.llnl.gov",
        "aff_unique_abbr": "Purdue;UC Berkeley;LLNL",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3cb86ad792",
        "title": "Towards Practical Non-Adversarial Distribution Matching",
        "site": "https://proceedings.mlr.press/v238/gong24b.html",
        "author": "Ziyu Gong; Ben Usman; Han Zhao; David I Inouye",
        "abstract": "Distribution matching can be used to learn invariant representations with applications in fairness and robustness. Most prior works resort to adversarial matching methods but the resulting minimax problems are unstable and challenging to optimize. Non-adversarial likelihood-based approaches either require model invertibility, impose constraints on the latent prior, or lack a generic framework for distribution matching. To overcome these limitations, we propose a non-adversarial VAE-based matching method that can be applied to any model pipeline. We develop a set of alignment upper bounds for distribution matching (including a noisy bound) that have VAE-like objectives but with a different perspective. We carefully compare our method to prior VAE-based matching approaches both theoretically and empirically. Finally, we demonstrate that our novel matching losses can replace adversarial losses in standard invariant representation learning pipelines without modifying the original architectures\u2014thereby significantly broadening the applicability of non-adversarial matching methods.",
        "bibtex": "@InProceedings{pmlr-v238-gong24b,\n  title = \t {Towards Practical Non-Adversarial Distribution Matching},\n  author =       {Gong, Ziyu and Usman, Ben and Zhao, Han and I Inouye, David},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4276--4284},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gong24b/gong24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gong24b.html},\n  abstract = \t {Distribution matching can be used to learn invariant representations with applications in fairness and robustness. Most prior works resort to adversarial matching methods but the resulting minimax problems are unstable and challenging to optimize. Non-adversarial likelihood-based approaches either require model invertibility, impose constraints on the latent prior, or lack a generic framework for distribution matching. To overcome these limitations, we propose a non-adversarial VAE-based matching method that can be applied to any model pipeline. We develop a set of alignment upper bounds for distribution matching (including a noisy bound) that have VAE-like objectives but with a different perspective. We carefully compare our method to prior VAE-based matching approaches both theoretically and empirically. Finally, we demonstrate that our novel matching losses can replace adversarial losses in standard invariant representation learning pipelines without modifying the original architectures\u2014thereby significantly broadening the applicability of non-adversarial matching methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gong24b/gong24b.pdf",
        "supp": "",
        "pdf_size": 1338942,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:QgR-IgrX_ZYJ:scholar.google.com/&scioq=Towards+Practical+Non-Adversarial+Distribution+Matching&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e57bd04ef1",
        "title": "Towards a Complete Benchmark on Video Moment Localization",
        "site": "https://proceedings.mlr.press/v238/chae24a.html",
        "author": "Jinyeong Chae; Donghwa Kim; Kwanseok Kim; Doyeon Lee; Sangho Lee; Seongsu Ha; Jonghwan Mun; Wooyoung Kang; Byungseok Roh; Joonseok Lee",
        "abstract": "In this paper, we propose and conduct a comprehensive benchmark on moment localization task, which aims to retrieve a segment that corresponds to a text query from a single untrimmed video. Our study starts from an observation that most moment localization papers report experimental results only on a few datasets in spite of availability of far more benchmarks. Thus, we conduct an extensive benchmark study to measure the performance of representative methods on widely used 7 datasets. Looking further into the details, we pose additional research questions and empirically verify them, including if they rely on unintended biases introduced by specific training data, if advanced visual features trained on classification task transfer well to this task, and if computational cost of each model pays off. With a series of these experiments, we provide multi-faceted evaluation of state-of-the-art moment localization models. Codes are available at \\url{https://github.com/snuviplab/MoLEF}.",
        "bibtex": "@InProceedings{pmlr-v238-chae24a,\n  title = \t {Towards a Complete Benchmark on Video Moment Localization},\n  author =       {Chae, Jinyeong and Kim, Donghwa and Kim, Kwanseok and Lee, Doyeon and Lee, Sangho and Ha, Seongsu and Mun, Jonghwan and Kang, Wooyoung and Roh, Byungseok and Lee, Joonseok},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4168--4176},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/chae24a/chae24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/chae24a.html},\n  abstract = \t {In this paper, we propose and conduct a comprehensive benchmark on moment localization task, which aims to retrieve a segment that corresponds to a text query from a single untrimmed video. Our study starts from an observation that most moment localization papers report experimental results only on a few datasets in spite of availability of far more benchmarks. Thus, we conduct an extensive benchmark study to measure the performance of representative methods on widely used 7 datasets. Looking further into the details, we pose additional research questions and empirically verify them, including if they rely on unintended biases introduced by specific training data, if advanced visual features trained on classification task transfer well to this task, and if computational cost of each model pays off. With a series of these experiments, we provide multi-faceted evaluation of state-of-the-art moment localization models. Codes are available at \\url{https://github.com/snuviplab/MoLEF}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/chae24a/chae24a.pdf",
        "supp": "",
        "pdf_size": 18376529,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:6USHa_rsbxMJ:scholar.google.com/&scioq=Towards+a+Complete+Benchmark+on+Video+Moment+Localization&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University; Kakao Brain; Kakao Brain; Kakao Brain; Seoul National University+Google Research",
        "aff_domain": "snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;kakaobrain.com;kakaobrain.com;kakaobrain.com;snu.ac.kr",
        "email": "snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr;kakaobrain.com;kakaobrain.com;kakaobrain.com;snu.ac.kr",
        "github": "https://github.com/snuviplab/MoLEF",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;1;1;1;0+2",
        "aff_unique_norm": "Seoul National University;Kakao Brain;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://www.snu.ac.kr;https://brain.kakao.com;https://research.google",
        "aff_unique_abbr": "SNU;Kakao Brain;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0+1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "e9aa9e93a5",
        "title": "Training Implicit Generative Models via an Invariant Statistical Loss",
        "site": "https://proceedings.mlr.press/v238/frutos24a.html",
        "author": "Jos\u00e9 Manuel de Frutos; Pablo Olmos; Manuel Alberto Vazquez Lopez; Joaqu\u00edn M\u00edguez",
        "abstract": "Implicit generative models have the capability to learn arbitrary complex data distributions. On the downside, training requires telling apart real data from artificially-generated ones using adversarial discriminators, leading to unstable training and mode-dropping issues. As reported by Zahee et al. (2017), even in the one-dimensional (1D) case, training a generative adversarial network (GAN) is challenging and often suboptimal. In this work, we develop a discriminator-free method for training one-dimensional (1D) generative implicit models and subsequently expand this method to accommodate multivariate cases. Our loss function is a discrepancy measure between a suitably chosen transformation of the model samples and a uniform distribution; hence, it is invariant with respect to the true distribution of the data. We first formulate our method for 1D random variables, providing an effective solution for approximate reparameterization of arbitrary complex distributions. Then, we consider the temporal setting (both univariate and multivariate), in which we model the conditional distribution of each sample given the history of the process. We demonstrate through numerical simulations that this new method yields promising results, successfully learning true distributions in a variety of scenarios and mitigating some of the well-known problems that state-of-the-art implicit methods present.",
        "bibtex": "@InProceedings{pmlr-v238-frutos24a,\n  title = \t {Training Implicit Generative Models via an Invariant Statistical Loss},\n  author =       {de Frutos, Jos\\'{e} Manuel and Olmos, Pablo and Alberto Vazquez Lopez, Manuel and M\\'{i}guez, Joaqu\\'{i}n},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2026--2034},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/frutos24a/frutos24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/frutos24a.html},\n  abstract = \t {Implicit generative models have the capability to learn arbitrary complex data distributions. On the downside, training requires telling apart real data from artificially-generated ones using adversarial discriminators, leading to unstable training and mode-dropping issues. As reported by Zahee et al. (2017), even in the one-dimensional (1D) case, training a generative adversarial network (GAN) is challenging and often suboptimal. In this work, we develop a discriminator-free method for training one-dimensional (1D) generative implicit models and subsequently expand this method to accommodate multivariate cases. Our loss function is a discrepancy measure between a suitably chosen transformation of the model samples and a uniform distribution; hence, it is invariant with respect to the true distribution of the data. We first formulate our method for 1D random variables, providing an effective solution for approximate reparameterization of arbitrary complex distributions. Then, we consider the temporal setting (both univariate and multivariate), in which we model the conditional distribution of each sample given the history of the process. We demonstrate through numerical simulations that this new method yields promising results, successfully learning true distributions in a variety of scenarios and mitigating some of the well-known problems that state-of-the-art implicit methods present.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/frutos24a/frutos24a.pdf",
        "supp": "",
        "pdf_size": 5777343,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7326065920991263060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "955ed23ce8",
        "title": "Training a Tucker Model With Shared Factors: a Riemannian Optimization Approach",
        "site": "https://proceedings.mlr.press/v238/peshekhonov24a.html",
        "author": "Ivan Peshekhonov; Aleksey Arzhantsev; Maxim Rakhuba",
        "abstract": "Factorization of a matrix into a product of two rectangular factors, is a classic tool in various machine learning applications. Tensor factorizations generalize this concept to more than two dimensions. In applications, where some of the tensor dimensions have the same size or encode the same objects (e.g., knowledge graphs with entity-relation-entity 3D tensors), it can also be beneficial for the respective factors to be shared. In this paper, we consider a well-known Tucker tensor factorization and study its properties under the shared factor constraint. We call it a shared-factor Tucker factorization (SF-Tucker). Since sharing factors breaks polylinearity of classical tensor factorizations, common optimization schemes such as alternating least squares become inapplicable. Nevertheless, as we show in this paper, a set of fixed-rank SF-Tucker tensors preserves a Riemannian manifold structure. Therefore, we develop efficient algorithms for the main ingredients of Riemannian optimization on the SF-Tucker manifold and implement a Riemannian optimization method with momentum. We showcase the benefits of our approach on several machine learning tasks including knowledge graph completion and compression of neural networks.",
        "bibtex": "@InProceedings{pmlr-v238-peshekhonov24a,\n  title = \t {Training a {T}ucker Model With Shared Factors: a {R}iemannian Optimization Approach},\n  author =       {Peshekhonov, Ivan and Arzhantsev, Aleksey and Rakhuba, Maxim},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3304--3312},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/peshekhonov24a/peshekhonov24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/peshekhonov24a.html},\n  abstract = \t {Factorization of a matrix into a product of two rectangular factors, is a classic tool in various machine learning applications. Tensor factorizations generalize this concept to more than two dimensions. In applications, where some of the tensor dimensions have the same size or encode the same objects (e.g., knowledge graphs with entity-relation-entity 3D tensors), it can also be beneficial for the respective factors to be shared. In this paper, we consider a well-known Tucker tensor factorization and study its properties under the shared factor constraint. We call it a shared-factor Tucker factorization (SF-Tucker). Since sharing factors breaks polylinearity of classical tensor factorizations, common optimization schemes such as alternating least squares become inapplicable. Nevertheless, as we show in this paper, a set of fixed-rank SF-Tucker tensors preserves a Riemannian manifold structure. Therefore, we develop efficient algorithms for the main ingredients of Riemannian optimization on the SF-Tucker manifold and implement a Riemannian optimization method with momentum. We showcase the benefits of our approach on several machine learning tasks including knowledge graph completion and compression of neural networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/peshekhonov24a/peshekhonov24a.pdf",
        "supp": "",
        "pdf_size": 775968,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9338408209664289736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "73cf063f7f",
        "title": "TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression",
        "site": "https://proceedings.mlr.press/v238/he24a.html",
        "author": "Zelin He; Ying Sun; Runze Li",
        "abstract": "The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method\u2019s robustness to covariate shifts.",
        "bibtex": "@InProceedings{pmlr-v238-he24a,\n  title = \t {TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression},\n  author =       {He, Zelin and Sun, Ying and Li, Runze},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {703--711},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/he24a/he24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/he24a.html},\n  abstract = \t {The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method\u2019s robustness to covariate shifts.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/he24a/he24a.pdf",
        "supp": "",
        "pdf_size": 6079148,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16681730780517793216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ddc9afd5b0",
        "title": "Transductive conformal inference with adaptive scores",
        "site": "https://proceedings.mlr.press/v238/gazin24a.html",
        "author": "Ulysse Gazin; Gilles Blanchard; Etienne Roquain",
        "abstract": "Conformal inference is a fundamental and versatile tool that provides distribution-free guarantees for many machine learning tasks. We consider the transductive setting, where decisions are made on a test sample of $m$ new points, giving rise to $m$ conformal $p$-values. While classical results only concern their marginal distribution, we show that their joint distribution follows a P\u00f3lya urn model, and establish a concentration inequality for their empirical distribution function. The results hold for arbitrary exchangeable scores, including adaptive ones that can use the covariates of the test${+}$calibration samples at training stage for increased accuracy. We demonstrate the usefulness of these theoretical results through uniform, in-probability guarantees for two machine learning tasks of current interest: interval prediction for transductive transfer learning and novelty detection based on two-class classification.",
        "bibtex": "@InProceedings{pmlr-v238-gazin24a,\n  title = \t {Transductive conformal inference with adaptive scores},\n  author =       {Gazin, Ulysse and Blanchard, Gilles and Roquain, Etienne},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1504--1512},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/gazin24a/gazin24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/gazin24a.html},\n  abstract = \t {Conformal inference is a fundamental and versatile tool that provides distribution-free guarantees for many machine learning tasks. We consider the transductive setting, where decisions are made on a test sample of $m$ new points, giving rise to $m$ conformal $p$-values. While classical results only concern their marginal distribution, we show that their joint distribution follows a P\u00f3lya urn model, and establish a concentration inequality for their empirical distribution function. The results hold for arbitrary exchangeable scores, including adaptive ones that can use the covariates of the test${+}$calibration samples at training stage for increased accuracy. We demonstrate the usefulness of these theoretical results through uniform, in-probability guarantees for two machine learning tasks of current interest: interval prediction for transductive transfer learning and novelty detection based on two-class classification.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/gazin24a/gazin24a.pdf",
        "supp": "",
        "pdf_size": 1055392,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6036073353348570878&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f22823a695",
        "title": "Trigonometric Quadrature Fourier Features for Scalable Gaussian Process Regression",
        "site": "https://proceedings.mlr.press/v238/li24o.html",
        "author": "Kevin Li; Max Balakirsky; Simon Mak",
        "abstract": "Fourier feature approximations have been successfully applied in the literature for scalable Gaussian Process (GP) regression. In particular, Quadrature Fourier Features (QFF) derived from Gaussian quadrature rules have gained popularity in recent years due to their improved approximation accuracy and better calibrated uncertainty estimates compared to Random Fourier Feature (RFF) methods. However, a key limitation of QFF is that its performance can suffer from well-known pathologies related to highly oscillatory quadrature, resulting in mediocre approximation with limited features. We address this critical issue via a new Trigonometric Quadrature Fourier Feature (TQFF) method, which uses a novel non-Gaussian quadrature rule specifically tailored for the desired Fourier transform. We derive an exact quadrature rule for TQFF, along with kernel approximation error bounds for the resulting feature map. We then demonstrate the improved performance of our method over RFF and Gaussian QFF in a suite of numerical experiments and applications, and show the TQFF enjoys accurate GP approximations over a broad range of length-scales using fewer features.",
        "bibtex": "@InProceedings{pmlr-v238-li24o,\n  title = \t {Trigonometric Quadrature {F}ourier Features for Scalable {G}aussian Process Regression},\n  author =       {Li, Kevin and Balakirsky, Max and Mak, Simon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3484--3492},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24o/li24o.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24o.html},\n  abstract = \t {Fourier feature approximations have been successfully applied in the literature for scalable Gaussian Process (GP) regression. In particular, Quadrature Fourier Features (QFF) derived from Gaussian quadrature rules have gained popularity in recent years due to their improved approximation accuracy and better calibrated uncertainty estimates compared to Random Fourier Feature (RFF) methods. However, a key limitation of QFF is that its performance can suffer from well-known pathologies related to highly oscillatory quadrature, resulting in mediocre approximation with limited features. We address this critical issue via a new Trigonometric Quadrature Fourier Feature (TQFF) method, which uses a novel non-Gaussian quadrature rule specifically tailored for the desired Fourier transform. We derive an exact quadrature rule for TQFF, along with kernel approximation error bounds for the resulting feature map. We then demonstrate the improved performance of our method over RFF and Gaussian QFF in a suite of numerical experiments and applications, and show the TQFF enjoys accurate GP approximations over a broad range of length-scales using fewer features.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24o/li24o.pdf",
        "supp": "",
        "pdf_size": 2524689,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1330791685361528497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b165f77175",
        "title": "Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting",
        "site": "https://proceedings.mlr.press/v238/sharrock24a.html",
        "author": "Louis Sharrock; Daniel Dodd; Christopher Nemeth",
        "abstract": "We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is via the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of Stein variational gradient descent, establishing a descent lemma which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, necessarily depends on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the free energy which is entirely learning rate free, based on coin betting techniques from convex optimization. We validate the performance of our algorithms across several numerical experiments, including several high-dimensional settings. Our results are competitive with existing particle-based methods, without the need for any hyperparameter tuning.",
        "bibtex": "@InProceedings{pmlr-v238-sharrock24a,\n  title = \t {Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting},\n  author =       {Sharrock, Louis and Dodd, Daniel and Nemeth, Christopher},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1810--1818},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sharrock24a/sharrock24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sharrock24a.html},\n  abstract = \t {We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is via the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of Stein variational gradient descent, establishing a descent lemma which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, necessarily depends on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the free energy which is entirely learning rate free, based on coin betting techniques from convex optimization. We validate the performance of our algorithms across several numerical experiments, including several high-dimensional settings. Our results are competitive with existing particle-based methods, without the need for any hyperparameter tuning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sharrock24a/sharrock24a.pdf",
        "supp": "",
        "pdf_size": 4598183,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12577367200438574686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "13145c81d3",
        "title": "Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process",
        "site": "https://proceedings.mlr.press/v238/kong24a.html",
        "author": "Lingkai Kong; Haotian Sun; Yuchen Zhuang; Haorui Wang; Wenhao Mu; Chao Zhang",
        "abstract": "Graph neural networks (GNNs) are powerful tools on graph data. However, their predictions are mis-calibrated and lack interpretability, limiting their adoption in critical applications. To address this issue, we propose a new uncertainty-aware and interpretable graph classification model that combines graph functional neural process and graph generative model. The core of our method is to assume a set of latent rationales which can be mapped to a probabilistic embedding space; the predictive distribution of the classifier is conditioned on such rationale embeddings by learning a stochastic correlation matrix. The graph generator serves to decode the graph structure of the rationales from the embedding space for model interpretability. For efficient model training, we adopt an alternating optimization procedure which mimics the well known Expectation-Maximization (EM) algorithm. The proposed method is general and can be applied to any existing GNN architecture. Extensive experiments on five graph classification datasets demonstrate that our framework outperforms state-of-the-art methods in both uncertainty quantification and GNN interpretability. We also conduct case studies to show that the decoded rationale structure can provide meaningful explanations.",
        "bibtex": "@InProceedings{pmlr-v238-kong24a,\n  title = \t {Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process},\n  author =       {Kong, Lingkai and Sun, Haotian and Zhuang, Yuchen and Wang, Haorui and Mu, Wenhao and Zhang, Chao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4582--4590},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kong24a/kong24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kong24a.html},\n  abstract = \t {Graph neural networks (GNNs) are powerful tools on graph data. However, their predictions are mis-calibrated and lack interpretability, limiting their adoption in critical applications. To address this issue, we propose a new uncertainty-aware and interpretable graph classification model that combines graph functional neural process and graph generative model. The core of our method is to assume a set of latent rationales which can be mapped to a probabilistic embedding space; the predictive distribution of the classifier is conditioned on such rationale embeddings by learning a stochastic correlation matrix. The graph generator serves to decode the graph structure of the rationales from the embedding space for model interpretability. For efficient model training, we adopt an alternating optimization procedure which mimics the well known Expectation-Maximization (EM) algorithm. The proposed method is general and can be applied to any existing GNN architecture. Extensive experiments on five graph classification datasets demonstrate that our framework outperforms state-of-the-art methods in both uncertainty quantification and GNN interpretability. We also conduct case studies to show that the decoded rationale structure can provide meaningful explanations.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kong24a/kong24a.pdf",
        "supp": "",
        "pdf_size": 3132751,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3543217830191915397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4ac4614238",
        "title": "Uncertainty Matters: Stable Conclusions under Unstable Assessment of Fairness Results",
        "site": "https://proceedings.mlr.press/v238/barrainkua24a.html",
        "author": "Ainhize Barrainkua; Paula Gordaliza; Jose A. Lozano; Novi Quadrianto",
        "abstract": "Recent studies highlight the effectiveness of Bayesian methods in assessing algorithm performance, particularly in fairness and bias evaluation. We present Uncertainty Matters, a multi-objective uncertainty-aware algorithmic comparison framework. In fairness focused scenarios, it models sensitive group confusion matrices using Bayesian updates and facilitates joint comparison of performance (e.g., accuracy) and fairness metrics (e.g., true positive rate parity). Our approach works seamlessly with common evaluation methods like K-fold cross-validation, effectively addressing dependencies among the K posterior metric distributions. The integration of correlated information is carried out through a procedure tailored to the classifier\u2019s complexity. Experiments demonstrate that the insights derived from algorithmic comparisons employing the Uncertainty Matters approach are more informative, reliable, and less influenced by particular data partitions. Code for the paper is publicly available at \\url{https://github.com/abarrainkua/UncertaintyMatters}.",
        "bibtex": "@InProceedings{pmlr-v238-barrainkua24a,\n  title = \t {Uncertainty Matters: Stable Conclusions under Unstable Assessment of Fairness Results},\n  author =       {Barrainkua, Ainhize and Gordaliza, Paula and Lozano, Jose A. and Quadrianto, Novi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1198--1206},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/barrainkua24a/barrainkua24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/barrainkua24a.html},\n  abstract = \t {Recent studies highlight the effectiveness of Bayesian methods in assessing algorithm performance, particularly in fairness and bias evaluation. We present Uncertainty Matters, a multi-objective uncertainty-aware algorithmic comparison framework. In fairness focused scenarios, it models sensitive group confusion matrices using Bayesian updates and facilitates joint comparison of performance (e.g., accuracy) and fairness metrics (e.g., true positive rate parity). Our approach works seamlessly with common evaluation methods like K-fold cross-validation, effectively addressing dependencies among the K posterior metric distributions. The integration of correlated information is carried out through a procedure tailored to the classifier\u2019s complexity. Experiments demonstrate that the insights derived from algorithmic comparisons employing the Uncertainty Matters approach are more informative, reliable, and less influenced by particular data partitions. Code for the paper is publicly available at \\url{https://github.com/abarrainkua/UncertaintyMatters}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/barrainkua24a/barrainkua24a.pdf",
        "supp": "",
        "pdf_size": 3182369,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=599279485311228948&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Basque Center for Applied Mathematics (BCAM), Spain; Universidad P\u00b4ublica de Navarra (UPNA), Spain; Institute for Advanced Materials and Mathematics (INAMAT2), Spain+University of the Basque Country UPV/EHU, Spain; Predictive Analytics Lab, University of Sussex, UK+Monash University, Indonesia",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/abarrainkua/UncertaintyMatters",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3;4+5",
        "aff_unique_norm": "Basque Center for Applied Mathematics;Universidad P\u00fablica de Navarra;Institute for Advanced Materials and Mathematics;University of the Basque Country;University of Sussex;Monash University",
        "aff_unique_dep": ";;;;Predictive Analytics Lab;",
        "aff_unique_url": "https://www.bcamath.org/;https://www.unav.es;;https://www.ehu.eus/en;https://www.sussex.ac.uk;https://www.monash.edu",
        "aff_unique_abbr": "BCAM;UPNA;INAMAT2;UPV/EHU;;Monash",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;1+2",
        "aff_country_unique": "Spain;United Kingdom;Indonesia"
    },
    {
        "id": "8bb439dd1c",
        "title": "Uncertainty-aware Continuous Implicit Neural Representations for Remote Sensing Object Counting",
        "site": "https://proceedings.mlr.press/v238/xu24b.html",
        "author": "Siyuan Xu; Yucheng Wang; Mingzhou Fan; Byung-Jun Yoon; Xiaoning Qian",
        "abstract": "Many existing object counting methods rely on density map estimation\u00a0(DME) of the discrete grid representation by decoding extracted image semantic features from designed convolutional neural networks\u00a0(CNNs). Relying on discrete density maps not only leads to information loss dependent on the original image resolution, but also has a scalability issue when analyzing high-resolution images with cubically increasing memory complexity. Furthermore, none of the existing methods can offer reliable uncertainty quantification\u00a0(UQ) for the derived count estimates. To overcome these limitations, we design UNcertainty-aware, hypernetwork-based Implicit neural representations for Counting\u00a0(UNIC) to assign probabilities and the corresponding counting confidence over continuous spatial coordinates. We derive a sampling-based Bayesian counting loss function and develop the corresponding model training algorithm. UNIC outperforms existing methods on the Remote Sensing Object Counting\u00a0(RSOC) dataset with reliable UQ and improved interpretability of the derived count estimates. Our code is available at https://github.com/SiyuanXu-tamu/UNIC.",
        "bibtex": "@InProceedings{pmlr-v238-xu24b,\n  title = \t {Uncertainty-aware Continuous Implicit Neural Representations for Remote Sensing Object Counting},\n  author =       {Xu, Siyuan and Wang, Yucheng and Fan, Mingzhou and Yoon, Byung-Jun and Qian, Xiaoning},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4105--4113},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/xu24b/xu24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/xu24b.html},\n  abstract = \t {Many existing object counting methods rely on density map estimation\u00a0(DME) of the discrete grid representation by decoding extracted image semantic features from designed convolutional neural networks\u00a0(CNNs). Relying on discrete density maps not only leads to information loss dependent on the original image resolution, but also has a scalability issue when analyzing high-resolution images with cubically increasing memory complexity. Furthermore, none of the existing methods can offer reliable uncertainty quantification\u00a0(UQ) for the derived count estimates. To overcome these limitations, we design UNcertainty-aware, hypernetwork-based Implicit neural representations for Counting\u00a0(UNIC) to assign probabilities and the corresponding counting confidence over continuous spatial coordinates. We derive a sampling-based Bayesian counting loss function and develop the corresponding model training algorithm. UNIC outperforms existing methods on the Remote Sensing Object Counting\u00a0(RSOC) dataset with reliable UQ and improved interpretability of the derived count estimates. Our code is available at https://github.com/SiyuanXu-tamu/UNIC.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/xu24b/xu24b.pdf",
        "supp": "",
        "pdf_size": 6346572,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1334170956244534641&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Electrical & Computer Engineering, Texas A&M University + Computational Science Initiative (CSI), Brookhaven National Laboratory; Electrical & Computer Engineering, Texas A&M University; Electrical & Computer Engineering, Texas A&M University; Electrical & Computer Engineering, Texas A&M University + Computational Science Initiative (CSI), Brookhaven National Laboratory; Electrical & Computer Engineering, Texas A&M University + Computer Science & Engineering, Texas A&M University + Computational Science Initiative (CSI), Brookhaven National Laboratory",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/SiyuanXu-tamu/UNIC",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0+1;0+0+1",
        "aff_unique_norm": "Texas A&M University;Brookhaven National Laboratory",
        "aff_unique_dep": "Electrical & Computer Engineering;Computational Science Initiative (CSI)",
        "aff_unique_url": "https://www.tamu.edu;https://www.bnl.gov",
        "aff_unique_abbr": "TAMU;BNL",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0;0+0;0+0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fa368f57c3",
        "title": "Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters",
        "site": "https://proceedings.mlr.press/v238/sun24a.html",
        "author": "Zhenyu Sun; Xiaochun Niu; Ermin Wei",
        "abstract": "Generalization performance is a key metric in evaluating machine learning models when applied to real-world applications. Good generalization indicates the model can predict unseen data correctly when trained under a limited number of data. Federated learning (FL), which has emerged as a popular distributed learning framework, allows multiple devices or clients to train a shared model without violating privacy requirements. While the existing literature has studied extensively the generalization performances of centralized machine learning algorithms, similar analysis in the federated settings is either absent or with very restrictive assumptions on the loss functions. In this paper, we aim to analyze the generalization performances of federated learning by means of algorithmic stability, which measures the change of the output model of an algorithm when perturbing one data point. Three widely-used algorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex and non-convex loss functions. Our analysis shows that the generalization performances of models trained by these three algorithms are closely related to the heterogeneity of clients\u2019 datasets as well as the convergence behaviors of the algorithms. Particularly, in the i.i.d. setting, our results recover the classical results of stochastic gradient descent (SGD).",
        "bibtex": "@InProceedings{pmlr-v238-sun24a,\n  title = \t {Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters},\n  author =       {Sun, Zhenyu and Niu, Xiaochun and Wei, Ermin},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {676--684},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/sun24a/sun24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/sun24a.html},\n  abstract = \t {Generalization performance is a key metric in evaluating machine learning models when applied to real-world applications. Good generalization indicates the model can predict unseen data correctly when trained under a limited number of data. Federated learning (FL), which has emerged as a popular distributed learning framework, allows multiple devices or clients to train a shared model without violating privacy requirements. While the existing literature has studied extensively the generalization performances of centralized machine learning algorithms, similar analysis in the federated settings is either absent or with very restrictive assumptions on the loss functions. In this paper, we aim to analyze the generalization performances of federated learning by means of algorithmic stability, which measures the change of the output model of an algorithm when perturbing one data point. Three widely-used algorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex and non-convex loss functions. Our analysis shows that the generalization performances of models trained by these three algorithms are closely related to the heterogeneity of clients\u2019 datasets as well as the convergence behaviors of the algorithms. Particularly, in the i.i.d. setting, our results recover the classical results of stochastic gradient descent (SGD).}\n}",
        "pdf": "https://proceedings.mlr.press/v238/sun24a/sun24a.pdf",
        "supp": "",
        "pdf_size": 818399,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2198277912467498653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "eac1cf4f1b",
        "title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
        "site": "https://proceedings.mlr.press/v238/ildiz24a.html",
        "author": "Muhammed E. Ildiz; Zhe Zhao; Samet Oymak",
        "abstract": "Large language models exhibit strong multitasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows, large language models exhibit emerging abilities where certain tasks can abruptly jump from poor to respectable performance. Such phenomena motivate a deeper understanding of how individual tasks evolve during multitasking. To this aim, we study a multitask representation learning setup where tasks can have distinct distributions, quantified by their covariance priors. Through random matrix theory, we precisely characterize the optimal linear representation for few-shot learning that minimizes the average test risk in terms of task covariances. When tasks have equal sample sizes, we prove a reduction to an equivalent problem with a single effective covariance from which the individual task risks of the original problem can be deduced. Importantly, we introduce \u201ctask competition\u201d to explain how tasks with dominant covariance eigenspectrum emerge faster than others. We show that task competition can potentially explain the inverse scaling of certain tasks i.e. reduced test accuracy as the model grows. Overall, this work sheds light on the risk and emergence of individual tasks and uncovers new high-dimensional phenomena (including multiple-descent risk curves) that arise in multitask representation learning.",
        "bibtex": "@InProceedings{pmlr-v238-ildiz24a,\n  title = \t {Understanding Inverse Scaling and Emergence in Multitask Representation Learning},\n  author =       {Ildiz, Muhammed E. and Zhao, Zhe and Oymak, Samet},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4726--4734},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ildiz24a/ildiz24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ildiz24a.html},\n  abstract = \t {Large language models exhibit strong multitasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows, large language models exhibit emerging abilities where certain tasks can abruptly jump from poor to respectable performance. Such phenomena motivate a deeper understanding of how individual tasks evolve during multitasking. To this aim, we study a multitask representation learning setup where tasks can have distinct distributions, quantified by their covariance priors. Through random matrix theory, we precisely characterize the optimal linear representation for few-shot learning that minimizes the average test risk in terms of task covariances. When tasks have equal sample sizes, we prove a reduction to an equivalent problem with a single effective covariance from which the individual task risks of the original problem can be deduced. Importantly, we introduce \u201ctask competition\u201d to explain how tasks with dominant covariance eigenspectrum emerge faster than others. We show that task competition can potentially explain the inverse scaling of certain tasks i.e. reduced test accuracy as the model grows. Overall, this work sheds light on the risk and emergence of individual tasks and uncovers new high-dimensional phenomena (including multiple-descent risk curves) that arise in multitask representation learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ildiz24a/ildiz24a.pdf",
        "supp": "",
        "pdf_size": 886318,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=140296336929429241&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Michigan, Ann Arbor; Google DeepMind; University of Michigan, Ann Arbor",
        "aff_domain": "umich.edu;google.com;umich.edu",
        "email": "umich.edu;google.com;umich.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Michigan;Google",
        "aff_unique_dep": ";Google DeepMind",
        "aff_unique_url": "https://www.umich.edu;https://deepmind.com",
        "aff_unique_abbr": "UM;DeepMind",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "49aa4c3bfd",
        "title": "Understanding Progressive Training Through the Framework of Randomized Coordinate Descent",
        "site": "https://proceedings.mlr.press/v238/szlendak24a.html",
        "author": "Rafa\u0142 Szlendak; Elnur Gasanov; Peter Richtarik",
        "abstract": "We propose a Randomized Progressive Training algorithm (RPT)\u2014a stochastic proxy for the well-known Progressive Training method (PT) (Karras et al., 2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was proposed as a heuristic, with no convergence analysis even for the simplest objective functions. On the contrary, to the best of our knowledge, RPT is the first PT-type algorithm with rigorous and sound theoretical guarantees for general smooth objective functions. We cast our method into the established framework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richtarik & Takac, 2014), for which (as a by-product of our investigations) we also propose a novel, simple and general convergence analysis encapsulating strongly-convex, convex and nonconvex objectives. We then use this framework to establish a convergence theory for RPT. Finally, we validate the effectiveness of our method through extensive computational experiments.",
        "bibtex": "@InProceedings{pmlr-v238-szlendak24a,\n  title = \t {Understanding Progressive Training Through the Framework of Randomized Coordinate Descent},\n  author =       {Szlendak, Rafa\\l{} and Gasanov, Elnur and Richtarik, Peter},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2161--2169},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/szlendak24a/szlendak24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/szlendak24a.html},\n  abstract = \t {We propose a Randomized Progressive Training algorithm (RPT)\u2014a stochastic proxy for the well-known Progressive Training method (PT) (Karras et al., 2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was proposed as a heuristic, with no convergence analysis even for the simplest objective functions. On the contrary, to the best of our knowledge, RPT is the first PT-type algorithm with rigorous and sound theoretical guarantees for general smooth objective functions. We cast our method into the established framework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richtarik & Takac, 2014), for which (as a by-product of our investigations) we also propose a novel, simple and general convergence analysis encapsulating strongly-convex, convex and nonconvex objectives. We then use this framework to establish a convergence theory for RPT. Finally, we validate the effectiveness of our method through extensive computational experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/szlendak24a/szlendak24a.pdf",
        "supp": "",
        "pdf_size": 897864,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15430445924102856603&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ecb2598aeb",
        "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
        "site": "https://proceedings.mlr.press/v238/ren24c.html",
        "author": "Yinuo Ren; Chao Ma; Lexing Ying",
        "abstract": "Why do neural networks trained with large learning rates for longer time often lead to better generalization? In this paper, we delve into this question by examining the relation between training and testing loss in neural networks. Through visualization of these losses, we note that the training trajectory with a large learning rate navigates through the minima manifold of the training loss, finally nearing the neighborhood of the testing loss minimum. Motivated by these findings, we introduce a nonlinear model whose loss landscapes mirror those observed for real neural networks. Upon investigating the training process using SGD on our model, we demonstrate that an extended phase with a large learning rate steers our model towards the minimum norm solution of the training loss, which may achieve near-optimal generalization, thereby affirming the empirically observed benefits of late learning rate decay.",
        "bibtex": "@InProceedings{pmlr-v238-ren24c,\n  title = \t {Understanding the Generalization Benefits of Late Learning Rate Decay},\n  author =       {Ren, Yinuo and Ma, Chao and Ying, Lexing},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4465--4473},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ren24c/ren24c.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ren24c.html},\n  abstract = \t {Why do neural networks trained with large learning rates for longer time often lead to better generalization? In this paper, we delve into this question by examining the relation between training and testing loss in neural networks. Through visualization of these losses, we note that the training trajectory with a large learning rate navigates through the minima manifold of the training loss, finally nearing the neighborhood of the testing loss minimum. Motivated by these findings, we introduce a nonlinear model whose loss landscapes mirror those observed for real neural networks. Upon investigating the training process using SGD on our model, we demonstrate that an extended phase with a large learning rate steers our model towards the minimum norm solution of the training loss, which may achieve near-optimal generalization, thereby affirming the empirically observed benefits of late learning rate decay.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ren24c/ren24c.pdf",
        "supp": "",
        "pdf_size": 1059496,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2455787607694966957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5b837287e2",
        "title": "Unified Transfer Learning in High-Dimensional Linear Regression",
        "site": "https://proceedings.mlr.press/v238/shuo-liu24a.html",
        "author": "Shuo Shuo Liu",
        "abstract": "Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v238-shuo-liu24a,\n  title = \t {Unified Transfer Learning in High-Dimensional Linear Regression},\n  author =       {Shuo Liu, Shuo},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1036--1044},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shuo-liu24a/shuo-liu24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shuo-liu24a.html},\n  abstract = \t {Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shuo-liu24a/shuo-liu24a.pdf",
        "supp": "",
        "pdf_size": 3162041,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13158989627372760118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Columbia University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e422096bac",
        "title": "Unsupervised Change Point Detection in Multivariate Time Series",
        "site": "https://proceedings.mlr.press/v238/wu24g.html",
        "author": "Daoping Wu; Suhas Gundimeda; Shaoshuai Mou; Christopher Quinn",
        "abstract": "We consider the challenging problem of unsupervised change point detection in multivariate time series when the number of change points is unknown. Our method eliminates the user\u2019s need for careful parameter tuning, enhancing its practicality and usability. Our approach identifies time series segments with similar empirically estimated distributions, coupled with a novel greedy algorithm guided by the minimum description length principle. We provide theoretical guarantees and, through experiments on synthetic and real-world data, provide empirical evidence for its improved performance in identifying meaningful change points in practical settings.",
        "bibtex": "@InProceedings{pmlr-v238-wu24g,\n  title = \t {Unsupervised Change Point Detection in Multivariate Time Series},\n  author =       {Wu, Daoping and Gundimeda, Suhas and Mou, Shaoshuai and Quinn, Christopher},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3844--3852},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/wu24g/wu24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/wu24g.html},\n  abstract = \t {We consider the challenging problem of unsupervised change point detection in multivariate time series when the number of change points is unknown. Our method eliminates the user\u2019s need for careful parameter tuning, enhancing its practicality and usability. Our approach identifies time series segments with similar empirically estimated distributions, coupled with a novel greedy algorithm guided by the minimum description length principle. We provide theoretical guarantees and, through experiments on synthetic and real-world data, provide empirical evidence for its improved performance in identifying meaningful change points in practical settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/wu24g/wu24g.pdf",
        "supp": "",
        "pdf_size": 8923363,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:bMrcK2I5n-AJ:scholar.google.com/&scioq=Unsupervised+Change+Point+Detection+in+Multivariate+Time+Series&hl=en&as_sdt=0,14",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1eb2d79951",
        "title": "Unsupervised Novelty Detection in Pretrained Representation Space with Locally Adapted Likelihood Ratio",
        "site": "https://proceedings.mlr.press/v238/ahmadian24a.html",
        "author": "Amirhossein Ahmadian; Yifan Ding; Gabriel Eilertsen; Fredrik Lindsten",
        "abstract": "Detecting novelties given unlabeled examples of normal data is a challenging task in machine learning, particularly when the novel and normal categories are semantically close. Large deep models pretrained on massive datasets can provide a rich representation space in which the simple k-nearest neighbor distance works as a novelty measure. However, as we show in this paper, the basic k-NN method might be insufficient in this context due to ignoring the \u2019local geometry\u2019 of the distribution over representations as well as the impact of irrelevant \u2019background features\u2019. To address this, we propose a fully unsupervised novelty detection approach that integrates the flexibility of k-NN with a locally adapted scaling of dimensions based on the \u2019neighbors of nearest neighbor\u2019 and computing a \u2019likelihood ratio\u2019 in pretrained (self-supervised) representation spaces. Our experiments with image data show the advantage of this method when off-the-shelf vision transformers (e.g., pretrained by DINO) are used as the feature extractor without any fine-tuning.",
        "bibtex": "@InProceedings{pmlr-v238-ahmadian24a,\n  title = \t {Unsupervised Novelty Detection in Pretrained Representation Space with Locally Adapted Likelihood Ratio},\n  author =       {Ahmadian, Amirhossein and Ding, Yifan and Eilertsen, Gabriel and Lindsten, Fredrik},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {874--882},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/ahmadian24a/ahmadian24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/ahmadian24a.html},\n  abstract = \t {Detecting novelties given unlabeled examples of normal data is a challenging task in machine learning, particularly when the novel and normal categories are semantically close. Large deep models pretrained on massive datasets can provide a rich representation space in which the simple k-nearest neighbor distance works as a novelty measure. However, as we show in this paper, the basic k-NN method might be insufficient in this context due to ignoring the \u2019local geometry\u2019 of the distribution over representations as well as the impact of irrelevant \u2019background features\u2019. To address this, we propose a fully unsupervised novelty detection approach that integrates the flexibility of k-NN with a locally adapted scaling of dimensions based on the \u2019neighbors of nearest neighbor\u2019 and computing a \u2019likelihood ratio\u2019 in pretrained (self-supervised) representation spaces. Our experiments with image data show the advantage of this method when off-the-shelf vision transformers (e.g., pretrained by DINO) are used as the feature extractor without any fine-tuning.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/ahmadian24a/ahmadian24a.pdf",
        "supp": "",
        "pdf_size": 2729056,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17230596547899558495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "04163cacde",
        "title": "Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation",
        "site": "https://proceedings.mlr.press/v238/kuang24a.html",
        "author": "Yiling Kuang; Chao Yang; Yang Yang; Shuang Li",
        "abstract": "In high-stakes systems such as healthcare, it is critical to understand the causal reasons behind unusual events, such as sudden changes in patient\u2019s health. Unveiling the causal reasons helps with quick diagnoses and precise treatment planning. In this paper, we propose an automated method for uncovering \u201cif-then\u201d logic rules to explain observational events. We introduce {\\it temporal point processes} to model the events of interest, and discover the set of latent rules to explain the occurrence of events. To achieve this goal, we employ an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the posterior probability of each event being explained by each discovered rule. In the M-step, we update both the rule set and model parameters to enhance the likelihood function\u2019s lower bound. Notably, we will optimize the rule set in a {\\it differential} manner. Our approach demonstrates accurate performance in both discovering rules and identifying root causes. We showcase its promising results using synthetic and real healthcare datasets.",
        "bibtex": "@InProceedings{pmlr-v238-kuang24a,\n  title = \t {Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation},\n  author =       {Kuang, Yiling and Yang, Chao and Yang, Yang and Li, Shuang},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2935--2943},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kuang24a/kuang24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kuang24a.html},\n  abstract = \t {In high-stakes systems such as healthcare, it is critical to understand the causal reasons behind unusual events, such as sudden changes in patient\u2019s health. Unveiling the causal reasons helps with quick diagnoses and precise treatment planning. In this paper, we propose an automated method for uncovering \u201cif-then\u201d logic rules to explain observational events. We introduce {\\it temporal point processes} to model the events of interest, and discover the set of latent rules to explain the occurrence of events. To achieve this goal, we employ an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the posterior probability of each event being explained by each discovered rule. In the M-step, we update both the rule set and model parameters to enhance the likelihood function\u2019s lower bound. Notably, we will optimize the rule set in a {\\it differential} manner. Our approach demonstrates accurate performance in both discovering rules and identifying root causes. We showcase its promising results using synthetic and real healthcare datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kuang24a/kuang24a.pdf",
        "supp": "",
        "pdf_size": 1670974,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17148786817720417116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5308251088",
        "title": "User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates",
        "site": "https://proceedings.mlr.press/v238/liu24g.html",
        "author": "Daogao Liu; Hilal Asi",
        "abstract": "We study differentially private stochastic convex optimization (DP-SCO) under user-level privacy, where each user may hold multiple data items. Existing work for user-level DP-SCO either requires super-polynomial runtime (Ghazi et al., 2023) or requires the number of users to grow polynomially with the dimensionality of the problem with additional strict assumptions (Bassily et al., 2023). We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.",
        "bibtex": "@InProceedings{pmlr-v238-liu24g,\n  title = \t {User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates},\n  author =       {Liu, Daogao and Asi, Hilal},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4240--4248},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/liu24g/liu24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/liu24g.html},\n  abstract = \t {We study differentially private stochastic convex optimization (DP-SCO) under user-level privacy, where each user may hold multiple data items. Existing work for user-level DP-SCO either requires super-polynomial runtime (Ghazi et al., 2023) or requires the number of users to grow polynomially with the dimensionality of the problem with additional strict assumptions (Bassily et al., 2023). We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/liu24g/liu24g.pdf",
        "supp": "",
        "pdf_size": 503002,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7871521197294839548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Apple Inc.; University of Washington",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Apple;University of Washington",
        "aff_unique_dep": "Apple Inc.;",
        "aff_unique_url": "https://www.apple.com;https://www.washington.edu",
        "aff_unique_abbr": "Apple;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2ce54e9d98",
        "title": "VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates",
        "site": "https://proceedings.mlr.press/v238/braun24a.html",
        "author": "Guillaume Braun; Masashi Sugiyama",
        "abstract": "Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge\u2019s side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data.",
        "bibtex": "@InProceedings{pmlr-v238-braun24a,\n  title = \t {{VEC-SBM}: Optimal Community Detection with Vectorial Edges Covariates},\n  author =       {Braun, Guillaume and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {532--540},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/braun24a/braun24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/braun24a.html},\n  abstract = \t {Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge\u2019s side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/braun24a/braun24a.pdf",
        "supp": "",
        "pdf_size": 995478,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8112474620228463813&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "RIKEN AIP; RIKEN AIP + University of Tokyo",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "RIKEN;University of Tokyo",
        "aff_unique_dep": "Advanced Institute for Computational Science;",
        "aff_unique_url": "https://www.aip.riken.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "RIKEN AIP;UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "fcc737548c",
        "title": "Variational Gaussian Process Diffusion Processes",
        "site": "https://proceedings.mlr.press/v238/verma24a.html",
        "author": "Prakhar Verma; Vincent Adam; Arno Solin",
        "abstract": "Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference, approximating the posterior process as a linear diffusion process, and point out pathologies in the approach. We propose an alternative parameterization of the Gaussian variational process using a site-based exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for learning model parameters.",
        "bibtex": "@InProceedings{pmlr-v238-verma24a,\n  title = \t {Variational {G}aussian Process Diffusion Processes},\n  author =       {Verma, Prakhar and Adam, Vincent and Solin, Arno},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1909--1917},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/verma24a/verma24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/verma24a.html},\n  abstract = \t {Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference, approximating the posterior process as a linear diffusion process, and point out pathologies in the approach. We propose an alternative parameterization of the Gaussian variational process using a site-based exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for learning model parameters.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/verma24a/verma24a.pdf",
        "supp": "",
        "pdf_size": 2420986,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3042142355317335330&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d557a2b72b",
        "title": "Variational Resampling",
        "site": "https://proceedings.mlr.press/v238/kviman24a.html",
        "author": "Oskar Kviman; Nicola Branchini; V\u00edctor Elvira; Jens Lagergren",
        "abstract": "We cast the resampling step in particle filters (PFs) as a variational inference problem, resulting in a new class of resampling schemes: variational resampling. Variational resampling is flexible as it allows for choices of 1) divergence to minimize, 2) target distribution to input to the divergence, and 3) divergence minimization algorithm. With this novel application of VI to particle filters, variational resampling further unifies these two powerful and popular methodologies. We construct two variational resamplers that replicate particles in order to maximize lower bounds with respect to two different target measures. We benchmark our variational resamplers on challenging smoothing tasks, outperforming PFs that implement the state-of-the-art resampling schemes.",
        "bibtex": "@InProceedings{pmlr-v238-kviman24a,\n  title = \t {Variational Resampling},\n  author =       {Kviman, Oskar and Branchini, Nicola and Elvira, V\\'{i}ctor and Lagergren, Jens},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3286--3294},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/kviman24a/kviman24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/kviman24a.html},\n  abstract = \t {We cast the resampling step in particle filters (PFs) as a variational inference problem, resulting in a new class of resampling schemes: variational resampling. Variational resampling is flexible as it allows for choices of 1) divergence to minimize, 2) target distribution to input to the divergence, and 3) divergence minimization algorithm. With this novel application of VI to particle filters, variational resampling further unifies these two powerful and popular methodologies. We construct two variational resamplers that replicate particles in order to maximize lower bounds with respect to two different target measures. We benchmark our variational resamplers on challenging smoothing tasks, outperforming PFs that implement the state-of-the-art resampling schemes.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/kviman24a/kviman24a.pdf",
        "supp": "",
        "pdf_size": 637642,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4160769740013291236&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ab96f1886",
        "title": "Vector Quantile Regression on Manifolds",
        "site": "https://proceedings.mlr.press/v238/pegoraro24a.html",
        "author": "Marco Pegoraro; Sanketh Vedula; Aviv A Rosenberg; Irene Tallini; Emanuele Rodola; Alex Bronstein",
        "abstract": "Quantile regression (QR) is a statistical tool for distribution-free estimation of conditional quantiles of a target variable given explanatory features. QR is limited by the assumption that the target distribution is univariate and defined on an Euclidean domain. Although the notion of quantiles was recently extended to multi-variate distributions, QR for multi-variate distributions on manifolds remains underexplored, even though many important applications inherently involve data distributed on, e.g., spheres (climate and geological phenomena), and tori (dihedral angles in proteins). By leveraging optimal transport theory and c-concave functions, we meaningfully define conditional vector quantile functions of high-dimensional variables on manifolds (M-CVQFs). Our approach allows for quantile estimation, regression, and computation of conditional confidence sets and likelihoods. We demonstrate the approach\u2019s efficacy and provide insights regarding the meaning of non-Euclidean quantiles through synthetic and real data experiments.",
        "bibtex": "@InProceedings{pmlr-v238-pegoraro24a,\n  title = \t {Vector Quantile Regression on Manifolds},\n  author =       {Pegoraro, Marco and Vedula, Sanketh and A Rosenberg, Aviv and Tallini, Irene and Rodola, Emanuele and Bronstein, Alex},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1999--2007},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/pegoraro24a/pegoraro24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/pegoraro24a.html},\n  abstract = \t {Quantile regression (QR) is a statistical tool for distribution-free estimation of conditional quantiles of a target variable given explanatory features. QR is limited by the assumption that the target distribution is univariate and defined on an Euclidean domain. Although the notion of quantiles was recently extended to multi-variate distributions, QR for multi-variate distributions on manifolds remains underexplored, even though many important applications inherently involve data distributed on, e.g., spheres (climate and geological phenomena), and tori (dihedral angles in proteins). By leveraging optimal transport theory and c-concave functions, we meaningfully define conditional vector quantile functions of high-dimensional variables on manifolds (M-CVQFs). Our approach allows for quantile estimation, regression, and computation of conditional confidence sets and likelihoods. We demonstrate the approach\u2019s efficacy and provide insights regarding the meaning of non-Euclidean quantiles through synthetic and real data experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/pegoraro24a/pegoraro24a.pdf",
        "supp": "",
        "pdf_size": 10094123,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5898609138769215003&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Sapienza, University of Rome; Technion; Technion; Sapienza, University of Rome; Technion; Sapienza, University of Rome + Technion + Sibylla",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;1;0+1+2",
        "aff_unique_norm": "University of Rome;Technion - Israel Institute of Technology;Sibylla",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uniroma1.it;https://www.technion.ac.il/en/;",
        "aff_unique_abbr": "Sapienza;Technion;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rome;",
        "aff_country_unique_index": "0;1;1;0;1;0+1",
        "aff_country_unique": "Italy;Israel;"
    },
    {
        "id": "6a83c7f395",
        "title": "Warped Diffusion for Latent Differentiation Inference",
        "site": "https://proceedings.mlr.press/v238/nakano24a.html",
        "author": "Masahiro Nakano; Hiroki Sakuma; Ryo Nishikimi; Ryohei Shibue; Takashi Sato; Tomoharu Iwata; Kunio Kashino",
        "abstract": "This paper proposes a Bayesian nonparametric diffusion model with a black-box warping function represented by a Gaussian process to infer potential diffusion structures latent in observed data, such as differentiation mechanisms of living cells and phylogenetic evolution processes of media information. In general, the task of inferring latent differentiation structures is very difficult to handle due to two interrelated settings. One is that the conversion mechanism between hidden structure and often higher dimensional observations is unknown (and is a complex mechanism). The other is that the topology of the hidden diffuse structure itself is unknown. Therefore, in this paper, we propose a BNP-based strategy as a natural way to deal with these two challenging settings simultaneously. Specifically, as an extension of the Gaussian process latent variable model, we propose a model in which the black box transformation from latent variable space to observed data space is represented by a Gaussian process, and introduce a BNP diffusion model for the latent variable space. We show its application to the visualization of the diffusion structure of media information and to the task of inferring cell differentiation structure from single-cell gene expression levels.",
        "bibtex": "@InProceedings{pmlr-v238-nakano24a,\n  title = \t {Warped Diffusion for Latent Differentiation Inference},\n  author =       {Nakano, Masahiro and Sakuma, Hiroki and Nishikimi, Ryo and Shibue, Ryohei and Sato, Takashi and Iwata, Tomoharu and Kashino, Kunio},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4789--4797},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nakano24a/nakano24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nakano24a.html},\n  abstract = \t {This paper proposes a Bayesian nonparametric diffusion model with a black-box warping function represented by a Gaussian process to infer potential diffusion structures latent in observed data, such as differentiation mechanisms of living cells and phylogenetic evolution processes of media information. In general, the task of inferring latent differentiation structures is very difficult to handle due to two interrelated settings. One is that the conversion mechanism between hidden structure and often higher dimensional observations is unknown (and is a complex mechanism). The other is that the topology of the hidden diffuse structure itself is unknown. Therefore, in this paper, we propose a BNP-based strategy as a natural way to deal with these two challenging settings simultaneously. Specifically, as an extension of the Gaussian process latent variable model, we propose a model in which the black box transformation from latent variable space to observed data space is represented by a Gaussian process, and introduce a BNP diffusion model for the latent variable space. We show its application to the visualization of the diffusion structure of media information and to the task of inferring cell differentiation structure from single-cell gene expression levels.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nakano24a/nakano24a.pdf",
        "supp": "",
        "pdf_size": 7100644,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:W6RqjL3OFTAJ:scholar.google.com/&scioq=Warped+Diffusion+for+Latent+Differentiation+Inference&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f06cb57ffa",
        "title": "Weight-Sharing Regularization",
        "site": "https://proceedings.mlr.press/v238/shakerinava24a.html",
        "author": "Mehran Shakerinava; Motahareh MS Sohrabi; Siamak Ravanbakhsh; Simon Lacoste-Julien",
        "abstract": "Weight-sharing is ubiquitous in deep learning. Motivated by this, we propose a \u201cweight-sharing regularization\u201d penalty on the weights $w \\in \\mathbb{R}^d$ of a neural network, defined as $\\mathcal{R}(w) = \\frac{1}{d - 1}\\sum_{i > j}^d |w_i - w_j|$. We study the proximal mapping of $\\mathcal{R}$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. We also parallelize existing algorithms for $\\mathrm{prox}_{\\mathcal{R}}$ (to run on GPU) and find that one of them is fast in practice but slow ($O(d)$) for worst-case inputs. Using the physical interpretation, we design a novel parallel algorithm which runs in $O(\\log^3 d)$ when sufficient processors are available, thus guaranteeing fast training. Our experiments reveal that weight-sharing regularization enables fully connected networks to learn convolution-like filters even when pixels have been shuffled while convolutional neural networks fail in this setting. Our code is available on \\href{https://github.com/motahareh-sohrabi/weight-sharing-regularization}{github}.",
        "bibtex": "@InProceedings{pmlr-v238-shakerinava24a,\n  title = \t {Weight-Sharing Regularization},\n  author =       {Shakerinava, Mehran and MS Sohrabi, Motahareh and Ravanbakhsh, Siamak and Lacoste-Julien, Simon},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4204--4212},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/shakerinava24a/shakerinava24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/shakerinava24a.html},\n  abstract = \t {Weight-sharing is ubiquitous in deep learning. Motivated by this, we propose a \u201cweight-sharing regularization\u201d penalty on the weights $w \\in \\mathbb{R}^d$ of a neural network, defined as $\\mathcal{R}(w) = \\frac{1}{d - 1}\\sum_{i > j}^d |w_i - w_j|$. We study the proximal mapping of $\\mathcal{R}$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. We also parallelize existing algorithms for $\\mathrm{prox}_{\\mathcal{R}}$ (to run on GPU) and find that one of them is fast in practice but slow ($O(d)$) for worst-case inputs. Using the physical interpretation, we design a novel parallel algorithm which runs in $O(\\log^3 d)$ when sufficient processors are available, thus guaranteeing fast training. Our experiments reveal that weight-sharing regularization enables fully connected networks to learn convolution-like filters even when pixels have been shuffled while convolutional neural networks fail in this setting. Our code is available on \\href{https://github.com/motahareh-sohrabi/weight-sharing-regularization}{github}.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/shakerinava24a/shakerinava24a.pdf",
        "supp": "",
        "pdf_size": 1058598,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17723140904080883077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3882ee7c40",
        "title": "When No-Rejection Learning is Consistent for Regression with Rejection",
        "site": "https://proceedings.mlr.press/v238/li24g.html",
        "author": "Xiaocheng Li; Shang Liu; Chunlin Sun; Hanzhao Wang",
        "abstract": "Learning with rejection has been a prototypical model for studying the human-AI interaction on prediction tasks. Upon the arrival of a sample instance, the model first uses a rejector to decide whether to accept and use the AI predictor to make a prediction or reject and defer the sample to humans. Learning such a model changes the structure of the original loss function and often results in undesirable non-convexity and inconsistency issues. For the classification with rejection problem, several works develop consistent surrogate losses for the joint learning of the predictor and the rejector, while there have been fewer works for the regression counterpart. This paper studies the regression with rejection (RwR) problem and investigates a no-rejection learning strategy that uses all the data to learn the predictor. We first establish the consistency for such a strategy under the weak realizability condition. Then for the case without the weak realizability, we show that the excessive risk can also be upper bounded with the sum of two parts: prediction error and calibration error. Lastly, we demonstrate the advantage of such a proposed learning strategy with empirical evidence.",
        "bibtex": "@InProceedings{pmlr-v238-li24g,\n  title = \t {When No-Rejection Learning is Consistent for Regression with Rejection},\n  author =       {Li, Xiaocheng and Liu, Shang and Sun, Chunlin and Wang, Hanzhao},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1126--1134},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/li24g/li24g.pdf},\n  url = \t {https://proceedings.mlr.press/v238/li24g.html},\n  abstract = \t {Learning with rejection has been a prototypical model for studying the human-AI interaction on prediction tasks. Upon the arrival of a sample instance, the model first uses a rejector to decide whether to accept and use the AI predictor to make a prediction or reject and defer the sample to humans. Learning such a model changes the structure of the original loss function and often results in undesirable non-convexity and inconsistency issues. For the classification with rejection problem, several works develop consistent surrogate losses for the joint learning of the predictor and the rejector, while there have been fewer works for the regression counterpart. This paper studies the regression with rejection (RwR) problem and investigates a no-rejection learning strategy that uses all the data to learn the predictor. We first establish the consistency for such a strategy under the weak realizability condition. Then for the case without the weak realizability, we show that the excessive risk can also be upper bounded with the sum of two parts: prediction error and calibration error. Lastly, we demonstrate the advantage of such a proposed learning strategy with empirical evidence.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/li24g/li24g.pdf",
        "supp": "",
        "pdf_size": 605858,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ynygHmaJ6tcJ:scholar.google.com/&scioq=When+No-Rejection+Learning+is+Consistent+for+Regression+with+Rejection&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4fa4fa006d",
        "title": "Why is parameter averaging beneficial in SGD? An objective smoothing perspective",
        "site": "https://proceedings.mlr.press/v238/nitanda24a.html",
        "author": "Atsushi Nitanda; Ryuhei Kikuchi; Shugo Maeda; Denny Wu",
        "abstract": "It is often observed that stochastic gradient descent (SGD) and its variants implicitly select a solution with good generalization performance; such implicit bias is often characterized in terms of the sharpness of the minima. Kleinberg et al. (2018) connected this bias with the smoothing effect of SGD which eliminates sharp local minima by the convolution using the stochastic gradient noise. We follow this line of research and study the commonly-used averaged SGD algorithm, which has been empirically observed in Izmailov et al. (2018) to prefer a flat minimum and therefore achieves better generalization. We prove that in certain problem settings, averaged SGD can efficiently optimize the smoothed objective which avoids sharp local minima. In experiments, we verify our theory and show that parameter averaging with an appropriate step size indeed leads to significant improvement in the performance of SGD.",
        "bibtex": "@InProceedings{pmlr-v238-nitanda24a,\n  title = \t {Why is parameter averaging beneficial in {SGD}? An objective smoothing perspective},\n  author =       {Nitanda, Atsushi and Kikuchi, Ryuhei and Maeda, Shugo and Wu, Denny},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3565--3573},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/nitanda24a/nitanda24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/nitanda24a.html},\n  abstract = \t {It is often observed that stochastic gradient descent (SGD) and its variants implicitly select a solution with good generalization performance; such implicit bias is often characterized in terms of the sharpness of the minima. Kleinberg et al. (2018) connected this bias with the smoothing effect of SGD which eliminates sharp local minima by the convolution using the stochastic gradient noise. We follow this line of research and study the commonly-used averaged SGD algorithm, which has been empirically observed in Izmailov et al. (2018) to prefer a flat minimum and therefore achieves better generalization. We prove that in certain problem settings, averaged SGD can efficiently optimize the smoothed objective which avoids sharp local minima. In experiments, we verify our theory and show that parameter averaging with an appropriate step size indeed leads to significant improvement in the performance of SGD.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/nitanda24a/nitanda24a.pdf",
        "supp": "",
        "pdf_size": 1700741,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:VxskKMp0_HoJ:scholar.google.com/&scioq=Why+is+parameter+averaging+beneficial+in+SGD%3F+An+objective+smoothing+perspective&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "IHPC, Agency for Science, Technology and Research, Singapore+CFAR, Agency for Science, Technology and Research, Singapore; Kyushu Institute of Technology, Japan; Kyushu Institute of Technology, Japan; New York University, United States+Flatiron Institute, United States",
        "aff_domain": "cfar.a-star.edu.sg;mail.kyutech.jp;mail.kyutech.jp;nyu.edu",
        "email": "cfar.a-star.edu.sg;mail.kyutech.jp;mail.kyutech.jp;nyu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;1;1;2+3",
        "aff_unique_norm": "Agency for Science, Technology and Research;Kyushu Institute of Technology;New York University;Flatiron Institute",
        "aff_unique_dep": "IHPC;;;",
        "aff_unique_url": "https://www.a-star.edu.sg;https://www.kyutech.ac.jp;https://www.nyu.edu;https://flatironinstitute.org",
        "aff_unique_abbr": "A*STAR;Kyutech;NYU;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;1;1;2+2",
        "aff_country_unique": "Singapore;Japan;United States"
    },
    {
        "id": "9fc18739b7",
        "title": "XB-MAML: Learning Expandable Basis Parameters for Effective Meta-Learning with Wide Task Coverage",
        "site": "https://proceedings.mlr.press/v238/lee24b.html",
        "author": "Jae-Jun Lee; Sung Whan Yoon",
        "abstract": "Meta-learning, which pursues an effective initialization model, has emerged as a promising approach to handling unseen tasks. However, a limitation remains to be evident when a meta-learner tries to encompass a wide range of task distribution, e.g., learning across distinctive datasets or domains. Recently, a group of works has attempted to employ multiple model initializations to cover widely-ranging tasks, but they are limited in adaptively expanding initializations. We introduce XB-MAML, which learns expandable basis parameters, where they are linearly combined to form an effective initialization to a given task. XB-MAML observes the discrepancy between the vector space spanned by the basis and fine-tuned parameters to decide whether to expand the basis. Our method surpasses the existing works in the multi-domain meta-learning benchmarks and opens up new chances of meta-learning for obtaining the diverse inductive bias that can be combined to stretch toward the effective initialization for diverse unseen tasks.",
        "bibtex": "@InProceedings{pmlr-v238-lee24b,\n  title = \t {{XB-MAML}: Learning Expandable Basis Parameters for Effective Meta-Learning with Wide Task Coverage},\n  author =       {Lee, Jae-Jun and Whan Yoon, Sung},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3196--3204},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/lee24b/lee24b.pdf},\n  url = \t {https://proceedings.mlr.press/v238/lee24b.html},\n  abstract = \t {Meta-learning, which pursues an effective initialization model, has emerged as a promising approach to handling unseen tasks. However, a limitation remains to be evident when a meta-learner tries to encompass a wide range of task distribution, e.g., learning across distinctive datasets or domains. Recently, a group of works has attempted to employ multiple model initializations to cover widely-ranging tasks, but they are limited in adaptively expanding initializations. We introduce XB-MAML, which learns expandable basis parameters, where they are linearly combined to form an effective initialization to a given task. XB-MAML observes the discrepancy between the vector space spanned by the basis and fine-tuned parameters to decide whether to expand the basis. Our method surpasses the existing works in the multi-domain meta-learning benchmarks and opens up new chances of meta-learning for obtaining the diverse inductive bias that can be combined to stretch toward the effective initialization for diverse unseen tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/lee24b/lee24b.pdf",
        "supp": "",
        "pdf_size": 3251392,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2060493053793081604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST); Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST)",
        "aff_domain": "unist.ac.kr;unist.ac.kr",
        "email": "unist.ac.kr;unist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology",
        "aff_unique_dep": "Graduate School of Artificial Intelligence",
        "aff_unique_url": "https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ulsan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "ac2fa431f6",
        "title": "autoMALA: Locally adaptive Metropolis-adjusted Langevin algorithm",
        "site": "https://proceedings.mlr.press/v238/biron-lattes24a.html",
        "author": "Miguel Biron-Lattes; Nikola Surjanovic; Saifuddin Syed; Trevor Campbell; Alexandre Bouchard-Cote",
        "abstract": "Selecting the step size for the Metropolis-adjusted Langevin algorithm (MALA) is necessary in order to obtain satisfactory performance. However, finding an adequate step size for an arbitrary target distribution can be a difficult task and even the best step size can perform poorly in specific regions of the space when the target distribution is sufficiently complex. To resolve this issue we introduce autoMALA, a new Markov chain Monte Carlo algorithm based on MALA that automatically sets its step size at each iteration based on the local geometry of the target distribution. We prove that autoMALA has the correct invariant distribution, despite continual automatic adjustments of the step size. Our experiments demonstrate that autoMALA is competitive with related state-of-the-art MCMC methods, in terms of the number of log density evaluations per effective sample, and it outperforms state-of-the-art samplers on targets with varying geometries. Furthermore, we find that autoMALA tends to find step sizes comparable to optimally-tuned MALA when a fixed step size suffices for the whole domain.",
        "bibtex": "@InProceedings{pmlr-v238-biron-lattes24a,\n  title = \t {{autoMALA}: Locally adaptive {M}etropolis-adjusted {L}angevin algorithm},\n  author =       {Biron-Lattes, Miguel and Surjanovic, Nikola and Syed, Saifuddin and Campbell, Trevor and Bouchard-Cote, Alexandre},\n  booktitle = \t {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4600--4608},\n  year = \t {2024},\n  editor = \t {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},\n  volume = \t {238},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {02--04 May},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v238/biron-lattes24a/biron-lattes24a.pdf},\n  url = \t {https://proceedings.mlr.press/v238/biron-lattes24a.html},\n  abstract = \t {Selecting the step size for the Metropolis-adjusted Langevin algorithm (MALA) is necessary in order to obtain satisfactory performance. However, finding an adequate step size for an arbitrary target distribution can be a difficult task and even the best step size can perform poorly in specific regions of the space when the target distribution is sufficiently complex. To resolve this issue we introduce autoMALA, a new Markov chain Monte Carlo algorithm based on MALA that automatically sets its step size at each iteration based on the local geometry of the target distribution. We prove that autoMALA has the correct invariant distribution, despite continual automatic adjustments of the step size. Our experiments demonstrate that autoMALA is competitive with related state-of-the-art MCMC methods, in terms of the number of log density evaluations per effective sample, and it outperforms state-of-the-art samplers on targets with varying geometries. Furthermore, we find that autoMALA tends to find step sizes comparable to optimally-tuned MALA when a fixed step size suffices for the whole domain.}\n}",
        "pdf": "https://proceedings.mlr.press/v238/biron-lattes24a/biron-lattes24a.pdf",
        "supp": "",
        "pdf_size": 3839496,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11271142464812413897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of British Columbia; University of British Columbia; University of Oxford; University of British Columbia; University of British Columbia",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of British Columbia;University of Oxford",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ubc.ca;https://www.ox.ac.uk",
        "aff_unique_abbr": "UBC;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Canada;United Kingdom"
    }
]