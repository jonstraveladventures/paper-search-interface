[
    {
        "id": "9981519",
        "title": "2D vs. 3D LiDAR-based Person Detection on Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Person detection is a crucial task for mobile robots navigating in human-populated environments. LiDAR sensors are promising for this task, thanks to their accurate depth measurements and large field of view. Two types of LiDAR sensors exist: the 2D LiDAR sensors, which scan a single plane, and the 3D LiDAR sensors, which scan multiple planes, thus forming a volume. How do they compare for the task of person detection? To answer this, we conduct a series of exper-iments, using the public, large-scale JackRabbot dataset and the state-of-the-art 2D and 3D LiDAR-based person detectors (DR-SPAAM and CenterPoint respectively). Our experiments include multiple aspects, ranging from the basic performance and speed comparison, to more detailed analysis on localization accuracy and robustness against distance and scene clutter. The insights from these experiments highlight the strengths and weaknesses of 2D and 3D LiDAR sensors as sources for person detection, and are especially valuable for designing mobile robots that will operate in close proximity to surrounding humans (e.g. service or social robot).",
        "primary_area": "",
        "author": "Dan Jia;Alexander Hermans;Bastian Leibe;Dan Jia;Alexander Hermans;Bastian Leibe",
        "authorids": "/37088688308;/37085358298;/37298473000;/37088688308;/37085358298;/37298473000",
        "aff": "Visual Computing Institute, RWTH, Aachen; Visual Computing Institute, RWTH, Aachen; Visual Computing Institute, RWTH, Aachen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981519/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10636131852827358985&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "RWTH Aachen University",
        "aff_unique_dep": "Visual Computing Institute",
        "aff_unique_url": "https://www.rwth-aachen.de",
        "aff_unique_abbr": "RWTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982142",
        "title": "360ST-Mapping: An Online Semantics-Guided Topological Mapping Module for Omnidirectional Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "As an abstract representation of the environment structure, a topological map has advantageous properties for path-planning and navigation. Here we proposed an online topological mapping method, 360ST-Mapping, using omnidirectional vision. The 360\u00b0 field-of-view allows the agent to obtain consistent observation and incrementally extract topological environment information. Moreover, we leverage semantic infor-mation to guide topological place recognition, further improving performance. The topological map possessing semantic infor-mation has the potential to support semantics-related advanced tasks. After integrating the topological mapping module into the omnidirectional visual SLAM system, we conducted extensive experiments in several large-scale indoor scenes and validated the method's effectiveness.",
        "primary_area": "",
        "author": "Hongji Liu;Huajian Huang;Sai-Kit Yeung;Ming Liu;Hongji Liu;Huajian Huang;Sai-Kit Yeung;Ming Liu",
        "authorids": "/37089658505;/37088691434;/37529101500;/37085398677;/37089658505;/37088691434;/37529101500;/37085398677",
        "aff": "The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Department of Computer Science and Engineering, The Hong Kong University of Science and Technology; The Department of Computer Science and Engineering, The Hong Kong University of Science and Technology; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982142/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9469748834704603783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Hong Kong;Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982265",
        "title": "3D Human Pose Estimation in Weightless Environments Using a Fisheye Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Three-dimensional (3D) human pose estimation is one of the most basic tasks for human-interacting robots. Especially in weightless environments such as the International Space Station (ISS), wherein objects may move with a higher degree of freedom compared to on the ground, a camera with a wider field of view (FOV) is crucial in improving the probability of capturing surrounding humans. To this end, we propose a learning-based 3D human pose estimation (3D-HPE) using a fisheye camera targeted at weightless environments. One impediment is that 3D-HPE trained on existing datasets are incapable of addressing the adverse effects of strong fisheye distortion and weightlessness as existing human detection and pose estimation datasets are recorded on the ground using typical rectilinear cameras. To overcome this difficulty, we integrate virtual camera projection to perform a detected human-centered undistortion from fisheye to rectilinear images. We also include upside-down augmentation during training to improve the performance toward weightlessness. Our results show that these two techniques successfully mitigate the adverse effects of weightlessness and fisheye distortion.",
        "primary_area": "",
        "author": "Koji Minoda;Takehisa Yairi;Koji Minoda;Takehisa Yairi",
        "authorids": "/37088761095;/37270951700;/37088761095;/37270951700",
        "aff": "Department of Aeronautics and Astronautics, Artificial Intelligence Laboratory, University of Tokyo, Tokyo, Japan; Department of Aeronautics and Astronautics, Artificial Intelligence Laboratory, University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982265/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10712027085220670709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981531",
        "title": "3D Lidar Reconstruction with Probabilistic Depth Completion for Robotic Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe motion planning in robotics requires planning into space which has been verified to be free of obstacles. However, obtaining such environment representations using lidars is challenging by virtue of the sparsity of their depth measurements. We present a learning-aided 3D lidar reconstruction framework that upsamples sparse lidar depth measurements with the aid of overlapping camera images so as to generate denser reconstructions with more definitively free space than can be achieved with the raw lidar measurements alone. We use a neural network with an encoder-decoder structure to predict dense depth images along with depth uncertainty estimates which are fused using a volumetric mapping system. We conduct experiments on real-world outdoor datasets captured using a handheld sensing device and a legged robot. Using input data from a 16-beam lidar mapping a building network, our experiments showed that the amount of estimated free space was increased by more than 40% with our approach. We also show that our approach trained on a synthetic dataset generalises well to real-world outdoor scenes without additional fine-tuning. Finally, we demonstrate how motion planning tasks can benefit from these denser reconstructions.",
        "primary_area": "",
        "author": "Yifu Tao;Marija Popovi\u0107;Yiduo Wang;Sundara Tejaswi Digumarti;Nived Chebrolu;Maurice Fallon;Yifu Tao;Marija Popovi\u0107;Yiduo Wang;Sundara Tejaswi Digumarti;Nived Chebrolu;Maurice Fallon",
        "authorids": "/37089659819;/37086001290;/37088689824;/37085517244;/37086411047;/37540365100;/37089659819;/37086001290;/37088689824;/37085517244;/37086411047;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981531/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1158372385968777701&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "University of Oxford;University of Bonn",
        "aff_unique_dep": "Oxford Robotics Institute;Institute of Geodesy and Geoinformation",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.uni-bonn.de",
        "aff_unique_abbr": "Oxford;Uni Bonn",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9981590",
        "title": "3D Object Aided Self-Supervised Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation has been actively studied in fields such as robot vision, autonomous driving, and 3D scene understanding. Given a sequence of color images, unsupervised learning methods based on the framework of Structure-From-Motion (SfM) simultaneously predict depth and camera relative pose. However, dynamically moving objects in the scene violate the static world assumption, resulting in inaccurate depths of dynamic objects. In this work, we propose a new method to address such dynamic object movements through monocular 3D object detection. Specifically, we first detect 3D objects in the images and build the per-pixel correspondence of the dynamic pixels with the detected object pose while leaving the static pixels corresponding to the rigid background to be modeled with camera motion. In this way, the depth of every pixel can be learned via a meaningful geometry model. Besides, objects are detected as cuboids with absolute scale, which is used to eliminate the scale ambiguity problem inherent in monocular vision. Experiments on the KITTI depth dataset show that our method achieves State-of-The-Art performance for depth estimation. Furthermore, joint training of depth, camera motion and object pose also improves monocular 3D object detection performance. To the best of our knowledge, this is the first work that allows a monocular 3D object detection network to be fine-tuned in a self-supervised manner.",
        "primary_area": "",
        "author": "Songlin Wei;Guodong Chen;Wenzheng Chi;Zhenhua Wang;Lining Sun;Songlin Wei;Guodong Chen;Wenzheng Chi;Zhenhua Wang;Lining Sun",
        "authorids": "/37089507962;/37085895073;/38580627700;/38466869900;/37273265800;/37089507962;/37085895073;/38580627700;/38466869900;/37273265800",
        "aff": "Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981590/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3553027068038112269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Soochow University",
        "aff_unique_dep": "School of Mechanical and Electric Engineering",
        "aff_unique_url": "http://www.soochow.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Suzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981905",
        "title": "3D Single-Object Tracking with Spatial-Temporal Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel 3D single-object tracker to more stably, accurately, and faster track objects, even if they are temporarily missed. Our idea is to utilize spatial-temporal data association to achieve object tracking robustly, and it consists of two main parts. We firstly employ a temporal motion model cross frames to estimate the object's temporal information and update the region of interest(ROI). The advanced detector only focuses on ROI rather than the whole scene to generate the spatial position. Second, we introduce a new pairwise evaluation system to exploit spatial-temporal data association in point clouds. The proposed evaluation system considers detection confidence, orientation offset, and objects distance to more stably achieve object matching. Then, we update the predicted state based on the pairwise spatial-temporal data. Finally, we utilize the previous trajectory to enhance the accuracy of static tracking in the refinement scheme. Experiments on the KITTI and nuScenes tracking datasets demonstrate that our method outperforms other state-of-the-art methods by a large margin (a 10% improvement and 280 FPS on a single NVIDIA 1080Ti GPU). Compared with multi-object tracking, our tracker also has superiority.",
        "primary_area": "",
        "author": "Yongchang Zhang;Hanbing Niu;Yue Guo;Wenhao He;Yongchang Zhang;Hanbing Niu;Yue Guo;Wenhao He",
        "authorids": "/37089579426;/37089579324;/37085844519;/37532766700;/37089579426;/37089579324;/37085844519;/37532766700",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981905/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16284604426023902578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;University of Electronic Science and Technology of China;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;;Institute of Automation",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.uestc.edu.cn;http://www.ia.cas.cn",
        "aff_unique_abbr": "UCAS;UESTC;CAS",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Beijing;Chengdu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982197",
        "title": "3D visual-based tension control in strip-like deformable objects using a catenary model",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there has been a growing interest in robotic manipulation of deformable objects. In order to perform certain tasks, the robot must control the shape of the object while taking care not to apply excessive stresses so as not to deform it irreversibly. This is the case when extracting elasto-plastic objects in strips from an industrial reel. In order to control the mechanical stresses within the object, we propose a vision-based control scheme to minimize tension by regulating the angular velocity of a motorized reel on which they are wound. In this paper, we propose a method, based on a catenary model and visual feedback from a low-cost RGB-D camera, to estimate the tension distribution along a rubber strip. Thus, the control strategy aims to achieve a desired tension value by varying the length of the suspended portion of the manipulated strip. Simulation and experimental results validate the proposed approach for strip-like objects of various dimensions.",
        "primary_area": "",
        "author": "N. Roca Filella;A. Koessler;B.C. Bouzgarrou;J.-A. Corrales Ramon;N. Roca Filella;A. Koessler;B.C. Bouzgarrou;J.-A. Corrales Ramon",
        "authorids": "/37088998534;/37086180046;/37078602100;/37086353284;/37088998534;/37086180046;/37078602100;/37086353284",
        "aff": "Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; Universit\u00e9 de Lorraine, Arts et Metiers Institute of Technology, LCFC, HESAM Universit\u00e9, Metz, France; Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, SPAIN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982197/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1850240259053305910&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;Universit\u00e9 de Lorraine;Universidade de Santiago de Compostela",
        "aff_unique_dep": ";;Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS)",
        "aff_unique_url": "https://www.uca.fr;https://www.univ-lorraine.fr;https://www.usc.es",
        "aff_unique_abbr": "UCA;UL;USC",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Clermont-Ferrand;Metz;Santiago de Compostela",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;Spain"
    },
    {
        "id": "9982006",
        "title": "3D-printable low-reduction cycloidal gearing for robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent trend towards low reduction gearing in robotic actuation has revitalised the need for high-performance gearing concepts. In this work we propose compact low-reduction cycloidal gearing, that is 3D-printable and combined with off-the-shelf components. This approach presents an enormous potential for high performance-to-cost implementations. After discussing parameter selection and design considerations, we present a prototype that is combined with a low-cost brushless motor to demonstrate its potential. Extensive experimental results demonstrate high performance, including >40Nm torque, low friction and play, and high impact robustness. The results show that the proposed approach can yield viable gearbox designs.",
        "primary_area": "",
        "author": "Wesley Roozing;Glenn Roozing;Wesley Roozing;Glenn Roozing",
        "authorids": "/37073342300;/37089658802;/37073342300;/37089658802",
        "aff": "Robotics & Mechatronics (RaM) group, University of Twente, The Netherlands; Auto Elect B.V., The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982006/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14982276838787419543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Twente;Auto Elect B.V.",
        "aff_unique_dep": "Robotics & Mechatronics (RaM) group;",
        "aff_unique_url": "https://www.utwente.nl;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9981838",
        "title": "6-DoF Pose Estimation of Household Objects for Robotic Manipulation: An Accessible Dataset and Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new dataset for 6-DoF pose estimation of known objects, with a focus on robotic manipulation research. We propose a set of toy grocery objects, whose physical instantiations are readily available for purchase and are appropriately sized for robotic grasping and manipulation. We provide 3D scanned textured models of these objects, suitable for generating synthetic training data, as well as RGBD images of the objects in challenging, cluttered scenes exhibiting partial occlusion, extreme lighting variations, multiple instances per image, and a large variety of poses. Using semi-automated RGBD-to-model texture correspondences, the images are annotated with ground truth poses accurate within a few millimeters. We also propose a new pose evaluation metric called ADD-H based on the Hungarian assignment algorithm that is robust to symmetries in object geometry without requiring their explicit enumeration. We share pre-trained pose estimators for all the toy grocery objects, along with their baseline performance on both validation and test sets. We offer this dataset to the community to help connect the efforts of computer vision researchers with the needs of roboticists.11https://github.com/swtyree/hope-dataset",
        "primary_area": "",
        "author": "Stephen Tyree;Jonathan Tremblay;Thang To;Jia Cheng;Terry Mosier;Jeffrey Smith;Stan Birchfield;Stephen Tyree;Jonathan Tremblay;Thang To;Jia Cheng;Terry Mosier;Jeffrey Smith;Stan Birchfield",
        "authorids": "/37074894100;/37086455314;/37086454929;/37088505823;/37088504181;/37086317886;/37371627300;/37074894100;/37086455314;/37086454929;/37088505823;/37088504181;/37086317886;/37371627300",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981838/",
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16994260591037461441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA Corporation",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982262",
        "title": "6D Robotic Assembly Based on RGB-only Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based robotic assembly is a crucial yet challenging task as the interaction with multiple objects requires high levels of precision. In this paper, we propose an integrated 6D robotic system to perceive, grasp, manipulate and assemble blocks with tight tolerances. Aiming to provide an off-the-shelf RGB-only solution, our system is built upon a monocular 6D object pose estimation network trained solely with synthetic images leveraging physically-based rendering. Subsequently, pose-guided 6D transformation along with collision-free assembly is proposed to construct any designed structure with arbitrary initial poses. Our novel 3-axis calibration operation further enhances the precision and robustness by disentangling 6D pose estimation and robotic assembly. Both quantitative and qualitative results demonstrate the effectiveness of our proposed 6D robotic assembly system.",
        "primary_area": "",
        "author": "Bowen Fu;Sek Kun Leong;Xiaocong Lian;Xiangyang Ji;Bowen Fu;Sek Kun Leong;Xiaocong Lian;Xiangyang Ji",
        "authorids": "/37089659713;/37089661964;/37085378062;/37271425200;/37089659713;/37089661964;/37085378062;/37271425200",
        "aff": "Department of Automation and BNRist, Tsinghua University, Beijing, China; Department of Automation and BNRist, Tsinghua University, Beijing, China; Department of Automation and BNRist, Tsinghua University, Beijing, China; Department of Automation and BNRist, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982262/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4615323390853044955&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation and BNRist",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982254",
        "title": "A 2D Georeferenced Map Aided Visual-Inertial System for Precise UAV Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise geolocalization is crucial for unmanned aerial vehicles (UAVs). However, most current deployed UAVs rely on the global navigation satellite systems (GNSS) for geolocalization. In this paper, we propose to use a lightweight visual-inertial system with a 2D georeferenced map to obtain accurate geodetic positions for UAVs. The proposed system firstly integrates a micro inertial measurement unit (MIMU) and a monocular camera to build a visual-inertial odometry (VIO) to consecutively estimate the UAV's motion states and reconstruct the 3D position of the observed visual features in the local world frame. To obtain the geolocation, the visual features tracked by the odometry are further registered to the 2D georeferenced map. While most conventional methods perform image-level aerial image registration, we propose to align the reconstructed 3D points with the map, and then use the registered 3D points to relocalize the vehicle in the geodetic frame, which helps to improve the geolocalization accuracy. Finally, a pose graph is deployed to fuse the geolocation from the point registration and the local navigation result from the visual-inertial odometry (VIO) to obtain smooth and drift-free geolocalization results. We have validated the proposed method by installing the sensors to a UAV body rigidly and have conducted two real-world flights in different environments with unknown initials. The results show that the proposed method can achieve less than 4m position error in flight at about 100m high and less than 9m position error in flight at about 300m high.",
        "primary_area": "",
        "author": "Mao Jun;Zhang Lilian;He Xiaofeng;Qu Hao;Hu Xiaoping;Mao Jun;Zhang Lilian;He Xiaofeng;Qu Hao;Hu Xiaoping",
        "authorids": "/37089658843;/37089658144;/37700652500;/37089661031;/37545582400;/37089658843;/37089658144;/37700652500;/37089661031;/37545582400",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982254/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3830851029887034484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981362",
        "title": "A Biologically-Inspired Simultaneous Localization and Mapping System Based on LiDAR Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) is one of the essential techniques and functionalities used by robots to perform autonomous navigation tasks. Inspired by the rodent hippocampus, this paper presents a biologically inspired SLAM system based on a LiDAR sensor using a hippocampal model to build a cognitive map and estimate the robot pose in indoor environments. Based on the biologically inspired models mimicking boundary cells, place cells, and head direction cells, the SLAM system using LiDAR point cloud data is capable of leveraging the self-motion cues from the LiDAR odometry and the boundary cues from the LiDAR boundary cells to build a cognitive map and estimate the robot pose. Experiment results show that with the LiDAR boundary cells the proposed SLAM system greatly outperforms the camera-based brain-inspired method in both simulation and indoor environments, and is competitive with the conventional LiDAR-based SLAM methods.",
        "primary_area": "",
        "author": "Genghang Zhuang;Zhenshan Bing;Yuhong Huang;Kai Huang;Alois Knoll;Genghang Zhuang;Zhenshan Bing;Yuhong Huang;Kai Huang;Alois Knoll",
        "authorids": "/37089009426;/37085994830;/37086357051;/37534912900;/37276234100;/37089009426;/37085994830;/37086357051;/37534912900;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Pazhou Laboratory, China; Department of Informatics, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981362/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1352151133187914827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Pazhou Laboratory",
        "aff_unique_dep": "Department of Informatics;",
        "aff_unique_url": "https://www.tum.de;",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9981783",
        "title": "A Camera-based Deep-Learning Solution for Visual Attention Zone Recognition in Maritime Navigational Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "The visual attention of navigators is imperative to understand the logic of navigation as well as the surveillance of navigators' status and operation. Current studies are implemented with the help of wearable eye-tracker glasses; yet, the high expenditure demanded by such equipment and service and its limitations on usability have impeded related research from further development. In this letter, the authors propose a framework, which is the first attempt in the maritime domain, to provide a camera-based deep-learning (CaBDeeL) visual attention recognition solution that outperforms the intrusive eye tracker regarding its shortcomings. A wide-angle camera is configured in front of the navigator in the advanced ship-bridge simulator in a way that visual attention reflected by their facial and head movements is captured in the front view. A pair of eye-tracker glasses is used to classify the captured visual attention images, which then form the primary database. During the process of classifying camera-captured images, a convolutional neural network (CNN) is built as an automatic classifier. The CNN is applied to two scenarios, and it shows an overall 95 % accuracy.",
        "primary_area": "",
        "author": "Baiheng Wu;Peihua Han;Motoyasu Kanazawa;Hans Petter Hildre;Luman Zhao;Houxiang Zhang;Guoyuan Li;Baiheng Wu;Peihua Han;Motoyasu Kanazawa;Hans Petter Hildre;Luman Zhao;Houxiang Zhang;Guoyuan Li",
        "authorids": "/37088549414;/37088506262;/37089165447;/37946148000;/37088550200;/37085775728;/37085769271;/37088549414;/37088506262;/37089165447;/37946148000;/37088550200;/37085775728;/37085769271",
        "aff": "Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway; Department of Ocean Operations and Civil Engineering (IHB), Norwegian University of Science and Technology (NTNU), \u00c5lesund, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981783/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10114277684702787080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology",
        "aff_unique_dep": "Department of Ocean Operations and Civil Engineering",
        "aff_unique_url": "https://www.ntnu.edu",
        "aff_unique_abbr": "NTNU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "\u00c5lesund",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9981394",
        "title": "A Centaur System for Assisting Human Walking with Load Carriage",
        "track": "main",
        "status": "Poster",
        "abstract": "Walking with load is a common task in daily life and disaster rescue. Long-term load carriage may cause irreversible damage to the human body. Although remarkable progress has been made in the field of wearable robots, it is still far from avoiding interference to human legs, which will lead to energy consumption. In this paper, a novel wearable robot, Centaur, for assisting load carriage has been proposed. The Centaur system consists of two rigid robotic legs of two degrees-of-freedom (DOFs) to transfer load weight to the ground. Different from exoskeletons, the robotic legs of the Centaur are placed behind the human rather than attached to human limbs, which can provide a larger support polygon and avoid additional interference to the wearer. Additionally, the Centaur can attain the locomotion stability of the quadruped while maintaining the motion agility of the biped itself. This paper also presents an interactive motion control strategy based on the human-robot interaction force. This control strategy incorporates legged robotics walking controller and real-time walking trajectory planning to realize the cooperative walking with human beings. Finally, experiments of human walking with load carriage have been conducted on flat terrain to verify the concept of the Centaur system. The result demonstrates that the Centaur system can effectively reduce 70.03% of load weight during the single stance phase, which indicates that the Centaur system provides a new solution for assisting human walking with load-carriage.",
        "primary_area": "",
        "author": "Ping Yang;Haoyun Yan;Bowen Yang;Jianquan Li;Kailin Li;Yuquan Leng;Chenglong Fu;Ping Yang;Haoyun Yan;Bowen Yang;Jianquan Li;Kailin Li;Yuquan Leng;Chenglong Fu",
        "authorids": "/37089619624;/37089663032;/37089464269;/37089663006;/37089662353;/37088505398;/37086455883;/37089619624;/37089663032;/37089464269;/37089663006;/37089662353;/37088505398;/37086455883",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China; Department of Automation, Wuhan University of Technology, Wuhan, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems and Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981394/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6916493414319483374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;Wuhan University of Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering;Department of Automation",
        "aff_unique_url": "https://www.sustech.edu.cn;http://www.wut.edu.cn",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981787",
        "title": "A Compact, Lightweight and Singularity-Free Wrist Joint Mechanism for Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Building humanoid robots with properties similar to those of humans in terms of strength and agility is a great and unsolved challenge. This work introduces a compact and lightweight wrist joint mechanism that is singularity-free and has large range of motion. The mechanism provides two degrees of freedom (DoF) and was developed for integration into a human scale humanoid robot arm. It is based on a parallel mechanism with rolling contact joint behaviour and remote actuation that facilitates a compact design with low mass and inertia. The mechanism's kinematics along with a solution of the inverse kinematics problem for the specific design, and the manipulability analysis are presented. The first prototype of the proposed mechanism shows the possible integration of actuation, sensing and electronics in small and narrow space. Experimental evaluations shows that the design feature unique performance regarding weight, speed, payload and accuracy.",
        "primary_area": "",
        "author": "Cornelius Klas;Tamim Asfour;Cornelius Klas;Tamim Asfour",
        "authorids": "/37088721742;/37295529100;/37088721742;/37295529100",
        "aff": "High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany; High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981787/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15117250899127468992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981321",
        "title": "A Comparative Study of Force Observers For Accurate Force Control of Multisensor-Based Force Controlled Motion Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a comprehensive comparative study of the multisensor-based force observers for accurate force control. A force controlled system which contains a force sensor for measuring force transmitted to the load by the motor and an encoder for measuring motor position is considered as the general multisensor-based motion system in this study. Even though these multisensor-based motion systems are emerging as potential motion systems as the demands for collaborative robots increase, there has been few studies that investigate their advantages and limitations. to address this issue, three types of observer-based force controllers that utilize the multisensors are designed and implemented. These controllers exploit the availability of force sensor, motor encoder, and motor torque information from the multisensor-based motion system to estimate accurate force which is later utilized to close the feedback loop. Mathematical and quantitative analyses are conducted to compare performances of the proposed observer-based force control and through this, their advantages and limitations are pointed out. Finally, simulation and an experimental case study with an actual robot are conducted to validate the force tracking performance of the designed force control systems.",
        "primary_area": "",
        "author": "Kangwagye Samuel;Sehoon Oh;Kangwagye Samuel;Sehoon Oh",
        "authorids": "/37086293662;/37279132500;/37086293662;/37279132500",
        "aff": "Department of Robotics and Mechatronics Engineering, DGIST, Daegu, Korea; Department of Robotics and Mechatronics Engineering, DGIST, Daegu, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981321/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9707421632194861274&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981467",
        "title": "A Composable Framework for Policy Design, Learning, and Transfer Toward Safe and Efficient Industrial Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "Delicate industrial insertion tasks (e.g., PC board assembly) remain challenging for industrial robots. The chal-lenges include low error tolerance, delicacy of the components, and large task variations with respect to the components to be inserted. To deliver a feasible robotic solution for these insertion tasks, we also need to account for hardware limits of existing robotic systems and minimize the integration effort. This paper proposes a composable framework for efficient integration of a safe insertion policy on existing robotic platforms to accomplish these insertion tasks. The policy has an interpretable modularized design and can be learned efficiently on hardware and transferred to new tasks easily. In particular, the policy includes a safe insertion agent as a baseline policy for insertion, an optimal configurable Cartesian tracker as an interface to robot hardware, a probabilistic inference module to handle component variety and insertion errors, and a safe learning module to optimize the parameters in the aforementioned modules to achieve the best performance on designated hard-ware. The experiment results on a URIO robot show that the proposed framework achieves safety (for the delicacy of components), accuracy (for low tolerance), robustness (against perception error and component defection), adaptability and transferability (for task variations), as well as task efficiency during execution plus data and time efficiency during learning.",
        "primary_area": "",
        "author": "Rui Chen;Chenxi Wang;Tianhao Wei;Changliu Liu;Rui Chen;Chenxi Wang;Tianhao Wei;Changliu Liu",
        "authorids": "/37088952173;/37089663390;/37086964129;/37085543217;/37088952173;/37089663390;/37086964129;/37085543217",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981467/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1304949598219874402&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982164",
        "title": "A Configurable Skill Oriented Architecture Based on OPC UA",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last years, research done in automation and industrial robotics has established the foundations for skill-oriented systems based on the OPC UA standard. Nevertheless, utilizing these advances in other areas of robotics research can be challenging and time consuming. We present a framework aiming to reduce this entry threshold. Our solution is an open source, easy to configure tool based on OPC UA, that provides with a hardware agnostic, skill-oriented, event driven interface to systems. The framework allows integrating external hardware and software by means of plugins. It also provides a mechanism for endowing skills with hardware agnostic motion control. We demonstrate how our framework can be combined with state of the art approaches to control in a simulated assembly task with multiple robots, conveyors, actuators and sensors involved.",
        "primary_area": "",
        "author": "Jorge Blesa Gracia;Felix Leber;Mohamed Aburaia;Wilfried W\u00f6ber;Jorge Blesa Gracia;Felix Leber;Mohamed Aburaia;Wilfried W\u00f6ber",
        "authorids": "/37089661919;/37086929801;/37087320191;/37087320594;/37089661919;/37086929801;/37087320191;/37087320594",
        "aff": "Department of Industrial Engineering, University of Applied Sciences Technikum, Wien, Austria; Department of Industrial Engineering, University of Applied Sciences Technikum, Wien, Austria; Department of Industrial Engineering, University of Applied Sciences Technikum, Wien, Austria; Department of Integrative Biology and Biodiversity Research, University of Natural Resources and Life Sciences, Institute for Integrative Nature Conservation Research, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982164/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12731506041136730034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Applied Sciences Technikum Wien;University of Natural Resources and Life Sciences",
        "aff_unique_dep": "Department of Industrial Engineering;Department of Integrative Biology and Biodiversity Research",
        "aff_unique_url": "https://www technikum-wien.at;https://www.boku.ac.at",
        "aff_unique_abbr": "TUW;BOKU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Wien;Vienna",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9981185",
        "title": "A Contact-Safe Reinforcement Learning Framework for Contact-Rich Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning shows great potential to solve complex contact-rich robot manipulation tasks. However, the safety of using RL in the real world is a crucial problem, since unexpected dangerous collisions might happen when the RL policy is imperfect during training or in unseen scenarios. In this paper, we propose a contact-safe reinforcement learning framework for contact-rich robot manipulation, which maintains safety in both the task space and joint space. When the RL policy causes unexpected collisions between the robot arm and the environment, our framework is able to immediately detect the collision and ensure the contact force to be small. Furthermore, the end-effector is enforced to perform contact-rich tasks compliantly, while keeping robust to external disturbances. We train the RL policy in simulation and transfer it to the real robot. Real world experiments on robot wiping tasks show that our method is able to keep the contact force small both in task space and joint space even when the policy is under unseen scenario with unexpected collision, while rejecting the disturbances on the main task.",
        "primary_area": "",
        "author": "Xiang Zhu;Shucheng Kang;Jianyu Chen;Xiang Zhu;Shucheng Kang;Jianyu Chen",
        "authorids": "/37089660056;/37089664060;/37086004703;/37089660056;/37089664060;/37086004703",
        "aff": "institute for interdisciplinary information sciences, Tsinghua University, Beijing, China; institute for interdisciplinary information sciences, Tsinghua University, Beijing, China; Shanghai Qizhi Insitute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981185/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10446408048886654039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Tsinghua University;Shanghai Qizhi Institute",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "Tsinghua;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981571",
        "title": "A Control Architecture of a Distributed Actuator System for a Bio-Inspired Spine",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of an articulated spine is important for humanoids' dynamic and balanced motion. Although there have been many spinal structures for humanoids, their actuation is still limited due to the usage of geared motors for joints. This paper introduces position control of a distributed electrome-chanical spine in a vertical plane. The spine dynamics model is approximated as an open chain. Gravitational and spring torques are compensated for the control. Moreover, torque-to-current conversion for the actuator is developed. Experimental results show the implemented control of the electromechanical spine for undulatory motions.",
        "primary_area": "",
        "author": "Bonhyun Ku;Arijit Banerjee;Bonhyun Ku;Arijit Banerjee",
        "authorids": "/37086932307;/38496446600;/37086932307;/38496446600",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981571/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18244651648950352277&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981782",
        "title": "A Creeping Snake-like Robot with Partial Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Enlightened by the creeping gait of natural snakes, snake-like robots swing joints side to side at similar tracks for generating propelling forces. However, it is not always essential to control all joints of a snake-like robot to realize the creeping gait. Therefore, in this paper, a creeping snake-like robot with partially actuated joints has been investigated, towards reducing the redundancy caused by full actuation. Essentially, this approach is composed of the following two concepts: 1) joint equipped with torsion spring mechanism bridges the passive joint to generate rhythm oscillation, and 2) harmonic joint trajectories assist the robot in generating more efficient locomotion. We hereafter demonstrated that the actuated joint dominates passive dynamics of the system, which contributes to overall motion. Meanwhile, different spring stiffness affects the motion performance. Additionally, the interaction between robot and environment through Coulomb friction has been considered to reveal the contributing factors that assist the snake-like robot to yield better locomotion performance.",
        "primary_area": "",
        "author": "Yiming Cao;Longchuan Li;Shugen Ma;Yiming Cao;Longchuan Li;Shugen Ma",
        "authorids": "/37089660657;/37086240920;/37280187400;/37089660657;/37086240920;/37280187400",
        "aff": "Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981782/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12195100589752130235&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ritsumeikan University;Beijing University of Chemical Technology",
        "aff_unique_dep": "Graduate School of Science and Engineering;College of Information Science and Technology",
        "aff_unique_url": "https://www.ritsumei.ac.jp;http://www.buct.edu.cn",
        "aff_unique_abbr": "Ritsumeikan;BUCT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Kusatsu;Beijing",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9981719",
        "title": "A Dataset and Benchmark for Learning the Kinematics of Concentric Tube Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Establishing a physics-based model capturing the kinetostatic behavior of concentric tube continuum robots is challenging as elastic interactions between the flexible tubes constituting the robot result in a highly non-linear problem. The Goldstandard physics-based model using the Cosserat theory of elastic rods achieves reasonable approximations with 1.5 - 3 % with respect to the robot's length, if well-calibrated. Learning-based models of concentric tube continuum robots have been shown to outperform the Goldstandard model with approximation errors below 1 %. Yet, the merits of learning-based models remain largely unexplored as no common dataset and benchmark exist. In this paper, we present a dataset captured from a three-tube concentric tube continuum robot for use in learning-based kinematics research. The dataset consists of 100 000 joint configurations and the corresponding four 6 dof sensors in SE(3) measured with an electromagnetic tracking system (github.com/ContinuumRoboticsLab/CRL-Dataset-CTCR-Pose). With our dataset, we empower the continuum robotics and machine learning community to advance the field. We share our insights and lessons learned on joint space representation, shape representation in task space, and sampling strategies. Furthermore, we provide benchmark results for learning the forward kinematics using a simple, shallow feedforward neural network. The benchmark results for the tip error are 0.74 mm w.r.t. position (0.4 % of total robot length) and 6.49\u00b0 w.r.t. orientation.",
        "primary_area": "",
        "author": "Reinhard M. Grassmann;Ryan Zeyuan Chen;Nan Liang;Jessica Burgner-Kahrs;Reinhard M. Grassmann;Ryan Zeyuan Chen;Nan Liang;Jessica Burgner-Kahrs",
        "authorids": "/37086574223;/37089662180;/37085749025;/37085433359;/37086574223;/37089662180;/37085749025;/37085433359",
        "aff": "Department of Mathematical and Computational Sciences, Continuum Robotics Laboratory, University of Toronto, Mississauga, ON, Canda; Department of Mathematical and Computational Sciences, Continuum Robotics Laboratory, University of Toronto, Mississauga, ON, Canda; Autonomous Systems and Biomechatronics Laboratory, Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mathematical and Computational Sciences, Continuum Robotics Laboratory, University of Toronto, Mississauga, ON, Canda",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981719/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7460834639388137811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Mathematical and Computational Sciences",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Mississauga;Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981239",
        "title": "A Deep Learning Technique as a Sensor Fusion for Enhancing the Position in a Virtual Reality Micro-Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Most virtual reality (VR) applications use a commercial controller for interaction. However, a typical virtual reality controller (VRC) lacks positional precision and accu-racy in millimeter-scale scenarios. This lack of precision and accuracy is caused by built-in sensors drift. Therefore, the tracking performance of a VRC needs to be enhanced for millimeter-scale scenarios. Herein, we introduce a novel way of enhancing the tracking performance of a commercial VRC in a millimeter-scale environment using a deep learning (DL) al-gorithm. Specifically, we use a long short-term memory (LSTM) model trained with data collected from a linear motor, an IMU sensor, and a VRC. We integrate the virtual environment developed in Unity software with the LSTM model running in Python. We designed three experimental conditions: the VRC, Kalman filter (KF), and LSTM modes. Furthermore, we evaluate tracking performances in the three conditions and two other experimental scenarios, namely stationary and dynamic. In the stationary experimental scenario, the system is left motionless for 10 s. By contrast, in the dynamic experimental scenarios, the linear stage moves the system by 12 mm along the X, Y, and Z axes. The experimental results indicate that the deep learning model outperforms the standard controllers positional performance by 85.69 % and 92.14 % in static and dynamic situations, respectively.",
        "primary_area": "",
        "author": "John David Prieto Prada;Miguel Luna;Sang Hyun Park;Cheol Song;John David Prieto Prada;Miguel Luna;Sang Hyun Park;Cheol Song",
        "authorids": "/37089660213;/37088727477;/37072759300;/37676950900;/37089660213;/37088727477;/37072759300;/37676950900",
        "aff": "Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981239/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14882739693629747743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "http://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982137",
        "title": "A Deep-Learning-based System for Indoor Active Cleaning",
        "track": "main",
        "status": "Poster",
        "abstract": "Cleaning public areas like commercial complexes is challenging due to their sophisticated surroundings and the vast kinds of real-life dirt. Robots are required to distinguish dirts and apply corresponding cleaning strategies. In this work, we proposed an active-cleaning framework by utilizing deep-learning methods for both solid wastes detection and liquid stains segmentation. Our system consists of 4 components: a Perception module integrated with deep-learning models, a Post-processing module for projection, a Tracking module for map localization, and a Planning and Control module for cleaning strategies. Compared with classic approaches, our vision-based system significantly improves cleaning efficiency. Besides, we released the largest real-world indoor hybrid dirt cleaning dataset (HD10K) containing 10K labeled images, together with a track-level evaluation metric for better cleaning performance measurement. The proposed deep-learning based system is verified with extensive experiments on our dataset, and deployed to Gaussian Robotics's robots operating globally. Dataset is available at: https://gaussianopensource.github.io/projects/active_cleaning.",
        "primary_area": "",
        "author": "Yike Yun;Linjie Hou;Zijian Feng;Wei Jin;Yang Liu;Heng Wang;Ruonan He;Weitao Guo;Bo Han;Baoxing Qin;Jiaxin Li;Yike Yun;Linjie Hou;Zijian Feng;Wei Jin;Yang Liu;Heng Wang;Ruonan He;Weitao Guo;Bo Han;Baoxing Qin;Jiaxin Li",
        "authorids": "/37089659061;/37089658586;/37089658772;/37089659147;/37089735328;/37089621999;/37089662577;/37089660971;/37089664007;/37089658351;/37089736348;/37089659061;/37089658586;/37089658772;/37089659147;/37089735328;/37089621999;/37089662577;/37089660971;/37089664007;/37089658351;/37089736348",
        "aff": "Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.; Gaussian Robotics Pte. Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982137/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7834274217008607708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Gaussian Robotics",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gaussianrobotics.com",
        "aff_unique_abbr": "Gaussian Robotics",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981583",
        "title": "A Dynamical System Approach to Decentralized Collision-free Autonomous Coordination of a Mobile Assistive Furniture Swarm",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to facilitate and assist the indoor mobility of people with special needs, the classically static objects in the environment, such as furniture, can be rendered mobile. The need for efficient and safe autonomous coordination of a mobile furniture swarm arises. We present a closed-form approach for mobile furniture obstacle avoidance and navigation within an indoor environment. The approach shows that each mobile furniture agent, defined by a polygonal surface, does not collide with any static or mobile obstacle (e.g., a person is moving around). All controllable mobile furniture converges towards a defined goal position and orientation. We showcase the application of this algorithm in simulation on mobile furniture for smart environments. Results demonstrate that the proposed method can coordinate a swarm of mobile furniture to get out of the way of a mobile agent representing a person with limited mobility passing through the room while avoiding obstacles and converging towards a predefined target pose.",
        "primary_area": "",
        "author": "Federico M. Conzelmann;Lukas Huber;Diego Paez-Granados;Anastasia Bolotnikova;Auke Ijspeert;Aude Billard;Federico M. Conzelmann;Lukas Huber;Diego Paez-Granados;Anastasia Bolotnikova;Auke Ijspeert;Aude Billard",
        "authorids": "/37089659732;/37086691700;/37085669907;/37086303237;/37268732300;/37273980800;/37089659732;/37086691700;/37085669907;/37086303237;/37268732300;/37273980800",
        "aff": "LASA Laboratory; LASA Laboratory; SCAI Laboratory at SPZ, Swiss Federal School of Technology in Zurich, ETH Zurich, Switzerland; Reconfigurable Robotics Laboratory, Swiss Federal School of Technology in Lausanne - EPFL, Switzerland; Biorobotics Laboratory; LASA Laboratory",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981583/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6419878602716027396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "LASA Laboratory;Swiss Federal Institute of Technology in Zurich (ETH Zurich);Swiss Federal Institute of Technology in Lausanne (EPFL);Biorobotics Laboratory",
        "aff_unique_dep": ";SCAI Laboratory at SPZ;Reconfigurable Robotics Laboratory;",
        "aff_unique_url": ";https://www.ethz.ch;https://www.epfl.ch;",
        "aff_unique_abbr": ";ETH Zurich;EPFL;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Zurich;Lausanne",
        "aff_country_unique_index": "1;1",
        "aff_country_unique": ";Switzerland"
    },
    {
        "id": "9981947",
        "title": "A Flexible Calibration Algorithm for High-speed Bionic Vision System based on Galvanometer",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional gimbal-based bionic eye systems usually use a multi-degree-of-freedom mechanical platform to move the camera freely, which makes the structure complex and bulky. The galvanometer-based reflective bionic eye system uses a galvanometer to replace the traditional mechanical rotation structure, which separates the camera from the gimbal system, greatly simplifying the structure. However, there are currently few methods for calibrating such systems, mostly for object detection and tracking. In this paper, a flexible method for high-precision calibration of a galvanometer-based reflective bionic eye system is proposed. In this method, a planar target is used for the calibration of the bionic eye system. The effectiveness and accuracy of the method are evaluated by the reprojection error of the control voltage and the spatial localization of the binocular system. Experiments show that the error of the control voltage after calibration is less than 0.2%. At an indoor distance of about 7 m, the RMSE of spatial visual localization is less than 0.3 cm.",
        "primary_area": "",
        "author": "Qing Li;Mengjuan Chen;Qingyi Gu;Idaku Ishii;Qing Li;Mengjuan Chen;Qingyi Gu;Idaku Ishii",
        "authorids": "/975844378209305;/37086476728;/37532525900;/37327589100;/975844378209305;/37086476728;/37532525900;/37327589100",
        "aff": "Samrt Robotics Lab., Hiroshima University, Hiroshima, Japan; Samrt Robotics Lab., Hiroshima University, Hiroshima, Japan; School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, China; Samrt Robotics Lab., Hiroshima University, Hiroshima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981947/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9550006167580385470&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hiroshima University;University of Chinese Academy of Sciences",
        "aff_unique_dep": "Samrt Robotics Lab.;School of Computer and Control Engineering",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp;http://www.ucas.ac.cn",
        "aff_unique_abbr": ";UCAS",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hiroshima;Beijing",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9981302",
        "title": "A Flexible and Robust Vision Trap for Automated Part Feeder Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast, robust, and flexible part feeding is essential for enabling automation of low volume, high variance assembly tasks. An actuated vision-based solution on a traditional vibratory feeder, referred to here as a vision trap, should in principle be able to meet these demands for a wide range of parts. However, in practice, the flexibility of such a trap is limited as an expert is needed to both identify manageable tasks and to configure the vision system. We propose a novel approach to vision trap design in which the identification of manageable tasks is automatic and the configuration of these tasks can be delegated to an automated feeder design system. We show that the trap's capabilities can be formalized in such a way that it integrates seamlessly into the ecosystem of automated feeder design. Our results on six canonical parts show great promise for autonomous configuration of feeder systems.",
        "primary_area": "",
        "author": "Rasmus Laurvig Haugaard;Thorbj\u03d5rn Mosekj\u00e6r Iversen;Anders Glent Buch;Aljaz Kramberger;Simon Faarvang Mathiesen;Rasmus Laurvig Haugaard;Thorbj\u03d5rn Mosekj\u00e6r Iversen;Anders Glent Buch;Aljaz Kramberger;Simon Faarvang Mathiesen",
        "authorids": "/37089538190;/37086208129;/37534052600;/37085387168;/37085786574;/37089538190;/37086208129;/37534052600;/37085387168;/37085786574",
        "aff": "SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981302/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15360645597854906448&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU Robotics, Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9981163",
        "title": "A Framework for Transferring Surface Finishing Skills to New Surface Geometries",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework for transferring surface finishing skills to new surface geometries while preserving the surface finish quality. The main idea is to estimate the contact area between the workpiece and the tool by using 3D point cloud approach and replicate a given material removal rate and the accumulated material removal, as these quantities are the main parameters for quality. The grinding motion trajectory is generated by solving a constrained optimization problem that minimizes the maximal point-wise deviation between actual and desired material removal and simultaneously minimizes the average deviation between actual and desired material removal rate. The proposed approach is verified in simulation to show the difference between direct replication of force/motion and the proposed replication of material removal. Finally, experimental results confirm that the quality of a surface finishing task can be transferred to new surface geometries with the proposed method.",
        "primary_area": "",
        "author": "Yitaek Kim;Christoffer Sloth;Aljaz Kramberger;Yitaek Kim;Christoffer Sloth;Aljaz Kramberger",
        "authorids": "/37089578934;/37547023600;/37085387168;/37089578934;/37547023600;/37085387168",
        "aff": "Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981163/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13510115937860144895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9982198",
        "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time control is an essential aspect of safe robot operation in the real world with dynamic objects. We present a framework for the analysis of object-aware con-trollers, methods for altering a robot's motion to anticipate and avoid possible collisions. This framework is focused on three design considerations: kinematics, motion profiles, and virtual constraints. Additionally, the analysis in this work relies on verification of robot behaviors using fundamental robot-obstacle experimental scenarios. To showcase the effectiveness of our method we compare three representative object-aware controllers. The comparison uses metrics originating from the design considerations. From the analysis, we find that the design of object-aware controllers often lacks kinematic considerations, continuity of control points, and stability in movement profiles. We conclude that this framework can be used in the future to design, compare, and benchmark obstacle avoidance methods.",
        "primary_area": "",
        "author": "Caleb Escobedo;Nataliya Nechyporenko;Shreyas Kadekodi;Alessandro Roncone;Caleb Escobedo;Nataliya Nechyporenko;Shreyas Kadekodi;Alessandro Roncone",
        "authorids": "/37089195404;/37089658613;/37089662086;/37085343755;/37089195404;/37089658613;/37089662086;/37085343755",
        "aff": "Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982198/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8498202537823122928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982172",
        "title": "A Framework of Rehabilitation-assisted Robot Skill Representation, Learning, and Modulation via Manifold-Mappings and Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Stroke survivors usually have dyskinesia, who have an urgent need for rehabilitation-assist training. To reduce the labor of rehabilitation therapists, this paper attempts to investigate an effective rehabilitation-assisted robot skill acquisition framework, which is inspired by the scheme of robot learning from demonstration (LfD). Since most of the current LfD methods were implemented with rigorous assumptions that the considering motion features are only represented on an individual manifold. Meanwhile, despite many advancements that have been achieved on time-position trajectories and position-velocity trajectories, those methods are restricted to Euclidean space and can not be applied to learn those dexterous and compliant rehabilitation-assisted robot skills such as position-orientation trajectories and force-stiffness trajectories, etc. In this paper, we propose a novel skill acquisition framework for rehabilitation-assisted robot using manifold-mappings and Gaussian processes, which allows the robot to 1) simultaneously considering the robot position, orientation, force as well as stiffness by manifold-mappings among d-dimensional Euclidean space \\mathcal{R}^{d}\\mathcal{R}^{d}, special orthogonal group S\\mathcal{O}S\\mathcal{O} (3), and Riemannian space \\mathcal{M}\\mathcal{M}, respectively, which resulting in accurate motion and compliant behavior; 2) retrieving skill representation by encap-sulating the variability of multiple high-dimensional demon-strations that with input-dependent noises; 3) implementing the via-points-based trajectory modulation by considering task constraints or environmental changes. To simplify the writing, we named the proposed framework as Multi-motion Features Fusion-based Robot Skill Learning (MF2 RoSL). To effectively evaluate the effectiveness of our proposed method, an upper limb rehabilitation training system with a collaborative Kinova robot is developed. The training exercises of our system are determined according to the Brunnstrom therapeutic approach t... Show More",
        "primary_area": "",
        "author": "Hongmin Wu;Zhihao Xu;Wu Yan;Yangmin Ou;Zhaoyang Liao;Xuefeng Zhou;Hongmin Wu;Zhihao Xu;Wu Yan;Yangmin Ou;Zhaoyang Liao;Xuefeng Zhou",
        "authorids": "/37085336289;/37086308586;/37087102764;/37089661104;/37089333448;/37406422900;/37085336289;/37086308586;/37087102764;/37089661104;/37089333448;/37406422900",
        "aff": "Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences Guangdong Key Laboratory of Modern Control Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982172/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15111224164243308522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Guangdong Academy of Sciences",
        "aff_unique_dep": "Institute of Intelligent Manufacturing",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981276",
        "title": "A General Method for Autonomous Assembly of Arbitrary Parts in the Presence of Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel and general method for autonomous robotic assembly of arbitrary and complex-shaped parts in the presence of 6-dimensional uncertainty. When a nominal assembly motion of the robot holding a part is stopped by contact due to uncertainty, our method finds the best estimate for the uncertainty and the contact configuration of the part based on sensed force/torque and uses that information to find a more accurate estimate of the goal configuration to guide a recovery motion of the part. It is based on a general, surface-based sphere tree representation of parts, a constrained optimization strategy to find the best estimate of the contact configuration under an uncertainty estimate, and a learned force/torque calibration model to relate computed force/torque and the sensed real force/torque. The method is applied and evaluated on different complex-shaped multi-peg-in-hole tasks. The results show that our method can achieve successful assembly with the presence of realistic 6-D uncertainties more than 10 times of the tight task clearances in terms of orientation clearance (< 0.015rad)(< 0.015rad) and position clearance (< 1.5mm)(< 1.5mm), in all the test cases.",
        "primary_area": "",
        "author": "Shichen Cao;Jing Xiao;Shichen Cao;Jing Xiao",
        "authorids": "/37089663723;/37278646600;/37089663723;/37278646600",
        "aff": "Robotics Engineering Department, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Department, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981276/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17788763077350789685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering Department",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981430",
        "title": "A Geometric Design Approach for Continuum Robots by Piecewise Approximation of Freeform Shapes",
        "track": "main",
        "status": "Poster",
        "abstract": "As soft, continuum robots see increasing areas of application, many scenarios have arisen where it is necessary to consider the geometric shape of the robot. The current approaches to robot kinematics, such as the piecewise constant-curvature (PCC) model, are effective in representing simple overall robot geometry and estimating the end-effector state, but they are less intuitive for planning robots that involve complex geometries. In this work, we propose a solution to the geometric design problem by a two-part approach: a freeform spline defines a \u201cshape curve\u201d that describes the overall geometry of the robot, and then a \u201ckinematic curve\u201d composed of shapes that are feasible to replicate with continuum robots is fitted to the shape curve. As an implementation of this approach, we specifically explore the application of piecewise cubic Bezier curves in designing the shape curve of the robot, and pairs of arcs to construct the kinematic curves. Finally, the approach is applied to a tip-extension \u201cvine\u201d robot that is designed and fabricated to \u201cgrow\u201d along a designed path and access the top surface of an obstacle.",
        "primary_area": "",
        "author": "Sicheng Wang;Laura H. Blumenschein;Sicheng Wang;Laura H. Blumenschein",
        "authorids": "/37089660568;/37085849839;/37089660568;/37085849839",
        "aff": "School of Mechanical Engineering, Purdue University, IN; School of Mechanical Engineering, Purdue University, IN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981430/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9994097695001565547&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Indiana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981488",
        "title": "A Hierarchical Deliberative Architecture Framework based on Goal Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing a complex autonomous mission with a multi-robot system requires to integrate several deliberative approaches to perform task allocation, optimization, and execution control. Implementing such a deliberative architecture is a complex task: it requires the developer to master the decision algorithms themselves (e.g., automated planning models), to have a good knowledge of the involved robotic platforms, and to think about how these elements will be assembled as a system architecture. We propose a framework to help designing such deliberative architectures. The framework relies on the concept of a hierarchical structure of actors, each actor managing goals with specific planning or optimization approaches, and delegating sub-goals to other actors.",
        "primary_area": "",
        "author": "Charles Lesire;Rafael Bailon-Ruiz;Magali Barbier;Christophe Grand;Charles Lesire;Rafael Bailon-Ruiz;Magali Barbier;Christophe Grand",
        "authorids": "/38275129600;/37086175316;/37085622144;/38335131900;/38275129600;/37086175316;/37085622144;/38335131900",
        "aff": "ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981488/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12979064378761193680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ONERA",
        "aff_unique_dep": "DTIS",
        "aff_unique_url": "https://www.onera.fr",
        "aff_unique_abbr": "ONERA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981618",
        "title": "A Hierarchical Finite-State Machine-Based Task Allocation Framework for Human-Robot Collaborative Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Work-related musculoskeletal disorders (MSD) are one of the major cause of injuries and absenteeism at work. These lead to important cost in the manufacturing industry. Human-robot collaboration can help decreasing this issue by appropriately distributing the tasks and decreasing the workload of the factory worker. This paper proposes a novel generic task allocation approach based on hierarchical finite-state machines for human-robot assembly tasks. The developed framework decomposes first the main task into sub-tasks modelled as state machines. Based on capabilities considerations, workload, and performance estimations, the task allocator assigns the sub-task to human or robot agent. The algorithm was validated on the assembly of a crusher unit of a smoothie machine using the collaborative Franka Emika Panda robot and showed promising results in terms of productivity thanks to task parallelization, with improvement of more than 30% of the total assembly time with respect to a collaborative scenario, where the agents perform the tasks sequentially.",
        "primary_area": "",
        "author": "Ilias El Makrini;Mohsen Omidi;Fabio Fusaro;Edoardo Lamon;Arash Ajoudani;Bram Vandcrborght;Ilias El Makrini;Mohsen Omidi;Fabio Fusaro;Edoardo Lamon;Arash Ajoudani;Bram Vandcrborght",
        "authorids": "/37086275097;/37089661227;/37088464502;/37086599073;/37945239900;/37089661293;/37086275097;/37089661227;/37088464502;/37086599073;/37945239900;/37089661293",
        "aff": "Flexible Assembly, Flanders Make, Belgium; Interuniversity Microelectronics Centre (IMEC), Belgium; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genova, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genova, Italy; Interuniversity Microelectronics Centre (IMEC), Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981618/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12682657191583707276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;3;1",
        "aff_unique_norm": "Flanders Make;Interuniversity Microelectronics Centre;Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Flexible Assembly;;Department of Electronics, Information and Bioengineering;HRI2 Lab",
        "aff_unique_url": "https://www.flandersmake.be;https://www.imec-int.com;https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": ";IMEC;Politecnico di Milano;",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";Milano;Genova",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "Belgium;Italy"
    },
    {
        "id": "9981862",
        "title": "A Hierarchical Framework for Long Horizon Planning of Object-Contact Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Given an object, an environment, and a goal pose, how should a robot make contact to move it? Solving this problem requires reasoning about rigid-body dynamics, object and environment geometries, and hybrid contact mechanics. This paper proposes a hierarchical framework that solves this problem in 2D worlds, with polygonal objects and point fingers. To achieve this, we decouple the problem in three stages: 1) a high-level graph search over regions of free-space, 2) a medium-level randomized motion planner for the object motion, and 3) a low-level contact-trajectory optimization for the robot and environment contacts. In contrast to the state of the art, this approach does not rely on handcrafted primitives and can still be solved efficiently. This algorithm does not require seeding and can be applied to complex object shapes and environments. We validate this framework with extensive simulated experiments showcasing long-horizon and contact-rich interactions. We demonstrate how our algorithm can reliably solve complex planar manipulation problems in the order of seconds.",
        "primary_area": "",
        "author": "Bernardo Aceituno;Alberto Rodriguez;Bernardo Aceituno;Alberto Rodriguez",
        "authorids": "/37089663987;/38194796600;/37089663987;/38194796600",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981862/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17172871493376621729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982022",
        "title": "A Hybrid PSO Algorithm for Multi-robot Target Search and Decision Awareness",
        "track": "main",
        "status": "Poster",
        "abstract": "Groups of robots can be tasked with identifying a location in an environment where a feature cue is past a threshold, then disseminating this information throughout the group \u2013 such as identifying a high-enough elevation location to place a communications tower. This is a continuous-cue target search, where multi-robot search algorithms like particle swarm optimization (PSO) can improve search time through parallelization. However, many robots lack global communication in large spaces, and PSO-based algorithms often fail to consider how robots disseminate target knowledge after a single robot locates it. We present a two-stage hybrid algorithm to solve this task: (1) locating a target with a variation of PSO, and (2) moving to maximize target knowledge across the group. We conducted parameter sweep simulations of up to 32 robots in a grid-based grayscale environment. Pre-decision, we find that PSO with a variable velocity update interval improves target localization. In the post-decision phase, we show that dispersion is the fastest strategy to communicate with all other robots. Our algorithm is also competitive with a coverage sweep benchmark, while requiring significantly less inter-individual coordination.",
        "primary_area": "",
        "author": "Julia T. Ebert;Florian Berlinger;Bahar Haghighat;Radhika Nagpal;Julia T. Ebert;Florian Berlinger;Bahar Haghighat;Radhika Nagpal",
        "authorids": "/37086454657;/37086054307;/37085379918;/37286742900;/37086454657;/37086054307;/37085379918;/37286742900",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, Massachusetts; Department of Mechanical and Aerospace Engineering and Computer Science, Princeton University, Princeton, New Jersey; Department of Mechanical and Aerospace Engineering and Computer Science, Princeton University, Princeton, New Jersey; Department of Mechanical and Aerospace Engineering and Computer Science, Princeton University, Princeton, New Jersey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982022/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10488603083994390465&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Harvard University;Princeton University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;Department of Mechanical and Aerospace Engineering and Computer Science",
        "aff_unique_url": "https://www.harvard.edu;https://www.princeton.edu",
        "aff_unique_abbr": "Harvard;Princeton",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Cambridge;Princeton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981188",
        "title": "A Hybrid Primitive-Based Navigation Planner for the Wheeled-Legged Robot CENTAURO",
        "track": "main",
        "status": "Poster",
        "abstract": "Wheeled-legged robots have the potential to navigate in cluttered and irregular scenarios by altering the locomotion modes to adapt to the terrain challenges and effectively reach targeted locations in unstructured spaces. To achieve this functionality, a hybrid locomotion planner is necessary. In this work we present a search-based planner, which explores a set of motion primitives and a 2.5D traversability map extracted from the environment to generate navigation plans for the hybrid mobility robot CENTAURO. The planner explores the map from the current robot position to the goal location requested by the user, considering the most appropriate composition and tuning of locomotion primitives to build up a feasible plan, which is then executed by the robot. The available primitives are prioritized and can be easily modified, added or removed through a configuration file. Our approach was evaluated both in simulation and on the real wheeled-legged robot CENTAURO, demonstrating traversing capabilities in cluttered environments with various obstacles.",
        "primary_area": "",
        "author": "Alessio De Luca;Luca Muratore;Nikos G. Tsagarakis;Alessio De Luca;Luca Muratore;Nikos G. Tsagarakis",
        "authorids": "/37089660712;/37086139432;/37295830800;/37089660712;/37086139432;/37295830800",
        "aff": "DIBRIS, Universita di Genova, Italy; Humanoids and Human-Centered Mechatronics Research Line Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, Italy; Humanoids and Human-Centered Mechatronics Research Line Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981188/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15137597440744306096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universita di Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "DIBRIS;Humanoids and Human-Centered Mechatronics Research Line",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Genova",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981919",
        "title": "A Large-Area Wearable Soft Haptic Device Using Stacked Pneumatic Pouch Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "While haptics research has traditionally focused on the fingertips and hands, other locations on the body provide large areas of skin that could be utilized to relay large-area haptic sensations. Researchers have thus developed wearable devices that use distributed vibrotactile actuators and distributed pneumatic force displays, but these methods have limitations. In prior work, we presented a novel actuation technique involving stacking pneumatic pouches and evaluated the actuator output. In this work, we developed a wearable haptic device using this actuation technique and evaluated how the actuator output is perceived. We conducted a user study with 20 participants to evaluate users' perception thresholds, ability to localize, and ability to detect differences in contact area and compare their perception using the stacked pneumatic pouch actuation to traditional single-layer pouch actuation. We also used our device with stacked pneumatic actuation in a demonstration of a haptic hug that replicates the dynamics, pressure profile, and mapping to the human back, showcasing how this actuation technique can be used to create novel haptic stimuli.",
        "primary_area": "",
        "author": "Cara M. Nunez;Brian H. Do;Andrew K. Low;Laura H. Blumenschein;Katsu Yamane;Allison M. Okamura;Cara M. Nunez;Brian H. Do;Andrew K. Low;Laura H. Blumenschein;Katsu Yamane;Allison M. Okamura",
        "authorids": "/37086377274;/37086414589;/37089279827;/37085849839;/37291289300;/37276156400;/37086377274;/37086414589;/37089279827;/37085849839;/37291289300;/37276156400",
        "aff": "Bioengineering Department, Stanford University; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; School of Mechanical Engineering, Purdue University, Lafayette, IN, USA; Honda Research Institute USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981919/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6892297707893542089&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Stanford University;Purdue University;Honda Research Institute",
        "aff_unique_dep": "Bioengineering Department;School of Mechanical Engineering;Honda Research Institute",
        "aff_unique_url": "https://www.stanford.edu;https://www.purdue.edu;https://honda-ri.com",
        "aff_unique_abbr": "Stanford;Purdue;HRI USA",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Stanford;Lafayette;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981255",
        "title": "A Legendre-Gauss Pseudospectral Collocation Method for Trajectory Optimization in Second Order Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Pseudospectral collocation methods have proven to be powerful tools to solve optimal control problems. While these methods generally assume the dynamics is given in the first order form xx = f(x, u, t), where xx is the state and uu is the control vector, robotic systems are typically governed by second order ODEs of the form qq = g(q, q, u, t), where qq is the configuration. To convert the second order ODE into a first order one, the usual approach is to introduce a velocity variable vv and impose its coincidence with the time derivative of q. Lobatto methods grant this constraint by construction, as their polynomials describing the trajectory for vv are the time derivatives of those for q, but the same cannot be said for the Gauss and Radau methods. This is problematic for such methods, as then they cannot guarantee that qq = g(q, q, u, t) at the collocation points. On their negative side, Lobatto methods cannot be used to solve initial value problems, as given the values of uu at the collocation points they generate an overconstrained system of equations for the states. In this paper, we propose a Legendre-Gauss collocation method that retains the advantages of the usual Lobatto, Gauss, and Radau methods, while avoiding their shortcomings. The collocation scheme we propose is applicable to solve initial value problems, preserves the consistency between the polynomials for vv and q, and ensures that qq= g(q, q, u, t) at the collocation points.",
        "primary_area": "",
        "author": "Siro Moreno-Mart\u00edn;Llu\u00eds Ros;Enric Celaya;Siro Moreno-Mart\u00edn;Llu\u00eds Ros;Enric Celaya",
        "authorids": "/37089662235;/37341176300;/37089662725;/37089662235;/37341176300;/37089662725",
        "aff": "Institut de Robotica i Informatica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Robotica i Informatica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Robotica i Informatica Industrial, CSIC-UPC, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981255/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7397101111155733171&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Institut de Robotica i Informatica Industrial",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "CSIC-UPC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981157",
        "title": "A LiDAR-inertial Odometry with Principled Uncertainty Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a LiDAR-inertial odometry that properly solves the uncertainty estimation problem, guided by the rules of designing a consistent estimator. Our system is built upon an iterated extended Kalman filter, with multiple states in an optimization window. To survive environments without distinctive geometric structures, we do not track features over time. We only extract planar primitives from the local map and use a direct point-to-plane distance metric as the measurement model. The realistic noise parameters are estimated online by modeling point distributions. We use nullspace projection to remove dependency on the feature planes, which is equivalent to transforming the pose-map measurement into relative pose constraints. To avoid reintegrating all the laser points in the local window after every state correction, we use the Schmidt Kalman update to consider the probabilistic effects of past poses while their values are left unaltered. A collection of octrees with an adaptive resolution is designed to manage measurement points and the map efficiently. The consistency and robustness of our system are verified in both simulation and real-world experiments.",
        "primary_area": "",
        "author": "Binqian Jiang;Shaojie Shen;Binqian Jiang;Shaojie Shen",
        "authorids": "/37087244909;/37954847200;/37087244909;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981157/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16353916120518585493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982063",
        "title": "A Method For Automated Drone Viewpoints to Support Remote Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Drones can provide a minimally-constrained adapting camera view to support robot telemanipulation. Furthermore, the drone view can be automated to reduce the burden on the operator during teleoperation. However, existing approaches do not focus on two important aspects of using a drone as an automated view provider. The first is how the drone should select from a range of quality viewpoints within the workspace (e.g., opposite sides of an object). The second is how to compensate for unavoidable drone pose uncertainty in determining the viewpoint. In this paper, we provide a nonlinear optimization method that yields effective and adaptive drone viewpoints for telemanipulation with an articulated manipulator. Our first key idea is to use sparse human-in-the-loop input to toggle between multiple automatically-generated drone viewpoints. Our second key idea is to introduce optimization objectives that maintain a view of the manipulator while considering drone uncertainty and the impact on viewpoint occlusion and environment collisions. We provide an instantiation of our drone viewpoint method within a drone-manipulator remote teleoperation system. Finally, we provide an initial validation of our method in tasks where we complete common household and industrial manipulations.",
        "primary_area": "",
        "author": "Emmanuel Senft;Michael Hagenow;Pragathi Praveena;Robert Radwin;Michael Zinn;Michael Gleicher;Bilge Mutlu;Emmanuel Senft;Michael Hagenow;Pragathi Praveena;Robert Radwin;Michael Zinn;Michael Gleicher;Bilge Mutlu",
        "authorids": "/37085768238;/37088814469;/37085879978;/37389499300;/37282367400;/37282585700;/38569363200;/37085768238;/37088814469;/37085879978;/37389499300;/37282367400;/37282585700;/38569363200",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison, Madison, USA; Department of Mechanical Engineering, University of Wisconsin-Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, USA; Department of Industrial and Systems Engineering, University of Wisconsin-Madison, Madison, USA; Department of Mechanical Engineering, University of Wisconsin-Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982063/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16687101083555092248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982227",
        "title": "A Metric for Finding Robust Start Positions for Medical Steerable Needle Automation",
        "track": "main",
        "status": "Poster",
        "abstract": "Steerable needles are medical devices with the ability to follow curvilinear paths to reach targets while circumventing obstacles. In the deployment process, a human operator typically places the steerable needle at its start position on a tissue surface and then hands off control to the automation that steers the needle to the target. Due to uncertainty in the placement of the needle by the human operator, choosing a start position that is robust to deviations is crucial since some start positions may make it impossible for the steerable needle to safely reach the target. We introduce a method to efficiently evaluate steerable needle motion plans such that they are safe to variation in the start position. This method can be applied to many steerable needle planners and requires that the needle's orientation angle at insertion can be robotically controlled. Specifically, we introduce a method that builds a funnel around a given plan to determine a safe insertion surface corresponding to insertion points from which it is guaranteed that a collision-free motion plan to the goal can be computed. We use this technique to evaluate multiple feasible plans and select the one that maximizes the size of the safe insertion surface. We evaluate our method through simulation in a lung biopsy scenario and show that the method is able to quickly find needle plans with a large safe insertion surface.",
        "primary_area": "",
        "author": "Janine Hoelscher;Inbar Fried;Mengyu Fu;Mihir Patwardhan;Max Christman;Jason Akulian;Robert J. Webster;Ron Alterovitz;Janine Hoelscher;Inbar Fried;Mengyu Fu;Mihir Patwardhan;Max Christman;Jason Akulian;Robert J. Webster;Ron Alterovitz",
        "authorids": "/37085664639;/37088528690;/37086578786;/37089662575;/37089662670;/37088531510;/37325029200;/37320259800;/37085664639;/37088528690;/37086578786;/37089662575;/37089662670;/37088531510;/37325029200;/37320259800",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Division of Pulmonary Diseases and Critical Care Medicine, University of North Carolina, Chapel Hill, NC, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982227/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3866045188307103512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;University of North Carolina;Vanderbilt University",
        "aff_unique_dep": "Department of Computer Science;Division of Pulmonary Diseases and Critical Care Medicine;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.unc.edu;https://www.unc.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "UNC Chapel Hill;UNC;Vanderbilt",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Chapel Hill;Nashville",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981512",
        "title": "A Micro-Robotic Approach for The Correction of Angular Deviations in AFM Samples From Generic Topographic Data",
        "track": "main",
        "status": "Poster",
        "abstract": "This article proposes a method for the correction of angular deviations caused during the fixing process of samples prepared for Atomic Force Microscopy (AFM). The correction is done using the angular control of a 6-DOF PPPS parallel platform were the sample is placed, while the AFM scan is performed by a 3-DOF serial cartesian robot with a tuning fork probe designed to perform FM-AFM. The method uses the generic x, y, and z data provided by the AFM after performing a scan on a free surface of the sample substrate. This is used to calculate the plane that closest approximates the points by solving a system of linear equations. This plane is then used to estimate the angular corrections that the 6-DOF parallel robot has to do in order to compensate the deviations. The proposed algorithm can be performed iteratively in order to refine the correction. The method also does not require any special preparation of the substrate. It only requires to have a free surface to scan. Experiments are performed using this algorithm to correct the orientation deviation of a substrate of V1 High-grade mica. The results show that the method is able to correct the angular deviation of the sample relatively to the AFM probe with an error of 0.2\u00b0 after only two iterations of the algorithm.",
        "primary_area": "",
        "author": "Freddy Romero Leiro;Ali Bazaei;St\u00e9phane R\u00e9gnier;Mokrane Boudaoud;Freddy Romero Leiro;Ali Bazaei;St\u00e9phane R\u00e9gnier;Mokrane Boudaoud",
        "authorids": "/37089514584;/37394637600;/37283234800;/37594372000;/37089514584;/37394637600;/37283234800;/37594372000",
        "aff": "Sorbonne Universite, Institut des Systemes Intelligents et de Robotique, Paris, France; School of Electrical Engineering and Computing, University of Newcastle Australia, Callaghan, NSW; Sorbonne Universite, Institut des Systemes Intelligents et de Robotique, Paris, France; Sorbonne Universite, Institut des Systemes Intelligents et de Robotique, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981512/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2681341650782084807&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Sorbonne Universite;University of Newcastle Australia",
        "aff_unique_dep": "Institut des Systemes Intelligents et de Robotique;School of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.sorbonne-universite.fr;https://www.newcastle.edu.au",
        "aff_unique_abbr": "Sorbonne U;UoN",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Paris;Callaghan",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;Australia"
    },
    {
        "id": "9981700",
        "title": "A Miniature Continuum Robot with Integrated Piezoelectric Beacon Transducers and its Ultrasonic Shape Detection in Robot-Assisted Minimally Invasive Surgeries",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimally invasive surgeries (MIS) or natural orifice transluminal endoscopic surgeries (NOTES) such as the transurethral resection of bladder tumor (TURBT) require the surgical robot to be miniaturized to perform surgical procedures in confined spaces. However, the surgical robot's tiny size poses problems in its fabrication and shape sensing. In this paper, a miniature continuum surgical robot is proposed with a unique laminated structure which can be fabricated through a 2D lamination process and converted into 3D through folding. This multi-material laminated structure also facilitates the integration of tiny piezoelectric transducers on the robot's surface as beacons to generate ultrasonic waves for shape detection. A novel beacon total focusing method (b-TFM) algorithm is developed to process the received ultrasonic data and create a high-quality ultrasonic image from which the shape of the continuum robot can be extracted. The proposed robot and the ultrasonic shape detection method are validated through simulations and experiments. The error in the open-loop trajectory control is less than 4 mm without compensation, and the error in the ultrasonic shape detection is less than 1 mm. This confirms the possibility of improving the trajectory control accuracy by using the detected shape as a feedback for closed-loop control.",
        "primary_area": "",
        "author": "Zhanpeng Yin;Yan Hong;Xiaoyu Sun;Zhiyuan Shen;Yingxuan Zhang;Feng Ju;Bruce W. Drinkwater;Zhanpeng Yin;Yan Hong;Xiaoyu Sun;Zhiyuan Shen;Yingxuan Zhang;Feng Ju;Bruce W. Drinkwater",
        "authorids": "/37089659285;/37089218683;/37089660277;/37086080507;/37087244839;/37540799600;/37294683900;/37089659285;/37089218683;/37089660277;/37086080507;/37087244839;/37540799600;/37294683900",
        "aff": "College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Mechanical Engineering, University of Bristol, Queen's Building, University Walk, Bristol, UK; Department of Mechanical Engineering, University of Bristol, Queen's Building, University Walk, Bristol, UK; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Mechanical Engineering, University of Bristol, Queen's Building, University Walk, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981700/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9126919351862135212&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;0;1",
        "aff_unique_norm": "Nanjing University of Aeronautics and Astronautics;University of Bristol",
        "aff_unique_dep": "College of Mechanical and Electrical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.nuaa.edu.cn;https://www.bristol.ac.uk",
        "aff_unique_abbr": "NUAA;Bristol",
        "aff_campus_unique_index": "0;0;1;1;0;0;1",
        "aff_campus_unique": "Nanjing;Bristol",
        "aff_country_unique_index": "0;0;1;1;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9981684",
        "title": "A Multi-Granularity Scene Segmentation Network for Human-Robot Collaboration Environment Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration (HRC) has been considered as a promising paradigm towards futuristic human-centric smart manufacturing, to meet the thriving needs of mass personalization. In this context, existing robotic systems normally adopt a single-granularity semantic segmentation scheme for environment perception, which lacks the flexibility to be implemented to various HRC situations. To fill the gap, this study proposes a multi-granularity scene segmentation network. Inspired by some recent network designs, we construct an encoder network with two ConvNext-T backbones for RGB and depth respectively, and an decoder network consisting of multi-scale supervision and multi-granularity segmentation branches. The proposed model is demonstrated in a human-robot collaborative battery disassembly scenario and further evaluated in comparison with state-of-the-art RGB-D semantic segmentation methods on the NYU-Depth V2 dataset.",
        "primary_area": "",
        "author": "Junming Fan;Pai Zheng;Carman K.M. Lee;Junming Fan;Pai Zheng;Carman K.M. Lee",
        "authorids": "/37088983964;/37085680663;/37634789600;/37088983964;/37085680663;/37634789600",
        "aff": "Laboratory for Artificial Intelligence in Design, Hong Kong SAR; Laboratory for Artificial Intelligence in Design, Hong Kong SAR; Laboratory for Artificial Intelligence in Design, Hong Kong SAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981684/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11747170459835964102&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University",
        "aff_unique_dep": "Laboratory for Artificial Intelligence in Design",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981814",
        "title": "A New Dense Hybrid Stereo Visual Odometry Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual odometry is an important part of the perception module of autonomous robots. Recent advances in deep learning approaches have given rise to hybrid visual odometry approaches that combine both deep networks and traditional pose estimation methods. One limitation of deep learning approaches is the availability of ground truth data needed to train the neural networks. For example, it is extremely difficult, if not impossible, to obtain a ground truth dense depth map of the environment to be used for stereo visual odometry. Even if unsupervised training of networks has been investigated, supervised training remains more reliable and robust. In this paper, we propose a new hybrid dense stereo visual odometry approach in which a dense depth map is obtained with a network that is supervised using ground truth poses that can be more easily obtained than ground truth depths maps. The depth map obtained from the neural network is used to warp the current image into the reference frame and the optimal pose is obtained by minimizing a cost function that encodes the similarity between the warped image and the reference image. The experimental results show that the proposed approach, not only improves state-of-the-art depth maps estimation networks on some of the standard benchmark datasets, but also outperforms the state-of-the-art visual odometry methods.",
        "primary_area": "",
        "author": "Ziming Liu;Ezio Malis;Philippe Martinet;Ziming Liu;Ezio Malis;Philippe Martinet",
        "authorids": "/37089658629;/37273959500;/37277258700;/37089658629;/37273959500;/37277258700",
        "aff": "ACENTAURI team at INRIA (Sophia Antipolis, France) and 3IA C\u00f4te d\u2019Azur Institute, Universit\u00e9 C\u00f4te d\u2019Azur (Nice, France); ACENTAURI team at INRIA (Sophia Antipolis, France) and 3IA C\u00f4te d\u2019Azur Institute, Universit\u00e9 C\u00f4te d\u2019Azur (Nice, France); ACENTAURI team at INRIA (Sophia Antipolis, France) and 3IA C\u00f4te d\u2019Azur Institute, Universit\u00e9 C\u00f4te d\u2019Azur (Nice, France)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981814/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14052741325009649271&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "ACENTAURI team",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "INRIA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sophia Antipolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9982229",
        "title": "A Novel Design and Evaluation of a Dactylus-Equipped Quadruped Robot for Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped robots are usually equipped with ad-ditional arms for manipulation, negatively impacting price and weight. On the other hand, the requirements of legged locomotion mean that the legs of such robots often possess the needed torque and precision to perform manipulation. In this paper, we present a novel design for a small-scale quadruped robot equipped with two leg-mounted manipulators inspired by crustacean chelipeds and knuckle-walker forelimbs. By making use of the actuators already present in the legs, we can achieve manipulation using only 3 additional motors per limb. The design enables the use of small and inexpensive actuators relative to the leg motors, further reducing cost and weight. The moment of inertia impact on the leg is small thanks to an integrated cable/pulley system. As we show in a suite of tele-operation experiments, the robot is capable of performing single- and dual-limb manipulation, as well as transitioning between manipulation modes. The proposed design performs similarly to an additional arm while weighing and costing 5 times less per manipulator and enabling the completion of tasks requiring 2 manipulators.",
        "primary_area": "",
        "author": "Yordan Tsvetkov;Subramanian Ramamoorthy;Yordan Tsvetkov;Subramanian Ramamoorthy",
        "authorids": "/37089663217;/37529920500;/37089663217;/37529920500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982229/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13363365515548770066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9981155",
        "title": "A Novel Human-Safe Robotic Gripper: An application of a Programmable Permanent Magnet Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "While collaborative robotic arms offer significant safety benefits, safety of the overall manipulator system cannot be guaranteed unless equally strict safety requirements are satisfied by the accompanying end-effector. Current robot grippers are not made in a way that fulfills such a requirement, resulting in collaborative robots needing to operate in a protected environment. This paper presents a novel permanent magnet actuator inside of a conventional industrial electric gripper which results in an end-effector that has an unmatched force range of 1-2N to 43N and exhibits interesting characteristics suited to the requirements of a safe gripper such as torque holding without power, variable stiffness and force sensing.",
        "primary_area": "",
        "author": "Chandramouly Ulagaoozhian;Vincent Duchaine;Chandramouly Ulagaoozhian;Vincent Duchaine",
        "authorids": "/37089663354;/37293913400;/37089663354;/37293913400",
        "aff": "Control and Robotics Laboratory, Ecole de Technologie Superieure University, Montreal, QC, Canada; Control and Robotics Laboratory, Ecole de Technologie Superieure University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981155/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:SrasZB3ljNEJ:scholar.google.com/&scioq=A+Novel+Human-Safe+Robotic+Gripper:+An+application+of+a+Programmable+Permanent+Magnet+Actuator&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ecole de Technologie Superieure University",
        "aff_unique_dep": "Control and Robotics Laboratory",
        "aff_unique_url": "https://www.etsmtl.ca",
        "aff_unique_abbr": "ETS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981219",
        "title": "A Novel Perceptive Robotic Cane with Haptic Navigation for Enabling Vision-Independent Participation in the Social Dynamics of Seat Choice",
        "track": "main",
        "status": "Poster",
        "abstract": "Goal-based navigation in public places is critical for independent mobility and for breaking barriers that exist for blind or visually impaired (BVI) people in a sight-centric society. Through this work we present a proof-of-concept system that autonomously leverages goal-based navigation assistance and perception to identify socially preferred seats and safely guide its user towards them in unknown indoor environments. The robotic system includes a camera, an IMU, vibrational motors, and a white cane, powered via a backpack-mounted laptop. The system combines techniques from computer vision, robotics, and motion planning with insights from psychology to perform 1) SLAM and object localization, 2) goal disambiguation and scoring, and 3) path planning and guidance. We introduce a novel 2-motor haptic feedback system on the cane's grip for navigation assistance. Through a pilot user study we show that the system is successful in classifying and providing haptic navigation guidance to socially preferred seats, while optimizing for users' convenience, privacy, and intimacy in addition to increasing their confidence in independent navigation. The implications are encouraging as this technology, with careful design guided by the BVI community, can be adopted and further developed to be used with medical devices enabling the BVI population to better independently engage in socially dynamic situations like seat choice.",
        "primary_area": "",
        "author": "Shivendra Agrawal;Mary Etta West;Bradley Hayes;Shivendra Agrawal;Mary Etta West;Bradley Hayes",
        "authorids": "/37086802642;/37089195452;/38573944100;/37086802642;/37089195452;/38573944100",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Colorado Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981219/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1295743504068184497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981434",
        "title": "A Novel Robot with Rolling and Climbing Modes for Power Transmission Line Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "As a hard high-altitude work, power transmission line inspection increasingly demands robots to conduct in place of the human being. A variety of robots have been developed to this end, with basic locomotion and inspection implemented on the lines. However, most current line inspection robots (LIRs) are only mobile platforms with complex structures and large weights, lacking sufficiently dexterous locomotion on lines, especially for obstacle overcoming and line transition. Also with sensors fixed on the platform, the inspection range is largely limited. For higher mobility and a larger inspection range, a novel biped robot that can roll and climb on a power transmission line for inspection, called Climbot-L, is proposed in this paper. While the rolling mode has the advantage of high locomotion efficiency, the biped climbing mode makes it possible to easily overcome obstacles on the line, transition to adjacent cables, and have multi-view detection. In this paper, the design of this novel robot is first introduced, the working principle of the wheel-gripper modules is then analyzed, and obstacle overcoming gaits are stated. The effectiveness and high maneuverability of the presented robot are verified by a series of experiments.",
        "primary_area": "",
        "author": "Qiang Fu;Yisheng Guan;Haifei Zhu;Qiang Fu;Yisheng Guan;Haifei Zhu",
        "authorids": "/37089283831;/37402001000;/37853668000;/37089283831;/37402001000;/37853668000",
        "aff": "Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981434/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14467222334847981103&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Guangdong University of Technology",
        "aff_unique_dep": "School of Electromechanical Engineering",
        "aff_unique_url": "http://www.gdut.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981169",
        "title": "A Novel Simulation-Based Quality Metric for Evaluating Grasps on 3D Deformable Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Evaluation of grasps on deformable 3\\mathrm{D}3\\mathrm{D} objects is a little-studied problem, even if the applicability of rigid object grasp quality measures for deformable ones is an open question. A central issue with most quality measures is their dependence on contact points, which for deformable objects depend on the deformations. This paper proposes a grasp quality measure for deformable objects that uses information about object deformation to calculate the grasp quality. Grasps are evaluated by simulating the deformations during grasping and predicting the contacts between the gripper and the grasped object. The contact information is then used as input for a new grasp quality metric to quantify the grasp quality. The approach is benchmarked against two classical rigid-body quality metrics on over 600 grasps in the Isaac gym simulation and over 50 real-world grasps. Experimental results show an average improvement of 18% in the grasp success rate for deformable objects compared to the classical rigid-body quality metrics. Furthermore, the proposed approach is approximately fifteen times faster to calculate than the shake task, which, to date, is one of the most reliable approaches to quantify a grasp on a deformable object.",
        "primary_area": "",
        "author": "Tran Nguyen Le;Jens Lundell;Fares J. Abu-Dakka;Ville Kyrki;Tran Nguyen Le;Jens Lundell;Fares J. Abu-Dakka;Ville Kyrki",
        "authorids": "/37088580421;/37086575749;/37086302962;/37274001900;/37088580421;/37086575749;/37086302962;/37274001900",
        "aff": "Intelligent Robotics Group at the Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, Finland; Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden; Intelligent Robotics Group at the Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, Finland; Intelligent Robotics Group at the Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981169/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=931437405477776475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Aalto University;KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering and Automation;EECS",
        "aff_unique_url": "https://www.aalto.fi;https://www.kth.se",
        "aff_unique_abbr": "Aalto;KTH",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stockholm",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Finland;Sweden"
    },
    {
        "id": "9981240",
        "title": "A Novel Wheelchair-Exoskeleton Hybrid Robot to Assist Movement and Aid Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "As a traditional movement assist equipment for people with lower-limb dysfunction, the wheelchair can support and carry users to perform a long-distance movement indoor and outdoor, however, prolonged inactivity can lead to muscle atrophy and deteriorate motion functions. As a promising solution, the lower limb exoskeleton provides people the ability of standing and walking to avoid these problems. However, the exoskeleton has inevitable shortcomings in long-distance movement and balance, which do not exist in a wheelchair. To integrate the advantages of both devices, in this paper, we proposed a wheelchair-exoskeleton hybrid robot (WeHR) that can not only provide users long-time support and long-distance movement but also provide walking training and keep self-balance. Moreover, motion transitions such as sit-to-stand and stand-to-sit can also be implemented by the newly proposed device without help from caregivers. We have developed the prototype to implement the above functions. In this paper, we emphasize the strategy of motion transition including two trajectory planning methods for the Sit-To-Stand (STS) process as well as the mechanism design to implement it. Furthermore, the preliminary experiments of motion transition and walking test are also conducted and the results prove that our device can support users sitting, standing, and walking and the motion transition.",
        "primary_area": "",
        "author": "Zhibin Song;Wenjie Ju;Dechao Chen;Hexi Gong;Rongjie Kang;Paolo Dario;Zhibin Song;Wenjie Ju;Dechao Chen;Hexi Gong;Rongjie Kang;Paolo Dario",
        "authorids": "/37086152459;/37089658200;/37089662210;/37089661827;/37882373200;/37280269300;/37086152459;/37089658200;/37089662210;/37089661827;/37882373200;/37280269300",
        "aff": "Key Laboratory of Mechanism Theory and Equipment Design, Ministry of Education, School of Mechanical Engineering, Centre for Advanced Mechanisms and Robotics, Tianjin University, China; Key Laboratory of Mechanism Theory and Equipment Design, Ministry of Education, School of Mechanical Engineering, Centre for Advanced Mechanisms and Robotics, Tianjin University, China; Key Laboratory of Mechanism Theory and Equipment Design, Ministry of Education, School of Mechanical Engineering, Centre for Advanced Mechanisms and Robotics, Tianjin University, China; Key Laboratory of Mechanism Theory and Equipment Design, Ministry of Education, School of Mechanical Engineering, Centre for Advanced Mechanisms and Robotics, Tianjin University, China; Key Laboratory of Mechanism Theory and Equipment Design, Ministry of Education, School of Mechanical Engineering, Centre for Advanced Mechanisms and Robotics, Tianjin University, China; Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981240/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9744863726664215885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Tianjin University;Scuola Superiore Sant'Anna",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Excellence in Robotics and AI",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.sssup.it",
        "aff_unique_abbr": "Tianjin U;SSSA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pisa",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "9981954",
        "title": "A Novel Wire-driven 3D Eyebrow Design for Communication with Humanoid Robot iCub",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this research is to contribute to social communication between humans and robots in scenes that have been considered difficult due to the limited facial expression capabilities of robots. In order to provide more detailed facial expressions, we designed a novel wire-driven 3D eyebrow using a soft material with a bending structure. We then demonstrated the mechanical properties of the eyebrow design and developed a prototype that could be implemented on the humanoid robot iCub to verify its operation. Lastly, we confirmed that the new design enables the production of more slight changes in facial expressions by allowing the eyebrows to change their shape at more delicate angles and continuity than the LED eyebrows of the conventional iCub.",
        "primary_area": "",
        "author": "Motonobu Aoki;Karthikeyan Kalyanasundaram Balasubramanian;Diego Torazza;Francesco Rea;Doreen Jirak;Giulio Sandini;Takura Yanagi;Atsushi Takamatsu;Stephane Bouet;Tomohiro Yamamura;Motonobu Aoki;Karthikeyan Kalyanasundaram Balasubramanian;Diego Torazza;Francesco Rea;Doreen Jirak;Giulio Sandini;Takura Yanagi;Atsushi Takamatsu;Stephane Bouet;Tomohiro Yamamura",
        "authorids": "/37089660954;/37089375951;/37088476644;/37948228400;/38546720500;/37295479800;/37086537405;/37088586232;/37089660698;/37089662933;/37089660954;/37089375951;/37088476644;/37948228400;/38546720500;/37295479800;/37086537405;/37088586232;/37089660698;/37089662933",
        "aff": "Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS), The University of Genoa, Italy; Electronics Design Laboratory (EDL), Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences (RBCS), Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences (RBCS), Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences (RBCS), Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences (RBCS), Italian Institute of Technology, Genoa, Italy; Mobility and AI laboratory, Research Division, Nissan Motor Co., Ltd., Kanagawa, Japan; Mobility and AI laboratory, Research Division, Nissan Motor Co., Ltd., Kanagawa, Japan; Mobility and AI laboratory, Research Division, Nissan Motor Co., Ltd., Kanagawa, Japan; Mobility and AI laboratory, Research Division, Nissan Motor Co., Ltd., Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981954/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17967530349687105106&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;1;1;1;2;2;2;2",
        "aff_unique_norm": "University of Genoa;Italian Institute of Technology;Nissan Motor Co., Ltd.",
        "aff_unique_dep": "Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS);Electronics Design Laboratory (EDL);Mobility and AI laboratory, Research Division",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it;https://www.nissan-global.com",
        "aff_unique_abbr": ";IIT;Nissan",
        "aff_campus_unique_index": "1;1;1;1;1",
        "aff_campus_unique": ";Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0;1;1;1;1",
        "aff_country_unique": "Italy;Japan"
    },
    {
        "id": "9981682",
        "title": "A Null-space based Approach for a Safe and Effective Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "During physical human robot collaboration, it is important to be able to implement a time-varying interactive behaviour while ensuring robust stability. Admittance control and passivity theory can be exploited for achieving these objectives. Nevertheless, when the admittance dynamics is time-varying, it can happen that, for ensuring a passive and stable behaviour, some spurious dissipative effects have to be introduced in the admittance dynamics. These effects are perceived by the user and degrade the collaborative performance. In this paper we exploit the task redundancy of the manipulator in order to harvest energy in the null space and to avoid spurious dynamics on the admittance. The proposed architecture is validated by simulations and by experiments onto a collaborative robot.",
        "primary_area": "",
        "author": "Federico Benzi;Cristian Secchi;Federico Benzi;Cristian Secchi",
        "authorids": "/37088995970;/37300905500;/37088995970;/37300905500",
        "aff": "Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981682/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11401159177857389486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981596",
        "title": "A Pneumatic MR-conditional Guidewire Delivery Mechanism with Decoupled Actuations for Endovascular Intervention",
        "track": "main",
        "status": "Poster",
        "abstract": "Percutaneous coronary intervention (PCI) involves the delivery of a flexible submillimeter guidewire and existing x- ray based approaches impose significant ironing radiation. The use of magnetic resonance imaging (MRI) for intraoperative guidance has the advantages of not only being safe but also having high positioning accuracy and excellent tissue contrast. This paper develops a pneumatically driven MR-conditional delivery mechanism for the ease of manipulation of the guidewire in vivo. It incorporates newly developed rotary pneumatic step motors and a pneumatic slip ring for actuation and decoupling of translational and rotational motions. An effective clamping mechanism for the locking and releasing of the guidewire is also incorporated. The proposed pneumatic slip ring mechanism decouples six gas lines, where four are used to supply a pneumatic step motor for translational motion and two for the clamping mechanism. High friction sil sleeve is used to hold the guidewire firmly. The rotary pneumatic motor has excellent sealing and stability, providing an output torque of 15.75 Nm/MPa. Experiments show that the average error of translational motion is 0.37 mm. Real-time MRI-guided endovascular intervention is performed in a vascular phantom with pulsatile flows to validate its potential clinical use. The imaging artifact test under MRI shows no noticeable distortion and the loss of Signal-to-Noise Ratio (SNR) is less than 2%.",
        "primary_area": "",
        "author": "Shaoping Huang;Chuqian Lou;Lian Xuan;Hongyan Gao;Anzhu Gao;Guang\u2013Zhong Yang;Shaoping Huang;Chuqian Lou;Lian Xuan;Hongyan Gao;Anzhu Gao;Guang\u2013Zhong Yang",
        "authorids": "/37086543846;/37089002000;/37089663954;/37089569303;/38027228000;/37276270800;/37086543846;/37089002000;/37089663954;/37089569303;/38027228000;/37276270800",
        "aff": "Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Materials and Technology Center of Robotics, Switzerland; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Jiao Tong University, Shanghai, China; Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981596/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9778894425062471661&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Materials and Technology Center of Robotics;Jiao Tong University",
        "aff_unique_dep": "Institute of Medical Robotics, School of Biomedical Engineering;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;;https://www.jtu.edu.cn",
        "aff_unique_abbr": "SJTU;;JTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;Switzerland"
    },
    {
        "id": "9982040",
        "title": "A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a portable multiscopic camera system with a dedicated model for novel view and time synthesis in dynamic scenes. Our goal is to render high-quality images for a dynamic scene from any viewpoint at any time using our portable multiscopic camera. To achieve such novel view and time synthesis, we develop a physical multiscopic camera equipped with five cameras to train a neural radiance field (NeRF) in both time and spatial domains for dynamic scenes. Our model maps a 6D coordinate (3D spatial position, 1D temporal coordinate, and 2D viewing direction) to view-dependent and time-varying emitted radiance and volume density. Volume rendering is applied to render a photo-realistic image at a specified camera pose and time. To improve the robustness of our physical camera, we propose a camera parameter optimization module and a temporal frame interpolation module to promote information propagation across time. We conduct experiments on both real-world and synthetic datasets to evaluate our system, and the results show that our approach outperforms alternative solutions qualitatively and quantitatively. Our code and dataset are available at https://yuenfuilau.github.io/.",
        "primary_area": "",
        "author": "Tianjia Zhang;Yuen-Fui Lau;Qifeng Chen;Tianjia Zhang;Yuen-Fui Lau;Qifeng Chen",
        "authorids": "/37089658441;/37089663426;/37087230927;/37089658441;/37089663426;/37087230927",
        "aff": "Individualized Interdisciplinary Program, Robotics Institute, Hong Kong University of Science and Technology, Hong Kong, China; Department of Mathematics, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982040/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9285886500720969608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982185",
        "title": "A Proprioceptive Method for Soft Robots Using Inertial Measurement Units",
        "track": "main",
        "status": "Poster",
        "abstract": "Proprioception, or the perception of the configuration of one's body, is challenging to achieve with soft robots due to their infinite degrees of freedom and incompatibility with most off-the-shelf sensors. This work explores the use of inertial measurement units (IMUs), sensors that output orientation with respect to the direction of gravity, to achieve soft robot proprioception. A simple method for estimating the shape of a soft continuum robot arm from IMUs mounted along the arm is presented. The approach approximates a soft arm as a serial chain of rigid links, where the orientation of each link is given by the output of an IMU or by spherical linear interpolation of the output of adjacent IMUs. In experiments conducted on a 660mm long real-world soft arm, this approach provided estimates of its end effector position with a median error of less than 10% of the arm's length. This demonstrates the potential of IMUs to serve as inexpensive off-the-shelf sensors for soft robot proprioception.",
        "primary_area": "",
        "author": "Yves J. Martin;Daniel Bruder;Robert J. Wood;Yves J. Martin;Daniel Bruder;Robert J. Wood",
        "authorids": "/37089660809;/37086161684;/37326227400;/37089660809;/37086161684;/37326227400",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982185/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9666995151979015831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982127",
        "title": "A Riemannian Take on Human Motion Analysis and Retargeting",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic motions of humans and robots are widely driven by posture-dependent nonlinear interactions between their degrees of freedom. However, these dynamical effects remain mostly overlooked when studying the mechanisms of human movement generation. Inspired by recent works, we hypothesize that human motions are planned as sequences of geodesic synergies, and thus correspond to coordinated joint movements achieved with piecewise minimum energy. The underlying computational model is built on Riemannian geometry to account for the inertial characteristics of the body. Through the analysis of various human arm motions, we find that our model segments motions into geodesic synergies, and successfully predicts observed arm postures, hand trajectories, as well as their respective velocity profiles. Moreover, we show that our analysis can further be exploited to transfer arm motions to robots by reproducing individual human synergies as geodesic paths in the robot configuration space.",
        "primary_area": "",
        "author": "Holger Klein;No\u00e9mie Jaquier;Andre Meixner;Tamim Asfour;Holger Klein;No\u00e9mie Jaquier;Andre Meixner;Tamim Asfour",
        "authorids": "/37089661844;/37086290815;/37088340400;/37295529100;/37089661844;/37086290815;/37088340400;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982127/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2293383449375169230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981773",
        "title": "A Robot Factors Approach to Designing Modular Hardware",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are increasingly being called on to operate in settings and on tasks originally designed for humans, or where humans are also expected to work. Accordingly, the hardware and tools to be packaged, operated, or maintained are typically designed for use by humans, not robots. Robot autonomy in such cases can be expedited by a \u201crobot factors\u201d approach to the design of hardware, analogous to ergonomics for humans, taking typical current robot capabilities into account during the design process. In this paper, we present two case studies of redesigning mission-critical hardware in space habitats to facilitate autonomous robot operation. In both cases, hardware that previously required dexterous bi-manual manipulation is redesigned such that the entire maintenance task can be completed by a single robotic arm with a standard parallel jaw gripper. We demonstrate successful autonomous replacement of modules in the two hardware systems, and characterize how orientation and compliance of a grasp helps compensate for positioning errors. Based on our findings, we identify several key design strategies that underpin the robot factors approach to designing robot-friendly hardware, including consolidating compound actions into simpler mechanisms, constraining required motions to a single axis, and introducing mechanical compliance to mitigate the effects of pose uncertainties.",
        "primary_area": "",
        "author": "Nathan Melenbrink;Clark Teeple;Justin Werfel;Nathan Melenbrink;Clark Teeple;Justin Werfel",
        "authorids": "/37086291970;/37086131116;/37266345300;/37086291970;/37086131116;/37266345300",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981773/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14724286980065803798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981910",
        "title": "A Robotic Aerial Platform with Functionally Anthropomorphic Arms designed for Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Frequently, ground robots are hampered by debris and objects on the ground, and safely surpassing them is not always trivial. On the contrary, a robot capable of flying is intrinsically immune to such obstacles and, therefore, greatly enhances the possibility of inspecting and intervening in adverse surroundings for humans. This work introduces a novel teleoperated aerial platform for inspection and intervention in unstructured environments. The robot is composed of an aerial base, two arms, and a two-degrees-of-freedom head that consent the access of human operators in any workplace in total safety. The arms are designed with a joint structure of tendons and are held by elastic components. This composition considerably improves the robustness by inserting softness and redistributing the weights to lessen the actions on the drone. Moreover, the aerial platform employs two soft hands capable of adapting to the shape of the objects under grasp, increasing the manipulation performance. We presented the mechanical and control design, a gazebo simulation employed to test the controllers, and a physical structure for the experimental validation of the system. The system is available as Open-Source material.",
        "primary_area": "",
        "author": "Fanyi Kong;Simone Monteleone;Giorgio Grioli;Manuel G. Catalano;Antonio Bicchi;Fanyi Kong;Simone Monteleone;Giorgio Grioli;Manuel G. Catalano;Antonio Bicchi",
        "authorids": "/37089660766;/37088353884;/37590311700;/37544547800;/37278626700;/37089660766;/37088353884;/37590311700;/37544547800;/37278626700",
        "aff": "Dipartimento di Ingegneria dell'Informazione, Centro di Ricerca E. Piaggio, Universit\u00e0 di Pisa, Pisa, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981910/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11701369820805542661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Universit\u00e0 di Pisa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dipartimento di Ingegneria dell'Informazione;",
        "aff_unique_url": "https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": "UNipi;IIT",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Pisa;Genova",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981281",
        "title": "A Robust Sidewalk Navigation Method for Mobile Robots Based on Sparse Semantic Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Last-mile delivery robots are usually required to navigate on the sidewalk through a fixed route. The current solutions heavily rely on the image-based perception and GPS localization to successfully complete delivery tasks. However, it is prone to fail and become unreliable when the robot runs in challenging conditions, such as operating in different illuminations, or under canopies of trees or buildings. To address these issues, this paper proposes a novel robust sidewalk navigation method for the last-mile delivery robots with an affordable sparse LiDAR, which consists of two main modules: Semantic Point Cloud Network (SegPCn) and Reactive Nav-igation Network (RNn), as shown in Fig. 1. More specifically, SegPCn takes the raw 3D point cloud as input and predicts the point-wise segmentation labels, presenting a robust perception capability even in the night. Then, the semantic point clouds are fed to RNn to generate an angular velocity to navigate the robot along the sidewalk, where the localization of the robot is not required. Moreover, an autolabeling mechanism is developed to reduce the labor involved in data preparation as well. And the LSTM neural network is explored to effectively leverage the historical context and derive correct decisions. Extensive experiments have been carried out to verify the efficacy of this method, and the results show that this method enables the robot to navigate on the sidewalk robustly during day and night. We open source the code and the data set on https://github.com/lukewenMX/Robust-Navigation-Method.",
        "primary_area": "",
        "author": "Mingxing Wen;Yunxiang Dai;Tairan Chen;Chunyang Zhao;Jun Zhang;Danwei Wang;Mingxing Wen;Yunxiang Dai;Tairan Chen;Chunyang Zhao;Jun Zhang;Danwei Wang",
        "authorids": "/37086451677;/37089659169;/37089662912;/37088406475;/37086009222;/37279547600;/37086451677;/37089659169;/37089662912;/37088406475;/37086009222;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981281/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17299612104393794549&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9982059",
        "title": "A Robust and Fast Occlusion-based Frontier Method for Autonomous Navigation in Unknown Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation through unknown, cluttered environments is a fundamental and challenging task for autonomous vehicles as they must deal with a myriad of obstacle configurations typically unknown a priori. Challenges arise because obstacles of unknown shapes and dimensions can create occlusions limiting sensor field of view and leading to uncertainty in motion planning. In this paper we propose to leverage such occlusions to quickly explore and cover unknown cluttered environments. Specifically, this work presents a novel occlusion-aware frontier-based approach that estimates gaps in point cloud data and shadows in the field of view to generate waypoints to navigate. Our scheme also proposes a breadcrumbing technique to save states of interest during exploration that can be exploited in future missions. For the latter aspect we focus primarily on the generation of the minimum number of breadcrumbs that will increase coverage and visibility of an explored environment. Extensive simulations and experiment results on an unmanned ground vehicle (UGV) are demonstrated to validate the proposed technique, showing improvements over traditional state of the art frontier-based exploration methods.",
        "primary_area": "",
        "author": "Nicholas Mohammad;Nicola Bezzo;Nicholas Mohammad;Nicola Bezzo",
        "authorids": "/37089629991;/37546843800;/37089629991;/37546843800",
        "aff": "Departments of Computer Science, Engineering Systems and Environment, and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Departments of Computer Science, Engineering Systems and Environment, and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982059/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4361021665660369265&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Departments of Computer Science, Engineering Systems and Environment, and Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981083",
        "title": "A Sampling Based Approach to Robust Planning for a Planetary Lander",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning for autonomous operation in unknown environments poses a number of technical challenges. The agent must ensure robustness to unknown phenomena, un-predictable variation in execution, and uncertain resources, all while maximizing its objective. These challenges are ex-acerbated in the context of space missions where uncertainty is often higher, long communication delays necessitate robust autonomous execution, and severely constrained computational resources limit the scope of planning techniques that can be used. We examine this problem in the context of a Europa Lander concept mission where an autonomous lander must collect valuable data and communicate that data back to Earth. We model the problem as a hierarchical task network, framing it as a utility maximization problem constrained by a strictly monotonically decreasing energy resource. We propose a novel deterministic planning framework that uses periodic replanning and sampling-based optimization to better handle model uncertainty and execution variation, while remaining computationally tractable. We demonstrate the efficacy of our framework through simulations of a Europa Lander concept mission in which our approach outperforms several baselines in utility maximization and robustness.",
        "primary_area": "",
        "author": "Connor Basich;Joseph A. Russino;Steve Chien;Shlomo Zilberstein;Connor Basich;Joseph A. Russino;Steve Chien;Shlomo Zilberstein",
        "authorids": "/37087105976;/37089663820;/37279813400;/37285091900;/37087105976;/37089663820;/37279813400;/37285091900",
        "aff": "University of Massachusetts Amherst, Amherst, Massachusetts; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, California; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, California; University of Massachusetts Amherst, Amherst, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981083/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13809375299154176248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Massachusetts Amherst;California Institute of Technology",
        "aff_unique_dep": ";Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.umass.edu;https://www.caltech.edu",
        "aff_unique_abbr": "UMass Amherst;Caltech",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Amherst;Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981483",
        "title": "A Saturation-Aware Trajectory-Based Explicit Reference Governor for a Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "As with all actuated mechanical systems, the development of a control scheme for robotic systems must take actuator saturation into account. Furthermore, in order to properly control a robotic arm, other types of mechanical limitations must also be considered (e.g. limited operating range of the joint, speed limitations). In this paper, we propose a saturation-aware trajectory-based Explicit Reference Governor, a lightweight constrained control scheme with no online optimization. Additionally, we tested the effectiveness of the proposed control architecture on a 7 degree-of-freedom KUKA LBR IIWA14 R820. Both the performance and the computational time of our proposed solution were tested against other constrained control solutions available in the literature.",
        "primary_area": "",
        "author": "Michele Ambrosino;Andres Cotorruelo;Emanuele Garone;Michele Ambrosino;Andres Cotorruelo;Emanuele Garone",
        "authorids": "/37088913566;/37086531949;/37299281800;/37088913566;/37086531949;/37299281800",
        "aff": "Service d'Automatique et d'Analyse des Syst\u00e8mes, Universit\u00e9 Libre de Bruxelles, Brussels, Belgium; Service d'Automatique et d'Analyse des Syst\u00e8mes, Universit\u00e9 Libre de Bruxelles, Brussels, Belgium; Service d'Automatique et d'Analyse des Syst\u00e8mes, Universit\u00e9 Libre de Bruxelles, Brussels, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981483/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2855321567747860256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 Libre de Bruxelles",
        "aff_unique_dep": "Service d'Automatique et d'Analyse des Syst\u00e8mes",
        "aff_unique_url": "https://www.ulb.ac.be",
        "aff_unique_abbr": "ULB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brussels",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9981265",
        "title": "A Soft Fabric-based Shrink-to-fit Pneumatic Sleeve for Comfortable Limb Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Upper limb impairments and weakness are com-mon post-stroke and with advanced aging. Rigid exoskeletons have been developed as a potential solution, but have had limited impact. In addition to user concerns about safety, their weight and appearance, the rigid attachment and typical anchoring methods can result in skin damage. In this paper, we present a soft, fabric-based pneumatic sleeve, which can shrink from a loose fit to a tight fit in order to anchor to the limbs temporarily, thereby enabling the application of mechanical assistance only when needed. The sleeve is comfortable, ergonomic and can be embedded unobtrusively with clothing. A mathematical model is built to simulate and design sleeves with different geometric parameters. The best sleeve was capable of generating a friction force of 98 N on the limb when inflated to 25 kPa. This sleeve was used to create a wearable assistive device, integrated with a cable-driven actuator. This device was able to lift a 1.44 kg forearm rig up to 95 degree at low pressure of 20 kPa. The device was tested with six healthy participants, in terms of fit, comfort and assistive functionality. The average acceptable sleeve pressure was found to be 33\u00b14.7 kPa. All participants liked the appearance of the sleeve, with a high average perceived assistance score of 7.33\u00b11.6 (out of 10). The shrink-to-fit sleeve is expected to significantly increase the development and adoption of soft robotic assistive devices and emerging powered clothing.",
        "primary_area": "",
        "author": "Richard Suphapol Diteesawat;Sam Hoh;Emanuele Pulvirenti;Nahian Rahman;Leah Morris;Ailie Turton;Mary Cramp;Jonathan Rossiter;Richard Suphapol Diteesawat;Sam Hoh;Emanuele Pulvirenti;Nahian Rahman;Leah Morris;Ailie Turton;Mary Cramp;Jonathan Rossiter",
        "authorids": "/37086843168;/37088504851;/37089371807;/37089658746;/37089662794;/37086281395;/37089662007;/37271190700;/37086843168;/37088504851;/37089371807;/37089658746;/37089662794;/37086281395;/37089662007;/37271190700",
        "aff": "Department of Engineering Math-ematics, Bristol Robotics Laboratory (BRL), University of Bristol, Bristol, UK; Department of Engineering Math-ematics, Bristol Robotics Laboratory (BRL), University of Bristol, Bristol, UK; Department of Engineering Math-ematics, Bristol Robotics Laboratory (BRL), University of Bristol, Bristol, UK; Department of Engineering Math-ematics, Bristol Robotics Laboratory (BRL), University of Bristol, Bristol, UK; School of Health and Social Wellbeing, University of the West of England, and BRL, Bristol, UK; School of Health and Social Wellbeing, University of the West of England, and BRL, Bristol, UK; School of Health and Social Wellbeing, University of the West of England, and BRL, Bristol, UK; Department of Engineering Math-ematics, Bristol Robotics Laboratory (BRL), University of Bristol, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981265/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3741005687086676684&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;1;0",
        "aff_unique_norm": "University of Bristol;University of the West of England",
        "aff_unique_dep": "Department of Engineering Mathematics;School of Health and Social Wellbeing",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.uwe.ac.uk",
        "aff_unique_abbr": "UoB;UWE",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981059",
        "title": "A Soft Fluidic Sensor-Actuator for Active Sensing of Force and Displacement in Biomedical Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving compact and biocompatible actuators with sensing capabilities is a key challenge for the safety critical and highly patient-specific biomedical field. In this study, a compact and versatile soft fluidic sensor-actuator capable of measuring both force and displacement in static and dynamic conditions is presented. Pressure and resistance are shown to be interchangeable in predicting load and sensor-actuator height, and showed good repeatability and distinction between the loaded and constrained conditions tested. Furthermore the sensor-actuator is demonstrated in a probe application and showed comparable findings to a tensile test machine when tested on three objects of varying stiffness. Overall, this sensor-actuator has the potential to be a key building block for biomedical robots that require large expansion, as well as continuous monitoring of both displacement and force.",
        "primary_area": "",
        "author": "Joanna Jones;Dana D. Damian;Joanna Jones;Dana D. Damian",
        "authorids": "/37088198042;/37587456200;/37088198042;/37587456200",
        "aff": "Department of Automatic Control and Systems Engineering, Sheffield Biomedical Robotics Laboratory, University of Sheffield, United Kingdom; Insigneo Institute for in silico Medicine, University of Sheffield, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981059/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3102521345772067378&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Sheffield",
        "aff_unique_dep": "Department of Automatic Control and Systems Engineering",
        "aff_unique_url": "https://www.sheffield.ac.uk",
        "aff_unique_abbr": "Sheffield",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sheffield;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981652",
        "title": "A Soft Robotic Haptic Feedback Glove for Colonoscopy Procedures",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a proof-of-concept soft robotic glove that provides haptic feedback to the surgeon's hand during interventional endoscopy procedures, specifically colonoscopy. The glove is connected to a force sensing soft robotic sleeve that is mounted onto a colonoscope. The glove consists of pneumatic actuators that inflate in proportion to the incident forces on the soft robotic sleeve. Thus, the glove is capable of alerting the surgeon of potentially dangerous forces exerted on the colon wall by the colonoscope during the navigation. The proposed glove is adaptable to a variety of hand sizes. It features modular actuators that facilitate convenient and rapid assembly and attachment before the procedure and removal afterward. The glove is calibrated to respond to incident forces on the soft robotic sleeve ranging from 0\u20133 N. The glove's actuators are able to reach an internal pressure of 53 kPa and exert forces up to 20 N, thereby relaying and amplifying the force exerted by the colonoscope on the colon to the surgeon's hand.",
        "primary_area": "",
        "author": "Arincheyan Gerald;Rukaiya Batliwala;Jonathan Ye;Patra Hsu;Hiroyuki Aihara;Sheila Russo;Arincheyan Gerald;Rukaiya Batliwala;Jonathan Ye;Patra Hsu;Hiroyuki Aihara;Sheila Russo",
        "authorids": "/37088853929;/37089659872;/37089661058;/37089659402;/37085803384;/38239019900;/37088853929;/37089659872;/37089661058;/37089659402;/37085803384;/38239019900",
        "aff": "Mechanical Engineering Department, Boston University, Boston, MA, USA; Mechanical Engineering Department, Boston University, Boston, MA, USA; Mechanical Engineering Department, Boston University, Boston, MA, USA; Biomedical Engineering Department, Boston University, Boston, MA, USA; Brigham and Women's Hospital, Harvard Medical School, Boston, MA, USA; Materials Science and Engineering Division, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981652/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16594230942240676572&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Boston University;Brigham and Women's Hospital",
        "aff_unique_dep": "Mechanical Engineering Department;Harvard Medical School",
        "aff_unique_url": "https://www.bu.edu;https://www.brighamandwomens.org",
        "aff_unique_abbr": "BU;BWH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981231",
        "title": "A Solution to Adaptive Mobile Manipulator Throwing",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulator throwing is a promising method to increase the flexibility and efficiency of dynamic manipulation in factories. Its major challenge is to efficiently plan a feasible throw under a wide set of task specifications. We show that the mobile manipulator throwing problem can be simplified to a planar problem, hence greatly reducing the computational costs. Using machine learning approaches, we build a model of the object's inverted flying dynamics and the robot's kinematic feasibility, which enables throwing motion generation within 1 ms for given query of target position. Thanks to the computational efficiency of our method, we show that the system is adaptive under disturbance, via replanning on the fly for alternative solutions, instead of sticking to the original throwing plan.",
        "primary_area": "",
        "author": "Yang Liu;Aradhana Nayak;Aude Billard;Yang Liu;Aradhana Nayak;Aude Billard",
        "authorids": "/37089664156;/37089662711;/37273980800;/37089664156;/37089662711;/37273980800",
        "aff": "Learning Algorithms and Systems Laboratory, Switzerland; Learning Algorithms and Systems Laboratory, Switzerland; Learning Algorithms and Systems Laboratory, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981231/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14391063832357308922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Learning Algorithms and Systems Laboratory",
        "aff_unique_dep": "Learning Algorithms and Systems",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981173",
        "title": "A Solution to Slosh-free Robot Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is about fast slosh-free fluid transportation. Existing approaches are either computationally heavy or only suitable for specific robots and container shapes. We model the end effector as a point mass suspended by a spherical pendulum and study the requirements for slosh-free motion and the validity of the point mass model. In this approach, slosh-free trajectories are generated by controlling the pendulum's pivot and simulating the motion of the point mass. We cast the trajectory optimization problem as a quadratic program-this strategy can be used to obtain valid control inputs. Through simulations and experiments on a 7 DoF Franka Emika Panda robot we validate the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Rafael I. Cabral Muchacho;Riddhiman Laha;Luis F.C. Figueredo;Sami Haddadin;Rafael I. Cabral Muchacho;Riddhiman Laha;Luis F.C. Figueredo;Sami Haddadin",
        "authorids": "/37089663190;/37089002102;/37063909900;/37542865300;/37089663190;/37089002102;/37063909900;/37542865300",
        "aff": "Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981173/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3880983165180966145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Munich Institute of Robotics & Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981626",
        "title": "A Standards-based Pipeline Route Drawing System using a Towed Sensing Unit",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method of drawing pipeline routes using a sensing unit with a rotary encoder and IMU (Inertial Measurement Unit), which is towed by a self-propelled in-pipe inspection robot. However, the IMU information generally contains integration errors, making it difficult to draw accurate pipeline routes. In this study, we propose a method combining gradient descent using a gyroscopic sensor and an accelerometer, and the correction of the route based on the standard information of the pipe. First, the method of identifying the start point, end point, direction of straight pipes, and bending direction of curved pipes is explained. Then, an experiment is conducted using the developed robot system on a 11.6-meter-long pipeline course that includes nine curved pipes and horizontal and vertical straight pipes. Consequently, the mean absolute error of the route dimension was reduced to 2.74 %.",
        "primary_area": "",
        "author": "Atsushi Kakogawa;Chihiro Hirose;Shugen Ma;Atsushi Kakogawa;Chihiro Hirose;Shugen Ma",
        "authorids": "/37846134700;/37089660370;/37280187400;/37846134700;/37089660370;/37280187400",
        "aff": "Research Organization of Science and Technology, Ritsumeikan University, Kusatsu, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Rit-sumeikan University, Kusatsu, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Rit-sumeikan University, Kusatsu, Shiga, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981626/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4647231602787610565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ritsumeikan University;Rit-sumeikan University",
        "aff_unique_dep": "Research Organization of Science and Technology;Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp;https://www.rit-sumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan;Rit-sumei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981802",
        "title": "A System for Imitation Learning of Contact-Rich Bimanual Manipulation Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we discuss a framework for teaching bimanual manipulation tasks by imitation. To this end, we present a system and algorithms for learning compliant and contact-rich robot behavior from human demonstrations. The presented system combines insights from admittance control and machine learning to extract control policies that can (a) recover from and adapt to a variety of disturbances in time and space, while also (b) effectively leveraging physical contact with the environment. We demonstrate the effectiveness of our approach using a real-world insertion task involving multiple simultaneous contacts between a manipulated object and insertion pegs. We also investigate efficient means of collecting training data for such bimanual settings. To this end, we conduct a human-subject study and analyze the effort and mental demand as reported by the users. Our experiments show that, while harder to provide, the additional force/torque information available in teleoperated demonstrations is crucial for phase estimation and task success. Ultimately, force/torque data substantially improves manipulation robustness, resulting in a 90% success rate in a multipoint insertion task. Code and videos can be found at https://bimanualmanipulation.com/",
        "primary_area": "",
        "author": "Simon Stepputtis;Maryam Bandari;Stefan Schaal;Heni Ben Amor;Simon Stepputtis;Maryam Bandari;Stefan Schaal;Heni Ben Amor",
        "authorids": "/37086175304;/37085436412;/37282144700;/37293927700;/37086175304;/37085436412;/37282144700;/37293927700",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, United States; [Google] Intrinsic, Mountain View, United States; [Google] Intrinsic, Mountain View, United States; School of Computing and Augmented Intelligence, Arizona State University, Tempe, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981802/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18079052420541151748&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Carnegie Mellon University;Google;Arizona State University",
        "aff_unique_dep": "Robotics Institute;Intrinsic;School of Computing and Augmented Intelligence",
        "aff_unique_url": "https://www.cmu.edu;https://www.google.com;https://asu.edu",
        "aff_unique_abbr": "CMU;Google;ASU",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Pittsburgh;Mountain View;Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981249",
        "title": "A Tightly-Coupled Event-Inertial Odometry using Exponential Decay and Linear Preintegrated Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce an event-based visual odometry and mapping framework that relies on decaying event-based corners. Event cameras, unlike conventional cam-eras, can provide sensor data during high-speed motions or in scenes with high dynamic ranges. Rather than providing intensity information at a global shutter rate, events are trig-gered asynchronously depending on whether there is a change in brightness at the pixel location. This novel sensing paradigm calls for unconventional ego-motion estimation techniques to address these new challenges. The key aspect of our framework is the use of a continuous representation of inertial measurements to characterise the system's motion which accommodates the asynchronous nature of the event data while estimating a discrete state in an optimisation-based approach. The proposed method relies on corners extracted from events-only data and associates them with a spatio-temporal locality scheme based on exponential decay. Event tracks are then tightly coupled with temporally accurate preintegrated inertial measurements, allowing for the estimation of ego-motion and a sparse map. The proposed method is evaluated on the Event Camera Dataset showing performance against the state-of-art in event-based visual-inertial odometry.",
        "primary_area": "",
        "author": "Benny Dai;Cedric Le Gentil;Teresa Vidal-Calleja;Benny Dai;Cedric Le Gentil;Teresa Vidal-Calleja",
        "authorids": "/37089659626;/37086935323;/37085384801;/37089659626;/37086935323;/37085384801",
        "aff": "Faculty of Engineering and IT, UTS: Robotics Institute, University of Technology, Sydney, Australia; Faculty of Engineering and IT, UTS: Robotics Institute, University of Technology, Sydney, Australia; Faculty of Engineering and IT, UTS: Robotics Institute, University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981249/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10421438992061767814&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Faculty of Engineering and IT",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981619",
        "title": "A Torque Controlled Approach for Virtual Remote Centre of Motion Implementation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel torque controller for the implementation virtual remote center of motion. The controller allows the system to implement the required behavior and guarantees the satisfaction of the remote center of motion constraint. Exploiting the Udwadia-Kalaba equation for constrained dynamic systems, the controller is synthesized considering the dynamic effect the constraint produces on the manipulator, achieving more effective control with respect to kinematic strategies, and allowing the implementation of compliance behaviors. Simulations and experimental validation with a KUKA LWR 4+ with 7 degrees of freedom has been performed to check the performances of the proposed controller. Results show the effectiveness of the proposed controller with different control action, and the capability to interact with the environment by implementing compliant motion control.",
        "primary_area": "",
        "author": "Marco Minelli;Cristian Secchi;Marco Minelli;Cristian Secchi",
        "authorids": "/37086036138;/37300905500;/37086036138;/37300905500",
        "aff": "Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981619/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12415497998970832851&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981224",
        "title": "A Training-Evaluation Method for Nursing Telerobot Operator with Unsupervised Trajectory Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "To cope with the difficulty of training and eval-uation for nursing telerobot operator. This paper proposes a training-evaluation method for operator with unsupervised trajectory segmentation. To evaluate the dexterity and proce-dural knowledge of the operators objectively, we propose a new unsupervised model TSC-CRP that can automatically segment trajectory from nursing robotic training sessions. By comparing the segmented sub-trajectories and the standard sub-trajectory process, the method can provide objective evaluation and meaningful feedback without the intervention from experts. Experiments show that TSC-CRP has higher segmentation accuracy than other unsupervised methods, and it can identify the operators with different skill levels. In practical, the proposed training-evaluation system allows to provide an in-depth analysis of operator action to assess their skills precisely.",
        "primary_area": "",
        "author": "Jiexin Xie;Deliang Zhu;Jiaxin Wang;Shijie Guo;Jiexin Xie;Deliang Zhu;Jiaxin Wang;Shijie Guo",
        "authorids": "/37086487515;/37089661633;/37089450364;/37086276620;/37086487515;/37089661633;/37089450364;/37086276620",
        "aff": "Academy for Engineering and Technology, Fudan University, Shanghai, China; School of Mechanical Engineering, HeBei University of Technology, Tianjin, China; School of Mechanical Engineering, HeBei University of Technology, Tianjin, China; Academy for Engineering and Technology, Fudan University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981224/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4008857977410588726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Fudan University;Hebei University of Technology",
        "aff_unique_dep": "Academy for Engineering and Technology;School of Mechanical Engineering",
        "aff_unique_url": "https://www.fudan.edu.cn;",
        "aff_unique_abbr": "Fudan;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Shanghai;Tianjin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981133",
        "title": "A Two-stage Learning Architecture that Generates High-Quality Grasps for a Multi-Fingered Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the problem of planning stable grasps for object manipulations using an 18-DOF robotic hand with four fingers. The main challenge here is the high-dimensional search space, and we address this problem using a novel two-stage learning process. In the first stage, we train an autoregressive network called the hand-pose-generator, which learns to generate a distribution of valid 6D poses of the palm for a given volumetric object representation. In the second stage, we employ a network that regresses 12D finger joint configurations and a scalar grasp quality from given object representations and palm poses. To train our networks, we use synthetic training data generated by a novel grasp planning algorithm, which also proceeds stage-wise: first the palm pose, then the finger positions. Here, we devise a Bayesian Optimization scheme for the palm pose and a physics-based grasp pose metric to rate stable grasps. In experiments on the YCB benchmark data set, we show a grasp success rate of over 83%, as well as qualitative results grasping unknown objects on a real robot system.",
        "primary_area": "",
        "author": "Dominik Winkelbauer;Berthold B\u00e4uml;Matthias Humt;Nils Thuerey;Rudolph Triebel;Dominik Winkelbauer;Berthold B\u00e4uml;Matthias Humt;Nils Thuerey;Rudolph Triebel",
        "authorids": "/37089000838;/37295469600;/37089663752;/37088391836;/37542908700;/37089000838;/37295469600;/37089663752;/37088391836;/37542908700",
        "aff": "Technical University of Munich (TUM), Germany; Deggendorf Institute of Technology (DIT), Germany; DLR Institute of Robotics & Mechatronics, Germany; Technical University of Munich (TUM), Germany; Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981133/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=263971479816285569&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Technical University of Munich;Deggendorf Institute of Technology;Deutsches Zentrum f\u00fcr Luft- und Raumfahrt (DLR)",
        "aff_unique_dep": ";;Institute of Robotics & Mechatronics",
        "aff_unique_url": "https://www.tum.de;https://www.dit.de;https://www.dlr.de",
        "aff_unique_abbr": "TUM;DIT;DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981702",
        "title": "A Unified and Modular Model Predictive Control Framework for Soft Continuum Manipulators under Internal and External Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Fluidically actuated soft robots have promising capabilities such as inherent compliance and user safety. The control of soft robots needs to properly handle nonlinear actuation dynamics, motion constraints, workspace limitations, and variable shape stiffness, so having a unique algorithm for all these issues would be extremely beneficial. In this work, we adapt Model Predictive Control (MPC), popular for rigid robots, to a soft robotic arm called SoPrA. We address the challenges that current control methods are facing, by proposing a frame-work that handles these in a modular manner. While previous work focused on Joint-Space formulations, we show through simulation and experimental results that Task-Space MPC can be successfully implemented for dynamic soft robotic control. We provide a way to couple the Piece-wise Constant Curvature and Augmented Rigid Body Model assumptions with internal and external constraints and actuation dynamics, delivering an algorithm that unites these aspects and optimizes over them. We believe that a MPC implementation based on our approach could be the way to address most of model-based soft robotics control issues within a unified and modular framework, while allowing to include improvements that usually belong to other control domains such as machine learning techniques.",
        "primary_area": "",
        "author": "Filippo A. Spinelli;Robert K. Katzschmann;Filippo A. Spinelli;Robert K. Katzschmann",
        "authorids": "/37089659078;/37085423557;/37089659078;/37085423557",
        "aff": "Soft Robotics Lab, ETH Zurich, Z\u00fcrich, Switzerland; Soft Robotics Lab, ETH Zurich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981702/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8634866856379303815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Soft Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981216",
        "title": "A Value-based Dynamic Learning Approach for Vehicle Dispatch in Ride-Sharing",
        "track": "main",
        "status": "Poster",
        "abstract": "To ensure real-time response to passengers, existing solutions to the vehicle dispatch problem typically optimize dispatch policies using small batch windows and ignore the spatial-temporal dynamics over the long-term horizon. In this paper, we focus on improving the long-term performance of ride-sharing services and propose a deep reinforcement learning based approach for the ride-sharing dispatch problem. In particular, this work includes: (1) an offline policy evaluation (OPE) based method to learn a value function that indicates the expected reward of a vehicle reaching a particular state; (2) an online learning procedure to update the offline trained value function to capture the real-time dynamics during the operation; (3) an efficient online dispatch method that optimizes the matching policy by considering both past and future influences. Extensive simulations are conducted based on New York City taxi data, and show that the proposed solution further increases the service rate compared to the state-of-the-art farsighted ride-sharing dispatch approach.",
        "primary_area": "",
        "author": "Cheng Li;David Parker;Qi Hao;Cheng Li;David Parker;Qi Hao",
        "authorids": "/37089000323;/37271264600;/37403530000;/37089000323;/37271264600;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; School of Computer Science, University of Birmingham, Birmingham, UK; Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981216/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1481454977632241357&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Birmingham",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Computer Science",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "SUSTech;UoB",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Birmingham",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9981378",
        "title": "A Versatile Co-Design Approach For Dynamic Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a versatile framework for the computational co-design of legged robots and dynamic maneuvers. Current state-of-the-art approaches are typically based on random sampling or concurrent optimization. We propose a novel bilevel optimization approach that exploits the derivatives of the motion planning sub-problem (i.e., the lower level). These motion-planning derivatives allow us to incorporate arbitrary design constraints and costs in an general-purpose nonlinear program (i.e., the upper level). Our approach allows for the use of any differentiable motion planner in the lower level and also allows for an upper level that captures arbitrary design constraints and costs. It efficiently optimizes the robot's morphology, payload distribution and actuator parameters while considering its full dynamics, joint limits and physical constraints such as friction cones. We demonstrate these capabilities by designing quadruped robots that jump and trot. We show that our method is able to design a more energy-efficient Solo robot for these tasks.",
        "primary_area": "",
        "author": "Traiko Dinev;Carlos Mastalli;Vladimir Ivan;Steve Tonneau;Sethu Vijayakumar;Traiko Dinev;Carlos Mastalli;Vladimir Ivan;Steve Tonneau;Sethu Vijayakumar",
        "authorids": "/37088686256;/37085537096;/37085552022;/37085790049;/37295595500;/37088686256;/37085537096;/37085552022;/37085790049;/37295595500",
        "aff": "Edinburgh Centre for Robotics, University of Edinburgh, UK; School of Engineering and Physical Sciences, Heriot-Watt University, U.K; Edinburgh Centre for Robotics, University of Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981378/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14854965374143879956&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Edinburgh;Heriot-Watt University",
        "aff_unique_dep": "Edinburgh Centre for Robotics;School of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.hw.ac.uk",
        "aff_unique_abbr": "UE;HWU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981225",
        "title": "A Virtual 2D Tactile Array for Soft Actuators Using Acoustic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "We create a virtual 2D tactile array for soft pneumatic actuators using embedded audio components. We detect contact-specific changes in sound modulation to infer tactile information. We evaluate different sound representations and learning methods to detect even small contact variations. We demonstrate the acoustic tactile sensor array by the example of a PneuFlex actuator and use a Braille display to individually control the contact of 29 x 4 pins with the actuator's 90 x 10 mm palmar surface. Evaluating the spatial resolution, the acoustic sensor localizes edges in x- and y-direction with a root-mean-square regression error of 1.67 mm and 0.0 mm, respectively. Even light contacts of a single Braille pin with a lifting force of 0.17 N are measured with high accuracy. Finally, we demonstrate the sensor's sensitivity to complex contact shapes by successfully reading the 26 letters of the Braille alphabet from a single display cell with a classification rate of 88 %.",
        "primary_area": "",
        "author": "Vincent Wall;Oliver Brock;Vincent Wall;Oliver Brock",
        "authorids": "/37085593443;/37279727100;/37085593443;/37279727100",
        "aff": "Research Cluster of Excellence, Science of Intelligence, Berlin, Germany; Research Cluster of Excellence, Science of Intelligence, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981225/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11957058352961688601&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Science of Intelligence",
        "aff_unique_dep": "Research Cluster of Excellence",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981895",
        "title": "A Whole-Body Controller Based on a Simplified Template for Rendering Impedances in Quadruped Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal manipulators require to be compliant when dealing with external forces during autonomous manipulation, tele-operation or physical human-robot interaction. This paper presents a whole-body controller that allows for the implementation of a Cartesian impedance control to coordinate tracking performance and desired compliance for the robot base and manipulator arm. The controller is formulated through an optimization problem using Quadratic Programming (QP) to impose a desired behavior for the system while satisfying friction cone constraints, unilateral force constraints, joint and torque limits. The presented strategy decouples the arm and the base of the platform, enforcing the behavior of a linear double-mass spring damper system, and allows to independently tune their inertia, stiffness and damping properties. The control architecture is validated through an extensive simulation study using the 90kg HyQ robot equipped with a 7-DoF manipulator arm. Simulation results show the impedance rendering performance when external forces are applied at the arm's end-effector. The paper presents results for full stance condition (all legs on the ground) and, for the first time, also shows how the impedance rendering is affected by the contact conditions during a dynamic gait.",
        "primary_area": "",
        "author": "Mattia Risiglione;Victor Barasuol;Darwin G. Caldwell;Claudio Semini;Mattia Risiglione;Victor Barasuol;Darwin G. Caldwell;Claudio Semini",
        "authorids": "/37089195410;/37071707300;/37295680400;/37542633100;/37089195410;/37071707300;/37295680400;/37542633100",
        "aff": "Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Istituto Italiano di Tecnologia (IIT), Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981895/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4410332875384241227&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981927",
        "title": "A compliant thorax design for robustness and elastic energy exchange in flapping-wing robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Flapping wing insects benefit from a compliant thorax that provides elastic energy exchange and resiliency to wing collisions. In this paper, we present a flapping wing robot that uses an underactuated compliant transmission inspired by the insect thorax. We developed a novel fabrication method that combines carbon fiber (CF) laminate and soft robotics fabrication techniques for transmission construction. The transmission design is optimized to achieve desired wingstroke requirements and to allow for independent motion of each wing. We validate these design choices in bench-top tests measuring transmission compliance and kinematics. We integrate the transmission with laminate wings and two types of actuation, demonstrating elastic energy exchange and limited lift-off capabilities Lastly, we tested collision mitigation through flapping wing experiments that obstructed the motion of a wing. These experiments demonstrate that an underactuated compliant, transmission can provide resilience and robustness to flapping wing robots.",
        "primary_area": "",
        "author": "Hang Gao;James Lynch;Nick Gravish;Hang Gao;James Lynch;Nick Gravish",
        "authorids": "/37089661579;/37089450022;/37085401269;/37089661579;/37089450022;/37085401269",
        "aff": "Hang Gao; James Lynch; Nick Gravish",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981927/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:agyNZ8DXs50J:scholar.google.com/&scioq=A+compliant+thorax+design+for+robustness+and+elastic+energy+exchange+in+flapping-wing+robots&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981475",
        "title": "A new gripper that acts as an active and passive joint to facilitate prehensile grasping and locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Among primates, the prehensile nature of the hand is vital for greater adaptability and a secure grip over the substrate/branches, particularly for arm-swinging motion or brachiation. Though various brachiation mechanisms that are mechanically equivalent to underactuated pendulum models are reported in the literature, not much attention has been given to the hand design that facilitates both locomotion and within-hand manipulation. In this paper, we propose a new robotic gripper design, equipped with shape conformable active gripping surfaces that can act as an active or passive joint and adapt to substrates with different shapes and sizes. A floating base serial chain, named GraspMaM, equipped with two such grippers, increases the versatility by performing a range of locomotion and manipulation modes without using dedicated systems. The unique gripper design allows the robot to estimate the passive joint state while arm-swinging and exhibits a dual relationship between manipulation and locomotion. We report the design details of the multimodal gripper and how it can be adapted for the brachiation motion assuming it as an articulated suspended pendulum model. Further, the system parameters of the physical prototype are estimated, and experimental results for the brachiation mode are discussed to validate and show the effectiveness of the proposed design.",
        "primary_area": "",
        "author": "Nagamanikandan Govindan;Shashank Ramesh;Asokan Thondiyath;Nagamanikandan Govindan;Shashank Ramesh;Asokan Thondiyath",
        "authorids": "/37086453895;/37088458911;/37992614600;/37086453895;/37088458911;/37992614600",
        "aff": "Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Department of Mechanical Engineering, Indian Institute of Technology, Madras, Chennai, India; Department of Engineering Design, Indian Institute of Technology, Madras, Chennai, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981475/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5052627991425466916&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "International Institute of Information Technology;Indian Institute of Technology Madras",
        "aff_unique_dep": "Robotics Research Center;Department of Mechanical Engineering",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.iitm.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad;IIT Madras",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Hyderabad;Chennai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9982206",
        "title": "A passive control framework for a bilateral leader-follower robotic surgical setup imposing RCM and active constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of controlling a bilateral leader-follower robotic surgical set-up to allow kinesthetic haptic feedback to the user when the instrument approaches a forbidden area like sensitive organs arteries or veins that should be protected from injuries during surgery. The leader is a haptic device while the follower is a general purpose manipulator holding an elongated tool with an articulated instrument that should be manipulated through an entry port. We propose a control framework that is proved passive, incorporating a target admittance model for the follower that is designed in a way to impose a remote center of motion (RCM) while being subject to repulsive forces generated by properly designed artificial potentials associated with forbidden areas. Simulation and experimental results utilizing a virtual intraoperative environment provided as a point cloud of a kidney and its surrounding vessels characterized as forbidden areas, validate and demonstrate the performance of the proposed control scheme.",
        "primary_area": "",
        "author": "Theodora Kastritsi;Zoe Doulgeri;Theodora Kastritsi;Zoe Doulgeri",
        "authorids": "/37086427599;/37274011500;/37086427599;/37274011500",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982206/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6599196574632810870&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981497",
        "title": "A passive, asymmetrically-compliant knee joint improves obstacle traversal in an insect-scale legged robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Insects can locomote readily in challenging environments, such as over steep inclines and across obstacle-laden terrains, which still frustrate robots of similar size. In this work, inspired by the passive compliant properties of insect limbs, we use the insect-scale Harvard Ambulatory Microrobot and multilayer microfabrication techniques as platform to study the ability of passive mechanisms to improve open-loop running in rough terrains. We tested the performance of different limb designs in vivo, exploring how the magnitude, directionality, and distribution of compliance incorporated into the leg impacted robot performance. Limbs were evaluated on both a featureless substrate and an increasingly-adversarial 3D-printed terrain designed to mimic natural environments. We tested the limbs using a trotting gait in the quasi-static (2 Hz) and body dynamics (25 Hz) stride frequency regimes. Performance was reported as bodylengths traveled per gait cycle on the featureless substrate, and as the largest feature height the robot was able to overcome in the terrain. The work presented here provides design principles for a passive limb that expands the terrain accessible to small robot; we find a limb with a single asymmetrical joint is able to improve quasi-static terrain traversal by 203% relative to a rigid limb.",
        "primary_area": "",
        "author": "Perrin E. Schiebel;Michelle C. Yuen;Robert J. Wood;Perrin E. Schiebel;Michelle C. Yuen;Robert J. Wood",
        "authorids": "/37089663984;/37085376647;/37326227400;/37089663984;/37085376647;/37326227400",
        "aff": "John A. Paulson School of Engineering & Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering & Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering & Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981497/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16490670748257401290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering & Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981205",
        "title": "A polynomial time approximation scheme for the scheduling problem in the AGV system",
        "track": "main",
        "status": "Poster",
        "abstract": "Logistics warehouses face the challenge of fulfilling large bulk pick orders limit in a given time, as the information of logistics orders is different and timeliness. Therefore, in automated warehouses, it is imperative to improve the efficiency and intelligence of order picking by robotic systems. However, the existing automated guided vehicle (AGV) system has only a few fixed functions (such as order sorting and transportation, etc.), which cannot be changed in time according to actual needs. Meanwhile, the scheduling algorithm has only mass heuristics results and a few approximate algorithm results. In this paper, we build a new AGV system, including two kinds of shelves and four kinds of stations, where the system can add new station types according to the actual situation. We establish the equivalent relationship between the order group picking task in this system and the multi-stage hybrid flow shop scheduling problem, without considering the order group transfer process between stations. Furthermore, we propose a polynomial time approximation scheme (PTAS) for the scheduling problem in this system which has been proved to be strongly NP-hard [13].",
        "primary_area": "",
        "author": "Xinrui Li;Chaoyang Wang;Hao Hu;Yanxue Liang;Xinrui Li;Chaoyang Wang;Hao Hu;Yanxue Liang",
        "authorids": "/37089660991;/37089663363;/37089660439;/37089662346;/37089660991;/37089663363;/37089660439;/37089662346",
        "aff": "Center of Innovative Research, Westlake University, Hangzhou, PR China; Center of Innovative Research, Westlake University, Hangzhou, PR China; Center of Innovative Research, Westlake University, Hangzhou, PR China; Center of Innovative Research, Westlake University, Hangzhou, PR China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981205/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mcvafOsblEgJ:scholar.google.com/&scioq=A+polynomial+time+approximation+scheme+for+the+scheduling+problem+in+the+AGV+system&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Westlake University",
        "aff_unique_dep": "Center of Innovative Research",
        "aff_unique_url": "https://www.westlake.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981575",
        "title": "A unified MPC design approach for AGV path following",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a unified approach to the design of Model Predictive Controllers (MPC), custom-tailored for path following by Automated Guided Vehicles (AGVs). The approach can be applied in a unified manner to several relevant AGV kinematic configurations, including tricycle, differential, and double steer-drive. By leveraging Linear Parameter Varying (LPV) MPC, it provides maximum maneuverability and industrial-grade positioning accuracy. We incorporate state-of-the-art optimized velocity planning, to maximize vehicle utilization. Experimental validation is performed on three different kinematic configurations, including a real forklift with tricycle configuration, using industrially-relevant positioning maneuvers.",
        "primary_area": "",
        "author": "Mirko Kokot;Damjan Mikli\u0107;Tamara Petrovi\u0107;Mirko Kokot;Damjan Mikli\u0107;Tamara Petrovi\u0107",
        "authorids": "/37086437443;/37545520600;/37638556300;/37086437443;/37545520600;/37638556300",
        "aff": "Romb Technologies d.o.o., Zagreb, Croatia; Romb Technologies d.o.o., Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981575/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10306055858549916325&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Romb Technologies;University of Zagreb",
        "aff_unique_dep": ";Faculty of Electrical Engineering and Computing",
        "aff_unique_url": ";https://www.unizg.hr",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Zagreb",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Croatia"
    },
    {
        "id": "9982042",
        "title": "A wearable system with harmonic oscillations to assess finger biomechanics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a wearable device for finger assessment that can identify finger joint impedance parameters through harmonic oscillation perturbations. This device is designed to help assess motor impairments related to hypertonic soft-tissue changes, that can arise from a number of conditions such as stroke. By measuring the ratio of the applied torque and resulting velocities, the impedance values for any bending direction of a metacarpophalangeal (MCP) joint can be estimated. The ability of this device to effectively estimate finger parameters was tested in experiments with six participants. The experimental result was validated through comparison to prior works on finger impedance estimation. The user experience of the presented system was also analysed, indicating that the device design is comfortable and acceptable for participants.",
        "primary_area": "",
        "author": "Hao Yu;Aran Sena;Etienne Burdet;Hao Yu;Aran Sena;Etienne Burdet",
        "authorids": "/37089660360;/37086454492;/37275851600;/37089660360;/37086454492;/37275851600",
        "aff": "Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK; Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK; Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982042/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3212109961072507959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College of Science, Technology and Medicine",
        "aff_unique_dep": "Department of Bioengineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981365",
        "title": "A-RIFT: Visual Substitution of Force Feedback for a Zero-Cost Interface in Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an accessible robot interface for telemanipulation (A-RIFT), which preserves the haptic channel partially in a zero-additional-cost interface by visual substitution of force feedback (VSFF). This work explores a gap in the literature, resulting from the focus on performance improvements in telerobotics at increasing interface costs. Unlike most telemanipulation interfaces for high-degree-of-freedom robotic systems, this one requires minimal training and can be run in a web browser under high latency conditions, using an Internet connected computer with the user's own mouse and keyboard. To evaluate the performance of the system, we ran a controlled user study (N=12) to test how different distances (local vs. remote) and VSFF (on vs. off) affect the system's usability. As expected, participants in remote conditions performed worse than those in closer proximity. Despite several participants claiming that the visual display of force feedback did not help them, our analysis of their task performance showed that operators in remote condition actually performed statistically significantly better with the visual force feedback display than without it. These results indicate a promising new interface design direction for low-cost telemanipulation.",
        "primary_area": "",
        "author": "Alexander Moortgat-Pick;Peter So;Michael J Sack;Emma G Cunningham;Benjamin P Hughes;Anna Adamczyk;Andriy Sarabakha;Leila Takayama;Sami Haddadin;Alexander Moortgat-Pick;Peter So;Michael J Sack;Emma G Cunningham;Benjamin P Hughes;Anna Adamczyk;Andriy Sarabakha;Leila Takayama;Sami Haddadin",
        "authorids": "/37088691333;/37089661440;/37089662117;/37089658915;/37089662292;/37088687867;/37085894614;/37395850000;/37542865300;/37088691333;/37089661440;/37089662117;/37089658915;/37089662292;/37088687867;/37085894614;/37395850000;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany; Human-Robot Interaction Lab, University of California, Santa Cruz, California, USA; Human-Robot Interaction Lab, University of California, Santa Cruz, California, USA; Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany; Human-Robot Interaction Lab, University of California, Santa Cruz, California, USA; Chair of Robotics and Systems Intelligence and MIRMI - Munich Institute of Robotics and Machine Intelligence (formerly MSRM), Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981365/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13075199789370022670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;University of California, Santa Cruz",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence;Human-Robot Interaction Lab",
        "aff_unique_url": "https://www.tum.de;https://www.ucsc.edu",
        "aff_unique_abbr": "TUM;UCSC",
        "aff_campus_unique_index": "0;0;1;1;0;0;0;1;0",
        "aff_campus_unique": "Munich;Santa Cruz",
        "aff_country_unique_index": "0;0;1;1;0;0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9981513",
        "title": "AB-Mapper: Attention and BicNet based Multi-agent Path Planning for Dynamic Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent path finding in dynamic environments is of great academic and practical value for multi-robot systems in the real world. To improve the effectiveness and efficiency of the learning process during path planning in dynamic environments, we introduce an algorithm called Attention and BicNet based Multi-agent path planning with effective reinforcement (AB-Mapper) under the actor-critic reinforcement learning framework. In this framework, on one hand, we design an actor-network that can utilize the BicNet with communication function to achieve the intra-team coordination. On the other hand, we propose a critic network that can selectively allocate attention weights to surrounding agents. This attention mechanism allows an individual agent to automatically learn a better evaluation of actions by considering the behaviours of its surrounding agents. Compared with the SOTA method Mapper in crowded environments with dynamic obstacles, our AB-Mapper is more effective (90.27\u00b10.06% vs. 61.65\u00b113.90% in terms of mean success rate) in solving the general multi-agent path finding problem.",
        "primary_area": "",
        "author": "Huifeng Guan;Yuan Gao;Min Zhao;Yong Yang;Fuqin Deng;Tin Lun Lam;Huifeng Guan;Yuan Gao;Min Zhao;Yong Yang;Fuqin Deng;Tin Lun Lam",
        "authorids": "/37089663659;/37089157084;/37089661103;/37088468673;/37087470921;/37571111600;/37089663659;/37089157084;/37089661103;/37088468673;/37087470921;/37571111600",
        "aff": "School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; 3irobotix Co., Ltd, Shenzhen, China; 3irobotix Co., Ltd, Shenzhen, China; School of Science and Engineering, the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981513/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6442851486694372672&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;3",
        "aff_unique_norm": "Wuyi University;Shenzhen Institute of Artificial Intelligence and Robotics for Society;3irobotix Co., Ltd;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Intelligent Manufacturing;;;School of Science and Engineering",
        "aff_unique_url": ";;;https://www.cuhk.edu.cn",
        "aff_unique_abbr": ";;;CUHK",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Jiangmen;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981591",
        "title": "ACEFusion - Accelerated and Energy-Efficient Semantic 3D Reconstruction of Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "ACEFusion is the first 3D reconstruction system able to capture the geometry and semantics of dynamic scenes using an RGB-D camera in real-time on a robotic computing platform. Harnessing the hardware accelerators of an Nvidia Jetson AGX Xavier, the system uses heterogeneous computing to achieve 30 FPS under a 30W power budget. Using a data-parallel design, we perform most image computation on the dedicated hardware accelerators, freeing the general purpose cores and GPU to process 3D geometry. To further increase efficiency, we employ a hybrid geometry representation with octrees for static-semantic reconstruction and surfels for dynamic reconstruction. ACEFusion achieves competitive results on standard benchmarks while efficiently performing a more complex overall task than existing SLAM techniques. Figure. 1 shows the output of our system on a dynamic sequence.",
        "primary_area": "",
        "author": "Mihai Bujanca;Barry Lennox;Mikel Luj\u00e1n;Mihai Bujanca;Barry Lennox;Mikel Luj\u00e1n",
        "authorids": "/37086934435;/37299751200;/37392848800;/37086934435;/37299751200;/37392848800",
        "aff": "University of Manchester, UK; University of Manchester, UK; University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981591/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11006604474241224091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981400",
        "title": "AFR: An Efficient Buffering Algorithm for Cloud Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication between robots and the server is a major problem for cloud robotic systems. In this paper, we address the problem caused by data loss during such communications and propose an efficient buffering algorithm, called AFR, to solve the problem. We model the problem into an optimization problem to maximize the received Quantity of Information (QoI). Our AFR algorithm is formally proved to achieve near-optimal QoI, which has a lower bound that is a constant multiple of the unrealizable optimal QoI. We implement our AFR algorithm in ROS without changing the API for the applications. Our experiments on two cloud robot applications show that our AFR algorithm can efficiently and effectively reduce the impact of data loss. For the remote mapping application, the RMSE caused by data loss can be reduced by about 20%. For the remote tracking application, the probability of tracking failure caused by data loss can be reduced from about 40 %-60 % to under 10%. Meanwhile, our AFR algorithm introduces time overhead of under 10 microseconds.",
        "primary_area": "",
        "author": "Yu-Ping Wang;Hao-Ning Wang;Zi-Xin Zou;Dinesh Manocha;Yu-Ping Wang;Hao-Ning Wang;Zi-Xin Zou;Dinesh Manocha",
        "authorids": "/37085396500;/37089662168;/37089198099;/37267825600;/37085396500;/37089662168;/37089198099;/37267825600",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Department of Mathematical Science, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science, University of Maryland, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981400/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ZcBsEqRRZQMJ:scholar.google.com/&scioq=AFR:+An+Efficient+Buffering+Algorithm+for+Cloud+Robotic+Systems&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Beijing Institute of Technology;Tsinghua University;University of Maryland",
        "aff_unique_dep": "School of Computer Science and Technology;Department of Mathematical Science;Department of Computer Science",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.tsinghua.edu.cn;https://www.umd.edu",
        "aff_unique_abbr": "BIT;THU;UMD",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Beijing;College Park",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981835",
        "title": "AFT-VO: Asynchronous Fusion Transformers for Multi-View Visual Odometry Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion estimation approaches typically employ sensor fusion techniques, such as the Kalman Filter, to handle individual sensor failures. More recently, deep learning-based fusion approaches have been proposed, increasing the performance and requiring less model-specific implementations. However, current deep fusion approaches often assume that sensors are synchronised, which is not always practical, especially for low-cost hardware. To address this limitation, in this work, we propose AFT-VO, a novel transformer-based sensor fusion architecture to estimate VO from multiple sensors. Our framework combines predictions from asynchronous multi-view cameras and accounts for the time discrepancies of measurements coming from different sources. Our approach first employs a Mixture Density Network (MDN) to estimate the probability distributions of the 6-DoF poses for every camera in the system. Then a novel transformer-based fusion module, AFT-VO, is introduced, which combines these asynchronous pose estimations, along with their confidences. More specifically, we introduce Discretiser and Source Encoding techniques which enable the fusion of multi-source asynchronous signals. We evaluate our approach on the popular nuScenes and KITTI datasets. Our experiments demonstrate that multi-view fusion for VO estimation provides robust and accurate trajectories, outperforming the state of the art in both challenging weather and lighting conditions.",
        "primary_area": "",
        "author": "Nimet Kaygusuz;Oscar Mendez;Richard Bowden;Nimet Kaygusuz;Oscar Mendez;Richard Bowden",
        "authorids": "/37089003434;/37710939600;/37268872100;/37089003434;/37710939600;/37268872100",
        "aff": "University of Surrey, UK; University of Surrey, UK; University of Surrey, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981835/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13879417127601741268&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981696",
        "title": "AIB-MDP: Continuous Probabilistic Motion Planning for Automated Vehicles by Leveraging Action Independent Belief Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "While automated research vehicles are already populating the roads, their commercial availability at scale is still to come. Presumably, one of the key challenges is to derive behaviors that are safe and comfortable but at the same time not overcautious, despite considerable uncertainties. These uncertainties stem from imperfect perception, occlusions and limited sensor range, but also from the unknown future behavior of other traffic participants. A holistic uncertainty treatment, for example in a general POMDP formulation, often induces a strong limitation on the action space due to the need for real-time capability. Further, related approaches often do not account for the need for verifiable safety, including traffic rule compliance. The proposed approach is targeted towards scenarios with clear precedence. It is based on an MDP with an action-independent belief (AIB-MDP): We assume that the future belief over the trajectories of other traffic participants is independent of the ego vehicle's behavior. Thus, the future belief can be predicted and simplified in an upstream module, independent of motion planning. This modularization facilitates subsequent ego motion planning in a continuous action space despite the thorough uncertainty consideration. The improved performance compared to state-of-the-art is demonstrated in three example scenarios.",
        "primary_area": "",
        "author": "Maximilian Naumann;Christoph Stiller;Maximilian Naumann;Christoph Stiller",
        "authorids": "/37086109465;/37284652100;/37086109465;/37284652100",
        "aff": "Bosch Center for Artificial Intelligence, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981696/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8646840867432684138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Artificial Intelligence;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.kit.edu",
        "aff_unique_abbr": "BCAI;KIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981190",
        "title": "Absolute Position Detection in 7-Phase Sensorless Electric Stepper Motor",
        "track": "main",
        "status": "Poster",
        "abstract": "Absolute position detection in sensorless electric stepper motors potentially allows for higher space efficiency, improved shock resistance, simplified installation, reduced number of parts and lowered cost. A prototype is demonstrated measuring 42 \u00d7 42 \u00d7 34 mm3 with seven coils arranged in a star configuration. The rotor is \u03d5 25.8 \u00d7 12.5 mm2 and has 51 teeth which are irregularly spaced. At the driver side, the coil currents are measured during motion in order to reconstruct the absolute position of the motor. Calibration and smoothing techniques are used to reduce systematic and stochastic measurement errors, respectively. The motor is able to detect and correct its position after externally-induced stalls at the tested motor speeds from 40 rpm to 108 rpm. The holding torque is 0.23 N m at an armature current of 1 A; on average the torque is 7% lower than that of a reference bipolar stepper motor with the same dimensions. The results show that dynamic position sensing and correction are possible for a range of velocities, but not at standstill. The driver requires seven current sensors and sufficient computational power, and proper calibration of motor intrinsics is required beforehand. The presented technology could make existing 3-D printers and other machines with open-loop stepper motors more robust and increase the range of operating speeds and accelerations, without the adverse side-effects of increased complexity and cost associated with dedicated position sensors.",
        "primary_area": "",
        "author": "Vincent Groenhuis;Gijs Rolff;Koen Bosman;Leon Abelmann;Stefano Stramigioli;Vincent Groenhuis;Gijs Rolff;Koen Bosman;Leon Abelmann;Stefano Stramigioli",
        "authorids": "/37085817635;/37088924806;/37088923369;/37266527500;/37282439300;/37085817635;/37088924806;/37088923369;/37266527500;/37282439300",
        "aff": "Robotics and Mechatronics University of Twente, 7500AE Enschede, The Netherlands; IMS BV, Almelo, The Netherlands; Benchmark Electronics, Almelo, The Netherlands; KIST Europe, Saarbr\u00fccken, Germany; Robotics and Mechatronics University of Twente, 7500AE Enschede, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981190/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17381520787056501956&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Twente;IMS BV;Benchmark Electronics;KIST Europe",
        "aff_unique_dep": "Robotics and Mechatronics;;;",
        "aff_unique_url": "https://www.utwente.nl;;;https://www.kist-europe.eu",
        "aff_unique_abbr": "UT;;;KIST-Europe",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Enschede;;Saarbr\u00fccken",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Netherlands;Germany"
    },
    {
        "id": "9981759",
        "title": "Accelerated Reinforcement Learning for Temporal Logic Control Objectives",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of learning control policies for mobile robots, modeled as unknown Markov Decision Processes (MDPs), that are tasked with temporal logic missions, such as sequencing, coverage, or surveillance. The MDP captures uncertainty in the workspace structure and the outcomes of control decisions. The control objective is to synthesize a control policy that maximizes the probability of accomplishing a high-level task, specified as a Linear Temporal Logic (LTL) formula. To address this problem, we propose a novel accelerated model-based reinforcement learning (RL) algorithm for LTL control objectives that is capable of learning control policies significantly faster than related approaches. Its sample-efficiency relies on biasing exploration towards directions that may contribute to task satisfaction. This is accomplished by leveraging an automaton representation of the LTL task as well as a continuously learned MDP model. Finally, we provide comparative experiments that demonstrate the sample efficiency of the proposed method against recent RL methods for LTL objectives.",
        "primary_area": "",
        "author": "Yiannis Kantaros;Yiannis Kantaros",
        "authorids": "/37085499544;/37085499544",
        "aff": "Department of Electrical and Systems Engineering, Washington University in St. Louis, St. Louis, MO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981759/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18193519852704347469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Washington University in St. Louis",
        "aff_unique_dep": "Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://wustl.edu",
        "aff_unique_abbr": "WUSTL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "St. Louis",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981296",
        "title": "Accurate Instance-Level CAD Model Retrieval in a Large-Scale Database",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new solution to the fine-grained retrieval of clean CAD models from a large-scale database in order to recover detailed object shape geometries for RGBD scans. Unlike previous work simply indexing into a moderately small database using an object shape descriptor and accepting the top retrieval result, we argue that in the case of a large-scale database a more accurate model may be found within a neighborhood of the descriptor. More importantly, we propose that the distinctiveness deficiency of shape descriptors at the instance level can be compensated by a geometry-based re-ranking of its neighborhood. Our approach first leverages the discriminative power of learned representations to distinguish between different categories of models and then uses a novel robust point set distance metric to re-rank the CAD neighbor-hood, enabling fine-grained retrieval in a large shape database. Evaluation on a real-world dataset shows that our geometry-based re-ranking is a conceptually simple but highly effective method that can lead to a significant improvement in retrieval accuracy compared to the state-of-the-art.",
        "primary_area": "",
        "author": "Jiaxin Wei;Lan Hu;Chenyu Wang;Laurent Kneip;Jiaxin Wei;Lan Hu;Chenyu Wang;Laurent Kneip",
        "authorids": "/37088998413;/37088505304;/37089446359;/37569040300;/37088998413;/37088505304;/37089446359;/37569040300",
        "aff": "Mobile Perception Lab, School of Information Science and Technology, ShanghaiTech University; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences and University of Chinese Academy of Sciences; Mobile Perception Lab, School of Information Science and Technology, ShanghaiTech University; Mobile Perception Lab, School of Information Science and Technology, ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981296/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14159184694520439542&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ShanghaiTech University;Shanghai Institute of Microsystem and Information Technology",
        "aff_unique_dep": "School of Information Science and Technology;",
        "aff_unique_url": "http://www.shanghaitech.edu.cn;http://www.sim.ac.cn",
        "aff_unique_abbr": "ShanghaiTech;SIM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981944",
        "title": "Accurate Pose Estimation for Comanipulation Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic comanipulation provides a cost-effective solution to telesurgery when remote operation is not strictly necessary. Within the field of laparoscopic surgery, the comanip-ulation scenario is only recently being exploited commercially in the form of lightweight backdrivable systems. A passive wrist backdrivable robot does not require preoperative alignment with the incision that acts as a fulcrum around which the laparoscopic instrument pivots. Moreover, backdrivable systems can be comanipulated by the user without the need for expensive force sensors. Unfortunately, most backdrivable systems only provide limited accuracy when measuring the end effector pose from their joint encoders. Accurate knowledge of the end effector pose is required to estimate the the instrument tip and fulcrum position. This work presents a robust method to improve localisation of the pose of the end effector of a backdrivable robot. The method fuses optical tracking with robot proprioception by means of an unscented Kalman filter and is robust against intermittent occlusions of the line of sight. The algorithm is experimentally validated by analyzing its initialization behavior and accuracy when estimating the instrument tip and fulcrum position. An accuracy of 1.58\\pm 0.1571.58\\pm 0.157 mm and 0.699\\pm 0.3890.699\\pm 0.389 mm is achieved when estimating the instrument tip and fulcrum position respectively, which makes the algorithm suitable for advanced guidance schemes in comanipulation robotic surgery.",
        "primary_area": "",
        "author": "Jef De Smet;Gianni Borghesan;Emmanuel Vander Poorten;Jef De Smet;Gianni Borghesan;Emmanuel Vander Poorten",
        "authorids": "/37087468009;/37396256700;/38537470200;/37087468009;/37396256700;/38537470200",
        "aff": "Department of Mechanical Engineering, KU Leuven, Leuven, Belgium; Core Lab ROB, Flanders Make, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981944/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=947799792147491741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KU Leuven;Flanders Make",
        "aff_unique_dep": "Department of Mechanical Engineering;Core Lab ROB",
        "aff_unique_url": "https://www.kuleuven.be;https://www.flandersmake.be",
        "aff_unique_abbr": "KU Leuven;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Leuven",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9981921",
        "title": "Accurate Vision-based Flight with Fixed-Wing Drones",
        "track": "main",
        "status": "Poster",
        "abstract": "Fixed-wing drones must navigate to the desired location accurately for maneuvers such as picking up objects and perching. However, current GNSS receivers limit their navigation accuracy to several meters in outdoor environments, making such maneuvers impossible. RTK GNSS can improve flight accuracy, but it requires ground stations at the target location and additional communication modules on the drone. Here, we describe a fixed-wing platform with onboard computation that uses positional information from a GNSS receiver and vision from an onboard camera. The drone relies on a GNSS signal for flying towards a point of interest and switches to vision-based information to accurately reach the target. We conducted outdoor experiments to compare the flight accuracy of three navigation methods: GNSS, RTK GNSS, and the proposed GNSS-vision method. We also systematically assessed the robustness of vision-based control to compensate for GNSS errors and quantify the accuracy of the proposed method. Our results show that the accuracy of the proposed GNSS-vision system is on par with RTK GNSS. GNSS-vision reduces the average error of GNSS by over an order of magnitude, from 3.033 m to 0.283 m, and reduces the variance across repeated flights from 2.095 m to 0.309 m. We open-source the software-hardware architecture used in this paper to enable the research community to build on these results and expand the capabilities of fixed-wing drones.",
        "primary_area": "",
        "author": "Valentin W\u00fcest;Enrico Ajanic;Matthias M\u00fcller;Dario Floreano;Valentin W\u00fcest;Enrico Ajanic;Matthias M\u00fcller;Dario Floreano",
        "authorids": "/37086289200;/37089565869;/37088216388;/37282168700;/37086289200;/37089565869;/37088216388;/37282168700",
        "aff": "Laboratory of Intelligent Systems, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland; Laboratory of Intelligent Systems, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland; Embodied AI Lab, Intel, Neubiberg, Germany; Laboratory of Intelligent Systems, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981921/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6997541443459461611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne (EPFL);Intel",
        "aff_unique_dep": "Laboratory of Intelligent Systems;Embodied AI Lab",
        "aff_unique_url": "https://www.epfl.ch;https://www.intel.de",
        "aff_unique_abbr": "EPFL;Intel",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Lausanne;Neubiberg",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9981824",
        "title": "Accurate edge detection for robotic welding through tactile exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Programming paths for robotic welding conventionally requires precise positioning of workpieces, detailed 3D models and/or tedious teach pendant programming. A new method is introduced in this paper that enables an operator to teach the weld path to the robot through a haptic-visual interface. The operator teaches the path by guiding the tool tip to contact on the workpiece surface with force feedback through the haptic device, and drawing exploratory paths that intersect the edge to be welded as well as adjoining surfaces. Tool-tip positions in contact with the workpiece are recorded. A RANSAC-type algorithm is used to automatically estimate a piecewise parametric curve along the edge as well as geometric parameters of the adjoining surfaces. The required tool trajectory for the robot to weld along the workpiece edge is automatically generated. Experiments performed in simulation and on a physical KUKA IIWA7 robot demonstrate that the developed method can successfully detect workpiece edges within a maximum deviation of 1mm. Furthermore, the method is intuitive, and requires no knowledge of robot programming for an operator to program multi-segment weld paths quickly.",
        "primary_area": "",
        "author": "Shameek Ganguly;Oussama Khatib;Shameek Ganguly;Oussama Khatib",
        "authorids": "/37088736592;/37283150000;/37088736592;/37283150000",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981824/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12775235440821776659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981355",
        "title": "Acoustic Localization and Communication Using a MEMS Microphone for Low-cost and Low-power Bio-inspired Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Having accurate localization capabilities is one of the fundamental requirements of autonomous robots. For underwater vehicles, the choices for effective localization are limited due to limitations of GPS use in water and poor environ-mental visibility that makes camera-based methods ineffective. Popular inertial navigation methods for underwater localization using Doppler-velocity log sensors, sonar, high-end inertial navigation systems, or acoustic positioning systems require bulky expensive hardware which are incompatible with low-cost, bio-inspired underwater robots. In this paper, we introduce an approach for underwater robot localization inspired by GPS methods known as acoustic pseudoranging. Our method allows us to potentially localize multiple bio-inspired robots equipped with commonly available micro electro-mechanical systems microphones. This is achieved through estimating the time difference of arrival of acoustic signals sent simultaneously through four speakers with a known constellation geometry. We also leverage the same acoustic framework to perform one-way communication with the robot to execute some primitive motions. To our knowledge, this is the first application of the approach for the on-board localization of small bio-inspired robots in water. Hardware schematics and the accompanying code are released to aid further development in the field33https://github.com/rpl-cmu/underwater-acoustic-pseudoranging.",
        "primary_area": "",
        "author": "Akshay Hinduja;Yunsik Ohm;Jiahe Liao;Carmel Majidi;Michael Kaess;Akshay Hinduja;Yunsik Ohm;Jiahe Liao;Carmel Majidi;Michael Kaess",
        "authorids": "/37086454167;/37086842982;/37086368220;/37589572800;/37324200400;/37086454167;/37086842982;/37086368220;/37589572800;/37324200400",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981355/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12229442727109394692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982061",
        "title": "Active Exploration for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation stands as a largely unsolved problem despite significant advances in robotics and machine learning in recent years. One of the key challenges in manipulation is the exploration of the dynamics of the environment when there is continuous contact between the objects being manipulated. This paper proposes a model-based active exploration approach that enables efficient learning in sparse-reward robotic manipulation tasks. The proposed method estimates an information gain objective using an ensemble of probabilistic models and deploys model predictive control (MPC) to plan actions online that maximize the expected reward while also performing directed exploration. We evaluate our proposed algorithm in simulation and on a real robot, trained from scratch with our method, on a challenging ball pushing task on tilted tables, where the target ball position is not known to the agent a-priori. Our real-world robot experiment serves as a fundamental application of active exploration in model-based reinforcement learning of complex robotic manipulation tasks. Project page https://sites.google.com/view/aerm.",
        "primary_area": "",
        "author": "Tim Schneider;Boris Belousov;Georgia Chalvatzaki;Diego Romeres;Devesh K. Jha;Jan Peters;Tim Schneider;Boris Belousov;Georgia Chalvatzaki;Diego Romeres;Devesh K. Jha;Jan Peters",
        "authorids": "/37089661443;/37087324763;/37085353493;/37086098761;/37072717800;/37533077600;/37089661443;/37087324763;/37085353493;/37086098761;/37072717800;/37533077600",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982061/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11061232815152141745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "9981875",
        "title": "Active Mapping via Gradient Ascent Optimization of Shannon Mutual Information over Continuous SE(3) Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of active mapping aims to plan an informative sequence of sensing views given a limited budget such as distance traveled. This paper considers active occupancy grid mapping using a range sensor, such as LiDAR or depth camera. State-of-the-art methods optimize information-theoretic measures relating the occupancy grid probabilities with the range sensor measurements. The non-smooth nature of ray-tracing within a grid representation makes the objective function non-differentiable, forcing existing methods to search over a discrete space of candidate trajectories. This work proposes a differentiable approximation of the Shannon mutual information between a grid map and ray-based observations that enables gradient ascent optimization in the continuous space of SE(3) sensor poses. Our gradient-based formulation leads to more informative sensing trajectories, while avoiding occlusions and collisions. The proposed method is demonstrated in simulated and real-world experiments in 2-D and 3-D environments. Materials supplementing this paper are available at: https://arashasgharivaskasi-bc.github.io/grad_active_mapping/",
        "primary_area": "",
        "author": "Arash Asgharivaskasi;Shumon Koga;Nikolay Atanasov;Arash Asgharivaskasi;Shumon Koga;Nikolay Atanasov",
        "authorids": "/37088997086;/37085850367;/37670511000;/37088997086;/37085850367;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981875/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11915203028411144506&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982224",
        "title": "Active SLAM in 3D deformable environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers active SLAM problem for 3D deformable environments where the trajectory of the robot is planned to optimize the SLAM results. A planning strategy combining an efficient global planner with an accurate local planner is proposed to solve the problem. Simulation results under different scenarios have shown that the proposed active SLAM algorithm provides a good balance between accuracy and efficiency as compared to the local planner and the global planner. The MATLAB code of this first active SLAM algorithm for 3D deformable environments is made publicly available4.",
        "primary_area": "",
        "author": "Mengya Xu;Liang Zhao;Shoudong Huang;Qi Hao;Mengya Xu;Liang Zhao;Shoudong Huang;Qi Hao",
        "authorids": "/37089000274;/37857963600;/37421307400;/37403530000;/37089000274;/37857963600;/37421307400;/37403530000",
        "aff": "Robotics Institute, University of Technology Sydney, NSW, Australia; Robotics Institute, University of Technology Sydney, NSW, Australia; Robotics Institute, University of Technology Sydney, NSW, Australia; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982224/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=194370657926896679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Technology Sydney;Southern University of Science and Technology",
        "aff_unique_dep": "Robotics Institute;Research Institute of Trustworthy Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au;https://www.sustech.edu.cn",
        "aff_unique_abbr": "UTS;SUSTech",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Sydney;Shenzhen",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "9982266",
        "title": "Active Tactile Exploration using Shape-Dependent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile signals provide rich information about objects via touch and are essential for a robot to perform dex-terous manipulation. Exploring actively via tactile perception collects important information about the workspace. However, designing an effective tactile exploration policy is challenging in unstructured environments. Typically, the geometric information is incomplete, and need to be completed by actively and repeatedly interacting with the environment. In this paper, we address the tactile exploration problem by proposing a shape-information-dependent exploration strategy, which consists of two components: (1) a Shape-Belief Encoder that encodes the explored area by learning effective 3-D reconstruction and predicts the complete object shape; (2) a shape-dependent exploration policy which incorporates the encoding in (1) to plan an exploration trajectory. The policy actively acquires new information about object surface by executing exploration actions. The Shape-Belief Encoder leverages the newly collected contact points to update the surface model and guides future exploration. We validate the proposed algorithm on simulated and real robots.",
        "primary_area": "",
        "author": "Shuo Jiang;Lawson L.S. Wong;Shuo Jiang;Lawson L.S. Wong",
        "authorids": "/37089658689;/38301013300;/37089658689;/38301013300",
        "aff": "Northeastern University, Boston, MA, USA; Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982266/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981091",
        "title": "Adapting Rapid Motor Adaptation for Bipedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in legged locomotion have en-abled quadrupeds to walk on challenging terrains. However, bipedal robots are inherently more unstable and hence it's harder to design walking controllers for them. In this work, we leverage recent advances in rapid adaptation for locomotion control, and extend them to work on bipedal robots. Similar to existing works, we start with a base policy which produces actions while taking as input an estimated extrinsics vector from an adaptation module. This extrinsics vector contains information about the environment and enables the walking controller to rapidly adapt online. However, the extrinsics estimator could be imperfect, which might lead to poor performance of the base policy which expects a perfect estimator. In this paper, we propose A-RMA (Adapting RMA), which additionally adapts the base policy for the imperfect extrinsics estimator by finetuning it using model-free RL. We demonstrate that A-RMA outperforms a number of RL-based baseline controllers and model-based controllers in simulation, and show zero-shot deployment of a single A-RMA policy to enable a bipedal robot, Cassie, to walk in a variety of different scenarios in the real world beyond what it has seen during training. Videos and results at https: //ashish-kmr.github.io/a-rma/",
        "primary_area": "",
        "author": "Ashish Kumar;Zhongyu Li;Jun Zeng;Deepak Pathak;Koushil Sreenath;Jitendra Malik;Ashish Kumar;Zhongyu Li;Jun Zeng;Deepak Pathak;Koushil Sreenath;Jitendra Malik",
        "authorids": "/37089497753;/37088691308;/37086963288;/37085372144;/37563179200;/37282929000;/37089497753;/37088691308;/37086963288;/37085372144;/37563179200;/37282929000",
        "aff": "University of California, Berkeley, California, USA; University of California, Berkeley, California, USA; University of California, Berkeley, California, USA; Carnegie Mellon University; University of California, Berkeley, California, USA; University of California, Berkeley, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981091/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7270660173402929979&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982287",
        "title": "Adaptive Coverage Path Planning for Efficient Exploration of Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for solving the coverage problem with the objective of autonomously exploring an unknown environment under mission time constraints. Here, the robot is tasked with planning a path over a horizon such that the accumulated area swept out by its sensor footprint is maximized. Because this problem exhibits a diminishing returns property known as submodularity, we choose to formulate it as a tree-based sequential decision making process. This formulation allows us to evaluate the effects of the robot's actions on future world coverage states, while simultaneously accounting for traversability risk and the dynamic constraints of the robot. To quickly find near-optimal solutions, we propose an effective approximation to the coverage sensor model which adapts to the local environment. Our method was extensively tested across various complex environments and served as the local exploration algorithm for a competing entry in the DARPA Subterranean Challenge.",
        "primary_area": "",
        "author": "Amanda Bouman;Joshua Ott;Sung-Kyun Kim;Kenny Chen;Mykel J. Kochenderfer;Brett Lopez;Ali-akbar Agha-mohammadi;Joel Burdick;Amanda Bouman;Joshua Ott;Sung-Kyun Kim;Kenny Chen;Mykel J. Kochenderfer;Brett Lopez;Ali-akbar Agha-mohammadi;Joel Burdick",
        "authorids": "/37087322528;/37089662054;/37598024600;/37088689284;/37596929200;/37085654767;/38274170800;/37265975700;/37087322528;/37089662054;/37598024600;/37088689284;/37596929200;/37085654767;/38274170800;/37265975700",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology; Department of Aeronautics and Astronautics, Stanford University; NASA Jet Propulsion Laboratory, California Institute of Technology; Department of Electrical and Computer Engineering, University of California Los Angeles; Department of Aeronautics and Astronautics, Stanford University; Department of Mechanical and Aerospace Engineering, University of California Los Angeles; NASA Jet Propulsion Laboratory, California Institute of Technology; Department of Mechanical and Civil Engineering, California Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982287/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18324921723235389751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;1;2;0;0",
        "aff_unique_norm": "California Institute of Technology;Stanford University;University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering;Department of Aeronautics and Astronautics;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.stanford.edu;https://www.ucla.edu",
        "aff_unique_abbr": "Caltech;Stanford;UCLA",
        "aff_campus_unique_index": "0;1;0;2;1;2;0;0",
        "aff_campus_unique": "Pasadena;Stanford;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982107",
        "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision Avoidance in Complex Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "The major challenges of collision avoidance for robot navigation in crowded scenes lie in accurate environment modeling, fast perceptions, and trustworthy motion planning policies. This paper presents a novel adaptive environment model based collision avoidance reinforcement learning (i.e., AEMCARL) framework for an unmanned robot to achieve collision-free motions in challenging navigation scenarios. The novelty of this work is threefold: (1) developing a hierarchical network of gated-recurrent-unit (GRU) for environment modeling; (2) developing an adaptive perception mechanism with an attention module; (3) developing an adaptive reward function for the reinforcement learning (RL) framework to jointly train the environment model, perception function and motion planning policy. The proposed method is tested with the Gym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various crowded scenes. Both simulation and experimental results have demonstrated the superior performance of the proposed method over baseline methods.",
        "primary_area": "",
        "author": "Shuaijun Wang;Rui Gao;Ruihua Han;Shengduo Chen;Chengyang Li;Qi Hao;Shuaijun Wang;Rui Gao;Ruihua Han;Shengduo Chen;Chengyang Li;Qi Hao",
        "authorids": "/377385021124096;/37089197744;/37086568236;/37088504241;/37086065691;/37403530000;/377385021124096;/37089197744;/37086568236;/37088504241;/37086065691;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science, The University of Hongkong; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Rsearch Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982107/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6195286523760641204&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "SUSTech;HKU",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981893",
        "title": "Adaptive Gradient-Descent Extended Kalman Filter for Pose Estimation of Mobile Robots with Sparse Reference Signals",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel extended Kalman filter (EKF) along with its adaptive variant for effective magnetic, angular rate and gravity (MARG) sensor-only pose estimation of mobile robots operated longer periods in reference-denied environments. First, a gradient-descent orientation-based EKF framework is derived, which formulates the MARG-based pose propagation with both bandpass-filtered and bias compensated external acceleration signals. The proposed approach uses two correction signals beside the orientation update, namely, virtual observations and sparse reference signals are incorporated in the state correction. Next, the instantaneous dynamics is characterized by accelerometer/gyroscope signals-based measures and an adaptive strategy is derived for real-time tuning of EKF parameters. The algorithm is fine tuned in an optimization framework on an appropriate database. This database of ground truth and raw MARG measurements contains 16 robot motion scenarios, where both slow motions and agile maneuvers are performed on different terrains. The conducted analysis highlights that the proposed algorithms outperform the standard approaches, moreover, the adaptive strategy further improves the performance by 13%. The comprehensive performance evaluation demonstrates the efficacy of the new algorithms, thereby these robust approaches are proposed in environments characterized by sparse reference measurements.",
        "primary_area": "",
        "author": "Akos Odry;Istvan Kecskes;Dominik Csik;Hashim A. Hashim;Peter Sarcevic;Akos Odry;Istvan Kecskes;Dominik Csik;Hashim A. Hashim;Peter Sarcevic",
        "authorids": "/37870620500;/37705983500;/37089004852;/37086517892;/37085376865;/37870620500;/37705983500;/37089004852;/37086517892;/37085376865",
        "aff": "Institute of Informatics, University of Dunaujvaros, Dunaujvaros, Hungary; Institute of Informatics, University of Dunaujvaros, Dunaujvaros, Hungary; Faculty of Engineering, University of Szeged, Szeged, Hungary; Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada; Faculty of Engineering, University of Szeged, Szeged, Hungary",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981893/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1085056170461560071&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "University of Dunaujvaros;University of Szeged;Carleton University",
        "aff_unique_dep": "Institute of Informatics;Faculty of Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": ";https://www.sze.hu;https://carleton.ca",
        "aff_unique_abbr": ";;Carleton",
        "aff_campus_unique_index": "0;0;1;2;1",
        "aff_campus_unique": "Dunaujvaros;Szeged;Ottawa",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Hungary;Canada"
    },
    {
        "id": "9982217",
        "title": "Adaptive Online Sampling of Periodic Processes with Application to Coral Reef Acoustic Abundance Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an approach that enables long-term monitoring of biological activity on coral reefs by extending mission time and adaptively focusing sensing resources on high-value periods. Coral reefs are one of the most biodiverse ecosystems on the planet; yet they are also among the most imperiled: facing bleaching, ecological community collapses due to global climate change, and degradation from human activities. Our proposed method improves the ability of scientists to monitor biological activity and abundance using passive acoustic sensors. We accomplish this by extracting periodicities from the observed abundance, and using them to predict future abundance. This predictive model is then used with a Monte Carlo Tree Search planning algorithm to schedule sampling at periods of high biological activity, and power down the sensor during periods of low activity. In simulated experiments using long-term acoustic datasets collected in the US Virgin Islands, our adaptive Online Sensor Scheduling algorithm is able to double the lifetime of a sensor while simultaneously increasing the average observed acoustic activity by 21%.",
        "primary_area": "",
        "author": "Seth McCammon;Nad\u00e8ge Aoki;T. Aran Mooney;Yogesh Girdhar;Seth McCammon;Nad\u00e8ge Aoki;T. Aran Mooney;Yogesh Girdhar",
        "authorids": "/37086071053;/37089659399;/37088835302;/37546414900;/37086071053;/37089659399;/37088835302;/37546414900",
        "aff": "Woods Hole Oceanographic Institution, Woods Hole, MA; Woods Hole Oceanographic Institution, Woods Hole, MA; Woods Hole Oceanographic Institution, Woods Hole, MA; Woods Hole Oceanographic Institution, Woods Hole, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982217/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17627876730461299424&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Woods Hole Oceanographic Institution",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.whoi.edu",
        "aff_unique_abbr": "WHOI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Woods Hole",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982113",
        "title": "Adaptive Sampling Site Selection for Robotic Exploration in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomously selecting the right sequence of locations to sample is critical during exploration missions in unknown environments, with constraints on the number of samples that can be collected, and a possibility of system failure. A key idea for decision-making in unknown environments is to exploit side information available to the agent, combined with the information gained from samples collected so far, to estimate the sampling values. In this paper, we pose the problem of sampling site selection as a problem of finding the optimal policy in a Markov decision process modeling the unknown sampling values and the outcomes associated with sampling attempts at different locations. Our solution exploits the fact that the partially unknown rewards of this Markov decision process are correlated to each other to devise a strategy that attempts to maximize the total sample value while also ensuring that the agent achieves its minimum mission requirement. We validate the utility of the proposed approach by evaluating the method against a baseline strategy that pursues collecting the samples that are estimated to be of the highest value. Our evaluations use a simulated sampling problem on Martian terrain and using OceanWATERS, a high-fidelity simulator of a future Europa lander mission.",
        "primary_area": "",
        "author": "Pranay Thangeda;Melkior Ornik;Pranay Thangeda;Melkior Ornik",
        "authorids": "/37088485040;/37086169387;/37088485040;/37086169387",
        "aff": "Department of Aerospace Engineering, Coordinated Science Laboratory, University of Illinois Urbana-Champaign, Urbana, USA; Department of Aerospace Engineering, Coordinated Science Laboratory, University of Illinois Urbana-Champaign, Urbana, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982113/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=799851220900218907&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982270",
        "title": "Adaptive Sampling of Latent Phenomena using Heterogeneous Robot Teams (ASLaP-HR)",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an online adaptive planning strategy for a team of robots with heterogeneous sensors to sample from a latent spatial field using a learned model for decision making. Current robotic sampling methods seek to gather information about an observable spatial field. However, many applications, such as environmental monitoring and precision agriculture, involve phenomena that are not directly observable or are costly to measure, called latent phenomena. In our approach, we seek to reason about the latent phenomenon in real-time by effectively sampling the observable spatial fields using a team of robots with heterogeneous sensors, where each robot has a distinct sensor to measure a different observable field. The information gain is estimated using a learned model that maps from the observable spatial fields to the latent phenomenon. This model captures aleatoric uncertainty in the relationship to allow for information theoretic measures. Additionally, we explicitly consider the correlations among the observable spatial fields, capturing the relationship between sensor types whose observations are not independent. We show it is possible to learn these correlations, and investigate the impact of the learned correlation models on the performance of our sampling approach. Through our qualitative and quantitative results, we illustrate that empirically learned correlations improve the overall sampling efficiency of the team. We simulate our approach using a data set of sensor measurements collected on Lac Hertel, in Quebec, which we make publicly available.",
        "primary_area": "",
        "author": "Matthew Malencia;Sandeep Manjanna;M. Ani Hsieh;George Pappas;Vijay Kumar;Matthew Malencia;Sandeep Manjanna;M. Ani Hsieh;George Pappas;Vijay Kumar",
        "authorids": "/37088506525;/37072300900;/38238444800;/37281547100;/37280341400;/37088506525;/37072300900;/38238444800;/37281547100;/37280341400",
        "aff": "GRASP Laboratory, Levine Hall 4th floor, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982270/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11833386421436184876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982012",
        "title": "Adaptive Sequential Composition for Robot Behaviours",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots are prone to fail in real world environments, where unknown factors can cause their world model to be inaccurate or incomplete. This causes robots to become stuck or repeatedly perform unsuccessful actions believing it is the best option. Static switching frameworks such as sequential composition guarantee stability of the overall system if its constituents are also stable. However, due to unknown factors, robot actions may fail when the robot senses the environment inaccurately. We propose Adaptive Sequential Composition, a novel framework that dynamically selects robot behaviours based on their utility to achieving success. We show the usefulness of the framework in a simulated second order system task as well as its application in navigating a robot through narrow gaps, where the clearance with the gap is smaller than position accuracy. Simulated results show adaptive sequential composition outperforms sequential composition by up to 30 % when presented with unknown factors leading to behaviour failure. For navigating through a narrow gap, adaptive sequential composition improved success by 65 %.",
        "primary_area": "",
        "author": "Benjamin Tam;Navinda Kottege;Nicolas Hudson;Michael Br\u00fcnig;Benjamin Tam;Navinda Kottege;Nicolas Hudson;Michael Br\u00fcnig",
        "authorids": "/37087647613;/37696586900;/37407757300;/37370471200;/37087647613;/37696586900;/37407757300;/37370471200",
        "aff": "Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982012/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3458750662971096162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "CSIRO;University of Queensland",
        "aff_unique_dep": "Robotics and Autonomous Systems Group;School of Information Technology and Electrical Engineering",
        "aff_unique_url": "https://www.csiro.au;https://www.uq.edu.au",
        "aff_unique_abbr": "CSIRO;UQ",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Pullenvale;Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981836",
        "title": "Additive Manufacturing for Tissue Engineering Applications in a Temperature-Controlled Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, with the combination of tissue engineering and additive manufacturing technologies, the possibility of fabricating scaffolds with porosity and complex structure has been improved. Since the properties of most biomaterial inks are influenced by temperature and thereby affect the quality of the scaffolds, a controlled printing environment is very important. This study focuses on temperature monitoring from the nozzle to the working platform. A compact heating jacket is developed to heat the needle and sense its temperature inside the nozzle. It makes it very different from common cartridge heating mechanisms. Moreover, a semi-closed printing environment composed of an air curtain and temperature circulation device is developed to create a stable cooling environment. It improves the uniformity of the work platform and increases by 50% the cooling time efficiency. To demonstrate the robustness for a wide range of temperatures, this study presents two experiments of printing two biomaterial inks at body and low temperatures, respectively.",
        "primary_area": "",
        "author": "Wei-Chih Tseng;Chao-Yaug Liao;Bo-Ren Chen;Luc Chassagne;Barth\u00e9lemy Cagneau;Wei-Chih Tseng;Chao-Yaug Liao;Bo-Ren Chen;Luc Chassagne;Barth\u00e9lemy Cagneau",
        "authorids": "/37089663684;/37089662644;/37089663743;/37322406900;/37573232900;/37089663684;/37089662644;/37089663743;/37322406900;/37573232900",
        "aff": "Universit\u00e9 de Versailles, V\u00e9lizy, France; Department of Mechanical Engineering, National Central University, Taoyuan, Taiwan; Department of Mechanical Engineering, National Central University, Taoyuan, Taiwan; Universit\u00e9 de Versailles, V\u00e9lizy, France; Universit\u00e9 de Versailles, V\u00e9lizy, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981836/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8330439658060848823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Universit\u00e9 de Versailles;National Central University",
        "aff_unique_dep": ";Department of Mechanical Engineering",
        "aff_unique_url": "https://www.univ versaailles.fr;https://www.ncu.edu.tw",
        "aff_unique_abbr": ";NCU",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "V\u00e9lizy;Taiwan",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "France;China"
    },
    {
        "id": "9982230",
        "title": "Adhesion Risk Assessment of An Aircraft Inspection Robot for Improving Operator Awareness",
        "track": "main",
        "status": "Poster",
        "abstract": "Vacuum-adhesion-based climbing robots have been developed to cater to the demands in the cleaning and inspection work of airplanes. A robot intended to clean and inspect an airplane faces a Risk of Adhesion (RoA) based on the robot and the surface conditions, such as worn-out suction cups. These sorts of underlying conditions are not easily noticeable for an operator of a robot and might lead to catastrophic events. Therefore, the ability of a robot to self-assess the RoA in a scenario and notify the operator is crucial for ensuring safety. Particularly, an aircraft inspection robot should have adhesion awareness. This paper proposes a novel method to self-assess the RoA of a vacuum-adhesion-based robot intended to clean and inspect airplanes. The RoA is assessed by a fuzzy inference system that analyzes the present pressure difference and the current duty setting of the vacuum pump of a robot. The robot operator can collaborate with the robot to take precautions based on the assessed RoA to ensure safety. The outcomes of the experiment conducted on an airplane skin validate the ability of the proposed method to assess the RoA associated with heterogeneous operating conditions effectively. Thus, the utilization of the proposed method would improve the safety of a vacuum-adhesion-based robot intended to clean and inspect airplanes.",
        "primary_area": "",
        "author": "M. A. Viraj;J. Muthugala;Manuel Vega-Heredia;Nay Htet Lin;S. M. Bhagya;P. Samarakoon;Mohan Rajesh Elara;M. A. Viraj;J. Muthugala;Manuel Vega-Heredia;Nay Htet Lin;S. M. Bhagya;P. Samarakoon;Mohan Rajesh Elara",
        "authorids": "/37085570415;/37085568853;/37087322480;/37089662070;/37086576513;/37086574744;/37546093700;/37085570415;/37085568853;/37087322480;/37089662070;/37086576513;/37086574744;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982230/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1230876114640998637&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981521",
        "title": "Adjustable Lever Mechanism with Double Parallel Link Platforms for Robotic Limbs",
        "track": "main",
        "status": "Poster",
        "abstract": "For universal robotic limbs, having a large workspace with high stiffness and adjustable output properties is important to adapt to various situations. A combination of parallel mechanisms that can change output characteristics is promising to meet these demands. As such, we propose a lever mechanism with double parallel link platforms. This mechanism is composed of a lever mechanism with the effort point and the pivot point; each is supported by a parallel link mechanism. First, we calculated the differential kinematics of this mechanism. Next, we investigated the workspace of the mechanism. The proposed mechanism can reach nearer positions than the posture with the most shrinking actuators thanks to the three-dimensional movable effort point. Then, we confirmed that this mechanism could change the output force profile at the end-effector by changing the lever ratio. The main change is the directional change of the maximum output force. The change range is larger when the squatting depth is larger. The changing tendency of the shape of the maximum output force profile by the position of the pivot plate depends on the force balance of the actuators. These analytical results show the potential of the proposed mechanism and would aid in the design of this mechanism for robotic limbs.",
        "primary_area": "",
        "author": "Satoshi Nishikawa;Daigo Tokunaga;Kazuo Kiguchi;Satoshi Nishikawa;Daigo Tokunaga;Kazuo Kiguchi",
        "authorids": "/37997724800;/37086667604;/37279644500;/37997724800;/37086667604;/37279644500",
        "aff": "Department of Mechanical Engineering, Graduate School of Engineering, Kyushu University, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kyushu University, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kyushu University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981521/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fGPwZzv2FI0J:scholar.google.com/&scioq=Adjustable+Lever+Mechanism+with+Double+Parallel+Link+Platforms+for+Robotic+Limbs&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Kyushu University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp",
        "aff_unique_abbr": "Kyushu U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981198",
        "title": "Advanced Skills by Learning Locomotion and Local Navigation End-to-End",
        "track": "main",
        "status": "Poster",
        "abstract": "The common approach for local navigation on challenging environments with legged robots requires path planning, path following and locomotion, which usually requires a locomotion control policy that accurately tracks a commanded velocity. However, by breaking down the navigation problem into these sub-tasks, we limit the robot's capabilities since the individual tasks do not consider the full solution space. In this work, we propose to solve the complete problem by training an end-to-end policy with deep reinforcement learning. Instead of continuously tracking a precomputed path, the robot needs to reach a target position within a provided time. The task's success is only evaluated at the end of an episode, meaning that the policy does not need to reach the target as fast as possible. It is free to select its path and the locomotion gait. Training a policy in this way opens up a larger set of possible solutions, which allows the robot to learn more complex behaviors. We compare our approach to velocity tracking and additionally show that the time dependence of the task reward is critical to successfully learn these new behaviors. Finally, we demonstrate the successful deployment of policies on a real quadrupedal robot. The robot is able to cross challenging terrains, which were not possible previously, while using a more energy-efficient gait and achieving a higher success rate. Supplementary videos can be found on the project website: https://sites.google.com/leggedrobotics.com/end-to-end-loco-navigation",
        "primary_area": "",
        "author": "Nikita Rudin;David Hoeller;Marko Bjelonic;Marco Hutter;Nikita Rudin;David Hoeller;Marko Bjelonic;Marco Hutter",
        "authorids": "/37089291474;/37088846413;/37085993346;/37545251000;/37089291474;/37088846413;/37085993346;/37545251000",
        "aff": "NVIDIA; NVIDIA; Robotic Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981198/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8689455935916415056&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "NVIDIA;ETH Zurich",
        "aff_unique_dep": "NVIDIA Corporation;Robotic Systems Lab",
        "aff_unique_url": "https://www.nvidia.com;https://www.ethz.ch",
        "aff_unique_abbr": "NVIDIA;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9982154",
        "title": "Adversarial Attacks on Monocular Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Advances in deep learning have resulted in steady progress in computer vision with improved accuracy on tasks such as object detection and semantic segmentation. Nevertheless, deep neural networks are vulnerable to adversarial attacks, thus presenting a challenge in reliable deployment. Two of the prominent tasks in 3D scene-understanding for robotics and advanced driver assistance systems are monocular depth and pose estimation, often learned together in an unsupervised manner. While studies evaluating the impact of adversarial attacks on monocular depth estimation exist, a systematic demonstration and analysis of adversarial perturbations against pose estimation are lacking. We show how additive imperceptible perturbations can not only change predictions to increase the trajectory drift but also catastrophically alter its geometry. We also study the relation between adversarial perturbations targeting monocular depth and pose estimation networks, as well as the transferability of perturbations to other networks with different architectures and losses. Our experiments show how the generated perturbations lead to notable errors in relative rotation and translation predictions and elucidate vulnerabilities of the networks.11Code can be found at https://github.com/NeurAI-Lab/mono-pose-attack.",
        "primary_area": "",
        "author": "Hemang Chawla;Arnav Varma;Elahe Arani;Bahram Zonooz;Hemang Chawla;Arnav Varma;Elahe Arani;Bahram Zonooz",
        "authorids": "/37088595013;/37088998385;/37088597781;/37088596827;/37088595013;/37088998385;/37088597781;/37088596827",
        "aff": "Advanced Research Lab, NavInfo Europe, The Netherlands; Advanced Research Lab, NavInfo Europe, The Netherlands; Advanced Research Lab, NavInfo Europe, The Netherlands; Advanced Research Lab, NavInfo Europe, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982154/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12785460825462598327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NavInfo Europe",
        "aff_unique_dep": "Advanced Research Lab",
        "aff_unique_url": "https://www.navinfo.com",
        "aff_unique_abbr": "NavInfo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9981973",
        "title": "Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Training a high-dimensional simulated agent with an under-specified reward function often leads the agent to learn physically infeasible strategies that are ineffective when deployed in the real world. To mitigate these unnatural behaviors, reinforcement learning practitioners often utilize complex reward functions that encourage physically plausible behaviors. However, a tedious labor-intensive tuning process is often required to create hand-designed rewards which might not easily generalize across platforms and tasks. We propose substituting complex reward functions with \u201cstyle rewards\u201d learned from a dataset of motion capture demonstrations. A learned style reward can be combined with an arbitrary task reward to train policies that perform tasks using naturalistic strategies. These natural strategies can also facilitate transfer to the real world. We build upon Adversarial Motion Priors - an approach from the computer graphics domain that encodes a style reward from a dataset of reference motions - to demonstrate that an adversarial approach to training policies can produce behaviors that transfer to a real quadrupedal robot without requiring complex reward functions. We also demonstrate that an effective style reward can be learned from a few seconds of motion capture data gathered from a German Shepherd and leads to energy-efficient locomotion strategies with natural gait transitions.",
        "primary_area": "",
        "author": "Alejandro Escontrela;Xue Bin Peng;Wenhao Yu;Tingnan Zhang;Atil Iscen;Ken Goldberg;Pieter Abbeel;Alejandro Escontrela;Xue Bin Peng;Wenhao Yu;Tingnan Zhang;Atil Iscen;Ken Goldberg;Pieter Abbeel",
        "authorids": "/37088999819;/37086454470;/37085891022;/37088504200;/37085362056;/37273026700;/37542877900;/37088999819;/37086454470;/37085891022;/37088504200;/37085362056;/37273026700;/37542877900",
        "aff": "Google Brain; UC Berkeley; Google Brain; Google Brain; Google Brain; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981973/",
        "gs_citation": 123,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15770035799494407975&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;1;1",
        "aff_unique_norm": "Google;University of California, Berkeley",
        "aff_unique_dep": "Google Brain;",
        "aff_unique_url": "https://brain.google.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Google Brain;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;0;0;1;1",
        "aff_campus_unique": "Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981752",
        "title": "Affective Behavior Learning for Social Robot Haru with Implicit Evaluative Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a human-in-the-loop reinforcement learning mechanism to help robots learn emotional behavior. Unlike the previous methods of providing explicit feedback via pressing keyboard buttons or mouse clicks, we provide a more natural way for ordinary people to train social robots how to perform social tasks according to their preferences - facial expressions. The whole experiment is carried out on the desktop robot Haru, which is mainly used for the research of emotion and empathy participation. Our experimental results show that through learning from implicit feedback of facial features, Haru can quickly understand and dynamically adapt to individual preferences, and obtain a similar performance to learning from explicit feedback. In addition, we observe that the recognition error of human feedback will cause a \u201ctemporary regress\u201d of the robot's learning performance, which is more obvious at the beginning of the training process. This phenomenon is shown to be correlated with the accuracy of recognizing negative implicit feedback.",
        "primary_area": "",
        "author": "Hui Wang;Jinying Lin;Zhen Ma;Yurii Vasylkiv;Heike Brock;Keisuke Nakamura;Randy Gomez;Bo He;Guangliang Li;Hui Wang;Jinying Lin;Zhen Ma;Yurii Vasylkiv;Heike Brock;Keisuke Nakamura;Randy Gomez;Bo He;Guangliang Li",
        "authorids": "/37089552976;/37087467016;/37088438862;/37085884941;/37086009097;/37534198900;/37979526500;/37399325300;/37086047680;/37089552976;/37087467016;/37088438862;/37085884941;/37086009097;/37534198900;/37979526500;/37399325300;/37086047680",
        "aff": "Ocean University of China; Ocean University of China; Ocean University of China; University of Manitoba; Honda Research Institute Japan Co., Ltd; Honda Research Institute Japan Co., Ltd; Honda Research Institute Japan Co., Ltd; Ocean University of China; Ocean University of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981752/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12431834749565057653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;2;2;2;0;0",
        "aff_unique_norm": "Ocean University of China;University of Manitoba;Honda Research Institute Japan Co., Ltd",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ouc.edu.cn;https://umanitoba.ca;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "OUC;U of M;HRI-JP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;2;2;2;0;0",
        "aff_country_unique": "China;Canada;Japan"
    },
    {
        "id": "9981417",
        "title": "Algorithm Design and Integration for a Robotic Apple Harvesting System",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to labor shortage and rising labor cost for the apple industry, there is an urgent need for the development of robotic systems to efficiently and autonomously harvest apples. In this paper, we present a system overview and algorithm design of our recently developed robotic apple harvester prototype. Our robotic system is enabled by the close integration of several core modules, including visual perception, planning, and control. This paper covers the main methods and advancements in deep learning-based multi-view fruit detection and localization, unified picking and dropping planning, and dexterous manipulation control. Indoor and field experiments were conducted to evaluate the performance of the developed system, which achieved an average picking rate of 3.6 seconds per apple. This is a significant improvement over other reported apple harvesting robots with a picking rate in the range of 7\u201310 seconds per apple. The current prototype shows promising performance towards further development of efficient and automated apple harvesting technology. Finally, limitations of the current system and future work are discussed.",
        "primary_area": "",
        "author": "Kaixiang Zhang;Kyle Lammers;Pengyu Chu;Nathan Dickinson;Zhaojian Li;Renfu Lu;Kaixiang Zhang;Kyle Lammers;Pengyu Chu;Nathan Dickinson;Zhaojian Li;Renfu Lu",
        "authorids": "/37085728219;/37089663950;/37089662680;/37089663637;/37085495645;/37088646826;/37085728219;/37089663950;/37089662680;/37089663637;/37085495645;/37088646826",
        "aff": "Department of Mechanical Engineering, Michigan State University, East Lansing, MI, USA; Department of Mechanical Engineering, Michigan State University, East Lansing, MI, USA; Department of Mechanical Engineering, Michigan State University, East Lansing, MI, USA; Department of Biosystems and Agricultural Engineering, Michigan State University, East Lansing, MI, USA; Department of Mechanical Engineering, Michigan State University, East Lansing, MI, USA; United States Department of Agriculture Agricultural Research Service, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981417/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6870433652407552157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Michigan State University;United States Department of Agriculture",
        "aff_unique_dep": "Department of Mechanical Engineering;Agricultural Research Service",
        "aff_unique_url": "https://www.msu.edu;https://www.ars.usda.gov",
        "aff_unique_abbr": "MSU;USDA ARS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981768",
        "title": "All You Need is LUV: Unsupervised Collection of Labeled Images Using UV-Fluorescent Markings",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based perception systems in robotics often requires large-scale image segmentation annotation. Current approaches rely on human labelers, which can be expensive, or simulation data, which can visually differ from real data. This paper proposes Labels from UltraViolet (LUV), a novel framework that enables rapid, automated, inexpensive, high quality data collection in real. LUV uses transparent, UV-fluorescent paint with programmable UV LEDs to collect paired images of a scene in standard and UV lighting. This makes it possible to autonomously extract segmentation masks and keypoints via color thresholding. We apply LUV to a suite of diverse robot perception tasks: locating fabric keypoints, cable segmentation, and surgical needle detection to evaluate its labeling quality, flexibility, and data collection rate. Results suggest that LUV is 180\u20132500 times faster than a human labeler across the tasks while retaining accuracy and strong task performance. Code, datasets, visualizations, and supplementary material can be found at https://sites.google.com/berkeley.edu/luv.",
        "primary_area": "",
        "author": "Brijen Thananjeyan;Justin Kerr;Huang Huang;Joseph E. Gonzalez;Ken Goldberg;Brijen Thananjeyan;Justin Kerr;Huang Huang;Joseph E. Gonzalez;Ken Goldberg",
        "authorids": "/37086105009;/37086803999;/37088985585;/37086566024;/37273026700;/37086105009;/37086803999;/37088985585;/37086566024;/37273026700",
        "aff": "The AUTOLab at UC Berkeley; The AUTOLab at UC Berkeley; The AUTOLab at UC Berkeley; The AUTOLab at UC Berkeley; The AUTOLab at UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981768/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15268764696183539156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "The AUTOLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982120",
        "title": "Amoeba-inspired swimming through isoperimetric modulation of body shape",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present the design of a swimming robot that is inspired by the body shape modulation of small microorganisms. Amoebas are small single celled organisms that locomote through deformation and shape change of their body. To achieve similar shape modulation for swimming propulsion in a robot we developed a novel flexible appendage using tape springs. A tape spring is an elongated strip of metal with a curved cross-section that can act as a stiff structure when loaded against the curvature, while it can easily buckle when loaded with the curvature. We develop a tape spring appendage that is capable of freely deforming its perimeter through two actuation inputs. In the first portion of this paper we develop the kinematics of the appendage mechanisms and compare with experiment. Next we present the design of a surface locomoting robot that uses two appendages for propulsion. From the appendage kinematics we derive the local connection vector field for locomotion kinematics and study the optimal gait for forward swimming. Lastly, we demonstrate robot swimming performance in open water conditions. The novel appendage design in this robot is advantageous because it enables omnidirectional movement, the appendages will not tangle in debris, and they are robust to collisions and contact with structures.",
        "primary_area": "",
        "author": "Curtis Sparks;Nathan Justus;Ross Hatton;Nick Gravish;Curtis Sparks;Nathan Justus;Ross Hatton;Nick Gravish",
        "authorids": "/37086934829;/37089553293;/37542919100;/37085401269;/37086934829;/37089553293;/37542919100;/37085401269",
        "aff": "School of Mechanical & Aerospace Engineering Department, University of California, San Diego; School of Mechanical Engineering Department, Oregon State University; School of Mechanical Engineering Department, Oregon State University; School of Mechanical & Aerospace Engineering Department, University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982120/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7868520408891998904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of California, San Diego;Oregon State University",
        "aff_unique_dep": "School of Mechanical & Aerospace Engineering;School of Mechanical Engineering",
        "aff_unique_url": "https://www.ucsd.edu;https://oregonstate.edu",
        "aff_unique_abbr": "UCSD;OSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981985",
        "title": "An Adaptive Approach to Whole-Body Balance Control of Wheel-Bipedal Robot Ollie",
        "track": "main",
        "status": "Poster",
        "abstract": "The wheel-bipedal robot has the advantages of both wheeled robots and legged robots, but as a cost, it is more challenging to perform flexible movements in various surroundings while keeping it balanced. The inaccurate dynamics of the robot makes the balance problem even more intractable. To solve this problem, the robot Ollie is used as a testbed. The whole-body control (WBC) framework is adopted to enhance the dexterity of the robot with multiple degrees of freedom in the task space. Moreover, a learning-based adaptive technique is applied to assist the WBC such that the balance controller can be designed in the absence of the accurate dynamics. Physical experiments demonstrate that the robot can manage various actions, with the help of the combination of the WBC and the learning-based adaptive technique.",
        "primary_area": "",
        "author": "Jingfan Zhang;Shuai Wang;Haitao Wang;Jie Lai;Zhenshan Bing;Yu Jiang;Yu Zheng;Zhengyou Zhang;Jingfan Zhang;Shuai Wang;Haitao Wang;Jie Lai;Zhenshan Bing;Yu Jiang;Yu Zheng;Zhengyou Zhang",
        "authorids": "/37086386519;/37088687660;/37089660899;/37088688811;/37085994830;/37089661329;/37086993722;/37088690693;/37086386519;/37088687660;/37089660899;/37088688811;/37085994830;/37089661329;/37086993722;/37088690693",
        "aff": "Tencent Robotics X, Tencent, Shenzhen, Guangdong, China; Tencent Robotics X, Tencent, Shenzhen, Guangdong, China; Tencent Robotics X, Tencent, Shenzhen, Guangdong, China; Tencent Robotics X, Tencent, Shenzhen, Guangdong, China; Department of Informatics, Technical University of Munich, Munich, Germany; ClearMotion, Inc., Billerica, MA, USA; Tencent Robotics X, Tencent, Shenzhen, Guangdong, China; Tencent Robotics X, Tencent, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981985/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18152074045111925278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;2;0;0",
        "aff_unique_norm": "Tencent;Technical University of Munich;ClearMotion, Inc.",
        "aff_unique_dep": "Tencent Robotics X;Department of Informatics;",
        "aff_unique_url": "https://www.tencent.com;https://www.tum.de;",
        "aff_unique_abbr": "Tencent;TUM;",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Shenzhen;Munich;",
        "aff_country_unique_index": "0;0;0;0;1;2;0;0",
        "aff_country_unique": "China;Germany;United States"
    },
    {
        "id": "9982052",
        "title": "An Adaptive, Affordable, Humanlike Arm Hand System for Deaf and DeafBlind Communication with the American Sign Language",
        "track": "main",
        "status": "Poster",
        "abstract": "To communicate, the ~ 1.5 million Americans living with deafblindess use tactile American Sign Language (t-ASL). To provide Deaf\u00dfilind (DB) individuals with a means of using their primary communication language without the use of an interpreter, we developed an assistive technology that promotes their autonomy. The TATUM (Tactile ASL Translational User Mechanism) anthropomorphic arm hand system leverages previous developments of a fingerspelling hand to sign more complex ASL words and phrases. The TATUM hand-wrist system is attached onto a 4 DOF robot arm and a human motion recognition and human to robot gesture transfer framework is used for signing recognition and replication. In particular, signing trajectories based on vision-based motion capture data from a sign demonstrator were used to control the robot's actuators. The performance of the system was evaluated through tactile based sign recognition performed by a blinded user and for its accuracy with novice, sighted users.",
        "primary_area": "",
        "author": "Che-Ming Chang;Felipe Sanches;Geng Gao;Samantha Johnson;Minas Liarokapis;Che-Ming Chang;Felipe Sanches;Geng Gao;Samantha Johnson;Minas Liarokapis",
        "authorids": "/37087236127;/37088226006;/37087027460;/37089188991;/38558084100;/37087236127;/37088226006;/37087027460;/37089188991;/38558084100",
        "aff": "Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Northeastern University, Boston, MA, USA; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982052/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16319365993058460186&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Auckland;Northeastern University",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.northeastern.edu",
        "aff_unique_abbr": "UoA;NEU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Boston",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "New Zealand;United States"
    },
    {
        "id": "9982214",
        "title": "An All-in-one Cable-driven Parallel Robot with Flexible Workspace and Its Auto-calibration Method",
        "track": "main",
        "status": "Poster",
        "abstract": "For traditional cable-driven parallel robots (CD-PRs), changing the workspace is relatively difficult, which needs to reconfigure the anchor points and the external frame. The main reason is that the winch is separated from the moving platform, and a series of pulleys are applied to guide the driving cables. This paper proposes a novel all-in-one suspended CDPR that integrates all components in the moving platform to realize a flexible workspace. For the rapid construction of the CDPR, the ends of the cables only need to be connected to the existing anchor point. However, due to the flexible workspace, the position values of the anchor points should be recalibrated by appropriate calibration methods, especially by using a rapid auto-calibration method in application sites. Thus, based on the kinetostatic model considering sagging cable, an auto-calibration method with an inclinometer is proposed. Simulation and experiment are conducted respectively, and the experiment results indicate that 78.56% totally reduces the errors of the fixed anchor points. Moreover, experiments were carried out to validate the design and kinematics.",
        "primary_area": "",
        "author": "Hao An;Hang Liu;Xintian Liu;Han Yuan;Hao An;Hang Liu;Xintian Liu;Han Yuan",
        "authorids": "/37085778282;/37089658467;/37089659238;/37086032159;/37085778282;/37089658467;/37089659238;/37086032159",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982214/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12401785776446244207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981329",
        "title": "An Analytical Study of Motion of Autonomous Vehicles under Imperfect Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "A fully tested autonomous system works predictably under ideal or assumed environment. However, its behavior is not fully defined when some components malfunction or fail. In this paper, we consider automated guided vehicle (AGV), equipped with multiple sensors, executing a traversal task in a static unknown environment. We have analytically studied the system, computed a set of performance and safety metrics, and validated it with simulation results in Webots. We have also analyzed the effect on system performance under independent and correlated sensing errors. We have also performed sensitivity analysis to identify the most critical components in any given system; and this can be utilized to increase the reliability of the system and its conformance to safety objectives.",
        "primary_area": "",
        "author": "Swagata Biswas;Himadri Sekhar Paul;Saurabh Bagchi;Swagata Biswas;Himadri Sekhar Paul;Saurabh Bagchi",
        "authorids": "/37086182021;/37085439099;/37273091100;/37086182021;/37085439099;/37273091100",
        "aff": "TCS Research, Kolkata, India; TCS Research, Kolkata, India; Dept. of Electrical and Computer Engg., Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981329/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:j6Bv3zhaoCsJ:scholar.google.com/&scioq=An+Analytical+Study+of+Motion+of+Autonomous+Vehicles+under+Imperfect+Sensing&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Tata Consultancy Services;Purdue University",
        "aff_unique_dep": "Research;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tcs.com;https://www.purdue.edu",
        "aff_unique_abbr": "TCS;Purdue",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Kolkata;West Lafayette",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9982007",
        "title": "An Autonomous Descending-Stair Cleaning Robot with RGB-D based Detection, Approaching, and Area coverage Process",
        "track": "main",
        "status": "Poster",
        "abstract": "Cleaning robots are one of the market dominators in the commercialized robot space. So far, numerous robots have been introduced that can perform cleaning tasks in various settings, including floor, pavement, pool, lawn, windows, etc. However, none of the existing commercial cleaning robots targets the staircase, commonly found in multi-story buildings. Even though few works in the literature introduced robotic solutions for staircase cleaning, they primarily focused on cleaning the ascending staircase often, with a loose connection to access the descending staircase. In this paper, we propose a novel autonomous reconfigurable robotic platform called sTetro-D that can autonomously detect the descending staircase, approach the step, and perform area coverage in an unknown environment. The developed autonomy framework consists of two modes which are search mode and clean mode. In search mode, we implemented an RGB-D camera-based fusion technique wherein we combined the image bounding box from DCNN (Deep Convolution Neural Network) with the depth information to find the 3D first step pose that assists the robot in approaching it precisely. After the successful stair approach, the cleaning mode enables the staircase area coverage process. We described all these aspects and concluded with an experimental analysis of the proposed robotic system in a real-world scenario. The results demonstrate that the robot has a significant performance in detecting the descending staircase, staircase approach, and area coverage.",
        "primary_area": "",
        "author": "Prabakaran Veerajagadheswar;Anh Vu Le;Phone Thiha Kyaw;Mohan Rajesh Elara;Aung Paing;Prabakaran Veerajagadheswar;Anh Vu Le;Phone Thiha Kyaw;Mohan Rajesh Elara;Aung Paing",
        "authorids": "/37086413184;/37086917297;/37088542039;/37546093700;/37088597633;/37086413184;/37086917297;/37088542039;/37546093700;/37088597633",
        "aff": "ROARS Lab, Engineering Product Development, Singapore University of Technology and Design, Singapore; ROARS Lab, Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Mechatronic Engineering, Yangon Technological University, Yangon, Myanmar; ROARS Lab, Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Mechatronic Engineering, Yangon Technological University, Yangon, Myanmar",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982007/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10339059615674365123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Singapore University of Technology and Design;Yangon Technological University",
        "aff_unique_dep": "Engineering Product Development;Department of Mechatronic Engineering",
        "aff_unique_url": "https://www.sutd.edu.sg;",
        "aff_unique_abbr": "SUTD;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Yangon",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "Singapore;Myanmar"
    },
    {
        "id": "9982023",
        "title": "An Efficient and Accurate Solution to Camera Pose Estimation Problem from Point and Line Correspondences Based on Null Space Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an accurate and simultaneously efficient solution to perspective-n-point-and-line (PnPL) problem by null space analysis. Although many PnPL-like methods have been proposed, it is hard to obtain the optimal solution considering both calculation efficiency and accuracy at the same time. Based on the remarkable EOPnP method, the proposed algorithm integrates linear-expressed line constraints with original point constraints, leading to a new solution named EOPnPL. For line error measurement, instead of using the algebraic error built with reprojected endpoints and image lines, we adopt line error function containing the distance from the reprojected midpoint of the model line segment to the image line and giving it a weight 4 times as that of the endpoints. A system of linear homogeneous equations only involving the rotation are derived, containing point and line constraints. Minima are obtained by a null space analysis according to rotation constraints and then the solution is selected by reprojection errors before iterative refinement. Experimental results show that the proposed method showcases great performances in both simulations and real-data experiment on VGG dataset. Great advantages are presented by EOPnPL compared to PnL methods when using only lines. Among the state-of-the-arts methods, the proposed method stands out with high accuracy under ordinary condition and comparable results in planar condition with the speed close to the fastest.",
        "primary_area": "",
        "author": "Yi Zhang;Yueqiang Zhang;Biao Hu;Yihe Yin;Wenjun Chen;Xiaolin Liu;Qifeng Yu;Yi Zhang;Yueqiang Zhang;Biao Hu;Yihe Yin;Wenjun Chen;Xiaolin Liu;Qifeng Yu",
        "authorids": "/37089663989;/37086103773;/37089660276;/37089662397;/37089661472;/37089658584;/37291675000;/37089663989;/37086103773;/37089660276;/37089662397;/37089661472;/37089658584;/37291675000",
        "aff": "Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China; Research Institute of Intelligent Optical Measurement and Detection, Shenzhen University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982023/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13858342024766838356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Shenzhen University",
        "aff_unique_dep": "Research Institute of Intelligent Optical Measurement and Detection",
        "aff_unique_url": "https://www.szu.edu.cn",
        "aff_unique_abbr": "SZU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982069",
        "title": "An Equivalent Time-Optimal Problem to find Energy-Optimal Paths for Skid-Steer Rovers",
        "track": "main",
        "status": "Poster",
        "abstract": "A skid-steer rover's power consumption is highly dependent on the turning radius of its path. For example, a point turn consumes a lot of power compared to a straight-line motion. Thus, in path planning for this kind of rover, turning radius is a factor that should be considered explicitly. There is a lack of any analytical approach in literature for finding energy-optimal paths for skid-steer rovers. The key contribution of this work is an energy-time equivalency theorem, for skid-steer rovers on obstacle-free hard ground. The theorem converts the energy-optimal problem into an equivalent time-optimal problem. This non-intuitive result stems from the fact that with this model of the system the total energy is fully parameterized by the geometry of the path alone. Hence, instead of directly solving the energy-optimal path planning problem, which is highly nonlinear, the equivalent time-optimal problem can be solved. Furthermore, experimental results are provided to experimentally prove the equivalency theorem while using Husky UGV skid-steer rover.",
        "primary_area": "",
        "author": "Meysam Effati;Krzysztof Skonieczny;Tim Freiman;Devin J. Balkcom;Meysam Effati;Krzysztof Skonieczny;Tim Freiman;Devin J. Balkcom",
        "authorids": "/37086152997;/38539052500;/37089660187;/37324093200;/37086152997;/38539052500;/37089660187;/37324093200",
        "aff": "Concrodia University, Montreal, QC, Canada; Concrodia University, Montreal, QC, Canada; Concrodia University, Montreal, QC, Canada; Dartmouth college, Hanover, New Hampshire, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982069/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11716473914568946987&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Concordia University;Dartmouth College",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.concordia.ca;https://dartmouth.edu",
        "aff_unique_abbr": "Concordia;Dartmouth",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Montreal;Hanover",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9981282",
        "title": "An Error-State Model Predictive Control on Connected Matrix Lie Groups for Legged Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports on a new error-state Model Predictive Control (MPC) approach to connected matrix Lie groups for robot control. The linearized tracking error dynamics and the linearized equations of motion are derived in the Lie algebra. Moreover, given an initial condition, the linearized tracking error dynamics and equations of motion are globally valid and evolve independently of the system trajectory. By exploiting the symmetry of the problem, the proposed approach shows faster convergence of rotation and position simultaneously than the state-of-the-art geometric variational MPC based on variational-based linearization. Numerical simulation on tracking control of a fully-actuated 3D rigid body dynamics confirms the benefits of the proposed approach compared to the baselines. Furthermore, the proposed MPC is also verified in pose control and locomotion experiments on a quadrupedal robot MIT Mini Cheetah.",
        "primary_area": "",
        "author": "Sangli Teng;Dianhao Chen;William Clark;Maani Ghaffari;Sangli Teng;Dianhao Chen;William Clark;Maani Ghaffari",
        "authorids": "/37088995976;/37089662177;/37086299313;/37087056400;/37088995976;/37089662177;/37086299313;/37087056400",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; Department of Mathematics, Cornell University, Ithaca, NY; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981282/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17885359375713051410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Michigan;Cornell University",
        "aff_unique_dep": ";Department of Mathematics",
        "aff_unique_url": "https://www.umich.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UM;Cornell",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Ann Arbor;Ithaca",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981176",
        "title": "An Event-triggered Visual Servoing Predictive Control Strategy for the Surveillance of Contour-based Areas using Multirotor Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, an Event-triggered Image-based Visual Servoing Nonlinear Model Predictive Controller (ET-IBVS-NMPC) for multirotor aerial vehicles is presented. The proposed scheme is developed for the autonomous surveillance of contour-based areas with different characteristics (e.g. forest paths, coastlines, road pavements). For this purpose, an appropriately trained Deep Neural Network (DNN) is employed for the accurate detection of the contours. In an effort to reduce the remarkably large computational cost required by an IBVS-NMPC algorithm, a triggering condition is designed to define when the Optimal Control Problem (OCP) should be resolved and new control inputs will be calculated. Between two successive triggering instants, the control input trajectory is applied to the robot in an open-loop fashion, which means that no control input computations are required. As a result, the system's computing effort and energy consumption are lowered, while its autonomy and flight duration are increased. The visibility and input constraints, as well as the external disturbances, are all taken into account throughout the control design. The efficacy of the proposed strategy is demonstrated through a series of real-time experiments using a quadrotor and an octorotor both equipped with a monocular downward looking camera.",
        "primary_area": "",
        "author": "Sotirios N. Aspragkathos;Mario Sinani;George C. Karras;Fotis Panetsos;Kostas J. Kyriakopoulos;Sotirios N. Aspragkathos;Mario Sinani;George C. Karras;Fotis Panetsos;Kostas J. Kyriakopoulos",
        "authorids": "/37089474488;/37089659609;/38559666800;/37089472738;/38181756700;/37089474488;/37089659609;/38559666800;/37089472738;/38181756700",
        "aff": "Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Dept. of Informatics and Telecommunications, University of Thessaly, Lamia, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981176/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10805692163453905544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "National Technical University of Athens;University of Thessaly",
        "aff_unique_dep": "School of Mechanical Engineering;Dept. of Informatics and Telecommunications",
        "aff_unique_url": "https://www.ntua.gr;https://www.uth.gr",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lamia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981391",
        "title": "An Impedance-Controlled Testbed for Simulating Variations in the Mechanical Fit of Wearable Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "The fit of a wearable device, such as a prosthesis, can be quantitatively characterized by the mechanical coupling at the user-device interface. It is thought that the mechanical impedance, specifically the stiffness and damping, of wearable device interfaces can significantly impact human performance while using them. To test this theory, we develop a forearm-mounted testbed with a motorized, two degree of freedom (2-DOF) gimbal to simulate variations in the mechanical fit of an upper-extremity wearable device during pointing and target tracking tasks. The two gimbal motors are impedance-controlled to vary the mechanical stiffness and damping between the user and the device's laser pointer end-effector. In this paper, experiments are conducted to determine the torque constants of the motors before implementation in the testbed, and to validate the accuracy of the joint impedance controller. The completed impedance-controlled wearable interface testbed is validated further by comparing the gimbal joint displacements and torques, recorded during 2-DOF base excitation experiments, to MATLAB Simulink simulation data.",
        "primary_area": "",
        "author": "Alexander B. Ambrose;Chelse VanAtter;Frank L. Hammond;Alexander B. Ambrose;Chelse VanAtter;Frank L. Hammond",
        "authorids": "/37088504917;/37089195081;/37394264300;/37088504917;/37089195081;/37394264300",
        "aff": "Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Biomedical Engineering, Clemson University, Clemson, South Carolina, USA; Department of Biomedical Engineering, Georgia Institute of Technology, Woodruff School of Mechanical Engineering and the Coulter, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981391/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DGvC9F97eA4J:scholar.google.com/&scioq=An+Impedance-Controlled+Testbed+for+Simulating+Variations+in+the+Mechanical+Fit+of+Wearable+Devices&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Clemson University",
        "aff_unique_dep": "Woodruff School of Mechanical Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.clemson.edu",
        "aff_unique_abbr": "Georgia Tech;Clemson",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Clemson",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981912",
        "title": "An In-pipe Crawling Robot based on Tensegrity Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel concept to develop robots capable of crawling in tubular environments, inspired by the movement of earthworms and the biological musculoskeletal systems in nature. A tensegrity structures-based robotic module with shape changeability actuated by only one linear actuator is proposed. The mechanical structure of the robotic module is determined on the basis of force density method. By serially cascading three uniform modules, the in-pipe crawling robot is designed and manufactured. The robot has the abilities to crawl in both horizontal and vertical pipes with different inner diameters, and to pass through elbow pipes adaptively under the control of a simple actuation sequence. The effectiveness of the robot is demonstrated by experimental results on the prototype. Compared with existing robots, this proposed approach enables compact yet robust structures, along with enhanced compliance, mobility, and adaptability.",
        "primary_area": "",
        "author": "Yixiang Liu;Qing Bi;Xiaolin Dai;Rui Song;Xizhe Zang;Yibin Li;Yixiang Liu;Qing Bi;Xiaolin Dai;Rui Song;Xizhe Zang;Yibin Li",
        "authorids": "/37085416040;/37087243979;/37089516967;/37546859100;/37546447400;/37279897500;/37085416040;/37087243979;/37089516967;/37546859100;/37546447400;/37279897500",
        "aff": "Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Shandong Institute of Advanced Technology, Chinese Academy of Sciences, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981912/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13663037693508991677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Engineering Research Center of Intelligent Unmanned System;Shandong Institute of Advanced Technology;Harbin Institute of Technology",
        "aff_unique_dep": "Ministry of Education;;State Key Laboratory of Robotics and System",
        "aff_unique_url": ";;http://www.hit.edu.cn/",
        "aff_unique_abbr": ";;HIT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Jinan;Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981118",
        "title": "An Integrated Actuation-Perception Framework for Robotic Leaf Retrieval: Detection, Localization, and Cutting",
        "track": "main",
        "status": "Poster",
        "abstract": "Contemporary robots in precision agriculture focus primarily on automated harvesting or remote sensing to monitor crop health. Comparatively less work has been performed with respect to collecting physical leaf samples in the field and retaining them for further analysis. Typically, orchard growers manually collect sample leaves and utilize them for stem water potential measurements to analyze tree health and determine irrigation routines. While this technique benefits orchard management, the process of collecting, assessing, and interpreting measurements requires significant human labor and often leads to infrequent sampling. Automated sampling can provide highly accurate and timely information to growers. The first step in such automated in-situ leaf analysis is identifying and cutting a leaf from a tree. This retrieval process requires new methods for actuation and perception. We present a technique for detecting and localizing candidate leaves using point cloud data from a depth camera. This technique is tested on both indoor and outdoor point clouds from avocado trees. We then use a custom-built leaf-cutting end-effector on a 6-DOF robotic arm to test the proposed detection and localization technique by cutting leaves from an avocado tree. Experimental testing with a real avocado tree demonstrates our proposed approach can enable our mobile manipulator and custom end-effector system to successfully detect, localize, and cut leaves.",
        "primary_area": "",
        "author": "Merrick Campbell;Amel Dechemi;Konstantinos Karydis;Merrick Campbell;Amel Dechemi;Konstantinos Karydis",
        "authorids": "/37088983532;/37086934209;/38252121900;/37088983532;/37086934209;/38252121900",
        "aff": "Dept. of Electrical and Computer Eng., Univ. of California, Riverside, Riverside, CA, USA; Dept. of Electrical and Computer Eng., Univ. of California, Riverside, Riverside, CA, USA; Dept. of Electrical and Computer Eng., Univ. of California, Riverside, Riverside, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981118/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11904076099784816745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Eng.",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981977",
        "title": "An Observer-Based Responsive Variable Impedance Control for Dual-User Haptic Training System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a variable impedance control architecture to facilitate eye surgery training in a dual-user haptic system. In this system, an expert surgeon (the trainer) and a novice surgeon (the trainee) collaborate on a surgical procedure using their own haptic devices. The mechanical impedance parameters of the trainer's haptic device remain constant during the operation, whereas those of the trainee vary with his/her proficiency level. The trainee's relative proficiency might be objectively quantified in real-time based on position error between the trainer and the trainee. The proposed architecture enables the trainer to intervene in the training process as needed to ensure the trainee is following the right course of action and to avoid the trainee's from potential tissue injuries. The stability of the overall nonlinear closed-loop system has been investigated using the input-to-state stability (ISS) criterion. High-gain observer with unknown inputs is considered in this work to estimate the interaction forces. Simulation and experimental results under different scenarios confirm the effectiveness of the proposed control methods.",
        "primary_area": "",
        "author": "A. Rashvand;R. Heidari;M. Motaharifar;A. Hassani;M.R. Dindarloo;M. J. Ahmadi;K. Hashtrudi-Zaad;M. Tavakoli;H. D. Taghirad;A. Rashvand;R. Heidari;M. Motaharifar;A. Hassani;M.R. Dindarloo;M. J. Ahmadi;K. Hashtrudi-Zaad;M. Tavakoli;H. D. Taghirad",
        "authorids": "/37089230400;/37088376394;/37945484500;/37089231459;/37089230017;/37089402605;/38277052700;/37282400400;/38180146500;/37089230400;/37088376394;/37945484500;/37089231459;/37089230017;/37089402605;/38277052700;/37282400400;/38180146500",
        "aff": "Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Department of Electrical Engineering, University of Isfahan, Isfahan, Iran; Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Queen's University, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Advanced Robotics and Automated Systems (ARAS), Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981977/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3490202457231634756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;0;2;3;0",
        "aff_unique_norm": "K.N. Toosi University of Technology;University of Isfahan;Queen's University;University of Alberta",
        "aff_unique_dep": "Faculty of Electrical Engineering;Department of Electrical Engineering;Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.kntu.ac.ir;http://www.ui.ac.ir;https://www.queensu.ca;https://www.ualberta.ca",
        "aff_unique_abbr": "KNTU;;Queen's U;UAlberta",
        "aff_campus_unique_index": "0;0;1;0;0;0;3;0",
        "aff_campus_unique": "Tehran;Isfahan;;Edmonton",
        "aff_country_unique_index": "0;0;0;0;0;0;1;1;0",
        "aff_country_unique": "Iran;Canada"
    },
    {
        "id": "9981697",
        "title": "An Online Interactive Approach for Crowd Navigation of Quadrupedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot navigation in human crowds remains the challenge of understanding human behaviors in different scenarios. We present an approach for interactive and human-friendly crowd navigation in complex static environments. The planner models the online interactions among the robot, humans, and the static environment based on game theory. It recurrently expands and optimizes the estimated trajectories for the robot and neighboring agents and provides human-friendly navigation commands. We use various indicators to evaluate the social awareness of the planners and show that our method outperforms existing approaches in success rate to reach the goals and compatibility with humans while maintaining low navigation times. The planner is successfully deployed on a real-world quadrupedal robot, demonstrating safe and interactive crowd navigation with real-time performance.",
        "primary_area": "",
        "author": "Bowen Yang;Jianhao Jiao;Lujia Wang;Ming Liu;Bowen Yang;Jianhao Jiao;Lujia Wang;Ming Liu",
        "authorids": "/37088996526;/37086552343;/37406752700;/37085398677;/37088996526;/37086552343;/37406752700;/37085398677",
        "aff": "Hong Kong University of Science and Technology, Hong Kong, SAR China; Hong Kong University of Science and Technology, Hong Kong, SAR China; Clear Water Bay Institute of Autonomous Driving; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981697/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7991435646053782427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Clear Water Bay Institute of Autonomous Driving",
        "aff_unique_dep": ";Institute of Autonomous Driving",
        "aff_unique_url": "https://www.ust.hk;",
        "aff_unique_abbr": "HKUST;",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Hong Kong;Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982273",
        "title": "An Optimal Dynamic Control Method for Robots with Virtual Links",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtual links and virtual joints can be appended to the kinematic chain of a robot arm to assist in modelling and control of certain tasks. Activities such as spray painting, sand blasting, or scanning with a laser or camera can be enhanced by modelling the fluid stream, light beam, or field of view using a virtual link. Virtual joints can be used to allow movement in semi-redundant degrees of freedom of the task space. This can can be exploited to optimize the control of the real robot. A prudent choice is to minimize the effort required by the manipulator to execute the task. This often requires the inversion of the inertia matrix. However, virtual links have no inertia so the inverse does not exist. This paper first explores methods of adding virtual mass or modifying the inertia matrix to allow inversion and the consequences. Then an optimal control problem is proposed that minimizes kinetic energy in the real manipulator and maximizes use of the virtual joints. In doing so, we only need the real inertia matrix which is always invertible. The method is validated in a case study for high pressure water blasting. It is shown to reduce the dynamic torque norm compared to a minimum velocity controller.",
        "primary_area": "",
        "author": "Jon Woolfrey;Dikai Liu;Jon Woolfrey;Dikai Liu",
        "authorids": "/37085806326;/37290601500;/37085806326;/37290601500",
        "aff": "Center for Robotics & Intelligent Systems, Istituto Italiano di Tecnologia, Genova, Italy; Robotics Institute, University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982273/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1280954922186431226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University of Technology Sydney",
        "aff_unique_dep": "Center for Robotics & Intelligent Systems;Robotics Institute",
        "aff_unique_url": "https://www.iit.it;https://www.uts.edu.au",
        "aff_unique_abbr": "IIT;UTS",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Genova;Ultimo",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Italy;Australia"
    },
    {
        "id": "9981642",
        "title": "An Optimal Motion Planning Framework for Quadruped Jumping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an optimal motion planning framework to generate versatile energy-optimal quadrupedal jumping motions automatically (e.g., flips, spin). The jumping motions via the centroidal dynamics are formulated as a 12-dimensional black-box optimization problem subject to the robot kino-dynamic constraints. Gradient-based approaches offer great success in addressing trajectory optimization (TO), yet, prior knowledge (e.g., reference motion, contact schedule) is required and results in sub-optimal solutions. The new proposed framework first employed a heuristics-based optimization method to avoid these problems. Moreover, a prioritization fitness function is created for heuristics-based algorithms in robot ground reaction force (GRF) planning, enhancing convergence and searching performance considerably. Since heuristics-based algorithms often require significant time, motions are planned offline and stored as a pre-motion library. A selector is designed to automatically choose motions with user-specified or perception information as input. The proposed framework has been successfully validated only with a simple continuously tracking PD controller in an open-source Mini-Cheetah by several challenging jumping motions, including jumping over a window-shaped obstacle with 30 cm height and left-flipping over a rectangle obstacle with 27 cm height. (Video*)",
        "primary_area": "",
        "author": "Zhitao Song;Linzhu Yue;Guangli Sun;Yihu Ling;Hongshuo Wei;Linhai Gui;Yun-Hui Liu;Zhitao Song;Linzhu Yue;Guangli Sun;Yihu Ling;Hongshuo Wei;Linhai Gui;Yun-Hui Liu",
        "authorids": "/37088504118;/37087053034;/37086356287;/37089659146;/37089658831;/37087052837;/37279412600;/37088504118;/37087053034;/37086356287;/37089659146;/37089658831;/37087052837;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hongkong; Department of Mechanical and Automation Engineering, The Chinese University of Hongkong; Department of Mechanical and Automation Engineering, The Chinese University of Hongkong; Staff of Hong Kong Centre for Logistics Robotics; Staff of Hong Kong Centre for Logistics Robotics; Department of Mechanical and Automation Engineering, The Chinese University of Hongkong; Department of Mechanical and Automation Engineering, The Chinese University of Hongkong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981642/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15368178270018745618&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Hong Kong Centre for Logistics Robotics",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981170",
        "title": "An Underwater Target Perception Framework for Underwater Operation Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an underwater target perception framework to comprehensively explore target information in underwater scenes, to improve the work efficiency and safety of underwater operations. This framework adopts a layered processing mechanism including water column imaging, constant false alarm rate detection (CFAR) detection, and local feature analysis, to accurately distinguish between false targets, static targets, and dynamic targets in the underwater scene, and obtain the motion trajectory of dynamic targets. The experiment is designed to simulate the underwater operation scene, and the results prove the effectiveness of the proposed framework.",
        "primary_area": "",
        "author": "Jue Gao;Chi Zhu;Jue Gao;Chi Zhu",
        "authorids": "/37089659957;/37289715600;/37089659957;/37289715600",
        "aff": "Department of Environment and Life Engineering, Maebashi Institute of Technology, Maebashi-City, Gunma, Japan; Department of Environment and Life Engineering, Maebashi Institute of Technology, Maebashi-City, Gunma, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981170/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7923079216979536856&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Maebashi Institute of Technology",
        "aff_unique_dep": "Department of Environment and Life Engineering",
        "aff_unique_url": "https://www.mae-tech.ac.jp",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Maebashi-City",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982109",
        "title": "An Unsupervised Domain Adaptive Approach for Multimodal 2D Object Detection in Adverse Weather Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Integrating different representations from complementary sensing modalities is crucial for robust scene interpretation in autonomous driving. While deep learning architectures that fuse vision and range data for 2D object detection have thrived in recent years, the corresponding modalities can degrade in adverse weather or lighting conditions, ultimately leading to a drop in performance. Although domain adaptation methods attempt to bridge the domain gap between source and target domains, they do not readily extend to heterogeneous data distributions. In this work, we propose an unsupervised domain adaptation framework, which adapts a 2D object detector for RGB and LiDAR sensors to one or more target domains featuring adverse weather conditions. Our proposed approach consists of three components. First, a data augmentation scheme that simulates weather distortions is devised to add domain confusion and prevent overfitting on the source data. Second, to promote cross-domain foreground object alignment, we leverage the complementary features of multiple modalities through a multi-scale entropy-weighted domain discriminator. Finally, we use carefully designed pretext tasks to learn a more robust representation of the target domain data. Experiments performed on the DENSE dataset show that our method can substantially alleviate the domain gap under the single-target domain adaptation setting and the less explored yet more general multi-target domain adaptation setting.",
        "primary_area": "",
        "author": "George Eskandar;Robert A. Marsden;Pavithran Pandiyan;Mario D\u00f6bler;Karim Guirguis;Bin Yang;George Eskandar;Robert A. Marsden;Pavithran Pandiyan;Mario D\u00f6bler;Karim Guirguis;Bin Yang",
        "authorids": "/37089179540;/37089550734;/37089663247;/37089550192;/37088587224;/37399884400;/37089179540;/37089550734;/37089663247;/37089550192;/37088587224;/37399884400",
        "aff": "University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; Robert Bosch GmbH, Renningen, Germany; University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982109/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13698984497718214651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Stuttgart;Robert Bosch GmbH",
        "aff_unique_dep": "Institute of Signal Processing and System Theory;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.bosch.com",
        "aff_unique_abbr": ";Bosch",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Stuttgart;Renningen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981466",
        "title": "An offline geometric model for controlling the shape of elastic linear objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new approach to control the shape of deformable objects with robots. Specifically, we consider a fixed-length elastic linear object lying on a 2D workspace. Our main idea is to encode the object's deformation behavior in an offline constant Jacobian matrix. To derive this Jacobian, we use geometric deformation modeling and combine recent work from the fields of deformable object control and multirobot systems. Based on this Jacobian, we then propose a robotic control law that is capable of driving a set of shape features on the object toward prescribed values. Our contribution relative to existing approaches is that at run-time we do not need to measure the full shape of the object or to estimate/simulate a deformation model. This simplification is achieved thanks to having abstracted the deformation behavior as an offline model. We illustrate the proposed approach in simulation and in experiments with real deformable linear objects.",
        "primary_area": "",
        "author": "Omid Aghajanzadeh;Miguel Aranda;Gonzalo L\u00f3pez-Nicol\u00e1s;Roland Lenain;Youcef Mezouar;Omid Aghajanzadeh;Miguel Aranda;Gonzalo L\u00f3pez-Nicol\u00e1s;Roland Lenain;Youcef Mezouar",
        "authorids": "/37089578095;/38575293000;/37546413100;/37283367600;/37299713100;/37089578095;/38575293000;/37546413100;/37283367600;/37299713100",
        "aff": "Universite Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Universit\u00e9 Clermont Auvergne, INRAE, URTSCF, Aubi\u00e8re, France; Universite Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981466/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13495746914541336102&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Universite Clermont Auvergne;Universidad de Zaragoza;Universit\u00e9 Clermont Auvergne",
        "aff_unique_dep": ";Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n;INRAE, URTSCF",
        "aff_unique_url": "https://www.universite-clermont-auvergne.fr;https://www.unizar.es;",
        "aff_unique_abbr": "UCA;;",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Clermont-Ferrand;;Aubi\u00e8re",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "France;Spain"
    },
    {
        "id": "9982245",
        "title": "An open-source motion planning framework for mobile manipulators using constraint-based task space control with linear MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an open source motion planning framework for ROS, which uses constraint and optimization based task space control to generate trajectories for the whole body of mobile manipulators. Motion goals are defined as constraints which are enforced on task space functions. They map the controllable degrees of freedom of a system onto custom task spaces, which can, but do not have to be, the Cartesian space. We use this expressive tool from motion control to pre-compute trajectories in order to utilize the fact that most robots offer controllers to follow such trajectories. As a result, our framework only requires a kinematic model of the robot to control it. In addition, we extend the constraint-based motion control approach with linear MPC to explicitly optimize for velocity, acceleration and jerk simultaneously, which allows us to enforce constraints on all derivatives in both joint and task space at the same time. As a result, we can reuse predefined motion goals on any robot without modifications. Our framework was tested on four different robots to show its generality.",
        "primary_area": "",
        "author": "Simon Stelter;Georg Bartels;Michael Beetz;Simon Stelter;Georg Bartels;Michael Beetz",
        "authorids": "/37086156090;/37586080900;/37279125900;/37086156090;/37586080900;/37279125900",
        "aff": "Institute for Artificial Intelligence, University of Bremen, Germany; Ubica Robotics GmbH; Institute for Artificial Intelligence, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982245/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5767719324960413871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Bremen;Ubica Robotics",
        "aff_unique_dep": "Institute for Artificial Intelligence;",
        "aff_unique_url": "https://www.uni-bremen.de;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981861",
        "title": "Analysis of Hybrid Cable-Thruster actuated ROV in heavy lifting interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "Many operations performed by work class Remotely Operated Vehicles (ROVs) require the manipulation of heavy loads. An example is the manipulation and grouting of armour stones. A way to increase the working capabilities of the ROV is to introduce cables among the set of actuators. The cable lengths and tensions are controlled by winches placed on the vehicle. Being similar to a cable-driven parallel robot (CDPR), the resultant system inherits some advantages such as the possibility to generate large forces over a large workspace and the possibility to use CDPR techniques to estimate the pose of the ROV. This paper proposes a complete control architecture for the Hybrid Cable-Thruster actuated ROV (HCT-ROV) and analyzes, in computer simulations, the performances of such a system while it performs real world operations, such as heavy lifting and hovering in presence of water current.",
        "primary_area": "",
        "author": "Nikolas Sacchi;Enrico Simetti;Gianluca Antonelli;Giovanni Indiveri;Vincent Creuze;Marc Gouttefarde;Nikolas Sacchi;Enrico Simetti;Gianluca Antonelli;Giovanni Indiveri;Vincent Creuze;Marc Gouttefarde",
        "authorids": "/37088914203;/37601568800;/37281306400;/37285395400;/37329638100;/37542917900;/37088914203;/37601568800;/37281306400;/37285395400;/37329638100;/37542917900",
        "aff": "DIII, Univ Pavia, Pavia, Italy; DIBRIS, Univ Genova, Genova, Italy; DIEI, Univ Cassino, Cassino, Italy; DIBRIS, Univ Genova, Genova, Italy; LIRMM, CNRS, Univ Mont-pellier, Montpellier, France; LIRMM, CNRS, Univ Mont-pellier, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981861/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14519385025022666509&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;3;3",
        "aff_unique_norm": "University of Pavia;University of Genoa;University of Cassino;Laboratoire d'Informatique, de Robotique et de Micro\u00e9lectronique de Montpellier (LIRMM)",
        "aff_unique_dep": "DIII;DIBRIS (Department of Informatics, Bioengineering, Robotics and Systems Engineering);Department of Information Engineering and Computer Science (DIEI);",
        "aff_unique_url": "https://www.unipv.eu;https://www.unige.it;https://www.unicassino.it;https://www.lirmm.fr",
        "aff_unique_abbr": ";Univ Genova;Univ Cassino;LIRMM",
        "aff_campus_unique_index": "0;1;2;1;3;3",
        "aff_campus_unique": "Pavia;Genova;Cassino;Montpellier",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "Italy;France"
    },
    {
        "id": "9981951",
        "title": "Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement Learning for Robotic Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Randomization is currently a widely used approach in Sim2Real transfer for data-driven learning algorithms in robotics. Still, most Sim2Real studies report results for a specific randomization technique and often on a highly customized robotic system, making it difficult to evaluate different randomization approaches systematically. To address this problem, we define an easy-to-reproduce experimental setup for a robotic reach-and-balance manipulator task, which can serve as a benchmark for comparison. We compare four randomization strategies with three randomized parameters both in simulation and on a real robot. Our results show that more randomization helps in Sim2Real transfer, yet it can also harm the ability of the algorithm to find a good policy in simulation. Fully randomized simulations and fine-tuning show differentiated results and translate better to the real robot than the other approaches tested.",
        "primary_area": "",
        "author": "Josip Josifovski;Mohammadhossein Malmir;Noah Klarmann;Bare Luka \u017dagar;Nicol\u00e1s Navarro-Guerrero;Alois Knoll;Josip Josifovski;Mohammadhossein Malmir;Noah Klarmann;Bare Luka \u017dagar;Nicol\u00e1s Navarro-Guerrero;Alois Knoll",
        "authorids": "/37086575655;/37086484292;/37089659094;/37089195933;/37086327612;/37276234100;/37086575655;/37086484292;/37089659094;/37089195933;/37086327612;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Rosenheim University of Applied Sciences, Rosenheim, Germany; Department of Informatics, Technical University of Munich, Germany; Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH, Germany; Department of Informatics, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981951/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5134357712757971795&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;0",
        "aff_unique_norm": "Technical University of Munich;Rosenheim University of Applied Sciences;Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH",
        "aff_unique_dep": "Department of Informatics;;",
        "aff_unique_url": "https://www.tum.de;https://www Rosenheim-university.de;https://www.dfki.de",
        "aff_unique_abbr": "TUM;;DFKI",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Munich;Rosenheim;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981934",
        "title": "Analysis of User Behavior and Workload During Simultaneous Tele-operation of Multiple Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses the tele-operation system for multiple mobile manipulators. If a single person could freely tele-operate multiple mobile manipulators simultaneously, it would be a great step toward the goal of \u201cavatar-symbiotic society\u201d allowing people to live beyond the constraints of their bodies, space, and time. At present, however, such a tele-operation system has not been developed. Therefore, we built a prototype system to tele-operate two mobile manipulators and conducted a subject experiment on a pick-and-place task to investigate the tele-operator's task performance, workload and gaze behavior. By analyzing these results, we obtained guidelines to design tele-operation system for multiple robots.",
        "primary_area": "",
        "author": "Tatsuya Aoki;Tomoaki Nakamura;Takayuki Nagai;Tatsuya Aoki;Tomoaki Nakamura;Takayuki Nagai",
        "authorids": "/37086199380;/37536789800;/37280601500;/37086199380;/37536789800;/37280601500",
        "aff": "Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Osaka, Japan; Department of Mechanical and Intelligent Systems Engineering, The University of Electro-Communications, Tokyo, Japan; Artificial Intelligence Exploration Research Center, The University of Electro-Communications, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981934/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=950388172526217720&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Osaka University;University of Electro-Communications",
        "aff_unique_dep": "Department of Systems Innovation;Department of Mechanical and Intelligent Systems Engineering",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.uec.ac.jp",
        "aff_unique_abbr": "Osaka U;UEC",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Osaka;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981356",
        "title": "Analytical Second-Order Partial Derivatives of Rigid-Body Inverse Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimization-based robot control strategies often rely on first-order dynamics approximation methods, as in iLQR. Using second-order approximations of the dynamics is expensive due to the costly second-order partial derivatives of the dynamics with respect to the state and control. Current approaches for calculating these derivatives typically use automatic differentiation (AD) and chain-rule accumulation or finite-difference. In this paper, for the first time, we present analytical expressions for the second-order partial derivatives of inverse dynamics for open-chain rigid-body systems with floating base and multi-DoF joints. A new extension of spatial vector algebra is proposed that enables the analysis. A recursive algorithm with complexity of \\mathcal{O}(Nd^{2})\\mathcal{O}(Nd^{2}) is also provided where N is the number of bodies and d is the depth of the kinematic tree. A comparison with AD in CasADi shows speedups of 1.5-3 x for serial kinematic trees with N > 5, and a C++ implementation shows runtimes of \\approx \\mathbf{5 1} \\mu \\mathrm{s}\\approx \\mathbf{5 1} \\mu \\mathrm{s} for a quadruped.",
        "primary_area": "",
        "author": "Shubham Singh;Ryan P. Russell;Patrick M. Wensing;Shubham Singh;Ryan P. Russell;Patrick M. Wensing",
        "authorids": "/37089249134;/37089249876;/37946046300;/37089249134;/37089249876;/37946046300",
        "aff": "University of Texas at Austin, Austin, TX, USA; University of Texas at Austin, Austin, TX, USA; Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981356/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4184536396193767886&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;University of Notre Dame",
        "aff_unique_dep": ";Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu;https://www.nd.edu",
        "aff_unique_abbr": "UT Austin;Notre Dame",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Austin;Notre Dame",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981286",
        "title": "Analyzing and Overcoming Degradation in Warm-Start Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) for robotic applications can benefit from a warm-start where the agent is initialized with a pretrained behavioral policy. However, when transitioning to RL updates, degradation in performance can occur, which may compromise the robot's safety. This degradation, which constitutes an inability to properly utilize the pretrained policy, is attributed to extrapolation error in the value function, a result of high values being assigned to Out-Of-Distribution actions not present in the behavioral policy's data. We investigate why the magnitude of degradation varies across policies and why the policy fails to quickly return to behavioral performance. We present visual confirmation of our analysis and draw comparisons to the Offline RL setting which suffers from similar difficulties. We propose a novel method, Confidence Constrained Learning (CCL) for Warm-Start RL, that reduces degradation by balancing between the policy gradient and constrained learning according to a confidence measure of the Q-values. For the constrained learning component we propose a novel objective, Positive Q-value Distance (CCL-PQD). We investigate a variety of constraint-based methods that aim to overcome the degradation, and find they constitute solutions for a multi-objective optimization problem between maximimal performance and miniminal degradation. Our results demonstrate that hyperparameter tuning for CCL-PQD produces solutions on the Pareto Front of this multi-objective problem, allowing the user to balance between performance and tolerable compromises to the robot's safety.",
        "primary_area": "",
        "author": "Benjamin Wexler;Elad Sarafian;Sarit Kraus;Benjamin Wexler;Elad Sarafian;Sarit Kraus",
        "authorids": "/37089659751;/37088870242;/37285129900;/37089659751;/37088870242;/37285129900",
        "aff": "Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel; Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel; Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981286/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9588470732484939885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bar-Ilan University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.biu.ac.il",
        "aff_unique_abbr": "BIU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ramat-Gan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981945",
        "title": "Animal Motions on Legged Robots Using Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a motion capture-driven locomotion controller for quadrupedal robots that replicates the non-periodic footsteps and subtle body movement of animal motions. We adopt a nonlinear model predictive control (NMPC) formulation that generates optimal base trajectories and stepping locations. By optimizing both footholds and base trajectories, our controller effectively tracks retargeted animal motions with natural body movements and highly irregular strides. We demonstrate our approach with prerecorded animal motion capture data. In simulation and hardware experiments, our motion controller enables quadrupedal robots to robustly reproduce fundamental characteristics of a target animal motion regardless of the significant morphological disparity.",
        "primary_area": "",
        "author": "Dongho Kang;Flavio De Vincenti;Naomi C. Adami;Stelian Coros;Dongho Kang;Flavio De Vincenti;Naomi C. Adami;Stelian Coros",
        "authorids": "/37089194550;/37089196705;/37089660084;/37077396200;/37089194550;/37089196705;/37089660084;/37077396200",
        "aff": "Computational Robotics Lab, Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland; Computational Robotics Lab, Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland; Laboratory for Movement Biomechanics in the Institute for Biomechanics (IfB), ETH Zurich, Switzerland; Computational Robotics Lab, Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981945/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15629694932946094990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Intelligent Interactive Systems",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981247",
        "title": "Anisotropic-Stiffness Belt in Mono wheeled Flexible Track for Rough Terrain Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Rescue robots that search around on debris during natural disasters require high mobility to overcome various shaped materials scattered in the environment. Our previous study developed a new tracked mechanism called Mono-wheel Track, an elastic track driven by a single wheel, having a high capability to get over obstacles. In designing the MW - Track, the track stiffness is an essential factor-the flexible track can adapt to the geometry of the obstacles, but the flexibility prevents grousers from anchoring to the environment steadily. If the track has different localized stiffnesses, both the adaptability and the stability might be archived. In this study, we developed an \u201canisotropic-stiffness track,\u201d exhibiting different stiffness depending on the bending side, and investigated its deformation characteristics and the effects on mobility. The basic deformation characteristics of the track were confirmed by load tests. The effects on mobility were evaluated by step-climbing tests, ditch-crossing tests, and traction measuring with a mobile robot.",
        "primary_area": "",
        "author": "Yu Ozawa;Masahiro Watanabe;Kenjiro Tadakuma;Satoshi Tadokoro;Yu Ozawa;Masahiro Watanabe;Kenjiro Tadakuma;Satoshi Tadokoro",
        "authorids": "/37088441287;/37403419100;/38534909200;/37296054300;/37088441287;/37403419100;/38534909200;/37296054300",
        "aff": "Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Tough Cyberphysical AI Research Center, Tohoku University, Sendai, Japan; Tough Cyberphysical AI Research Center, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981247/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12549842091514883760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Graduate School of Information Sciences",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981701",
        "title": "Application of Ghost-DeblurGAN to Fiducial Marker Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature extraction or localization based on the fiducial marker could fail due to motion blur in real-world robotic applications. To solve this problem, a lightweight generative adversarial network, named Ghost-DeblurGAN, for real-time motion deblurring is developed in this paper. Furthermore, on account that there is no existing deblurring benchmark for such task, a new large-scale dataset, York-Tag, is proposed that provides pairs of sharp/blurred images containing fiducial markers. With the proposed model trained and tested on YorkTag, it is demonstrated that when applied along with fiducial marker systems to motion-blurred images, Ghost-DeblurGAN improves the marker detection significantly. The datasets and codes used in this paper are available at: https://github.com/York-SDCNLab/Ghost-DeblurGAN.",
        "primary_area": "",
        "author": "Yibo Liu;Amaldev Haridevan;Hunter Schofield;Jinjun Shan;Yibo Liu;Amaldev Haridevan;Hunter Schofield;Jinjun Shan",
        "authorids": "/37089034416;/37089663185;/37089033704;/37708721000;/37089034416;/37089663185;/37089033704;/37708721000",
        "aff": "Department of Earth and Space Science and Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, York University, Toronto, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981701/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17849328533068273287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "York University",
        "aff_unique_dep": "Department of Earth and Space Science and Engineering",
        "aff_unique_url": "https://www.yorku.ca",
        "aff_unique_abbr": "York U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981207",
        "title": "Application of Piece-wise Constant Strain Model to Flexible Deformation Calculation of Sports Prosthesis and Stiffness Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we present an application of the Piece-wise Constant Strain (PCS) model to a flexible deformation analysis of a sports prosthesis leg. Dynamic motion analysis of an athlete wearing a sports prosthesis is important to clarify a relationship between the prosthesis characteristics and the performance of an athlete, which contributes to training of an athlete or design of the prosthesis. However, there are few studies on modeling of the three-dimensional deformation of the sports prosthesis. In soft robotics, the PCS model was proposed for calculating a flexible deformation of a beam or rod structure with a low computational cost. We employ the PCS model to calculate the flexible deformation of the prosthesis, assuming that its structure can be discretized into a finite number of segments. Moreover, we propose an estimation method of the prosthesis stiffness using optical motion capture data and calculating the semi-definite programming.",
        "primary_area": "",
        "author": "Yuta Shimane;Taiki Ishigaki;Sunghee Kim;Yosuke Ikegami;Ko Yamamoto;Yuta Shimane;Taiki Ishigaki;Sunghee Kim;Yosuke Ikegami;Ko Yamamoto",
        "authorids": "/37089659845;/37089197618;/37089661470;/38251779000;/37536641800;/37089659845;/37089197618;/37089661470;/38251779000;/37536641800",
        "aff": "Department of Mechano-informatics, Univ. of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981207/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2216396544382320823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hongo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981283",
        "title": "Are We Ready for Robust and Resilient SLAM? A Framework For Quantitative Characterization of SLAM Datasets",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliability of SLAM systems is considered one of the critical requirements in modern autonomous systems. This directed the efforts to developing many state-of-the-art systems, creating challenging datasets, and introducing rigorous metrics to measure SLAM performance. However, the link between datasets and performance in the robustness/resilience context has rarely been explored. In order to fill this void, characterization of the operating conditions of SLAM systems is essential in order to provide an environment for quantitative measurement of robustness and resilience. In this paper, we argue that for proper evaluation of SLAM performance, the characterization of SLAM datasets serves as a critical first step. The study starts by reviewing previous efforts for quantitative characterization of SLAM datasets. Then, the problem of perturbation characterization is discussed and the linkage to SLAM robustness/resilience is established. After that, we pro-pose a novel, generic and extendable framework for quantitative analysis and comparison of SLAM datasets. Additionally, a description of different characterization parameters is provided. Finally, we demonstrate the application of our framework by presenting the characterization results of three SLAM datasets: KITTI, EuroC-MAV, and TUM-VI highlighting the level of insights achieved by the proposed framework.",
        "primary_area": "",
        "author": "Islam Ali;Hong Zhang;Islam Ali;Hong Zhang",
        "authorids": "/37089663179;/37280789900;/37089663179;/37280789900",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Electronic and Electrical Engineering, SUSTech, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981283/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9727510932818942361&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Alberta;SUSTech",
        "aff_unique_dep": "Department of Computing Science;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.ualberta.ca;https://www.sustech.edu.cn",
        "aff_unique_abbr": "UAlberta;SUSTech",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Edmonton;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "9981779",
        "title": "Articulated Object Interaction in Unknown Scenes with Whole-Body Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "A kitchen assistant needs to operate human-scale objects, such as cabinets and ovens, in unmapped environments with dynamic obstacles. Autonomous interactions in such environments require integrating dexterous manipulation and fluid mobility. While mobile manipulators in different form factors provide an extended workspace, their real-world adoption has been limited. Executing a high-level task for general objects requires a perceptual understanding of the object as well as adaptive whole-body control among dynamic obstacles. In this paper, we propose a two-stage architecture for autonomous interaction with large articulated objects in unknown environments. The first stage, object-centric planner, only focuses on the object to provide an action-conditional sequence of states for manipulation using RGB-D data. The second stage, agent-centric planner, formulates the whole-body motion control as an optimal control problem that ensures safe tracking of the generated plan, even in scenes with moving obstacles. We show that the proposed pipeline can handle complex static and dynamic kitchen settings for both wheel-based and legged mobile manipulators. Compared to other agent-centric planners, our proposed planner achieves a higher success rate and a lower execution time. We also perform hardware tests on a legged mobile manipulator to interact with various articulated objects in a kitchen. For additional material, please check: www.pair.toronto.edularticulated-mm/.",
        "primary_area": "",
        "author": "Mayank Mittal;David Hoeller;Farbod Farshidian;Marco Hutter;Animesh Garg;Mayank Mittal;David Hoeller;Farbod Farshidian;Marco Hutter;Animesh Garg",
        "authorids": "/37089654860;/37088846413;/37085428006;/37545251000;/37086330576;/37089654860;/37088846413;/37085428006;/37545251000;/37086330576",
        "aff": "ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; University of Toronto, Canada and Vector Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981779/",
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15734682615352513250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "ETH Zurich;University of Toronto",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ethz.ch;https://www.utoronto.ca",
        "aff_unique_abbr": "ETH;U of T",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Switzerland;Canada"
    },
    {
        "id": "9982112",
        "title": "AssembleRL: Learning to Assemble Furniture from Their Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "The rise of simulation environments has enabled learning-based approaches for assembly planning, which is otherwise a labor-intensive and daunting task. Assembling furniture is especially interesting since furniture are intricate and pose challenges for learning-based approaches. Surprisingly, humans can solve furniture assembly mostly given a 2D snapshot of the assembled product. Although recent years have witnessed promising learning-based approaches for furniture assembly, they assume the availability of correct connection labels for each assembly step, which are expensive to obtain in practice. In this paper, we alleviate this assumption and aim to solve furniture assembly with as little human expertise and supervision as possible. To be specific, we assume the availability of the assembled point cloud, and comparing the point cloud of the current assembly and the point cloud of the target product, obtain a novel reward signal based on two measures: Incorrectness and incompleteness. We show that our novel reward signal can train a deep network to successfully assemble different types of furniture. Code and networks available here: https://github.com/METU-KALFA/AssembleRL.",
        "primary_area": "",
        "author": "Ozgur Aslan;Burak Bolat;Batuhan Bal;Tugba Tumer;Erol Sahin;Sinan Kalkan;Ozgur Aslan;Burak Bolat;Batuhan Bal;Tugba Tumer;Erol Sahin;Sinan Kalkan",
        "authorids": "/37086877295;/37089659420;/37089660745;/37089660202;/37371122800;/37836992800;/37086877295;/37089659420;/37089660745;/37089660202;/37371122800;/37836992800",
        "aff": "Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey; Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey; Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey; Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey; Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey; Dept. of Computer Engineering, KOVAN Research Lab; METU-ROMER, Center for Robotics and Artificial Intelligence, Middle East Technical University, Ankara, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982112/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8985331911518551663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;0;1;0;1;0;1;0;1",
        "aff_unique_norm": "KOVAN Research Lab;Middle East Technical University",
        "aff_unique_dep": "Dept. of Computer Engineering;Center for Robotics and Artificial Intelligence",
        "aff_unique_url": ";https://www.metu.edu.tr",
        "aff_unique_abbr": ";METU",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Ankara",
        "aff_country_unique_index": "1;1;1;1;1;1",
        "aff_country_unique": ";T\u00fcrkiye"
    },
    {
        "id": "9981623",
        "title": "Assembly Planning from Observations under Physical Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of copying an unknown assembly of primitives with known shape and appearance using information extracted from a single photograph by an off-the-shelf procedure for object detection and pose estimation. The proposed algorithm uses a simple combination of physical stability constraints, convex optimization and Monte Carlo tree search to plan assemblies as sequences of pick-and-place operations represented by STRIPS operators. It is efficient and, most importantly, robust to the errors in object detection and pose estimation unavoidable in any real robotic system. The proposed approach is demonstrated with thorough experiments on a UR5 manipulator.",
        "primary_area": "",
        "author": "Thomas Chabal;Robin Strudel;Etienne Arlaud;Jean Ponce;Cordelia Schmid;Thomas Chabal;Robin Strudel;Etienne Arlaud;Jean Ponce;Cordelia Schmid",
        "authorids": "/37089663805;/37087323370;/37089658142;/37282647000;/37282990700;/37089663805;/37087323370;/37089658142;/37282647000;/37282990700",
        "aff": "D\u00e9partement d'informatique de l'ENS, Ecole normale sup\u00e9rieure, CNRS, PSL Research University; D\u00e9partement d'informatique de l'ENS, Ecole normale sup\u00e9rieure, CNRS, PSL Research University; INRIA; Center for Data Science, New York University; D\u00e9partement d'informatique de l'ENS, Ecole normale sup\u00e9rieure, CNRS, PSL Research University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981623/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4901495159212980119&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Ecole Normale Sup\u00e9rieure;INRIA;New York University",
        "aff_unique_dep": "D\u00e9partement d'informatique;;Center for Data Science",
        "aff_unique_url": "https://www.ens.fr;https://www.inria.fr;https://www.nyu.edu",
        "aff_unique_abbr": "ENS;INRIA;NYU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "9981760",
        "title": "Asynchronous Real-time Decentralized Multi-Robot Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel overconstraining and constraint-discarding method for asynchronous, real-time, decentralized, multi-robot trajectory planning that ensures collision avoidance. Our approach utilizes communication between robots. The communication medium is best-effort: messages may be dropped, re-ordered or delayed. Robots conservatively constrain themselves against others assuming they may be working with outdated information, and discard constraints when they receive update messages from others. Our method can augment existing synchronized decentralized receding horizon planning algorithms that utilize separating hyperplanes for collision avoidance thereby making them applicable to asynchronous setups. As an example, we extend an existing model predictive control based, synchronized, decentralized multi-robot planner using our method. We show our method's effectiveness under asynchronous planning and imperfect communication by comparing our extension to the base version. Our extension does not result in any collisions or synchronization-induced deadlocks to which the base version is prone.",
        "primary_area": "",
        "author": "Baskin \u015eenba\u015flar;Gaurav S. Sukhatme;Baskin \u015eenba\u015flar;Gaurav S. Sukhatme",
        "authorids": "/37089662074;/37278934100;/37089662074;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA, United States; Department of Computer Science, University of Southern California, Los Angeles, CA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981760/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16849234311944425902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982143",
        "title": "Attention-Based Deep Driving Model for Autonomous Vehicles with Surround-View Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Experienced human drivers always make safe driving decisions by selectively observing the front, rear and side- view mirrors. Several end - to-end methods have been pro-posed to learn driving models with multi-view visual infor-mation. However, these benchmark methods lack semantic understanding of multi-view image contents, where human drivers usually reason these information for decision making with different visual region of interests. In this paper, we propose an attention-based deep learning method to learn a driving model with input of surround-view visual information and the route planner, in which a multi-view attention module is designed for obtaining region of interests from human drivers. We evaluate our model on the Drive360 dataset with comparison of benchmarking deep driving models. Results demonstrate that our model achieves a competitive accuracy in both steering angle and speed prediction than benchmarking methods. Code is available at https://githuh.com/jet-uestc/MVA-Net.",
        "primary_area": "",
        "author": "Yang Zhao;Jie Li;Rui Huang;Boqi Li;Ao Luo;Yaochen Li;Hong Cheng;Yang Zhao;Jie Li;Rui Huang;Boqi Li;Ao Luo;Yaochen Li;Hong Cheng",
        "authorids": "/37897003800;/37089736349;/37085625169;/37086592399;/37089014361;/37715813500;/37280209600;/37897003800;/37089736349;/37085625169;/37086592399;/37089014361;/37715813500;/37280209600",
        "aff": "Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Software Egineering, Xi'an Jiaotong University, Xi'an, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982143/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ixzTFzoRay0J:scholar.google.com/&scioq=Attention-Based+Deep+Driving+Model+for+Autonomous+Vehicles+with+Surround-View+Cameras&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China;University of Michigan;Xi'an Jiao Tong University",
        "aff_unique_dep": "School of Automation Engineering;Mechanical Engineering Department;School of Software Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn;https://www.umich.edu;http://www.xjtu.edu.cn",
        "aff_unique_abbr": "UESTC;UM;XJTU",
        "aff_campus_unique_index": "0;0;0;1;0;2;0",
        "aff_campus_unique": "Chengdu;Ann Arbor;Xi'an",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981429",
        "title": "Attention-Based Population-Invariant Deep Reinforcement Learning for Collision-Free Flocking with A Scalable Fixed-Wing UAV Swarm",
        "track": "main",
        "status": "Poster",
        "abstract": "A swarm of fixed-wing unmanned aerial vehicles (UAVs) is expected to efficiently accomplish various tasks in complex scenarios. This paper proposes an attention-based population-invariant multi-agent deep reinforcement learning (MADRL) approach to deal with the decentralized collision-free flocking problem for a scalable fixed-wing UAV swarm. First, this problem is modeled as a decentralized partially observable Markov decision process from the perspective of each follower. Then, an improved multi-agent deep deterministic policy gradient (MADDPG) algorithm is presented to efficiently learn the population-invariant flocking policy. In this algorithm, the parameter sharing with ego-centric representation mechanism is incorporated to improve learning efficiency. Besides, the attention-based population-invariant network structure (APINet) is designed by leveraging the self-attention mechanism. With this structure, the learned flocking policy is invariant to the population of the swarm. Finally, both numerical and hardware-in-the-loop simulation results verify the efficiency and scalability of the proposed approach.",
        "primary_area": "",
        "author": "Chao Yan;Kin Huat Low;Xiaojia Xiang;Tianjiang Hu;Lincheng Shen;Chao Yan;Kin Huat Low;Xiaojia Xiang;Tianjiang Hu;Lincheng Shen",
        "authorids": "/37086440285;/37267827500;/37085698451;/37286680100;/37287404300;/37086440285;/37267827500;/37085698451;/37286680100;/37287404300",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University (NTU), Singapore; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; School of Aeronautics and Astronautics, Sun Yat-sen University, Guangzhou, Guangdong, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981429/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6136037523952287195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "Nanyang Technological University;National University of Defense Technology;Sun Yat-sen University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;College of Intelligence Science and Technology;School of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.ntu.edu.sg;;http://www.sysu.edu.cn",
        "aff_unique_abbr": "NTU;;SYSU",
        "aff_campus_unique_index": "0;0;1;2;1",
        "aff_campus_unique": "Singapore;Changsha;Guangzhou",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9981242",
        "title": "Attention-guided RGB-D Fusion Network for Category-level 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work focuses on estimating 6D poses and sizes of category-level objects from a single RGB-D image. How to exploit the complementary RGB and depth features plays an important role in this task yet remains an open question. Due to the large intra-category texture and shape variations, an object instance in test may have different RGB and depth features from those of the object instances in training, which poses challenges to previous RGB-D fusion methods. To deal with such problem, an Attention-guided RGB-D Fusion Network (ARF-Net) is proposed in this work. Our key design is an ARF module that learns to adaptively fuse RGB and depth features with guidance from both structure-aware attention and relation-aware attention. Specifically, the structure-aware attention captures spatial relationship among object parts and the relation-aware attention captures the RGB-to-depth correlations between the appearance and geometric features. Our ARF -Net directly establishes canonical correspondences with a compact decoder based on the multi-modal features from our ARF module. Extensive experiments show that our method can effectively fuse RGB features to various popular point cloud encoders and provide consistent performance improvement. In particular, without reconstructing instance 3D models, our method with its relatively compact architecture outperforms all state-of-the-art models on CAMERA25 and REAL275 benchmarks by a large margin.",
        "primary_area": "",
        "author": "Hao Wang;Weiming Li;Jiyeon Kim;Qiang Wang;Hao Wang;Weiming Li;Jiyeon Kim;Qiang Wang",
        "authorids": "/37089736120;/37404629700;/37089584982;/37089198031;/37089736120;/37404629700;/37089584982;/37089198031",
        "aff": "SAIT China Lab, Samsung Research Center, Beijing, China; SAIT China Lab, Samsung Research Center, Beijing, China; Samsung Advanced Institute of Technology(SAIT), South Korea; SAIT China Lab, Samsung Research Center, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981242/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4116003591841854334&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "SAIT China Lab",
        "aff_unique_url": "https://www.samsung.com",
        "aff_unique_abbr": "SRC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9981549",
        "title": "Audio-Visual Depth and Material Estimation for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reflective and textureless surfaces such as windows, mirrors, and walls can be a challenge for scene reconstruction, due to depth discontinuities and holes. We propose an audio-visual method that uses the reflections of sound to aid in depth estimation and material classification for 3D scene reconstruction in robot navigation and AR/VR applications. The mobile phone prototype emits pulsed audio, while recording video for audio-visual classification for 3D scene reconstruction. Reflected sound and images from the video are input into our audio (EchoCNN-A) and audio-visual (EchoCNN-AV) convolutional neural networks for surface and sound source detection, depth estimation, and material classification. The inferences from these classifications enhance 3D scene reconstructions containing open spaces and reflective surfaces by depth filtering, inpainting, and placement of unmixed sound sources in the scene. Our prototype, demos, and experimental results from real-world with challenging surfaces and sound, also validated with virtual scenes, indicate high success rates on classification of material, depth estimation, and closed/open surfaces, leading to considerable improvement in 3D scene reconstruction for robot navigation.",
        "primary_area": "",
        "author": "Justin Wilson;Nicholas Rewkowski;Ming C. Lin;Justin Wilson;Nicholas Rewkowski;Ming C. Lin",
        "authorids": "/37087322840;/37086348683;/37278387400;/37087322840;/37086348683;/37278387400",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill, United States; Department of Computer Science, University of Maryland at College Park, United States; Department of Computer Science, University of Maryland at College Park, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981549/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=578074989747076609&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;University of Maryland",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.unc.edu;https://www/umd.edu",
        "aff_unique_abbr": "UNC Chapel Hill;UMD",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Chapel Hill;College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982199",
        "title": "Augment-Connect-Explore: a Paradigm for Visual Action Planning with Data Scarcity",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual action planning particularly excels in applications where the state of the system cannot be computed explicitly, such as manipulation of deformable objects, as it enables planning directly from raw images. Even though the field has been significantly accelerated by deep learning techniques, a crucial requirement for their success is the availability of a large amount of data. In this work, we propose the Augment-Connect-Explore (ACE) paradigm to enable visual action planning in cases of data scarcity. We build upon the Latent Space Roadmap (LSR) framework which performs planning with a graph built in a low dimensional latent space. In particular, ACE is used to i) Augment the available training dataset by autonomously creating new pairs of datapoints, ii) create new unobserved Connections among representations of states in the latent graph, and iii) Explore new regions of the latent space in a targeted manner. We validate the proposed approach on both simulated box stacking and real-world folding task showing the applicability for rigid and deformable object manipulation tasks, respectively.",
        "primary_area": "",
        "author": "Martina Lippi;Michael C. Welle;Petra Poklukar;Alessandro Marino;Danica Kragic;Martina Lippi;Michael C. Welle;Petra Poklukar;Alessandro Marino;Danica Kragic",
        "authorids": "/37086443839;/38202265300;/37088686149;/37390952800;/37281296000;/37086443839;/38202265300;/37088686149;/37390952800;/37281296000",
        "aff": "Roma Tre University, Rome, Italy; KTH Royal Institute of Technology Stockholm, Sweden; KTH Royal Institute of Technology Stockholm, Sweden; University of Cassino and Southern Lazio, Cassino, Italy; KTH Royal Institute of Technology Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982199/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4256675371795742209&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Roma Tre University;KTH Royal Institute of Technology;University of Cassino and Southern Lazio",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uniroma3.it;https://www.kth.se;https://www.unicas.it",
        "aff_unique_abbr": "Roma Tre;KTH;",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Rome;Stockholm;Cassino",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Italy;Sweden"
    },
    {
        "id": "9981263",
        "title": "Autoexplorer: Autonomous Exploration of Unknown Environments using Fast Frontier-Region Detection and Parallel Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a fully autonomous system for mobile robot exploration in unknown environments. Our system employs a novel frontier detection algorithm based on the fast front propagation (FFP) technique and uses parallel path planning to reach the detected front regions. Given an occupancy grid map in 2D, possibly updated online, our algorithm can find all the frontier points that can allow mobile robots to visit unexplored regions to maximize the exploratory coverage. Our FFP method is six~seven times faster than the state-of-the-art wavefront frontier detection algorithm in terms of finding frontier points without compromising the detection accuracy. The speedup can be further accelerated by simplifying the map without degrading the detection accuracy. To expedite locating the optimal frontier point, We also eliminate spurious points by the obstacle filter and the novel boundary filter. In addition, we parallelize the global planning phase using the branch-and-bound A*, where the search space of each thread is confined by its best knowledge discovered during the parallel search. As a result, our parallel path-planning algorithm operating on 20 threads is about 30 times faster than the vanilla exploration system that operates on a single thread. Our method is validated through extensive experiments, including autonomous robot exploration in both synthetic and real-world scenarios. In the real-world experiment, we show that an autonomous navigation system using a human-sized mobile manipulator robot equipped with a low-end embedded processor that fully integrates our FFP and parallel path-planning algorithms.",
        "primary_area": "",
        "author": "Kyung Min Han;Young J. Kim;Kyung Min Han;Young J. Kim",
        "authorids": "/37088507416;/38185529300;/37088507416;/38185529300",
        "aff": "department of computer science and engineering, Ewha womans university in Korea; department of computer science and engineering, Ewha womans university in Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981263/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=106140125810900390&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ewha Womans University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "http://www.ewha.ac.kr",
        "aff_unique_abbr": "Ewha",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981979",
        "title": "Automated Aerial Screwing with a Fully Actuated Aerial Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "The tasks that unmanned aerial vehicles (UAVs) have taken upon have progressively grown in complexity over the years, alongside with the level of autonomy with which they are carried out. In this work, we present an example of aerial screwing operations with a fully-actuated tilt-rotor platform. Key contributions include a new control framework to automate screwing operations through a robust hole search and in-hole detection algorithm. These are achieved without a-priori knowledge of the exact hole location, and without the use of external tools, such as vision based hole detection or force sensors. Wrench coupling is implemented to account for the platform's kinematic constraints during screwing. The application of a constant contact force and a compliant response to induced disturbances are obtained with the use of admittance control. The full framework is validated with extensive flight experiments that demonstrate the effectiveness of each subsystem, as well as the complete architecture. We also validate the robustness of the detection algorithm against false positives. Within the results we demonstrate the ability to perform the automated task with a 86% success rate over 35 flights, and measured hole search time of 9s (median value).",
        "primary_area": "",
        "author": "Micha Schuster;David Bernstein;Paul Reck;Salua Hamaza;Michael Beitelschmidt;Micha Schuster;David Bernstein;Paul Reck;Salua Hamaza;Michael Beitelschmidt",
        "authorids": "/37089662239;/37089662836;/37089662960;/37085715218;/37087097447;/37089662239;/37089662836;/37089662960;/37085715218;/37087097447",
        "aff": "Chair for Dynamics and Mechanism Design, Technische Universit\u00e4t Dresden (TU Dresden), Dresden, Germany; Chair for Dynamics and Mechanism Design, Technische Universit\u00e4t Dresden (TU Dresden), Dresden, Germany; Chair for Dynamics and Mechanism Design, Technische Universit\u00e4t Dresden (TU Dresden), Dresden, Germany; Micro Air Vehicle Laboratory, Delft University of Technology (TU Delft), Delft, The Netherlands; Chair for Dynamics and Mechanism Design, Technische Universit\u00e4t Dresden (TU Dresden), Dresden, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981979/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16960442585950968114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Dresden;Delft University of Technology",
        "aff_unique_dep": "Chair for Dynamics and Mechanism Design;Micro Air Vehicle Laboratory",
        "aff_unique_url": "https://www.tu-dresden.de;https://www.tudelft.nl",
        "aff_unique_abbr": "TU Dresden;TU Delft",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Dresden;Delft",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "9981164",
        "title": "Automated Flexible Needle Trajectory Planning for Keyhole Neurosurgery Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning a safe trajectory for minimally invasive (keyhole) neurosurgery procedures require avoiding critical anatomical structures such as blood vessels and ventricles while optimizing the needle trajectory parameters such as length and curvature to comply with the needle kinematics. In this paper, we propose a reinforcement learning-based method for obtaining kinematically feasible trajectories for flexible needle insertions. Proposed approach utilizes Bezier curve control points that are generated by a reward-based reinforcement learning framework, called Flexible Needle Path Generation (FNPG). FNPG framework is trained using an environment that consists of (1) critical structures (e.g. ventricles) obtained through atlas based segmentation of MRI-T1 images, (2) blood vessels segmented from MR angiography (MRA) data and, (3) simulated brain tumor with varying size and location. The curvilinear paths obtained through the FNPG framework are compared with the traditional sampling based algorithm RRT*. The results show that the FNPG approach can produce smoother and shorter trajectories compared to RRT* while avoiding the critical anatomical structures.",
        "primary_area": "",
        "author": "Jayesh Kumar;Chinmay Satish Raut;Niravkumar Patel;Jayesh Kumar;Chinmay Satish Raut;Niravkumar Patel",
        "authorids": "/37089659520;/37089659256;/37089189193;/37089659520;/37089659256;/37089189193",
        "aff": "Department of Engineering Design at Indian Institute of Technology Madras, Chennai, India; Department of Engineering Design at Indian Institute of Technology Madras, Chennai, India; Department of Engineering Design at Indian Institute of Technology Madras, Chennai, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981164/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4368891162251507501&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Madras",
        "aff_unique_dep": "Department of Engineering Design",
        "aff_unique_url": "https://www.iitm.ac.in",
        "aff_unique_abbr": "IIT Madras",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chennai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9981987",
        "title": "Automated Fruit Quality Testing using an Electrical Impedance Tomography-Enabled Soft Robotic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic grippers are becoming increasingly popular for agricultural and logistics automation. Their passive conformability enables them to adapt to varying product shapes and sizes, providing stable large-area grasps. This work presents a novel methodology for combining soft robotic grippers with electrical impedance tomography-based sensors to infer intrinsic properties of grasped fruits. We use a Fin Ray soft robotic finger with embedded microspines to grab and obtain rich multi-direction electrical properties of the object. Learning-based techniques are then used to infer the desired fruit properties. The framework is extensively tested and validated on multiple fruit groups. Our results show that ripeness parameters and even weight of the grasped fruit can be estimated with reasonable accuracy autonomously using the proposed system.",
        "primary_area": "",
        "author": "Elijah Almanzor;Thomas George Thuruthel;Fumiya Iida;Elijah Almanzor;Thomas George Thuruthel;Fumiya Iida",
        "authorids": "/37089663804;/37086306163;/37552719700;/37089663804;/37086306163;/37552719700",
        "aff": "Department of Engineering, The Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, The Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, The Bio-Inspired Robotics Lab, University of Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981987/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8473709258318912595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981723",
        "title": "Automated design of task specific additively manufacturable coupled serial chain mechanisms for tracing predefined planar trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Simon Schiele;Sebastian Baumgartner;Simon Laudahn;Tim C. Lueth;Simon Schiele;Sebastian Baumgartner;Simon Laudahn;Tim C. Lueth",
        "authorids": "/37086933976;/37089662187;/37088420551;/37389804500;/37086933976;/37089662187;/37088420551;/37389804500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981723/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13190254143336176686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9982013",
        "title": "Automatic Co-Design of Aerial Robots Using a Graph Grammar",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles (UAVs) have broad applications including disaster response, transportation, photography, and mapping. A significant bottleneck in the development of UAVs is the limited availability of automatic tools for task-specific co-design of a UAV's shape and controller. The development of such tools is particularly challenging as UAVs can take many forms, including fixed-wing planes, radial copters, and hybrid topologies, with each class of topology showing different advantages. In this work, we present a computational design pipeline for UAVs based on a graph grammar that can search across a wide range of topologies. Graphs generated by the grammar encode different topologies and component selections, while continuous parameters encode the dimensions and properties of each component. We further augment the shape representation with deformation cages, which allow expressing a variety of wing shapes. Each UAV design is associated with an LQR controller with tunable continuous parameters. To search over this complex discrete and continuous design space, we develop a hybrid algorithm that combines discrete graph search strategies and gradient-based continuous optimization methods using a differentiable UAV simulator. We evaluate our pipeline on a set of simulated flight tasks requiring dynamic motions, showing that it discovers novel UAV designs that outperform canonical UAVs typically made by engineers.",
        "primary_area": "",
        "author": "Allan Zhao;Tao Du;Jie Xu;Josie Hughes;Juan Salazar;Pingchuan Ma;Wei Wang;Daniela Rus;Wojciech Matusik;Allan Zhao;Tao Du;Jie Xu;Josie Hughes;Juan Salazar;Pingchuan Ma;Wei Wang;Daniela Rus;Wojciech Matusik",
        "authorids": "/37088827263;/37088842690;/37088996337;/37085816016;/37089450321;/37089448038;/37073346500;/37279652300;/37295070400;/37088827263;/37088842690;/37088996337;/37085816016;/37089450321;/37089448038;/37073346500;/37279652300;/37295070400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computational Robot Design and Fabrication Lab, \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL); Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982013/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3625483458321205795&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Computational Robot Design and Fabrication Lab",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.epfl.ch",
        "aff_unique_abbr": "MIT;EPFL",
        "aff_campus_unique_index": "0;0;0;1;0;0;0;0;0",
        "aff_campus_unique": "Cambridge;Lausanne",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9982201",
        "title": "Automatic Generation of Optimization Model using Process Mining and Petri Nets for Optimal Motion Planning of 6-DOF Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an optimization system for motion planning of robot arms using Petri Nets. The proposed optimization system consists of four sub-systems consisting of automatic generation of Petri Nets from event log data, optimization system of firing sequence of derived Petri Net model, verification system using Petri Net simulation, and an automatic program generation system. The model generation system automatically generates the Petri Net model from the event logs using process mining. The Petri Net verification system is used to check the consistency of the generated Petri Nets to obtain the optimal firing sequence for robot motion. The motion planning algorithm generates motion programs for robots based on optimal firing sequences. The proposed optimization model is applied to a 6-DOF (Degree of Freedom) robot manipulator (Niryo Ned). Experimental results show that the proposed method achieves motion plan optimization for the pick-and-place operation with different robot configurations.",
        "primary_area": "",
        "author": "Takuma Bando;Tatsushi Nishi;Md Moktadir Alam;Ziang Liu;Tomofumi Fujiwara;Takuma Bando;Tatsushi Nishi;Md Moktadir Alam;Ziang Liu;Tomofumi Fujiwara",
        "authorids": "/37089662729;/37275663600;/37089662905;/37089658290;/37089658717;/37089662729;/37275663600;/37089662905;/37089658290;/37089658717",
        "aff": "Graduate School of Natural Science and technology, Okayama University, Japan; Graduate School of Natural Science and technology, Okayama University, Japan; Graduate School of Natural Science and technology, Okayama University, Japan; Graduate School of Natural Science and technology, Okayama University, Japan; Graduate School of Natural Science and technology, Okayama University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982201/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16722315740599272420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Okayama University",
        "aff_unique_dep": "Graduate School of Natural Science and Technology",
        "aff_unique_url": "https://www.okayama-u.ac.jp",
        "aff_unique_abbr": "Okayama U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981454",
        "title": "Automatic Keyframe Detection for Critical Actions from the Experience of Expert Surgeons",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-Assisted Minimally Invasive Surgery (RAMIS), which introduced robot-actuated invasive tools to increase the dexterity and efficiency of traditional MIS, has become popular. Investigations on how to achieve autonomy in RAMIS have drawn vast intention recently, which urges further insights into the process of the surgical procedures. In this paper, the definition of critical actions, which discriminates the essential stages from regular surgical actions, is proposed to help decompose the complicated surgical processes. A critical intra-operative moment of the surgical workflow, which is called the keyframe, is introduced to indicate the beginning or ending moments of the critical actions. A keyframe detection method is proposed for critical action identification based on a new in-vivo dataset labeled by expert surgeons. Surgeons' criteria for critical actions are captured by the explainable features, which can be extracted from the raw laparoscopic images with a two-stage network. Motivated by the surgeon's decision process of keyframes, a hierarchical structure is designed for keyframe identification by checking the spatial-temporal characteristics of the explainable features. Experimental results show that the reliability of the proposed method for keyframe detection achieves unanimous agreement by expert surgeons.",
        "primary_area": "",
        "author": "Jie Zhang;Shenchao Shi;Yiwei Wang;Chidan Wan;Huan Zhao;Xiong Cai;Han Ding;Jie Zhang;Shenchao Shi;Yiwei Wang;Chidan Wan;Huan Zhao;Xiong Cai;Han Ding",
        "authorids": "/37089663828;/37089659604;/37086051271;/37089662254;/37086356398;/37089661772;/37855758100;/37089663828;/37089659604;/37086051271;/37089662254;/37086356398;/37089661772;/37855758100",
        "aff": "State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, Chlna; Department of Hepatobiliary Surgery, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, Chlna; Department of Hepatobiliary Surgery, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, Chlna; Department of Hepatobiliary Surgery, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, Chlna",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981454/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11682555822845368903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "State Key Laboratory of Digital Manufacturing Equipment and Technology",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981552",
        "title": "Automatic Parameter Adaptation for Quadrotor Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Online trajectory planners enable quadrotors to safely and smoothly navigate in unknown cluttered environments. However, tuning parameters is challenging since modern planners have become too complex to mathematically model and predict their interaction with unstructured environments. This work takes humans out of the loop by proposing a planner parameter adaptation framework that formulates objectives into two complementary categories and optimizes them asynchronously. Objectives evaluated with and without trajectory execution are optimized using Bayesian Optimization (BayesOpt) and Particle Swarm Optimization (PSO), respectively. By combining two kinds of objectives, the total convergence rate of the black-box optimization is accelerated while the dimension of optimized parameters can be increased. Benchmark comparisons demonstrate its superior performance over other strategies. Tests with changing obstacle densities validate its real-time environment adaption, which is difficult for prior manual tuning. Real-world flights with different drone platforms, environments, and planners show the proposed framework's scalability and effectiveness.",
        "primary_area": "",
        "author": "Xin Zhou;Chao Xu;Fei Gao;Xin Zhou;Chao Xu;Fei Gao",
        "authorids": "/37088432733;/37404060100;/37086045143;/37088432733;/37404060100;/37086045143",
        "aff": "Huzhou institute of Zhejiang University, Huzhou, China; Huzhou institute of Zhejiang University, Huzhou, China; Huzhou institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981552/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18301898532475458781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981058",
        "title": "Automatic Tuning and Selection of Whole-Body Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing controllers for complex robots such as humanoids is not an easy task. Often, researchers hand-tune controllers, but this is a time-consuming approach that yields a single controller which cannot generalize well to varied tasks. This work presents a method which uses the NSGA-II multi-objective optimization algorithm with various training trajectories to output a diverse Pareto set of well-functioning controller weights and gains. The best of these are shown to also work well on the real Talos robot. The learned Pareto front is then used in a Bayesian optimization (BO) algorithm both as a search space and as a source of prior information in the initial mean estimate. This combined learning approach, leveraging the two optimization methods together, finds a suitable parameter set for a new trajectory within 20 trials and outperforms both BO in the continuous parameter search space and random search along the precomputed Pareto front. The few trials required for this formulation of BO suggest that it could feasibly be applied on the physical robot using a Pareto front generated in simulation.",
        "primary_area": "",
        "author": "Evelyn D'Elia;Jean-Baptiste Mouret;Jens Kober;Serena Ivaldi;Evelyn D'Elia;Jean-Baptiste Mouret;Jens Kober;Serena Ivaldi",
        "authorids": "/37089663560;/37586421200;/37542833400;/38534379600;/37089663560;/37586421200;/37542833400;/38534379600",
        "aff": "Artificial and Mechanical Intelligence Lab, Italian Institute of Technology, Genoa, Italy; Inria, University of Lorraine, CNRS, Loria, Nancy, France; Delft University of Technology, Delft, Netherlands; Inria, University of Lorraine, CNRS, Loria, Nancy, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981058/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18293852956042003757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Italian Institute of Technology;INRIA;Delft University of Technology",
        "aff_unique_dep": "Artificial and Mechanical Intelligence Lab;;",
        "aff_unique_url": "https://www.iit.it;https://www.inria.fr;https://www.tudelft.nl",
        "aff_unique_abbr": "IIT;Inria;TU Delft",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Genoa;;Delft",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "Italy;France;Netherlands"
    },
    {
        "id": "9982176",
        "title": "Automatic laser steering for middle ear surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the control of a laser spot in the context of minimally invasive surgery of the middle ear, e.g., cholesteatoma removal. More precisely, our work is concerned with the exhaustive burring of residual infected cells after primary mechanical resection of the pathological tissues since the latter cannot guarantee the treatment of all the infected tissues, the remaining infected cells cause regeneration of the diseases in 20%-25 % of cases, which require a second surgery 12\u201318 months later. To tackle such a complex surgery, we have developed a robotic platform that consists of the combination of a macro-scale system (7 degrees of freedoms (DoFs) robotic arm) and a micro-scale flexible system (2 DoFs) which operates inside the middle ear cavity. To be able to treat the residual cholesteatoma regions, we proposed a method to generate optimal laser automatically scanning trajectories inside the areas and between them. The trajectories are tacked using an image-based control scheme. The proposed method and materials were validated experimentally using the lab-made robotic platform. The obtained results in terms of accuracy and behaviour meet the laser surgery requirements perfectly.",
        "primary_area": "",
        "author": "Jae-Hun So;J\u00e9r\u00eame Szewczyk;Brahim Tamadazte;Jae-Hun So;J\u00e9r\u00eame Szewczyk;Brahim Tamadazte",
        "authorids": "/37088564418;/37541684100;/37681656800;/37088564418;/37541684100;/37681656800",
        "aff": "CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France; CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France; CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982176/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4711206766736628846&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 18,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981425",
        "title": "Autonomous Control of Redundant Hydraulic Manipulator Using Reinforcement Learning with Action Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents an entirely data-driven approach for autonomous control of redundant manipulators with hydraulic actuation. The approach only requires minimal system information, which is inherited from a simulation model. The non-linear hydraulic actuation dynamics are modeled using actuator networks from the data gathered during the manual operation of the manipulator to effectively emulate the real system in a simulation environment. A neural network control policy for autonomous control, based on end-effector (EE) position tracking is then learned using Reinforcement Learning (RL) with Ornstein-Uhlenbeck process noise (OUNoise) for efficient exploration. The RL agent also receives feedback based on supervised learning of the forward kinematics which facilitates selecting the best suitable action from exploration. The control policy directly provides the joint variables as outputs based on provided target EE position while taking into account the system dynamics. The joint variables are then mapped to the hydraulic valve commands, which are then fed to the system without further modifications. The proposed approach is implemented on a scaled hydraulic forwarder crane with three revolute and one prismatic joint to track the desired position of the EE in 3-Dimensional (3D) space. With the emulated dynamics and extensive learning in simulation, the results demonstrate the feasibility of deploying the learned controller directly on the real system.",
        "primary_area": "",
        "author": "Rohit Dhakate;Christian Brommer;Christoph Bohm;Harald Gietler;Stephan Weiss;Jan Steinbrener;Rohit Dhakate;Christian Brommer;Christoph Bohm;Harald Gietler;Stephan Weiss;Jan Steinbrener",
        "authorids": "/37089512046;/37086574162;/37088521138;/37086041868;/37535323400;/37087049144;/37089512046;/37086574162;/37088521138;/37086041868;/37535323400;/37087049144",
        "aff": "Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Sensors and Actuators Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981425/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1116751468587574287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Department of Smart Systems Technologies",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "Uni Klagenfurt",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Klagenfurt",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9981042",
        "title": "Autonomous Cycle Time Reduction of Robotic Tasks Using Iterative Learning Control",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots are used to automate repetitive production tasks, the productivity of the manufacturing system crucially depends on the robot's task execution speed. An out-of-the-box solution is typically slow, whereas achieving shorter cycle times typically requires large efforts with respect to controller design and tuning. This dilemma can be resolved by learning control algorithms that autonomously improve performance without requiring any system-specific tuning. In the present work, we propose a novel learning control scheme that autonomously reduces the execution times of robotic systems that perform repetitive manufacturing tasks. To this end, we combine an Iterative Learning Control (ILC) approach with a trial-varying reference adaptation. The reference trajectory is slowly adapted to ensure that the given task is performed successfully on every single iteration without constraint violations. Therefore, the learning process can be carried out during operation. We validate the practical applicability of the method by real-world experiments on a 6-axis robot that performs a linear motion and a contact-force task. Despite the fundamentally different characteristics of these two tasks, the proposed algorithm achieves a remarkable reduction of cycle times, namely, by a factor of 4 in the linear motion task and a factor of 10 in the contact-force task. These results provide an important step toward robotic manufacturing systems that autonomously optimize their own performance during operation.",
        "primary_area": "",
        "author": "Lorenz Halt;Michael Meindl;Victor Bayer;Werner Kraus;Thomas Seel;Lorenz Halt;Michael Meindl;Victor Bayer;Werner Kraus;Thomas Seel",
        "authorids": "/37546420100;/37089544070;/37089663212;/37357181400;/37085514508;/37546420100;/37089544070;/37089663212;/37357181400;/37085514508",
        "aff": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Embedded Mechatronics Laboratory, Hochschule Karlsruhe, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Departement Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-Universi\u00e4t Erlangen-N\u00fcrnberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981042/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15557740397624642028&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;Hochschule Karlsruhe;Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg",
        "aff_unique_dep": ";Embedded Mechatronics Laboratory;Departement of Artificial Intelligence in Biomedical Engineering",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.hs-karlsruhe.de;https://www fau.de",
        "aff_unique_abbr": "Fraunhofer IPA;;FAU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stuttgart;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981152",
        "title": "Autonomous Emergency Landing for Multicopters using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Luca Bartolomei;Yves Kompis;Lucas Teixeira;Margarita Chli;Luca Bartolomei;Yves Kompis;Lucas Teixeira;Margarita Chli",
        "authorids": "/37087322350;/37088941680;/37086010655;/37546501900;/37087322350;/37088941680;/37086010655;/37546501900",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981152/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8531874002583739811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9982141",
        "title": "Autonomous Intraluminal Navigation of a Soft Robot using Deep-Learning-based Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation inside luminal organs is an arduous task that requires non-intuitive coordination between the movement of the operator's hand and the information obtained from the endoscopic video. The development of tools to automate certain tasks could alleviate the physical and mental load of doctors during interventions allowing them to focus on diagnosis and decision-making tasks. In this paper we present a synergic solution for intraluminal navigation consisting of a 3D printed endoscopic soft robot that can move safely inside luminal structures. Visual servoing based on Convolutional Neural Networks (CNNs) is used to achieve the autonomous navigation task. The CNN is trained with phantoms and in-vivo data to segment the lumen and a model-less approach is presented to control the movement in constrained environments. The proposed robot is validated in anatomical phantoms in different path configurations. We analyze the movement of the robot using different metrics such as task completion time smoothness error in the steady-state mean and maximum error. We show that our method is suitable to navigate safely in hollow environments and conditions which are different than the ones the network was originally trained on.",
        "primary_area": "",
        "author": "Jorge F. Lazo;Chun-Feng Lai;Sara Moccia;Benoit Rosa;Michele Catellani;Michel de Mathelin;Giancarlo Ferrigno;Paul Breedveld;Jenny Dankelman;Elena De Momi;Jorge F. Lazo;Chun-Feng Lai;Sara Moccia;Benoit Rosa;Michele Catellani;Michel de Mathelin;Giancarlo Ferrigno;Paul Breedveld;Jenny Dankelman;Elena De Momi",
        "authorids": "/37088854941;/37089417881;/37085884204;/38542454300;/37088854858;/37283578000;/37294130300;/37565161500;/37402716500;/37947344300;/37088854941;/37089417881;/37085884204;/38542454300;/37088854858;/37283578000;/37294130300;/37565161500;/37402716500;/37947344300",
        "aff": "ICube, UMR 7357, CNRS-Universite de Strasbourg, Strasbourg, France; Delft University of Technology, Delft, Netherlands; The Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy; ICube, UMR 7357, CNRS-Universite de Strasbourg, Strasbourg, France; ICube, UMR 7357, CNRS-Universite de Strasbourg, Strasbourg, France; European Institute of Oncology (IRCCS), Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982141/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7369243947096142588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;2;0;0;3;4;1;1;4",
        "aff_unique_norm": "Universite de Strasbourg;Delft University of Technology;Scuola Superiore Sant'Anna;European Institute of Oncology;Politecnico di Milano",
        "aff_unique_dep": "ICube;;Department of Excellence in Robotics and AI;;Department of Electronics, Information and Bioengineering",
        "aff_unique_url": "https://www.unistra.fr;https://www.tudelft.nl;https://www.sssup.it;https://www.ieo.eu;https://www.polimi.it",
        "aff_unique_abbr": ";TU Delft;SSSA;IEO;Politecnico di Milano",
        "aff_campus_unique_index": "0;1;2;0;0;3;3;1;1;3",
        "aff_campus_unique": "Strasbourg;Delft;Pisa;Milan",
        "aff_country_unique_index": "0;1;2;0;0;2;2;1;1;2",
        "aff_country_unique": "France;Netherlands;Italy"
    },
    {
        "id": "9982274",
        "title": "Autonomous Mobile 3D Printing of Large-Scale Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile 3D Printing (M3DP), using printing-in-motion, is a powerful paradigm for automated construction. A mobile robot, equipped with its own power, materials and an arm-mounted extruder, simultaneously navigates and creates its environment. Such systems can be highly scalable, parallelizable and flexible. However, planning and controlling the motion of the arm and base at the same time is challenging and most deployments either avoid robot-base motion entirely or use human prescribed robot-base paths. In a previous paper, we developed a high-level planning algorithm to automate M3DP given a print task. The generated robot-base paths avoid collisions and maintain task reachability. In this paper, we extend this work to robot control. We develop and compare three different ways to integrate the long-duration planned path with a short horizon Model Predictive Controller. Experiments are carried out via a new M3DP system - Armstone. We evaluate and demonstrate our algorithm in a 250 m long multi-layer print which is about 5 times longer than any previous physical printing-in-motion system.",
        "primary_area": "",
        "author": "Julius Sustarevas;Dimitrios Kanoulas;Simon Julier;Julius Sustarevas;Dimitrios Kanoulas;Simon Julier",
        "authorids": "/37086578524;/38230575500;/37264968900;/37086578524;/38230575500;/37264968900",
        "aff": "Department of Computer Science, University College London, Gower Street, UK; Department of Computer Science, University College London, Gower Street, UK; Department of Computer Science, University College London, Gower Street, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982274/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=65410949898064390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gower Street",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981114",
        "title": "Autonomous Pipeline Tracking Using Bernoulli Filter for Unmanned Underwater Surveys",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspection of subsea pipelines is crucial for avoiding any hazards and minimizing the risks to infrastructure and the environment. These inspections are achieved using Autonomous Underwater Vehicles (AUVs) in favour of reduced operational costs. This work presents a vehicle agnostic approach for tracking subsea pipelines at close-range for autonomous guidance along the pipeline using an AUV. A multibeam echosounder is used as the primary tracking sensor augmented by fluxgate magnetometers that can track buried pipelines over short ranges until they are exposed again. A Bernoulli filter is proposed to efficiently track pipelines in presence of environmental clutter. Field experiments were carried out in a dock and at sea to evaluate the proposed system and the benefits of using a Bernoulli filter over a Kalman filter-based solution.",
        "primary_area": "",
        "author": "Vibhav Bharti;Sen Wang;Vibhav Bharti;Sen Wang",
        "authorids": "/37086011869;/37086278300;/37086011869;/37086278300",
        "aff": "Edinbugh Centre for Robotics, School of Engineering and Physical Sciences, Heriot-Watt University, UK; Edinbugh Centre for Robotics, School of Engineering and Physical Sciences, Heriot-Watt University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981114/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14570823942391376781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "School of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981929",
        "title": "Autonomous Quadrotor Landing on Inclined Surfaces in High Particle Environments Using Radar Sensor Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an autonomous approach for landing a quadrotor on inclined surfaces up to 40 degrees using radar perception in a high particle environment, such as dust, rain, or fog. This system uses five radar sensors to determine the direction, angle, and smoothness of a slope through eigenvalue decomposition of a point cloud covariance matrix. The point cloud itself is generated using a FIFO queue with the radar sensors after their points are transformed to a common frame. Then, two asymmetric landing skids of different lengths actively conform to a slope in order to maintain level body attitude upon landing. For perception error tolerance, a study to understand the distance between the propeller and slope surface with respect to slope angles was developed. We evaluate the accuracy and consistency of radar sensors in accomplishing these tasks, to include a comparison of the results with a depth camera while in a high particle environment. Finally, the experimental result shows that the detected slope angle and direction were within 2.2 and 2.4 degrees of ground, and the proposed system is viable and robust for use in real-world applications.",
        "primary_area": "",
        "author": "Mark C. Lesak;Dylan Taylor;Jinho Kim;Christopher Korpela;Mark C. Lesak;Dylan Taylor;Jinho Kim;Christopher Korpela",
        "authorids": "/37088689702;/37088940532;/37088917492;/37680206300;/37088689702;/37088940532;/37088917492;/37680206300",
        "aff": "Army Cyber Institute, the United States Military Academy, West Point, NY, USA; Department of Electrical Engineering and Computer Science, Robotics Research Center, The United States Military Academy, West Point, NY, USA; Department of Electrical Engineering and Computer Science, Robotics Research Center, The United States Military Academy, West Point, NY, USA; Department of Electrical Engineering and Computer Science, Robotics Research Center, The United States Military Academy, West Point, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981929/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Mljmbji8040J:scholar.google.com/&scioq=Autonomous+Quadrotor+Landing+on+Inclined+Surfaces+in+High+Particle+Environments+Using+Radar+Sensor+Perception&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "United States Military Academy",
        "aff_unique_dep": "Army Cyber Institute",
        "aff_unique_url": "https://www.usma.edu/",
        "aff_unique_abbr": "USMA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "West Point",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981268",
        "title": "Avoiding Dynamic Obstacles with Real-time Motion Planning using Quadratic Programming for Varied Locomotion Modes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a real-time motion planner that avoids multiple moving obstacles without knowing their dynamics or intentions. This method uses convex optimization to generate trajectories for linear plant models over a planning horizon (i.e. model-predictive control). While convex optimizations allow for fast planning, obstacle avoidance can be challenging to incorporate because Euclidean distance calculations tend to break convexity. By using a half-space convex relaxation, our planner reasons about an approximated distance-to-obstacle measure that is linear in its decision variables and preserves convexity. Further, by iteratively updating the relaxation over the planning horizon, the half-space approximation is improved, enabling nimble avoidance maneuvers. We further augment avoidance performance with a soft penalty slack-variable for-mulation that introduces a piecewise quadratic cost. As a proof of concept, we demonstrate the planner on double-integrator models in both single-agent and multi-agent tasks-avoiding multiple obstacles and other agents in 2D and 3D environments. We show extensions to legged locomotion by bipedally walking around obstacles in simulation using the Linear Inverted Pendulum Model (LIPM). We then present two sets of hardware experiments showing real-time obstacle avoid-ance with quadcopter drones: (1) avoiding a 10m/s swinging pendulum and (2) dodging a chasing drone.",
        "primary_area": "",
        "author": "Jason White;David Jay;Tianze Wang;Christian Hubicki;Jason White;David Jay;Tianze Wang;Christian Hubicki",
        "authorids": "/37088506782;/37089450928;/37089660957;/37085380316;/37088506782;/37089450928;/37089660957;/37085380316",
        "aff": "Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981268/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16033871409071272744&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Florida State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.fsu.edu",
        "aff_unique_abbr": "FSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981258",
        "title": "BEV-SLAM: Building a Globally-Consistent World Map Using Monocular Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to produce large-scale maps for nav-igation, path planning and other tasks is a crucial step for autonomous agents, but has always been challenging. In this work, we introduce BEV-SLAM, a novel type of graph-based SLAM that aligns semantically-segmented Bird's Eye View (BEV) predictions from monocular cameras. We introduce a novel form of occlusion reasoning into BEV estimation and demonstrate its importance to aid spatial aggregation of BEV predictions. The result is a versatile SLAM system that can operate across arbitrary multi-camera configurations and can be seamlessly integrated with other sensors. We show that the use of multiple cameras significantly increases performance, and achieves lower relative error than high-performance GPS. The resulting system is able to create large, dense, globally-consistent world maps from monocular cameras mounted around an ego vehicle. The maps are metric and correctly-scaled, making them suitable for downstream navigation tasks.",
        "primary_area": "",
        "author": "James Ross;Oscar Mendez;Avishkar Saha;Mark Johnson;Richard Bowden;James Ross;Oscar Mendez;Avishkar Saha;Mark Johnson;Richard Bowden",
        "authorids": "/37089658485;/37710939600;/37089002033;/37089000738;/37268872100;/37089658485;/37710939600;/37089002033;/37089000738;/37268872100",
        "aff": "Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981258/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6389880845748084297&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Vision, Speech and Signal Processing",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guildford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981250",
        "title": "BIMRL: Brain Inspired Meta Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sample efficiency has been a key issue in reinforcement learning (RL). An efficient agent must be able to leverage its prior experiences to quickly adapt to similar, but new tasks and situations. Meta-RL is one attempt at formalizing and ad-dressing this issue. Inspired by recent progress in meta-RL, we introduce BIMRL, a novel multi-layer architecture along with a novel brain-inspired memory module that will help agents quickly adapt to new tasks within a few episodes. We also utilize this memory module to design a novel intrinsic reward that will guide the agent's exploration. Our architecture is inspired by findings in cognitive neuroscience and is compatible with the knowledge on connectivity and functionality of different regions in the brain. We empirically validate the effectiveness of our proposed method by competing with or surpassing the performance of some strong baselines on multiple MiniGrid environments.",
        "primary_area": "",
        "author": "Seyed Roozbeh Razavi Rohani;Saeed Hedayatian;Mahdieh Soleymani Baghshah;Seyed Roozbeh Razavi Rohani;Saeed Hedayatian;Mahdieh Soleymani Baghshah",
        "authorids": "/37089658854;/37089658927;/37831839400;/37089658854;/37089658927;/37831839400",
        "aff": "Department of Computer Engineering, Sharif University of Technology; Department of Mathematical Sciences, Sharif University of Technology; Department of Computer Engineering, Sharif University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981250/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6577642345258393327&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sharif University of Technology",
        "aff_unique_dep": "Department of Computer Engineering",
        "aff_unique_url": "https://www.sharif.edu",
        "aff_unique_abbr": "Sharif UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Iran"
    },
    {
        "id": "9981732",
        "title": "BITKOMO: Combining Sampling and Optimization for Fast Convergence in Optimal Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimal sampling based motion planning and trajectory optimization are two competing frameworks to generate optimal motion plans. Both frameworks have complementary properties: Sampling based planners are typically slow to converge, but provide optimality guarantees. Trajectory optimizers, however, are typically fast to converge, but do not provide global optimality guarantees in nonconvex problems, e.g. scenarios with obstacles. To achieve the best of both worlds, we introduce a new planner, BITKOMO, which integrates the asymptotically optimal Batch Informed Trees (BIT*) planner with the K-Order Markov Optimization (KOMO) trajectory optimization framework. Our planner is anytime and maintains the same asymptotic optimality guarantees provided by BIT*, while also exploiting the fast convergence of the KOMO trajectory optimizer. We experimentally evaluate our planner on manipulation scenarios that involve high dimensional configuration spaces, with up to two 7-DoF manipulators, obstacles and narrow passages. BITKOMO performs better than KOMO by succeeding even when KOMO fails, and it outperforms BIT* in terms of convergence to the optimal solution.",
        "primary_area": "",
        "author": "Jay Kamat;Joaquim Ortiz-Haro;Marc Toussaint;Florian T. Pokorny;Andreas Orthey;Jay Kamat;Joaquim Ortiz-Haro;Marc Toussaint;Florian T. Pokorny;Andreas Orthey",
        "authorids": "/37089025857;/37088998356;/37528418600;/37077268000;/37077150400;/37089025857;/37088998356;/37528418600;/37077268000;/37077150400",
        "aff": "BITS Pilani, India; Learning & Intelligent Systems Lab, TU Berlin, Germany; Learning & Intelligent Systems Lab, TU Berlin, Germany; RPL, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Learning & Intelligent Systems Lab, TU Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981732/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11514913336015862196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Birla Institute of Technology and Science;Technische Universit\u00e4t Berlin;KTH Royal Institute of Technology",
        "aff_unique_dep": ";Learning & Intelligent Systems Lab;EECS",
        "aff_unique_url": "https://www.bits-pilani.ac.in;https://www.tu-berlin.de;https://www.kth.se",
        "aff_unique_abbr": "BITS Pilani;TU Berlin;KTH",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Pilani;Berlin;Stockholm",
        "aff_country_unique_index": "0;1;1;2;1",
        "aff_country_unique": "India;Germany;Sweden"
    },
    {
        "id": "9981135",
        "title": "BOBCAT: Behaviors, Objectives and Binary states for Coordinated Autonomous Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present our framework Behaviors, Objectives and Binary states for Coordinated Autonomous Tasks (BOBCAT), a multi-agent decision making and task management system for autonomous robots. BOBCAT builds on behavior-based systems and the Belief-Desire-Intention model for decision-making, by using mission objectives as the basis for selecting tasks, or behaviors. We describe how BOBCAT is formulated and present the results of a real-world implementation in the context of exploring austere underground environments in the DARPA Subterranean Challenge.",
        "primary_area": "",
        "author": "Danny G. Riley;Eric W. Frew;Danny G. Riley;Eric W. Frew",
        "authorids": "/37088503826;/37268793800;/37088503826;/37268793800",
        "aff": "Department of Computer Science, University of Colorado Boulder, CO; Smead Department of Aerospace Engineering Sciences, University of Colorado Boulder, CO",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981135/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7195124778605234465&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982015",
        "title": "BOEM-SLAM: A Block Online EM Algorithm for the Visual-Inertial SLAM Backend",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present BOEM-SLAM, a backend for visual-inertial SLAM systems capable of creating a globally consistent trajectory and map without retaining the entire history of data. By leveraging the hidden Markov model structure, BOEM-SLAM can summarize historical data into sufficient statistics and then discard it. As a data-efficient algorithm, BOEM-SLAM addresses the growing computational costs and storage requirements of the SLAM backend. To demonstrate the performance of our algorithm we compare BOEM-SLAM to other fundamental approaches on both synthetic data and the EuRoC dataset. For evaluation on the EuRoC dataset, we use the open source okvis frontend and apply the Lie group state space representation and visual outlier removal. Overall, BOEM-SLAM shows a considerably lower computation time with comparable estimation performance. For example, the processing time of BOEM-SLAM is 50 times smaller than the optimization-based method using simulated data and 5 times smaller than the optimization-based method in the EuRoC dataset experiments.",
        "primary_area": "",
        "author": "Tsang-Kai Chang;Alexandra Pogue;Ankur Mehta;Tsang-Kai Chang;Alexandra Pogue;Ankur Mehta",
        "authorids": "/37086302387;/37085443001;/37086302574;/37086302387;/37085443001;/37086302574",
        "aff": "Electrical and Computer Engineering Department, University of California Los Angeles, Los Angeles, CA, USA; Mechanical Engineering Department, University of California Los Angeles; Electrical and Computer Engineering Department, University of California Los Angeles, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982015/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5748882980515090399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981928",
        "title": "BSA - Bi-Stiffness Actuation for optimally exploiting intrinsic compliance and inertial coupling effects in elastic joint robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Compliance in actuation has been exploited to generate highly dynamic maneuvers such as throwing that take advantage of the potential energy stored in joint springs. However, the energy storage and release could not be well-timed yet. On the contrary, for multi-link systems, the natural system dynamics might even work against the actual goal. With the introduction of variable stiffness actuators, this problem has been partially addressed. With a suitable optimal control strategy, the approximate decoupling of the motor from the link can be achieved to maximize the energy transfer into the distal link prior to launch. However, such continuous stiffness variation is complex and typically leads to oscillatory swing-up motions instead of clear launch sequences. To circumvent this issue, we investigate decoupling for speed maximization with a dedicated novel actuator concept denoted Bi-Stiffness Actuation. With this, it is possible to fully decouple the link from the joint mechanism by a switch-and-hold clutch and simultaneously keep the elastic energy stored. We show that with this novel paradigm, it is not only possible to reach the same optimal performance as with power-equivalent variable stiffness actuation, but even directly control the energy transfer timing. This is a major step forward compared to previous optimal control approaches, which rely on optimizing the full time-series control input.",
        "primary_area": "",
        "author": "Dennis Ossadnik;Mehmet C. Yildirim;Fan Wu;Abdalla Swikir;Hugo T. M. Kussaba;Saeed Abdolshah;Sami Haddadin;Dennis Ossadnik;Mehmet C. Yildirim;Fan Wu;Abdalla Swikir;Hugo T. M. Kussaba;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37086601649;/37085627474;/37086454850;/37085861833;/37712480000;/37086148547;/37542865300;/37086601649;/37085627474;/37086454850;/37085861833;/37712480000;/37086148547;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany; Department of Electrical and Electronic Engineering, Omar Al-Mukhtar University (OMU), Albaida, Libya; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981928/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5089555110208374551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Technical University of Munich;Omar Al-Mukhtar University",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.tum.de;",
        "aff_unique_abbr": "TUM;OMU",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Munich;Albaida",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "Germany;Libya"
    },
    {
        "id": "9981315",
        "title": "Back to the Manifold: Recovering from Out-of-Distribution States",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from previously collected datasets of expert data offers the promise of acquiring robotic policies without unsafe and costly online explorations. However, a major challenge is a distributional shift between the states in the training dataset and the ones visited by the learned policy at the test time. While prior works mainly studied the distribution shift caused by the policy during the offline training, the problem of recovering from out-of-distribution states at the deployment time is not very well studied yet. We alleviate the distributional shift at the deployment time by introducing a recovery policy that brings the agent back to the training manifold whenever it steps out of the in-distribution states, e.g., due to an external perturbation. The recovery policy relies on an approximation of the training data density and a learned equivariant mapping that maps visual observations into a latent space in which translations correspond to the robot actions. We demonstrate the effectiveness of the proposed method through several manipulation experiments on a real robotic platform. Our results show that the recovery policy enables the agent to complete tasks while the behavioral cloning alone fails because of the distributional shift problem.",
        "primary_area": "",
        "author": "Alfredo Reichlin;Giovanni Luca Marchetti;Hang Yin;Ali Ghadirzadeh;Danica Kragic;Alfredo Reichlin;Giovanni Luca Marchetti;Hang Yin;Ali Ghadirzadeh;Danica Kragic",
        "authorids": "/37089663394;/37089228949;/37088353838;/37085340524;/37281296000;/37089663394;/37089228949;/37088353838;/37085340524;/37281296000",
        "aff": "KTH Royal Institute of Technology; KTH Royal Institute of Technology; KTH Royal Institute of Technology; Stanford University; KTH Royal Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981315/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=266153025588046579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kth.se;https://www.stanford.edu",
        "aff_unique_abbr": "KTH;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "9981869",
        "title": "Backward Imitation and Forward Reinforcement Learning via Bi-directional Model Rollouts",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional model-based reinforcement learning (RL) methods generate forward rollout traces using the learnt dynamics model to reduce interactions with the real environment. The recent model-based RL method considers the way to learn a backward model that specifies the conditional probability of the previous state given the previous action and the current state to additionally generate backward rollout trajectories. However, in this type of model-based method, the samples derived from backward rollouts and those from forward rollouts are simply aggregated together to optimize the policy via the model-free RL algorithm, which may decrease both the sample efficiency and the convergence rate. This is because such an approach ignores the fact that backward rollout traces are often generated starting from some high-value states and are certainly more instructive for the agent to improve the behavior. In this paper, we propose the backward imitation and forward reinforcement learning (BIFRL) framework where the agent treats backward rollout traces as expert demonstrations for the imitation of excellent behaviors, and then collects forward rollout transitions for policy reinforcement. Consequently, BIFRL empowers the agent to both reach to and explore from high-value states in a more efficient manner, and further reduces the real interactions, making it potentially more suitable for real-robot learning. Moreover, a value-regularized generative adversarial network is introduced to augment the valuable states which are infrequently received by the agent. Theoretically, we provide the condition where BIFRL is superior to the baseline methods. Experimentally, we demonstrate that BIFRL acquires the better sample efficiency and produces the competitive asymptotic performance on various MuJoCo locomotion tasks compared against state-of-the-art model-based methods.",
        "primary_area": "",
        "author": "Yuxin Pan;Fangzhen Lin;Yuxin Pan;Fangzhen Lin",
        "authorids": "/37086598743;/37086524302;/37086598743;/37086524302",
        "aff": "Division of Emerging Interdisciplinary Areas under IPO, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981869/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7835699748066534907&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Division of Emerging Interdisciplinary Areas under IPO",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981432",
        "title": "Balancing Control and Pose Optimization for wheel-legged Robots Navigating High Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel approach to controlling wheel-legged quadrupedal robots using pose optimization and force-based control via quadratic programming (QP). Our method allows the robot to leverage the whole-body motion and the wheel actuation to roll over high obstacles while keeping wheel traction with the terrain. In detail, we first present linear rigid body dynamics with wheels that can be used for real-time balancing control of wheel-legged robots. We then introduce an effective pose optimization method for wheel-legged robot's locomotion over steep ramp and stair terrains. The pose optimization solves for optimal poses to enhance stability and enforce collision-free constraints at critical pose locations for rolling over high obstacles. Experimental validation of the real robot demonstrated the capability of rolling up on a 0.36 m obstacle. The robot can also successfully roll up and down multiple stairs without lifting its legs or colliding with the terrain.",
        "primary_area": "",
        "author": "Junheng Li;Junchao Ma;Quan Nguyen;Junheng Li;Junchao Ma;Quan Nguyen",
        "authorids": "/37089279082;/37089662175;/37085362091;/37089279082;/37089662175;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981432/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13539711438355183668&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982175",
        "title": "Bayesian Active Learning for Sim-to-Real Robotic Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "While learning from synthetic training data has recently gained an increased attention, in real-world robotic applications, there are still performance deficiencies due to the so-called Sim-to-Real gap. In practice, this gap is hard to resolve with only synthetic data. Therefore, we focus on an efficient acquisition of real data within a Sim-to-Real learning pipeline. Concretely, we employ deep Bayesian active learning to minimize manual annotation efforts and devise an autonomous learning paradigm to select the data that is considered useful for the human expert to annotate. To achieve this, a Bayesian Neural Network (BNN) object detector providing reliable un-certainty estimates is adapted to infer the informativeness of the unlabeled data. Furthermore, to cope with misalignments of the label distribution in uncertainty-based sampling, we develop an effective randomized sampling strategy that performs favorably compared to other complex alternatives. In our experiments on object classification and detection, we show benefits of our approach and provide evidence that labeling efforts can be reduced significantly. Finally, we demonstrate the practical effectiveness of this idea in a grasping task on an assistive robot.",
        "primary_area": "",
        "author": "Jianxiang Feng;Jongseok Lee;Maximilian Durner;Rudolph Triebel;Jianxiang Feng;Jongseok Lee;Maximilian Durner;Rudolph Triebel",
        "authorids": "/37089659329;/37086580791;/37086116487;/37542908700;/37089659329;/37086580791;/37086116487;/37542908700",
        "aff": "Technical University of Munich (TUM), Munich, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Technical University of Munich (TUM), Munich, Germany; Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982175/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11767573259738098925&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Technical University of Munich;German Aerospace Center",
        "aff_unique_dep": ";Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tum.de;https://www.dlr.de",
        "aff_unique_abbr": "TUM;DLR",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Munich;Wessling",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981774",
        "title": "Behavior-Tree Embeddings for Robot Task-Level Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the behavior tree is gaining popularity as a robotic task-level knowledge representation. Manual design of behavior trees from scratch is tedious and cumbersome. Motivated by the need for an efficient way to reuse or transfer robot task-level knowledge, we propose a vector-space embedding approach that encodes a symbolic task into a numerical form. This approach, called behavior-tree embedding, takes a behavior tree that produces a single task as input and generates a corresponding vector. By exploiting the pretrained language-embedding model and the node-aggregation mechanism, the produced embedding is capable of preserving both semantic information of task description and structural information of the hierarchical task organization. We evaluated the effectiveness and versatility of our proposed vector-space embedding approach in three different tasks.",
        "primary_area": "",
        "author": "Yue Cao;C.S. George Lee;Yue Cao;C.S. George Lee",
        "authorids": "/37089660678;/37292819200;/37089660678;/37292819200",
        "aff": "Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, U.S.A; Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981774/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10428821539395646461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Elmore Family School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981588",
        "title": "Behaviour Learning with Adaptive Motif Discovery and Interacting Multiple Model",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach that enables simultaneous interpretable learning of a high-level discrete behaviour and its low-level rhythmic sub-behaviour. We do this though a unified reward function, where a reward function that only describes low-level behaviour, with less impact on learning of other behaviours is recovered from few-shot motion demonstrations. To this end, we first extract local behaviour motifs from state-only human demonstrations and random driving samples using an adaptive motif discovery approach derived from the Matrix Profile algorithm. We then optimize parameters for motif discovery by maximizing the sum and entropy over motif sizes. Interacting Multiple Model (IMM) estimators are constructed on top of linear-Gaussian dynamics of discovered motifs, the cumulative distributions over motifs estimated by IMMs serve as the basis of the reward function. By combining the recovered reward with the terrain type signal gathered from the environment, we are able to train a dual-objective off-road vehicle controller that demonstrates both terrain selection and human-like driving behaviours. Compared with related approaches across 10 people, our rhythmic behaviour reward recovery approach enables the controller to produce higher preference over human driving demonstrations. In addition to performing more stable across different people with 87% less variance than the best baseline in rhythmic behaviour indicator, our method reduces the negative effects on higher-level behaviour learning while maintaining high interpretability at all stages of the algorithm.",
        "primary_area": "",
        "author": "Hanging Zhao;Travis Manderson;Hao Zhang;Xue Liu;Gregory Dudek;Hanging Zhao;Travis Manderson;Hao Zhang;Xue Liu;Gregory Dudek",
        "authorids": "/37089659405;/38491501400;/37089660751;/37292951400;/37274057100;/37089659405;/38491501400;/37089660751;/37292951400;/37274057100",
        "aff": "School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada; Dept. of Electronic Engineering, Tsinghua University, Beijing, China; School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981588/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15517665070879077289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "McGill University;Tsinghua University",
        "aff_unique_dep": "School of Computer Science;Dept. of Electronic Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "McGill;THU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Montreal;Beijing",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "9981743",
        "title": "Benchmarking Augmentation Methods for Learning Robust Navigation Agents: the Winning Entry of the 2021 iGibson Challenge",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in deep reinforcement learning and scalable photorealistic simulation have led to increasingly mature embodied AI for various visual tasks, including navigation. However, while impressive progress has been made for teaching embodied agents to navigate static environments, much less progress has been made on more dynamic environments that may include moving pedestrians or movable obstacles. In this study, we aim to benchmark different augmentation techniques for improving the agent's performance in these challenging environments. We show that adding several dynamic obstacles into the scene during training confers significant improvements in test-time generalization, achieving much higher success rates than baseline agents. We find that this approach can also be combined with image augmentation methods to achieve even higher success rates. Additionally, we show that this approach is also more robust to sim-to-sim transfer than image augmentation methods. Finally, we demonstrate the effectiveness of this dynamic obstacle augmentation approach by using it to train an agent for the 2021 iGibson Challenge at CVPR, where it achieved 1st place for Interactive Navigation.",
        "primary_area": "",
        "author": "Naoki Yokoyama;Qian Luo;Dhruv Batra;Sehoon Ha;Naoki Yokoyama;Qian Luo;Dhruv Batra;Sehoon Ha",
        "authorids": "/37089657541;/37089000136;/37294512800;/37086314268;/37089657541;/37089000136;/37294512800;/37086314268",
        "aff": "College of Electrical Engineering and College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; College of Electrical Engineering and College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; DB is with Facebook AI Research (FAIR). The Georgia Tech effort was supported in part by NSF, DARPA, ONR YIP, and ARO PECASE; College of Electrical Engineering and College of Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981743/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=870628610879522818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Meta",
        "aff_unique_dep": "College of Electrical Engineering;Facebook AI Research",
        "aff_unique_url": "https://www.gatech.edu;https://research.facebook.com",
        "aff_unique_abbr": "Georgia Tech;FAIR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982139",
        "title": "Beyond mAP: Towards practical object detection for weed spraying in precision agriculture",
        "track": "main",
        "status": "Poster",
        "abstract": "The evolution of smaller and more powerful GPUs over the last 2 decades has vastly increased the opportunity to apply robust deep learning-based machine vision approaches to real-time use cases in practical environments. One exciting application domain for such technologies is precision agriculture, where the ability to integrate on-board machine vision with data-driven actuation means that farmers can make decisions about crop care and harvesting at the level of the individual plant rather than the whole field. This makes sense both economically and environmentally. This paper assesses the feasibility of precision spraying weeds via a comprehensive evaluation of weed detection accuracy and speed using two separate datasets, two types of GPU, and several state-of-the-art object detection algorithms. A simplified model of precision spraying is used to determine whether the weed detection accuracy achieved could result in a sufficiently high weed hit rate combined with a significant reduction in herbicide usage. The paper introduces two metrics to capture these aspects of the real-world deployment of precision weeding and demonstrates their utility through experimental results.",
        "primary_area": "",
        "author": "Adrian Salazar-Gomez;Madeleine Darbyshire;Junfeng Gao;Elizabeth I Sklar;Simon Parsons;Adrian Salazar-Gomez;Madeleine Darbyshire;Junfeng Gao;Elizabeth I Sklar;Simon Parsons",
        "authorids": "/37089447058;/37089658296;/37089579402;/37284979400;/37285102400;/37089447058;/37089658296;/37089579402;/37284979400;/37285102400",
        "aff": "Lincoln Centre for Autonomous Systems, University of Lincoln, UK; Lincoln Centre for Autonomous Systems, University of Lincoln, UK; Lincoln Centre for Autonomous Systems, University of Lincoln, UK; Lincoln Centre for Autonomous Systems, University of Lincoln, UK; Lincoln Centre for Autonomous Systems, University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982139/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8601252826550267949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "Lincoln Centre for Autonomous Systems",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981708",
        "title": "Beyond the Limit Automated Driving with Performance Constrained Reachability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Professional human drivers usually have more than one driving strategy to handle incoming traffic situations. These different strategies activate different performance characteristics of the vehicle, enabling the driver to minimize the risk in a variety of situations by optimizing the strategy selection. In the same spirit, we define a novel concept of strategy-wise performance metric and creatively combine this performance metric with reachability analysis to evaluate candidate control strategies. Such a performance evaluation produces solid guarantees on which strategies will not qualify for the given traffic scenario. Then we automate the strategy selection process by weighing and minimizing the overall risk of each strategy candidate.",
        "primary_area": "",
        "author": "Tong Zhao;Ekim Yurtsever;Giorgio Rizzoni;Tong Zhao;Ekim Yurtsever;Giorgio Rizzoni",
        "authorids": "/37086594379;/37085640372;/37298200300;/37086594379;/37085640372;/37298200300",
        "aff": "Department of Mechanical and Aerospace Engineering, The Ohio State University, Columbus, OH, USA; Center for Automotive Research, The Ohio State University, Columbus, OH, USA; Department of Mechanical and Aerospace Engineering, The Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981708/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2246995983029990522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981567",
        "title": "Bilateral Knowledge Distillation for Unsupervised Domain Adaptation of Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation (UDA) aims to learn domain-invariant representations between the labeled source domain and the unlabeled target domain. Existing self- training-based UDA methods use ground truth and pseudo- labels to supervise source data and target data respectively. However, strong supervision in the source domain and pseudo- label noise in the target domain lead to some problems, such as biased predictions and over-fitting. To tackle these issues, we propose a novel Bilateral Knowledge Distillation (BKD) framework for UDA in semantic segmentation, which adopts different knowledge distillation strategies depending on the domain. Specifically, we first introduce a Source-Flow Distillation (SD) to smooth the labels of source images, which weakens the supervision in the source domain. Meanwhile, a Target-Flow Distillation (TD) is designed to extract the inter- class knowledge in the probability map output from the teacher model, which alleviates the influence of pseudo-label noise in the target domain. Considering the class imbalance in semantic segmentation, we further propose an Image-Wise Hard Pixel Mining (HPM) to address this issue without estimating class frequency in the unlabeled target domain. The effectiveness of our framework against existing state-of-the-art methods is demonstrated by extensive experiments on two benchmarks: GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes.",
        "primary_area": "",
        "author": "Yunnan Wang;Jianxun Li;Yunnan Wang;Jianxun Li",
        "authorids": "/37088987523;/37336334200;/37088987523;/37336334200",
        "aff": "Department of Automation, Shanghai Jiao Tong University, China; Department of Automation, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981567/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8141703915071760336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981819",
        "title": "Bio-Inspired Grasping Controller for Sensorized 2-DoF Grippers",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a holistic grasping controller, combining free-space position control and in-contact force-control for reliable grasping given uncertain object pose estimates. Employing tactile fingertip sensors, undesired object displacement during grasping is minimized by pausing the finger closing motion for individual joints on first contact until force-closure is established. While holding an object, the controller is compliant with external forces to avoid high internal object forces and prevent object damage. Gravity as an external force is explicitly considered and compensated for, thus preventing gravity-induced object drift. We evaluate the controller in two experiments on the TIAGo robot and its parallel-jaw gripper proving the effectiveness of the approach for robust grasping and minimizing object displacement. In a series of ablation studies, we demonstrate the utility of the individual controller components.",
        "primary_area": "",
        "author": "Luca Lach;S\u00e9verin Lemaignan;Francesco Ferro;Helge Ritter;Robert Haschke;Luca Lach;S\u00e9verin Lemaignan;Francesco Ferro;Helge Ritter;Robert Haschke",
        "authorids": "/37089658145;/38482927400;/37659768500;/37266153900;/37565751900;/37089658145;/38482927400;/37659768500;/37266153900;/37565751900",
        "aff": "Neuroinformatics Group, Bielefeld University, Bielefeld, Germany; PAL Robotics, Barcelona, Spain; PAL Robotics, Barcelona, Spain; Neuroinformatics Group, Bielefeld University, Bielefeld, Germany; Neuroinformatics Group, Bielefeld University, Bielefeld, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981819/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7116027003208289505&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Bielefeld University;PAL Robotics",
        "aff_unique_dep": "Neuroinformatics Group;",
        "aff_unique_url": "https://www.uni-bielefeld.de;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Bielefeld;Barcelona",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Germany;Spain"
    },
    {
        "id": "9981088",
        "title": "Bio-inspired 2D Vertical Climbing with a Novel Tripedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Climbing robots have the potential to revolutionize the maintenance and inspection operations of many types of vertical structures. In nature, parrots exhibit a remarkable capacity for manipulation during climbing behaviors, for which robotics can benefit from studying. In this paper we present a novel tripedal robot that is inspired by the morphology of these impressive birds, which use their legs and beak in a tripedal fashion when climbing. We propose several foot placement, trajectory generation, and control methods for this system along with performance evaluation in simulation. A video of select simulations and live bird data is included in the supplementary material, and can also be found at https://youtu.be/vRVGralyQgQ.",
        "primary_area": "",
        "author": "Clyde Webster;Felix H. Kong;Robert Fitch;Clyde Webster;Felix H. Kong;Robert Fitch",
        "authorids": "/37089479816;/37088545936;/38466367800;/37089479816;/37088545936;/38466367800",
        "aff": "Faculty of Engineering and Information Technology, School of Mechanical and Mechatronic Engineering, University of Technology Sydney, Sydney, NSW, Australia; Faculty of Engineering and Information Technology, School of Mechanical and Mechatronic Engineering, University of Technology Sydney, Sydney, NSW, Australia; Faculty of Engineering and Information Technology, School of Mechanical and Mechatronic Engineering, University of Technology Sydney, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981088/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15423219503256266180&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "School of Mechanical and Mechatronic Engineering",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981310",
        "title": "Bio-inspired Reflex System for Learning Visual Information for Resilient Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans have an incredible sense of self-preservation that is both instilled, and also learned through experience. One system which contributes to this is the pain and reflex system which both minimizes damage through involuntary reflex actions and also serves as a means of 'negative reinforcement\u2019 to allow learning of poor actions or decision. Equipping robots with a reflex system and parallel learning architecture could help to prolong their useful life and allow for continued learning of safe actions. Focusing on a specific mock-up scenario of cubes on a 'stove\u2019 like setup, we investigate the hardware and learning approaches for a robotic manipulator to learn the presence of 'hot\u2019 objects and its contextual relationship to the environment. By creating a reflex arc using analog electronics that bypasses the 'brain\u2019 of the system we show an increase in the speed of release by at least two-fold. In parallel we have a learning procedure which combines visual information of the scene with this 'pain signal\u2019 to learn and predict when an object may be hot, utilizing an object detection neural network. Finally, we are able to extract the learned contextual information of the environment by introducing a method inspired by 'thought experiments' to generate heatmaps that indicate the probability of the environment being hot.",
        "primary_area": "",
        "author": "Kai Junge;Kevin Qiu;Josie Hughes;Kai Junge;Kevin Qiu;Josie Hughes",
        "authorids": "/37087317554;/37089663387;/37085816016;/37087317554;/37089663387;/37085816016",
        "aff": "CREATE Lab, EPFL, Lausanne, Switzerland; CREATE Lab, EPFL, Lausanne, Switzerland; CREATE Lab, EPFL, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981310/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14951682683714146122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "CREATE Lab",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982226",
        "title": "Bioinspired Antagonist-agonist Artificial Muscles for Humanoid Eyeball Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural eyeball motions in humanoid robots can contribute to friendly communication, thus improving the human-robot interaction. In this paper, we develop antagonist-agonist artificial muscles for humanoid eyeball motions, by using dielectric elastomer actuators (DEAs). Inspired by human eyeballs, the artificial muscles consist of two pairs of DEA: one pair for the horizontal motion, and the other for the vertical motion. The fabrication time of actuators can be significantly decreased due to their simple structure. The antagonist-agonist actuator outperforms the dielectric elastomer minimum energy structure in terms of actuation displacement and response time. We conduct experiments in a lifesize human face model. The experiments demonstrate the capability of antagonist-agonist artificial muscles to mimic eyeball motions in the horizontal, vertical, and diagonal directions. Future work includes modeling and control of artificial muscles for optimal performance of various humanoid eyeball motions.",
        "primary_area": "",
        "author": "Zhen Luo;Zhipeng Xu;Jisen Li;Jian Zhu;Zhen Luo;Zhipeng Xu;Jisen Li;Jian Zhu",
        "authorids": "/37089662645;/37089659891;/37088836514;/37089777174;/37089662645;/37089659891;/37088836514;/37089777174",
        "aff": "School of Science and Engineering, Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982226/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11811565191693062493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "School of Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981403",
        "title": "Biomechanical Design Optimization of Passive Exoskeletons through Surrogate Modeling on Industrial Activity Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Passive exoskeletons are unpowered wearable robotic devices aimed at providing biomechanical assistance. They can be applied in industries such as manufacturing, construction and logistics to reduce repetitive stress injuries among workers. Their design process typically considers a static user, with muscle outputs computed later during dynamic tasks to evaluate performance. Attempting to reduce human muscle effort at this stage requires manual redesign. Instead, we propose a parameter optimization approach that minimizes muscle effort rates during realistic dynamic tasks in the design stage itself. We extract human kinematics in assembly tasks from an industry-oriented motion capture dataset, and compute the induced joint torques. Using a passive exoskeleton for shoulder joint gravity compensation from the literature as a baseline, we optimize its design parameters through a multi-objective Pareto Local Search, minimizing the muscle effort rates during these tasks. As the estimation of muscle outputs through biomechanical simulation techniques is computation-ally expensive, we train ensemble regression models for each muscle of interest during the task motions. These models serve as surrogates for the objective function in the design optimization procedure, speeding up search in the parameter space. The resulting exoskeleton with optimized design param-eters reduces estimated muscle effort rates by an average of 5.73% and peak of 35.1 % compared to default parameters, and an average of 14.5% and peak of 32.2% compared to not wearing an exoskeleton in overhead assembly tasks. A larger peak reduction compared to default parameters may be due to hindrance in motion caused by device. This approach may be adapted to other exoskeletons and applications, improving biomechanical assistance by design.",
        "primary_area": "",
        "author": "Vighnesh Vatsal;Balamuralidhar Purushothaman;Vighnesh Vatsal;Balamuralidhar Purushothaman",
        "authorids": "/37086323124;/37086011989;/37086323124;/37086011989",
        "aff": "TCS Research & Innovation, Tata Consultancy Services, Bengaluru, Karnataka, India; TCS Research & Innovation, Tata Consultancy Services, Bengaluru, Karnataka, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981403/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7319438326642496682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "TCS Research & Innovation",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bengaluru",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9982156",
        "title": "Block-based Novel Haptic Data Reduction for Time-delayed Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a novel haptic data reduction scheme for time-delayed teleoperation by coding information as blocks. State-of-the-art (SOTA) haptic data reduction approaches are mainly sampled-based schemes. They encode haptic signals sample by sample in order to minimize the introduced coding delay. In contrast, our proposed block-based coding approach transmits a sample block as a single unit (haptic packet). Although it introduces additional algorithmic delays that are proportional to the block length, block coding has benefits since the packet rate is easy to control, the coding approach can be lossless, and the intra-block information can be employed to improve the force feedback quality. We further develop an energy adjustment approach that uses the information in a block to mitigate force oscillations caused by the Time Domain Passivity Approach. Simulation experiments and subjective tests demonstrate that our method reduces network load and significantly increases force feedback quality compared with the SOTA sample-based coding schemes, particularly for mid- to high-latency networks and low packet rates.",
        "primary_area": "",
        "author": "Ming Gui;Xiao Xu;Eckehard Steinbach;Ming Gui;Xiao Xu;Eckehard Steinbach",
        "authorids": "/37089582631;/38238310400;/37273225600;/37089582631;/38238310400;/37273225600",
        "aff": "Centre for Tactile In-ternet with Human-in-the-Loop (CeTI), Chair of Media Technology and Munich Institute of Robotics and Machine Intelligence, Technical University of Munich; Centre for Tactile In-ternet with Human-in-the-Loop (CeTI), Chair of Media Technology and Munich Institute of Robotics and Machine Intelligence, Technical University of Munich; Centre for Tactile In-ternet with Human-in-the-Loop (CeTI), Chair of Media Technology and Munich Institute of Robotics and Machine Intelligence, Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982156/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13657192234337244415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Media Technology and Munich Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981304",
        "title": "BonnBot-I: A Precise Weed Management and Crop Monitoring Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Cultivation and weeding are two of the primary tasks performed by farmers today. A recent challenge for weeding is the desire to reduce herbicide and pesticide treatments while maintaining crop quality and quantity. In this paper we introduce BonnBot-I a precise weed management platform which can also performs field monitoring. Driven by crop monitoring approaches which can accurately locate and classify plants (weed and crop) we further improve their performance by fusing the platform available GNSS and wheel odometry. This improves tracking accuracy of our crop monitoring approach from a normalized average error of 8.3% to 3.5%, evaluated on a new publicly available corn dataset. We also present a novel arrangement of weeding tools mounted on linear actuators evaluated in simulated environments. We replicate weed distributions from a real field, using the results from our monitoring approach, and show the validity of our work-space division techniques which require significantly less movement (a 50% reduction) to achieve similar results. Overall, BonnBot-I is a significant step forward in precise weed management with a novel method of selectively spraying and controlling weeds in an arable field.",
        "primary_area": "",
        "author": "Alireza Ahmadi;Michael Halstead;Chris McCool;Alireza Ahmadi;Michael Halstead;Chris McCool",
        "authorids": "/37085486371;/37085368005;/38274733400;/37085486371;/37085368005;/38274733400",
        "aff": "University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981304/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17892471312671784421&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bonn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982108",
        "title": "Bounded Rational Game-theoretical Modeling of Human Joint Actions with Incomplete Information",
        "track": "main",
        "status": "Poster",
        "abstract": "As humans and robots start to collaborate in close proximity, robots are tasked to perceive, comprehend, and anticipate human partners' actions, which demands a predictive model to describe how humans collaborate with each other in joint actions. Previous studies either simplify the collaborative task as an optimal control problem between two agents or do not consider the learning process of humans during repeated interaction. This idyllic representation is thus not able to model human rationality and the learning process. In this paper, a bounded-rational and game-theoretical human cooperative model is developed to describe the cooperative behaviors of the human dyad. An experiment of a joint object pushing collaborative task was conducted with 30 human subjects using haptic interfaces in a virtual environment. The proposed model uses inverse optimal control (IOC) to model the reward parameters in the collaborative task. The collected data verified the accuracy of the predicted human trajectory generated from the bounded rational model excels the one with a fully rational model. We further provide insight from the conducted experiments about the effects of leadership on the performance of human collaboration.",
        "primary_area": "",
        "author": "Yiwei Wang;Pallavi Shintre;Sunny Amatya;Wenlong Zhang;Yiwei Wang;Pallavi Shintre;Sunny Amatya;Wenlong Zhang",
        "authorids": "/37086051271;/37089660125;/37085358324;/37085823780;/37086051271;/37089660125;/37085358324;/37085823780",
        "aff": "School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; School of Manufacturing Systems and Networks, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; School of Manufacturing Systems and Networks, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; School of Manufacturing Systems and Networks, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982108/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6821831290193148253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Tempe;Mesa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981266",
        "title": "BoxGraph: Semantic Place Recognition and Pose Estimation from 3D LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is about extremely robust and lightweight localisation using LiDAR point clouds based on instance segmentation and graph matching. We model 3D point clouds as fully-connected graphs of semantically identified components where each vertex corresponds to an object instance and encodes its shape. Optimal vertex association across graphs allows for full 6-Degree-of-Freedom (DoF) pose estimation and place recognition by measuring similarity. This representation is very concise, condensing the size of maps by a factor of 25 against the state-of-the-art, requiring only 3 kB to represent a 1.4 MB laser scan. We verify the efficacy of our system on the SemanticKITTI dataset, where we achieve a new state-of-the-art in place recognition, with an average of 88.4 % recall at 100 % precision where the next closest competitor follows with 64.9 %. We also show accurate metric pose estimation performance - estimating 6-DoF pose with median errors of 10cm and 0.33 deg.",
        "primary_area": "",
        "author": "Georgi Pramatarov;Daniele De Martini;Matthew Gadd;Paul Newman;Georgi Pramatarov;Daniele De Martini;Matthew Gadd;Paul Newman",
        "authorids": "/37089661229;/37086404606;/37085439081;/37335903100;/37089661229;/37086404606;/37085439081;/37335903100",
        "aff": "Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981266/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6671586981837023242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Mobile Robotics Group",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981518",
        "title": "Bubble Planner: Planning High-speed Smooth Quadrotor Trajectories using Receding Corridors",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrotors are agile platforms. With human experts, they can perform extremely high-speed flights in cluttered environments. However, fully autonomous flight at high speed remains a significant challenge. In this work, we propose a motion planning algorithm based on the corridor-constrained minimum control effort trajectory optimization (MINCO) framework. Specifically, we use a series of overlapping spheres to represent the free space of the environment and propose two novel designs that enable the algorithm to plan high-speed quadrotor trajectories in real-time. One is a sampling-based corridor generation method that generates spheres with large overlapped areas (hence overall corridor size) between two neighboring spheres. The second is a Receding Horizon Corridors (RHC) strategy, where part of the previously generated corridor is reused in each replan. Together, these two designs enlarge the corridor spaces in accordance with the quadrotor's current state and hence allow the quadrotor to maneuver at high speeds. We benchmark our algorithm against other state-of-the-art planning methods to show its superiority in simulation. Comprehensive ablation studies are also conducted to show the necessity of the two designs. The proposed method is finally evaluated on an autonomous LiDAR-navigated quadrotor UAV in woods environments, achieving flight speeds over 13.7m/s without any prior map of the environment or external localization facility.",
        "primary_area": "",
        "author": "Yunfan Ren;Fangcheng Zhu;Wenyi Liu;Zhepei Wang;Yi Lin;Fei Gao;Fu Zhang;Yunfan Ren;Fangcheng Zhu;Wenyi Liu;Zhepei Wang;Yi Lin;Fei Gao;Fu Zhang",
        "authorids": "/37087243712;/37089661744;/37089663499;/37086601081;/37086281245;/37086045143;/38245883800;/37087243712;/37089661744;/37089663499;/37086601081;/37086281245;/37086045143;/38245883800",
        "aff": "Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong; School of Electronics and Information Engineering, Harbin Institute of Technology, Shenzhen; College of Control Science and Engineering, Zhejiang University; Dji Co.; College of Control Science and Engineering, Zhejiang University; Department of Mechanical Engineering, University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981518/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9747875901660473200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;3;2;0",
        "aff_unique_norm": "University of Hong Kong;Harbin Institute of Technology;Zhejiang University;DJI",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Electronics and Information Engineering;College of Control Science and Engineering;",
        "aff_unique_url": "https://www.hku.hk;http://www.hit.edu.cn/;http://www.zju.edu.cn;https://www.dji.com",
        "aff_unique_abbr": "HKU;HIT;ZJU;DJI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981172",
        "title": "CA-SpaceNet: Counterfactual Analysis for 6D Pose Estimation in Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable and stable 6D pose estimation of un-cooperative space objects plays an essential role in on-orbit servicing and debris removal missions. Considering that the pose estimator is sensitive to background interference, this paper proposes a counterfactual analysis framework named CA-SpaceNet to complete robust 6D pose estimation of the space-borne targets under complicated background. Specifically, conventional methods are adopted to extract the features of the whole image in the factual case. In the counterfactual case, a non-existent image without the target but only the background is imagined. Side effect caused by background interference is reduced by counterfactual analysis, which leads to unbiased prediction in final results. In addition, we also carry out low-bit-width quantization for CA-SpaceNet and deploy part of the framework to a Processing-In-Memory (PIM) accelerator on FPGA. Qualitative and quantitative results demonstrate the effectiveness and efficiency of our proposed method. To our best knowledge, this paper applies causal inference and network quantization to the 6D pose estimation of space-borne targets for the first time. The code is available at https://github.com/Shunli-Wang/CA-SpaceNet.",
        "primary_area": "",
        "author": "Shunli Wang;Shuaibing Wang;Bo Jiao;Dingkang Yang;Liuzhen Su;Peng Zhai;Chixiao Chen;Lihua Zhang;Shunli Wang;Shuaibing Wang;Bo Jiao;Dingkang Yang;Liuzhen Su;Peng Zhai;Chixiao Chen;Lihua Zhang",
        "authorids": "/37089365164;/37089660663;/37089336547;/37089365559;/37089662855;/37089334222;/38241039100;/37088834340;/37089365164;/37089660663;/37089336547;/37089365559;/37089662855;/37089334222;/38241039100;/37088834340",
        "aff": "Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Engineering Research Center of AI and Robotics, Ministry of Education, China; Artifical Intelligence and Unmanned Systems Engineering Research Center of Jilin Province, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981172/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1096575557005049391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Engineering Research Center of AI and Robotics;Jilin Province Artifical Intelligence and Unmanned Systems Engineering Research Center",
        "aff_unique_dep": "Ministry of Education;Artifical Intelligence and Unmanned Systems Engineering",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981826",
        "title": "CFP-SLAM: A Real-time Visual SLAM Based on Coarse-to-Fine Probability in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The dynamic factors in the environment will lead to the decline of camera localization accuracy due to the violation of the static environment assumption of SLAM algorithm. Recently, some related works generally use the combination of semantic constraints and geometric constraints to deal with dynamic objects, but problems can still be raised, such as poor real-time performance, easy to treat people as rigid bodies, and poor performance in low dynamic scenes. In this paper, a dynamic scene-oriented visual SLAM algorithm based on object detection and coarse-to-fine static probability named CFP-SLAM is proposed. The algorithm combines semantic constraints and geometric constraints to calculate the static probability of objects, keypoints and map points, and takes them as weights to participate in camera pose estimation. Extensive evaluations show that our approach can achieve almost the best results in high dynamic and low dynamic scenarios compared to the state-of-the-art dynamic SLAM methods, and shows quite high real-time ability.",
        "primary_area": "",
        "author": "Xinggang Hu;Yunzhou Zhang;Zhenzhong Cao;Rong Ma;Yanmin Wu;Zhiqiang Deng;Wenkai Sun;Xinggang Hu;Yunzhou Zhang;Zhenzhong Cao;Rong Ma;Yanmin Wu;Zhiqiang Deng;Wenkai Sun",
        "authorids": "/37089229423;/37310459100;/37089239385;/37089473362;/37088690951;/37089230577;/37089231413;/37089229423;/37310459100;/37089239385;/37089473362;/37088690951;/37089230577;/37089231413",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Beijing Simulation Center, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981826/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2035499308973543684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "Northeastern University;Beijing Simulation Center;Peking University",
        "aff_unique_dep": "College of Information Science and Engineering;;School of Electronic and Computer Engineering",
        "aff_unique_url": "http://www.neu.edu.cn/;;http://www.pku.edu.cn",
        "aff_unique_abbr": "NEU;;PKU",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "Shenyang;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982110",
        "title": "CGLR: Dense Multi-Agent Navigation Using Voronoi Cells and Congestion Metric-based Replanning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a decentralized path-planning algorithm for navigating multiple differential-drive robots in dense environments. In contrast to prior decentralized methods, we propose a novel congestion metric-based replanning that couples local and global planning techniques to efficiently navigate in scenarios with multiple corridors. To handle dense scenes with narrow passages, our approach computes the initial path for each agent to its assigned goal using a lattice planner. Based on neighbors' information, each agent performs online replanning using a congestion metric that tends to reduce the collisions and improves the navigation performance. Furthermore, we use the Voronoi cells of each agent to plan the local motion as well as a corridor selection strategy to limit the congestion in narrow passages. We evaluate the performance of our approach in complex scenes with tens of agents and narrow passages. We show that our Coupled Global-Local approach and Replanning (CGLR) improves the performance and efficiency over prior decentralized methods. In addition, our approach results in a higher success rate in terms of collision-free navigation to the goals, showing improvement in the range of 3-70% over prior decentralized solutions in certain scenarios.",
        "primary_area": "",
        "author": "Senthil Hariharan Arul;Dinesh Manocha;Senthil Hariharan Arul;Dinesh Manocha",
        "authorids": "/37086929465;/37267825600;/37086929465;/37267825600",
        "aff": "Department of Electrical and computer Engineering, University of Maryland at College Park, Maryland, United States; Department of Computer Science, University of Maryland, Maryland, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982110/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14259545485096787581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "College Park;Maryland",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981113",
        "title": "CGiS-Net: Aggregating Colour, Geometry and Implicit Semantic Features for Indoor Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe a novel approach to indoor place recognition from RGB point clouds based on aggregating low-level colour and geometry features with high-level implicit semantic features. It uses a 2-stage deep learning framework, in which the first stage is trained for the auxiliary task of semantic segmentation and the second stage uses features from layers in the first stage to generate discriminate descriptors for place recognition. The auxiliary task encourages the features to be semantically meaningful, hence aggregating the geometry and colour in the RGB point cloud data with implicit semantic information. We use an indoor place recognition dataset derived from the ScanNet dataset for training and evaluation, with a test set comprising 3,608 point clouds generated from 100 different rooms. Comparison with a traditional feature-based method and four state-of-the-art deep learning methods demonstrate that our approach significantly outperforms all five methods, achieving, for example, a top-3 average recall rate of 75% compared with 41% for the closest rival method. Our code is available at: https://github.com/YuhangMing/Semantic-Indoor-Place-Recognition",
        "primary_area": "",
        "author": "Yuhang Ming;Xingrui Yang;Guofeng Zhang;Andrew Calway;Yuhang Ming;Xingrui Yang;Guofeng Zhang;Andrew Calway",
        "authorids": "/37089196703;/37085952161;/37405938800;/37326243500;/37089196703;/37085952161;/37405938800;/37326243500",
        "aff": "Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981113/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15793338572910252492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Bristol;Zhejiang University",
        "aff_unique_dep": "Department of Computer Science;State Key Lab of CAD&CG",
        "aff_unique_url": "https://www.bristol.ac.uk;http://www.zju.edu.cn",
        "aff_unique_abbr": "UoB;ZJU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Bristol;Hangzhou",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9982241",
        "title": "COMPASS: Contrastive Multimodal Pretraining for Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning representations that generalize across tasks and domains is challenging yet necessary for autonomous systems. Although task-driven approaches are appealing, de-signing models specific to each application can be difficult in the face of limited data, especially when dealing with highly variable multimodal input spaces arising from different tasks in different environments. We introduce the first general-purpose pretraining pipeline, COntrastive Multimodal Pretraining for AutonomouS Systems (COMPASS), to overcome the limitations of task-specific models and existing pretraining approaches. COMPASS constructs a multimodal graph by considering the essential information for autonomous systems and the proper-ties of different modalities. Through this graph, multimodal signals are connected and mapped into two factorized spatio-temporal latent spaces: a \u201cmotion pattern space\u201d and a \u201ccurrent state space.\u201d By learning from multimodal correspondences in each latent space, COMPASS creates state representations that models necessary information such as temporal dynamics, geometry, and semantics. We pretrain COMPASS on a large-scale multimodal simulation dataset TartanAir [1] and evaluate it on drone navigation, vehicle racing, and visual odometry tasks. The experiments indicate that COMPASS can tackle all three scenarios and can also generalize to unseen environments and real-world data.11Our code implementation can be found at https://github.com/microsoft/COMPASS",
        "primary_area": "",
        "author": "Shuang Ma;Sai Vemprala;Wenshan Wang;Jayesh K. Gupta;Yale Song;Daniel McDufft;Ashish Kapoor;Shuang Ma;Sai Vemprala;Wenshan Wang;Jayesh K. Gupta;Yale Song;Daniel McDufft;Ashish Kapoor",
        "authorids": "/37086565371;/37085796013;/37087322184;/37089658531;/37085682508;/37089660906;/37397699500;/37086565371;/37085796013;/37087322184;/37089658531;/37085682508;/37089660906;/37397699500",
        "aff": "Microsoft Redmond, WA; Microsoft Redmond, WA; Carnegie Mellon University Pittsburgh, PA; Microsoft Redmond, WA; Microsoft Redmond, WA; Microsoft Redmond, WA; Microsoft Redmond, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982241/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14544202378503515197&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "Microsoft;Carnegie Mellon University",
        "aff_unique_dep": "Microsoft Corporation;",
        "aff_unique_url": "https://www.microsoft.com;https://www.cmu.edu",
        "aff_unique_abbr": "Microsoft;CMU",
        "aff_campus_unique_index": "0;0;1;0;0;0;0",
        "aff_campus_unique": "Redmond;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981372",
        "title": "CPQNet: Contact Points Quality Network for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "In typical data-based grasping methods, a grasp based on parallel-jaw grippers is parameterized by the center of the gripper, the rotation angle, and the gripper opening width so as to predict the quality and pose of grasps at every pixel. In contrast, a grasp is represented using only two contact points for contact-points-based grasp representation, which allows for fusion with tactile sensors more naturally. In this work, we propose a method using contact-points-based grasp representation to get a robust grasp using only one contact points quality map generated by a neural network, which significantly reduces the complexity of the network with fewer parameters. We provide a synthetic dataset including depth image and contact points quality map generated by thousands of 3D models. We also provide the method for data generation, which can be used for contact-points-based multi-fingers grasp. Experiments show that contact points quality network can plan an available grasp in 0.15 seconds. The grasping success rate for unknown household objects is 94%. Our method is also available for deformable objects with a success rate of 95%. The dataset and reference code can be found on the project website: https://sites.google.com/view/cpqnet.",
        "primary_area": "",
        "author": "Zhihao Li;Pengfei Zeng;Jionglong Su;Qingda Guo;Ning Ding;Jiaming Zhang;Zhihao Li;Pengfei Zeng;Jionglong Su;Qingda Guo;Ning Ding;Jiaming Zhang",
        "authorids": "/37089323181;/37089660530;/37086158813;/37085819731;/37086099653;/37086300692;/37089323181;/37089660530;/37086158813;/37085819731;/37086099653;/37086300692",
        "aff": "Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong (Shenzhen), Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; School of AI and Advanced Computing, XJTLU Entrepreneur College (Taicang), Xi'an Jiaotong-Liverpool University, Suzhou, China; TOP-AIRS Hospital Intelligent Technique Joint Lab, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981372/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5099946784276924292&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;1",
        "aff_unique_norm": "Chinese University of Hong Kong (Shenzhen);Shenzhen Institute of Artificial Intelligence and Robotics for Society;Xi'an Jiao Tong-Liverpool University;TOP-AIRS Hospital Intelligent Technique Joint Lab",
        "aff_unique_dep": "Institute of Robotics and Intelligent Manufacturing;;School of AI and Advanced Computing;",
        "aff_unique_url": "https://www.cuhk.edu.cn;;https://www.xjtlu.edu.cn;",
        "aff_unique_abbr": "CUHK (Shenzhen);;XJTLU;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Shenzhen;Taicang;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981558",
        "title": "CROON: Automatic Multi-LiDAR Calibration and Refinement Method in Road Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor-based environmental perception is a crucial part of the autonomous driving system. In order to get an excellent perception of the surrounding environment, an intelligent system would configure multiple LiDARs (3D Light Detection and Ranging) to cover the distant and near space of the car. The precision of perception relies on the quality of sensor calibration. This research aims at developing an accurate, automatic, and robust calibration strategy for multiple LiDAR systems in the general road scene. We thus propose CROON (automatic multi-LiDAR Calibration and Refinement methOd in rOad sceNe), a two-stage method including rough and refinement calibration. The first stage can calibrate the sensor from an arbitrary initial pose, and the second stage is able to precisely calibrate the sensor iteratively. Specifically, CROON utilize the nature characteristics of road scene so that it is independent and easy to apply in large-scale conditions. Experimental results on real-world and simulated data sets demonstrate the reliability and accuracy of our method. All the related data sets and codes are open-sourced on the Github website https://github.com/OpenCalib/LiDAR2LiDAR.",
        "primary_area": "",
        "author": "Pengjin Wei;Guohang Yan;Yikang Li;Kun Fang;Xinyu Cai;Jie Yang;Wei Liu;Pengjin Wei;Guohang Yan;Yikang Li;Kun Fang;Xinyu Cai;Jie Yang;Wei Liu",
        "authorids": "/37089659959;/37089659382;/37089161200;/37088972016;/37089661769;/37280203600;/37898950200;/37089659959;/37089659382;/37089161200;/37088972016;/37089661769;/37280203600;/37898950200",
        "aff": "Department of Automation, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Department of Automation, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Department of Automation, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China; Department of Automation, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981558/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2317450446305531504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Shanghai AI Laboratory",
        "aff_unique_dep": "Department of Automation, Institute of Image Processing and Pattern Recognition;Autonomous Driving Group",
        "aff_unique_url": "https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "SJTU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981830",
        "title": "CSA-SVM method for internal cavitation defects detection and its application of district heating pipes",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of this paper is to develop an ultrasonic detection device that can be mounted on an underwater snake vehicle (USV) for underwater district heating pipe (DHP) detection in the future. Ultrasonic detection technology (UDT) is the detection means used, and the cavitation defects in polyurethane (PUR) layer of DHPs are the object being detected. Due to the large thickness of PUR layer and the complex interface information of multi-layer structure, detecting defects of DHPs quantitatively is a difficult task. To address this issue, this paper proposes an approach that combines feature extraction and crow search algorithm (CSA) optimized support vector machine (SVM). Firstly, the main parameters and detection method of UDT are designed after investigation. Secondly, defective signals are pre-processed by signal processing to extract the features form three domains. Finally, four different classifiers are used to identify cavitation defects based on the feature-set. When compared among optimized random forest (RF), k-nearest neighbor (KNN), and ordinary SVM, the experimental results show that CSA-SVM had the highest accuracy in defect size prediction, and the validation-experiment verifies the practicability and feasibility of the CSA-SVM classifier. All experiments illustrate that the issue could be well solved by our method.",
        "primary_area": "",
        "author": "Yanran Chen;Shugen Ma;Longchuan Li;Zhiqing Li;Yulin Yang;Yanran Chen;Shugen Ma;Longchuan Li;Zhiqing Li;Yulin Yang",
        "authorids": "/37088897067;/37280187400;/37086240920;/37597736000;/37088897389;/37088897067;/37280187400;/37086240920;/37597736000;/37088897389",
        "aff": "College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981830/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9209296251168017896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Beijing University of Chemical Technology;Ritsumeikan University",
        "aff_unique_dep": "College of Information Science and Technology;Graduate School of Science and Engineering",
        "aff_unique_url": "http://www.buct.edu.cn;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "BUCT;Ritsumeikan",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Beijing;Kusatsu",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9981087",
        "title": "CVFNet: Real-time 3D Object Detection by Learning Cross View Features",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years 3D object detection from LiDAR point clouds has made great progress thanks to the development of deep learning technologies. Although voxel or point based methods are popular in 3D object detection, they usually involve time-consuming operations such as 3D convolutions on voxels or ball query among points, making the resulting network inappropriate for time critical applications. On the other hand, 2D view-based methods feature high computing efficiency while usually obtaining inferior performance than the voxel or point based methods. In this work, we present a real-time view-based single stage 3D object detector, namely CVFNet to fulfill this task. To strengthen the cross-view feature learning under the condition of demanding efficiency, our framework extracts the features of different views and fuses them in an efficient progressive way. We first propose a novel Point-Range feature fusion module that deeply integrates point and range view features in multiple stages. Then, a special Slice Pillar is designed to well maintain the 3D geometry when transforming the obtained deep point-view features into bird's eye view. To better balance the ratio of samples, a sparse pillar detection head is presented to focus the detection on the nonempty grids. We conduct experiments on the popular KITTI and NuScenes benchmark, and state-of-the-art performances are achieved in terms of both accuracy and speed.",
        "primary_area": "",
        "author": "Jiaqi Gu;Zhiyu Xiang;Pan Zhao;Tingming Bai;Lingxuan Wang;Xijun Zhao;Zhiyuan Zhang;Jiaqi Gu;Zhiyu Xiang;Pan Zhao;Tingming Bai;Lingxuan Wang;Xijun Zhao;Zhiyuan Zhang",
        "authorids": "/37088799685;/37331922100;/37089664006;/37089194222;/37088802328;/37539423000;/37086278396;/37088799685;/37331922100;/37089664006;/37089194222;/37088802328;/37539423000;/37086278396",
        "aff": "College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; Laboratory of Information Processing, Communication and Networking, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; North Vehicle Research Institute, Beijing, China; Ningbo Research Institute, Zhejiang University, Ningbo, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981087/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6094312022820693351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Zhejiang University;North Vehicle Research Institute",
        "aff_unique_dep": "College of Information Science & Electronic Engineering;",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;0;2",
        "aff_campus_unique": "Hangzhou;;Ningbo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982025",
        "title": "Can we reach human expert programming performance? A tactile manipulation case study in learning time and task performance",
        "track": "main",
        "status": "Poster",
        "abstract": "Reaching human-level performance in tactile manipulation is one of the grand challenges in nowadays robotics research. Over the past decade significant progress in both skill control and learning was made. However, the achievable execution speed still falls behind the human ability, without clearly understanding whether the specific shortcomings are mainly in the control, skill learning, or motion planning layer. For gaining a better understanding of this complex problem, we draw an experimental side-by-side comparative case study. First, given a task program for a challenging benchmarking task, the goal is to objectify the achievable task performance from a human expert programmer against autonomously learning these assembly behaviors with a state-of-the-art skill learning framework. Second, we compare the manually tuned and learned robot skills to the performance of an adult human solving the task manually. For the former, it could be shown that despite longer learning duration, the task execution speed of the machine learning-based solution is equivalent to the one programmed by the human expert. For the latter, the identified performance gap remained significantly larger, where only for some specific isolated skills the system was able to reach comparable or even faster than human execution speeds. The overall analysis gave also useful hints where in particular manipulation policies and arm-hand coordination still need significant improvements in the future.",
        "primary_area": "",
        "author": "Lars Johannsmeier;Sami Haddadin;Lars Johannsmeier;Sami Haddadin",
        "authorids": "/37085776668;/37542865300;/37085776668;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence and the Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany; Chair of Robotics and Systems Intelligence and the Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982025/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7276023611128458873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981631",
        "title": "Capability-Aware Task Allocation and Team Formation Analysis for Cooperative Exploration of Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve autonomy in complex real-world exploration missions, we consider deployment strategies for a team of robots with heterogeneous capabilities. We formulate a multi-robot exploration mission and compute an operation policy to maintain robot team productivity and maximize mission success. The environment description, robot capability, and mission outcome are modeled as a Markov decision process (MDP). We also include constraints, such as sensor failures, limited communication coverage, and mobility-stressing elements. The proposed operation model is applied to the DARPA Subterranean (SubT) Challenge. The deployment policy is also compared against the human-based operation strategy in the final competition of the SubT Challenge.",
        "primary_area": "",
        "author": "Muhammad Fadhil Ginting;Kyohei Otsu;Mykel J. Kochenderfer;Ali-akbar Agha-mohammadi;Muhammad Fadhil Ginting;Kyohei Otsu;Mykel J. Kochenderfer;Ali-akbar Agha-mohammadi",
        "authorids": "/37086345435;/37085558541;/37596929200;/38274170800;/37086345435;/37085558541;/37596929200;/38274170800",
        "aff": "NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Aeronautics & Astronautics, Stanford University, Stanfurd, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981631/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14079728357748275540&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "California Institute of Technology;Stanford University",
        "aff_unique_dep": "NASA Jet Propulsion Laboratory;Department of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.caltech.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Caltech;Stanford",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pasadena;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982029",
        "title": "Category-Independent Articulated Object Tracking with Factor Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots deployed in human-centric environments may need to manipulate a diverse range of articulated objects, such as doors, dishwashers, and cabinets. Articulated objects often come with unexpected articulation mechanisms that are inconsistent with categorical priors: for example, a drawer might rotate about a hinge joint instead of sliding open. We propose a category-independent framework for predicting the articulation models of unknown objects from sequences of RGB-D images. The prediction is performed by a two-step process: first, a visual perception module tracks object part poses from raw images, and second, a factor graph takes these poses and infers the articulation model including the current configuration between the parts as a 6D twist. We also propose a manipulation-oriented metric to evaluate predicted joint twists in terms of how well a compliant robot controller would be able to manipulate the articulated object given the predicted twist. We demonstrate that our visual perception and factor graph modules outperform baselines on simulated data and show the applicability of our factor graph on real world data.",
        "primary_area": "",
        "author": "Nick Heppert;Toki Migimatsu;Brent Yi;Claire Chen;Jeannette Bohg;Nick Heppert;Toki Migimatsu;Brent Yi;Claire Chen;Jeannette Bohg",
        "authorids": "/37089660890;/37086141343;/37088687522;/37089198158;/37591153900;/37089660890;/37086141343;/37088687522;/37089198158;/37591153900",
        "aff": "Department of Computer Science, TU Darmstadt, Germany; Department of Computer Science, Stanford University, USA; Department of Electrical Engineering and Computer Sciences, UC Berkeley, USA; Department of Computer Science, Stanford University, USA; Department of Computer Science, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982029/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15431371206443082853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Stanford University;University of California, Berkeley",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "TU Darmstadt;Stanford;UC Berkeley",
        "aff_campus_unique_index": "1;2;1;1",
        "aff_campus_unique": ";Stanford;Berkeley",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9982117",
        "title": "Centralized-Equivalent Pairwise Estimation with Asynchronous Communication Constraints for two Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaboratively estimating the state of two robots under communication constraints is challenging regarding computational complexity and statistical optimality. Previous work only achieves practical solutions by either disregarding parts of the measurements or imposing a communication overhead, being non-optimal or not entirely distributed, respectively. In this work, we present a centralized-equivalent but dis-tributed approach for pairwise state estimation where two agents only communicate when they meet. Our approach utilizes elements from wave scattering theory to efficiently and consistently summarize (pre-compute) past estimator information (i.e., state evolution and uncertainty) between encounters of two agents. This summarized information is then used in a joint correction step taking into account all past information of each agent in a statistically correct way. This novel approach enables us to distribute the pre-computations of both state evolution and uncertainties on the agents and reconstruct the centralized-equivalent system estimate with very few computations once the agents meet again while still applying all measurements from both agents on both estimates upon encounter. We compare our approach on a real-world dataset against a state of the art collaborative state estimation approach.",
        "primary_area": "",
        "author": "Eren Allak;Axel Barrau;Roland Jung;Jan Steinbrener;Stephan Weiss;Eren Allak;Axel Barrau;Roland Jung;Jan Steinbrener;Stephan Weiss",
        "authorids": "/37086580226;/38488659000;/37087323495;/37087049144;/37535323400;/37086580226;/38488659000;/37087323495;/37087049144;/37535323400",
        "aff": "Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Safran Tech, Groupe Safran, Magny Les Hameaux CEDEX, France; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982117/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4474610937322081703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Klagenfurt;Safran Tech",
        "aff_unique_dep": "Department of Smart Systems Technologies;",
        "aff_unique_url": "https://www.uni-klagenfurt.at;",
        "aff_unique_abbr": "Uni Klagenfurt;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Klagenfurt;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Austria;France"
    },
    {
        "id": "9981662",
        "title": "Characterization of Real-time Haptic Feedback from Multimodal Neural Network-based Force Estimates during Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Force estimation using neural networks is a promising approach to enable haptic feedback in minimally invasive surgical robots without end-effector force sensors. Various network architectures have been proposed, but none have been tested in real time with surgical-like manipulations. Thus, questions remain about the real-time transparency and stability of force feedback from neural network-based force estimates. We characterize the real-time impedance transparency and stability of force feedback rendered on a da Vinci Research Kit teleoperated surgical robot using neural networks with visiononly, state-only, and state and vision inputs. Networks were trained on an existing dataset of teleoperated manipulations without force feedback. To measure real-time stability and transparency during teleoperation with force feedback to the operator, we modeled a one-degree-of-freedom human and surgeon-side manipulandum that moved the patient-side robot to perform manipulations on silicone artificial tissue over various robot and camera configurations, and tools. We found that the networks using state inputs displayed more transparent impedance than a vision-only network. However, state-based networks displayed large instability when used to provide force feedback during lateral manipulation of the silicone. In contrast, the vision-only network showed consistent stability in all the evaluated directions. We confirmed the performance of the vision-only network for real-time force feedback in a demonstration with a human teleoperator.",
        "primary_area": "",
        "author": "Zonghe Chua;Allison M. Okamura;Zonghe Chua;Allison M. Okamura",
        "authorids": "/37088506881;/37276156400;/37088506881;/37276156400",
        "aff": "Mechanical Engineering Department, Stanford University, CA, USA; Mechanical Engineering Department, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981662/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2968289024959050659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981908",
        "title": "Child Engagement Estimation in Heterogeneous Child-Robot Interactions Using Spatiotemporal Visual Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are increasingly introduced in various Child-Robot Interactions with educational, entertainment or even therapeutic goals. In order to achieve qualitative inter-actions, robots need to adjust their behavior according to children's response. A robot's ability to successfully estimate partner's engagement is of great importance towards this direction. In this research we propose a method to estimate the engagement level of children during heterogeneous and challenging child-robot interactions. Our method uses the spatiotemporal residual \\mathrm{R}(2+1)\\mathrm{D}\\mathrm{R}(2+1)\\mathrm{D} blocks to simultaneously leverage the rich RGB and temporal information, which is crucial for the engagement estimation. We present results on three different groups of data, including the PInSoRo open dataset, proving our method's robustness and improvement over previous works.",
        "primary_area": "",
        "author": "Dafni Anagnostopoulou;Niki Efthymiou;Christina Papailiou;Petros Maragos;Dafni Anagnostopoulou;Niki Efthymiou;Christina Papailiou;Petros Maragos",
        "authorids": "/37089001378;/37085415030;/37086189905;/37285070800;/37089001378;/37085415030;/37086189905;/37285070800",
        "aff": "School of ECE, National Technical University of Athens, Athens, Greece; School of ECE, National Technical University of Athens, Athens, Greece; Department of Early Childhood Education and Care, University of West Attica, Athens, Greece; School of ECE, National Technical University of Athens, Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981908/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12926450480696224011&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Technical University of Athens;University of West Attica",
        "aff_unique_dep": "School of ECE;Department of Early Childhood Education and Care",
        "aff_unique_url": "https://www.ntua.gr;https://www.uoa.gr",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Athens",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981996",
        "title": "City-wide Street-to-Satellite Image Geolocalization of a Mobile Ground Agent",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-view image geolocalization provides an estimate of an agent's global position by matching a local ground image to an overhead satellite image without the need for GPS. It is challenging to reliably match a ground image to the correct satellite image since the images have significant viewpoint differences. Existing works have demonstrated localization in constrained scenarios over small areas but have not demonstrated wider-scale localization. Our approach, called Wide-Area Geolocalization (WAG), combines a neural network with a particle filter to achieve global position estimates for agents moving in GPS-denied environments, scaling efficiently to city-scale regions. WAG introduces a trinomial loss function for a Siamese network to robustly match non-centered image pairs and thus enables the generation of a smaller satellite image database by coarsely discretizing the search area. A modified particle filter weighting scheme is also presented to improve localization accuracy and convergence. Taken together, WAG's network training and particle filter weighting approach achieves city-scale position estimation accuracies on the order of 20 meters, a 98% reduction compared to a baseline training and weighting approach. Applied to a smaller-scale testing area, WAG reduces the final position estimation error by 64% compared to a state-of-the-art baseline from the literature. WAG's search space discretization additionally significantly reduces storage and processing requirements. We include in our submission a video demonstrating particle filter convergence results for WAG compared to the baseline for the Chicago test area.",
        "primary_area": "",
        "author": "Lena M. Downes;Dong-Ki Kim;Ted J. Steiner;Jonathan P. How;Lena M. Downes;Dong-Ki Kim;Ted J. Steiner;Jonathan P. How",
        "authorids": "/37088482864;/37087324178;/38242279400;/37276347700;/37088482864;/37087324178;/38242279400;/37276347700",
        "aff": "Draper, Perception and Embedded ML Group, Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Draper, Perception and Embedded ML Group, Cambridge, MA, USA; Faculty of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981996/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16436476853630867494&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Draper;Massachusetts Institute of Technology",
        "aff_unique_dep": "Perception and Embedded ML Group;Laboratory for Information and Decision Systems",
        "aff_unique_url": ";https://web.mit.edu",
        "aff_unique_abbr": ";MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981167",
        "title": "Class-Incremental Gesture Recognition Learning with Out-of-Distribution Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Gesture recognition is a popular human-computer interaction technology, which has been widely applied in many fields (e.g., autonomous driving, medical care, VR and AR). However, 1) most existing gesture recognition methods focus on the fixed recognition scenarios with several gestures, which could lead to memory consumption and computational effort when continuously learning new gestures; 2) Meanwhile, the performance of popular class-incremental methods degrades significantly for previously learned classes (i.e., catastrophic forgetting) due to the ambiguity and variability of gestures. To tackle these challenges, we propose a novel class-incremental gesture recognition method with out-of-distribution (OOD) detection, which can continuously adapt to new gesture classes and achieve high performance for both learned and new gestures. Specifically, we construct an episodic memory with a subset of learned training samples to preserve the previous knowledge from forgetting. Moreover, the OOD detection-based memory management is developed for exploring the most representative and informative core set from the learned datasets. When a new gesture recognition task with strange classes comes, rehearsal enhancement is adopted to increase the diversity of memory exemplars for better fitting the real characteristics of gesture recognition. After deriving an effective class-incremental gesture recognition strategy, we perform experiments on two representative datasets to validate the superiority of our method. Evaluation experiments demonstrate that our proposed method substantially outperforms the state-of-the-art methods with about 2.17%-3.81% improvement under different class-incremental learning scenarios.",
        "primary_area": "",
        "author": "Mingxue Li;Yang Cong;Yuyang Liu;Gan Sun;Mingxue Li;Yang Cong;Yuyang Liu;Gan Sun",
        "authorids": "/37089660920;/37662105600;/37089920672;/37086416861;/37089660920;/37662105600;/37089920672;/37086416861",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981167/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5484416479642138636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Beijing;Shenyang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982105",
        "title": "Classification of Time-Series Data Using Boosted Decision Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Time-series data classification is central to the analysis and control of autonomous systems, such as robots and self-driving cars. Temporal logic-based learning algorithms have been proposed recently as classifiers of such data. However, current frameworks are either inaccurate for real-world applications, such as autonomous driving, or they generate long and complicated formulae that lack interpretability. To address these limitations, we introduce a novel learning method, called Boosted Concise Decision Trees (BCDTs), to generate binary classifiers that are represented as Signal Temporal Logic (STL) formulae. Our algorithm leverages an ensemble of Concise Decision Trees (CDTs) to improve the classification performance, where each CDT is a decision tree that is empowered by a set of techniques to generate simpler formulae and improve interpretability. The effectiveness and classification performance of our algorithm are evaluated on naval surveillance and urban-driving case studies.",
        "primary_area": "",
        "author": "Erfan Aasi;Cristian Ioan Vasile;Mahroo Bahreinian;Calin Belta;Erfan Aasi;Cristian Ioan Vasile;Mahroo Bahreinian;Calin Belta",
        "authorids": "/37088922590;/37085532895;/37088337008;/37276061600;/37088922590;/37085532895;/37088337008;/37276061600",
        "aff": "Boston University, Boston, MA, USA; Lehigh University, Bethlehem, PA, USA; Boston University, Boston, MA, USA; Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982105/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4137183872972564275&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Boston University;Lehigh University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bu.edu;https://www.lehigh.edu",
        "aff_unique_abbr": "BU;Lehigh",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Boston;Bethlehem",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981472",
        "title": "Closed-Loop Next-Best-View Planning for Target-Driven Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Picking a specific object from clutter is an essential component of many manipulation tasks. Partial observations often require the robot to collect additional views of the scene before attempting a grasp. This paper proposes a closed-loop next-best-view planner that drives exploration based on occluded object parts. By continuously predicting grasps from an up-to-date scene reconstruction, our policy can decide online to finalize a grasp execution or to adapt the robot's trajectory for further exploration. We show that our reactive approach decreases execution times without loss of grasp success rates compared to common camera placements and handles situations where the fixed baselines fail. Video and code are available at https://github.com/ethz-asl/active_grasp.",
        "primary_area": "",
        "author": "Michel Breyer;Lionel Ott;Roland Siegwart;Jen Jen Chung;Michel Breyer;Lionel Ott;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37086692289;/38251784400;/37281398300;/37085668354;/37086692289;/38251784400;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981472/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4519351319074435263&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981542",
        "title": "Closing the Loop: Graph Networks to Unify Semantic Objects and Visual Features for Multi-object Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "In Simultaneous Localization and Mapping (SLAM), Loop Closure Detection (LCD) is essential to minimize drift when recognizing previously visited places. Visual Bag- of-Words (vBoW) has been an LCD algorithm of choice for many state-of-the-art SLAM systems. It uses a set of visual features to provide robust place recognition but fails to perceive the semantics or spatial relationship between feature points. Previous work has mainly focused on addressing these issues by combining vBoW with semantic and spatial information from objects in the scene. However, they are unable to exploit spatial information of local visual features and lack a structure that unifies semantic objects and visual features, therefore limiting the symbiosis between the two components. This paper proposes SymbioLCD2, which creates a unified graph structure to integrate semantic objects and visual features symbiotically. Our novel graph-based LCD system utilizes the unified graph structure by applying a Weisfeiler-Lehman graph kernel with temporal constraints to robustly predict loop closure candidates. Evaluation of the proposed system shows that having a unified graph structure incorporating semantic objects and visual features improves LCD prediction accuracy, illustrating that the proposed graph structure provides a strong symbiosis between these two complementary components. It also outperforms other Machine Learning algorithms - such as SVM, Decision Tree, Random Forest, Neural Network and GNN based Graph Matching Networks. Furthermore, it has shown good performance in detecting loop closure candidates earlier than state-of-the-art SLAM systems, demonstrating that extended semantic and spatial awareness from the unified graph structure significantly impacts LCD performance.",
        "primary_area": "",
        "author": "Jonathan J.Y. Kim;Martin Urschler;Patricia J. Riddle;Jorg S. Wicker;Jonathan J.Y. Kim;Martin Urschler;Patricia J. Riddle;Jorg S. Wicker",
        "authorids": "/37089195032;/37392041500;/37565812900;/37087404551;/37089195032;/37392041500;/37565812900;/37087404551",
        "aff": "Callaghan Innovation, New Zealand; School of Computer Science, University of Auckland, New Zealand; School of Computer Science, University of Auckland, New Zealand; School of Computer Science, University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981542/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8595582051213019842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Callaghan Innovation;University of Auckland",
        "aff_unique_dep": ";School of Computer Science",
        "aff_unique_url": "https://www.callaghaninnovation.govt.nz;https://www.auckland.ac.nz",
        "aff_unique_abbr": ";UoA",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Auckland",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9981565",
        "title": "Cloud-Edge Training Architecture for Sim-to-Real Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) is a promising approach to solve complex control tasks by learning policies through interactions with the environment. However, the training of DRL policies requires large amounts of training experiences, making it impractical to learn the policy directly on physical systems. Sim-to-real approaches leverage simulations to pretrain DRL policies and then deploy them in the real world. Unfortunately, the direct real-world deployment of pretrained policies usually suffers from performance deterioration due to the different dynamics, known as the reality gap. Recent sim-to-real methods, such as domain randomization and domain adaptation, focus on improving the robustness of the pretrained agents. Nevertheless, the simulation-trained policies often need to be tuned with real-world data to reach optimal performance, which is challenging due to the high cost of real-world samples. This work proposes a distributed cloud-edge architecture to train DRL agents in the real world in real-time. In the architecture, the inference and training are assigned to the edge and cloud, separating the real-time control loop from the computationally expensive training loop. To overcome the reality gap, our architecture exploits sim-to-real transfer strategies to continue the training of simulation-pretrained agents on a physical system. We demonstrate its applicability on a physical inverted-pendulum control system, analyzing critical parameters. The real-world experiments show that our architecture can adapt the pretrained DRL agents to unseen dynamics consistently and efficiently.11A video showing a real-world training process under the proposed method can be found from https://youtu.be/hMY9-c0SST0.",
        "primary_area": "",
        "author": "Hongpeng Cao;Mirco Theile;Federico G. Wyrwal;Marco Caccamo;Hongpeng Cao;Mirco Theile;Federico G. Wyrwal;Marco Caccamo",
        "authorids": "/37089663239;/37086532277;/37089662646;/37272874700;/37089663239;/37086532277;/37089662646;/37272874700",
        "aff": "Technical University of Munich (TUM), School of Engineering and Design, Munich, Germany; Technical University of Munich (TUM), School of Engineering and Design, Munich, Germany; Technical University of Munich (TUM), School of Engineering and Design, Munich, Germany; Technical University of Munich (TUM), School of Engineering and Design, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981565/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2486725997639599140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "School of Engineering and Design",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982276",
        "title": "CloudAttention: Efficient Multi-Scale Attention Scheme For 3D Point Cloud Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Processing 3D data efficiently has always been a challenge. Spatial operations on large-scale point clouds, stored as sparse data, require extra cost. Attracted by the success of transformers, researchers are using multi-head attention for vision tasks. However, attention calculations in transformers come with quadratic complexity in the number of inputs and miss spatial intuition on sets like point clouds. We redesign set transformers in this work and incorporate them into a hierarchical framework for shape classification and part and scene segmentation. We propose our local attention unit, which captures features in a spatial neighborhood. We also compute efficient and dynamic global cross attentions by leveraging sampling and grouping at each iteration. Finally, to mitigate the non-heterogeneity of point clouds, we propose an efficient Multi-Scale Tokenization (MST), which extracts scale-invariant tokens for attention operations. The proposed hierarchical model achieves state-of-the-art shape classification in mean accuracy and yields results on par with the previous segmentation methods while requiring significantly fewer computations. Our proposed architecture predicts segmentation labels with around half the latency and parameter count of the previous most effi-cient method with comparable performance. The code is available at https://github.com/YigeWang-WHU/CloudAttention.",
        "primary_area": "",
        "author": "Mahdi Saleh;Yige Wang;Nassir Navab;Benjamin Busam;Federico Tombari;Mahdi Saleh;Yige Wang;Nassir Navab;Benjamin Busam;Federico Tombari",
        "authorids": "/37086832879;/37089664101;/37282965500;/37085664553;/37593332100;/37086832879;/37089664101;/37282965500;/37085664553;/37593332100",
        "aff": "Faculty of Computer Science, Technische Universit\u00e4t M\u00fcnchen (TUM), Garching bei M\u00fcnchen, Germany; Faculty of Computer Science, Technische Universit\u00e4t M\u00fcnchen (TUM), Garching bei M\u00fcnchen, Germany; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Faculty of Computer Science, Technische Universit\u00e4t M\u00fcnchen (TUM), Garching bei M\u00fcnchen, Germany; Google, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982276/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1097539853067291983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Johns Hopkins University;Google",
        "aff_unique_dep": "Faculty of Computer Science;Department of Computer Science;Google",
        "aff_unique_url": "https://www.tum.de;https://www.jhu.edu;https://www.google.ch",
        "aff_unique_abbr": "TUM;JHU;Google",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Garching bei M\u00fcnchen;Baltimore;Zurich",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "Germany;United States;Switzerland"
    },
    {
        "id": "9981825",
        "title": "Co-optimization of Acrobot Design and Controller for Increased Certifiable Stability",
        "track": "main",
        "status": "Poster",
        "abstract": "Unlike fully actuated systems, the control of underactuated robots necessitates the use of passive dynamics to fulfill control objectives. Hence, there is an increased interdependence between their design parameters and the closed loop performance. This paper proposes a novel approach for co-optimization of robot design and controller parameters for increased certifiable stability obtained with means of region of attraction analysis and gradient free optimization. In particular, it discusses the co-optimization problem of a gymnastic acrobot robot where the design and the controller are optimized to have a large region of attraction (ROA) taking into account the closed loop dynamics of the non-linear system stabilized by a linear quadratic regulator (LQR) controller. The results are validated by extensive simulation of the acrobot's closed loop dynamics.",
        "primary_area": "",
        "author": "Lasse Jenning Maywald;Felix Wiebe;Shivesh Kumar;Mahdi Javadi;Frank Kirchner;Lasse Jenning Maywald;Felix Wiebe;Shivesh Kumar;Mahdi Javadi;Frank Kirchner",
        "authorids": "/37089662407;/37089660513;/37085850436;/37089663141;/37283559600;/37089662407;/37089660513;/37085850436;/37089663141;/37283559600",
        "aff": "Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Department of Mathematics and Computer Science, AG Robotics, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981825/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11775327694471698775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "DFKI GmbH;University of Bremen",
        "aff_unique_dep": "Robotics Innovation Center;Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.dfki.de;https://www.uni-bremen.de",
        "aff_unique_abbr": "DFKI;Uni Bremen",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981479",
        "title": "CoMBiNED: Multi-Constrained Model Based Planning for Navigation in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent deep reinforcement learning (DRL) approaches have achieved high success rate in map-less dynamic obstacle avoidance tasks. However, navigation in unseen dynamic scenarios without a pre-built map in the presence of dynamic obstacles still remains an open challenge. Since, learning accurate models for complex robotic scenarios such as navigation directly from high dimensional sensory measurements requires a large amount of data and training. Furthermore, even a small change on robot configuration such as kino-dynamics or sensor in the inference time requires re-training of the policy. In this paper, we address these issues in a principled fashion through a multi-constraint model based online planning (CoMBiNED) framework that does not require any retraining or modifications on the existing policy. We disentangle the given task into sub-tasks and learn dynamical models for them. Treating these dynamical models as soft-constraints, we employ stochastic optimisation to jointly optimize these sub-tasks on-the-fly at the inference time. We consider navigation as central application in this work and evaluate our approach on publicly available benchmark with complex dynamic scenarios and achieved significant improvement over recent approaches both in the cases of with-and-without given map of the environment.",
        "primary_area": "",
        "author": "Harit Pandya;Rudra P.K. Poudel;Stephan Liwicki;Harit Pandya;Rudra P.K. Poudel;Stephan Liwicki",
        "authorids": "/37085346690;/37088637865;/38487494500;/37085346690;/37088637865;/38487494500",
        "aff": "Toshiba Research, Cambridge, UK; Toshiba Research, Cambridge, UK; Toshiba Research, Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981479/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:cdF8eWHDwSgJ:scholar.google.com/&scioq=CoMBiNED:+Multi-Constrained+Model+Based+Planning+for+Navigation+in+Dynamic+Environments&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Toshiba Research Europe Limited",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toshiba-research.eu",
        "aff_unique_abbr": "TREL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982041",
        "title": "Cola-HRL: Continuous-Lattice Hierarchical Reinforcement Learning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has shown promising performance in autonomous driving applications in recent years. The early end-to-end RL method is usually unexplainable and fails to generate stable actions, while the hierarchical RL (HRL) method can tackle the above issues by dividing complex problems into multiple sub-tasks. Prior HRL works either select discrete driving behaviors with continuous control commands, or generate expected goals for the low-level controller. However, they typically have strong scenario dependence or fail to generate goals with good quality. To address the above challenges, we propose a Continuous-Lattice Hierarchical RL (Cola-HRL) method for autonomous driving tasks to make high-quality decisions in various scenarios. We utilize the continuous-lattice module to generate reasonable goals, ensuring temporal and spatial reachability. Then, we train and evaluate our method under different traffic scenarios based on real-world High Definition maps. Experimental results show our method can handle multiple scenarios. In addition, our method also demonstrates better performance and driving behaviors compared to existing RL methods.",
        "primary_area": "",
        "author": "Lingping Gao;Ziqing Gu;Cong Qiu;Lanxin Lei;Shengbo Eben Li;Sifa Zheng;Wei Jing;Junbo Chen;Lingping Gao;Ziqing Gu;Cong Qiu;Lanxin Lei;Shengbo Eben Li;Sifa Zheng;Wei Jing;Junbo Chen",
        "authorids": "/37089196389;/37088073917;/37089196838;/37089197195;/38184217700;/37086475843;/37089852321;/37089196396;/37089196389;/37088073917;/37089196838;/37089197195;/38184217700;/37086475843;/37089852321;/37089196396",
        "aff": "Alibaba Group, Hangzhou, China; State Key Lab of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; State Key Lab of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Lab of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982041/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12340311991761077693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;1;0;0",
        "aff_unique_norm": "Alibaba Group;Tsinghua University",
        "aff_unique_dep": ";School of Vehicle and Mobility",
        "aff_unique_url": "https://www.alibaba.com;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Alibaba;THU",
        "aff_campus_unique_index": "0;1;0;0;1;1;0;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981547",
        "title": "Collaborative Navigation-Aware Coverage in Feature-Poor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi agent coverage and robot navigation are two very important research fields within robotics. However, their intersection has received limited attention. In multi agent coverage, perfect navigation is often assumed, and in robot navigation, the focus is often to minimize the localization error with the aid of stationary features from the environment. The need for integration of the two becomes clear in environments with very sparse features or landmarks, for example when a group of Autonomous Underwater Vehicles (AUVs) are to search a uniform seafloor for mines or other dangerous objects. In such environments, localization systems are often deprived of detectable features to use that could increase their accuracy. In this paper we propose an algorithm for doing navigation aware multi agent coverage in areas with no landmarks. Instead of using identical lawn mower patterns, we propose to mirror every other pattern to enable the agents to meet up and make inter-agent measurements and share information regularly. This improves performance in two ways, global drift in relation to the area to be covered is reduced, and local coverage gaps between adjacent patterns are reduced. Further, we show that this can be accomplished within the constraints of very limited sensing, computing and communication resources that most AUVs have available. The effectiveness of our method is shown through statistically significant simulated experiments.",
        "primary_area": "",
        "author": "\u00d6zer \u00d6zkahraman;Petter \u00d6gren;\u00d6zer \u00d6zkahraman;Petter \u00d6gren",
        "authorids": "/37086852374;/37275141600;/37086852374;/37275141600",
        "aff": "\u00d6zer \u00d6zkahraman; Petter \u00d6gren",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981547/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=366070754954827437&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Petter \u00d6gren",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981426",
        "title": "Collaborative Teleoperation with Haptic Feedback for Collision-Free Navigation of Ground Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a collaborative teleoperation algorithm which utilizes haptic force feedback to guide users around oncoming obstacles while accounting for non-holonomic constraints. The proposed algorithm predicts the user's goal, plans a path using a modified RRT* algorithm to the predicted goal, and provides haptic guidance to the path and away from obstacles when the user is in an unsafe pose. We show that the vehicle cannot collide with obstacles under the proposed algorithm following the haptic commands. We assess the per-formance of our algorithm with a virtual pilot in simulations and hardware experiments, demonstrating its ability to prevent collisions while reaching the goal location. Additionally, we demonstrate human-in-the-loop navigation with a Geomagic Touch haptic device providing force feedback to the user. These simulations and experiments show that the proposed haptic guidance system is a useful and effective tool for co-navigation of non-holonomic vehicles via teleoperation.",
        "primary_area": "",
        "author": "Mela Coffey;Alyssa Pierson;Mela Coffey;Alyssa Pierson",
        "authorids": "/37088336178;/37085345711;/37088336178;/37085345711",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981426/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8564931916283468294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981622",
        "title": "Collective Decision Making in Communication-Constrained Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main tasks for autonomous robot swarms is to collectively decide on the best available option. Achieving that requires a high quality communication between the agents that may not always be available in a real world environment. In this paper we introduce the communication-constrained collective decision-making problem where some areas of the environment limit the agents' ability to communicate, either by reducing success rate or blocking the communication channels. We propose a decentralised algorithm for mapping environmental features for robot swarms as well as improving collective decision making in communication-limited environments without prior knowledge of the communication landscape. Our results show that making a collective aware of the communication environment can improve the speed of convergence in the presence of communication limitations, at least 3 times faster, without sacrificing accuracy.",
        "primary_area": "",
        "author": "Thomas G. Kelly;Mohammad Divband Soorati;Klaus-Peter Zauner;Sarvapali D. Ramchurn;Danesh Tarapore;Thomas G. Kelly;Mohammad Divband Soorati;Klaus-Peter Zauner;Sarvapali D. Ramchurn;Danesh Tarapore",
        "authorids": "/37089663813;/37086204877;/37303965600;/37284873800;/37086275308;/37089663813;/37086204877;/37303965600;/37284873800;/37086275308",
        "aff": "School of Electronics and Computer Science, University of Southampton, Southampton, UK; School of Electronics and Computer Science, University of Southampton, Southampton, UK; School of Electronics and Computer Science, University of Southampton, Southampton, UK; School of Electronics and Computer Science, University of Southampton, Southampton, UK; School of Electronics and Computer Science, University of Southampton, Southampton, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981622/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12762109576701701099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southampton",
        "aff_unique_dep": "School of Electronics and Computer Science",
        "aff_unique_url": "https://www.southampton.ac.uk",
        "aff_unique_abbr": "Southampton",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Southampton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982019",
        "title": "Collective Decision-Making with Bayesian Robots in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Collective decision-making enables self-organizing robot swarms to act autonomously on a swarm level and is essential to coordinate their actions as a whole. When robots only share and communicate information locally a distributed and decentralized approach is required. In a previous paper [4], an efficient method based on a distributed Bayesian algorithm was created to distinguish a binary environment. We extended it to have the capability of dealing with dynamic environments. Therefore, it must avoid global lock-in states. In many realistic applications the robot swarm needs to adapt to (collectively) measurable changes at runtime by revising previous collective decisions. The trade-off between decision-making speed and readiness to revise previous decisions is a seemingly unavoidable challenge. We present our extension of the former approach and study how this trade-off can efficiently be balanced.",
        "primary_area": "",
        "author": "Kai Pfister;Heiko Hamann;Kai Pfister;Heiko Hamann",
        "authorids": "/37089662161;/37683321200;/37089662161;/37683321200",
        "aff": "Institute of Computer Engineering, University of Luebeck, Germany; Institute of Computer Engineering, University of Luebeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982019/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3999793610101541571&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Luebeck",
        "aff_unique_dep": "Institute of Computer Engineering",
        "aff_unique_url": "https://www.uni-luebeck.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981151",
        "title": "Collision and Rollover-Free g2 Path Planning for Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a path planning refinement technique that allows the efficient collision and rollover-free motion planning for mobile manipulator robots working on rough terrain. First, the necessary theoretical background on a mobile manipulator's kinematics and dynamic stability measure is introduced. Then, after the brief introduction of the sampling-based path planning problem, the additional refinement stage and its problem formulation will be introduced. Within the refinement stage, the novel B\u00e9zier control point addition method is introduced to allow for fast, collision and rollover-free path smoothing using curvature-continuous parametrized curves. Analytical proofs and simulated comparisons are provided in the paper to show effectiveness. The beneficial effect of the refined path on trajectory planning will also be demonstrated through simulation.",
        "primary_area": "",
        "author": "Jiazhi Song;Inna Sharf;Jiazhi Song;Inna Sharf",
        "authorids": "/37087105850;/37283633500;/37087105850;/37283633500",
        "aff": "Jiazhi Song; Inna Sharf",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981151/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17963763138427830485&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981767",
        "title": "Collision detection and identification for a legged manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "To safely deploy legged robots in the real world it is necessary to provide them with the ability to reliably detect unexpected contacts and accurately estimate the corresponding contact force. In this paper, we propose a collision detection and identification pipeline for a quadrupedal manipulator. We first introduce an approach to estimate the collision time span based on band-pass filtering and show that this information is key for obtaining accurate collision force estimates. We then improve the accuracy of the identified force magnitude by compensating for model inaccuracies, unmodeled loads, and any other potential source of quasi-static disturbances acting on the robot. We validate our framework with extensive hardware experiments in various scenarios, including trotting and additional unmodeled load on the robot.",
        "primary_area": "",
        "author": "Jessie Van Dam;Andreea Tulbure;Maria Vittoria Minniti;Firas Abi-Farraj;Marco Hutter;Jessie Van Dam;Andreea Tulbure;Maria Vittoria Minniti;Firas Abi-Farraj;Marco Hutter",
        "authorids": "/37089659212;/37086133908;/37086923041;/37086034393;/37545251000;/37089659212;/37086133908;/37086923041;/37086034393;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981767/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8535344927526797527&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981870",
        "title": "Collision-Aware Fast Simulation for Soft Robots by Optimization-Based Geometric Computing",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots can safely interact with environments because of their mechanical compliance. Self-collision is also employed in the modern design of soft robots to enhance their performance during different tasks. However, developing an efficient and reliable simulator that can handle the collision response well, is still a challenging task in the research of soft robotics. This paper presents a collision-aware simulator based on geometric optimization, in which we develop a highly efficient and realistic collision checking / response model incorporating a hyperelastic material property. Both actuated deformation and collision response for soft robots are formulated as geometry-based objectives. The collision-free body of a soft robot can be obtained by minimizing the geometry-based objective function. Unlike the FEA-based physical simulation, the proposed pipeline performs a much lower computational cost. Moreover, adaptive remeshing is applied to achieve the improvement of the convergence when dealing with soft robots that have large volume variations. Experimental tests are conducted on different soft robots to verify the performance of our approach.",
        "primary_area": "",
        "author": "Guoxin Fang;Yingjun Tian;Andrew Weightman;Charlie C.L. Wang;Guoxin Fang;Yingjun Tian;Andrew Weightman;Charlie C.L. Wang",
        "authorids": "/37086103358;/37088908192;/37891948500;/37538386600;/37086103358;/37088908192;/37891948500;/37538386600",
        "aff": "Faculty of Industrial Design Engineering, Delft University of Technology, The Netherlands; Department of Mechanical, Aerospace and Civil Engineering, The University of Manchester, United Kingdoms; Department of Mechanical, Aerospace and Civil Engineering, The University of Manchester, United Kingdoms; Department of Mechanical, Aerospace and Civil Engineering, The University of Manchester, United Kingdoms",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981870/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9500075514152668826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Delft University of Technology;University of Manchester",
        "aff_unique_dep": "Faculty of Industrial Design Engineering;Department of Mechanical, Aerospace and Civil Engineering",
        "aff_unique_url": "https://www.tudelft.nl;https://www.manchester.ac.uk",
        "aff_unique_abbr": "TU Delft;UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Netherlands;United Kingdom"
    },
    {
        "id": "9981138",
        "title": "Collision-free Minimum-time Trajectory Planning for Multiple Vehicles based on ADMM",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper presents a practical approach for planning trajectories for multiple vehicles where both collision avoidance and minimum travelling time are simultaneously considered. It is first proposed to exploit the mixed-integer programming (MIP) approach to formulate the collision avoidance paradigm, where the linear dynamic models are utilized to derive the linear constraints. Moreover, travelling time of each vehicle is compromised among them and set to be minimized so that all the vehicles can practically reach the expected destinations at the shortest time. Unfortunately, the formulated optimization problem is NP-hard. In order to effectively address it, we propose to employ the alternating direction method of multipliers (ADMM), which can share the computational burdens to distributive optimization solvers. Thus, the proposed method can enable each vehicle to obtain an expected trajectory in a practical time. Convergence of the proposed algorithm is also discussed. To verify effectiveness of our approach, we implemented it in a numerical example, where the obtained results are highly promising.",
        "primary_area": "",
        "author": "Thanh Binh Nguyen;Thang Nguyen;Truong Nghiem;Linh Nguyen;Jose Baca;Pablo Rangel;Hyoung-Kyu Song;Thanh Binh Nguyen;Thang Nguyen;Truong Nghiem;Linh Nguyen;Jose Baca;Pablo Rangel;Hyoung-Kyu Song",
        "authorids": "/37089662042;/37073022700;/37897179500;/37085341217;/37592344100;/443550242963949;/37270117500;/37089662042;/37073022700;/37897179500;/37085341217;/37592344100;/443550242963949;/37270117500",
        "aff": "Department of Information Communication Engineering, Convergence Engineering for Intelligent Drone, Sejong University, Seoul, Korea; Department of Engineering, Texas A&M University-Corpus Christi, Corpus Christi, TX, USA; School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, AZ, USA; School of Engineering, Information Technology and Physical Sciences, Federation University Australia, Churchill, VIC, Australia; Department of Engineering, Texas A&M University-Corpus Christi, Corpus Christi, TX, USA; Department of Engineering, Texas A&M University-Corpus Christi, Corpus Christi, TX, USA; Department of Information Communication Engineering, Convergence Engineering for Intelligent Drone, Sejong University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981138/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14170789170055506839&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;1;1;0",
        "aff_unique_norm": "Sejong University;Texas A&M University-Corpus Christi;Northern Arizona University;Federation University Australia",
        "aff_unique_dep": "Department of Information Communication Engineering;Department of Engineering;School of Informatics, Computing, and Cyber Systems;School of Engineering, Information Technology and Physical Sciences",
        "aff_unique_url": "http://www.sejong.ac.kr;https://www.tamucc.edu;https://nau.edu;https://www.federation.edu.au",
        "aff_unique_abbr": "Sejong;TAMU-CC;NAU;FedUni",
        "aff_campus_unique_index": "0;1;2;3;1;1;0",
        "aff_campus_unique": "Seoul;Corpus Christi;Flagstaff;Churchill",
        "aff_country_unique_index": "0;1;1;2;1;1;0",
        "aff_country_unique": "South Korea;United States;Australia"
    },
    {
        "id": "9981480",
        "title": "Colonoscopy Navigation using End-to-End Deep Visuomotor Control: A User Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible Endoscopes (FEs) for colonoscopy present several limitations due to their inherent complexity, resulting in patient discomfort and lack of intuitiveness for clinicians. Robotic FEs with autonomous control represent a viable solution to reduce the workload of endoscopists and the training time while improving the procedure outcome. Prior works on autonomous endoscope FE control use heuristic policies that limit their generalisation to the unstructured and highly deformable colon environment and require frequent human intervention. This work proposes an image-based FE control using Deep Reinforcement Learning, called Deep Visuomotor Control (DVC), to exhibit adaptive behaviour in convoluted sections of the colon. DVC learns a mapping between the images and the FE control signal. A first user study of 20 expert gastrointestinal endoscopists was carried out to compare their navigation performance with DVC using a realistic virtual simulator. The results indicate that DVC shows equivalent performance on several assessment parameters, being more safer. Moreover, a second user study with 20 novice users was performed to demonstrate easier human supervision compared to a state-of-the-art heuristic control policy. Seamless supervision of colonoscopy procedures would enable endoscopists to focus on the medical decision rather than on the control of FE.",
        "primary_area": "",
        "author": "Ameya Pore;Martina Finocchiaro;Diego Dall'Alba;Albert Hernansanz;Gastone Ciuti;Alberto Arezzo;Arianna Menciassi;Alicia Casals;Paolo Fiorini;Ameya Pore;Martina Finocchiaro;Diego Dall'Alba;Albert Hernansanz;Gastone Ciuti;Alberto Arezzo;Arianna Menciassi;Alicia Casals;Paolo Fiorini",
        "authorids": "/37088506135;/37089001267;/37089663908;/37947814300;/37394078700;/38233742700;/37280284800;/37277266200;/37279139000;/37088506135;/37089001267;/37089663908;/37947814300;/37394078700;/38233742700;/37280284800;/37277266200;/37279139000",
        "aff": "Department of Enginyeria de Sistemas, Automatica i Informatica Industrial, Univiversitat Politecnica de Catalunya, Barcelona, Spain; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Computer Science, University of Verona, Italy; Department of Enginyeria de Sistemas, Automatica i Informatica Industrial, Univiversitat Politecnica de Catalunya, Barcelona, Spain; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Surgical Sciences, University of Torino, Turin, Italy; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Enginyeria de Sistemas, Automatica i Informatica Industrial, Univiversitat Politecnica de Catalunya, Barcelona, Spain; Department of Computer Science, University of Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981480/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8066627406955780481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;1;3;1;0;2",
        "aff_unique_norm": "Universitat Politecnica de Catalunya;Scuola Superiore Sant'Anna;University of Verona;University of Torino",
        "aff_unique_dep": "Department of Enginyeria de Sistemes, Automatica i Informatica Industrial;The BioRobotics Institute;Department of Computer Science;Department of Surgical Sciences",
        "aff_unique_url": "https://www.upc.edu;https://www.sssup.it;https://www.univr.it;https://www.unito.it",
        "aff_unique_abbr": "UPC;SSSA;;UniTO",
        "aff_campus_unique_index": "0;1;0;1;3;1;0",
        "aff_campus_unique": "Barcelona;Pisa;;Turin",
        "aff_country_unique_index": "0;1;1;0;1;1;1;0;1",
        "aff_country_unique": "Spain;Italy"
    },
    {
        "id": "9981699",
        "title": "Communication-Preserving Bids in Market-Based Task Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the effects of impaired communications on the performances of auction-based task allocation in a dynamic surveillance scenario. We propose a novel connectivity term to include in the bid valuation formula, that aims at improving communications in the multi-robot team. We evaluate our method as well as another state-of-the-art method using robot inter-distance to maintain communication, on randomly generated scenarios and on a real-world scenario. We demonstrate that including our connectivity term in the bid valuation formula improves the performances of the auction scheme.",
        "primary_area": "",
        "author": "Felix Quinton;Christophe Grand;Charles Lesire;Felix Quinton;Christophe Grand;Charles Lesire",
        "authorids": "/37086537807;/38335131900;/38275129600;/37086537807;/38335131900;/38275129600",
        "aff": "ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981699/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11393225219801270942&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ONERA",
        "aff_unique_dep": "DTIS",
        "aff_unique_url": "https://www.onera.fr",
        "aff_unique_abbr": "ONERA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981720",
        "title": "Compact Strawberry Harvesting Tube Employing Laser Cutter",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel prototype for hanging produce harvesting is presented, that is productive, versatile, and robust. In our methodology, the robot-mounted tube approaches, and eventually surrounds the produce of interest at the entry side, that can be as small as the produce diameter, plus a small margin. The stem is then cut by a laser beam, with the optics set up for a distant focal point. Such arrangement allows for minimal hardware at the produce-entry side and in turn, the interaction, and possible disturbance to the local environment. This is essential for fruit reachability and avoiding it dislocation. Experiments has been conducted to drive the laser power to time of cut relation, as well as successful demonstration to sample harvest strawberry.",
        "primary_area": "",
        "author": "Mohamed Sorour;P\u00e5L Johan From;Khaled Elgeneidy;Stratis Kanarachos;Mohamed Sallam;Mohamed Sorour;P\u00e5L Johan From;Khaled Elgeneidy;Stratis Kanarachos;Mohamed Sallam",
        "authorids": "/37085622077;/37571980700;/37086581226;/37085661715;/37073391200;/37085622077;/37571980700;/37086581226;/37085661715;/37073391200",
        "aff": "Robotics Group, Faculty of Science and Technology, Norwegian University of Life Sciences (NMBU), Norway; Robotics Group, Faculty of Science and Technology, Norwegian University of Life Sciences (NMBU), Norway; School of Engineering, Coventry University, Cairo, Egypt; School of Engineering, Coventry University, Cairo, Egypt; Department of Mechanical Engineering, Helwan University, Cairo, Egypt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981720/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5968090896621079167&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "Norwegian University of Life Sciences;Coventry University;Helwan University",
        "aff_unique_dep": "Faculty of Science and Technology;School of Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nmbu.no;https://www.coventry.ac.uk;https://www.helwan.edu.eg",
        "aff_unique_abbr": "NMBU;;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Cairo",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "Norway;Egypt"
    },
    {
        "id": "9981131",
        "title": "Comparative Model Evaluation with a Symmetric Three-Link Swimming Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present swimming and modeling for Trident, a three-link lamprey inspired robot that is able to climb on flat smooth walls. We explore two gaits proposed to work for linear swimming, and three gaits for turning maneuvers. We compare the experimental results obtained from these swimming experiments with two different reduced order fluid interaction models, one a previously published potential flow model, and the other a slender cylinder model we developed. We find that depending on the the parameters of swimming chosen, we are able to move forward, backward and sideways with a peak speed of 2.5 cm/s. We identify the conditions when these models apply and aspects that will require additional complexity.",
        "primary_area": "",
        "author": "Brian J. Van Stratum;Max P. Austin;Kourosh Shoele;Jonathan E. Clark;Brian J. Van Stratum;Max P. Austin;Kourosh Shoele;Jonathan E. Clark",
        "authorids": "/37089659441;/37086355499;/37085361247;/37533408500;/37089659441;/37086355499;/37085361247;/37533408500",
        "aff": "FAMU/FSU College of Engineering, Tallahassee, FL; FAMU/FSU College of Engineering, Tallahassee, FL; FAMU/FSU College of Engineering, Tallahassee, FL; FAMU/FSU College of Engineering, Tallahassee, FL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981131/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6152635643029039353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Florida A&M University - Florida State University College of Engineering",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "http://www.famu-fsu.edu",
        "aff_unique_abbr": "FAMU/FSU CoE",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981495",
        "title": "Comparing Human Haptic Perception and Robotic Force/Torque Sensing in a Simulated Surgical Palpation Task",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Timo Markert;Sebastian Matich;Elias Hoerner;Jonas Pfannes;Andreas Theissler;Martin Atzmueller;Timo Markert;Sebastian Matich;Elias Hoerner;Jonas Pfannes;Andreas Theissler;Martin Atzmueller",
        "authorids": "/37089171890;/37085470402;/37089168765;/37089662078;/37086252870;/37828624700;/37089171890;/37085470402;/37089168765;/37089662078;/37086252870;/37828624700",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981495/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=739250444974995704&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "9981533",
        "title": "Comparing Reconstruction- and Contrastive-based Models for Visual Task Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning state representations enables robotic planning directly from raw observations such as images. Several methods learn state representations by utilizing losses based on the reconstruction of the raw observations from a lower-dimensional latent space. The similarity between observations in the space of images is often assumed and used as a proxy for estimating similarity between the underlying states of the system. However, observations commonly contain task-irrelevant factors of variation which are nonetheless important for reconstruction, such as varying lighting and different camera viewpoints. In this work, we define relevant evaluation metrics and perform a thorough study of different loss functions for state representation learning. We show that models exploiting task priors, such as Siamese networks with a simple contrastive loss, outperform reconstruction-based representations in visual task planning in case of task-irrelevant factors of variations.",
        "primary_area": "",
        "author": "Constantinos Chamzas;Martina Lippi;Michael C. Welle;Anastasia Varava;Lydia E. Kavraki;Danica Kragic;Constantinos Chamzas;Martina Lippi;Michael C. Welle;Anastasia Varava;Lydia E. Kavraki;Danica Kragic",
        "authorids": "/37086933748;/37086443839;/38202265300;/37086619259;/37279015600;/37281296000;/37086933748;/37086443839;/38202265300;/37086619259;/37279015600;/37281296000",
        "aff": "Rice University, Houston, TX, USA; Roma Tre University, Roma, RM, Italy; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; Rice University, Houston, TX, USA; KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981533/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10142378463456580373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 17,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;2",
        "aff_unique_norm": "Rice University;Roma Tre University;KTH Royal Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.rice.edu;https://www.uniroma3.it;https://www.kth.se",
        "aff_unique_abbr": "Rice;Roma Tre;KTH",
        "aff_campus_unique_index": "0;1;2;2;0;2",
        "aff_campus_unique": "Houston;Roma;Stockholm",
        "aff_country_unique_index": "0;1;2;2;0;2",
        "aff_country_unique": "United States;Italy;Sweden"
    },
    {
        "id": "9982275",
        "title": "Comparison of EKF-Based Floating Base Estimators for Humanoid Robots with Flat Feet",
        "track": "main",
        "status": "Poster",
        "abstract": "Extended Kalman filtering is a common approach to achieve floating base estimation of a humanoid robot. These filters rely on measurements from an Inertial Measurement Unit (IMU) and relative forward kinematics for estimating the base position-and-orientation and its linear velocity along with the augmented states of feet position-and-orientation. We refer to such filters as flat-foot filters. However, the availability of only partial measurements often poses the question of consistency in the filter design. In this paper, we perform an experimental comparison of state-of-the-art flat-foot filters based on the representation choice of state, observation, matrix Lie group error and system dynamics evaluated for filter consistency and trajectory errors. The comparison is performed over simulated and real-world experiments conducted on the iCub humanoid platform. It is observed that filters on Lie groups that exploit properties of invariant filtering tend to perform better as consistent estimators while discrete-time filters in general provide higher accuracy along observable directions.",
        "primary_area": "",
        "author": "Prashanth Ramadoss;Giulio Romualdi;Stefano Dafarra;Silvio Traversaro;Daniele Pucci;Prashanth Ramadoss;Giulio Romualdi;Stefano Dafarra;Silvio Traversaro;Daniele Pucci",
        "authorids": "/37087983620;/37086598289;/37086168241;/37085503650;/37706167200;/37087983620;/37086598289;/37086168241;/37085503650;/37706167200",
        "aff": "DIBRIS, University of Genoa, Genoa, Italy; DIBRIS, University of Genoa, Genoa, Italy; Artificial and Mechanical Intelligence, Italian Institute of Technology, Genoa, Italy; Artificial and Mechanical Intelligence, Italian Institute of Technology, Genoa, Italy; Artificial and Mechanical Intelligence, Italian Institute of Technology, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982275/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:E1lKGXRGuRwJ:scholar.google.com/&scioq=Comparison+of+EKF-Based+Floating+Base+Estimators+for+Humanoid+Robots+with+Flat+Feet&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "University of Genoa;Italian Institute of Technology",
        "aff_unique_dep": "DIBRIS;Artificial and Mechanical Intelligence",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981991",
        "title": "Competency Assessment for Autonomous Agents using Deep Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous agents to act as trustworthy partners to human users, they must be able to reliably communicate their competency for the tasks they are asked to perform. Towards this objective, we develop probabilistic world models based on deep generative modelling that allow for the simulation of agent trajectories and accurate calculation of tasking outcome probabilities. By combining the strengths of conditional variational autoencoders with recurrent neural networks, the deep generative world model can probabilistically forecast trajectories over long horizons to task completion. We show how these forecasted trajectories can be used to calculate outcome probability distributions, which enable the precise assessment of agent competency for specific tasks and initial settings.",
        "primary_area": "",
        "author": "Aastha Acharya;Rebecca Russell;Nisar R. Ahmed;Aastha Acharya;Rebecca Russell;Nisar R. Ahmed",
        "authorids": "/37089662584;/37087682958;/37533152500;/37089662584;/37087682958;/37533152500",
        "aff": "The Charles Stark Draper Laboratory, Inc., Cambridge, Massachusetts; The Charles Stark Draper Laboratory, Inc., Cambridge, Massachusetts; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981991/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17175186008174260693&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Charles Stark Draper Laboratory, Inc.;University of Colorado Boulder",
        "aff_unique_dep": ";Ann and H.J. Smead Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.draper.com;https://www.colorado.edu",
        "aff_unique_abbr": "Draper Lab;CU Boulder",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Cambridge;Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981757",
        "title": "Comprehensive Reactive Safety: No Need For A Trajectory If You Have A Strategy",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety guarantees in motion planning for autonomous driving typically involve certifying the trajectory to be collision-free under any motion of the uncontrollable participants in the environment, such as the human-driven vehicles on the road. As a result they usually employ a conservative bound on the behavior of such participants, such as reachability analysis. We point out that planning trajectories to rigorously avoid the entirety of the reachable regions is unnecessary and too restrictive, because observing the environment in the future will allow us to prune away most of them; disregarding this ability to react to future updates could prohibit solutions to scenarios that are easily navigated by human drivers. We propose to account for the autonomous vehicle's reactions to future environment changes by a novel safety framework, Comprehensive Reactive Safety. Validated in simulations in several urban driving scenarios such as unprotected left turns and lane merging, the resulting planning algorithm called Reactive ILQR demonstrates strong negotiation capabilities and better safety at the same time.",
        "primary_area": "",
        "author": "Fang Da;Fang Da",
        "authorids": "/37089449259;/37089449259",
        "aff": "QCraft Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981757/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6334993658121126691&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "QCraft Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982151",
        "title": "Computation and Selection of Secure Gravity Based Caging Grasps of Planar Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Gravity based caging grasps are robotic grasps where the robot hand passively supports an object against gravity. When a robot hand supports an object at a local minimum of the object gravitational energy, the robot hand forms a basket like grasp of the object. Any object movement in a basket grasp requires an increase of the object gravitational energy, thus allowing secure object pickup and transport with robot hands that use a small number fingers. The basket grasp depth measures the minimal additional energy the object must acquire to escape the basket grasp. This paper describes a computation scheme that determines the depth of entire sets of candidate basket grasps associated with alternative finger placements on the object boundary before pickup. The computation relies on categorization of escape stances that mark the basket grasp depth: double-support escapes are first analyzed and computed, then single-support escapes are analyzed and computed. The minimum energy combination of both types of escape stances defines the depth of entire sets of candidate basket grasps, which is then used to identify the deepest and hence most secure basket grasp. The computation scheme is fully implemented and demonstrated on several examples with reported run-times.",
        "primary_area": "",
        "author": "A. Shirizly;E. D. Rimon;A. Shirizly;E. D. Rimon",
        "authorids": "/37088640404;/37265270200;/37088640404;/37265270200",
        "aff": "Technion\u2014Israel Institute of Technology, Haifa, Israel; Technion\u2014Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982151/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14962510873172640222&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion\u2014Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981381",
        "title": "Conditional Patch-Based Domain Randomization: Improving Texture Domain Randomization Using Natural Image Patches",
        "track": "main",
        "status": "Poster",
        "abstract": "Using Domain Randomized synthetic data for training deep learning systems is a promising approach for addressing the data and the labeling requirements for supervised techniques to bridge the gap between simulation and the real world. We propose a novel approach for generating and applying class-specific Domain Randomization textures by using randomly cropped image patches from real-world data. In evaluation against the current Domain Randomization texture application techniques, our approach outperforms the highest performing technique by 4.94 AP and 6.71 AP when solving object detection and semantic segmentation tasks on the YCB-M [1] real-world robotics dataset. Our approach is a fast and inexpensive way of generating Domain Randomized textures while avoiding the need to handcraft texture distributions currently being used.",
        "primary_area": "",
        "author": "Mohammad Ani;Hector Basevi;Ale\u0161 Leonardis;Mohammad Ani;Hector Basevi;Ale\u0161 Leonardis",
        "authorids": "/37088854911;/37088401644;/38560304200;/37088854911;/37088401644;/38560304200",
        "aff": "This work was done while at the School of Computer Science, University of Birmingham, Birmingham, UK; School of Computer Science, University of Birmingham, Birmingham, UK; School of Computer Science, University of Birmingham, Birmingham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981381/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0Gb4W4BnjIMJ:scholar.google.com/&scioq=Conditional+Patch-Based+Domain+Randomization:+Improving+Texture+Domain+Randomization+Using+Natural+Image+Patches&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Birmingham",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Birmingham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981443",
        "title": "Conditional Visual Servoing for Multi-Step Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Servoing has been effectively used to move a robot into specific target locations or to track a recorded demonstration. It does not require manual programming, but it is typically limited to settings where one demonstration maps to one environment state. We propose a modular approach to extend visual servoing to scenarios with multiple demonstration sequences. We call this conditional servoing, as we choose the next demonstration conditioned on the observation of the robot. This method presents an appealing strategy to tackle multi-step problems, as individual demonstrations can be combined flexibly into a control policy. We propose different selection functions and compare them on a shape-sorting task in simulation. With the reprojection error yielding the best overall results, we implement this selection function on a real robot and show the efficacy of the proposed conditional servoing. For videos of our experiments, please check out our project page: https://lmb.informatik.uni-freiburg.de/projects/conditional_servoing/",
        "primary_area": "",
        "author": "Sergio Izquierdo;Max Argus;Thomas Brox;Sergio Izquierdo;Max Argus;Thomas Brox",
        "authorids": "/37089661728;/38252090800;/37541664500;/37089661728;/38252090800;/37541664500",
        "aff": "University of Zaragoza; University of Freiburg and members of Brain-Links-Brain-Tools; University of Freiburg and members of Brain-Links-Brain-Tools",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981443/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11480306689642679472&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Zaragoza;University of Freiburg",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unizar.es;https://www.uni-freiburg.de",
        "aff_unique_abbr": "UniZar;UoF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Spain;Germany"
    },
    {
        "id": "9981251",
        "title": "Confidence-rich Localization and Mapping based on Particle Filter for Robotic Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper mainly studies the localization and mapping of range sensing robots in the confidence-rich map (CRM) and then extends it to provide a full state estimate for information-theoretic exploration. Most previous works about active simultaneous localization and mapping and exploration always assumed the known robot poses or utilized inaccurate information metrics to approximate pose uncertainty, resulting in imbalanced exploration performance and efficiency in the unknown environment. This inspires us to extend the confidence-rich mutual information (CRMI) with measurable pose uncertainty. Specifically, we propose a Rao- Blackwellized particle filter-based localization and mapping scheme (RBPF -CLAM) for CRM, then we develop a new closed-form weighting method to improve the localization accuracy without scan matching. We further derive the uncertain CRMI (UCRMI) with the weighted particles by a more accurate approximation. Simulations and experimental evaluations show the localization accuracy and exploration performance of the proposed methods.",
        "primary_area": "",
        "author": "Yang Xu;Ronghao Zheng;Senlin Zhang;Meiqin Liu;Yang Xu;Ronghao Zheng;Senlin Zhang;Meiqin Liu",
        "authorids": "/37088835668;/37074209000;/37535987900;/37401511300;/37088835668;/37074209000;/37535987900;/37401511300",
        "aff": "State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981251/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8704755866512777961&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981764",
        "title": "Confined Water Body Coverage under Resource Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel algorithm for monitoring marine environments utilizing a resource-constrained robot. Collecting water quality data from large bodies of water is paramount for monitoring the ecosystem's health, particularly for predicting harmful cyanobacteria blooms. The large spatial dimensions of such bodies of water and the slow varying of water quality parameters make exhaustive, complete coverage impractical and unnecessary. This work explores a new strategy for efficiently measuring water quality quantities with an autonomous surface vehicle (ASV). The method utilizes the medial axis of the water body producing a guideline for the ASV trajectory that visits representative areas of the environment. The proposed method ensures data collection in the narrower parts of the lake, where researchers have historically observed harmful blooms while also visiting open water areas. It also presents an analysis of the Spatio-temporal sensitivity of the target sensor. A comparison with the traditional lawnmower algorithm demonstrates that the conventional BCD-based complete coverage method cannot sample the small coves of a lake. As such, we show that the proposed method captures more diverse regions of the area with a partial coverage technique. Offline analysis of several lakes and reservoirs and results from field deployments at Lake Murray, SC, USA, demonstrate the proposed method's effectiveness.",
        "primary_area": "",
        "author": "Ibrahim Salman;Jason Raiti;Nare Karapetyan;Archana Venkatachari;Annie Bourbonnais;Jason M. O'Kane;Ioannis Rekleitis;Ibrahim Salman;Jason Raiti;Nare Karapetyan;Archana Venkatachari;Annie Bourbonnais;Jason M. O'Kane;Ioannis Rekleitis",
        "authorids": "/37089649643;/37089658237;/37086299803;/37089646350;/37089646307;/37279835400;/37281356300;/37089649643;/37089658237;/37086299803;/37089646350;/37089646307;/37279835400;/37281356300",
        "aff": "Computer Science & Engineering Department, University of South Carolina, USA; Florida State University; University of Maryland, College Park; School of Earth, Ocean, and the Environment, University of South Carolina, USA; School of Earth, Ocean, and the Environment, University of South Carolina, USA; Computer Science & Engineering Department, University of South Carolina, USA; Computer Science & Engineering Department, University of South Carolina, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981764/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13289632600985743602&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;0",
        "aff_unique_norm": "University of South Carolina;Florida State University;University of Maryland",
        "aff_unique_dep": "Computer Science & Engineering Department;;",
        "aff_unique_url": "https://www.sc.edu;https://www.fsu.edu;https://www/umd.edu",
        "aff_unique_abbr": "USC;FSU;UMD",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";College Park;Columbia",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982018",
        "title": "Conflict-Based Search for Multi-Robot Motion Planning with Kinodynamic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot motion planning (MRMP) is the fundamental problem of finding non-colliding trajectories for multiple robots acting in an environment, under kinodynamic constraints. Due to its complexity, existing algorithms are either incomplete, or utilize simplifying assumptions. This work introduces Kinodynamic Conflict-Based Search (K-CBS), a decentralized MRMP algorithm that is general, scalable, and probabilistically complete. The algorithm takes inspiration from successful solutions to the discrete analogue of MRMP over finite graphs, known as Multi-Agent Path Finding (MAPF). Specifically, we adapt ideas from Conflict-Based Search (CBS)-a popular decentralized MAPF algorithm-to the MRMP setting. The novelty of our approach is that we work directly in the continuous domain, without discretization. In particular, the kinodynamic constraints are treated natively. K-CBS plans for each robot individually using a low-level planner and grows a conflict tree to resolve collisions between robots by defining constraints. The low-level planner can be any sampling-based, tree-search algorithm for kinodynamic robots, thus lifting existing planners for single robots to the multi-robot setting. We show that K-CBS inherits the (probabilistic) completeness of the low-level planner. We illustrate the generality and performance of K-CBS in several case studies and benchmarks.",
        "primary_area": "",
        "author": "Justin Kottinger;Shaull Almagor;Morteza Lahijanian;Justin Kottinger;Shaull Almagor;Morteza Lahijanian",
        "authorids": "/37089000996;/37089001811;/37398443600;/37089000996;/37089001811;/37398443600",
        "aff": "Dept. of Aerospace Engineering Sciences, University of Colorado Boulder, USA; The Henry and Marilyn Taub Faculty of Computer Science, Technion, Israel; Dept. of Computer Science, University of Colorado Boulder, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982018/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4856593899625628479&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Colorado Boulder;Technion",
        "aff_unique_dep": "Dept. of Aerospace Engineering Sciences;Faculty of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.cs.technion.ac.il",
        "aff_unique_abbr": "CU Boulder;Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9981184",
        "title": "Connected Reconfiguration of Polyominoes Amid Obstacles using RRT",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates using a sampling-based approach, the RRT*, to reconfigure a 2D set of connected tiles in complex environments, where multiple obstacles might be present. Since the target application is automated building of discrete, cellular structures using mobile robots, there are constraints that determine what tiles can be picked up and where they can be dropped off during reconfiguration. We compare our approach to two algorithms as global and local planners, and show that we are able to find more efficient build sequences using a reasonable amount of samples, in environments with varying degrees of obstacle space.",
        "primary_area": "",
        "author": "Javier Garcia;Michael Yannuzzi;Peter Kramer;Christian Rieck;Aaron T. Becker;Javier Garcia;Michael Yannuzzi;Peter Kramer;Christian Rieck;Aaron T. Becker",
        "authorids": "/37089271798;/37088505587;/37089658659;/37088506026;/37588897100;/37089271798;/37088505587;/37089658659;/37088506026;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Computer Science, TU Braunschweig, Braunschweig, Germany; Department of Computer Science, TU Braunschweig, Braunschweig, Germany; Department of Computer Science, TU Braunschweig, Braunschweig, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981184/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3395746182745990072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "University of Houston;TU Braunschweig",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.uh.edu;https://tu-braunschweig.de",
        "aff_unique_abbr": "UH;TUBS",
        "aff_campus_unique_index": "0;0;1;1;1",
        "aff_campus_unique": "Houston;Braunschweig",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9981827",
        "title": "Consensus-based Normalizing-Flow Control: A Case Study in Learning Dual-Arm Coordination",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop two consensus-based learning algorithms for multi-robot systems applied on complex tasks involving collision constraints and force interactions, such as the cooperative peg-in-hole placement. The proposed algorithms integrate multi-robot distributed consensus and normalizing-flow-based reinforcement learning. The algorithms guarantee the stability and the consensus of the multi-robot system's generalized variables in a transformed space. This transformed space is obtained via a diffeomorphic transformation parameterized by normalizing-flow models that the algorithms use to train the underlying task, learning hence skillful, dexterous trajectories required for the task accomplishment. We validate the proposed algorithms by parameterizing reinforcement learning policies, demonstrating efficient cooperative learning, and strong generalization of dual-arm assembly skills in a dynamics-engine simulator.",
        "primary_area": "",
        "author": "Hang Yin;Christos K. Verginis;Danica Kragic;Hang Yin;Christos K. Verginis;Danica Kragic",
        "authorids": "/37088353838;/37085751745;/37281296000;/37088353838;/37085751745;/37281296000",
        "aff": "CAS/RPL, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Electrical Engineering, Division of Signals and Systems, Uppsala University, Uppsala, Sweden; CAS/RPL, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981827/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6968144552182320826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Uppsala University",
        "aff_unique_dep": "CAS/RPL;Department of Electrical Engineering, Division of Signals and Systems",
        "aff_unique_url": "https://www.kth.se;https://www.uu.se",
        "aff_unique_abbr": "KTH;UU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stockholm;Uppsala",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9981414",
        "title": "Conservative Filtering for Heterogeneous Decentralized Data Fusion in Dynamic Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for Bayesian multi-robot peer-to-peer data fusion where any pair of autonomous robots hold non-identical, but overlapping parts of a global joint probability distribution, representing real world inference tasks (e.g., mapping, tracking). It is shown that in dynamic stochastic systems, filtering, which corresponds to marginalization of past variables, results in direct and hidden dependencies between variables not mutually monitored by the robots, which might lead to an overconfident fused estimate. The paper makes both theoretical and practical contributions by providing (i) a rigorous analysis of the origin of the dependencies and (ii) a conservative filtering algorithm for heterogeneous data fusion in dynamic systems that can be integrated with existing fusion algorithms. This work uses factor graphs as both the analysis tool and the inference engine. Each robot in the network maintains a local factor graph and communicates only relevant parts of it (a sub-graph) to its neighboring robot. We discuss the applicability to various multi-robot robotic applications and demonstrate the performance using a multi-robot multi-target tracking simulation, showing that the proposed algorithm produces conservative estimates at each robot.",
        "primary_area": "",
        "author": "Ofer Dagan;Nisar R. Ahmed;Ofer Dagan;Nisar R. Ahmed",
        "authorids": "/37088540869;/37533152500;/37088540869;/37533152500",
        "aff": "Smead Aerospace Engineering Sciences Department, University of Colorado Boulder, Boulder, CO, USA; Smead Aerospace Engineering Sciences Department, University of Colorado Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981414/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13258670116242728906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Smead Aerospace Engineering Sciences Department",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981586",
        "title": "Constrained Differential Dynamic Programming: A primal-dual augmented Lagrangian approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization is an efficient approach for solving optimal control problems for complex robotic systems. It relies on two key components: first the transcription into a sparse nonlinear program, and second the corresponding solver to iteratively compute its solution. On one hand, differential dynamic programming (DDP) provides an efficient approach to transcribe the optimal control problem into a finite-dimensional problem while optimally exploiting the sparsity induced by time. On the other hand, augmented Lagrangian methods make it possible to formulate efficient algorithms with advanced constraint-satisfaction strategies. In this paper, we propose to combine these two approaches into an efficient optimal control algorithm accepting both equality and inequality constraints. Based on the augmented Lagrangian literature, we first derive a generic primal-dual augmented Lagrangian strategy for nonlinear problems with equality and inequality constraints. We then apply it to the dynamic programming principle to solve the value-greedy optimization problems inherent to the backward pass of DDP, which we combine with a dedicated globalization strategy, resulting in a Newton-like algorithm for solving constrained trajectory optimization problems. Contrary to previous attempts of formu-lating an augmented Lagrangian version of DDP, our approach exhibits adequate convergence properties without any switch in strategies. We empirically demonstrate its interest with several case-studies from the robotics literature.",
        "primary_area": "",
        "author": "Wilson Jallet;Antoine Bambade;Nicolas Mansard;Justin Carpentier;Wilson Jallet;Antoine Bambade;Nicolas Mansard;Justin Carpentier",
        "authorids": "/37089448726;/37089658667;/37542913400;/37085506841;/37089448726;/37089658667;/37542913400;/37085506841",
        "aff": "D\u00e9partement d'informatique de l'ENS, Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; ENPC, France; LAAS-CNRS, Toulouse, France; D\u00e9partement d'informatique de l'ENS, Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981586/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=378260423552714158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure;Ecole Nationale des Ponts et Chauss\u00e9es;LAAS-CNRS",
        "aff_unique_dep": "D\u00e9partement d'informatique;;",
        "aff_unique_url": "https://www.ens.fr;https://www.enpc.fr;https://www.laas.fr",
        "aff_unique_abbr": "ENS;ENPC;",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Paris;;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981909",
        "title": "Constraint-based Task Specification and Trajectory Optimization for Sequential Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "To economically deploy robotic manipulators the programming and execution of robot motions must be swift. To this end, we propose a novel, constraint-based method to intuitively specify sequential manipulation tasks and to compute time-optimal robot motions for such a task specification. Our approach follows the ideas of constraint-based task specification by aiming for a minimal and object-centric task description that is largely independent of the underlying robot kinematics. We transform this task description into a non-linear optimization problem. By solving this problem we obtain a (locally) time-optimal robot motion, not just for a single motion, but for an entire manipulation sequence. We demonstrate the capabilities of our approach in a series of experiments involving five distinct robot models, including a highly redundant mobile manipulator.",
        "primary_area": "",
        "author": "Mun Seng Phoon;Philipp S. Schmitt;Georg V. Wichert;Mun Seng Phoon;Philipp S. Schmitt;Georg V. Wichert",
        "authorids": "/37089662390;/37086094898;/37330987000;/37089662390;/37086094898;/37330987000",
        "aff": "Mun Seng Phoon; Siemens Technology, Munich, Germany; Siemens Technology, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981909/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14021169540653764444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Mun Seng Phoon;Siemens Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.siemens.com",
        "aff_unique_abbr": ";Siemens",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "1;1",
        "aff_country_unique": ";Germany"
    },
    {
        "id": "9981926",
        "title": "Construction of a Simulator to Reproduce Changes in Running due to Motion Strategies Using Spring-Loaded Inverted Pendulum Model",
        "track": "main",
        "status": "Poster",
        "abstract": "This study aims to construct a running simulator based on a motion generation and control system that enables the description of motion strategies using the spring-loaded inverted pendulum (SLIP) model. The problems of stability and robustness encountered in the running simulation with the SLIP model are elucidated, and stable running is achieved by controlling the stiffness and the attitude angle dynamically at touchdown, as well as human energy adjustment that is introduced to consider the active motion strategy. As a result, passive and active control by humans can be expressed, and a framework that can express the changes in running due to motion strategies is constructed. Finally, we discuss the possibility of describing and elucidating the motion strategies.",
        "primary_area": "",
        "author": "Masaki Kitagawa;Takayuki Tanaka;Akihiko Murai;Masaki Kitagawa;Takayuki Tanaka;Akihiko Murai",
        "authorids": "/37089661613;/37277533100;/37274016000;/37089661613;/37277533100;/37274016000",
        "aff": "Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan; Japan Science and Technology Agency PRESTO, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981926/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10520063431098369784&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hokkaido University;Japan Science and Technology Agency",
        "aff_unique_dep": "Graduate School of Information Science and Technology;PRESTO",
        "aff_unique_url": "https://www.hokudai.ac.jp;https://www.jst.go.jp",
        "aff_unique_abbr": "Hokkaido U.;JST",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sapporo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981476",
        "title": "Contact-Implicit Differential Dynamic Programming for Model Predictive Control with Relaxed Complementarity Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a novel differential dynamic programming (DDP) framework for systems involving contact with the ground. The approach converts a general constrained differential dynamic programming into contact-implicit one by incorporating contact dynamics in a linear complementarity problem (LCP) formulation. Analytical gradients of the contact dynamics are obtained through a relaxed complementarity condition in the LCP formulation that helps the search directions of optimization avoid stalling in bad local minima or saddle points. Incorporation of contact dynamics and its analytical gradients into DDP enables an online discovery of not only dynamically-feasible trajectories of states, control inputs, and contact forces but also contact mode sequences. We demonstrate that our Contact-Implicit Differential Dynamic Programming framework successfully finds totally new dynamic motions with contact mode sequences in a variety of robotic systems including an one-legged hopping robot and planar quadrupedal robot in simulation environment.",
        "primary_area": "",
        "author": "Gijeong Kim;Dongyun Kang;Joon-Ha Kim;Hae-Won Park;Gijeong Kim;Dongyun Kang;Joon-Ha Kim;Hae-Won Park",
        "authorids": "/37089446621;/37089659260;/37087322590;/37086265865;/37089446621;/37089659260;/37087322590;/37086265865",
        "aff": "Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981476/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11977366004990370688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Humanoid Robot Research Center",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981686",
        "title": "Contact-Implicit Trajectory Optimization with Hydroelastic Contact and iLQR",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact-implicit trajectory optimization offers an appealing method of automatically generating complex and contact-rich behaviors for robot manipulation and locomotion. The scalability of such techniques has been limited, however, by the challenge of ensuring both numerical reliability and physical realism. In this paper, we present preliminary results suggesting that the Iterative Linear Quadratic Regulator (iLQR) algorithm together with the recently proposed pressure-field-based hydroelastic contact model enables reliable and physically realistic trajectory optimization through contact. We use this approach to synthesize contact-rich behaviors like quadruped locomotion and whole-arm manipulation. Furthermore, open-loop playback on a Kinova Gen3 robot arm demonstrates the physical accuracy of the whole-arm manipulation trajectories. Code is available at https://bit.ly/ilqr_hc and videos can be found at https://youtu.be/IqxJKbM8_ms.",
        "primary_area": "",
        "author": "Vince Kurtz;Hai Lin;Vince Kurtz;Hai Lin",
        "authorids": "/37086192874;/37291989100;/37086192874;/37291989100",
        "aff": "Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981686/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12278401772624191118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981044",
        "title": "Contact-implicit Trajectory and Grasp Planning for Soft Continuum Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots begin to move from structured industrial environments to the real world, they must be equipped to not only safely interact with the environment, but also reason about how to leverage contact to perform tasks. In this work, we develop a modeling and motion planning framework for continuum robots that accounts for contact anywhere along the robot. We first present an analytical model for continuum manipulators under contact and discuss the ideal choice of generalized coordinates given properties of the manipulator and task specifications. We then demonstrate the utility of our model by developing a motion planning framework that can solve a diverse set of tasks. We apply our framework to end effector path planning for a soft arm in an obstacle-rich environment, and grasp planning for soft robotic grippers, where contact can happen anywhere on the arm or gripper. Finally, we verify the utility of our model and planning framework by planning a grasp with a desired contact force for a soft antipodal gripper and testing this grasp in a hardware demonstration. Overall, our model and planning approach further enhance soft and continuum robots where they already excel: utilizing contact with the world to achieve their goals with a gentle touch.",
        "primary_area": "",
        "author": "Moritz A. Graule;Clark B. Teeple;Robert J. Wood;Moritz A. Graule;Clark B. Teeple;Robert J. Wood",
        "authorids": "/37085771962;/37086131116;/37326227400;/37085771962;/37086131116;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981044/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15991301105287121357&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Allston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981284",
        "title": "Contact-timing and Trajectory Optimization for 3D Jumping on Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing highly agile acrobatic motions with a long flight phase requires perfect timing, high accuracy, and coordination of the full-body motion. To address these challenges, we present a novel approach on timings and trajectory optimization framework for legged robots performing aggressive 3D jumping. In our method, we firstly utilize an effective optimization framework using simplified rigid body dynamics to solve for contact timings and a reference trajectory of the robot body. The solution of this module is then used to formulate a full-body trajectory optimization based on the full nonlinear dynamics of the robot. This combination allows us to effectively optimize for contact timings while ensuring that the jumping trajectory can be effectively realized in the robot hardware. We first validate the efficiency of the proposed framework on the A1 robot model for various 3D jumping tasks such as double-backflips off the high altitude of 2m. Experimental validation was then successfully conducted for various aggressive 3D jumping motions such as diagonal jumps, barrel roll, and double barrel roll from a box of heights 0.4m and 0.9m, respectively.",
        "primary_area": "",
        "author": "Chuong Nguyen;Quan Nguyen;Chuong Nguyen;Quan Nguyen",
        "authorids": "/37089660432;/37085362091;/37089660432;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, USA; Department of Aerospace and Mechanical Engineering, University of Southern California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981284/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=987238801068632935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981581",
        "title": "Containerization and Orchestration of Software for Autonomous Mobile Robots: a Case Study of Mixed-Criticality Tasks across Edge-Cloud Computing Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "Containerization promises to strengthen platform-independent development, better resource utilization, and secure deployment of software. As these benefits come with negligible overhead in CPU and memory utilization, containerization is increasingly being adopted in mobile robotic applications. An open challenge is supporting software tasks that have mixed-criticality requirements. Even more challenging is the combination of real-time containers with orchestration, which is an emerging paradigm to automate the deployment, networking, scaling, and availability of containerized workloads and services. This paper addresses this challenge by presenting a framework that extends the de-facto reference standard for container orchestration, Kubernetes, to schedule tasks with mixed-criticality requirements. Quantitative experimental results on the software implementing the mission of a Robotnik RB-Kairos mobile robot demonstrate the effectiveness of the proposed approach. The source code is publicly available on GitHub.",
        "primary_area": "",
        "author": "Francesco Lumpp;Franco Fummi;Hiren D. Patel;Nicola Bombieri;Francesco Lumpp;Franco Fummi;Hiren D. Patel;Nicola Bombieri",
        "authorids": "/37088908590;/37274499900;/37279232400;/37273824500;/37088908590;/37274499900;/37279232400;/37273824500",
        "aff": "Dept. of Computer Science, Univ. of Verona, Italy; Dept. of Computer Science, Univ. of Verona, Italy; Dept. of Electrical and Computer Eng., Univ. of Waterloo, Canada; Dept. of Computer Science, Univ. of Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981581/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11375256820956420893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Verona;University of Waterloo",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.univr.it;https://uwaterloo.ca",
        "aff_unique_abbr": "Univr;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Italy;Canada"
    },
    {
        "id": "9981465",
        "title": "Context and Intention aware 3D Human Body Motion Prediction using an Attention Deep Learning model in Handover Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This work explores how contextual information and human intention affect the motion prediction of humans during a handover operation with a social robot. By classifying human intention in four different classes, we developed a model able to generate a different motion for each intention class. Furthermore, the model uses a multi-headed attention architecture to add contextual information to the pipeline, such as the position of the robot end effector (REE) or the position of obstacles in the interaction scene. We generate predictions up to two and half seconds in the future given an input sequence of one second containing the previous motion of the human. The results show an improvement of the prediction accuracy, both for the full skeleton prediction and the human hand used for the delivery. The model also allows to generate different sequences with the desired human intention.",
        "primary_area": "",
        "author": "Javier Laplaza;Francesc Moreno-Noguer;Alberto Sanfeliu;Javier Laplaza;Francesc Moreno-Noguer;Alberto Sanfeliu",
        "authorids": "/37088946607;/38274555200;/37270957300;/37088946607;/38274555200;/37270957300",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e1tica Industrial de Barcelona (IRI), Catalonia, Spain; Institut de Rob\u00f2tica i Inform\u00e1tica Industrial de Barcelona (IRI), Catalonia, Spain; Institut de Rob\u00f2tica i Inform\u00e1tica Industrial de Barcelona (IRI), Catalonia, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981465/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16792458879998847517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e1tica Industrial de Barcelona",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981063",
        "title": "Contextual Driving Scene Perception from Anonymous Vehicle Bus Data for Automotive Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, driving context perception has emerged as one of the key aspects to design driving assistance algorithms and user interfaces that are effective in adapting to different traffic situations or environments. To this aim, we introduce the Anonymous Driving Scene Perception (ADSP) Model, a novel deep neural network designed to classify anony-mous Controller Area Network (CAN)-bus data into multiple driving context domains. ADSP extends the idea of driving scene classification to time series signals, as previous works relied heavily on visual features. Our model achieved a multi -domain classification accuracy of 84.9% on our custom-built naturalistic data set, as a combination of 92.7% on road type classification and 90.1 % on binary traffic detection, performing 2.0% and 1.6% better than the state-of-the-art model for multivariate time series classification. Our work demonstrates the feasibility of driving scene classification from anonymous CAN-bus data, without collecting sensitive data from users (images or GPS).",
        "primary_area": "",
        "author": "Marco Wiedner;Francesco Branca;Enrico Mion;Andrea Censi;Emilio Frazzoli;Marco Wiedner;Francesco Branca;Enrico Mion;Andrea Censi;Emilio Frazzoli",
        "authorids": "/37089662648;/37089658563;/37086386395;/37398994000;/37283368500;/37089662648;/37089658563;/37086386395;/37398994000;/37283368500",
        "aff": "Department of Mechanical and Process Engineering, ETH Zurich, Z\u00fcrich, Switzerland; Department of Information Technology and Electrical Engineering, ETH Zurich, Z\u00fcrich, Switzerland; Department of Mechanical and Process Engineering, ETH Zurich, Z\u00fcrich, Switzerland; Department of Mechanical and Process Engineering, ETH Zurich, Z\u00fcrich, Switzerland; Department of Mechanical and Process Engineering, ETH Zurich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981063/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:bFtEKVgdYMUJ:scholar.google.com/&scioq=Contextual+Driving+Scene+Perception+from+Anonymous+Vehicle+Bus+Data+for+Automotive+Applications&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Mechanical and Process Engineering",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981780",
        "title": "Contextual Tuning of Model Predictive Control for Autonomous Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based model predictive control has been widely applied in autonomous racing to improve the closed-loop behaviour of vehicles in a data-driven manner. When environmental conditions change, e.g., due to rain, often only the predictive model is adapted, but the controller parameters are kept constant. However, this can lead to suboptimal behaviour. In this paper, we address the problem of data-efficient controller tuning, adapting both the model and objective simultaneously. The key novelty of the proposed approach is that we leverage a learned dynamics model to encode the environmental condition as a so-called context. This insight allows us to employ contextual Bayesian optimization to efficiently transfer knowledge across different environmental conditions. Consequently, we require fewer data to find the optimal controller configuration for each context. The proposed framework is extensively evaluated with more than 3'000 laps driven on an experimental platform with 1:28 scale RC race cars. The results show that our approach successfully optimizes the lap time across different contexts requiring fewer data compared to other approaches based on standard Bayesian optimization.",
        "primary_area": "",
        "author": "Lukas P. Fr\u00f6hlich;Christian K\u00fcttel;Elena Arcari;Lukas Hewing;Melanie N. Zeilinger;Andrea Carron;Lukas P. Fr\u00f6hlich;Christian K\u00fcttel;Elena Arcari;Lukas Hewing;Melanie N. Zeilinger;Andrea Carron",
        "authorids": "/37087322364;/37089659064;/37086042210;/37085842469;/37398798800;/38547450500;/37087322364;/37089659064;/37086042210;/37085842469;/37398798800;/38547450500",
        "aff": "Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; SENER Aerospace, Tres Cantos, Madrid, Spain; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981780/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15582018038078337264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "ETH Zurich;SENER Aerospace",
        "aff_unique_dep": "Institute of Dynamic Systems and Control;",
        "aff_unique_url": "https://www.ethz.ch;",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Zurich;Tres Cantos",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Switzerland;Spain"
    },
    {
        "id": "9981747",
        "title": "Continuous Calibration and Narrow Compensation Algorithm to Estimate a Joint Axis under the Various Conditions with Unit Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robots have been developed to aid or substitute the gait locomotion of humans. To assist gait locomotion based on the intention of a wearer, a gait pattern analysis is required with a wearable sensor by measuring body information, i.e., a joint angular velocity. However, measuring a precise joint angular velocity is difficult because the attachment position of a sensor has a curvature and an anatomical joint axis which is invisible. Therefore, a sensor calibration algorithm, which aligns a sensor axis into an anatomical joint axis, is required to provide an optimal assist for a wearer. Hence, in this paper, a new and simple sensor calibration algorithm is proposed with a unit sensor. Since a wearer shakes the body or collides with the ground when walking, the attachment position of a sensor may be changed. Thus, a continuous sensor compensation algorithm is also proposed. Additionally, the effectiveness of this new algorithm is demonstrated by gait locomotion experiments on various paths.",
        "primary_area": "",
        "author": "Wonjeong Seo;Haseok Lee;Jungsu Choi;Wonjeong Seo;Haseok Lee;Jungsu Choi",
        "authorids": "/37089661754;/37089658431;/37085898280;/37089661754;/37089658431;/37085898280",
        "aff": "Department of Robotics Engineering, Yeungnam University, Gyeongsan, Korea; Department of Robotics Engineering, Yeungnam University, Gyeongsan, Korea; Department of Robotics Engineering, Yeungnam University, Gyeongsan, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981747/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:-azQGqRn2B8J:scholar.google.com/&scioq=Continuous+Calibration+and+Narrow+Compensation+Algorithm+to+Estimate+a+Joint+Axis+under+the+Various+Conditions+with+Unit+Sensor&hl=en&as_sdt=0,14",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yeungnam University",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "http://www.yu.ac.kr",
        "aff_unique_abbr": "YU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gyeongsan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982195",
        "title": "Continuous Self-Localization on Aerial Images Using Visual and Lidar Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel method for geo-tracking, i.e. continuous metric self-localization in outdoor environments by registering a vehicle's sensor information with aerial imagery of an unseen target region. Geo- tracking methods offer the potential to supplant noisy signals from global navigation satellite systems (GNSS) and expensive and hard to maintain prior maps that are typically used for this purpose. The proposed geo-tracking method aligns data from on-board cameras and lidar sensors with geo-registered orthophotos to continuously localize a vehicle. We train a model in a metric learning setting to extract visual features from ground and aerial images. The ground features are projected into a top-down perspective via the lidar points and are matched with the aerial features to determine the relative pose between vehicle and orthophoto. Our method is the first to utilize on-board cameras in an end-to-end differentiable model for metric self-localization on unseen orthophotos. It exhibits strong generalization, is robust to changes in the environment and requires only geo-poses as ground truth. We evaluate our approach on the KITTI-360 dataset and achieve a mean absolute position error (APE) of 0.94m. We further compare with previous approaches on the KITTI odometry dataset and achieve state-of-the-art results on the geo-tracking task. 3",
        "primary_area": "",
        "author": "Florian Fervers;Sebastian Bullinger;Christoph Bodensteiner;Michael Arens;Rainer Stiefelhagen;Florian Fervers;Sebastian Bullinger;Christoph Bodensteiner;Michael Arens;Rainer Stiefelhagen",
        "authorids": "/37089659367;/37085686649;/37586948700;/37393645400;/37269459200;/37089659367;/37085686649;/37586948700;/37393645400;/37269459200",
        "aff": "Fraunhofer IOSB, Ettlingen, Germany; Fraunhofer IOSB, Ettlingen, Germany; Fraunhofer IOSB, Ettlingen, Germany; Fraunhofer IOSB, Ettlingen, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982195/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14611630491434006069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Fraunhofer IOSB;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iosb.fraunhofer.de/;https://www.kit.edu",
        "aff_unique_abbr": "IOSB;KIT",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Ettlingen;Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981154",
        "title": "Continuous locomotion mode recognition and gait phase estimation based on a shank-mounted IMU with artificial neural networks",
        "track": "main",
        "status": "Poster",
        "abstract": "To improve the control of wearable robotics for gait assistance, we present an approach for continuous locomotion mode recognition as well as gait phase and stair slope estimation based on artificial neural networks that include time history information. The input features consist exclusively of processed variables that can be measured with a single shank-mounted inertial measurement unit. We introduce a wearable device to acquire real-world environment test data to demonstrate the performance and the robustness of the approach. Mean absolute error (gait phase, stair slope) and accuracy (locomotion mode) were determined for steady level walking and steady stair ambulation. Robustness was assessed using test data from different sensor hardware, sensor fixations, ambulation environments and subjects. The mean absolute error from the steady gait test data for the gait phase was 2.0-3.5 % for gait phase estimation and 3.3-3.8\u00b0 for stair slope estimation. The accuracy of classifying the correct locomotion mode on the test data with the utilization of time history information was in between 98.51% and 99.67 %. Results show high performance and robustness for continuously predicting gait phase, stair slope and locomotion mode during steady gait. As hypothesized, time history information improves the locomotion mode recognition. However, while the gait phase estimation performed well for untrained transitions between locomotion modes, our qualitative analysis revealed that it may be beneficial to include transition data into the training of the neural network to improve the prediction of the slope and the locomotion mode. Our results suggest that artificial neural networks could be used for high level control of wearable lower limb robotics.",
        "primary_area": "",
        "author": "Florian Weigand;Andreas H\u00f6hl;Julian Zeiss;Ulrich Konigorski;Martin Grimmer;Florian Weigand;Andreas H\u00f6hl;Julian Zeiss;Ulrich Konigorski;Martin Grimmer",
        "authorids": "/37089660015;/37089660309;/37089659247;/37394829300;/37951258200;/37089660015;/37089660309;/37089659247;/37394829300;/37951258200",
        "aff": "Control Systems and Mechatronics Laboratory, Technical University of Darmstadt, Germany; Control Systems and Mechatronics Laboratory, Technical University of Darmstadt, Germany; Control Systems and Mechatronics Laboratory, Technical University of Darmstadt, Germany; Control Systems and Mechatronics Laboratory, Technical University of Darmstadt, Germany; Locomotion Laboratory, Institute of Sport Science, Technical University of Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981154/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9595240052039669245&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Darmstadt",
        "aff_unique_dep": "Control Systems and Mechatronics Laboratory",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Darmstadt",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981592",
        "title": "Contrastive Learning for Cross-Domain Open World Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to evolve is fundamental for any valuable autonomous agent whose knowledge cannot remain limited to that injected by the manufacturer. Consider for example a home assistant robot: it should be able to incrementally learn new object categories when requested, but also to recognize the same objects in different environments (rooms) and poses (hand-held/on the floor/above furniture), while rejecting unknown ones. Despite its importance, this scenario has started to raise interest in the robotic community only recently and the related research is still in its infancy, with existing experimental testbeds but no tailored methods. With this work, we propose the first learning approach that deals with all the previously mentioned challenges at once by exploiting a single contrastive objective. We show how it learns a feature space perfectly suitable to incrementally include new classes and is able to capture knowledge which generalizes across a variety of visual domains. Our method is endowed with a tailored effective stopping criterion for each learning episode and exploits a self-paced thresholding strategy that provides the classifier with a reliable rejection option. Both these novel contributions are based on the observation of the data statistics and do not need manual tuning. An extensive experimental analysis confirms the effectiveness of the proposed approach in establishing the new state-of-the-art. The code is available at https://github.com/FrancescoCappio/Contrastive_Open_World.",
        "primary_area": "",
        "author": "Francesco Cappio Borlino;Silvia Bucci;Tatiana Tommasi;Francesco Cappio Borlino;Silvia Bucci;Tatiana Tommasi",
        "authorids": "/37088854892;/37087233867;/37546801200;/37088854892;/37087233867;/37546801200",
        "aff": "Italian Institute of Technology, Italy; DAUIN Department at Politecnico di Torino, Italy; Italian Institute of Technology, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981592/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9169455203312585449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Italian Institute of Technology;Politecnico di Torino",
        "aff_unique_dep": ";DAUIN Department",
        "aff_unique_url": "https://www.iit.it;https://www.polito.it",
        "aff_unique_abbr": "IIT;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981455",
        "title": "Controlled Fabrication of Micro-Chain Robot Using Magnetically Guided Arraying Microfluidic Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "The magnetic microrobot has become a promising approach in many biomedical applications due to its small volume, flexible motion, and untethered micromachines. The micro-chain robot is one of the most popular magnetic microrobots. However, the uncontrollable magnetic moment direction and quantity of the magnetic beads consisted in the existing self-assembled micro-chain robot limit their locomotion and applications. This paper proposed an on-chip micro-chain robot fabrication method to assemble the magnetic beads with controllable magnetic moment direction and quantity. The bead quantity can be controlled by the structure limits of the microchannel, and the direction of the magnetic moment can be adj usted by the integrated external magnetic field. The assembled magnetic beads are then glued by the hydrogel under UV exposure. The micro-chain robots with different quantities and magnetic moment directions of the magnetic beads were successfully fabricated and tested in experiments. Due to the array structure of the microfluidic device, batch manufacturing of low-cost magnetic robots was achieved in our method. The movement of dual-bead microrobots with two orthogonal magnetic moment directions was analyzed and compared. One of the dual-bead microrobots was applied in the transportation of the hydrogel module using pushing and pulling modes. It indicated that the proposed controllable on-chip fabrication of the magnetic micro-chain robots has the potential to enhance the microrobot ability in biomedical applications.",
        "primary_area": "",
        "author": "Xiaoqing Tang;Xiaoming Liu;Yuyang Li;Dan Liu;Yuke Li;Masaru Kojima;Qiang Huang;Tatsuo Arai;Xiaoqing Tang;Xiaoming Liu;Yuyang Li;Dan Liu;Yuke Li;Masaru Kojima;Qiang Huang;Tatsuo Arai",
        "authorids": "/37086473572;/37085366355;/37089499832;/37086960115;/37089499833;/37528394100;/37279982900;/37281360800;/37086473572;/37085366355;/37089499832;/37086960115;/37089499833;/37528394100;/37279982900;/37281360800",
        "aff": "Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Department of Materials Engineering Science, Osaka University, Osaka, Japan; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Advanced Innovation Center for Intelligent Robots and Systems, and School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981455/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:xZJ1oMX3Zk4J:scholar.google.com/&scioq=Controlled+Fabrication+of+Micro-Chain+Robot+Using+Magnetically+Guided+Arraying+Microfluidic+Devices&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;Osaka University",
        "aff_unique_dep": "School of Mechatronical Engineering;Department of Materials Engineering Science",
        "aff_unique_url": "http://www.bit.edu.cn/;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "BIT;Osaka U",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Beijing;Osaka",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9981993",
        "title": "Controller design of a robotic assistant for the transport of large and fragile objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the design of a robotic assistant for the transport of large and fragile objects. We propose a new collaborative robotic controller that fulfills the main requirements of co-transportation tasks of large and fragile objects: to execute any trajectory in a collaborative mode while minimizing the stress applied on the object by both partners in order to avoid damaging it. This controller prevents the robot from applying torques on the object while maintaining a desired orientation of the object along the transport trajectory in order to follow the operator. An original feature of our approach is to care about torques applied by both partners (not only by operator) during any co-manipulation trajectory execution. It leads to a novel outcome: the minimization of stress applied by both partners on a large and fragile object during its transport on any trajectory. We demonstrate the effectiveness of this approach in a collaborative transportation task.",
        "primary_area": "",
        "author": "Julie Dumora;Julien Nicolas;Franck Geffard;Julie Dumora;Julien Nicolas;Franck Geffard",
        "authorids": "/38540977600;/37089662028;/37444691300;/38540977600;/37089662028;/37444691300",
        "aff": "Interactive Robotics Plateform, CEA Tech Nouvelle Aquitaine, Pessac, France; Interactive Robotics Plateform, CEA Tech Nouvelle Aquitaine, Pessac, France; Universit\u00e9 Paris-Saclay, CEA, List, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981993/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:_7ooA2HnPVEJ:scholar.google.com/&scioq=Controller+design+of+a+robotic+assistant+for+the+transport+of+large+and+fragile+objects&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "CEA Tech;Universit\u00e9 Paris-Saclay",
        "aff_unique_dep": "Interactive Robotics Plateform;CEA List",
        "aff_unique_url": ";https://www.universite-paris-saclay.fr",
        "aff_unique_abbr": "CEA Tech;UPS",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Nouvelle Aquitaine;Palaiseau",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981678",
        "title": "Controlling the Cascade: Kinematic Planning for N-ball Toss Juggling",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic movements are ubiquitous in human motor behavior as they tend to be more efficient and can solve a broader range of skill domains than their quasi-static counterparts. For decades, robotic juggling tasks have been among the most frequently studied dynamic manipulation problems since the required dynamic dexterity can be scaled to arbitrarily high difficulty. However, successful approaches have been limited to basic juggling skills, indicating a lack of understanding of the required constraints for dexterous toss juggling. We present a detailed analysis of the toss juggling task, identifying the key challenges of the switching contacts task and formalizing it as a trajectory optimization problem. Building on our state-of-the-art, real-world toss juggling platform, we reach the theoretical limits of toss juggling in simulation, evaluate a resulting real-time controller in environments of varying difficulty and achieve robust toss juggling of up to 17 balls on two anthropomorphic manipulators. https://sites.google.com/view/controlling-the-cascade",
        "primary_area": "",
        "author": "Kai Ploeger;Jan Peters;Kai Ploeger;Jan Peters",
        "authorids": "/37086429831;/37533077600;/37086429831;/37533077600",
        "aff": "Technical University of Darmstadt; Technical University of Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981678/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5785576585913941791&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Darmstadt",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981535",
        "title": "Controlling the Impression of Robots via GAN-based Gesture Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "As a type of body language, gestures can largely affect the impressions of human-like robots perceived by users. Recent data-driven approaches to the generation of co-speech gestures have successfully promoted the naturalness of produced gestures. These approaches also possess greater generalizability to work under various contexts than rule-based methods. However, most have no direct control over the human impressions of robots. The main obstacle is that creating a dataset that covers various impression labels is not trivial. In this study, based on previous findings in cognitive science on robot impressions, we present a heuristic method to control them without manual labeling, and demonstrate its effectiveness on a virtual agent and partially on a humanoid robot through subjective experiments with 50 participants.",
        "primary_area": "",
        "author": "Bowen Wu;Jiaqi Shi;Chaoran Liu;Carlos T. Ishi;Hiroshi Ishiguro;Bowen Wu;Jiaqi Shi;Chaoran Liu;Carlos T. Ishi;Hiroshi Ishiguro",
        "authorids": "/37089659928;/37088640798;/37406600100;/37295360800;/37274136400;/37089659928;/37088640798;/37406600100;/37295360800;/37274136400",
        "aff": "Department of Engineering Science, Osaka University, Japan; Department of Engineering Science, Osaka University, Japan; Hiroshi Ishiguro Labs, ATR, Japan; Hiroshi Ishiguro Labs, ATR, Japan; Hiroshi Ishiguro Labs, ATR, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981535/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6903304161637571945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Osaka University;ATR Hiroshi Ishiguro Labs",
        "aff_unique_dep": "Department of Engineering Science;Hiroshi Ishiguro Labs",
        "aff_unique_url": "https://www.osaka-u.ac.jp;",
        "aff_unique_abbr": "Osaka U;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981898",
        "title": "Coordinated Multi-Agent Exploration, Rendezvous, & Task Allocation in Unknown Environments with Limited Connectivity",
        "track": "main",
        "status": "Poster",
        "abstract": "The lack of communication between agents in a multi-robot system is often regarded as a limiting factor that can affect and delay cooperative exploration and exploitation of cluttered and uncertain environments. On the contrary, this paper proposes a complete planning framework to enable cooperative behavior without the need for constant communication between robots, demonstrating drastic improvements in task completion and coverage time as compared to both fully connected robotic networks and widely used frontier-based exploration methods. Specifically, the proposed scheme considers three behaviors: i) exploration, promoting separation and disconnection, ii) rendezvous to reconnect and share information gained during exploration, and iii) task allocation for prioritized objectives. Exploration is achieved via a Sobel edge detection frontier algorithm that enables navigation of unknown complex (both convex and non-convex) environments. Once a task is discovered, a multi-objective weighted sum optimization method is proposed for allocating tasks based on prioritization and expectation estimation. The utility, generality, and scalability of the proposed approach is demonstrated using extensive simulations and experiments with unmanned ground vehicles in various cluttered environments.",
        "primary_area": "",
        "author": "Lauren Bramblett;Rahul Peddi;Nicola Bezzo;Lauren Bramblett;Rahul Peddi;Nicola Bezzo",
        "authorids": "/37089628310;/37086941760;/37546843800;/37089628310;/37086941760;/37546843800",
        "aff": "Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981898/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13589305120269199088&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981543",
        "title": "Coordinated Toolpath Planning for Multi-Extruder Additive Manufacturing",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new algorithm for coordinating the motion of multiple extruders to increase throughput in fused filament fabrication (FFF)/fused deposition modeling (FDM) additive manufacturing. Platforms based on FFF are commonly available and advantageous to several industries, but are limited by slow fabrication time and could be could be significantly improved through efficient use of multiple extruders. We propose the coordinated toolpath planning problem for systems of extruders mounted as end-effectors on robot arms with the objective of maximizing utilization and avoiding collisions. Building on the idea of dependency graphs introduced in our earlier work, we develop a planning and control framework that precomputes a set of multi-layer toolpath segments from the input model and efficiently assigns them to individual extruders such that executed toolpaths are collision-free. Our method overcomes key limitations of existing methods, including utilization loss from workspace partitioning, precomputed toolpaths subject to collisions with the partially fabricated object, and wasted motion resulting from strict layer-by-layer fabrication. We report simulation results that show a major increase in utilization compared to single and multi-extruder methods, and favorable fabrication results using commodity hardware that demonstrate the feasibility of our method in practice.",
        "primary_area": "",
        "author": "Jayant Khatkar;Chanyeol Yool;Robert Fitch;Lee Clemon;Ramgopal Mettu;Jayant Khatkar;Chanyeol Yool;Robert Fitch;Lee Clemon;Ramgopal Mettu",
        "authorids": "/37088503903;/37089660817;/38466367800;/37088504669;/37972758100;/37088503903;/37089660817;/38466367800;/37088504669;/37972758100",
        "aff": "School of Mechanical and Mechatronic Engineering, University of Technology, Sydney, Australia; School of Mechanical and Mechatronic Engineering, University of Technology, Sydney, Australia; School of Mechanical and Mechatronic Engineering, University of Technology, Sydney, Australia; School of Mechanical and Mechatronic Engineering, University of Technology, Sydney, Australia; Department of Computer Science, Tulane University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981543/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10275412307322112391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Technology Sydney;Tulane University",
        "aff_unique_dep": "School of Mechanical and Mechatronic Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.uts.edu.au;https://www.tulane.edu",
        "aff_unique_abbr": "UTS;Tulane",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9982277",
        "title": "Coordination With Humans Via Strategy Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Human and robot partners increasingly need to work together to perform tasks as a team. Robots designed for such collaboration must reason about how their task-completion strategies interplay with the behavior and skills of their human team members as they coordinate on achieving joint goals. Our goal in this work is to develop a computational framework for robot adaptation to human partners in human-robot team collaborations. We first present an algorithm for autonomously recognizing available task-completion strategies by observing human-human teams performing a collaborative task. By transforming team actions into low dimensional representations using hidden Markov models, we can identify strategies without prior knowledge. Robot policies are learned on each of the identified strategies to construct a Mixture-of-Experts model that adapts to the task strategies of unseen human partners. We evaluate our model on a collaborative cooking task using an Overcooked simulator. Results of an online user study with 125 participants demonstrate that our framework improves the task performance and collaborative fluency of human-agent teams, as compared to state of the art reinforcement learning methods.",
        "primary_area": "",
        "author": "Michelle Zhao;Reid Simmons;Henny Admoni;Michelle Zhao;Reid Simmons;Henny Admoni",
        "authorids": "/37089661134;/37270716800;/38570430500;/37089661134;/37270716800;/38570430500",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982277/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10050388630909504125&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981636",
        "title": "Core Processes in Intelligent Robotic Lab Assistants: Flexible Liquid Handling",
        "track": "main",
        "status": "Poster",
        "abstract": "Laboratory automation is a suitable solution to establish higher reproducibility with less manual work and thus higher quality standards in life sciences. To date, mobile robots are capable of performing autonomous pick-and-place tasks in the laboratory, and specialized pipetting machines can be used for sequenced liquid handling. However, the complex and creative process of developing new research protocols requires flexible robotic systems that can perform tasks such as pipetting in more versatile ways. In addition, the correct technique, according to ISO standards, has a great influence on precision and accuracy and therefore on reproducibility. This paper introduces our Intelligent Robotic Lab Assistants in the framework of our holistic, human-like, but standardized paradigm for collaborative lab automation, AI.Laboratory. Our system demonstrates mastery of pipetting following ISO 8655 as a force-sensitive robotic manipulation skill, which is a key component of our taxonomy of cell culture skills and the first steps toward true intelligent robotic laboratory assistants. This intelligent robotic pipetting skill is a versatile tool for general handling of \u00b5L-liquids, using only standard laboratory equipment that can be flexibly positioned in the robot's workspace. To demonstrate its pipetting performance, flexible handling of small volumes from 10 \u00b5L to 1000 \u00b5L was experimentally validated to the ISO 8655 standard, demonstrating superhuman performance that outperformed laymen, human experts, and other commercial and non-commercial robotic pipetting systems.",
        "primary_area": "",
        "author": "Dennis Knobbe;Henning Zwirnmann;Moritz Eckhoff;Sami Haddadin;Dennis Knobbe;Henning Zwirnmann;Moritz Eckhoff;Sami Haddadin",
        "authorids": "/37089660035;/37087644138;/37089446685;/37542865300;/37089660035;/37087644138;/37089446685;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981636/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10218052416506480278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981033",
        "title": "CreativeBot: a Creative Storyteller Agent Developed by Leveraging Pre-trained Language Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In an attempt to nurture children's creativity, we developed a creative conversational agent to be used in a collaborative storytelling context with a child. We presented a novel approach to develop creative Artificial Intelligence (AI). Our approach uses the four creativity measures: fluency, flexi-bility, elaboration and originality in order to generate creative behavior. We analyzed and annotated our previously collected storytelling data sets -collected with children- according to our four creativity measures. We then used the extracted and annotated data (636 statements) in order to fine-tune two pre-trained language models (Open AI GPT-3). The two models were aimed at generating creative versus non-creative behavior in a collaborative storytelling scenario. We developed the two models to be able to assess the results and compare them together. We conducted an evaluation to assess stories generated collaboratively between a human and both agents separately (n = 26). Adult Users rated the creativity of the agent according to the stories generated. Results showed that the creative agent was perceived as significantly more creative than the non-creative agent. With the experiment results confirming the validity of our system, we may therefore proceed with testing the effects of the creative behavior of the agent on children's creativity skills.",
        "primary_area": "",
        "author": "Maha Elgarf;Christopher Peters;Maha Elgarf;Christopher Peters",
        "authorids": "/37089550789;/37073347000;/37089550789;/37073347000",
        "aff": "KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981033/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13693304646316429304&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9981350",
        "title": "Cross-modal Fusion-based Prior Correction for Road Detection in Off-road Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Road detection plays a fundamental role in the visual navigation system of autonomous vehicles. However, it's still challenging to achieve robust road detection in off-road scenarios due to their complicated road appearances and ambiguous road structures. Therefore, existing image-based road detection approaches usually fail to extract the right routes due to the lack of the effective fusion of the image and prior reference paths(road guidances generated via map annotations and GPS localization). Besides, the reference paths are not always reliable because of GPS localization errors and mapping errors. To achieve robust road detection in off-road scenarios, we propose a prior-correction-based road detection network named PR-ROAD via fusing the cross-model information provided by both the reference path and the input image. These two heterogeneous data, prior and image, are deeply fused by a cross-attention module and formulate contextual inter-dependencies. We conduct experiments in our collected rural, off-road and urban datasets. The experimental results demonstrate the effectiveness of the proposed method both on unstructured and structured roads.",
        "primary_area": "",
        "author": "Yuru Wang;Yi Sun;Jian Li;Meiping Shi;Yuru Wang;Yi Sun;Jian Li;Meiping Shi",
        "authorids": "/37089664184;/37089655910;/37676295400;/37650428300;/37089664184;/37089655910;/37676295400;/37650428300",
        "aff": "School of Intelligence Science and Technology, National University of Defense technology, Changsha, Hunan, China; School of Intelligence Science and Technology, National University of Defense technology, Changsha, Hunan, China; School of Intelligence Science and Technology, National University of Defense technology, Changsha, Hunan, China; School of Intelligence Science and Technology, National University of Defense technology, Changsha, Hunan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981350/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17121322258439354455&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "School of Intelligence Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982247",
        "title": "Cutaneous Feedback Interface for Teleoperated In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In-hand pivoting is one of the important manipulation skills that leverage robot grippers' extrinsic dexterity to perform repositioning tasks to compensate for environmental uncertainties and imprecise motion execution. Although many researchers have been trying to solve pivoting problems using mathematical modeling or learning-based approaches, the problems remain as open challenges. On the other hand, humans perform in-hand manipulation with remarkable precision and speed. Hence, the solution could be provided by making full use of this intrinsic human skill through dexterous teleoperation. For dexterous teleoperation to be successful, interfaces that enhance and complement haptic feedback are of great necessity. In this paper, we propose a cutaneous feedback interface that complements the somatosensory information humans rely on when performing dexterous skills. The interface is designed based on five-bar link mechanisms and provides two contact points in the index finger and thumb for cutaneous feedback. By integrating the interface with a commercially available haptic device, the system can display information such as grasping force, shear force, friction, and grasped object's pose. Passive pivoting tasks inside a numerical simulator Isaac Sim is conducted to evaluate the effect of the proposed cutaneous feedback interface.",
        "primary_area": "",
        "author": "Yaonan Zhu;Jacinto Colan;Tadayoshi Aoyama;Yasuhisa Hasegawa;Yaonan Zhu;Jacinto Colan;Tadayoshi Aoyama;Yasuhisa Hasegawa",
        "authorids": "/37086591677;/37089378418;/37573656900;/37272575600;/37086591677;/37089378418;/37573656900;/37272575600",
        "aff": "Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982247/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1854109709068516742&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nagoya University",
        "aff_unique_dep": "Department of Micro-Nano Mechanical Science and Engineering",
        "aff_unique_url": "https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Nagoya U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981388",
        "title": "D-LC-Nets: Robust Denoising and Loop Closing Networks for LiDAR SLAM in Complicated Circumstances with Noisy Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "The current LiDAR SLAM (Simultaneous Localization and Mapping) system suffers greatly from low accuracy and limited robustness when faced with complicated circumstances. From our experiments, we find that current LiDAR SLAM systems have limited performance when the noise level in the obtained point clouds is large. Therefore, in this work, we propose a general framework to tackle the problem of denoising and loop closure for LiDAR SLAM in complex environments with many noises and outliers caused by reflective materials. Current approaches for point clouds denoising are mainly designed for small-scale point clouds and can not be extended to large-scale point clouds scenes. In this work, we firstly proposed a lightweight network for large-scale point clouds denoising. Subsequently, we have also designed an efficient loop closure network for place recognition in global optimization to improve the localization accuracy of the whole system. Finally, we have demonstrated by extensive experiments and benchmark studies that our method can have a significant boost on the localization accuracy of the LiDAR SLAM system when faced with noisy point clouds, with a marginal increase in computational cost.",
        "primary_area": "",
        "author": "Kangcheng Liu;Aoran Xiao;Jiaxing Huang;Kaiwen Cui;Yun Xing;Shijian Lu;Kangcheng Liu;Aoran Xiao;Jiaxing Huang;Kaiwen Cui;Yun Xing;Shijian Lu",
        "authorids": "/37087245508;/37089013768;/37089013280;/37088886349;/37089661002;/37405953500;/37087245508;/37089013768;/37089013280;/37088886349;/37089661002;/37405953500",
        "aff": "School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore; School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore; School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore; School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore; School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore; School of Computer Science and Engineering, Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE), Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981388/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=661285633431430821&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981441",
        "title": "DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop Neighbors",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent reinforcement learning (MARL) meth-ods face a curse of dimensionality in the policy and value function representations as the number of agents increases. The development of distributed or parallel training techniques is also hindered by the global coupling among the agent dynamics, requiring simultaneous state transitions. This paper introduces Distributed multi-Agent Reinforcement Learning with One-hop Neighbors (DARLIN). DARLIN is an off-policy actor-critic MARL method that breaks the curse of dimensionality and achieves distributed training by restricting the agent interactions to one-hop neighborhoods. Each agent optimizes its value and policy functions over a one-hop neighborhood, reducing the representation complexity, yet maintaining expressiveness by training with varying numbers and states of neighbors. This structure enables the key contribution of DARLIN: a distributed training procedure in which each compute node simulates the state transitions of only a small subset of the agents, greatly accelerating the training of large-scale MARL policies. Comparisons with state-of-the-art MARL methods show that DARLIN significantly reduces training time without sacrificing policy quality as the number of agents increases.",
        "primary_area": "",
        "author": "Baoqian Wang;Junfei Xie;Nikolay Atanasov;Baoqian Wang;Junfei Xie;Nikolay Atanasov",
        "authorids": "/37086377335;/37085354420;/37670511000;/37086377335;/37085354420;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego and San Diego State University, La Jolla, CA; Department of Electrical and Computer Engineering, San Diego State University, San Diego, CA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981441/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12304330541360932529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, San Diego;San Diego State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://ucsd.edu;https://www.sdsu.edu",
        "aff_unique_abbr": "UCSD;SDSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "La Jolla;San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981353",
        "title": "DC-MRTA: Decentralized Multi-Robot Task Allocation and Navigation in Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel reinforcement learning (RL) based task allocation and decentralized navigation algorithm for mobile robots in warehouse environments. Our approach is designed for scenarios in which multiple robots are used to perform various pick up and delivery tasks. We consider the problem of joint decentralized task allocation and navigation and present a two level approach to solve it. At the higher level, we solve the task allocation by formulating it in terms of Markov Decision Processes and choosing the appropriate rewards to minimize the Total Travel Delay (TTD). At the lower level, we use a decentralized navigation scheme based on ORCA that enables each robot to perform these tasks in an independent manner, and avoid collisions with other robots and dynamic obstacles. We combine these lower and upper levels by defining rewards for the higher level as the feedback from the lower level navigation algorithm. We perform extensive evaluation in complex warehouse layouts with large number of agents and highlight the benefits over state-of-the-art algorithms based on myopic pickup distance minimization and regret-based task selection. We observe improvement up to 14% in terms of task completion time and up-to 40% improvement in terms of computing collision-free trajectories for the robots.",
        "primary_area": "",
        "author": "Aakriti Agrawal;Senthil Hariharan;Amrit Singh Bedi;Dinesh Manocha;Aakriti Agrawal;Senthil Hariharan;Amrit Singh Bedi;Dinesh Manocha",
        "authorids": "/37089660072;/37089001838;/37085892109;/37267825600;/37089660072;/37089001838;/37085892109;/37267825600",
        "aff": "College Park, University of Maryland, MD, USA; College Park, University of Maryland, MD, USA; College Park, University of Maryland, MD, USA; College Park, University of Maryland, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981353/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18199345470260774536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981670",
        "title": "DGBench: An Open-Source, Reproducible Benchmark for Dynamic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces DGBench, a fully reproducible open-source testing system to enable benchmarking of dynamic grasping in environments with unpredictable relative motion between robot and object. We use the proposed benchmark to compare several visual perception arrangements. Traditional perception systems developed for static grasping are unable to provide feedback during the final phase of a grasp due to sensor minimum range, occlusion, and a limited field of view. A multi-camera eye-in-hand perception system is presented that has advantages over commonly used camera configurations. We quantitatively evaluate the performance on a real robot with an image-based visual servoing grasp controller and show a significantly improved success rate on a dynamic grasping task.",
        "primary_area": "",
        "author": "Ben Burgess-Limerick;Chris Lehnert;J\u00fcrgen Leitner;Peter Corke;Ben Burgess-Limerick;Chris Lehnert;J\u00fcrgen Leitner;Peter Corke",
        "authorids": "/37089449320;/37546443200;/37885671300;/37279654600;/37089449320;/37546443200;/37885671300;/37279654600",
        "aff": "Centre for Robotics (QCR), Queensland University of Technology, Brisbane, Australia; Centre for Robotics (QCR), Queensland University of Technology, Brisbane, Australia; LYRO Robotics, Brisbane, Australia; Centre for Robotics (QCR), Queensland University of Technology, Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981670/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4813529180307899245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Queensland University of Technology;LYRO Robotics",
        "aff_unique_dep": "Centre for Robotics (QCR);",
        "aff_unique_url": "https://www.qut.edu.au;",
        "aff_unique_abbr": "QUT;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981061",
        "title": "DH-LC: Hierarchical Matching and Hybrid Bundle Adjustment Towards Accurate and Robust Loop Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "A loop closure module plays an important role in visual SLAM systems, which can reduce the accumulat-ed drift. This task faces the challenges of large viewpoint changes and expensive computational costs when optimizing the global map. This paper proposes DH-LC, a novel accurate and robust loop closure method that consists of hierarchical spatial feature matching (HSFM) and hybrid bundle adjustment (HBA). HSFM estimates a reliable relative pose between the query image and the retrieval image in a coarse-to-fine way. Specifically, 3D points are firstly triangulated and then clus-tered according to the spatial distribution. The cluster centers estimate coarse cube-level matching pairs in a larger perception field which can tolerate large viewpoint changes. HBA optimizes the global map efficiently by adaptively selecting incremental bundle adjustment or full bundle adjustment according to the accumulated drift and relative pose verification in the temporal window. Experimental results demonstrate that our proposed method easily detects loops in large viewpoint changes and efficiently optimizes the global map. When compared with the state-of-the-art methods, our method increases loop closure recall and improves SLAM localization accuracy with reducing the accumulated drift.",
        "primary_area": "",
        "author": "Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim;Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim",
        "authorids": "/37089195222;/37086529587;/37089198031;/37086499563;/37089195222;/37086529587;/37089198031;/37086499563",
        "aff": "SAIT-China Lab, Samsung Research Center, Beijing, China; SAIT-China Lab, Samsung Research Center, Beijing, China; SAIT-China Lab, Samsung Research Center, Beijing, China; AR&Graphics Lab, Samsung Advanced Institute of Technology, Beijing, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981061/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:HMUQYT6nQ24J:scholar.google.com/&scioq=DH-LC:+Hierarchical+Matching+and+Hybrid+Bundle+Adjustment+Towards+Accurate+and+Robust+Loop+Closure&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "SAIT-China Lab",
        "aff_unique_url": "https://www.samsung.com/cn/research/",
        "aff_unique_abbr": "SRC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9981868",
        "title": "DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to move in the real world, they must first correctly understand the state of its own body and the tools that it holds. In this research, we propose DIJE, an algorithm to estimate the image Jacobian for every pixel. It is based on an optical flow calculation and a simplified Kalman Filter that can be efficiently run on the whole image in real time. It does not rely on markers nor knowledge of the robotic structure. We use the DIJE in a self-recognition process which can robustly distinguish between movement by the robot and by external entities, even when the motion overlaps. We also propose a visual servoing controller based on DIJE, which can learn to control the robot's body to conduct reaching movements or bimanual tool-tip control. The proposed algorithms were implemented on a physical musculoskeletal robot and its performance was verified. We believe that such global estimation of the visuomotor policy has the potential to be extended into a more general framework for manipulation.",
        "primary_area": "",
        "author": "Yasunori Toshimitsu;Kento Kawaharazuka;Akihiro Miki;Kei Okada;Masayuki Inaba;Yasunori Toshimitsu;Kento Kawaharazuka;Akihiro Miki;Kei Okada;Masayuki Inaba",
        "authorids": "/37086842924;/37086101930;/37089295157;/37280639000;/37286658200;/37086842924;/37086101930;/37089295157;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981868/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5212002634421112243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981822",
        "title": "DRACo-SLAM: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar Equipped Underwater Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "An essential task for a multi-robot system is generating a common understanding of the environment and relative poses between robots. Cooperative tasks can be executed only when a vehicle has knowledge of its own state and the states of the team members. However, this has primarily been achieved with direct rendezvous between underwater robots, via inter-robot ranging. We propose a novel distributed multi-robot simultaneous localization and mapping (SLAM) framework for underwater robots using imaging sonar-based perception. By passing only scene descriptors between robots, we do not need to pass raw sensor data unless there is a likelihood of inter-robot loop closure. We utilize pairwise consistent measurement set maximization (PCM), making our system robust to erroneous loop closures. The functionality of our system is demonstrated using two real-world datasets, one with three robots and another with two robots. We show that our system effectively estimates the trajectories of the multi-robot system and keeps the bandwidth requirements of inter-robot communication low. To our knowledge, this paper describes the first instance of multi-robot SLAM using real imaging sonar data (which we implement offline, using simulated communication). Code link: https://github.com/jake3991/DRACo-SLAM.",
        "primary_area": "",
        "author": "John McConnell;Yewei Huang;Paul Szenher;Ivana Collado-Gonzalez;Brendan Englot;John McConnell;Yewei Huang;Paul Szenher;Ivana Collado-Gonzalez;Brendan Englot",
        "authorids": "/37827503600;/37086487764;/37088995925;/37089660640;/37601539900;/37827503600;/37086487764;/37088995925;/37089660640;/37601539900",
        "aff": "Stevens Institute of Technology, Hoboken, NJ, USA; Stevens Institute of Technology, Hoboken, NJ, USA; Stevens Institute of Technology, Hoboken, NJ, USA; Stevens Institute of Technology, Hoboken, NJ, USA; Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981822/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5087503707727263937&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981238",
        "title": "DRG-SLAM: A Semantic RGB-D SLAM using Geometric Features for Indoor Dynamic Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual SLAM methods based on point features have achieved acceptable results in texture-rich static scenes, but they often suffer from a deficiency of texture and the existence of dynamic objects in real indoor scenes, which limits the application of these methods. In this paper, we have presented DRG-SLAM, which combines line features and plane features into point features to improve the robustness of the system. We tested the proposed algorithm on publicly available datasets, and the results demonstrate that the algorithm has superior accuracy and robustness in indoor dynamic scenes compared with the state-of-the-art methods.",
        "primary_area": "",
        "author": "Yanan Wang;Kun Xu;Yaobin Tian;Xilun Ding;Yanan Wang;Kun Xu;Yaobin Tian;Xilun Ding",
        "authorids": "/37089664180;/37086446190;/37085904639;/37329764000;/37089664180;/37086446190;/37085904639;/37329764000",
        "aff": "Robotics Institute of School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, China; Robotics Institute of School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, China; Robotics Institute of School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, China; Robotics Institute of School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981238/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12346349697563832186&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981361",
        "title": "DRL-ISP: Multi-Objective Camera ISP with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a multi-objective camera ISP framework that utilizes Deep Reinforcement Learning (DRL) and camera ISP toolbox that consist of network-based and conventional ISP tools. The proposed DRL-based camera ISP framework iteratively selects a proper tool from the toolbox and applies it to the image to maximize a given vision task-specific reward function. For this purpose, we implement total 51 ISP tools that include exposure correction, color-and-tone correction, white balance, sharpening, denoising, and the others. We also propose an efficient DRL network architecture that can extract the various aspects of an image and make a rigid mapping relationship between images and a large number of actions. Our proposed DRL-based ISP framework effectively improves the image quality according to each vision task such as RAW-to-RGB image restoration, 2D object detection, and monocular depth estimation.",
        "primary_area": "",
        "author": "Ukcheol Shin;Kyunghyun Lee;In So Kweon;Ukcheol Shin;Kyunghyun Lee;In So Kweon",
        "authorids": "/37087323766;/37088503961;/37270474800;/37087323766;/37088503961;/37270474800",
        "aff": "School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981361/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4323077950793172475&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981201",
        "title": "DRPD, Dual Reduction Ratio Planetary Drive for Articulated Robot Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a reduction mechanism for robot actuators that can switch between two types of reduction ratio. By fixing the carrier or ring gear of the proposed actuator which is based on the 3K compound planetary drive, the actuator can shift its reduction ratio. For compact design with reduced weight of the actuator, unique pawl brake mechanism interacting with cams and micro servos for switching mechanism is designed. The resulting prototype module has a reduction ratio of 6.91 and 44.93 for \u2018low-reduction\u2019 and \u2018high-reduction\u2019 ratios, respectively. Reduction ratios can be easily adjusted by modifying the pitch diameters of gears. Experimental results demonstrate that the proposed actuator could extend its operation region via two reduction modes that are interchangeable with gear shifting.",
        "primary_area": "",
        "author": "Tae-Gyu Song;Young-Ha Shin;Seungwoo Hong;Hyungho Chris Choi;Joon-Ha Kim;Hae-Won Park;Tae-Gyu Song;Young-Ha Shin;Seungwoo Hong;Hyungho Chris Choi;Joon-Ha Kim;Hae-Won Park",
        "authorids": "/37089662508;/37405271100;/37086581983;/37089662936;/37087322590;/37086265865;/37089662508;/37405271100;/37086581983;/37089662936;/37087322590;/37086265865",
        "aff": "Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea; Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea; Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea; Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea; Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea; Department of Mechanical Engineering Korea Advanced Institute of Science and Technology, Humanoid Research Center,School of Mechanical, Aerospace & Systems Engineering, Yuseong-gu, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981201/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9844603416126730557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981491",
        "title": "DSOL: A Fast Direct Sparse Odometry Scheme",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we describe Direct Sparse Odometry Lite (DSOL), an improved version of Direct Sparse Odometry (DSO) [1]. We propose several algorithmic and implementation enhancements which speed up computation by a significant factor (on average 5x) even on resource-constrained platforms. The increase in speed allows us to process images at higher frame rates, which in turn provides better results on rapid motions. Our open-source implementation is available at https://github.com/versatran01/dso1.",
        "primary_area": "",
        "author": "Chao Qu;Shreyas S. Shivakumar;Ian D. Miller;Camillo J. Taylor;Chao Qu;Shreyas S. Shivakumar;Ian D. Miller;Camillo J. Taylor",
        "authorids": "/37085780604;/37086151076;/37086928894;/37277248500;/37085780604;/37086151076;/37086928894;/37277248500",
        "aff": "GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981491/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2327847872363497775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981528",
        "title": "DULA and DEBA: Differentiable Ergonomic Risk Models for Postural Assessment and Optimization in Ergonomically Intelligent pHRI",
        "track": "main",
        "status": "Poster",
        "abstract": "Ergonomics and human comfort are essential concerns in physical human-robot interaction applications. Defining an accurate and easy-to-use ergonomic assessment model stands as an important step in providing feedback for postural correction to improve operator health and comfort. Common practical methods in the area suffer from inaccurate ergonomics models in performing postural optimization. In order to retain assessment quality, while improving computational considerations, we propose a novel framework for postural assessment and optimization for ergonomically intelligent physical human-robot interaction. We introduce DULA and DEBA, differentiable and continuous ergonomics models learned to replicate the popular and scientifically validated RULA and REBA assessments with more than 99% accuracy. We show that DULA and DEBA provide assessment comparable to RULA and REBA while providing computational benefits when being used in postural optimization. We evaluate our framework through human and simulation experiments. We highlight DULA and DEBA's strength in a demonstration of postural optimization for a simulated pHRI task.",
        "primary_area": "",
        "author": "Amir Yazdani;Roya Sabbagh Novin;Andrew Merryweather;Tucker Hermans;Amir Yazdani;Roya Sabbagh Novin;Andrew Merryweather;Tucker Hermans",
        "authorids": "/37086578140;/37085576685;/37086281901;/38230909600;/37086578140;/37085576685;/37086281901;/38230909600",
        "aff": "NVIDIA, Seattle, WA, USA; NVIDIA, Seattle, WA, USA; NVIDIA, Seattle, WA, USA; NVIDIA, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981528/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10411387560483745873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NV",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981406",
        "title": "DUQIM-Net: Probabilistic Object Hierarchy Representation for Multi-View Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Object manipulation in cluttered scenes is a difficult and important problem in robotics. To efficiently manipulate objects, it is crucial to understand their surroundings, especially in cases where multiple objects are stacked one on top of the other, preventing effective grasping. We here present DUQIM-Net, a decision-making approach for object manipulation in a setting of stacked objects. In DUQIM-Net, the hierarchical stacking relationship is assessed using Adj-Net, a model that leverages existing Transformer Encoder-Decoder object detectors by adding an adjacency head. The output of this head probabilistically infers the underlying hierarchical structure of the objects in the scene. We utilize the properties of the adjacency matrix in DUQIM-Net to perform decision making and assist with object-grasping tasks. Our experimental results show that Adj-Net surpasses the state-of-the-art in object-relationship inference on the Visual Manipulation Relationship Dataset (VMRD), and that DUQIM-Net outperforms comparable approaches in bin clearing tasks.",
        "primary_area": "",
        "author": "Vladimir Tchuiev;Yakov Miron;Dotan Di Castro;Vladimir Tchuiev;Yakov Miron;Dotan Di Castro",
        "authorids": "/37086447716;/37089615142;/37062208100;/37086447716;/37089615142;/37062208100",
        "aff": "Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981406/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16971573715081931538&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://www.bosch-ai.com",
        "aff_unique_abbr": "BCAI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981418",
        "title": "DXQ-Net: Differentiable LiDAR-Camera Extrinsic Calibration Using Quality-aware Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate LiDAR-camera extrinsic calibration is a precondition for many multi-sensor systems in mobile robots. Most calibration methods rely on laborious manual operations and calibration targets. While working online, the calibration methods should be able to extract information from the environment to construct the cross-modal data association. Convolutional neural networks (CNNs) have powerful feature extraction ability and have been used for calibration. However, most of the past methods solve the extrinsic as a regression task, without considering the geometric constraints involved. In this paper, we propose a novel end-to-end extrinsic calibration method named DXQ-Net, using a differentiable pose estimation module for generalization. We formulate a probabilistic model for LiDAR-camera calibration flow, yielding a prediction of uncertainty to measure the quality of LiDAR-camera data association. Testing experiments illustrate that our method achieves a competitive with other methods for the translation component and state-of-the-art performance for the rotation component. Generalization experiments illustrate that the generalization performance of our method is significantly better than other deep learning-based methods.",
        "primary_area": "",
        "author": "Xin Jing;Xiaqing Ding;Rong Xiong;Huanjun Deng;Yue Wang;Xin Jing;Xiaqing Ding;Rong Xiong;Huanjun Deng;Yue Wang",
        "authorids": "/37089660430;/37086331151;/37271511300;/37088996595;/37072299700;/37089660430;/37086331151;/37271511300;/37088996595;/37072299700",
        "aff": "Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981418/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3222270237296530565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Alibaba Group;Zhejiang University",
        "aff_unique_dep": ";State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "https://www.alibaba.com;http://www.zju.edu.cn",
        "aff_unique_abbr": "Alibaba;ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981997",
        "title": "Data-Driven Kinematic Control Scheme for Cable-Driven Parallel Robots Allowing Collisions",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-Driven Parallel Robots (CDPRs) have been proposed for a variety of applications such as material handling, rehabilitation, and instrumentation. However, the collision-free constraint of CDPRs limits the workspace of CDPRs and the feasible position of anchor points. To address the collision-free constraint of CDPRs, a data-driven kinematic control scheme is developed for CDPRs, enabling a CDPR to control its pose even if suffering collisions between a cable and the base or the end-effector. To deal with the collisions, the data-driven kinematic control scheme utilizes a motion model obtained based on data samples of the motion of the CDPR, rather than the Jacobian matrix of the CDPR, to map a control law in the task space to the time derivative of the length of cables in the joint space. To evaluate the effectiveness of the developed data-driven kinematic control scheme, experiments of controlling a suspended CDPR with two cables allowing collisions are conducted.",
        "primary_area": "",
        "author": "Yongwei Zou;Yusheng Hu;Huanhui Cao;Yuchen Xu;Yuanjie Yu;Wenjie Lu;Hao Xiong;Yongwei Zou;Yusheng Hu;Huanhui Cao;Yuchen Xu;Yuanjie Yu;Wenjie Lu;Hao Xiong",
        "authorids": "/37089617646;/37089619732;/37089332809;/37089661210;/37089662371;/37086613756;/37088636912;/37089617646;/37089619732;/37089332809;/37089661210;/37089662371;/37086613756;/37088636912",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, People's Republic of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981997/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15762080242977740537&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982037",
        "title": "Data-Driven Variable Impedance Control of a Powered Knee-Ankle Prosthesis for Sit, Stand, and Walk with Minimal Tuning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the average healthy adult transitions from sit to stand over 60 times per day, most research on powered prosthesis control has only focused on walking. In this paper, we present a data-driven controller that enables sitting, standing, and walking with minimal tuning. Our controller comprises two high level modes of sit/stand and walking, and we develop heuristic biomechanical rules to control transitions. We use a phase variable based on the user's thigh angle to parameterize both walking and sit/stand motions, and use variable impedance control during ground contact and position control during swing. We extend previous work on data-driven optimization of continuous impedance parameter functions to design the sit/stand control mode using able-bodied data. Experiments with a powered knee-ankle prosthesis used by a participant with above-knee amputation demonstrate promise in clinical outcomes, as well as trade-offs between our minimal-tuning approach and accommodation of user preferences. Specifically, our controller enabled the participant to complete the sit/stand task 20% faster and reduced average asymmetry by half compared to his everyday passive prosthesis. The controller also facilitated a timed up and go test involving sitting, standing, walking, and turning, with only a mild (10%) decrease in speed compared to the everyday prosthesis. Our sit/stand/walk controller enables multiple activities of daily life with minimal tuning and mode switching.",
        "primary_area": "",
        "author": "Cara Gonzalez Welker;T. Kevin Best;Robert D. Gregg;Cara Gonzalez Welker;T. Kevin Best;Robert D. Gregg",
        "authorids": "/37088844811;/37089197029;/37547699100;/37088844811;/37089197029;/37547699100",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982037/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3479055327270904074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981408",
        "title": "Data-driven Kalman Filter with Kernel-based Koopman Operators for Nonlinear Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing the Kalman filter for nonlinear robot systems with theoretical guarantees is challenging, especially when the dynamics model is unavailable. This paper proposes a data-driven Kalman filter algorithm using kernel-based Koop-man operators for unknown nonlinear robot systems. First, the Koopman operator using sparse kernel-based extended dynamic decomposition (EDMD) is presented to learn the unknown dynamics with input-output datasets. Unlike classic EDMD, which requires manual selection of kernel functions, our approach automatically constructs kernel functions using an approximate linear dependency analysis method. The resulting Koopman model is a linear dynamic evolution in the kernel space, enabling us to address the nonlinear filtering problem using the standard linear Kalman filter design process. Despite this, our approach generates a nonlinear filtering law thanks to the adopted nonlinear kernel functions. Finally, the effectiveness of the proposed approach is validated by simulated experiments.",
        "primary_area": "",
        "author": "Wei Jiang;Xing long Zhang;Zhen Zuo;Meiping Shi;Shaojing Su;Wei Jiang;Xing long Zhang;Zhen Zuo;Meiping Shi;Shaojing Su",
        "authorids": "/37086087808;/37088567941;/38546440700;/37650428300;/37071746900;/37086087808;/37088567941;/38546440700;/37650428300;/37071746900",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981408/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6866664802688927898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981721",
        "title": "Decay-Based Error Correction in Collective Robotic Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot systems have been shown to build large-scale, user-specified structures using distributed, environmentally-mediated coordination in simulation. Little attention, however, has been devoted to error propagation and mitigation. In this paper, we introduce a detailed simulation of TERMES, a prototypical construction system, in which robots have realistic error profiles. We use this simulator and 32 randomly generated 250-brick blueprints to show that action errors can have significant long-term effects. We study the spatio-temporal error distribution and introduce and characterize the efficacy of a simple decay-based error correction mechanism. Although inefficient, this type of error correction is promising because it can be performed by robots with the same limited sensory capabilities as those who place bricks. To limit the impact on the construction rate, we also examine decay mechanisms informed by spatial and temporal error distributions. The incorporation of decay in our building process increases the probability of successful completion by ~ 4, at the expense of ~1/4 decrease in construction rate.",
        "primary_area": "",
        "author": "Jiahe Chen;Kirstin Petersen;Jiahe Chen;Kirstin Petersen",
        "authorids": "/37089662926;/37086043400;/37089662926;/37086043400",
        "aff": "School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981721/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2486761563055648078&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981959",
        "title": "Decentralized Control of Minimalistic Robotic Swarms For Guaranteed Target Encapsulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a decentralized control algorithm for a minimalistic robotic swarm with limited capabilities such that the desired global behavior emerges. We consider the problem of searching for and encapsulating various targets present in the environment while avoiding collisions with both static and dynamic obstacles. The novelty of this work is the guaranteed generation of desired complex swarm behavior with constrained individual robots which have no memory, no localization, and no knowledge of the exact relative locations of their neighbors. Moreover, we analyze how the emergent behavior changes with different parameters of the task, noise in the sensor reading, and asynchronous execution.",
        "primary_area": "",
        "author": "Himani Sinhmar;Hadas Kress-Gazit;Himani Sinhmar;Hadas Kress-Gazit",
        "authorids": "/37088225030;/38307602100;/37088225030;/38307602100",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981959/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9844318492620855164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981665",
        "title": "Decentralized Learning With Limited Communications for Multi-robot Coverage of Unknown Spatial Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an algorithm for a team of mobile robots to simultaneously learn a spatial field over a domain and spatially distribute themselves to optimally cover it. Drawing from previous approaches that estimate the spatial field through a centralized Gaussian process, this work leverages the spatial structure of the coverage problem and presents a decentralized strategy where samples are aggregated locally by establishing communications through the boundaries of a Voronoi partition. We present an algorithm whereby each robot runs a local Gaussian process calculated from its own measurements and those provided by its Voronoi neighbors, which are incorporated into the individual robot's Gaussian process only if they provide sufficiently novel information. The performance of the algorithm is evaluated in simulation and compared with centralized approaches.",
        "primary_area": "",
        "author": "Kensuke Nakamura;Mar\u00eda Santos;Naomi Ehrich Leonard;Kensuke Nakamura;Mar\u00eda Santos;Naomi Ehrich Leonard",
        "authorids": "/37086961952;/37086276250;/37275145000;/37086961952;/37086276250;/37275145000",
        "aff": "Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981665/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15546408626501380907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981894",
        "title": "Decentralized Multi-robot Velocity Estimation for UAVs Enhancing Onboard Camera-based Velocity Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Within the field of multi-robot systems, developing systems that rely only on onboard sensing without the use of external infrastructure (e.g. GNSS) has many potential applications. However, relying only on visual-based modalities for localization presents challenges in terms of accuracy and reliability. We introduce a decentralized multi-robot lateral velocity estimation method for Unmanned Aerial Vehicles (UAVs) to improve onboard measurements in case GNSS infrastructure is not available. This method relies on sharing the onboard measurements of neighbors, as well as the estimation of the relative motion of a focal UAV within the swarm, based on observation of coworking robots. The proposed velocity estimation method does not rely on centralized communication to achieve high reliability and scalability within the swarm system. The performance of the state estimation approach has been verified in simulations and real-world experiments. The results have shown that a swarm of UAVs using the proposed velocity estimator can stabilize individual robots when their primary onboard localization source is not reliable enough.",
        "primary_area": "",
        "author": "Jiri Horyna;Vit Kratky;Eliseo Ferrante;Martin Saska;Jiri Horyna;Vit Kratky;Eliseo Ferrante;Martin Saska",
        "authorids": "/37088916574;/37087632349;/38230571500;/37298817800;/37088916574;/37087632349;/38230571500;/37298817800",
        "aff": "Multi-Robot Systems Group, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Multi-Robot Systems Group, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Autonomous Research Robotics Centre, Technology Innovative Institute, Masdar City, Abu Dhabi, United Arab Emirates; Multi-Robot Systems Group, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981894/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15435038274960293206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Czech Technical University in Prague;Technology Innovative Institute",
        "aff_unique_dep": "Faculty of Electrical Engineering;Autonomous Research Robotics Centre",
        "aff_unique_url": "https://www.cvut.cz;",
        "aff_unique_abbr": "CTU;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Prague;Masdar City",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Czech Republic;United Arab Emirates"
    },
    {
        "id": "9981786",
        "title": "Deep Augmentation for Electrode Shift Compensation in Transient High-density sEMG: Towards Application in Neurorobotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Going beyond the traditional sparse multi-channel peripheral human-machine interface that has been used widely in neurorobotics, high-density surface electromyography (HD-sEMG) has shown significant potential for decoding upper-limb motor control. We have recently proposed heterogeneous temporal dilation of LSTM in a deep neural network architecture for a large number of gestures (>60), securing spatial resolution and fast convergence. However, several fundamental questions remain unanswered. One problem targeted explicitly in this paper is the issue of \u201celectrode shift,\u201d which can happen specifically for high-density systems and during doffing and donning the sensor grid. Another real-world problem is the question of transient versus plateau classification, which connects to the temporal resolution of neural interfaces and seamless control. In this paper, for the first time, we implement gesture prediction on the transient phase of HD-sEMG data while robustifying the human-machine interface decoder to electrode shift. For this, we propose the concept of deep data augmentation for transient HD-sEMG. We show that without using the proposed augmentation, a slight shift of 10mm may drop the decoder's performance to as low as 20%. Combining the proposed data augmentation with a 3D Convolutional Neural Network (CNN), we recovered the performance to 84.6% while securing a high spatiotemporal resolution, robustifying to the electrode shift, and getting closer to large-scale adoption by the end-users, enhancing resiliency.",
        "primary_area": "",
        "author": "Tianyun Sun;Jacqueline Libby;JohnRoss Rizzo;S. Farokh Atashzar;Tianyun Sun;Jacqueline Libby;JohnRoss Rizzo;S. Farokh Atashzar",
        "authorids": "/37088910516;/37089939196;/37086000958;/37592440100;/37088910516;/37089939196;/37086000958;/37592440100",
        "aff": "Department of Electrical and Computer Engineering, New York University, New York, NY, USA; NYU Center for Urban Science and Progress (CUSP), New York, NY, USA; NYU School of Medicine, New York, NY; Department of Electrical and Computer Engineering and with the Department of Mechanical and Aerospace Engineering and with NYU WIRELESS, NYU Center for Urban Science and Progress (CUSP), New York University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981786/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9354800575238043127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "New York University;New York University School of Medicine",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Medicine",
        "aff_unique_url": "https://www.nyu.edu;https://med.nyu.edu",
        "aff_unique_abbr": "NYU;NYU School of Medicine",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981734",
        "title": "Deep Gesture Generation for Social Robots Using Type-Specific Libraries",
        "track": "main",
        "status": "Poster",
        "abstract": "Body language such as conversational gesture is a powerful way to ease communication. Conversational gestures do not only make a speech more lively but also contain semantic meaning that helps to stress important information in the discussion. In the field of robotics, giving conversational agents (humanoid robots or virtual avatars) the ability to properly use gestures is critical, yet remain a task of extraordinary difficulty. This is because given only a text as input, there are many possibilities and ambiguities to generate an appropriate gesture. Different to previous works we propose a new method that explicitly takes into account the gesture types to reduce these ambiguities and generate human-like conversational gestures. Key to our proposed system is a new gesture database built on the TED dataset that allows us to map a word to one of three types of gestures: \u201cImagistic\u201d gestures, which express the content of the speech, \u201cBeat\u201d gestures, which emphasize words, and \u201cNo gestures.\u201d We propose a system that first maps the words in the input text to their corresponding gesture type, generate type-specific gestures and combine the generated gestures into one final smooth gesture. In our comparative experiments, the effectiveness of the proposed method was confirmed in user studies for both avatar and humanoid robot.",
        "primary_area": "",
        "author": "Hitoshi Teshima;Naoki Wake;Diego Thomas;Yuta Nakashima;Hiroshi Kawasaki;Katsushi Ikeuchi;Hitoshi Teshima;Naoki Wake;Diego Thomas;Yuta Nakashima;Hiroshi Kawasaki;Katsushi Ikeuchi",
        "authorids": "/37089299201;/37088602119;/37086122204;/37528235200;/37270111600;/37281068600;/37089299201;/37088602119;/37086122204;/37528235200;/37270111600;/37281068600",
        "aff": "Kyushu University; Microsoft; Kyushu University; Osaka University; Kyushu University; Microsoft",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981734/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5279197324326008382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;1",
        "aff_unique_norm": "Kyushu University;Microsoft;Osaka University",
        "aff_unique_dep": ";Microsoft Corporation;",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.microsoft.com;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Kyushu U;Microsoft;Osaka U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9982167",
        "title": "Deep Kernel Learning for Uncertainty Estimation in Multiple Trajectory Prediction Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting future paths of vehicles or pedestrians is an essential task for automated vehicles to allow for planning the own trajectory. Using predicted paths, a planning algorithm can, e.g., react to anticipated manoeuvres of other traffic participants. For calculating risks of planned manoeuvres, it is essential that the predicted paths are generated with information about their uncertainty. Since today's state of the art trajectory prediction algorithms are based on deep neural networks (DNNs), the estimation of uncertainty is left to the neural networks as well, which usually provide no means of assessing how the uncertainty estimation works. In this paper, we present a combination of DNNs with Gaussian processes via Deep Kernel Learning (DKL), which combines the ability of DNNs to perform the prediction task with the advantage of Gaussian processes of having more interpretable probabilistic outputs. We propose and evaluate two different variants for the task of multimodal trajectory prediction using Stochastic Variational Gaussian Processes (SVGPs) and the recently proposed regression method Deep Sigma Point Processes (DSPPs), respectively. We evaluate the predictive distributions of both approaches on the publicly available Argoverse Motion Forecasting dataset and compare them to other, purely neural network based methods for uncertainty estimation.",
        "primary_area": "",
        "author": "Jan Strohbeck;Johannes M\u00fcller;Martin Herrmann;Michael Buchholz;Jan Strohbeck;Johannes M\u00fcller;Martin Herrmann;Michael Buchholz",
        "authorids": "/37087103892;/37086442433;/37086231292;/38180084100;/37087103892;/37086442433;/37086231292;/38180084100",
        "aff": "Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982167/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7635374690736648257&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ulm University",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology",
        "aff_unique_url": "https://www.uni-ulm.de",
        "aff_unique_abbr": "Ulm U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ulm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981457",
        "title": "Deep Learning Classification of Touch Gestures Using Distributed Normal and Shear Force",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans socially interact with another agent (e.g., human, pet, or robot) through touch, they do so by applying varying amounts of force with different directions, locations, contact areas, and durations. While previous work on touch gesture recognition has focused on the spatio-temporal distribution of normal forces, we hypothesize that the addition of shear forces will permit more reliable classification. We present a soft, flexible skin with an array of tri-axial tactile sensors for the arm of a person or robot. We use it to collect data on 13 touch gesture classes through user studies and train a Convolutional Neural Network (CNN) to learn spatio-temporal features from the recorded data. The network achieved a recognition accuracy of 74% with normal and shear data, compared to 66% using only normal force data. Adding distributed shear data improved classification accuracy for 11 out of 13 touch gesture classes.",
        "primary_area": "",
        "author": "Hojung Choi;Dane Brouwer;Michael A. Lin;Kyle T. Yoshida;Carine Rognon;Benjamin Stephens-Fripp;Allison M. Okamura;Mark R. Cutkosky;Hojung Choi;Dane Brouwer;Michael A. Lin;Kyle T. Yoshida;Carine Rognon;Benjamin Stephens-Fripp;Allison M. Okamura;Mark R. Cutkosky",
        "authorids": "/37088198472;/37088853650;/37085798138;/37086964272;/37085688879;/37086337789;/37276156400;/37329470000;/37088198472;/37088853650;/37085798138;/37086964272;/37085688879;/37086337789;/37276156400;/37329470000",
        "aff": "Stanford University, USA; Stanford University, USA; Stanford University, USA; Stanford University, USA; Reality Labs Research, Meta Platforms Inc., Redmond, USA; Reality Labs Research, Meta Platforms Inc., Redmond, USA; Stanford University, USA; Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981457/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1383935086681138067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;0;0",
        "aff_unique_norm": "Stanford University;Meta",
        "aff_unique_dep": ";Reality Labs Research",
        "aff_unique_url": "https://www.stanford.edu;https://www.meta.com",
        "aff_unique_abbr": "Stanford;Meta",
        "aff_campus_unique_index": "0;0;0;0;1;1;0;0",
        "aff_campus_unique": "Stanford;Redmond",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981669",
        "title": "Deep Reinforcement Learning Based on Local GNN for Goal-Conditioned Deformable Object Rearranging",
        "track": "main",
        "status": "Poster",
        "abstract": "Object rearranging is one of the most common deformable manipulation tasks, where the robot needs to rearrange a deformable object into a goal configuration. Previous studies focus on designing an expert system for each specific task by model-based or data-driven approaches and the application scenarios are therefore limited. Some research has been attempting to design a general framework to obtain more advanced manipulation capabilities for deformable rearranging tasks, with lots of progress achieved in simulation. However, transferring from simulation to reality is difficult due to the limitation of the end-to-end CNN architecture. To address these challenges, we design a local GNN (Graph Neural Network) based learning method, which utilizes two representation graphs to encode keypoints detected from images. Self-attention is applied for graph updating and cross-attention is applied for generating manipulation actions. Extensive experiments have been conducted to demonstrate that our framework is effective in multiple 1-D (rope, rope ring) and 2-D (cloth) rearranging tasks in simulation and can be easily transferred to a real robot by fine-tuning a keypoint detector.",
        "primary_area": "",
        "author": "Yuhong Deng;Chongkun Xia;Xueqian Wang;Lipeng Chen;Yuhong Deng;Chongkun Xia;Xueqian Wang;Lipeng Chen",
        "authorids": "/37087323947;/37086260813;/37085383477;/37086579788;/37087323947;/37086260813;/37085383477;/37086579788",
        "aff": "The Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; The Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; The Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981669/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13945963522347282137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Tsinghua University;Tencent",
        "aff_unique_dep": "Center for Intelligent Control and Telescience;Robotics",
        "aff_unique_url": "http://www.tsinghua.edu.cn;https://www.tencent.com",
        "aff_unique_abbr": "Tsinghua;Tencent",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982133",
        "title": "Deep Reinforcement Learning based Robot Navigation in Dynamic Environments using Occupancy Values of Motion Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Deep Reinforcement Learning based navigation approach in which we define the occu-pancy observations as heuristic evaluations of motion primitives, rather than using raw sensor data. Our method enables fast mapping of the occupancy data, generated by multi-sensor fusion, into trajectory values in 3D workspace. The computationally efficient trajectory evaluation allows dense sampling of the action space. We utilize our occupancy observations in different data structures to analyze their effects on both training process and navigation performance. We train and test our methodology on two different robots within challenging physics-based simulation environments including static and dy-namic obstacles. We benchmark our occupancy representations with other conventional data structures from state-of-the-art methods. The trained navigation policies are also validated successfully with physical robots in dynamic environments. The results show that our method not only decreases the required training time but also improves the navigation performance as compared to other occupancy representations. The open-source implementation of our work and all related info are available at https://github.com/RIVeR-Lab/tentabot.",
        "primary_area": "",
        "author": "Ne\u015fet \u00dcnver Akmandor;Hongyu Li;Gary Lvov;Eric Dusel;Ta\u015fkin Padir;Ne\u015fet \u00dcnver Akmandor;Hongyu Li;Gary Lvov;Eric Dusel;Ta\u015fkin Padir",
        "authorids": "/37088594588;/37089621661;/37089661669;/37089661135;/38496444600;/37088594588;/37089621661;/37089661669;/37089661135;/38496444600",
        "aff": "Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982133/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=150346636313112478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Northeastern University;Institute for Experiential Robotics",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.northeastern.edu;",
        "aff_unique_abbr": "NU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981182",
        "title": "Deep Residual Reinforcement Learning based Autonomous Blimp Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Blimps are well suited to perform long-duration aerial tasks as they are energy efficient, relatively silent and safe. To address the blimp navigation and control task, in previous work we developed a hardware and software-in-the-loop framework and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, making PID controllers difficult to tune. Thus, often resulting in large tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to variations in ambient temperature and pressure. To address these issues, in this paper we present a learning-based framework based on deep residual reinforcement learning (DRRL), for the blimp control task. Within this framework, we first employ a PID controller to provide baseline performance. Subsequently, the DRRL agent learns to modify the PID decisions by interaction with the environment. We demonstrate in simulation that DRRL agent consistently improves the PID performance. Through rigorous simulation experiments, we show that the agent is robust to changes in wind speed and buoyancy. In real-world experiments, we demonstrate that the agent, trained only in simulation, is sufficiently robust to control an actual blimp in windy conditions. We openly provide the source code of our approach at https://github.com/robot-perception-group/AutonomousBlimpDRL. Video demonstration is provided at https://youtu.be/EMC4KnlH0yI.",
        "primary_area": "",
        "author": "Yu Tang Liu;Eric Price;Michael J. Black;Aamir Ahmad;Yu Tang Liu;Eric Price;Michael J. Black;Aamir Ahmad",
        "authorids": "/37088474833;/37086410453;/37265915500;/37085636639;/37088474833;/37086410453;/37265915500;/37085636639",
        "aff": "Institute for Flight Mechanics and Controls,The Faculty of Aerospace Engineering and Geodesy,University of Stuttgart, Stuttgart, Germany; Max Planck Institute for Intelligent Systems., T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems., T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems., T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981182/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3611377454681441668&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Stuttgart;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Institute for Flight Mechanics and Controls;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "Uni Stuttgart;MPI-IS",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Stuttgart;T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981931",
        "title": "DeepCIR: Insights into CIR-based Data-driven UWB Error Mitigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultra-Wide-Band (UWB) ranging sensors have been widely adopted for robotic navigation thanks to their extremely high bandwidth and hence high resolution. However, off-the-shelf devices may output ranges with significant errors in cluttered, severe non-line-of-sight (NLOS) environments. Recently, neural networks have been actively studied to improve the ranging accuracy of UWB sensors using the channel-impulse-response (CIR) as input. However, previous works have not systematically evaluated the efficacy of various packet types and their possible combinations in a two-way-ranging transaction, including poll, response and final packets. In this paper, we firstly investigate the utility of different packet types and their combinations when used as input for a neural network. Secondly, we propose two novel data-driven approaches, namely FMCIR and WMCIR, that leverage two-sided CIRs for efficient UWB error mitigation. Our approaches outperform state-of-the-art by a significant margin, further reducing range errors up to 45%. Finally, we create and release a dataset of transaction-level synchronized CIRs (each sample consists of the CIR of the poll, response and final packets), which will enable further studies in this area.",
        "primary_area": "",
        "author": "Vu Tran;Zhuangzhuang Dai;Niki Trigoni;Andrew Markham;Vu Tran;Zhuangzhuang Dai;Niki Trigoni;Andrew Markham",
        "authorids": "/37089235373;/37085774002;/37297514400;/37410667900;/37089235373;/37085774002;/37297514400;/37410667900",
        "aff": "Department of Computer Science, The University of Oxford; Department of Computer Science, The University of Oxford; Department of Computer Science, The University of Oxford; Department of Computer Science, The University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981931/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4657592304096348999&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981778",
        "title": "DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose DeepFusion, a modular multi-modal architecture to fuse lidars, cameras and radars in different combinations for 3D object detection. Specialized feature extractors take advantage of each modality and can be exchanged easily, making the approach simple and flexible. Extracted features are transformed into bird's-eye-view as a common representation for fusion. Spatial and semantic alignment is performed prior to fusing modalities in the feature space. Finally, a detection head exploits rich multi-modal features for improved 3D detection performance. Experimental results for lidar-camera, lidar-camera-radar and camera-radar fusion show the flexibility and effectiveness of our fusion approach. In the process, we study the largely unexplored task of faraway car detection up to 225 meters, showing the benefits of our lidar-camera fusion. Furthermore, we investigate the required density of lidar points for 3D object detection and illustrate implications at the example of robustness against adverse weather conditions. Moreover, ablation studies on our camera-radar fusion highlight the importance of accurate depth estimation.",
        "primary_area": "",
        "author": "Florian Drews;Di Feng;Florian Faion;Lars Rosenbaum;Michael Ulrich;Claudius Gl\u00e4ser;Florian Drews;Di Feng;Florian Faion;Lars Rosenbaum;Michael Ulrich;Claudius Gl\u00e4ser",
        "authorids": "/37085386178;/37086544464;/37089611758;/37086546688;/37699980100;/37699244900;/37085386178;/37086544464;/37089611758;/37086546688;/37699980100;/37699244900",
        "aff": "Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981778/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1887086268325584185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Robert Bosch GmbH",
        "aff_unique_dep": "Corporate Research",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981975",
        "title": "DeepMLE: A Robust Deep Maximum Likelihood Estimator for Two-view Structure from Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Two-view structure from motion (SfM) is the cornerstone of 3D reconstruction and visual SLAM (vSLAM). Many existing end-to-end learning-based methods usually formulate it as a brute regression problem. However, the inadequate utilization of traditional geometry model makes the model not robust in unseen environments. To improve the generalization capability and robustness of end-to-end two-view SfM network, we formulate the two-view SfM problem as a maximum likelihood estimation (MLE) and solve it with the proposed framework, denoted as DeepMLE. First, we propose to take the deep multi-scale correlation maps to depict the visual similarities of 2D image matches decided by ego-motion. In addition, in order to increase the robustness of our framework, we formulate the likelihood function of the correlations of 2D image matches as a Gaussian and Uniform mixture distribution which takes the uncertainty caused by illumination changes, image noise and moving objects into account. Meanwhile, an uncertainty prediction module is presented to predict the pixel-wise distribution parameters. Finally, we iteratively refine the depth and relative camera pose using the gradient-like information to maximize the likelihood function of the correlations. Extensive experimental results on several datasets prove that our method significantly outperforms the state-of-the-art end-to-end two-view SfM approaches in accuracy and generalization capability.",
        "primary_area": "",
        "author": "Yuxi Xiao;Li Li;Xiaodi Li;Jian Yao;Yuxi Xiao;Li Li;Xiaodi Li;Jian Yao",
        "authorids": "/37089663708;/38559914200;/37089660654;/37085387191;/37089663708;/38559914200;/37089660654;/37085387191",
        "aff": "School of School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, P.R. China; School of School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, P.R. China; School of School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, P.R. China; School of School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981975/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13084697366842081834&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Wuhan University",
        "aff_unique_dep": "School of Remote Sensing and Information Engineering",
        "aff_unique_url": "http://en.whu.edu.cn/",
        "aff_unique_abbr": "WHU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982097",
        "title": "DeepShapeKit: accurate 4D shape reconstruction of swimming fish",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present methods for capturing 4D body shapes of swimming fish with affordable small training datasets and textureless 2D videos. Automated capture of spatiotemporal animal movements and postures is revolutionizing the study of collective animal behavior. 4D (including 3D space + time) shape data from animals like schooling fish contains a rich array of social and non-social information that can be used to shed light on the fundamental mechanisms underlying collective behavior. However, unlike the large datasets used for 4D shape reconstructions of the human body, there are no large amounts of labeled training datasets for reconstructing fish bodies in 4D, due to the difficulty of underwater data collection. We created a template mesh model using 3D scan data from a real fish, then extracted silhouettes (segmentation masks) and key-points of the fish body using Mask R-CNN and DeepLabCut, respectively. Next, using the Adam optimizer, we optimized the 3D template mesh model for each frame by minimizing the difference between the projected 3D model and the detected silhouettes as well as the key-points. Finally, using an LSTM-based smoother, we generated accurate 4D shapes of schooling fish based on the 3D shapes over each frame. Our results show that the method is effective for 4D shape reconstructions of swimming fish, with greater fidelity than other state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Ruiheng Wu;Oliver Deussen;Liang Li;Ruiheng Wu;Oliver Deussen;Liang Li",
        "authorids": "/37089658373;/37266781000;/38468152300;/37089658373;/37266781000;/38468152300",
        "aff": "Department of Computer and Information Science, University of Konstanz, Germany; Centre for the Advanced Study of Collective Behaviour, University of Konstanz, Konstanz, Germany; Department of Biology, University of Konstanz, Konstanz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982097/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7271464184814277709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Konstanz",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.uni-konstanz.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Konstanz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981649",
        "title": "Deliberative Democracy with Robot Swarms",
        "track": "main",
        "status": "Poster",
        "abstract": "Decision-making among groups of humans can benefit from open discussion and inclusion of a diversity of opinions, promoting deliberative democracy. In this work, we test whether a swarm of robots can help facilitate decision-making by visually representing the diversity of opinions. We used a swarm of robots we built, called MOSAIX, that consists of 4-inch touchscreens-on-wheels robots called Tiles. The robots acted as physical avatars for opinions, helping them travel and mix together. We recruited 46 participants split into groups of 7 and 8 to test whether the robot movement had an impact on the decision-making process versus using the robots stationary in the participants' hands akin to smartphones. Furthermore, we wanted to test whether the participants felt comfortable expressing their opinion through the robots. Results show the participants indeed felt comfortable using the robots, and user engagement increased with the movement of the robots. The difference between the participants' first and last opinions also increased with the movement of the robots. We believe that robot swarms have not been used before to facilitate decision-making among a group of people. Therefore, our contribution is in testing the possibility of how and whether using a moving robot swarm helps humans reach a decision.",
        "primary_area": "",
        "author": "Merihan Alhafnawi;Edmund R. Hunt;Severin Lemaignan;Paul O'Dowd;Sabine Hauert;Merihan Alhafnawi;Edmund R. Hunt;Severin Lemaignan;Paul O'Dowd;Sabine Hauert",
        "authorids": "/37088762229;/37089448236;/38482927400;/38230680300;/37546505900;/37088762229;/37089448236;/38482927400;/38230680300;/37546505900",
        "aff": "Faculty of Engineering, University of Bristol, UK; Faculty of Engineering, University of Bristol, UK; Faculty of Environment and Technology, University of the West of England, Bristol, UK; Faculty of Engineering, University of Bristol, UK; Faculty of Engineering, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981649/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17348558064642347619&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Bristol;University of the West of England",
        "aff_unique_dep": "Faculty of Engineering;Faculty of Environment and Technology",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.uwe.ac.uk",
        "aff_unique_abbr": "UoB;UWE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981257",
        "title": "DeltaZ: An Accessible Compliant Delta Robot Manipulator for Research and Education",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the DeltaZ robot, a centimeter-scale, low-cost, delta-style robot that allows for a broad range of capabilities and robust functionalities. The DeltaZ robot is 3D-printed from soft and rigid materials with a design that is easy to assemble and maintain, and lowers the barriers to utilize. Functionality of the robot stems from its three translational degrees of freedom and a closed form kinematic solution which makes manipulation problems more intuitive compared to many other manipulators. Moreover, the low cost of the robot presents an opportunity to democratize manipulators for research and education settings. We describe how the robot can be used as a reinforcement learning bench-mark. Open-source 3D-printable designs and code for building and using the robot are available to the public.",
        "primary_area": "",
        "author": "Sarvesh Patil;Samuel C. Alvares;Pragna Mannam;Oliver Kroemer;F. Zeynep Temel;Sarvesh Patil;Samuel C. Alvares;Pragna Mannam;Oliver Kroemer;F. Zeynep Temel",
        "authorids": "/37089658154;/37089662935;/37088996626;/37593222300;/37944884400;/37089658154;/37089662935;/37088996626;/37593222300;/37944884400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Rose-Hulman Institute of Technology, Terre Haute, IN, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981257/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12399746126045610882&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Rose-Hulman Institute of Technology",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.rose-hulman.edu",
        "aff_unique_abbr": "CMU;Rose-Hulman",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Pittsburgh;Terre Haute",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981982",
        "title": "Demonstrate Once, Imitate Immediately (DOME): Learning Visual Servoing for One-Shot Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present DOME, a novel method for one-shot imitation learning, where a task can be learned from just a single demonstration and then be deployed immediately, without any further data collection or training. DOME does not require prior task or object knowledge, and can perform the task in novel object configurations and with distractors. At its core, DOME uses an image-conditioned object segmentation network followed by a learned visual servoing network, to move the robot's end-effector to the same relative pose to the object as during the demonstration, after which the task can be completed by replaying the demonstration's end-effector velocities. We show that DOME achieves near 100% success rate on 7 real-world everyday tasks, and we perform several studies to thoroughly understand each individual component of DOME. Videos and supplementary material are available at: https://www.robot-learning.uk/dome.",
        "primary_area": "",
        "author": "Eugene Valassakis;Georgios Papagiannis;Norman Di Palo;Edward Johns;Eugene Valassakis;Georgios Papagiannis;Norman Di Palo;Edward Johns",
        "authorids": "/37088689402;/37088996689;/37089196767;/37602799000;/37088689402;/37088996689;/37089196767;/37602799000",
        "aff": "The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981982/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6999260377005585196&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981794",
        "title": "Dependability Analysis of Deep Reinforcement Learning based Robotics and Autonomous Systems through Probabilistic Model Checking",
        "track": "main",
        "status": "Poster",
        "abstract": "While Deep Reinforcement Learning (DRL) provides transformational capabilities to the control of Robotics and Autonomous Systems (RAS), the black-box nature of DRL and uncertain deployment environments of RAS pose new challenges on its dependability. Although existing works impose constraints on the DRL policy to ensure successful completion of the mission, it is far from adequate to assess the DRL-driven RAS in a holistic way considering all dependability properties. In this paper, we formally define a set of dependability properties in temporal logic and construct a Discrete-Time Markov Chain (DTMC) to model the dynamics of risk/failures of a DRL-driven RAS interacting with the stochastic environment. We then conduct Probabilistic Model Checking (PMC) on the designed DTMC to verify those properties. Our experimental results show that the proposed method is effective as a holistic assessment framework while uncovering conflicts between the properties that may need trade-offs in training. Moreover, we find that the standard DRL training cannot improve dependability properties, thus requiring bespoke optimisation objectives. Finally, our method offers sensitivity analysis of dependability properties to disturbance levels from environments, providing insights for the assurance of real RAS.",
        "primary_area": "",
        "author": "Yi Dong;Xingyu Zhao;Xiaowei Huang;Yi Dong;Xingyu Zhao;Xiaowei Huang",
        "authorids": "/37088957127;/37086526949;/37086944121;/37088957127;/37086526949;/37086944121",
        "aff": "Department of Computer Science, University of Liverpool, UK; Department of Computer Science, University of Liverpool, UK; Department of Computer Science, University of Liverpool, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981794/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5381787732879459429&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Liverpool",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.liverpool.ac.uk",
        "aff_unique_abbr": "Liv Uni",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982161",
        "title": "Depth-CUPRL: Depth-Imaged Contrastive Unsupervised Prioritized Representations in Reinforcement Learning for Mapless Navigation of Unmanned Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) has presented an impressive performance in video games through raw pixel imaging and continuous control tasks. However, RL performs poorly with high-dimensional observations such as raw pixel images. It is generally accepted that physical state-based RL policies such as laser sensor measurements give a more sample-efficient result than learning by pixels. This work presents a new approach that extracts information from a depth map estimation to teach an RL agent to perform the mapless navigation of Unmanned Aerial Vehicle (UAV). We propose the Depth-Imaged Contrastive Unsupervised Prioritized Representations in Reinforcement Learning (Depth-CUPRL) that estimates the depth of images with a prioritized replay memory. We used a combination of RL and Contrastive Learning to lead with the problem of RL based on images. From the analysis of the results with Unmanned Aerial Vehicles (UAVs), it is possible to conclude that our Depth-CUPRL approach is effective for the decision-making and outperforms state-of-the-art pixel-based approaches in the mapless navigation capability.",
        "primary_area": "",
        "author": "Junior C. de Jesus;Victor A. Kich;Alisson H. Kolling;Ricardo B. Grando;Rodrigo S. Guerra;Paulo L. J. Drews;Junior C. de Jesus;Victor A. Kich;Alisson H. Kolling;Ricardo B. Grando;Rodrigo S. Guerra;Paulo L. J. Drews",
        "authorids": "/37088754453;/37088996004;/37089001470;/37088755051;/37089143479;/38520902100;/37088754453;/37088996004;/37089001470;/37088755051;/37089143479;/38520902100",
        "aff": "NAUTEC, Centro de Ciencias Computacionais, Universidade Federal do Rio Grande - FURG, RS, Brazil; Universidade Federal de Santa Maria - UFSM, RS, Brazil; Universidade Federal de Santa Maria - UFSM, RS, Brazil; Technological University of Uruguay, Rivera, Uruguay; Universidade Federal de Santa Maria - UFSM, RS, Brazil; NAUTEC, Centro de Ciencias Computacionais, Universidade Federal do Rio Grande - FURG, RS, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982161/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7206933429927384929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "Universidade Federal do Rio Grande - FURG;Universidade Federal de Santa Maria;Technological University of Uruguay",
        "aff_unique_dep": "Centro de Ciencias Computacionais;;",
        "aff_unique_url": "https://www.furg.br;https://www.ufsm.br;https://www.utu.edu.uy",
        "aff_unique_abbr": "FURG;UFSM;UTU",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Santa Maria;Rivera",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Brazil;Uruguay"
    },
    {
        "id": "9981751",
        "title": "Depth360: Self-supervised Learning for Monocular Depth Estimation using Learnable Camera Distortion Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised monocular depth estimation has been widely investigated to estimate depth images and relative poses from RGB images. This framework is promising because the depth and pose networks can be trained from just time-sequence images without the need for the ground truth depth and poses. In this work, we estimate the depth around a robot (360\u00b0 view) using time-sequence spherical camera images, from a camera whose parameters are unknown. We propose a learnable axisymmetric camera model which accepts distorted spherical camera images with two fisheye camera images as well as pinhole camera images. In addition, we trained our models with a photo-realistic simulator to generate ground truth depth images to provide supervision. Moreover, we introduced loss functions to provide floor constraints to reduce artifacts that can result from reflective floor surfaces. We demonstrate the efficacy of our method using the spherical camera images from the GO Stanford dataset and pinhole camera images from the KITTI dataset to compare our method's performance with that of baseline method in learning the camera parameters.",
        "primary_area": "",
        "author": "Noriaki Hirose;Kosuke Tahara;Noriaki Hirose;Kosuke Tahara",
        "authorids": "/37574851500;/37087107692;/37574851500;/37087107692",
        "aff": "Toyota Central R&D Labs., Inc., Aichi, Japan; Toyota Central R&D Labs., Inc., Aichi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981751/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10231541821319845093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982149",
        "title": "Design Interface Mapping for Efficient Free-form Tele-manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion tracking interfaces are intuitive for free-form teleoperation tasks. However, efficient manipulation control can be difficult with such interfaces because of issues like the interference of unintended motions and the limited precision of human motion control. The limitation in control efficiency reduces the operator's performance and increases their workload and frustration during robot teleoperation. To improve the efficiency, we proposed separating controlled degrees of freedom (DoFs) and adjusting the motion scaling ratio of a motion tracking interface. The motion tracking of handheld controllers from a Virtual Reality system was used for the interface. We separated the translation and rotational control into: 1) two controllers held in the dominant and non-dominant hands and 2) hand pose tracking and trackpad inputs of a controller. We scaled the control mapping ratio based on 1) the environmental constraints and 2) the teleoperator's control speed. We further conducted a user study to investigate the effectiveness of the proposed methods in increasing efficiency. Our results show that the separation of position and orientation control into two controllers and the environment-based scaling methods perform better than their alternatives.",
        "primary_area": "",
        "author": "Achyuthan Unni Krishnan;Tsung-Chi Lin;Zhi Li;Achyuthan Unni Krishnan;Tsung-Chi Lin;Zhi Li",
        "authorids": "/37087323052;/37087325287;/37085821311;/37087323052;/37087325287;/37085821311",
        "aff": "Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982149/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16773742393720146722&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981352",
        "title": "Design Optimization of an Ultrafast-Striking Mantis Shrimp Microrobot",
        "track": "main",
        "status": "Poster",
        "abstract": "Mantis shrimp produce one of the fastest strikes in the animal kingdom, their striking appendages reaching tip velocities of tens of meters per second underwater. Their ultrafast movement is capable of crushing the shells of prey and generating cavitation bubbles, and has long raised interest from the scientific community. To study the underlying mechanisms and operating principles behind these behaviors, prior research has developed physical models that mimic the motions and speeds of mantis shrimp. That microrobot demonstrated speeds of approximately 5 m/s in water and 26 m/s in air. Here we utilize an accurate dynamical model of the four-bar mechanism and geometric latch observed in biological shrimp in a numerical trajectory optimization approach to find the design changes that can maximize the microrobot's striking velocities. Through a suboptimization problem maximizing the energy loaded in the mechanism's spring, we manage to improve the performance of the microrobot by over 58%, reaching tip velocities of 41.2 \\pm 0.641.2 \\pm 0.6 m/s.",
        "primary_area": "",
        "author": "Sandra C. Wells;Nak-Seung P. Hyun;Emma Steinhardt;Tran H. Nguyen;Robert J. Wood;Sandra C. Wells;Nak-Seung P. Hyun;Emma Steinhardt;Tran H. Nguyen;Robert J. Wood",
        "authorids": "/37088919856;/37085360876;/37089660334;/37089662068;/37326227400;/37088919856;/37085360876;/37089660334;/37089662068;/37326227400",
        "aff": "ETH Z\u00fcrich, Z\u00fcrich, Switzerland; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981352/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11068283605116962275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "ETH Zurich;Harvard University",
        "aff_unique_dep": ";School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.ethz.ch;https://www.harvard.edu",
        "aff_unique_abbr": "ETHZ;Harvard",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Z\u00fcrich;Boston",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9981191",
        "title": "Design and Analysis of Truss Aerial Transportation System (TATS): The Lightweight Bar Spherical Joint Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "In aerial cooperative transportation missions, it has been recognized that for small-sized but heavy payloads, the cable-suspended framework is a preferred manner. However, to maintain proper safe flight distances, cables always stay inclined, which implies that horizontal force components have to be generated by UAVs, and only partial thrust forces are used for gravity compensation. To overcome this drawback, in this paper, a new cooperative transportation system named Truss Aerial Transportation System (TATS) is proposed, where those horizontal forces can be internally compensated by the bar spherical joint structure. In the TATS, rigid bars can powerfully sustain the desired distances among UAVs for safe flight, resulting in a more compact and effective transportation system. Thanks to the structural advantage of the truss, the rigid bars can be made lightweight so as to minimize their induced gravity burden. The construction method of the proposed TATS is presented. The improvement in energy efficiency is analyzed and compared with the cable-suspended framework. Furthermore, the robustness property of a TATS configuration is evaluated by computing the margin capacity. Finally, a load test experiment is conducted on our made prototype, the results of which show the effectiveness and feasibility of the proposed TATS.",
        "primary_area": "",
        "author": "Xiaozhen Zhang;Qingkai Yang;Rui Yu;Delong Wu;Shaozhun Wei;Jinqiang Cui;Hao Fang;Xiaozhen Zhang;Qingkai Yang;Rui Yu;Delong Wu;Shaozhun Wei;Jinqiang Cui;Hao Fang",
        "authorids": "/37088347835;/37077823200;/37089663846;/37089662328;/37089660486;/37089661931;/37398431100;/37088347835;/37077823200;/37089663846;/37089662328;/37089660486;/37089661931;/37398431100",
        "aff": "State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China; Department of Mathematics and Theories Peng Cheng Laboratory, Shenzhen, China; State Key Laboratory of Intelligent Control and Decision of Complex System School of Automation Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981191/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15853552297597025062&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Beijing Institute of Technology;Pengcheng Laboratory",
        "aff_unique_dep": "School of Automation;Department of Mathematics and Theories",
        "aff_unique_url": "http://www.bit.edu.cn/;",
        "aff_unique_abbr": "BIT;",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981855",
        "title": "Design and Characterisation of a Soft Barometric Sensing Skin for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft sensorised skins are essential for improving robotic manipulation capabilities towards that of humans. Integration of sensors into existing robotic hands is challenging due to rigidity of components, low packing density or poor sensor response. We propose a sensorised skin, based-on barometric sensing, which can be molded over a skeletal robot hand. The sensors connect air chambers embedded in the soft skin to wrist-mounted pressure sensors, allowing sensor spacing 2\u20134 mm, force ranges from 23 mN to 5700 mN and bandwidth of 20 Hz. Integrating this with a skeletal hand allows us to showcase the potential of these sensors to aid robotic manipulation. We demonstrate 3-axis contact modelling, useful for in-hand manipulation and exploration. In addition, by grasping a chopstick and sensing forces transmitted from the environment, the system can remotely detect small environmental features, e.g., hole finding using tools.",
        "primary_area": "",
        "author": "Kieran Gilday;Louis Relandeau;Fumiya Iida;Kieran Gilday;Louis Relandeau;Fumiya Iida",
        "authorids": "/37086574748;/37089661272;/37552719700;/37086574748;/37089661272;/37552719700",
        "aff": "Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981855/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9368326696634833473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981940",
        "title": "Design and Characterization of 3D Printed, Open-Source Actuators for Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Impressive animal locomotion capabilities are mediated by the co-evolution of the skeletal morphology and muscular properties. Legged robot performance would also likely benefit from the co-optimization of actuators and leg morphology. However, development of custom actuators for legged robots is expensive and time consuming, discouraging application-specific actuator optimization. This paper presents open-source designs for two quasi-direct-drive actuators with performance regimes appropriate for an 8\u201315 kg robot, built from off the shelf and 3D-printed components for less than $200 USD each. The mechanical, electrical, and thermal properties of each actuator are characterized and compared to benchmark data. Actuators subjected to 420k strides of gait data experienced only a 2% reduction in efficiency and 26 mrad in backlash growth, demonstrating viability for rigorous and sustained research applications. We present a thermal solution that nearly doubles the thermally-driven torque limits of our plastic actuator design. The performance results are comparable to traditional metallic actuators for use in high-speed legged robots of the same scale. These 3D printed designs demonstrate an approach for designing and characterizing low-cost, highly customizable and reproducible actuators, democratizing the field of actuator design and enabling co-design and optimization of actuators and robot legs.",
        "primary_area": "",
        "author": "Karthik Urs;Challen Enninful Adu;Elliott J. Rouse;Talia Y. Moore;Karthik Urs;Challen Enninful Adu;Elliott J. Rouse;Talia Y. Moore",
        "authorids": "/37089659281;/37089658914;/37991140400;/37089658780;/37089659281;/37089658914;/37991140400;/37089658780",
        "aff": "Robotics, Ann Arbor, MI, USA; Robotics, Ann Arbor, MI, USA; Mechanical Engineering, Ann Arbor, MI, USA; Ecology and Evolutionary Biology, and the Museum of Zoology, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981940/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3121492983919563486&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982126",
        "title": "Design and Control of a Multi-Modal Soft Gripper Inspired by Elephant Fingers",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft grippers have the potential to solve many existing manipulation challenges, particularly in agile industry applications. However, existing soft grippers are often limited in the range of objects they can pick, or by cluttered environments. We present a design inspired by the nose and fingers at the end of an elephant's trunk, which can pick both by suction and pinching, allowing increased grasping diversity. In addition, we observe an emergent grasping mode, a hybrid of pinching and suction where the cup aperture is morphed online, using embedded soft fingers, to form a seal over challenging objects. An algorithmic grasping strategy, based-on analytical grasping models and primitive objects, is presented. With this, we predict grasping performance and show increased grasping range compared to other soft gripper designs. Finally, the gripper and grasping strategy are successfully applied to grasping more varied everyday objects, demonstrating exploitation of this multi-modal gripping for adaptive grasping.",
        "primary_area": "",
        "author": "Shogo Washio;Kieran Gilday;Fumiya Iida;Shogo Washio;Kieran Gilday;Fumiya Iida",
        "authorids": "/37089663834;/37086574748;/37552719700;/37089663834;/37086574748;/37552719700",
        "aff": "Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982126/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4207860375205109404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981526",
        "title": "Design and Development of a Lorentz Force-Based MRI-Driven Neuroendoscope",
        "track": "main",
        "status": "Poster",
        "abstract": "The introduction of neuroendoscopy, microneu- rosurgery, neuronavigation, and intraoperative imaging for surgical operations has made significant improvements over other traditionally invasive surgical techniques. The integration of magnetic resonance imaging (MRI)-driven surgical devices with intraoperative imaging and endoscopy can enable further advancements in surgical treatments and outcomes. This work proposes the design and development of an MRI-driven endo- scope leveraging the high (3\u20137 T), external magnetic field of an MR scanner for heat-mitigated steering within the ventricular system of the brain. It also demonstrates the effectiveness of a Lorentz force-based grasper for diseased tissue manipulation and ablation. Feasibility studies show the neuroendoscope can be steered precisely within the lateral ventricle to locate a tumor using both MRI and endoscopic guidance. Results also indicate grasping forces as high as 31 mN are possible and power inputs as low as 0.69 mW can cause cancerous tissue ablation. These findings enable further developments of steerable devices using MR imaging integrated with endoscopic guidance for improved outcomes.",
        "primary_area": "",
        "author": "Martin Francis Phelan;Nihal Olcay Dogan;Jelena Lazovic;Metin Sitti;Martin Francis Phelan;Nihal Olcay Dogan;Jelena Lazovic;Metin Sitti",
        "authorids": "/37089661929;/37089661800;/37086503153;/37265828200;/37089661929;/37089661800;/37086503153;/37265828200",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Biomedical Engineering, ETH Zurich, Zurich, Switzerland; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; College of Engineering and School of Medicine, Ko\u00e7 University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981526/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3198526920891477690&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Carnegie Mellon University;ETH Zurich;Max Planck Institute for Intelligent Systems;Ko\u00e7 University",
        "aff_unique_dep": "Department of Mechanical Engineering;Institute for Biomedical Engineering;Physical Intelligence Department;College of Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.ethz.ch;https://www.mpi-is.mpg.de;https://www.koc.edu.tr",
        "aff_unique_abbr": "CMU;ETHZ;MPI-IS;Ko\u00e7",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "Pittsburgh;Zurich;Stuttgart;Istanbul",
        "aff_country_unique_index": "0;1;2;3",
        "aff_country_unique": "United States;Switzerland;Germany;T\u00fcrkiye"
    },
    {
        "id": "9981503",
        "title": "Design and Evaluation of the infant Cardiac Robotic Surgical System (iCROSS)",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, the infant Cardiac Robotic Surgical System (iCROSS) is developed to assist a surgeon in performing the patent ductus arteriosus (PDA) closure and other infant cardiac surgeries. The iCROSS is a dual-arm robot allowing two surgical instruments to collaborate in a narrow space while keeping a sufficiently large workspace. Compared with the existing surgical robotic systems, the iCROSS meets the specific requirements of infant cardiac surgeries. Its feasibility has been validated through several teleoperated tasks performed in the experiment. In particular, the iCROSS is able to perform surgical ligation successfully within one minute.",
        "primary_area": "",
        "author": "Po-Chih Chen;Pei-An Hsieh;Jing-Yuan Huang;Shu-Chien Huang;Cheng-Wei Chen;Po-Chih Chen;Pei-An Hsieh;Jing-Yuan Huang;Shu-Chien Huang;Cheng-Wei Chen",
        "authorids": "/37089658644;/37089662758;/37088859242;/37089662942;/38026044800;/37089658644;/37089662758;/37088859242;/37089662942;/38026044800",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Surgery, National Taiwan University Hospital, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981503/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:AtlVurnUCVIJ:scholar.google.com/&scioq=Design+and+Evaluation+of+the+infant+Cardiac+Robotic+Surgical+System+(iCROSS)&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "National Taiwan University;National Taiwan University Hospital",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Surgery",
        "aff_unique_url": "https://www.ntu.edu.tw;https://www.ntuh.gov.tw",
        "aff_unique_abbr": "NTU;NTUH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981896",
        "title": "Design and Experiments of Snake Robots with Docking Function",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel snake robot with the docking function, which can help the snake robots to connect with each other to achieve a stronger one with double length and double degrees of freedom. First, the mechanical design of the snake robot with docking function is introduced, including the body link and the head-tail passive docking mechanical structure. Second, the control system is built, and the control strategies of locomotion and docking are separately proposed. Then, the visual perception function is implemented for the target recognition during the docking process. Finally, the prototype is developed. The mobility and the docking function are fully verified and analyzed through the physical experiments.",
        "primary_area": "",
        "author": "Fatao Qin;Xiaojie Duan;Shihao Ma;Jinglun Yuan;Xiangyu Wang;Jianming Wang;Xuan Xiao;Fatao Qin;Xiaojie Duan;Shihao Ma;Jinglun Yuan;Xiangyu Wang;Jianming Wang;Xuan Xiao",
        "authorids": "/37089663520;/37086022646;/37089663296;/37089663037;/37089661677;/37538990400;/37088987287;/37089663520;/37086022646;/37089663296;/37089663037;/37089661677;/37538990400;/37088987287",
        "aff": "School of Electronic and Information Engineering, Tiangong University, Tianjin, China; School of Electronic and Information Engineering, Tiangong University, Tianjin, China; School of Electronic and Information Engineering, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Electronic and Information Engineering, Tiangong University, Tianjin, China; Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981896/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18051612573092642199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Tiangong University;Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems",
        "aff_unique_dep": "School of Electronic and Information Engineering;Autonomous Intelligence Technology and Systems",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tianjin;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982261",
        "title": "Design and Modelling of A Spring-Like Continuum Joint with Variable Pitch for Endoluminal Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "In endoluminal surgery, the miniature instruments shall be of high accuracy and flexibility for minimal invasive diagnosis and surgical intervention. To this end, continuum robots with flexible joints have been proposed as the mechanism of endoscopic instruments. The compliance and deformability of the continuum joints enable access into the curved lumen. However, the manufacturing tolerances are normally not considered in the design procedure, and led to inaccuracy in the robotic control. To improve the control accuracy and flexibility of endoluminal surgical robots, we propose a novel design of a metal printed continuum joint in this paper, which incorporates a variable pitch design into the spring-like structure. The design can reduce the position errors accumulated on the distal tip of the joint, especially at large bending angles. The specification of variable pitch is investigated and determined with a friction model. In addition, to eliminate the distortion of the joint induced during the metal printing process, an extensive experiment was conducted to access the effect of the variables in the design (pitch, thickness, width and number of coils), with the aim of determining optimal parameters for reducing discrepancy caused by manufacturing variations. The final results indicated that the bending error of a single joint can be reduced from 18.10% to 4.63%, and a multi-segment prototype was developed to verify its effectiveness for potential surgical applications.",
        "primary_area": "",
        "author": "Wei Li;Dandan Zhang;Guang-Zhong Yang;Benny Lo;Wei Li;Dandan Zhang;Guang-Zhong Yang;Benny Lo",
        "authorids": "/37086577761;/37086595836;/37276270800;/38183567000;/37086577761;/37086595836;/37276270800;/38183567000",
        "aff": "Hamlyn Centre for Robotic Surgery at Imperial College London, London, UK; Bristol Robotics Lab and the Department of Engineering Mathematics, University of Bristol, United Kingdom; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; Hamlyn Centre for Robotic Surgery at Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982261/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3053994574059566890&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Imperial College London;University of Bristol;Shanghai Jiao Tong University",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery;Department of Engineering Mathematics;Institute of Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.bristol.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Imperial College;UoB;SJTU",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "London;;Shanghai",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9981305",
        "title": "Design of EMG-driven Musculoskeletal Model for Volitional Control of a Robotic Ankle Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing robotic lower-limb prostheses use autonomous control to address cyclic, locomotive tasks, but are inadequate in adapting to variations in non-cyclic and unpredictable tasks. This study aims to address this challenge by designing a novel electromyography (EMG)-driven musculoskeletal model for volitional control of a robotic ankle-foot prosthesis. The proposed controller ensures continuous control of the device, allowing users to freely manipulate the prosthesis behavior. A Hill-type muscle model was implemented to model a dorsiflexor and a plantarflexor to function around a virtual ankle joint. The model parameters for a subject specific model was determined by fitting the model to the experimental data collected from an able-bodied subject. EMG signals recorded from antagonist muscle pairs were used to activate the virtual muscle models. This model-based approach was then validated via offline simulations and real-time prosthesis control. Additionally, the feasibility of the proposed prosthesis control on assisting the user's functional tasks was demonstrated. The present control may further improve the function of robotic prosthesis for supporting versatile activities in individuals with lower-limb amputations.",
        "primary_area": "",
        "author": "Chinmay Shah;Aaron Fleming;Varun Nalam;Ming Liu;He Helen Huang;Chinmay Shah;Aaron Fleming;Varun Nalam;Ming Liu;He Helen Huang",
        "authorids": "/37086142233;/37086495165;/37086046980;/38237723700;/37401091200;/37086142233;/37086495165;/37086046980;/38237723700;/37401091200",
        "aff": "Department of Mechanical and Aerospace Engineering, North Carolina State University, USA; Joint Department of Biomedical Engineering, North Carolina State University and University of North Carolina at Chapel Hill, USA; Joint Department of Biomedical Engineering, North Carolina State University and University of North Carolina at Chapel Hill, USA; Joint Department of Biomedical Engineering, North Carolina State University and University of North Carolina at Chapel Hill, USA; Joint Department of Biomedical Engineering, North Carolina State University and University of North Carolina at Chapel Hill, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981305/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16476948933957811744&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "North Carolina State University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ncsu.edu",
        "aff_unique_abbr": "NCSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981125",
        "title": "Design of a Reconfigurable Robot with Size-Adaptive Path Planner",
        "track": "main",
        "status": "Poster",
        "abstract": "Area coverage is demanded from the robots utilized in application domains such as floor cleaning. Even though many advanced coverage algorithms have been developed, the area coverage performance is limited due to the inaccessibility of narrow spaces caused by physical constraints. Reconfigurable robots have been introduced to overcome this limitation where reconfigurability could help in assessing narrow spaces. Nevertheless, the state-of-the-art reconfigurable robots are not capable of changing the morphology size and shape as a single entity. Therefore, this paper proposes a novel design of a reconfigurable robot with a size-adaptive coverage strategy. The reconfiguration mechanism is designed in such a way that the robot can independently expand or shrink its size along the principal planar axes, where the behavior allows the change of size and shape. The coverage strategy is based on boustrophedon motion and the A* algorithm modified for accessing narrow areas using the size adaptability. The design of the robot is detailed in the paper, including electro-mechanical aspects, design considerations, and the coverage path planning method. Experiments have been conducted using a prototype of the proposed design to analyze and evaluate the characteristics and the performance of the robot. The results show that the proposed robot design can improve the productivity of a floor cleaning robot in terms of area coverage and coverage time.",
        "primary_area": "",
        "author": "S. M. Bhagya P. Samarakoon;M. A. Viraj J. Muthugala;Manivannan Kalimuthu;Sathis Kumar Chandrasekaran;Mohan Rajesh Elara;S. M. Bhagya P. Samarakoon;M. A. Viraj J. Muthugala;Manivannan Kalimuthu;Sathis Kumar Chandrasekaran;Mohan Rajesh Elara",
        "authorids": "/37086182161;/37085785341;/37086445348;/37089659493;/37546093700;/37086182161;/37085785341;/37086445348;/37089659493;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981125/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16223687519032460608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981189",
        "title": "Design of a Soft Wearable Passive Fitness Device for Upper Limb Resistance Exercise",
        "track": "main",
        "status": "Poster",
        "abstract": "An increase in health awareness has fueled the development of fitness equipment or devices nowadays. Most conventional fitness devices have had some issues in space limitation and the high cost of equipment. With the advance in wearable robotics, we proposed a soft passive fitness wearable device for upper limb resistance exercises such as chest press, frontal raise, and chest fly. Users can customize the exercise intensity by adjusting the length of the elastic bands embedded in the wearable device. Moreover, the exer-tainment (Exercise-entertainment) user display interface was designed to motivate the user. Movements of users were estimated using inertial measurement units (IMUs), and haptic feedback was provided through the vibro-stimulation. Furthermore, the effectiveness of the proposed device was evaluated with the Borg scales representing the rating of perceived exertion (RPE) and measuring the surface electromyography (sEMG) of the three muscles located one on the shoulder and two on the chest. Both the Borg 6\u201320 and CR 10 scales were increased, and the normalized sEMG activities of the upper limb muscles with the activated device had more than double in magnitude compared to that with a bare condition; therefore, the proposed device has a potential effectiveness as for resistance exercise. Overall, this research devotes preliminary evidence on the benefits of the device in promoting the user to work out and contributing to the exercise effects.",
        "primary_area": "",
        "author": "Junghoon Park;Jaehong Kim;Dong Hyun Kim;Jungsik Hwang;Youngtae G. Kim;SeungYong Hyung;Soon-Heum Ko;Minhyung Lee;Junghoon Park;Jaehong Kim;Dong Hyun Kim;Jungsik Hwang;Youngtae G. Kim;SeungYong Hyung;Soon-Heum Ko;Minhyung Lee",
        "authorids": "/37089658432;/37089663029;/37089661855;/37089658714;/37089659016;/38540153800;/37089662126;/38252785200;/37089658432;/37089663029;/37089661855;/37089658714;/37089659016;/38540153800;/37089662126;/38252785200",
        "aff": "Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea; Samsung Research, Seocho-gu, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981189/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17709607397353486093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "Samsung Research",
        "aff_unique_url": "https://www.samsung.com/global/research/",
        "aff_unique_abbr": "Samsung",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981127",
        "title": "Design of a low-cost passive acoustic monitoring system for animal localisation from calls",
        "track": "main",
        "status": "Poster",
        "abstract": "The field of bioacoustics is concerned with monitoring wild animals based on their vocalisations. Passive acoustic recorders are now commonly used to collect data of the soundscapes of our wild places. While the data they collect is extremely useful, the majority of the recorders use a single omnidirectional microphone, and thus cannot independently perform localisation of a calling animal. Localisation can be useful to differentiate between multiple calling animals, to improve statistical estimates of abundance, and to locate calling posts, which may be close to nests. In this paper, we consider the design of a low-cost, practical, passive directional acoustic recorder that will facilitate animal localisation, and present and evaluate a prototype system for this purpose.",
        "primary_area": "",
        "author": "Benjamin Yen;Jemima Prins;Gian Schmid;Yusuke Hioka;Susan Ellis;Stephen Marsland;Benjamin Yen;Jemima Prins;Gian Schmid;Yusuke Hioka;Susan Ellis;Stephen Marsland",
        "authorids": "/37086505689;/37089662355;/37085885598;/38565532300;/37089659894;/37271839400;/37086505689;/37089662355;/37085885598;/38565532300;/37089659894;/37271839400",
        "aff": "Department of Mechanical and Mechatronics Engineering, Acoustics Research Centre, University of Auckland, Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, Acoustics Research Centre, University of Auckland, Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, Acoustics Research Centre, University of Auckland, Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, Acoustics Research Centre, University of Auckland, Auckland, New Zealand; GNS SCience, Lower Hutt, New Zealand; School of Mathematics and Statistics, Victoria University of Wellington, Wellington, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981127/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15125825105341692776&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "University of Auckland;GNS Science;Victoria University of Wellington",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;;School of Mathematics and Statistics",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.gns.cri.nz;https://www.victoria.ac.nz",
        "aff_unique_abbr": "UoA;;VUW",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Auckland;Lower Hutt;Wellington",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9982238",
        "title": "Design of a modular continuum robot with alterable compliance using tubular-actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Compliance is good. However, it is challenging for one compliant continuum robot to finish both high precision manipulation and environmental-adapted motions. In this paper, a modular continuum robot with the alterable compliance characteristic is proposed. Besides, an actuation module is also proposed using a tubular-screw mechanism for non-slippage transmission. Kinematic analyses and dynamic co-simulation are performed to study the continuum robot. Furthermore, two potential application scenarios of pick-and-place manipulation and confined space navigating are carried out to demonstrate the advantages of the alterable compliance design. This study presents a capable continuum robotic solution for non-structural inspection tasks, with potential for in-situ applications in restricted and hazardous environments.",
        "primary_area": "",
        "author": "Mingyuan Wang;Liang Du;Sheng Bao;Jianjun Yuan;Jinshu Zhou;Shugen Ma;Mingyuan Wang;Liang Du;Sheng Bao;Jianjun Yuan;Jinshu Zhou;Shugen Ma",
        "authorids": "/37089197781;/37087006997;/37088951181;/37293594200;/37089658570;/37280187400;/37089197781;/37087006997;/37088951181;/37293594200;/37089658570;/37280187400",
        "aff": "Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Department of Robotics, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982238/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10138246760172948862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Shanghai University;Ritsumeikan University",
        "aff_unique_dep": "Shanghai Robotics Institute;Department of Robotics",
        "aff_unique_url": "https://www.shu.edu.cn;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SHU;Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shanghai;Shiga",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9981806",
        "title": "Design, Modeling and Control for a Tilt-rotor VTOL UAV in the Presence of Actuator Failure",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling vertical take-off and landing while pro-viding the ability to fly long ranges opens the door to a wide range of new real-world aircraft applications while improving many existing tasks. Tiltrotor vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs) are a better choice than fixed-wing and multirotor aircraft for such applications. Prior works on these aircraft have addressed the aerodynamic performance, design, modeling, and control. However, a less explored area is the study of their potential fault tolerance due to their inherent redundancy, which allows them to tol-erate some degree of actuation failure. This paper introduces tolerance to several types of actuator failures in a tiltrotor VTOL aircraft. We discuss the design and modeling of a custom tiltrotor VTOL UAV, which is a combination of a fixed-wing aircraft and a quadrotor with tilting rotors, where the four propellers can be rotated individually. Then, we analyze the feasible wrench space the vehicle can generate and design the dynamic control allocation so that the system can adapt to actuator failures, benefiting from the configuration redundancy. The proposed approach is lightweight and is implemented as an extension to an already-existing flight control stack. Extensive experiments validate that the system can maintain the controlled flight under different actuator failures. To the best of our knowledge, this work is the first study of the tiltrotor VTOL's fault-tolerance that exploits the configuration redundancy. The source code and simulation can be accessed from https://theairlab.org/vtol.",
        "primary_area": "",
        "author": "Mohammadreza Mousaei;Junyi Geng;Azarakhsh Keipour;Dongwei Bai;Sebastian Scherer;Mohammadreza Mousaei;Junyi Geng;Azarakhsh Keipour;Dongwei Bai;Sebastian Scherer",
        "authorids": "/37086172398;/37089251620;/38547709500;/37089662448;/37584159000;/37086172398;/37089251620;/38547709500;/37089662448;/37584159000",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics AI, Amazon, Washington, DC, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981806/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16846342586604620334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Amazon",
        "aff_unique_dep": "The Robotics Institute;Robotics AI",
        "aff_unique_url": "https://www.cmu.edu;https://www.amazon.com",
        "aff_unique_abbr": "CMU;Amazon",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Washington, DC",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982090",
        "title": "Design, Modeling and Control of a Composable and Extensible Drone with Tilting Rotors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a composable and extensible drone with tilting rotors (CEDTR). We aimed for a function that could optimally match the load capacity, degree of freedom (DOF), speed and endurance with diverse mission requirements by changing the quantity and form of combinations. First, we propose a decentralized modular controller to allow a team of physically connected modules to fly cooperatively. Second, we divide all the combinations into three categories according to the different control methods. Three generalized control strategies are proposed to control both position and attitude independently by tilting the directions of the propellers. We carried out experiments to demonstrate the feasibility of this mechanical design and control method. The experiment video is available at https://youtu.be/7RvxiV4FPq4.",
        "primary_area": "",
        "author": "Zegui Wu;Ruqing Zhao;Mengfan Yu;Yanchun Zhao;Wanqi Yang;Weiye Zhang;Fusheng Li;Zegui Wu;Ruqing Zhao;Mengfan Yu;Yanchun Zhao;Wanqi Yang;Weiye Zhang;Fusheng Li",
        "authorids": "/37088844393;/37089659282;/37089496651;/37088844721;/37089658490;/37089659912;/37086942986;/37088844393;/37089659282;/37089496651;/37088844721;/37089658490;/37089659912;/37086942986",
        "aff": "Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China; Yangtze Delta Region Institute of University of Electronic Science and Technology of China, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982090/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8917679448341299348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "Yangtze Delta Region Institute",
        "aff_unique_url": "http://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981536",
        "title": "Design, Teleoperation Control and Experimental Validation of a Dexterous Robotic Flexible Endoscope for Laparoscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing robotic endoscopes for laparoscopic surgery, predominantly rigid or limited in dexterity, occupy a large motion space1, The large occupied motion space necessitates large incisions and reduces the motion space for surgeons to simultaneously operate other surgical instruments. Meanwhile, surgeons only have limited view adjustment capability to avoid occlusion and they often have to lift/push some organs to observe occluded target lesions in some operations such as cholecystectomy. The situation gets worse when the operations are on obese patients. In this paper, we develop a novel dexterous robotic flexible endoscope (DRFE), which is comprised of a concentric cable-driven structure and a 2-DoF articulated joint attached to the end of DRFE, for laparoscopic surgery. The proposed design occupies much less motion space both inside and outside human body as compared to conventional robotic flexible endoscopes. When used in surgery, the part of the endoscope outside the body can remain still, which reduces the risk of expanding the incision and simplifies the structure of the remote center mechanism. Simulation and experimental studies are performed to validate the effectiveness of the proposed device in the improvement of vision occlusion and usability. Initial results reveal that the DRFE is highly dexterous and accurate in observing lesions with vision occlusion.",
        "primary_area": "",
        "author": "Xin Ma;Xuchen Wang;Rui Cao;Kwok Wai Samuel Au;Xin Ma;Xuchen Wang;Rui Cao;Kwok Wai Samuel Au",
        "authorids": "/37085857304;/37089485280;/37089917938;/37435246800;/37085857304;/37089485280;/37089917938;/37435246800",
        "aff": "Multi-scale Medical Robotics Center, Hong Kong, China; Department of MAE, Chinese University of Hong Kong, Hong Kong, China; Department of MAE, Chinese University of Hong Kong, Hong Kong, China; Multi-scale Medical Robotics Center, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981536/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4709379958430793528&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Multi-scale Medical Robotics Center;Chinese University of Hong Kong",
        "aff_unique_dep": ";Department of MAE",
        "aff_unique_url": ";https://www.cuhk.edu.hk",
        "aff_unique_abbr": ";CUHK",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982148",
        "title": "Designing Underactuated Graspers with Dynamically Variable Geometry Using Potential Energy Map Based Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a potential energy map based approach that provides a framework for the design and control of a robotic grasper. Unlike other potential energy map approaches, our framework considers friction for a more realistic perspective on grasper performance. Our analysis establishes the importance of considering dynamically variable geometry in grasper design, namely palm width, link lengths, and transmission ratios, which are assumed to be able to change in real-time. Our analysis assumes a two-phalanx tendon-pulley underactuated grasper, but it can be extended to other underactuated mechanisms. We demonstrate the utility of these novel potential energy maps and the method used to generate them in order by showing how various design parameters impact the grasping and in-hand manipulation performance of a particular design across a range of object sizes and friction coefficients. Optimal grasping designs have palms that scale with object size and transmission ratios that scale with the coefficient of friction. Using a custom in-hand manipulation metric, we compared the in-hand manipulation capabilities of a grasper that only dynamically varied its palm size, link lengths, and transmission ratios to a grasper with a variable palm and controllable actuation efforts. The analysis revealed the advantage of dynamically variable geometry; by varying only its palm size, link lengths, and transmission ratios in real-time, safe, caged in-hand manipulation of a wide range of objects could be performed.",
        "primary_area": "",
        "author": "Connor L. Yako;Shenli Yuan;J. Kenneth Salisbury;Connor L. Yako;Shenli Yuan;J. Kenneth Salisbury",
        "authorids": "/37088686183;/37088506196;/37355483800;/37088686183;/37088506196;/37355483800",
        "aff": "Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982148/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15005603817223949785&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Artificial Intelligence Lab (SAIL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981559",
        "title": "Detecting Adversarial Perturbations in Multi-Task Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "While deep neural networks (DNNs) achieve impressive performance on environment perception tasks, their sensitivity to adversarial perturbations limits their use in practical applications. In this paper, we (i) propose a novel adversarial perturbation detection scheme based on multi-task perception of complex vision tasks (i.e., depth estimation and semantic segmentation). Specifically, adversarial perturbations are detected by inconsistencies between extracted edges of the input image, the depth output, and the segmentation output. To further improve this technique, we (ii) develop a novel edge consistency loss between all three modalities, thereby improving their initial consistency which in turn supports our detection scheme. We verify our detection scheme's effectiveness by employing various known attacks and image noises. In addition, we (iii) develop a multi-task adversarial attack, aiming at fooling both tasks as well as our detection scheme. Experimental evaluation on the Cityscapes and KITTI datasets shows that under an assumption of a 5% false positive rate up to 100% of images are correctly detected as adversarially perturbed, depending on the strength of the perturbation. Code is available at https://github.com/ifnspaml/AdvAttackDet. A short video at https://youtu.be/KKa6gOyWmH4 provides qualitative results.",
        "primary_area": "",
        "author": "Marvin Klingner;Varun Ravi Kumar;Senthil Yogamani;Andreas B\u00e4r;Tim Fingscheidt;Marvin Klingner;Varun Ravi Kumar;Senthil Yogamani;Andreas B\u00e4r;Tim Fingscheidt",
        "authorids": "/37088450196;/37086543375;/37086351846;/37086964064;/37298976300;/37088450196;/37086543375;/37086351846;/37086964064;/37298976300",
        "aff": "Institute for Communications Technology, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany; Valeo DAR, Kronach, Germany; Valeo Vision Systems, Tuam, Ireland; Institute for Communications Technology, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany; Institute for Communications Technology, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981559/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5437786522576329449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Braunschweig;Valeo;Valeo Vision Systems",
        "aff_unique_dep": "Institute for Communications Technology;DAR;",
        "aff_unique_url": "https://tu-braunschweig.de;https://www.valeo.com;",
        "aff_unique_abbr": "TU Braunschweig;;",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Braunschweig;Kronach;Tuam",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;Ireland"
    },
    {
        "id": "9981564",
        "title": "Detecting Invalid Map Merges in Lifelong SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "For Lifelong SLAM, one has to deal with temporary localization failures, e.g., induced by kidnapping. We achieve this by starting a new map and merging it with the previous map as soon as relocalization succeeds. Since relocalization methods are fallible, it can happen that such a merge is invalid, e.g., due to perceptual aliasing. To address this issue, we propose methods to detect and undo invalid merges. These methods compare incoming scans with scans that were previously merged into the current map and consider how well they agree with each other. Evaluation of our methods takes place using a dataset that consists of multiple flat and office environments, as well as the public MIT Stata Center dataset. We show that methods based on a change detection algorithm and on comparison of gridmaps perform well in both environments and can be run in real-time with a reasonable computational cost.",
        "primary_area": "",
        "author": "Matthias Holoch;Gerhard Kurz;Peter Biber;Matthias Holoch;Gerhard Kurz;Peter Biber",
        "authorids": "/37089195607;/37089696351;/37301850700;/37089195607;/37089696351;/37301850700",
        "aff": "Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981564/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9642769774675007636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Robert Bosch GmbH",
        "aff_unique_dep": "Corporate Research",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982134",
        "title": "Development and Control of Robot Hand with Finger Camera for Garment Handling Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic automation is steadily growing in different industries around the world. However, in some industries, such as garment manufacturing, most tasks are still predominantly manual, due to the flexible nature of clothes. Garment and clothes are easily deformed when some force is applied, so it is difficult for robots to handle them while predicting their deformation. Our general research goal is to realize flexible cloth handling using robots to automate different tasks in the garment manufacturing industry. We draw inspiration from the actions that humans perform when manipulating clothes and emulate them using a robotic system. In this paper, we developed a robot hand with a camera at the finger, to obtain local information of the contact between the garment and the robot hand, in order to achieve garment handling tasks. Specifically, we focus on the pinch and slide motion that humans perform when straightening a piece of cloth. We selected a specific task to be automated and proposed three manipulation strategies to approach the garment using visual information from the finger camera that enabled the system to perform the task consistently. We carried out two validation experiments to demonstrate the effectiveness of the proposed methods, and an application experiment where we evaluate their applicability to a specific task.",
        "primary_area": "",
        "author": "Hirokazu Kondo;Jose Victorio Salazar Luces;Yasuhisa Hirata;Hirokazu Kondo;Jose Victorio Salazar Luces;Yasuhisa Hirata",
        "authorids": "/37089659383;/37088234483;/37274134900;/37089659383;/37088234483;/37274134900",
        "aff": "Department of Robotics, Tohoku University, Sendai, Japan; Department of Robotics, Tohoku University, Sendai, Japan; Department of Robotics, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982134/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1933108177733855461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981468",
        "title": "Development and Experimental Evaluation of a Novel Portable Haptic Robotic Exoskeleton Glove System for Patients with Brachial Plexus Injuries",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the development and experimental evaluation of a portable haptic exoskeleton glove system designed for people who suffer from brachial plexus injuries to restore their lost grasping functionality. The proposed glove system involves force perception, linkage-driven finger mechanism, and personalized voice control to achieve various grasping functionality requirements. The fully integrated system provides our wearable device with lightweight, portable, and comfortable characterization for grasping objects used in daily activities. Rigid articulated linkages powered by Series Elastic Actuators (SEAs) with slip detection on the fingertips provide stable and robust grasp for multiple objects. The passive abduction-adduction motion of each finger is also considered to provide better grasping flexibility for the user. The continuous voice control with bio-authentication also provides a hands-free user interface. The experiments with different objects verify the functionalities and capabilities of the proposed exoskeleton glove system in grasping objects with various shapes and weights used in activities of daily living (ADLs).",
        "primary_area": "",
        "author": "Wenda Xu;Yunfei Guo;Cesar Bravo;Pinhas Ben-Tzvi;Wenda Xu;Yunfei Guo;Cesar Bravo;Pinhas Ben-Tzvi",
        "authorids": "/37088978836;/37088977231;/37088979857;/38277770000;/37088978836;/37088977231;/37088979857;/38277770000",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Carilion Clinic Institute of Orthopaedics and Neurosciences, Virginia Tech Carilion School of Medicine, Roanoke, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981468/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2005887933197387114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Virginia Tech;Virginia Tech Carilion School of Medicine",
        "aff_unique_dep": "Department of Mechanical Engineering;Institute of Orthopaedics and Neurosciences",
        "aff_unique_url": "https://www.vt.edu;https://www.vtcarsom.edu",
        "aff_unique_abbr": "VT;VTCSOM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Blacksburg;Roanoke",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981691",
        "title": "Development and Field Testing of an Optimal Path Following ASV Controller for Marine Surveys",
        "track": "main",
        "status": "Poster",
        "abstract": "Marine autonomous vehicles deployed to conduct marine geophysical surveys are becoming an increasingly used asset in the commercial, academic, and defense industries. However, the ability to collect high-quality data from applicable sensors is directly related to the robustness of vehicle motion caused by environmental disturbances. In this paper we designed and integrated a new path following controller on an autonomous surface vehicle (ASV) that minimizes the linear and angular accelerations on the sensor's local frame. Simulation and experimental results verify reduction of vehicle motion, improvement in path following, and improvement in preliminary sonar data quality compared to that of the existing proportional-yaw path following controller.",
        "primary_area": "",
        "author": "Kleio Baxevani;Grant E. Otto;Herbert G. Tanner;Arthur C. Trembanis;Kleio Baxevani;Grant E. Otto;Herbert G. Tanner;Arthur C. Trembanis",
        "authorids": "/37089279990;/37089662659;/37267233400;/37399902400;/37089279990;/37089662659;/37267233400;/37399902400",
        "aff": "Department of Mechanical Engineering, University of Delaware; School of Marine Science and Policy, University of Delaware; Department of Mechanical Engineering, University of Delaware; School of Marine Science and Policy, University of Delaware",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981691/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3595967747015562344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981337",
        "title": "Development of Low-Inertia Backdrivable Arm Focusing on Learning-Based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot designed to coexist and work with humans in the same workspace should be able to work at the same speed as humans and have safe contact with humans and with the environment. However, when a robot arm has been given flexibility through mechanisms and controls for the purpose of coexistence, it is difficult for it to perform tasks at the speed and accuracy desired by humans if it is moved simply by using conventional position-based controls. With such an arm, we consider that the use of learning-based control is necessary to achieve both safety and speed. Therefore, we prototyped a low-inertia, high-backdrivability arm as a platform for studying learning-based control and tested two types of learning-based control. This paper describes our design process, in which hardware suitable for learning-based control was developed according to the requirements of the specific task. It also presents the results of our evaluation experiments, in which tasks involving quick movements and motion requiring physical contact with an object were performed using learning-based control.",
        "primary_area": "",
        "author": "Manabu Nishiura;Akira Hatano;Kazutoshi Nishii;Yoshihiro Okumatsu;Manabu Nishiura;Akira Hatano;Kazutoshi Nishii;Yoshihiro Okumatsu",
        "authorids": "/37088690295;/37089663567;/37564469800;/37089659355;/37088690295;/37089663567;/37564469800;/37089659355",
        "aff": "Frontier Research Center, Toyota Motor Corporation, Nishihirose-cho, Aichi, Japan; Frontier Research Center, Toyota Motor Corporation, Nishihirose-cho, Aichi, Japan; Frontier Research Center, Toyota Motor Corporation, Nishihirose-cho, Aichi, Japan; Frontier Research Center, Toyota Motor Corporation, Nishihirose-cho, Aichi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981337/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17462712045132449315&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Toyota Motor Corporation",
        "aff_unique_dep": "Frontier Research Center",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nishihirose-cho",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982208",
        "title": "Development of Pneumatically Driven Tensegrity Manipulator without Mechanical Springs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports a tensegrity manipulator driven by 40 pneumatic cylinders without mechanical springs. In general, tensegrity robots use mechanical springs to achieve a stable/curved tensegrity structure, and this is true even when a component extends/retracts with an actuator. The stiffness of the mechanical spring should be high to increase the stiffness of the entire structure and improve the control response, but low to deform the structure. This fact means that the introduction of mechanical springs causes serious trade-offs in its design and control. In this study, we use pneumatic actuators not only for active deformation but also for passive. In this paper, we introduce the design and control system and then show the difference in response characteristics between the case with and without a spring, demonstrating the importance of the approach without a mechanical spring.",
        "primary_area": "",
        "author": "Yuhei Yoshimitsu;Kenta Tsukamoto;Shuhei Ikemoto;Yuhei Yoshimitsu;Kenta Tsukamoto;Shuhei Ikemoto",
        "authorids": "/37089658663;/37089779695;/37659393100;/37089658663;/37089779695;/37659393100",
        "aff": "Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology, Kitakyushu, Fukuoka, Japan; Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology, Kitakyushu, Fukuoka, Japan; Research Center for Neuromporphic AI Hard-ware, Kyushu Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982208/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16707799127000964496&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Kyushu Institute of Technology",
        "aff_unique_dep": "Graduate School of Life Science and Systems Engineering",
        "aff_unique_url": "https://www.kyutech.ac.jp",
        "aff_unique_abbr": "Kyutech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kitakyushu;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981437",
        "title": "Development of a 6 DOF Soft Robotic Manipulator with Integrated Sensing Skin",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new 6 DOF soft robotic manipulator intended for colorectal surgery. The manipulator, based on a novel design that employs an inextensible tube to limit axial extension, is shown to maximize the force exerted at its tip and the bending angle, the latter being measured with a soft sensing skin. Manufacturing of the prototype is achieved with a lost-wax silicone-casting technique. The kinematic model of the manipulator, its workspace, and its manipulability are discussed. The prototype is evaluated with extensive experiments, including pressure-deflection measurement with and without tip load, and lateral force measurements with and without the soft sensing skin to assess hysteresis. The experimental results indicate that the prototype fulfils the key design requirements for colorectal surgery: (i) it can generate sufficient force to perform a range of laparoscopic tasks; (ii) the workspace is commensurate with the dimensions of the large intestine; (iii) the soft sensing skin only results in a marginal reduction of the maximum tip rotation within the range of pressures and external loads relevant for the chosen application.",
        "primary_area": "",
        "author": "Shen Treratanakulchai;Enrico Franco;Arnau Garriga-Casanovas;Hu Minghao;Panagiotis Kassanos;Ferdinando Rodriguez y Baena;Shen Treratanakulchai;Enrico Franco;Arnau Garriga-Casanovas;Hu Minghao;Panagiotis Kassanos;Ferdinando Rodriguez y Baena",
        "authorids": "/37085534256;/37085386901;/37085716200;/37089662455;/37543246000;/37085496644;/37085534256;/37085386901;/37085716200;/37089662455;/37543246000;/37085496644",
        "aff": "Biomedical and Robotic Technology Laboratory, Mahidol University, Nakon Pathom, Thailand; The Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom; The Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College, London, United Kingdom; The Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981437/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16220065120974180108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Mahidol University;Imperial College London",
        "aff_unique_dep": "Biomedical and Robotic Technology Laboratory;Mechatronics in Medicine Laboratory",
        "aff_unique_url": "http://www.mahidol.ac.th;https://www.imperial.ac.uk",
        "aff_unique_abbr": ";ICL",
        "aff_campus_unique_index": "0;1;1;1;1;1",
        "aff_campus_unique": "Nakon Pathom;London",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "Thailand;United Kingdom"
    },
    {
        "id": "9981232",
        "title": "Development of a Conveyor-Type Object Release Mechanism for a Parallel Gripper with a Mushroom-Shaped Gecko-Inspired Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "A surface microstructure that mimics the surface of a gecko's foot can exert a large gripping force with a small contact force. If such a structure is applied to the fingertips of a two-fingered parallel gripper, stable grasping can be achieved independent of the wetting and frictional state of the contact surface. However, the adhesive force of the microstructure is large while releasing the object, which hinders the release of the object. In this study, we developed a release method using a conveyor mechanism that easily peels off in the direction of rotation with a focus on the characteristics of the micro-protrusion structure. This mechanism is driven in conjunction with the gripper's grasping and releasing motions. Our experiments confirmed that the gripper can stably release the object using the proposed mechanism. The proposal in this paper is a mechanism that dynamically changes the adhesive force on a fingertip by mechanically switching the surface state in accordance with the gripper's grasping and releasing states. This idea can be applied to not only surface microstructure such as gecko-inspired surfaces but also adhesive surfaces such as adhesive tape, and provides novel knowledge in the field of robotics as a method of mechanically changing the fingertip adhesive force.",
        "primary_area": "",
        "author": "Shunsuke Nagahama;Atsushi Nakao;Shigeki Sugano;Shunsuke Nagahama;Atsushi Nakao;Shigeki Sugano",
        "authorids": "/37086147262;/37089658929;/37274050800;/37086147262;/37089658929;/37274050800",
        "aff": "Future Robotics Organization, Waseda University, Tokyo, Shinjuku, Japan; Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Shinjuku, Japan; Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Shinjuku, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981232/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Y9QLWom3oigJ:scholar.google.com/&scioq=Development+of+a+Conveyor-Type+Object+Release+Mechanism+for+a+Parallel+Gripper+with+a+Mushroom-Shaped+Gecko-Inspired+Surface&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Future Robotics Organization",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981124",
        "title": "Development of a Novel Low-profile Robotic Exoskeleton Glove for Patients with Brachial Plexus Injuries",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and development of a novel, low-profile, exoskeleton robotic glove aimed for people who suffer from brachial plexus injuries to restore their lost grasping functionality. The key idea of this new glove lies in its new finger mechanism that takes advantage of the rigid coupling hybrid mechanism (RCHM) concept. This mechanism concept couples the motions of the adjacent human finger links using rigid coupling mechanisms so that the overall mechanism motion (e.g., bending, extension, etc.) could be achieved using fewer actuators. The finger mechanism utilizes the single degree of freedom case of the RCHM that uses a rack-and-pinion mechanism as the rigid coupling mechanism. This special arrangement enables to design each finger mechanism of the glove as thin as possible while maintaining mechanical robustness simultaneously. Based on this novel finger mechanism, a two-finger low-profile robotic glove was developed. Remote center of motion mechanisms were used for the metacarpophalangeal (MCP) joints. Kinematic analysis and optimization-based kinematic synthesis were conducted to determine the design parameters of the new glove. Passive abduction/adduction joints were considered to improve the grasping flexibility. A proof-of-concept prototype was built and pinch grasping experiments of various objects were conducted. The results validated the mechanism and the mechanical design of the new robotic glove and demonstrated its functionalities and capabilities in grasping objects with various shapes and weights that are used in activities of daily living (ADLs).",
        "primary_area": "",
        "author": "Wenda Xu;Yujiong Liu;Pinhas Ben-Tzvi;Wenda Xu;Yujiong Liu;Pinhas Ben-Tzvi",
        "authorids": "/37088978836;/37089448790;/38277770000;/37088978836;/37089448790;/38277770000",
        "aff": "Mechanical Engineering Department, Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, USA; Mechanical Engineering Department, Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, USA; Mechanical Engineering Department, Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981124/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2272746365310422805&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981436",
        "title": "Development of a Research Testbed for Cooperative Driving in Mixed Traffic of Human-driven and Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a cooperative driving testbed based on vehicle-to-vehicle (V2V) communication, which can be used for research in intelligent transportation systems, such as collision avoidance in mixed traffic of both human-driven vehicles and autonomous vehicles. To achieve the goal, an intelligent copilot is developed. The copilot can share the data regarding vehicle status, intention, etc, with other nearby vehicles through V2V communication. Several case studies are conducted to validate the proposed testbed and evaluate the performances of cooperative driving. When dangerous situations occur, the copilot solves the collision avoidance problem using Mixed Integer Programming (MIP), which either provides control commands to the autonomous vehicle, or advises the human driver to take action. Experimental results show that the safety and stability of the involved vehicles have been significantly enhanced. This cooperative driving testbed can be used by researchers to develop and test cooperative driving algorithms before they are deployed in real vehicles.",
        "primary_area": "",
        "author": "Jiaxing Lu;Ryan Stracener;Weihua Sheng;He Bai;Sanzida Hossain;Jiaxing Lu;Ryan Stracener;Weihua Sheng;He Bai;Sanzida Hossain",
        "authorids": "/37088690371;/37089660108;/37276312200;/37085643488;/37089658819;/37088690371;/37089660108;/37276312200;/37085643488;/37089658819",
        "aff": "School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, Stillwater, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, Stillwater, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981436/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10919633299969063686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Oklahoma State University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.okstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stillwater",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981761",
        "title": "Development of a Stingray-inspired High-Frequency Propulsion Platform with Variable Wavelength",
        "track": "main",
        "status": "Poster",
        "abstract": "Undulatory fin motions in fish-like robots are typically created using intricate arrays of servo motors. Motor arrays offer impressive versatility in terms of kinematics, but their complexity leads to constraints on size, hydrodynamic force production, and power consumption, particularly when studying propulsive performance at high-frequencies. Here we present an alternative design that uses a single motor and a tunable rotary cam-train system to achieve a spectrum of fin motions running from oscillation (wavenumber < 1) to undulation (wavenumber > 1). Our platform enables thrust, lift, power, and wake measurements at prescribed pitch amplitudes, frequencies, and wavenumbers. We demonstrated the platform's oscillating and undulating capabilities via force and wake measurements in a water tank. Studies of fin wavenumber offer design insights for fish-like underwater robots, particularly those with stingray-inspired designs.",
        "primary_area": "",
        "author": "Qiang Zhong;Yicong Fu;Leo Liu;Daniel B. Quinn;Qiang Zhong;Yicong Fu;Leo Liu;Daniel B. Quinn",
        "authorids": "/37089658969;/37089658369;/37089661218;/37086942858;/37089658969;/37089658369;/37089661218;/37086942858",
        "aff": "Department of Mechanical and Aerospace Engineering, University of Virginia, Charlottesville, VA, USA; Department of Mechanical and Aerospace Engineering, University of Virginia, Charlottesville, VA, USA; Department of Mechanical and Aerospace Engineering, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981761/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4022209365472793879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981770",
        "title": "Development of a cable-driven Growing Sling to assist patient transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "As the aging of society continues to accelerate, the number of elderly patients is increasing, as is the demand for manpower to care for them. In particular, there is an urgent need for bedridden patient care. However, limitations in the supply of human resources have caused an increase in the burden for care. In particular, nursing personnel often experience inconvenience and difficulties owing to the great deal of effort required to transfer a patient from bed to wheelchair, or vice versa. The most difficult process during the patient transfer is inserting the sling under the patient. Aiming to solve this problem, a mechanical Growing Sling was devised. The proposed sling adapts a growing mechanism comprising a low-friction fabric and steel shafts, and the sling is inserted under the patient by towing the steel shafts with cables connected to a motor. For the comfort and safety of the sling insertion, the required towing force was analyzed to find the minimum diameter of the shaft. The results from experimental evaluations using the proposed sling verified that it can be inserted under the patient without moving the patient, and with an acceptable level of pressure being applied to the patient.",
        "primary_area": "",
        "author": "MyungJoong Lee;Yonghwan Moon;Jeongryul Kim;Seungjun Lee;Keri Kim;HyunKi In;MyungJoong Lee;Yonghwan Moon;Jeongryul Kim;Seungjun Lee;Keri Kim;HyunKi In",
        "authorids": "/37088687411;/37088688641;/37088475975;/37088688353;/37085344004;/37589373000;/37088687411;/37088688641;/37088475975;/37088688353;/37085344004;/37589373000",
        "aff": "Division of Nano-Information Technology (HCI & Robotics), University of Science and Technology, Daejeon, Republic of Korea; Center for Medical Robotics, Seoul, Republic of Korea; Center for Medical Robotics, Seoul, Republic of Korea; Center for Medical Robotics, Seoul, Republic of Korea; Division of Bio-Medical Science and Technology, University of Science and Technology, Daejeon, Korea; Center for Medical Robotics, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981770/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:MQVEKBK--VUJ:scholar.google.com/&scioq=Development+of+a+cable-driven+Growing+Sling+to+assist+patient+transfer&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "University of Science and Technology;Center for Medical Robotics",
        "aff_unique_dep": "Division of Nano-Information Technology (HCI & Robotics);",
        "aff_unique_url": "http://www.ust.ac.kr;",
        "aff_unique_abbr": "UST;",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "Daejeon;Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981345",
        "title": "DiMOpt: a Distributed Multi-robot Trajectory Optimization Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with Multi-robot Trajectory Planning, that is, the problem of computing trajectories for multiple robots navigating in a shared space while minimizing for control energy. Approaches based on trajectory optimization can solve this problem optimally. However, such methods are hampered by complex robot dynamics and collision constraints that couple robot's decision variables. We propose a distributed multi-robot optimization algorithm (DiMOpt) that addresses these issues by exploiting (1) consensus optimization strategies to tackle coupling collision constraints, and (2) a single-robot sequential convex programming method for efficiently handling non-convexities introduced by dynamics. We compare DiMOpt with a baseline centralized multi-robot sequential convex programming algorithm (SCP). We empirically demonstrate that DiMOpt scales well for large fleets of robots while computing solutions faster and with lower costs. Finally, DiMOpt is an iterative algorithm that finds feasible trajectories before converging to a locally optimal solution, and results suggest the quality of such fast initial solutions is comparable to a converged solution computed via SCP.",
        "primary_area": "",
        "author": "Jo\u00e3o Salvado;Masoumeh Mansouri;Federico Pecora;Jo\u00e3o Salvado;Masoumeh Mansouri;Federico Pecora",
        "authorids": "/37086201112;/37085453076;/37564376200;/37086201112;/37085453076;/37564376200",
        "aff": "AASS Research Centre, \u00d6rebro University; School of Computer Science, University of Birmingham; AASS Research Centre, \u00d6rebro University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981345/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11410382046604972737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "\u00d6rebro University;University of Birmingham",
        "aff_unique_dep": "AASS Research Centre;School of Computer Science",
        "aff_unique_url": "https://www.oru.se;https://www.birmingham.ac.uk",
        "aff_unique_abbr": ";UoB",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Birmingham",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United Kingdom"
    },
    {
        "id": "9981060",
        "title": "Diaphragm Ankle Actuation for Efficient Series Elastic Legged Robot Hopping",
        "track": "main",
        "status": "Poster",
        "abstract": "The observation of the anatomy of agile animals and their locomotion capabilities emphasizes the importance of fast and lightweight legs and confirms the intrinsic compliance integrated into muscle-tendon units as a major ingredient for energy efficient and robust locomotion. This quality is especially relevant for distal leg segments which are subject to aggressive dynamics. Legged robots are accordingly designed to improve dynamic performance by lightweight mechanisms combined with series elastic actuation systems. However, so far no designs are available that feature all characteristics of a perfect distal legged locomotion actuator such as a lightweight and low-inertia structure, with high mechanical efficiency, no stick and sliding friction, and low mechanical complexity. With this goal in mind, we propose a novel robotic leg which integrates all above features. Specifically, we develop, implement, and characterize a bioinspired robot leg that features a lightweight Series ELastic Diaphragm distal Actuator (SELDA) for active control of foot motion. We conducted experiments to compare two leg configurations, with and without foot actuation, to demonstrate the effectiveness of the proposed solution in agile forward hopping controlled by a central pattern generator. We studied how tuning SELDA's activation timing can adjust the robot's hopping height by 11% and its forward velocity by 14%, even with comparatively low power injection to the distal joint.",
        "primary_area": "",
        "author": "Marco Bolignari;An Mo;Marco Fontana;Alexander Badri-Spr\u00f6witz;Marco Bolignari;An Mo;Marco Fontana;Alexander Badri-Spr\u00f6witz",
        "authorids": "/37086580790;/37089658196;/38278237200;/37088340110;/37086580790;/37089658196;/38278237200;/37088340110",
        "aff": "Institute of Mechanical Intelligence, Scuola Superiore Sant'Anna, Pisa, Italy; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Institute of Mechanical Intelligence, Scuola Superiore Sant'Anna, Pisa, Italy; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981060/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1933636577901666323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Scuola Superiore Sant'Anna;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Institute of Mechanical Intelligence;Dynamic Locomotion Group",
        "aff_unique_url": "https://www.sssup.it;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "SSSUP;MPI-IS",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Pisa;Stuttgart",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9981101",
        "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in manipulation of deformable objects is typically conducted on a limited range of scenarios, because handling each scenario on hardware takes significant effort. Realistic simulators with support for various types of deformations and interactions have the potential to speed up experimentation with novel tasks and algorithms. However, for highly deformable objects it is challenging to align the output of a simulator with the behavior of real objects. Manual tuning is not intuitive, hence automated methods are needed. We view this alignment problem as a joint perception-inference challenge and demonstrate how to use recent neural network architectures to successfully perform simulation parameter inference from real point clouds. We analyze the performance of various architectures, comparing their data and training requirements. Furthermore, we propose to leverage differentiable point cloud sampling and differentiable simulation to significantly reduce the time to achieve the alignment. We employ an efficient way to propagate gradients from point clouds to simulated meshes and further through to the physical simulation parameters, such as mass and stiffness. Experiments with highly deformable objects show that our method can achieve comparable or better alignment with real object behavior, while reducing the time needed to achieve this by more than an order of magnitude. Videos and supplementary material are available at https://tinyurl.com/diffcloud.",
        "primary_area": "",
        "author": "Priya Sundaresan;Rika Antonova;Jeannette Bohgl;Priya Sundaresan;Rika Antonova;Jeannette Bohgl",
        "authorids": "/37087011905;/37085991913;/37089658335;/37087011905;/37085991913;/37089658335",
        "aff": "Department of Computer Science, Stanford University, Stanford, USA; Department of Computer Science, Stanford University, Stanford, USA; Department of Computer Science, Stanford University, Stanford, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981101/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16753185739808912149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981093",
        "title": "Differentiable Collision Avoidance Using Collision Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "A central aspect of robotic motion planning is collision avoidance, where a multitude of different approaches are currently in use. Optimization-based motion planning is one method, that often heavily relies on distance computations between robots and obstacles. These computations can easily become a bottleneck, as they do not scale well with the complexity of the robots or the environment. To improve performance, many different methods suggested to use collision primitives, i.e. simple shapes that approximate the more complex rigid bodies, and that are simpler to compute distances to and from. However, each pair of primitives requires its own specialized code, and certain pairs are known to suffer from numerical issues. In this paper, we propose an easy-to-use, unified treatment of a wide variety of primitives. We formulate distance computation as a minimization problem, which we solve iteratively. We show how to take derivatives of this minimization problem, allowing it to be seamlessly integrated into a trajectory optimization method. We demonstrate that the resulting method can be used to plan smooth and collision-free paths based on a variety of single- and multi-robot scenarios with different obstacles.",
        "primary_area": "",
        "author": "Simon Zimmermann;Matthias Busenhart;Simon Huber;Roi Poranne;Stelian Coros;Simon Zimmermann;Matthias Busenhart;Simon Huber;Roi Poranne;Stelian Coros",
        "authorids": "/37088231270;/37088012289;/37086961842;/37085580542;/37077396200;/37088231270;/37088012289;/37086961842;/37085580542;/37077396200",
        "aff": "Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel; Department of Computer Science, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981093/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13254918584953548468&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETHZ;UoH",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "9981260",
        "title": "DirectTracker: 3D Multi-Object Tracking Using Direct Image Alignment and Photometric Bundle Adjustment",
        "track": "main",
        "status": "Poster",
        "abstract": "Direct methods have shown excellent performance in the applications of visual odometry and SLAM. In this work we propose to leverage their effectiveness for the task of 3D multi-object tracking. To this end, we propose DirectTracker, a framework that effectively combines direct image alignment for the short-term tracking and sliding-window photometric bundle adjustment for 3D object detection. Object proposals are estimated based on the sparse sliding-window pointcloud and further refined using an optimization-based cost function that carefully combines 3D and 2D cues to ensure consistency in image and world space. We propose to evaluate 3D tracking using the recently introduced higher-order tracking accuracy (HOTA) metric and the generalized intersection over union sim-ilarity measure to mitigate the limitations of the conventional use of intersection over union for the evaluation of vision-based trackers. We perform evaluation on the KITTI Tracking benchmark for the Car class and show competitive performance in tracking objects both in 2D and 3D.",
        "primary_area": "",
        "author": "Mariia Gladkova;Nikita Korobov;Nikolaus Demmel;Aljo\u0161a O\u0161ep;Laura Leal-Taix\u00e9;Daniel Cremers;Mariia Gladkova;Nikita Korobov;Nikolaus Demmel;Aljo\u0161a O\u0161ep;Laura Leal-Taix\u00e9;Daniel Cremers",
        "authorids": "/37088999478;/37089658810;/37595100200;/37085554303;/38286861700;/37282875300;/37088999478;/37089658810;/37595100200;/37085554303;/38286861700;/37282875300",
        "aff": "Technical University of Munich (TUM); Technical University of Munich (TUM); Technical University of Munich (TUM); Technical University of Munich (TUM); Technical University of Munich (TUM); Technical University of Munich (TUM)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981260/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13964758474811248862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981659",
        "title": "Direction-Aware Adaptive Online Neural Speech Enhancement with an Augmented Reality Headset in Real Noisy Conversational Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the practical response- and performance-aware development of online speech enhancement for an augmented reality (AR) headset that helps a user understand conversations made in real noisy echoic environments (e.g., cocktail party). One may use a state-of-the-art blind source separation method called fast multichannel nonnegative matrix factorization (FastMNMF) that works well in various environments thanks to its unsupervised nature. Its heavy computational cost, however, prevents its application to real-time processing. In contrast, a supervised beamforming method that uses a deep neural network (DNN) for estimating spatial information of speech and noise readily fits real-time processing, but suffers from drastic performance degradation in mismatched conditions. Given such complementary characteristics, we propose a dual-process robust online speech enhancement method based on DNN-based beamforming with FastMNMF-guided adaptation. FastMNMF (back end) is performed in a mini-batch style and the noisy and enhanced speech pairs are used together with the original parallel training data for updating the direction-aware DNN (front end) with backpropagation at a computationally-allowable interval. This method is used with a blind dereverberation method called weighted prediction error (WPE) for transcribing the noisy reverberant speech of a speaker, which can be detected from video or selected by a user's hand gesture or eye gaze, in a streaming manner and spatially showing the transcriptions with an AR technique. Our experiment showed that the word error rate was improved by more than 10 points with the run-time adaptation using only twelve minutes observation.",
        "primary_area": "",
        "author": "Kouhei Sekiguchi;Aditya Arie Nugraha;Yicheng Du;Yoshiaki Bando;Mathieu Fontaine;Kazuyoshi Yoshii;Kouhei Sekiguchi;Aditya Arie Nugraha;Yicheng Du;Yoshiaki Bando;Mathieu Fontaine;Kazuyoshi Yoshii",
        "authorids": "/37085659600;/38235599600;/37088586502;/37085462443;/37086245260;/37823276500;/37085659600;/38235599600;/37088586502;/37085462443;/37086245260;/37823276500",
        "aff": "Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris, Paris, France; Graduate School of Informatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981659/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12064249801557976135&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;1",
        "aff_unique_norm": "RIKEN;Kyoto University;National Institute of Advanced Industrial Science and Technology;T\u00e9l\u00e9com Paris",
        "aff_unique_dep": "Center for Advanced Intelligence Project (AIP);Graduate School of Informatics;Center for Advanced Intelligence Project;LTCI",
        "aff_unique_url": "https://www.riken.jp;https://www.kyoto-u.ac.jp;https://www.aist.go.jp;https://www.telecom-paris.fr",
        "aff_unique_abbr": "RIKEN;Kyoto U;AIST;T\u00e9l\u00e9com Paris",
        "aff_campus_unique_index": "0;0;1;3;1",
        "aff_campus_unique": "Tokyo;Kyoto;;Paris",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Japan;France"
    },
    {
        "id": "9981158",
        "title": "Discover Life Skills for Planning as Bandits via Observing and Learning How the World Works",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel approach for planning agents to compose abstract skills via observing and learning from historical interactions with the world. Our framework operates in a Markov state-space model via a set of actions under unknown pre-conditions. We formulate skills as high-level abstract policies that propose action plans based on the current state. Each policy learns new plans by observing the states' transitions while the agent interacts with the world. Such an approach automatically learns new plans to achieve specific intended effects, but the success of such plans is often dependent on the states in which they are applicable. Therefore, we formulate the evaluation of such plans as infinitely many multi-armed bandit problems, where we balance the allocation of resources on evaluating the success probability of existing arms and exploring new options. The result is a planner capable of automatically learning robust high-level skills under a noisy environment; such skills implicitly learn the action pre-condition without explicit knowledge. We show that this planning approach is experimentally very competitive in high-dimensional state space domains.",
        "primary_area": "",
        "author": "Tin Lai;Tin Lai",
        "authorids": "/37086935412;/37086935412",
        "aff": "School of Computer Science, The University of Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981158/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4270162827489388379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981116",
        "title": "Disentangled Sequence Clustering for Human Intention Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Equipping robots with the ability to infer human intent is a vital precondition for effective collaboration. Most computational approaches towards this objective derive a probability distribution of \u201cintent\u201d conditioned on the robot's perceived state. However, these approaches typically assume task-specific labels of human intent are known a priori. To overcome this constraint, we propose the Disentangled Sequence Clustering Variational Autoencoder (DiSCVAE), a clustering framework capable of learning such a distribution of intent in an unsupervised manner. The proposed framework leverages recent advances in unsupervised learning to disentangle latent representations of sequence data, separating time-varying local features from time-invariant global attributes. As a novel extension, the DiSCVAE also infers a discrete variable to form a latent mixture model and thus enable clustering over these global sequence concepts, e.g. high-level intentions. We evaluate the DiSCVAE on a real-world human-robot interaction dataset collected using a robotic wheelchair. Our findings reveal that the inferred discrete variable coincides with human intent, holding promise for collaborative settings, such as shared control.",
        "primary_area": "",
        "author": "Mark Zolotas;Yiannis Demiris;Mark Zolotas;Yiannis Demiris",
        "authorids": "/37086096013;/37296338900;/37086096013;/37296338900",
        "aff": "Dept. of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London, UK; Dept. of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981116/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1640820667683713833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dept. of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981136",
        "title": "Disk-Graph Probabilistic Roadmap: Biased Distance Sampling for Path Planning in a Partially Unknown Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new sampling-based path planning approach, focusing on the challenges linked to autonomous exploration. Our method relies on the definition of a disk graph of free-space bubbles, from which we derive a biased sampling function that expands the graph towards known free space for maximal navigability and frontiers discovery. The proposed method demonstrates an exploratory behavior similar to Rapidly-exploring Random Trees, while retaining the connectivity and flexibility of a graph-based planner. We demonstrate the interest of our method by first comparing its path planning capabilities against state-of-the-art approaches, before discussing exploration-specific aspects, namely replanning capabilities and incremental construction of the graph. A simple frontiers-driven exploration controller derived from our planning method is also demonstrated using the Pioneer platform.",
        "primary_area": "",
        "author": "T. No\u00ebl;S. Kabbour;A. Lehuger;E. Marchand;F. Chaumette;T. No\u00ebl;S. Kabbour;A. Lehuger;E. Marchand;F. Chaumette",
        "authorids": "/37418659000;/37089695860;/37089661700;/37269970500;/37265186700;/37418659000;/37089695860;/37089661700;/37269970500;/37265186700",
        "aff": "Cr\u00e9ative Ing\u00e9nierie, Rennes, France; Cr\u00e9ative Ing\u00e9nierie, Rennes, France; Cr\u00e9ative Ing\u00e9nierie, Rennes, France; Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981136/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1888648446507266420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Cr\u00e9ative Ing\u00e9nierie;University of Rennes;INRIA",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.univ-rennes1.fr;https://www.inria.fr",
        "aff_unique_abbr": ";Univ Rennes;Inria",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9982145",
        "title": "Distilled Visual and Robot Kinematics Embeddings for Metric Depth Estimation in Monocular Scene Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating precise metric depth and scene reconstruction from monocular endoscopy is a fundamental task for surgical navigation in robotic surgery. However, traditional stereo matching adopts binocular images to perceive the depth information, which is difficult to transfer to the soft robotics-based surgical systems due to the use of monocular endoscopy. In this paper, we present a novel framework that combines robot kinematics and monocular endoscope images with deep unsupervised learning into a single network for metric depth estimation and then achieve 3D reconstruction of complex anatomy. Specifically, we first obtain the relative depth maps of surgical scenes by leveraging a brightness-aware monocular depth estimation method. Then, the corresponding endoscope poses are computed based on non-linear optimization of geo-metric and photometric reprojection residuals. Afterwards, we develop a Depth-driven Sliding Optimization (DDSO) algorithm to extract the scaling coefficient from kinematics and calculated poses offline. By coupling the metric scale and relative depth data, we form a robust ensemble that represents the metric and consistent depth. Next, we treat the ensemble as supervisory labels to train a metric depth estimation network for surgeries (i.e., MetricDepthS-Net) that distills the embeddings from the robot kinematics, endoscopic videos, and poses. With accurate metric depth estimation, we utilize a dense visual reconstruction method to recover the 3D structure of the whole surgical site. We have extensively evaluated the proposed framework on public SCARED and achieved comparable performance with stereo-based depth estimation methods. Our results demon-strate the feasibility of the proposed approach to recover the metric depth and 3D structure with monocular inputs.",
        "primary_area": "",
        "author": "Ruofeng Wei;Bin Li;Hangjie Mo;Fangxun Zhong;Yonghao Long;Qi Dou;Yun-Hui Liu;Dong Sun;Ruofeng Wei;Bin Li;Hangjie Mo;Fangxun Zhong;Yonghao Long;Qi Dou;Yun-Hui Liu;Dong Sun",
        "authorids": "/37088701950;/37089266122;/37086577797;/37085712708;/37088902647;/37085465414;/37279412600;/37277362800;/37088701950;/37089266122;/37086577797;/37085712708;/37088902647;/37085465414;/37279412600;/37277362800",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982145/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12312956174566929361&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;1;1;1;0",
        "aff_unique_norm": "City University of Hong Kong;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CityU;CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981749",
        "title": "Distributed Coach-Based Reinforcement Learning Controller for Snake Robot Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning commonly suffers from slow convergence speed and requires thousands of episodes, which makes it hard to be applied for physical robotic applications. Little research has been studied for snake robot control using RL because of the additional difficulty of high redundancy of freedom. Existing methods either adopts an asynchronous A3C structure or a joint state representation. We propose a distributed coach-based deep learning method for snake robot control, which can greatly expedite the training speed with less episodes. The major contributions include: 1) a completely distributed graphical formulation; 2) an explicit stochastic density propagation rule for each robot link; 3) various interaction models with uncertainty estimation. The preliminary results of both simulation and real-world experiments have demonstrated the promising performance in comparison with state-of-the-art.",
        "primary_area": "",
        "author": "Yuanyuan Jia;Shugen Ma;Yuanyuan Jia;Shugen Ma",
        "authorids": "/37088689758;/37280187400;/37088689758;/37280187400",
        "aff": "Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981749/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10943872213019127611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982028",
        "title": "Distributed Ranging SLAM for Multiple Robots with Ultra-WideBand and Odometry Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "To accomplish task efficiently in a multiple robots system, a problem that has to be addressed is Simultaneous Localization and Mapping (SLAM). LiDAR (Light Detection and Ranging) has been used for many SLAM solutions due to its superb accuracy, but its performance degrades in featureless environments, like tunnels or long corridors. Centralized SLAM solves the problem with a cloud server, which requires a huge amount of computational resources and lacks robustness against central node failure. To address these issues, we present a distributed SLAM solution to estimate the trajectory of a group of robots using Ultra-WideBand (UWB) ranging and odometry measurements. The proposed approach distributes the processing among the robot team and significantly mitigates the computation concern emerged from the centralized SLAM. Our solution determines the relative pose (also known as loop closure) between two robots by minimizing the UWB ranging measurements taken at different positions when the robots are in close proximity. UWB provides a good distance measure in line-of-sight conditions, but retrieving a precise pose estimation remains a challenge, due to ranging noise and unpredictable path traveled by the robot. To deal with the suspicious loop closures, we use Pairwise Consistency Maximization (PCM) to examine the quality of loop closures and perform outlier rejections. The filtered loop closures are then fused with odometry in a distributed pose graph optimization (DPGO) module to recover the full trajectory of the robot team. Extensive experiments are conducted to validate the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Ran Liu;Zhongyuan Deng;Zhiqiang Cao;Muhammad Shalihan;Billy Pik Lik Lau;Kaixiang Chen;Kaushik Bhowmik;Chau Yuen;U-Xuan Tan;Ran Liu;Zhongyuan Deng;Zhiqiang Cao;Muhammad Shalihan;Billy Pik Lik Lau;Kaixiang Chen;Kaushik Bhowmik;Chau Yuen;U-Xuan Tan",
        "authorids": "/37085618269;/37089659115;/37090039313;/37089579302;/37086062940;/37089662277;/37089659396;/37273147100;/37085617165;/37085618269;/37089659115;/37090039313;/37089579302;/37086062940;/37089662277;/37089659396;/37273147100;/37085617165",
        "aff": "Singapore University of Technology and Design, Singapore; Southwest University of Science and Technology, Mianyang, Sichuan, China; Southwest University of Science and Technology, Mianyang, Sichuan, China; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Southwest University of Science and Technology, Mianyang, Sichuan, China; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982028/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4255522822580119741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;0;0;1;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design;Southwest University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sutd.edu.sg;",
        "aff_unique_abbr": "SUTD;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Mianyang",
        "aff_country_unique_index": "0;1;1;0;0;1;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9981256",
        "title": "Distributed Riemannian Optimization with Lazy Communication for Collaborative Geometric Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first distributed optimization al-gorithm with lazy communication for collaborative geometric estimation, the backbone of modern collaborative simultaneous localization and mapping (SLAM) and structure-from-motion (SfM) applications. Our method allows agents to cooperatively reconstruct a shared geometric model on a central server by fusing individual observations, but without the need to transmit potentially sensitive information about the agents themselves (such as their locations). Furthermore, to alleviate the burden of communication during iterative optimization, we design a set of communication triggering conditions that enable agents to selectively upload a targeted subset of local information that is useful to global optimization. Our approach thus achieves significant communication reduction with minimal impact on optimization performance. As our main theoretical contribution, we prove that our method converges to first-order critical points with a global sublinear convergence rate. Numerical evaluations on bundle adjustment problems from collaborative SLAM and SfM datasets show that our method performs competitively against existing distributed techniques, while achieving up to 78% total communication reduction.",
        "primary_area": "",
        "author": "Yulun Tian;Amrit Singh Bedi;Alec Koppel;Miguel Calvo-Fullana;David M. Rosen;Jonathan P. How;Yulun Tian;Amrit Singh Bedi;Alec Koppel;Miguel Calvo-Fullana;David M. Rosen;Jonathan P. How",
        "authorids": "/37088451604;/37085892109;/37085457697;/37085697475;/38252288400;/37276347700;/37088451604;/37085892109;/37085457697;/37085697475;/38252288400;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Institute of Systems Research, University Of Mary-land, College Park, MD, USA; Supply Chain Optimization Technologies, Bellevue, WA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Electrical and Computer Engineering and Mathematics, Northeastern University, Boston, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981256/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1160327988759606521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Maryland;Supply Chain Optimization Technologies;Northeastern University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Institute of Systems Research;;Department of Electrical and Computer Engineering and Mathematics",
        "aff_unique_url": "https://web.mit.edu;https://www.umd.edu;;https://www.northeastern.edu",
        "aff_unique_abbr": "MIT;UMD;;NU",
        "aff_campus_unique_index": "0;1;2;0;3;0",
        "aff_campus_unique": "Cambridge;College Park;Bellevue;Boston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982020",
        "title": "Divide & Conquer Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "When cast into the Deep Reinforcement Learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. In such context, Imitation Learning (IL) can be a powerful approach to bootstrap the learning process. However, most IL methods require several expert demonstrations which can be prohibitively difficult to acquire. Only a handful of IL algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. In this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. Based on a sequential inductive bias, our method divides the complex task into smaller skills. The skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. We show that our method imitates a non-holonomic navigation task and scales to a complex simulated robotic manipulation task with very high sample efficiency.",
        "primary_area": "",
        "author": "Alexandre Chenu;Nicolas Perrin-Gilbert;Olivier Sigaud;Alexandre Chenu;Nicolas Perrin-Gilbert;Olivier Sigaud",
        "authorids": "/37089661781;/37089659339;/37571613800;/37089661781;/37089659339;/37571613800",
        "aff": "Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique, ISIR, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982020/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18085475473597700187&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9",
        "aff_unique_dep": "Institut des Syst\u00e8mes Intelligents et de Robotique",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9982196",
        "title": "Domain Invariant Siamese Attention Mask for Small Object Change Detection via Everyday Indoor Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of image change detection via every-day indoor robot navigation is explored from a novel perspective of the self-attention technique. Detecting semantically non-distinctive and visually small changes remains a key challenge in the robotics community. Intuitively, these small non-distinctive changes may be better handled by the recent paradigm of the attention mechanism, which is the basic idea of this work. However, existing self-attention models require significant retraining cost per domain, so it is not directly applicable to robotics applications. We propose a new self-attention technique with an ability of unsupervised on-the-fly domain adaptation, which introduces an attention mask into the intermediate layer of an image change detection model, without modifying the input and output layers of the model. Experiments, in which an indoor robot aims to detect visually small changes in everyday navigation, demonstrate that our attention technique significantly boosts the state-of-the-art image change detection model. Our datset is available at https://github.com/KojiTakeda00/Small_object_change_detection",
        "primary_area": "",
        "author": "Koji Takeda;Kanji Tanaka;Yoshimasa Nakamura;Koji Takeda;Kanji Tanaka;Yoshimasa Nakamura",
        "authorids": "/37089659611;/37538090300;/37087118768;/37089659611;/37538090300;/37087118768",
        "aff": "Tokyo Metropolitan Industrial Technology Research Institute, Tokyo, Japan; Faculty of Engineering, University of Fukui, Japan; Tokyo Metropolitan Industrial Technology Research Institute, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982196/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12746967634976602305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tokyo Metropolitan Industrial Technology Research Institute;University of Fukui",
        "aff_unique_dep": ";Faculty of Engineering",
        "aff_unique_url": "https://www.tMRI.or.jp;https://www.u-fukui.ac.jp",
        "aff_unique_abbr": "TMRI;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982147",
        "title": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned Interactive Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion forecasting in highly interactive scenarios is a challenging problem in autonomous driving. In such scenarios, we need to accurately predict the joint behavior of interacting agents to ensure the safe and efficient navigation of autonomous vehicles. Recently, goal-conditioned methods have gained increasing attention due to their advantage in performance and their ability to capture the multimodality in trajec-tory distribution. In this work, we study the joint trajectory prediction problem with the goal-conditioned framework. In particular, we introduce a conditional-variational-autoencoder-based (CVAE) model to explicitly encode different interaction modes into the latent space. However, we discover that the vanilla model suffers from posterior collapse and cannot induce an informative latent space as desired. To address these issues, we propose a novel approach to avoid KL vanishing and induce an interpretable interactive latent space with pseudo labels. The proposed pseudo labels allow us to incorporate domain knowledge on interaction in a flexible manner. We motivate the proposed method using an illustrative toy example. In addition, we validate our framework on the Waymo Open Motion Dataset with both quantitative and qualitative evaluations.",
        "primary_area": "",
        "author": "Lingfeng Sur;Chen Tang;Yaru Niu;Enna Sachdeva;Chiho Choi;Teruhisa Misu;Masayoshi Tomizuka;Wei Zhan;Lingfeng Sur;Chen Tang;Yaru Niu;Enna Sachdeva;Chiho Choi;Teruhisa Misu;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37089662482;/37086487301;/37089661692;/37085682495;/37086937192;/37085998814;/37281933000;/37067099600;/37089662482;/37086487301;/37089661692;/37085682495;/37086937192;/37085998814;/37281933000;/37067099600",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, GA, USA; Honda Research Institute, CA, USA; Honda Research Institute, CA, USA; Honda Research Institute, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982147/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4890396407352736894&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;2;2;2;0;0",
        "aff_unique_norm": "University of California, Berkeley;Georgia Institute of Technology;Honda Research Institute",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.gatech.edu;https://www.honda-ri.com",
        "aff_unique_abbr": "UC Berkeley;Georgia Tech;HRI",
        "aff_campus_unique_index": "0;0;1;2;2;2;0;0",
        "aff_campus_unique": "Berkeley;Georgia;CA",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982235",
        "title": "Don't Share My Face: Privacy Preserving Inpainting for Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization is an important task for many robotic and augmented reality applications. As localizing within large scale maps can be memory and computationally de-manding, cloud-based localization services are appealing for developers. However, such services raise important privacy concerns for both passive and active users. In particular, some sensitive information might be revealed by an attacker who intercepts data during the data-sharing process. Therefore, the sensitive data in the image should be concealed before it is shared. As a motivating case, we demonstrated the exposure generated by the common feature descriptor SIFT when attempting to recover private content. In this paper, we propose a pipeline to effectively conceal privacy-sensitive image regions from possible attacks to the transmission or localization services, by making use of learning-based image inpainting techniques while preserving, and even boosting, the localization performance. We tested our pipeline with two off-the-shelf localization services based on deep neural networks on the publicly available Oxford Robotcar dataset, showing that the localization performance on our generated private concealed images is on par with the non-private baseline. 1",
        "primary_area": "",
        "author": "Saad Himmi;Oguzhan Ilter;Fran\u00e7ois Pailleau;Roland Siegwart;Berta Bescos;Cesar Cadena;Saad Himmi;Oguzhan Ilter;Fran\u00e7ois Pailleau;Roland Siegwart;Berta Bescos;Cesar Cadena",
        "authorids": "/37089660754;/37089660739;/37089660096;/37281398300;/37086432844;/37593590400;/37089660754;/37089660739;/37089660096;/37281398300;/37086432844;/37593590400",
        "aff": "Saad Himmi; Oguzhan Ilter; Fran\u00e7ois Pailleau; Roland Siegwart; Berta Bescos; Cesar Cadena",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982235/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8149237463209226496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Berta Bescos",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981140",
        "title": "Downwash-aware Control Allocation for Over-actuated UAV Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking position and orientation independently affords more agile maneuver for over-actuated multirotor Unmanned Aerial Vehicles (UAVs) while introducing undesired downwash effects; downwash flows generated by thrust generators may counteract others due to close proximity, which significantly threatens the stability of the platform. The complexity of modeling aerodynamic airflow challenges control algorithms from properly compensating for such a side effect. Leveraging the input redundancies in over-actuated UAVs, we tackle this issue with a novel control allocation framework that considers downwash effects and explores the entire allocation space for an optimal solution. This optimal solution avoids downwash effects while providing high thrust efficiency within the hardware constraints. To the best of our knowledge, ours is the first formal derivation to investigate the downwash effects on over-actuated UAVs. We verify our framework on different hardware configurations in both simulation and experiment.",
        "primary_area": "",
        "author": "Yao Su;Chi Chu;Meng Wang;Jiarui Li;Liu Yang;Yixin Zhu;Hangxin Liu;Yao Su;Chi Chu;Meng Wang;Jiarui Li;Liu Yang;Yixin Zhu;Hangxin Liu",
        "authorids": "/37086579130;/37089659294;/37859315700;/37089921853;/37090020881;/37086172463;/37086274715;/37086579130;/37089659294;/37859315700;/37089921853;/37090020881;/37086172463;/37086274715",
        "aff": "Beijing Institute for General Artificial Intelligence (BIGAI); Department of Automation, Tsinghua University; Beijing Institute for General Artificial Intelligence (BIGAI); College of Engineering, Peking University; Academy of Arts & Design, Tsinghua University; School of Artificial Intelligence, Peking University; Beijing Institute for General Artificial Intelligence (BIGAI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981140/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1115501916849612135&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;1;2;0",
        "aff_unique_norm": "Beijing Institute for General Artificial Intelligence;Tsinghua University;Peking University",
        "aff_unique_dep": ";Department of Automation;College of Engineering",
        "aff_unique_url": "http://www.bigmodel.cn/;https://www.tsinghua.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "BIGAI;THU;Peking U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981405",
        "title": "DreamingV2: Reinforcement Learning with Discrete World Models without Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "The present paper proposes a novel reinforce-ment learning method with world models, DreamingV2, a collaborative extension of DreamerV2 and Dreaming. Dream- erV2 is a cutting-edge model-based reinforcement learning from pixels that uses discrete world models to represent latent states with categorical variables. Dreaming is also a form of reinforcement learning from pixels that attempts to avoid the auto encoding process in general world model training by involving a reconstruction-free contrastive learning objective. The proposed DreamingV2 is a novel approach of adopting both the discrete representation of DreamingV2 and the reconstruction-free objective of Dreaming. Compared to DreamerV2 and other recent model-based methods without reconstruction, DreamingV2 achieves the best scores on five simulated challenging 3D robot arm tasks. We believe that DreamingV2 will be a reliable solution for robot learning since its discrete representation is suitable to describe discontinuous environments, and the reconstruction-free fashion well manages complex vision observations.",
        "primary_area": "",
        "author": "Masashi Okada;Tadahiro Taniguchi;Masashi Okada;Tadahiro Taniguchi",
        "authorids": "/37086454122;/37273806600;/37086454122;/37273806600",
        "aff": "Technology Division, Panasonic Corporation, Digital & AI Technology Center, Japan; Ritsumeikan University, College of Information Science and Engineering, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981405/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10035443973160549010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Panasonic Corporation;Ritsumeikan University",
        "aff_unique_dep": "Technology Division, Digital & AI Technology Center;College of Information Science and Engineering",
        "aff_unique_url": "https://www.panasonic.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Panasonic;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981330",
        "title": "Drift Reduced Navigation with Deep Explainable Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern autonomous vehicles (AVs) often rely on vision, LIDAR, and even radar-based simultaneous localization and mapping (SLAM) frameworks for precise localization and navigation. However, modern SLAM frameworks often lead to unacceptably high levels of drift (i.e., localization error) when AVs observe few visually distinct features or encounter occlusions due to dynamic obstacles. This paper argues that minimizing drift must be a key desiderata in AV motion planning, which requires an AV to take active control decisions to move towards feature-rich regions while also minimizing conventional control cost. To do so, we first introduce a novel data-driven perception module that observes LIDAR point clouds and estimates which features/regions an AV must navigate towards for drift minimization. Then, we introduce an interpretable model predictive controller (MPC) that moves an AV toward such feature-rich regions while avoiding visual occlusions and gracefully trading off drift and control cost. Our experiments on challenging, dynamic scenarios in the state-of-the-art CARLA simulator indicate our method reduces drift up to 76.76% compared to benchmark approaches.",
        "primary_area": "",
        "author": "Mohd Omama;Sripada V. S. Sundar;Sandeep Chinchali;Arun Kumar Singh;K. Madhava Krishna;Mohd Omama;Sripada V. S. Sundar;Sandeep Chinchali;Arun Kumar Singh;K. Madhava Krishna",
        "authorids": "/37089514291;/37089664026;/37089002336;/38237873200;/38201465600;/37089514291;/37089664026;/37089002336;/38237873200;/38201465600",
        "aff": "Robotics Research Center, IIIT-Hyderabad, India; Robotics Research Center, IIIT-Hyderabad, India; ECE Department, The University of Texas at Austin; Institute of Technology, University of Tartu; Robotics Research Center, IIIT-Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981330/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9396512483364087269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "IIIT-Hyderabad;University of Texas at Austin;University of Tartu",
        "aff_unique_dep": "Robotics Research Center;ECE Department;Institute of Technology",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.utexas.edu;https://www.ut.ee",
        "aff_unique_abbr": "IIIT-H;UT Austin;UT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "India;United States;Estonia"
    },
    {
        "id": "9981815",
        "title": "Driving Anomaly Detection Using Contrastive Multiview Coding to Interpret Cause of Anomaly",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern advanced driver assistant systems (ADAS) rely on various types of sensors to monitor the vehicle status, driver's behaviors and road condition. The multimodal systems in the vehicle include sensors, such as accelerometers, pressure sensors, cameras, lidar and radars. When looking at a given scene with multiple modalities, there should be congruent in-formation among different modalities. Exploring the congruent information across modalities can lead to appealing solutions to create robust multimodal representations. This work proposes an unsupervised approach based on contrastive multiview coding (CMC) to capture the correlations in representations extracted from different modalities, learning a more discriminative rep-resentation space for unsupervised anomaly driving detection. We use CMC to train our model to extract view-invariant factors by maximizing the mutual information between mul-tiple representations from a given view, and increasing the distance of views from unrelated segments. We consider the vehicle driving data, driver's physiological data, and external environment data consisting of distances to nearby pedestrians, bicycles, and vehicles. The experimental results on the driving anomaly dataset (DAD) indicate that the CMC representation is effective for driving anomaly detection. The approach is efficient, scalable and interpretable, where the distances in the contrastive embedding for each view can be used to understand potential causes of the detected anomalies.",
        "primary_area": "",
        "author": "Yuning Qiu;Teruhisa Misu;Carlos Busso;Yuning Qiu;Teruhisa Misu;Carlos Busso",
        "authorids": "/37087103489;/37085998814;/38549078200;/37087103489;/37085998814;/38549078200",
        "aff": "Department of Electrical and Computer Engineering, University of Texas at Dallas, Richardson, TX, USA; Honda Research Institute, Mountain View, California, USA; Department of Electrical and Computer Engineering, University of Texas at Dallas, Richardson, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981815/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:vkoCZ70Pee4J:scholar.google.com/&scioq=Driving+Anomaly+Detection+Using+Contrastive+Multiview+Coding+to+Interpret+Cause+of+Anomaly&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Dallas;Honda Research Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.utdallas.edu;https://www.honda-ri.com",
        "aff_unique_abbr": "UT Dallas;HRI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Richardson;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982219",
        "title": "Drone with Pneumatic-tethered Suction-based Perching Mechanism for High Payload Application",
        "track": "main",
        "status": "Poster",
        "abstract": "Concrete infrastructures provide the means to connect cities and transport people and goods. They require regular inspection to assess their current conditions. Aerial work platforms and underbridge platforms or scaffolding are the common equipment used for inspection of elevated infrastructure. These methods often cost more to operate and maintain, are time-consuming, and raise risks for the inspector. One interesting field of research for UAVs that can be used for infrastructure inspection is aerial perching. A perching UAV can be loaded with an inspection apparatus foregoing the need for costly equipment and risks involved in the inspection. Many have presented aerial perching for various applications and not as much for applications related to concrete infrastructure inspection. This study investigates a perching UAV that can perform perching on both smooth and rough concrete surfaces. This paper presents an unmanned aerial system that utilizes a suction-based perching mechanism with a pneumatic supply tethered from the ground. The proposed perching mechanism provides a reliable and high payload capacity needed for non-destructive testing of the infrastructure. The paper introduces the concept, presents the design and proof of concept, and validates the idea through actual bridge experiments.",
        "primary_area": "",
        "author": "Jim David Ang;Lester Librado;Carl John Salaan;Jonathan Maglasang;Kristine Sanchez;Marcelo Ang;Jim David Ang;Lester Librado;Carl John Salaan;Jonathan Maglasang;Kristine Sanchez;Marcelo Ang",
        "authorids": "/37089659297;/37089332853;/37085662193;/37089331013;/37089659047;/37279138700;/37089659297;/37089332853;/37085662193;/37089331013;/37089659047;/37279138700",
        "aff": "College of Engineering and Technology, Mindanao State University - Iligan Institute of Technology, Philippines; College of Engineering and Technology, Mindanao State University - Iligan Institute of Technology, Philippines; College of Engineering and Technology, Mindanao State University - Iligan Institute of Technology, Philippines; Cebu Technological University-Main Campus, Philippines; College of Engineering and Technology, Mindanao State University - Iligan Institute of Technology, Philippines; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982219/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8334396761873828756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;2",
        "aff_unique_norm": "Mindanao State University - Iligan Institute of Technology;Cebu Technological University;National University of Singapore",
        "aff_unique_dep": "College of Engineering and Technology;;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mindanao.edu.ph;https://www.ctu.edu.ph;https://www.nus.edu.sg",
        "aff_unique_abbr": "MSU-IIT;CTU;NUS",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Iligan;Main Campus;",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Philippines;Singapore"
    },
    {
        "id": "9981485",
        "title": "Dual-camera High Magnification Surveillance System with Non-delay Gaze Control and Always-in-focus Function in Indoor Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a dual-camera system for indoor high magnification surveillance which is capable of achieving always-in-focus and non-delay gaze control based on high-speed vision. The users are enabled to move the mouse freely on the wide-view screen while observing its in-focal zoom-in monitoring video in real-time. The proposed system consists of a wide-angle camera for wide-view and a Galvano mirror-enabled ultra-fast pan-tilt-zoom (PTZ) camera for zoom-in view. To achieve always-in-focus, a high-speed focus scanning system is proposed that is comprised of a high-speed camera, a parfocal zoom lens, and a gear mechanism. Through continuously reciprocating rotational motion of the focusing ring driven by the servo motor, the high-speed camera captures sets of images with varying focal distances. Moreover, we proposed a most-in-focus (MIF) frame extraction algorithm to select the sharpest images as output. The experimental results are obtained to confirm the effectiveness of our system.",
        "primary_area": "",
        "author": "Tianyi Zhang;Shaopeng Hu;Kohei Shimasaki;Idaku Ishii;Akio Namiki;Tianyi Zhang;Shaopeng Hu;Kohei Shimasaki;Idaku Ishii;Akio Namiki",
        "authorids": "/37089658616;/37086813964;/37085993633;/37327589100;/37273962400;/37089658616;/37086813964;/37085993633;/37327589100;/37273962400",
        "aff": "Department of Mechanical Engineering, Graduate School of Engineering, Chiba University, Japan; Robotics Laboratory, Graduate School of Advanced Science and Engineering, Hiroshima University, Japan; Robotics Laboratory, Graduate School of Advanced Science and Engineering, Hiroshima University, Japan; Robotics Laboratory, Graduate School of Advanced Science and Engineering, Hiroshima University, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Chiba University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981485/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2401105726751217276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Chiba University;Hiroshima University",
        "aff_unique_dep": "Department of Mechanical Engineering;Graduate School of Advanced Science and Engineering",
        "aff_unique_url": "https://www.chiba-u.ac.jp;https://www.hiroshima-u.ac.jp",
        "aff_unique_abbr": "Chiba U;Hiroshima U",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Hiroshima",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981737",
        "title": "Dynamic Compressed Sensing of Unsteady Flows with a Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale environmental sensing with a finite number of mobile sensors is a challenging task that requires tremendous resources and time. This is especially true when the environmental features of interest are spatiotemporally changing with unknown or partially known dynamics. Fortunately, these dynamic features often evolve in a low-dimensional space, making it possible to capture their dynamics sufficiently well with a finite number of sensor measurements. This paper investigates the problem of dynamic compressed sensing of an unsteady, periodic flow field with a mobile sensor. We take advantage of the inherently low dimensionality of the under-lying flow dynamics to reduce number of critical waypoints for sensor trajectory. The optimal set of sensing waypoints are identified by an iterative compressed sensing algorithm that optimizes the flow reconstruction based on the proper orthogonal decomposition modes. An optimal sampling trajectory is then found to traverse these waypoints while minimizing the energy consumption, time, and flow reconstruction error. Simulation results in a double-gyre flow field is presented to demonstrate the efficacy of the proposed algorithms. Experimental results with an indoor quadcopter are presented to show the tracking feasibility of the resulting trajectory.",
        "primary_area": "",
        "author": "Sachin Shriwastav;Gregory Snyder;Zhuoyuan Song;Sachin Shriwastav;Gregory Snyder;Zhuoyuan Song",
        "authorids": "/37086268232;/37089663525;/37085342795;/37086268232;/37089663525;/37085342795",
        "aff": "Department of Mechanical Engineering, University of Hawai'i at M\u00e3noa, Honolulu, HI, USA; Department of Mechanical Engineering, University of Hawai'i at M\u00e3noa, Honolulu, HI, USA; Department of Mechanical Engineering, University of Hawai'i at M\u00e3noa, Honolulu, HI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981737/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12789207992435930756&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Hawai'i at M\u00e3noa",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hawaii.edu",
        "aff_unique_abbr": "UH M\u0101noa",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Honolulu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981447",
        "title": "Dynamic Free-Space Roadmap for Safe Quadrotor Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Free-space-oriented roadmaps typically generate a series of convex geometric primitives, which constitute the safe region for motion planning. However, a static environment is assumed for this kind of roadmap. This assumption makes it unable to deal with dynamic obstacles and limits its applications. In this paper, we present a dynamic free-space roadmap, which provides feasible spaces and a navigation graph for safe quadrotor motion planning. Our roadmap is constructed by continuously seeding and extracting free regions in the environment. In order to adapt our map to environments with dynamic obstacles, we incrementally decompose the polyhedra intersecting with obstacles into obstacle-free regions, while the graph is also updated by our well-designed mechanism. Extensive simulations and real-world experiments demonstrate that our method is practically applicable and efficient.",
        "primary_area": "",
        "author": "Junlong Guo;Zhiren Xun;Shuang Geng;Yi Lin;Chao Xu;Fei Gao;Junlong Guo;Zhiren Xun;Shuang Geng;Yi Lin;Chao Xu;Fei Gao",
        "authorids": "/37089663923;/37089341159;/37089660254;/37086281245;/37404060100;/37086045143;/37089663923;/37089341159;/37089660254;/37086281245;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; DJI, Shenzhen, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981447/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1063697076812104951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;DJI",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.dji.com",
        "aff_unique_abbr": "ZJU;DJI",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Huzhou;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981449",
        "title": "Dynamic Inference on Graphs using Structured Transition Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling robots to perform complex dynamic tasks such as picking up an object in one sweeping motion or pushing off a wall to quickly turn a corner is a challenging problem. The dynamic interactions implicit in these tasks are critical towards the successful execution of such tasks. Graph neural networks (GNNs) provide a principled way of learning the dynamics of interactive systems but can suffer from scaling issues as the number of interactions increases. Furthermore, the problem of using learned GNN-based models for optimal control is insufficiently explored. In this work, we present a method for efficiently learning the dynamics of interacting systems by simultaneously learning a dynamic graph structure and a stable and locally linear forward model of the system. The dynamic graph structure encodes evolving contact modes along a trajectory by making probabilistic predictions over the edges of the graph. Additionally, we introduce a temporal dependence in the learned graph structure which allows us to incorporate contact measurement updates during execution thus enabling more accurate forward predictions. The learned stable and locally linear dynamics enable the use of optimal control algorithms such as iLQR for long-horizon planning and control for complex interactive tasks. Through experiments in simulation and in the real world, we evaluate the performance of our method by using the learned interaction dynamics for control and demonstrate generalization to more objects and interactions not seen during training. We introduce a control scheme that takes advantage of contact measurement updates and hence is robust to prediction inaccuracies during execution.",
        "primary_area": "",
        "author": "Saumya Saxena;Oliver Kroemer;Saumya Saxena;Oliver Kroemer",
        "authorids": "/37086365761;/37593222300;/37086365761;/37593222300",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981449/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:kG_s36DXeT8J:scholar.google.com/&scioq=Dynamic+Inference+on+Graphs+using+Structured+Transition+Models&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981938",
        "title": "Dynamic Network Model for Multi-Domain End-to-end Task-Oriented Dialogue System",
        "track": "main",
        "status": "Poster",
        "abstract": "Dialogue State Tracking (DST) is an important part in task-oriented dialog system, whose target is to infer the current dialog states and user intentions according to the dialog history information. To this end, we have achieved improvements to the existing work and proposed a dynamic network model suitable for multi-domain dialog, which can explicitly use domain information and better cope with zero-shot tasks. The model is composed of three modules: an encoder, a decoder and a slot classifier. The encoder module introduces a mixed-separate framework so that it can obtain the feature information of each domain on the premise of extracting the shared information between all domains. The experimental results show that the model achieves joint accuracy of 48.38% for the five domains of MultiWOZ, which is superior to existing models. Besides, by simulating the zero-shot scenario, the knowledge transferability of the model has also been well proven. Finally, in order to verify the effectiveness of the robot simulation system, this paper also uses the robot simulation technology to simulate the common tasks of helping users complete the task of taking items in the home environment service.",
        "primary_area": "",
        "author": "F. D. Zhao;M. L. Qiu;X. S. Li;D. D. Guo;F. D. Zhao;M. L. Qiu;X. S. Li;D. D. Guo",
        "authorids": "/38086438200;/37089662981;/38090536100;/37089658293;/38086438200;/37089662981;/38090536100;/37089658293",
        "aff": "School of Information Science and Engineering, Xinjiang University of Science and Technology, Korla, China; Key Laboratory for Software Engineering of Hebei Province, School of Information Science and Engineering, Yanshan University, Qinhuangdao, China; Key Laboratory for Software Engineering of Hebei Province, School of Information Science and Engineering, Yanshan University, Qinhuangdao, China; Key Laboratory for Software Engineering of Hebei Province, School of Information Science and Engineering, Yanshan University, Qinhuangdao, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981938/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13995093202485090954&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Xinjiang University of Science and Technology;Yanshan University",
        "aff_unique_dep": "School of Information Science and Engineering;School of Information Science and Engineering",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Korla;Qinhuangdao",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981617",
        "title": "Dynamic Replanning with Posterior Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "When navigating to a goal in an uncertain environment, a robot must simultaneously navigate the exploration-exploitation tradeoff: should it aim to gain information and reduce uncertainty, or should it simply brave the unknown? We formalize this as the Bayesian dynamic motion planning problem, and we analyze how several strategies from the literature balance these concerns via determinization and planning. Within the framework of determinization in the face of uncertainty, we shift the burden of exploration to determinization rather than planning. Dynamic Replanning with Posterior Sampling (DRPS) is very efficient: each iteration consists of a single posterior update and a shortest path query. Relative to comparative baselines across seven datasets of 2D planning problems, DRPS has a higher percentage of success, traverses lower or comparable total distances, and accelerates total planning time by 4\u20137\u00d7. Across a dataset of larger 7D Baxter manipulator planning problems, DRPS reduces total distance by 40% and total planning time by 18\u00d7.",
        "primary_area": "",
        "author": "Brian Hou;Siddhartha S. Srinivasa;Brian Hou;Siddhartha S. Srinivasa",
        "authorids": "/37088506431;/37339877600;/37088506431;/37339877600",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Paul G. Allen School of Computer Science & Engineering, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981617/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4613677024840372116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981102",
        "title": "Dynamic-GAN: Learning Spatial-Temporal Attention for Dynamic Object Removal in Feature Dense Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an attention-based, deep learning framework that converts robot camera frames with dynamic content into static frames to more easily apply simultaneous localization and mapping (SLAM) algorithms. The vast majority of SLAM methods have difficulty in the presence of dynamic objects appearing in the environment and occluding the area being captured by the camera. Despite past attempts to deal with dynamic objects, challenges remain to reconstruct large, occluded areas with complex backgrounds. Our proposed Dynamic-GAN framework employs a generative adversarial network to remove dynamic objects from a scene and inpaint a static image free of dynamic objects. The Dynamic-GAN framework utilizes spatial-temporal transformers, and a novel spatial-temporal loss function. The evaluation of Dynamic-GAN was comprehensively conducted both quantitatively and qualitatively by testing it on benchmark datasets, and on a mobile robot in indoor navigation environments. As people appeared dynamically in close proximity to the robot, results showed that large, feature-rich occluded areas can be accurately reconstructed with our attention-based deep learning framework for dynamic object removal. Through experiments we demonstrate that our proposed algorithm has up to 25% better performance on average as compared to the standard benchmark algorithms.",
        "primary_area": "",
        "author": "Christopher M Trombley;Sumit Kumar Das;Dan O Popa;Christopher M Trombley;Sumit Kumar Das;Dan O Popa",
        "authorids": "/37088912367;/37088998074;/37283733600;/37088912367;/37088998074;/37283733600",
        "aff": "Louisville Automation and Robotics Institute (LARRI), University of Louisville in Kentucky, USA; Louisville Automation and Robotics Institute (LARRI), University of Louisville in Kentucky, USA; Louisville Automation and Robotics Institute (LARRI), University of Louisville in Kentucky, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981102/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3076675160764449661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Louisville",
        "aff_unique_dep": "Louisville Automation and Robotics Institute (LARRI)",
        "aff_unique_url": "https://www.louisville.edu",
        "aff_unique_abbr": "UofL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Louisville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981323",
        "title": "Dynamics-Aware Spatiotemporal Occupancy Prediction in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Detection and segmentation of moving obstacles, along with prediction of the future occupancy states of the local environment, are essential for autonomous vehicles to proactively make safe and informed decisions. In this paper, we propose a framework that integrates the two capabilities together using deep neural network architectures. Our method first detects and segments moving objects in the scene, and uses this information to predict the spatiotemporal evolution of the environment around autonomous vehicles. to address the problem of direct integration of both static-dynamic object segmentation and environment prediction models, we propose using occupancy-based environment representations across the whole framework. Our method is validated on the real-world Waymo Open Dataset and demonstrates higher prediction accuracy than baseline methods.",
        "primary_area": "",
        "author": "Maneekwan Toyungyernsub;Esen Yel;Jiachen Li;Mykel J. Kochenderfer;Maneekwan Toyungyernsub;Esen Yel;Jiachen Li;Mykel J. Kochenderfer",
        "authorids": "/37088596307;/37086422921;/37086309095;/37596929200;/37088596307;/37086422921;/37086309095;/37596929200",
        "aff": "Stanford Intelligent Systems Laboratory (SISL), Stanford University, CA, USA; Stanford Intelligent Systems Laboratory (SISL), Stanford University, CA, USA; Stanford Intelligent Systems Laboratory (SISL), Stanford University, CA, USA; Stanford Intelligent Systems Laboratory (SISL), Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981323/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16920106310172613323&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Intelligent Systems Laboratory (SISL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982191",
        "title": "E-TRoll: Tactile Sensing and Classification via A Simple Robotic Gripper for Extended Rolling Manipulations",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic tactile sensing provides a method of recognizing objects and their properties where vision fails. Prior work on tactile perception in robotic manipulation has frequently focused on exploratory procedures (EPs). However, the also-human-inspired technique of in-hand-manipulation can glean rich data in a fraction of the time of EPs. We propose a simple 3-DOF robotic hand design, optimized for object rolling tasks via a variable-width palm and associated control system. This system dynamically adjusts the distance between the finger bases in response to object behavior. Compared to fixed finger bases, this technique significantly increases the area of the object that is exposed to finger-mounted tactile arrays during a single rolling motion (an increase of over 60% was observed for a cylinder with a 30-millimeter diameter). In addition, this paper presents a feature extraction algorithm for the collected spatiotemporal dataset, which focuses on object corner identification, analysis, and compact representation. This technique drastically reduces the dimensionality of each data sample from \\boldsymbol{10\\times 1500}\\boldsymbol{10\\times 1500} time series data to 80 features, which was further reduced by Principal Component Analysis (PCA) to 22 components. An ensemble subspace k-nearest neighbors (KNN) classification model was trained with 90 observations on rolling three different geometric objects, resulting in a three-fold cross-validation accuracy of 95.6% for object shape recognition.",
        "primary_area": "",
        "author": "Xin Zhou;Adam J. Spiers;Xin Zhou;Adam J. Spiers",
        "authorids": "/37089663070;/38514763300;/37089663070;/38514763300",
        "aff": "Imperial College London; Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982191/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1409773468786776444&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981322",
        "title": "E2Pose: Fully Convolutional Networks for End-to-End Multi-Person Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly accurate multi-person pose estimation at a high framerate is a fundamental problem in autonomous driving. Solving the problem could aid in preventing pedestrian-car accidents. The present study tackles this problem by proposing a new model composed of a feature pyramid and an original head to a general backbone. The original head is built using lightweight CNNs and directly estimates multi-person pose coordinates. This configuration avoids the complex post-processing and two-stage estimation adopted by other models and allows for a lightweight model. Our model can be trained end-to-end and performed in real-time on a resource-limited platform (low-cost edge device) during inference. Experimental results using the COCO and CrowdPose datasets showed that our model can achieve a higher framerate (approx. 20 frames/sec with NVIDIA Jetson AGX Xavier) than other state-of-the-art models while maintaining sufficient accuracy for practical use.",
        "primary_area": "",
        "author": "Masakazu Tobeta;Yoshihide Sawada;Ze Zheng;Sawa Takamuku;Naotake Natori;Masakazu Tobeta;Yoshihide Sawada;Ze Zheng;Sawa Takamuku;Naotake Natori",
        "authorids": "/37089662698;/37089368510;/37089661204;/37088952612;/37086106910;/37089662698;/37089368510;/37089661204;/37088952612;/37086106910",
        "aff": "AISIN Corporation, Fukuoka, Japan; AISIN Corporation, Tokyo, Japan; AISIN Corporation, Tokyo, Japan; AISIN Corporation, Tokyo, Japan; AISIN Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981322/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6954086795897430659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "AISIN Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981162",
        "title": "EMG-based Feedback Modulation for Increased Transparency in Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "In interacting with stiff environments through teleoperated systems, time delays cause a mismatch between haptic feedback and the expected feedback by the operator. This mismatch causes artefacts in the feedback, which decrease transparency, but so does filtering these artefacts. Through modelling of operator stiffness and the expected feedback force with EMG, the artifacts can be selectively filtered without loss of transparency. We developed several feedback modulation techniques to bring the feedback force closer to the expected force: 1) the average between the modelled operator force and the feedback force, 2) a low pass filter and 3) a scaling modulation. To control for overdamping, a transparency check is included. We show that the averaging approach yields significantly better contacts than unmodulated feedback. None of the modulation algorithms differ significantly from the unmodulated feedback in transparency.",
        "primary_area": "",
        "author": "Luc Schoot Uiterkamp;Francesco Porcini;Gwenn Englebienne;Antonio Frisoli;Douwe Dresscher;Luc Schoot Uiterkamp;Francesco Porcini;Gwenn Englebienne;Antonio Frisoli;Douwe Dresscher",
        "authorids": "/37089661124;/37087121821;/38109194100;/37297504100;/38246460200;/37089661124;/37087121821;/38109194100;/37297504100;/38246460200",
        "aff": "Human Media Interaction, Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, AE, The Netherlands; PERCRO Lab, Institute of Mechanical Intelligence, Scuola Superiore Sant'Anna, Ghezzano, Italy; Human Media Interaction, Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, AE, The Netherlands; PERCRO Lab, Institute of Mechanical Intelligence, Scuola Superiore Sant'Anna, Ghezzano, Italy; Robotics and Mechatronics, Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, AE, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981162/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15425091061306690937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Twente;Scuola Superiore Sant'Anna",
        "aff_unique_dep": "Faculty of Electrical Engineering, Mathematics and Computer Science;Institute of Mechanical Intelligence",
        "aff_unique_url": "https://www.utwente.nl;https://www.sssup.it",
        "aff_unique_abbr": "UT;",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Enschede;Ghezzano",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Netherlands;Italy"
    },
    {
        "id": "9981615",
        "title": "EMG-based Hybrid Impedance-Force Control for Human-Robot Collaboration on Ultrasound Imaging",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound (US) imaging is a common but physically demanding task in the medical field, and sonographers may need to put in considerable physical effort for producing high-quality US images. During physical human-robot interaction on US imaging, robot compliance is a critical feature that can ensure human user safety while automatic force regulation ability can help to improve task performance. However, higher robot compliance may mean lower force regulation accuracy, and vice versa. Especially, the contact/non-contact status transition can largely affect the control system stability. In this paper, a novel electromyography (EMG)-based hybrid impedance-force control system is developed for US imaging task. The proposed control system incorporates the robot compliance and force regulation ability via a hybrid controller while the EMG channel enables the user to online modulate the trade-off between the two features as necessary. Two experiments are conducted to examine the hybrid controller and show the necessity of involving an EMG-based modulator. A proof-of-concept study on US imaging is performed with implementing the proposed EMG-based control system, and the effectiveness is demonstrated. The proposed control system is promising to ensure robot's stability and patient's safety, thus obtain high-quality US images, while monitoring and reducing sonographer's fatigue. Furthermore, it can be easily adapted to other physically demanding tasks in the field of medicine.",
        "primary_area": "",
        "author": "Teng Li;Hongjun Xing;Hamid D. Taghirad;Mahdi Tavakoli;Teng Li;Hongjun Xing;Hamid D. Taghirad;Mahdi Tavakoli",
        "authorids": "/37089938702;/37085871400;/38180146500;/37282400400;/37089938702;/37085871400;/38180146500;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, Faculty of Engineering, University of Alberta, Alberta, Canada; College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Advanced Robotics ana Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Faculty of Engineering, University of Alberta, Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981615/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11834592305319883168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Alberta;Nanjing University of Aeronautics and Astronautics;K. N. Toosi University of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;College of Astronautics;Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.ualberta.ca;http://www.nuaa.edu.cn;",
        "aff_unique_abbr": "UAlberta;NUAA;KNTU",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Alberta;Nanjing;Tehran",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Canada;China;Iran"
    },
    {
        "id": "9981149",
        "title": "EPAR: An Efficient and Privacy-Aware Augmented Reality Framework for Indoor Location-Based Services",
        "track": "main",
        "status": "Poster",
        "abstract": "Augmented reality (AR) defines a new information-delivery paradigm by overlaying computer-generated information on the perception of the real world. AR-integrated robot has become an appealing concept in terms of enhanced human-robot interaction. Despite intensive research on AR, existing indoor location-based AR systems are vulnerable to attacks and can hardly meet the security and privacy requirements in practice. The problem of designing a secure AR framework to ensure the efficiency and privacy of location-based AR has not been sufficiently studied. In this paper, we holistically study this problem and propose EPAR, an efficient and privacy-aware AR framework for indoor location-based services. EPAR distinguishes itself from the existing work by being the first to address the issues of AR delivery in terms of system scalability, accuracy, privacy, and efficiency. First, an effective indoor location cloaking scheme is presented to safeguard user's privacy while improving system scalability and accuracy. Then, a novel privacy-aware localization scheme is proposed to hierarchically localize the user with privacy concerns. Finally, for the AR content delivery, a new authenticated data structure is tailored to save the data transmission cost and improve system efficiency. We implement EPAR and conduct extensive experiments in real-world scenarios. Evaluation results demonstrate the effectiveness of our EPAR system.",
        "primary_area": "",
        "author": "Zhe Peng;Songlin Hou;Yixuan Yuan;Zhe Peng;Songlin Hou;Yixuan Yuan",
        "authorids": "/37085648110;/37089664028;/37075918800;/37085648110;/37089664028;/37075918800",
        "aff": "Department of Computer Science, Baptist University, Hong Kong; Department of Computer Science, Worcester Polytechnic Institute, Worcester, USA; Department of Electrical Engineering, City University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981149/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5503572646736617189&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Baptist University;Worcester Polytechnic Institute;City University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Department of Electrical Engineering",
        "aff_unique_url": "https://www.bu.edu.hk;https://www.wpi.edu;https://www.cityu.edu.hk",
        "aff_unique_abbr": "BUHK;WPI;CityU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Worcester",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981470",
        "title": "EVOPS Benchmark: Evaluation of Plane Segmentation from RGBD and LiDAR Data",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper provides the EVOPS dataset for plane segmentation from 3D data, both from RGBD images and LiDAR point clouds. We have designed two annotation methodologies (RGBD and LiDAR) running on well-known and widely-used datasets for SLAM evaluation and we have provided a complete set of benchmarking tools including point, planes and segmentation metrics. The data includes a total number of 10k RGBD and 7K LiDAR frames over different selected scenes which consist of high quality segmented planes. The experiments report quality of SOTA methods for RGBD plane segmentation on our annotated data. We also have provided learnable baseline for plane segmentation in LiDAR point clouds. All labeled data and benchmark tools used have been made publicly available https://evops.netlify.app/.",
        "primary_area": "",
        "author": "Anastasiia Kornilova;Dmitrii Iarosh;Denis Kukushkin;Nikolai Goncharov;Pavel Mokeev;Arthur Saliou;Gonzalo Ferrer;Anastasiia Kornilova;Dmitrii Iarosh;Denis Kukushkin;Nikolai Goncharov;Pavel Mokeev;Arthur Saliou;Gonzalo Ferrer",
        "authorids": "/37089196897;/37086921423;/37088556516;/37089663556;/37089658931;/37089660936;/38469245200;/37089196897;/37086921423;/37088556516;/37089663556;/37089658931;/37089660936;/38469245200",
        "aff": "Skolkovo Institute of Science and Technology (Skoltech), Center for AI Technology (CAIT).; Software Engineering Department, Saint Petersburg State University; Skolkovo Institute of Science and Technology (Skoltech), Center for AI Technology (CAIT).; Skolkovo Institute of Science and Technology (Skoltech), Center for AI Technology (CAIT).; Software Engineering Department, Saint Petersburg State University; Software Engineering Department, Saint Petersburg State University; Skolkovo Institute of Science and Technology (Skoltech), Center for AI Technology (CAIT).",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981470/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15203920508877519709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;1;0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Saint Petersburg State University",
        "aff_unique_dep": "Center for AI Technology;Software Engineering Department",
        "aff_unique_url": "https://www.skoltech.ru;https://spbu.ru",
        "aff_unique_abbr": "Skoltech;SPbSU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Saint Petersburg",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9982267",
        "title": "Early Recall, Late Precision: Multi-Robot Semantic Object Mapping under Operational Constraints in Perceptually-Degraded Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic object mapping in uncertain, perceptually degraded environments during long-range multi-robot autonomous exploration tasks such as search-and-rescue is important and challenging. During such missions, high recall is desirable to avoid missing true target objects and high precision is also critical to avoid wasting valuable operational time on false positives. Given recent advancements in visual perception algorithms, the former is largely solvable autonomously, but the latter is difficult to address without the supervision of a human operator. However, operational constraints such as mission time, computational requirements and mesh network bandwidth can make the operator's task infeasible unless properly managed. We propose the Early Recall, Late Precision (EaRLaP) semantic object mapping pipeline to solve this problem. EaRLaP was used by Team CoSTAR in DARPA Subterranean Challenge, where it successfully detected all the artifacts encountered by the team of robots. We will discuss these results and the performance of the EaRLaP on various datasets.",
        "primary_area": "",
        "author": "Xianmei Lei;Taeyeon Kim;Nicolas Marchal;Daniel Pastor;Barry Ridge;Frederik Sch\u00f6ller;Edward Terry;Fernando Chavez;Thomas Touma;Kyohei Otsu;Benjamin Morrell;Ali Agha;Xianmei Lei;Taeyeon Kim;Nicolas Marchal;Daniel Pastor;Barry Ridge;Frederik Sch\u00f6ller;Edward Terry;Fernando Chavez;Thomas Touma;Kyohei Otsu;Benjamin Morrell;Ali Agha",
        "authorids": "/37089659758;/37089661648;/37087413747;/37087323301;/37546416900;/37089213113;/37089658333;/37086486345;/37088472679;/37085558541;/37086454259;/37086689631;/37089659758;/37089661648;/37087413747;/37087323301;/37546416900;/37089213113;/37089658333;/37086486345;/37088472679;/37085558541;/37086454259;/37086689631",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, United State; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State; Jet Propulsion Laboratory, California Institute of Technology, United State",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982267/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16380433106658443869&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory;Department of Electrical Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "Caltech;KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9981478",
        "title": "Effects of Design and Hydrodynamic Parameters on Optimized Swimming for Simulated, Fish-inspired Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we developed a mathematical model and a simulation platform for a fish-inspired robotic template, namely Magnetic, Modular, Undulatory Robot (\\mu \\text{Bot})(\\mu \\text{Bot}). Through this platform, we systematically explored the effects of robot design and fluid parameters on swimming performance via reinforcement learning. The mathematical model was composed of two interacting subsystems, the robotic dynamic model and the hydrodynamic model. The hydrodynamic model consisted of the reactive components (added-mass force and pressure forces) and the resistive components (drag and friction forces). These components were nondimensionalized for deriving key \u201ccontrol parameters\u201d of the robot-fluid interaction. The \\mu\\text{Bots}\\mu\\text{Bots} were actuated via magnetic actuators controlled with harmonic voltage signals, which were optimized via EM-based Policy Hyper Parameter Exploration (EPHE) to maximize forward swimming speed. By varying the control parameters, a total of 36 cases with different robot template variations (Number of Actuators (NoA) and stiffness) and hydrodynamic parameters were simulated and optimized via EPHE. Results showed that the wavelength of the optimized gaits (i.e., backward traveling wave along the body) was independent of template variations and hydrodynamic parameters. Higher NoA yielded higher speed but lower speed per body length, suggesting a diminishing gain from added actuators. Body and caudal-fin dynamics were dominated by the interaction among fluid added-mass, spring, and actuation torque, with negligible contribution from fluid resistive drag. In contrast, thrust was dominated by the pressure force acting on the caudal fin, as steady swimming resulted from a balance between resistive force and pressure force, with minor contributions from added-mass force and body drag forces. Therefore, added-mass force only indirectly affected the thrust generation and forward swimming speed via the caudal fin dynamics.",
        "primary_area": "",
        "author": "Donghao Li;Hankun Deng;Yagiz E. Bayiz;Bo Cheng;Donghao Li;Hankun Deng;Yagiz E. Bayiz;Bo Cheng",
        "authorids": "/37089196935;/37089195069;/37086455709;/37536373700;/37089196935;/37089195069;/37086455709;/37536373700",
        "aff": "Department of Mechanical Engineering, Penn State University, PA, USA; Department of Mechanical Engineering, Penn State University, PA, USA; Department of Mechanical Engineering, Penn State University, PA, USA; Department of Mechanical Engineering, Penn State University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981478/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=504059386449963596&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Penn State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981048",
        "title": "Effects of Multiple Avatar Images Presented Consecutively with Temporal Delays on Self-Body Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-body awareness refers to the recognition of one's body as one's own and consists of two senses: \u201csense of body ownership\u201d and \u201csense of agency.\u201d In telexistence/telepresence robot operation, time delays in the robot's motion degrade self-body awareness of the robot body. We investigated how self-body recognition can be affected in a telexistence robot operation in a VR space when the robot is presented with a real robot arm that simulates a real robot with a delay and a virtual robot arm, or several virtual robot arms, with a delay less than that of the real robot. These experimental conditions include a \u2018Predictive Display,\u2019 which is well known as a time delay countermeasure. The results suggest that virtual robot arms presented consecutively with less delay than a real robot arm do not induce a sense of body ownership to the real robot arm, but they enhance the sense of agency to the real robot arm, and that sense of agency is stronger when the task requires precision.",
        "primary_area": "",
        "author": "Eimei Oyama;Yuya Ioka;Arvin Agah;Hiroyuki Okada;Sotaro Shimada;Eimei Oyama;Yuya Ioka;Arvin Agah;Hiroyuki Okada;Sotaro Shimada",
        "authorids": "/37330252200;/37089663644;/37274079700;/37532860700;/38468674300;/37330252200;/37089663644;/37274079700;/37532860700;/38468674300",
        "aff": "Tsukuba Science City, Industrial CPS Research Center, National Institute of Advanced Science and Technology, Ibaraki, Japan; Honda Motor Co., Ltd., M Asaka-shi, Saitama, Japan; Dean of Engineering, The University of Kansas, Lawrence, KS, USA; College of Engineering, Tamagawa University, Machida City, Tokyo, Japan; School of Science and Technology, Meiji University, Kawasaki-shi, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981048/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:R3cBWHpqgVwJ:scholar.google.com/&scioq=Effects+of+Multiple+Avatar+Images+Presented+Consecutively+with+Temporal+Delays+on+Self-Body+Recognition&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "National Institute of Advanced Science and Technology;Honda Motor Co., Ltd.;University of Kansas;Tamagawa University;Meiji University",
        "aff_unique_dep": "Industrial CPS Research Center;;Engineering;College of Engineering;School of Science and Technology",
        "aff_unique_url": "https://www.aist.go.jp;https://www.honda.com;https://www.ku.edu;https://www.tamagawa.ac.jp;https://www.meiji.ac.jp",
        "aff_unique_abbr": "AIST;Honda;KU;Tamagawa U;Meiji",
        "aff_campus_unique_index": "0;2;3;4",
        "aff_campus_unique": "Tsukuba;;Lawrence;Machida City, Tokyo;Kawasaki-shi, Kanagawa",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9981200",
        "title": "Efficient 2D Graph SLAM for Sparse Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) plays a vital role in mapping unknown spaces and aiding autonomous navigation. Virtually all state-of-the-art solutions today for 2D SLAM are designed for dense and accurate sensors such as laser range-finders (LiDARs). However, these sensors are not suitable for resource-limited nano robots, which become increasingly capable and ubiquitous nowadays, and these robots tend to mount economical and low-power sensors that can only provide sparse and noisy measurements. This introduces a challenging problem called SLAM with sparse sensing. This work addresses the problem by adopting the form of the state-of-the-art graph-based SLAM pipeline with a novel frontend and an improvement for loop closing in the backend, both of which are designed to work with sparse and uncertain range data. Experiments show that the maps constructed by our algorithm have superior quality compared to prior works on sparse sensing. Furthermore, our method is capable of running in real-time on a modern PC with an average processing time of 1/100th the input interval time.",
        "primary_area": "",
        "author": "Hanzhi Zhou;Zichao Hu;Sihang Liu;Samira Khan;Hanzhi Zhou;Zichao Hu;Sihang Liu;Samira Khan",
        "authorids": "/37089661625;/37089663453;/37086358903;/37085386385;/37089661625;/37089663453;/37086358903;/37085386385",
        "aff": "Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981200/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11700035045330761217&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982047",
        "title": "Efficient 2D LIDAR-Based Map Updating For Long-Term Operations in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-time operations of autonomous vehicles and mobile robots in logistics and service applications are still a challenge. To avoid a continuous re-mapping, the map can be updated to obtain a consistent representation of the current environment. In this paper, we propose a novel LIDAR-based occupancy grid map updating algorithm for dynamic environments taking into account possible localisation and measurement errors. The proposed approach allows robust long-term operations as it can detect changes in the working area even in presence of moving elements. Results highlighting map quality and localisation performance, both in simulation and experiments, are reported.",
        "primary_area": "",
        "author": "Elisa Stefanini;Enrico Ciancolini;Alessandro Settimi;Lucia Pallottino;Elisa Stefanini;Enrico Ciancolini;Alessandro Settimi;Lucia Pallottino",
        "authorids": "/37088829279;/37089659829;/37889368400;/37278580100;/37088829279;/37089659829;/37889368400;/37278580100",
        "aff": "Soft Robotics for Human Cooperation and Rehabilitation, Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Proxima Robotics s.r.l., Pisa, Italy; Proxima Robotics s.r.l., Pisa, Italy; Centro di Ricerca \u201cE. Piaggio\u201d e Dipartimento di Ingegneria dell'Informazione, Universit\u00e0 di Pisa, Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982047/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=522514868460339334&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Fondazione Istituto Italiano di Tecnologia;Proxima Robotics;Universit\u00e0 di Pisa",
        "aff_unique_dep": "Soft Robotics for Human Cooperation and Rehabilitation;;Dipartimento di Ingegneria dell'Informazione",
        "aff_unique_url": "https://www.iit.it;;https://www.unipi.it",
        "aff_unique_abbr": "IIT;;UniPi",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Genova;;Pisa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981312",
        "title": "Efficient Concurrent Design of the Morphology of Unmanned Aerial Systems and their Collective-Search Behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "The collective operation of robots, such as unmanned aerial vehicles (UAVs) operating as a team or swarm, is affected by their individual capabilities, which in turn is dependent on their physical design, aka morphology. However, with the exception of a few (albeit ad hoc) evolutionary robotics methods, there has been very little work on understanding the interplay of morphology and collective behavior. There is especially a lack of computational frameworks to concurrently search for the robot morphology and the hyper-parameters of their behavior model that jointly optimize the collective (team) performance. To address this gap, this paper proposes a new co-design framework. Here the exploding computational cost of an otherwise nested morphology/behavior co-design is effectively alleviated through the novel concept of \u201ctalent\u201d metrics; while also allowing significantly better solutions compared to the typically sub-optimal sequential morphology \u2192 behavior design approach. This framework comprises four major steps: talent metrics selection, talent Pareto exploration (a multi-objective morphology optimization process), behavior optimization, and morphology finalization. This co-design concept is demonstrated by applying it to design UAVs that operate as a team to localize signal sources, e.g., in victim search and hazard localization. Here, the collective behavior is driven by a recently reported batch Bayesian search algorithm called Bayes-Swarm. Our case studies show that the outcome of co-design provides significantly higher success rates in signal source localization compared to a baseline design, across a variety of signal environments and teams with 6 to 15 UAVs. Moreover, this co-design process provides two orders of magnitude reduction in computing time compared to a projected nested design approach.",
        "primary_area": "",
        "author": "Chen Zeng;Prajit KrisshnaKumar;Jhoel Witter;Souma Chowdhury;Chen Zeng;Prajit KrisshnaKumar;Jhoel Witter;Souma Chowdhury",
        "authorids": "/37089658764;/37089663125;/37089662308;/37086117851;/37089658764;/37089663125;/37089662308;/37086117851",
        "aff": "Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981312/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3752330986343374508&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University at Buffalo",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.buffalo.edu",
        "aff_unique_abbr": "UB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Buffalo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981606",
        "title": "Efficient Extrinsic Calibration of Multi-Sensor 3D LiDAR Systems for Autonomous Vehicles using Static Objects Information",
        "track": "main",
        "status": "Poster",
        "abstract": "For an autonomous vehicle, the ability to sense its surroundings and to build an overall representation of the environment by fusing different sensor data streams is fundamental. To this end, the poses of all sensors need to be accurately determined. Traditional calibration methods are based on: 1) using targets specifically designed for calibration purposes in controlled environments, 2) optimizing a quality metric of the point clouds collected while traversing an unknown but static environment, or 3) optimizing the match among persensor incremental motion observations along a motion path fulfilling special requirements. In real scenarios, however, the online applicability of these methods can be limited, as they are typically highly dynamic, contain degenerate paths, and require fast computations. In this paper, we propose an approach that tackles some of these challenges by formulating the calibration problem as a joint but structured optimization problem of all sensor calibrations that takes as input a summary of the point cloud information consisting of ground points and pole detections. We demonstrate the efficiency and quality of the results of the proposed approach in a set of experiments with LiDAR simulation and real data from an urban trip.",
        "primary_area": "",
        "author": "Brahayam Ponton;Magda Ferri;Lars K\u00f6nig;Marcus Bartels;Brahayam Ponton;Magda Ferri;Lars K\u00f6nig;Marcus Bartels",
        "authorids": "/37086175065;/37089662828;/37070971600;/37271540800;/37086175065;/37089662828;/37070971600;/37271540800",
        "aff": "IBEO Automotive Systems GmbH, Hamburg, Germany; IBEO Automotive Systems GmbH, Hamburg, Germany; IBEO Automotive Systems GmbH, Hamburg, Germany; IBEO Automotive Systems GmbH, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981606/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12419553977248861625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ibeo Automotive Systems GmbH",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ibeo-as.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981744",
        "title": "Efficient Learning of Inverse Dynamics Models for Adaptive Computed Torque Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Modelling robot dynamics accurately is essential for control, motion optimisation and safe human-robot collaboration. Given the complexity of modern robotic systems, dynamics modelling remains non-trivial, mostly in the presence of compliant actuators, mechanical inaccuracies, friction and sensor noise. Recent efforts have focused on utilising datadriven methods such as Gaussian processes and neural networks to overcome these challenges, as they are capable of capturing these dynamics without requiring extensive knowledge beforehand. While Gaussian processes have shown to be an effective method for learning robotic dynamics with the ability to also represent the uncertainty in the learned model through its variance, they come at a cost of cubic time complexity rather than linear, as is the case for deep neural networks. In this work, we leverage the use of deep kernel models, which combine the computational efficiency of deep learning with the nonparametric flexibility of kernel methods (Gaussian processes), with the overarching goal of realising an accurate probabilistic framework for uncertainty quantification. Through using the predicted variance, we adapt the feedback gains as more accurate models are learned, leading to low-gain control without compromising tracking accuracy. Using simulated and real data recorded from a seven degree-of-freedom robotic manipulator, we illustrate how using stochastic variational inference with deep kernel models increases compliance in the computed torque controller, and retains tracking accuracy. We empirically show how our model outperforms current state-of-the-art methods with prediction uncertainty for online inverse dynamics model learning, and solidify its adaptation and generalisation capabilities across different setups.",
        "primary_area": "",
        "author": "David Jorge;Gabriella Pizzuto;Michael Mistry;David Jorge;Gabriella Pizzuto;Michael Mistry",
        "authorids": "/37089663902;/37087016402;/37542865600;/37089663902;/37087016402;/37542865600",
        "aff": "Institute of Perception, Action and Behaviour University of Edinburgh, United Kingdom; Department of Chemistry, University of Liverpool, United Kingdom; Institute of Perception, Action and Behaviour University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981744/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7013277630580259015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Edinburgh;University of Liverpool",
        "aff_unique_dep": "Institute of Perception, Action and Behaviour;Department of Chemistry",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.liverpool.ac.uk",
        "aff_unique_abbr": "Edinburgh;Liv Uni",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981244",
        "title": "Efficient Multi-Task Learning via Iterated Single-Task Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to be effective general purpose machines in real world environments, robots not only will need to adapt their existing manipulation skills to new circumstances, they will need to acquire entirely new skills on-the-fly. One approach to achieving this capability is via Multi-task Reinforcement Learning (MTRL). Most recent work in MTRL trains a single policy to solve all tasks at once. In this work, we investigate the feasibility of instead training separate policies for each task, and only transferring from a task once the policy for it has finished training. We describe a method of finding near optimal sequences of transfers to perform in this setting, and use it to show that performing the optimal sequence of transfer is competitive with other MTRL methods on the Meta World MT10 benchmark. Lastly, we describe a method for finding nearly optimal transfer sequences during training that is able to improve on training each task from scratch.",
        "primary_area": "",
        "author": "K.R. Zentner;Ujjwal Puri;Yulun Zhang;Ryan Julian;Gaurav S. Sukhatme;K.R. Zentner;Ujjwal Puri;Yulun Zhang;Ryan Julian;Gaurav S. Sukhatme",
        "authorids": "/37089658529;/37089660128;/37086571190;/37089662688;/37278934100;/37089658529;/37089660128;/37086571190;/37089662688;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA; Department of Computer Science, University of Southern California, Los Angeles, CA; Department of Computer Science, University of Southern California, Los Angeles, CA; Department of Computer Science, University of Southern California, Los Angeles, CA; USC and as an Amazon Scholar",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981244/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1947743764908892757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982188",
        "title": "Efficient Range-Constraint Manifold Optimization with Application to Cooperative Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a manifold optimization approach to solve inference and planning problems with range constraints. The core of our approach is the definition of a manifold that represents points or poses with range constraints. We discover that the manifold of range-constrained points is homogeneous under the rigid transformation group action, and utilize the group action to derive the tangent space, retraction and topology of the manifold. We evaluate the performance of manifold optimization approach on solving range-constrained inference problems over state-of-the-art constrained optimization methods. The results show that manifold optimization with the range-constraint manifold achieves both faster speed and better constraint satisfaction. We further study the conditions of inference problems that we can treat range measurements as constraints in practice.",
        "primary_area": "",
        "author": "Yetong Zhang;Gerry Chen;Adam Rutkowski;Frank Dellaert;Yetong Zhang;Gerry Chen;Adam Rutkowski;Frank Dellaert",
        "authorids": "/37088998216;/37089000441;/37089884777;/37282902200;/37088998216;/37089000441;/37089884777;/37282902200",
        "aff": "College of Computing, Georgia Institute of Technology, Atlanta, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA; Munitions Directorate, Air Force Research Laboratory, Eglin AFB, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982188/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12465682930381627332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Air Force Research Laboratory",
        "aff_unique_dep": "College of Computing;Munitions Directorate",
        "aff_unique_url": "https://www.gatech.edu;https://www.afrl.af.mil/",
        "aff_unique_abbr": "Georgia Tech;AFRL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Atlanta;Eglin AFB",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982169",
        "title": "Efficient Sampling-Based Planning for Subterranean Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes a path planning solution for autonomous robotic exploration of complex subterranean environments. The work contributes to the family of graph-based planners by bringing the following improvements. Firstly, an occupancy grid-based sample-and-project solution to terrain-assessment is proposed instead of building an explicit elevation map of the environment. Secondly, the solution-search method is formulated as a constraint-satisfaction problem to obtain a good-enough solution instead of optimizing for a single objective function parametrized by penalty gains. This method is shown to significantly improve the computational efficiency of the planner. Thirdly, a coordination solution is proposed that relies on the position histories of the robots instead of merged-maps or merged-graphs, therefore, making the planning solution resilient to inter-robot map misalignments, while also reducing the communication bandwidth required to carry out coordination. Finally, the planner also takes into account changes in the environment such as blocked passages that are initially open. The proposed planning solution is demonstrated at the DARPA Subterranean Challenge final event by team MARBLE, the third place finisher of the challenge.",
        "primary_area": "",
        "author": "Shakeeb Ahmad;J. Sean Humbert;Shakeeb Ahmad;J. Sean Humbert",
        "authorids": "/37086176864;/37530064300;/37086176864;/37530064300",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado Boulder, CO, USA; Department of Mechanical Engineering, University of Colorado Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982169/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11451489490258398158&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981707",
        "title": "Efficient Sampling-based Multirotors Kinodynamic Planning with Fast Regional Optimization and Post Refining",
        "track": "main",
        "status": "Poster",
        "abstract": "For real-time multirotor kinodynamic planning, the efficiency of sampling-based methods is usually hindered by difficult-to-sample homotopy classes like narrow passages. In this paper, we address this issue by a hybrid scheme. We firstly propose a fast regional optimizer exploiting the information of local environments and then integrate it into a bidirectional global sampling process. The incorporation of the local optimization shows significantly improved success rates and less planning time in various types of challenging environments. We further present a refinement module utilizing the same framework as the regional optimizer. It comprehensively investigates the resulting trajectory of the global sampling and improves its smoothness with nearly negligible computation effort. Benchmark results illustrate that our proposed method can better exploit a previous trajectory compared to the state-of-the-art ones. The planning methods are applied to generate trajectories for a quadrotor system in simulation and real-world, and their capability is validated in real-time applications.",
        "primary_area": "",
        "author": "Hongkai Ye;Neng Pan;Qianhao Wang;Chao Xu;Fei Gao;Hongkai Ye;Neng Pan;Qianhao Wang;Chao Xu;Fei Gao",
        "authorids": "/37086811929;/37088986697;/37089197978;/37404060100;/37086045143;/37086811929;/37088986697;/37089197978;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981707/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14616080174247938652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981939",
        "title": "Efficient Spatial Representation and Routing of Deformable One-Dimensional Objects for Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "With the field of rigid-body robotics having matured in the last fifty years, routing, planning, and manipulation of deformable objects have recently emerged as a more untouched research area in many fields ranging from surgical robotics to industrial assembly and construction. Routing approaches for deformable objects which rely on learned implicit spatial representations (e.g., Learning-from-Demonstration methods) make them vulnerable to changes in the environment and the specific setup. On the other hand, algorithms that entirely separate the spatial representation of the deformable object from the routing and manipulation, often using a representation approach independent of planning, result in slow planning in high dimensional space. This paper proposes a novel approach to routing deformable one-dimensional objects (e.g., wires, cables, ropes, sutures, threads). This approach utilizes a compact representation for the object, allowing efficient and fast online routing. The spatial representation is based on the geometrical decomposition of the space into convex subspaces, resulting in a discrete coding of the deformable object configuration as a sequence. With such a configuration, the routing problem can be solved using a fast dynamic programming sequence matching method that calculates the next routing move. The proposed method couples the routing and efficient configuration for improved planning time. Our simulation and real experiments show the method correctly computing the next manipulation action in sub-millisecond time and accomplishing various routing and manipulation tasks.",
        "primary_area": "",
        "author": "Azarakhsh Keipour;Maryam Bandari;Stefan Schaal;Azarakhsh Keipour;Maryam Bandari;Stefan Schaal",
        "authorids": "/38547709500;/37085436412;/37282144700;/38547709500;/37085436412;/37282144700",
        "aff": "Robotics AI, Amazon, Washington, DC; Intrinsic, Mountain View, CA; Intrinsic, Mountain View, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981939/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16079440552448738060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Amazon;Intrinsic",
        "aff_unique_dep": "Robotics AI;",
        "aff_unique_url": "https://www.amazon.com;",
        "aff_unique_abbr": "Amazon;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Washington, DC;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981210",
        "title": "Efficient Spatial-Temporal Information Fusion for LiDAR-Based 3D Moving Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate moving object segmentation is an es-sential task for autonomous driving. It can provide effective information for many downstream tasks, such as collision avoidance, path planning, and static map construction. How to effectively exploit the spatial-temporal information is a critical question for 3D LiDAR moving object segmentation (LiDAR-MOS). In this work, we propose a novel deep neural network exploiting both spatial-temporal information and different representation modalities of LiDAR scans to improve LiDAR-MOS performance. Specifically, we first use a range image-based dual-branch structure to separately deal with spatial and temporal information that can be obtained from sequential LiDAR scans, and later combine them using motion-guided attention modules. We also use a point refinement module via 3D sparse convolution to fuse the information from both LiDAR range image and point cloud representations and reduce the artifacts on the borders of the objects. We verify the effectiveness of our proposed approach on the LiDAR-MOS benchmark of SemanticKITTI. Our method outperforms the state-of-the-art methods significantly in terms of LiDAR-MOS IoU. Benefiting from the devised coarse-to-fine architecture, our method operates online at sensor frame rate. Code is available at: https://github.com/haomo-ai/MotionSeg3D.",
        "primary_area": "",
        "author": "Jiadai Sun;Yuchao Dai;Xianjing Zhang;Jintao Xu;Rui Ai;Weihao Gu;Xieyuanli Chen;Jiadai Sun;Yuchao Dai;Xianjing Zhang;Jintao Xu;Rui Ai;Weihao Gu;Xieyuanli Chen",
        "authorids": "/37089236717;/37404463400;/37089660538;/37089419486;/37089419638;/37089419973;/37086247697;/37089236717;/37404463400;/37089660538;/37089419486;/37089419638;/37089419973;/37086247697",
        "aff": "Northwestern Polytechnical University; Northwestern Polytechnical University; HAOMO.AI Tech. Co., Ltd.; HAOMO.AI Tech. Co., Ltd.; HAOMO.AI Tech. Co., Ltd.; HAOMO.AI Tech. Co., Ltd.; HAOMO.AI Tech. Co., Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981210/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16355676030556301594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;1;1",
        "aff_unique_norm": "Northwestern Polytechnical University;HAOMO.AI Tech. Co., Ltd.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nwpu.edu.cn;",
        "aff_unique_abbr": "NWPU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981280",
        "title": "Efficient Task/Motion Planning for a Dual-arm Robot from Language Instructions and Cooking Images",
        "track": "main",
        "status": "Poster",
        "abstract": "When generating robot motions based on instructions such as cooking recipes, ambiguity of the instructions and lack of necessary information are problematic for the robot. To solve this problem, we propose an efficient motion planning approach for a dual-arm robot by constructing a graph repre-senting a motion sequence based on a recipe consisting of verbal instructions and cooking images. A functional unit is generated based on the linguistic instructions in the recipe. Since most recipes lack the necessary information for executing the motion, we first consider extracting the information about the cooking motion like cutting from the food images of the recipe and supplementing it. In addition, to supplement the actions that humans perform unconsciously, we generate functional units for actions not explicitly mentioned in the recipe based on the current situation of the cooking process, and then connect them to the functional units generated from the recipe. Moreover, during the connection we consider the motion of the robot's arms in parallel for an efficient execution of the recipe, similar to those of a human. Through experiments, we demonstrate that for a given recipe, the proposed method can be used to generate a cooking sequence with the supplementary information needed, and executed by a dual-arm robot. The results show that the proposed method is effective and can simplify robot teaching in cooking tasks.",
        "primary_area": "",
        "author": "Kota Takata;Takuya Kiyokawa;Ixchel G. Ramirez-Alpizar;Natsuki Yamanobe;Weiwei Wan;Kensuke Harada;Kota Takata;Takuya Kiyokawa;Ixchel G. Ramirez-Alpizar;Natsuki Yamanobe;Weiwei Wan;Kensuke Harada",
        "authorids": "/37089661165;/37086694759;/38272901900;/37281644100;/37085689483;/37277067400;/37089661165;/37086694759;/38272901900;/37281644100;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan; Industrial Cyber-Physical Systems Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Industrial Cyber-Physical Systems Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Graduate School of Engineering Science, Osaka University, Japan; Industrial Cyber-Physical Systems Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981280/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6421585369214546343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;1",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;Industrial Cyber-Physical Systems Research Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981422",
        "title": "Efficiently Learning Manipulations by Selecting Structured Skill Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "A key challenge in learning to perform manipulation tasks is selecting a suitable skill representation. While specific skill representations are often easier to learn, they are often only suitable for a narrow set of tasks. In most prior works, roboticists manually provide the robot with a suitable skill representation to use e.g. a neural network or DMPs. By contrast, we propose to allow the robot to select the most appropriate skill representation for the underlying task. Given the large space of skill representations, we utilize a single demonstration to select a small set of potential task-relevant representations. This set is then further refined using reinforcement learning to select the most suitable skill representation. Experiments in both simulation and real world show how our proposed approach leads to improved sample efficiency and enables directly learning on the real robot.",
        "primary_area": "",
        "author": "Mohit Sharma;Oliver Kroemer;Mohit Sharma;Oliver Kroemer",
        "authorids": "/37086376038;/37593222300;/37086376038;/37593222300",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981422/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:wctq5pgNe9AJ:scholar.google.com/&scioq=Efficiently+Learning+Manipulations+by+Selecting+Structured+Skill+Representations&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981710",
        "title": "Ego+X: An Egocentric Vision System for Global 3D Human Pose Estimation and Social Interaction Characterization",
        "track": "main",
        "status": "Poster",
        "abstract": "Egocentric vision is an emerging topic, which has demonstrated great potential in assistive healthcare scenarios, ranging from human-centric behavior analysis to personal social assistance. Within this field, due to the heterogeneity of visual perception from first-person views, egocentric pose estimation is one of the most significant prerequisites for enabling various downstream applications. However, existing methods for egocentric pose estimation mainly focus on predicting the pose represented in the camera coordinates from a single image, which ignores the latent cues in the temporal domain and results in less accuracy. In this paper, we propose Ego+X, an egocentric vision based system for 3D canonical pose estimation and human-centric social interaction characterization. Our system is composed of two head-mounted egocentric cameras, where one is faced downwards and the other looks outwards. By leveraging the global context provided by visual SLAM, we first propose Ego-Glo for spatial-accurate and temporal-consistent egocentric 3D pose estimation in the canonical coordinate system. With the help of an egocentric camera looking outwards, we then propose Ego-Soc by extending Ego-Glo to various social interaction tasks, e.g., object detection and human-human interaction. Quantitative and qualitative experiments have been conducted to demonstrate the effectiveness of our proposed Ego+X.",
        "primary_area": "",
        "author": "Yuxuan Liu;Jianxin Yang;Xiao Gu;Yao Guo;Guang-Zhong Yang;Yuxuan Liu;Jianxin Yang;Xiao Gu;Yao Guo;Guang-Zhong Yang",
        "authorids": "/37089612525;/37089447797;/37086360965;/37086919325;/37276270800;/37089612525;/37089447797;/37086360965;/37086919325;/37276270800",
        "aff": "Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Hamlyn Centre, Imperial College London, UK; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981710/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16722980359652849372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Imperial College London",
        "aff_unique_dep": "Institute of Medical Robotics;Hamlyn Centre",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.imperial.ac.uk",
        "aff_unique_abbr": "SJTU;ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9982098",
        "title": "Electro-Adhesive Tubular Clutch for Variable-Stiffness Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Electro-adhesive clutches have become effective tools for variable stiffness functions in many robotic systems due to their light weight, high speed and strong brake force. In this paper, we present a novel, tubular design of an electro-adhesive clutch. Our clutch consists of flexible electrode sheets rolled into a tubular structure. This design allows encapsulating large electrode areas in a compact size for strong brake force. Additionally, the tubular structure acts as a guide for directional sliding without external guides. The structure also ensures that the electrode surfaces are encapsulated, preventing the accumulation of dust and thus leading to reliable performance. This structure is therefore an improvement over the commonly used planar designs. The characterization of the electro-adhesive tubular clutch shows that the frictional force increases with the increase of the electrode contact area, the decrease of the roll diameter and the dielectric layer thickness. A retractable tubular clutch is made by fixing an elastic cable along the clutch axis and achieves a stiffness change factor up to 260. Applications of this retractable clutch in robotics to achieve variable stiffness are demonstrated in two systems: a tensegrity structure and a wing skeleton. Changes in stiffness by 13.2 and 30.2 times are achieved for the two systems, respectively. The proposed tubular clutch is an effective means of achieving variable stiffness, particularly in the case of robotic systems that transmit forces through tensioned cables.",
        "primary_area": "",
        "author": "Yi Sun;Krishna Manaswi Digumarti;Hoang-Vu Phan;Omar Aloui;Dario Floreano;Yi Sun;Krishna Manaswi Digumarti;Hoang-Vu Phan;Omar Aloui;Dario Floreano",
        "authorids": "/37089661089;/37086145365;/37089658537;/37089663419;/37282168700;/37089661089;/37086145365;/37089658537;/37089663419;/37282168700",
        "aff": "Laboratory of Intelligent Systems, Institute of Mechanical Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory of Intelligent Systems, Institute of Mechanical Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory of Intelligent Systems, Institute of Mechanical Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory of Intelligent Systems, Institute of Mechanical Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory of Intelligent Systems, Institute of Mechanical Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982098/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8037018078803222522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Institute of Mechanical Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982131",
        "title": "Electroadhesive Clutches for Programmable Shape Morphing of Soft Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic actuators are safe and adaptable devices with inherent compliance, which makes them attractive for manipulating delicate and complex objects. Researchers have integrated stiff materials into soft actuators to increase their force capacity and direct their deformation. However, these embedded materials have largely been pre-prescribed and static, which constrains the actuators to a predetermined range of motion. In this work, electroadhesive (EA) clutches integrated on a single-chamber soft pneumatic actuator (SPA) provide local programmable stiffness modulation to control the actuator deformation. We show that activating different clutch patterns inflates a silicone membrane into pyramidal, round, and plateau shapes. Curvatures from these shapes are combined during actuation to apply forces on both a 3.7 g and 820 g object along five different degrees of freedom (DoF). The actuator workspace is up to 12 mm for light objects. Clutch deactivation, which results in local elastomeric expansion, rapidly applies forces up to 3.2 N to an object resting on the surface and launches a 3.7 g object in controlled directions. The actuator also rotates a heavier, 820 g, object by 5 degrees and rapidly restores it to horizontal alignment after clutch deactivation. This actuator is fully powered by a 5 V battery, AA battery, DC-DC transformer, and 4.5 V (63 g) DC air pump. These results demonstrate a first step towards realizing a soft actuator with high DoF shape change that preserves the inherent benefits of pneumatic actuation while gaining the electrical controllability and strength of EA clutches. We envision such a system supplying human contact forces in the form of a low-profile sit-to-stand assistance device, bed-ridden patient manipulator, or other ergonomic mechanism.",
        "primary_area": "",
        "author": "Gregory M. Campbell;Jessica Yin;Yuyang Song;Umesh Gandhi;Mark Yim;James Pikul;Gregory M. Campbell;Jessica Yin;Yuyang Song;Umesh Gandhi;Mark Yim;James Pikul",
        "authorids": "/37089371929;/37086575177;/37089658952;/37089488226;/37274063600;/37847228500;/37089371929;/37086575177;/37089658952;/37089488226;/37274063600;/37847228500",
        "aff": "GRASP Lab; GRASP Lab; Toyota Research Institute North America (TRINA), Ann Arbor, MI, USA; Toyota Research Institute North America (TRINA), Ann Arbor, MI, USA; GRASP Lab; GRASP Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982131/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8658977592536603788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "University City Science Center;Toyota Research Institute North America",
        "aff_unique_dep": "GRASP Lab;",
        "aff_unique_url": "https://www.grasplab.org;https://www.tri-na.com",
        "aff_unique_abbr": "GRASP;TRINA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981507",
        "title": "Elevation Mapping for Locomotion and Navigation using GPU",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceiving the surrounding environment is crucial for autonomous mobile robots. An elevation map provides a memory-efficient and simple yet powerful geometric represen-tation of the terrain for ground robots. The robots can use this information for navigation in an unknown environment or perceptive locomotion control over rough terrain. Depending on the application, various post processing steps may be incorpo-rated, such as smoothing, inpainting or plane segmentation. In this work, we present an elevation mapping pipeline leveraging GPU for fast and efficient processing with additional features both for navigation and locomotion. We demonstrated our map-ping framework through extensive hardware experiments. Our mapping software was successfully deployed for underground exploration during DARPA Subterranean Challenge and for various experiments of quadrupedal locomotion.",
        "primary_area": "",
        "author": "Takahiro Miki;Lorenz Wellhausen;Ruben Grandia;Fabian Jenelten;Timon Homberger;Marco Hutter;Takahiro Miki;Lorenz Wellhausen;Ruben Grandia;Fabian Jenelten;Timon Homberger;Marco Hutter",
        "authorids": "/37086454028;/37086200470;/37086355336;/37086332855;/37085994390;/37545251000;/37086454028;/37086200470;/37086355336;/37086332855;/37085994390;/37545251000",
        "aff": "Robotic Systems Lab, ETH, Zurich; Robotic Systems Lab, ETH, Zurich; Robotic Systems Lab, ETH, Zurich; Robotic Systems Lab, ETH, Zurich; Robotic Systems Lab, ETH, Zurich; Robotic Systems Lab, ETH, Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981507/",
        "gs_citation": 95,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14572247132378318091&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981647",
        "title": "Elevation State-Space: Surfel-Based Navigation in Uneven Environments for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new method for robot motion planning and navigation in uneven environments through a surfel representation of underlying point clouds. The proposed method addresses the shortcomings of state-of-the-art navigation methods by incorporating both kinematic and physical constraints of a robot with standard motion planning algorithms (e.g., those from the Open Motion Planning Library), thus enabling efficient sampling-based planners for challenging uneven terrain navigation on raw point cloud maps. Unlike techniques based on Digital Elevation Maps (DEMs), our novel surfel-based state-space formulation and implementation are based on raw point cloud maps, allowing for the modeling of overlapping surfaces such as bridges, piers, and tunnels. Experimental results demonstrate the robustness of the proposed method for robot navigation in real and simulated unstructured environments. The proposed approach also optimizes planners' performances by boosting their success rates up to 5x for challenging unstructured terrain planning and navigation, thanks to our surfel-based approach's robot constraint-aware sampling strategy. Finally, we provide an open-source implementation of the proposed method to benefit the robotics community.",
        "primary_area": "",
        "author": "Fetullah Atas;Grzegorz Cielniak;Lars Grimstad;Fetullah Atas;Grzegorz Cielniak;Lars Grimstad",
        "authorids": "/37088230294;/37550177700;/37085721771;/37088230294;/37550177700;/37085721771",
        "aff": "Norwegian University of Life Sciences; University of Lincoln; Norwegian University of Life Sciences",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981647/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12188429529105267561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Norwegian University of Life Sciences;University of Lincoln",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nmbu.no;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "NMBU;UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Norway;United Kingdom"
    },
    {
        "id": "9981505",
        "title": "Embeddable Coiled Soft Sensor-Based Joint Angle Sensing for Flexible Surgical Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Tendon-driven flexible endoscopic surgical robots have been developed to access narrow curved paths without incision. Robot shape information is essential for precise control and to prevent unwanted tissue damage. In this paper, we propose a joint angle sensing method using coiled soft sensors to estimate the shape of the hyperredundant manipulator, which is commonly used in flexible endoscopic surgical robots. The soft sensors can be fabricated with small size and are highly stretchable, such that by being pre-stretched, they can be integrated between individual joints, maintain a center hollow, and sense both compression and extension. The pre-stretch length is experimentally selected by using the sensor linearity to maximize the potential sensitivity. We validated the proposed design using a two-degree of freedom (DOF) single joint manipulator by implementing two sensors; sensors at all joints could sense joint angle independently and simultaneously with a root-mean-square error (RMSE) less than 2.53\u00b0. Based on the proposed method, a two-DOF configuration of the hyperredundant manipulator that can be used in real applications was achieved, following a constant curvature model in real time with values RMSE of 2.30\u00b0 and 2.63\u00b0, for pitch and yaw joint angle respectively.",
        "primary_area": "",
        "author": "Yesung Yi;Jung-Hwan Youn;Ki-Uk Kyung;Dong-Soo Kwon;Yesung Yi;Jung-Hwan Youn;Ki-Uk Kyung;Dong-Soo Kwon",
        "authorids": "/37089663341;/37088689454;/37283149200;/37278487100;/37089663341;/37088689454;/37283149200;/37278487100",
        "aff": "Division of Mechanical Engineering, School of Mechanical, Aerospace and Systems Engineering, KAIST, Daejeon, South Korea; Division of Mechanical Engineering, School of Mechanical, Aerospace and Systems Engineering, KAIST, Daejeon, South Korea; Division of Mechanical Engineering, School of Mechanical, Aerospace and Systems Engineering, KAIST, Daejeon, South Korea; CEO of EasyEndo Surgical Inc., Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981505/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13913885214885258760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "KAIST;EasyEndo Surgical Inc.",
        "aff_unique_dep": "Division of Mechanical Engineering;",
        "aff_unique_url": "https://www.kaist.ac.kr;",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981540",
        "title": "Embedding Koopman Optimal Control in Robot Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Embedding an optimization process has been explored for imposing efficient and flexible policy structures. Existing work often build upon nonlinear optimization with explicitly iteration steps, making policy inference prohibitively expensive for online learning and real-time control. Our approach embeds a linear-quadratic-regulator (LQR) formulation with a Koopman representation, thus exhibiting the tractability from a closed-form solution and richness from a non-convex neural network. We use a few auxiliary objectives and reparameterization to enforce optimality conditions of the policy that can be easily integrated to standard gradient-based learning. Our approach is shown to be effective for learning policies rendering an optimality structure and efficient reinforcement learning, including simulated pendulum control, 2D and 3D walking, and manipulation for both rigid and deformable objects. We also demonstrate real world application in a robot pivoting task.",
        "primary_area": "",
        "author": "Hang Yin;Michael C. Welle;Danica Kragic;Hang Yin;Michael C. Welle;Danica Kragic",
        "authorids": "/37088353838;/38202265300;/37281296000;/37088353838;/38202265300;/37281296000",
        "aff": "CAS/RPL, KTH Royal Institute of Technology, Stockholm, Sweden; CAS/RPL, KTH Royal Institute of Technology, Stockholm, Sweden; CAS/RPL, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981540/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15726865242536567699&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "CAS/RPL",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9982001",
        "title": "Embodying Rather Than Encoding: Undulation with Binary Input",
        "track": "main",
        "status": "Poster",
        "abstract": "Undulation is the most common gait generated by legless creatures, which enables their robust and efficient locomotion in various environments. Such advantages inspired the control design of many kinds of locomotion robots. Despite their technical details, most of them realize the undulation gait via tracking predetermined trajectories called serpenoid curves, which are a group of sinusoidal waveforms with specified phase differences. This technique, however, sounds quite redundant in terms of sensing and control. Here, we investigate the research question: whether the sinusoidal waveform is necessary to be encoded in the control signal to make the whole body an \u201cS-shape\u201d? We use a 4-link rigid body dynamics model as a simple example, by which numerical simulations are conducted. Together with theoretical analysis, we show that undulation gait emerges naturally based on embodied position controller and filter, where binary actuation torques are required only. Our results not only discover locomotion mechanisms for significantly reducing the sensing and control requirement of generating artificial undulation gait, but also provide additional understandings for biological systems from the mechanical engineering point of view.",
        "primary_area": "",
        "author": "Longchuan Li;Shugen Ma;Isao Tokuda;Yang Tian;Yiming Cao;Makoto Nokata;Zhiqing Li;Longchuan Li;Shugen Ma;Isao Tokuda;Yang Tian;Yiming Cao;Makoto Nokata;Zhiqing Li",
        "authorids": "/37086240920;/37280187400;/38241778000;/37085347588;/37089660657;/37325259400;/37597736000;/37086240920;/37280187400;/38241778000;/37085347588;/37089660657;/37325259400;/37597736000",
        "aff": "College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982001/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9199055174898489294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;0",
        "aff_unique_norm": "Beijing University of Chemical Technology;Ritsumeikan University",
        "aff_unique_dep": "College of Information Science and Technology;Graduate School of Science and Engineering",
        "aff_unique_url": "http://www.buct.edu.cn;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "BUCT;Ritsumeikan",
        "aff_campus_unique_index": "0;1;1;1;1;1;0",
        "aff_campus_unique": "Beijing;Kusatsu",
        "aff_country_unique_index": "0;1;1;1;1;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9981235",
        "title": "Enabling Massage Actions: An Interactive Parallel Robot with Compliant Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a parallel massage robot with compliant joints based on the series elastic actuator (SEA), offering a unified force-position control approach. First, the kinematic and static force models are established for obtaining the corresponding control variables. Then, a novel force-position control strategy is proposed to separately control the force-position along the normal direction of the surface and another two-direction displacement, without the requirement of a robotic dynamics model. To evaluate its performance, we implement a series of robotic massage experiments. The results demonstrate that the proposed massage manipulator can successfully achieve desired forces and motion patterns of massage tasks, arriving at a high-score user experience.",
        "primary_area": "",
        "author": "Huixu Dong;Yue Feng;Chen Qiu;Ye Pan;Miao He;I-Ming Chen;Huixu Dong;Yue Feng;Chen Qiu;Ye Pan;Miao He;I-Ming Chen",
        "authorids": "/37086340778;/37088556432;/37089110391;/37089660666;/37089664073;/37277668700;/37086340778;/37088556432;/37089110391;/37089660666;/37089664073;/37277668700",
        "aff": "Robot Perception and Grasp Lab, Zhejiang University, China; Robotics Research Center, Nanyang Technological University, Singapore; Maider Medical Industry Equipment Co., Itd, China; Shanghai Jiaotong University, China; Chongqing University of Technology, China; Robotics Research Center, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981235/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6253474008965596716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;4;1",
        "aff_unique_norm": "Zhejiang University;Nanyang Technological University;Maider Medical Industry Equipment Co.;Shanghai Jiao Tong University;Chongqing University of Technology",
        "aff_unique_dep": "Robot Perception and Grasp Lab;Robotics Research Center;;;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.ntu.edu.sg;;https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "ZJU;NTU;;SJTU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9981712",
        "title": "End-Point Stiffness and Joint Viscosity Control of Musculoskeletal Robotic Arm Using Muscle Redundancy",
        "track": "main",
        "status": "Poster",
        "abstract": "This study focuses on replicating the muscu-loskeletal system of human arms for mimicking its movement. Muscle redundancy is critical for regulating the mechanical impedance of arms and legs. However, when implementing muscle redundancy on robots, making an ill-posed problem that cannot determine the muscle forces uniquely. In this paper, first, a method for controlling end-point stiffness in the muscle space for the joint and muscle redundant system is described. Next, the muscle model imitating the nonlinear viscosity characteristic of human muscles is introduced. Then, a method to control the joint viscosity by adjusting the internal forces of muscles adequately without affecting the stiffness control directly is proposed. Finally, numerical simulations are performed to investigate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Shoki Tsuboi;Hitoshi Kino;Kenji Tahara;Shoki Tsuboi;Hitoshi Kino;Kenji Tahara",
        "authorids": "/37089661734;/37319633200;/37542756300;/37089661734;/37319633200;/37542756300",
        "aff": "Department of Mechanial Engineering, Faculty of Engineering, Kyushu University, Fukuoka, Japan; Department of Mechanical and Systems Engineering, School of Engineering, Chukyo University; Department of Mechanial Engineering, Faculty of Engineering, Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981712/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10552589129270574503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Kyushu University;Chukyo University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Systems Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.chukyo-u.ac.jp",
        "aff_unique_abbr": "Kyushu U;Chukyo U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fukuoka;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981882",
        "title": "End-to-End Feature Decontaminated Network for UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Object feature pollution is one of the burning issues in vision-based UAV tracking, commonly caused by occlusion, fast motion, and illumination variation. Due to the contaminated information in the polluted object features, most trackers fail to precisely estimate the object location and scale. To address the above disturbing issue, this work proposes a novel end-to-end feature decontaminated network for efficient and effective UAV tracking, i.e., FDNT. FDNT mainly includes two modules: a decontaminated downsampling network and a decontaminated upsampling network. The former reduces the interference information of the feature pollution and enhanced the expression of the object location information with two asymmetric convolution branches. The latter restores the object scale information with the super-resolution technology-based low-to-high encoder, achieving a further decontamination effect. Moreover, a novel pooling distance loss is carefully developed to assist the decontaminated downsampling network in concentrating on the critical regions with the object information. Exhaustive experiments on three well-known benchmarks validate the effectiveness of FDNT, especially on the sequences with feature pollution. In addition, real-world tests show the efficiency of FDNT with 31.4 frames per second. The code and demo videos are available at https://github.com/vision4robotics/FDNT.",
        "primary_area": "",
        "author": "Haobo Zuo;Changhong Fu;Sihang Li;Junjie Ye;Guangze Zheng;Haobo Zuo;Changhong Fu;Sihang Li;Junjie Ye;Guangze Zheng",
        "authorids": "/37089661486;/37086797986;/37089451036;/37088917418;/37088996628;/37089661486;/37086797986;/37089451036;/37088917418;/37088996628",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981882/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13962620816678354920&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981285",
        "title": "Energy-Aware Planning-Scheduling for Autonomous Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an online planning-scheduling approach for battery-powered autonomous aerial robots. The approach consists of simultaneously planning a coverage path and scheduling onboard computational tasks. We further derive a novel variable coverage motion robust to air-borne constraints and an empirically motivated energy model. The model includes the energy contribution of the schedule based on an automatic computational energy modeling tool. Our experiments show how an initial flight plan is adjusted online as a function of the available battery, accounting for uncertainty. Our approach remedies possible in-flight failure in case of unexpected battery drops, e.g., due to adverse atmospheric conditions, and increases the overall fault tolerance.",
        "primary_area": "",
        "author": "Adam Seewald;H\u00e9ctor Garc\u00eda de Marina;Henrik Skov Midtiby;Ulrik Pagh Schultz;Adam Seewald;H\u00e9ctor Garc\u00eda de Marina;Henrik Skov Midtiby;Ulrik Pagh Schultz",
        "authorids": "/37088596945;/38277848100;/37088597426;/37545488500;/37088596945;/38277848100;/37088597426;/37545488500",
        "aff": "Department of Mechanical Engineering and Materials Science, Yale University, CT, USA; Department of Computer Engineering, Automation, and Robotics, CITIC, University of Granada, Spain; SDU UAS, University of Southern Denmark; SDU UAS, University of Southern Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981285/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10707520342587528318&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Yale University;University of Granada;University of Southern Denmark",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science;Department of Computer Engineering, Automation, and Robotics;SDU UAS",
        "aff_unique_url": "https://www.yale.edu;https://www.ugr.es;https://www.sdu.dk",
        "aff_unique_abbr": "Yale;UGr;SDU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New Haven;",
        "aff_country_unique_index": "0;1;2;2",
        "aff_country_unique": "United States;Spain;Denmark"
    },
    {
        "id": "9981818",
        "title": "Energy-efficient Orienteering Problem in the Presence of Ocean Currents",
        "track": "main",
        "status": "Poster",
        "abstract": "In many environmental monitoring applications robots are often tasked to visit various distinct locations to make observations and/or collect specific measurements. The problem of scheduling and assigning robots to the various tasks and planning feasible paths for the robots can be posed as an Orienteering Problem (OP). In the standard OP, routing and scheduling is achieved by maximizing an objective function by visiting the most rewarding locations while respecting a limited travel budget. However, traditional formulations for such problems usually neglect some environmental features that can greatly impact the tour, e.g., flows, such as wind or ocean currents. This is of particular importance for applications in marine and atmospheric environments where vehicle motions can be significantly impacted by the environmental dynamics and the environment exerts a non-negligible force on the vehicles. In this paper, we tackle the OP in fluid environments where robots must operate in the presence of ocean and/or atmospheric currents. We introduce a novel multi-objective formulation that combines both task and path planning problems, and whose goals are to (i) maximize the collected reward, while (ii) minimizing the energy expenditure by leveraging the environmental dynamics wherever possible. We validate our strategy using simulated ocean model data to show that our approach can generate a diverse set of solutions that have an adequate compromise between both objectives.",
        "primary_area": "",
        "author": "Ariella Mansfield;Douglas G. Macharet;M. Ani Hsieh;Ariella Mansfield;Douglas G. Macharet;M. Ani Hsieh",
        "authorids": "/37088688381;/37590114800;/38238444800;/37088688381;/37590114800;/38238444800",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, USA; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil; GRASP Laboratory, University of Pennsylvania, Philadelphia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981818/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9562842649762964847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Universidade Federal de Minas Gerais",
        "aff_unique_dep": "GRASP Laboratory;Department of Computer Science",
        "aff_unique_url": "https://www.upenn.edu;http://www.ufmg.br",
        "aff_unique_abbr": "UPenn;UFMG",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Philadelphia;MG",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "9981704",
        "title": "Energy-efficient tunable-stiffness soft robots using second moment of area actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "The optimal stiffness for soft swimming robots depends on swimming speed, which means no single stiffness can maximise efficiency in all swimming conditions. Tunable-stiffness would produce an increased range of high-efficiency swimming speeds for robots with flexible propulsors and enable soft control surfaces for steering underwater vehicles. We propose and demonstrate a method for tunable soft robotic stiffness using inflatable rubber tubes to stiffen a silicone foil through pressure and second moment of area change. We achieved double the effective stiffness of the system for an input pressure change from 0 to 0.8 bar and 2 J energy input. We achieved a resonant amplitude gain of 5 to 7 times the input amplitude and tripled the high-gain frequency range compared to a foil with fixed stiffness. These results show that changing second moment of area is an energy effective approach to tunable-stiffness robots.",
        "primary_area": "",
        "author": "L. Micklem;G.D. Weymouth;B. Thornton;L. Micklem;G.D. Weymouth;B. Thornton",
        "authorids": "/37089661994;/37299297000;/37548786900;/37089661994;/37299297000;/37548786900",
        "aff": "Southampton Marine and Maritime Institute, University of Southampton, UK; Alan Turing Institute, London, UK; Institute of Industrial Science, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981704/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16853939529939198015&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Southampton;Alan Turing Institute;University of Tokyo",
        "aff_unique_dep": "Southampton Marine and Maritime Institute;;Institute of Industrial Science",
        "aff_unique_url": "https://www.southampton.ac.uk;https://www.turing.ac.uk;https://www.iis.u-tokyo.ac.jp",
        "aff_unique_abbr": "UoS;ATI;UTokyo",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Southampton;London;Tokyo",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;Japan"
    },
    {
        "id": "9981643",
        "title": "Enforcing Vision-Based Localization using Perception Constrained N-MPC for Multi-Rotor Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This work introduces a Nonlinear Model Predictive Control (N-MPC) for camera-equipped Unmanned Aerial Vehicles (UAVs), which controls at the motor level the UAV motion to ensure the quality of vision-based state estimation while performing other tasks. The controller ensures visibility over a sufficient amount of features, while optimizing their coverage, based on an assessment of the estimation quality. The controller works for the very broad class of generic multirotor UAVs, including platforms with any number of propellers, which can be both collinear, as in the quadrotor, and fixedly-tilted. The low-level inputs are computed in real-time and realistically constrained, in terms of maximum motor torque. This allows the platform to exploit its full actuation capabilities to maintain the visibility over the set of points of interest. Our implementation is tested in Gazebo simulations and in mocap-free real experiments, and features a visual-inertial state estimation based on Kalman filter. The software is provided open-source.",
        "primary_area": "",
        "author": "Martin Jacquet;Antonio Franchi;Martin Jacquet;Antonio Franchi",
        "authorids": "/37088506435;/37541446900;/37088506435;/37541446900",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981643/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11543345441812475750&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "LAAS-CNRS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981674",
        "title": "Enhanced Quadruped Locomotion of a Rat Robot Based on the Lateral Flexion of a Soft Actuated Spine",
        "track": "main",
        "status": "Poster",
        "abstract": "In nature, the movement of quadrupeds is completed under the combined action of the spine and the legs. Inspired by this, this paper explores the effect of a lateral flexing spine on the locomotion of a rat robot. Benefiting from the regular lateral flexion of a soft actuated spine, the rat robot exhibits enhance step length of its hind legs and increased translational velocity by coordinating the opposite movements of the left and right sides. Furthermore, this paper introduces a mathematical model of the effect of the flexible spine on the robot velocity. Finally, extensive experiments are conducted in simulations and on the physical rat robot. Compared with the locomotion without a flexing spine, the simulation results show that the velocity of the robot can be increased up to 218.29%, which is in line with the theoretical results from the proposed mathematical model. Limited by the gap between simulation and the real world, the experiment results of the physical rat robot show a slight performance than the theoretical results. But the physical rat robot can still enhance its translational velocity with the help of a lateral flexing spine.",
        "primary_area": "",
        "author": "Yuhong Huang;Zhenshan Bing;Florian Walter;Alex Rohregger;Zitao Zhang;Kai Huang;Fabrice O. Morin;Alois Knoll;Yuhong Huang;Zhenshan Bing;Florian Walter;Alex Rohregger;Zitao Zhang;Kai Huang;Fabrice O. Morin;Alois Knoll",
        "authorids": "/37086357051;/37085994830;/37086029750;/37089658323;/37089617791;/37534912900;/37089373727;/37276234100;/37086357051;/37085994830;/37086029750;/37089658323;/37089617791;/37534912900;/37089373727;/37276234100",
        "aff": "Technical University of Munich, Munich, German; Technical University of Munich, Munich, German; Technical University of Munich, Munich, German; Technical University of Munich, Munich, German; Sun Yat-Sen University, Guangdong, China; Sun Yat-Sen University, Guangdong, China; Technical University of Munich, Munich, German; Technical University of Munich, Munich, German",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981674/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17875864759779820454&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;0;0",
        "aff_unique_norm": "Technical University of Munich;Sun Yat-sen University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tum.de;http://www.sysu.edu.cn/",
        "aff_unique_abbr": "TUM;SYSU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;0;1;1;0;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9981446",
        "title": "Ensemble Based Anomaly Detection for Legged Robots to Explore Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploring unknown environments, such as caves or planetary surfaces, requires a quick understanding of the surroundings. Beforehand, only aerial footage from satellites or images from previous missions might be available. The proposed ensemble based anomaly detection framework utilizes previously gained knowledge and incorporates it with insights gained during the mission. The modular system consists of different networks which are combined to determine anomalies in the current surroundings. By utilizing data from other missions, simulations or aerial photos, a precise anomaly detection can be achieved at the start of a mission. The system can further be improved by training new networks during the mission, which can be incorporated into the ensemble at runtime. This allows for synchronous execution of mission and training of models on a base station. The proposed system is tested and evaluated on an ANYmal C walking robot in different scenarios, however the approach is applicable for different kinds of mobile robots. The results show a clear improvement of ensembles compared to individual networks, while keeping a small memory footprint and low inference time on the mobile system.",
        "primary_area": "",
        "author": "Lennart Puck;Maximilian Schik;Tristan Schnell;Timothee Buettner;Arne Roennau;R\u00fcdiger Dillmann;Lennart Puck;Maximilian Schik;Tristan Schnell;Timothee Buettner;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37087012686;/37089660781;/37087011877;/37086158340;/37590849800;/37280242100;/37087012686;/37089660781;/37087011877;/37086158340;/37590849800;/37280242100",
        "aff": "Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981446/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13382359433212520272&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "FZI Research Center for Information Technology",
        "aff_unique_dep": "Department of Interactive Diagnosis and Service Systems (IDS)",
        "aff_unique_url": "https://www.fzi.de",
        "aff_unique_abbr": "FZI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981160",
        "title": "Estimation of Soft Robotic Bladder Compression for Smart Helmets using IR Range Finding and Hall Effect Magnetic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "This research focuses on soft robotic bladders that are used to monitor and control the interaction between a user's head and the shell of a Smart Helmet. Compression of these bladders determines impact dissipation; hence the focus of this paper is sensing and estimation of bladder compression. An IR rangefinder-based solution is evaluated using regression techniques as well as a Neural Network to estimate bladder compression. A Hall-Effect (HE) magnetic sensing system is also examined where HE sensors embedded in the base of the bladder sense the position of a magnet in the top of the bladder. The paper presents the HE sensor array, signal processing of HE voltage data, and then a Neural Network (NN) for predicting bladder compression. Efficacy of different training data sets on NN performance is studied. Different NN configurations are examined to determine a configuration that provides accurate estimates with as few nodes as possible. Different bladder compression profiles are evaluated to characterize IR range finding and HE based techniques in application scenarios.",
        "primary_area": "",
        "author": "Colin Pollard;Jon Aston;Mark A. Minor;Colin Pollard;Jon Aston;Mark A. Minor",
        "authorids": "/37089661539;/37088483850;/37279831800;/37089661539;/37088483850;/37279831800",
        "aff": "University of Utah, SaltLake City, UT, USA; University of Utah, SaltLake City, UT, USA; University of Utah, SaltLake City, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981160/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rsX-MO5AewEJ:scholar.google.com/&scioq=Estimation+of+Soft+Robotic+Bladder+Compression+for+Smart+Helmets+using+IR+Range+Finding+and+Hall+Effect+Magnetic+Sensing&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Salt Lake City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981334",
        "title": "Evaluating Human-like Explanations for Robot Actions in Reinforcement Learning Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Explainable artificial intelligence is a research field that tries to provide more transparency for autonomous intelligent systems. Explainability has been used, particularly in reinforcement learning and robotic scenarios, to better understand the robot decision-making process. Previous work, however, has been widely focused on providing technical explanations that can be better understood by AI practitioners than non-expert end-users. In this work, we make use of human-like explanations built from the probability of success to complete the goal that an autonomous robot shows after performing an action. These explanations are intended to be understood by people who have no or very little experience with artificial intelligence methods. This paper presents a user trial to study whether these explanations that focus on the probability an action has of succeeding in its goal constitute a suitable explanation for non-expert end-users. The results obtained show that non-expert participants rate robot explanations that focus on the probability of success higher and with less variance than technical explanations generated from Q-values, and also favor counterfactual explanations over standalone explanations.",
        "primary_area": "",
        "author": "Francisco Cruz;Charlotte Young;Richard Dazeley;Peter Vamplew;Francisco Cruz;Charlotte Young;Richard Dazeley;Peter Vamplew",
        "authorids": "/37085344103;/37089659682;/37594377400;/37086162450;/37085344103;/37089659682;/37594377400;/37086162450",
        "aff": "Escuela de Ingenier\u00eda, Universidad Central de Chile, Santiago, Chile; School of Engineering, IT and Physical Sciences, Federation University, Ballarat, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Engineering, IT and Physical Sciences, Federation University, Ballarat, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981334/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=408794316060968363&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Universidad Central de Chile;Federation University;Deakin University",
        "aff_unique_dep": "Escuela de Ingenier\u00eda;School of Engineering, IT and Physical Sciences;School of Information Technology",
        "aff_unique_url": "https://www.uchile.cl;https://www.federation.edu.au;https://www.deakin.edu.au",
        "aff_unique_abbr": "UCH;;Deakin",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Santiago;Ballarat;Geelong",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Chile;Australia"
    },
    {
        "id": "9982072",
        "title": "Evaluating the Benefit of Using Multiple Low-Cost Forward-Looking Sonar Beams for Collision Avoidance in Small AUVs",
        "track": "main",
        "status": "Poster",
        "abstract": "We seek to rigorously evaluate the benefit of using a few beams rather than a single beam for a low-cost obstacle avoidance sonar for small AUVs. For a small low-cost AUV, the complexity, cost, and volume required for a multi-beam forward looking sonar are prohibitive. In contrast, a single-beam system is relatively easy to integrate into a small AUV, but does not provide the performance of a multi-beam solution. To better understand this trade-off, we seek to rigorously quantify the improvement with respect to obstacle avoidance performance of adding just a few beams to a single-beam forward looking sonar relative to the performance of the single-beam system. Our work fundamentally supports the goal of using small low-cost AUV systems in cluttered and unstructured environments. Specifically, we investigate the benefit of incorporating a port and starboard beam to a single-beam sonar system for collision avoidance. A methodology for collision avoidance is developed to obtain a fair comparison between a single-beam and multi-beam system, explicitly incorporating the geometry of the beam patterns from forward-looking sonars with large beam angles, and simulated using a high-fidelity representation of acoustic signal propagation.",
        "primary_area": "",
        "author": "Christopher Morency;Daniel J. Stilwell;Christopher Morency;Daniel J. Stilwell",
        "authorids": "/37087243028;/37283170000;/37087243028;/37283170000",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982072/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18148832957771332643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981490",
        "title": "Evaluation of On-Robot Capacitive Proximity Sensors with Collision Experiments for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot must comply with very restrictive safety standards in close human-robot collaboration applications. These standards limit the robot's performance because of speed reductions to avoid potentially large forces exerted on humans during collisions. On-robot capacitive proximity sensors (CPS) can serve as a solution to allow higher speeds and thus better productivity. They allow early reactive measures before contacts occur to reduce the forces during collisions. An open question on designing the systems is the selection of an adequate activation distance to trigger safety measures for a specific robot while considering latency and detection robustness. Furthermore, the systems' actual effectiveness of impact attenuation and performance gain has not been evaluated before. In this work, we define and conduct a unified test procedure based on collision experiments to determine these parameters and investigate the performance gain. Two capacitive proximity sensor systems are evaluated on this test strategy on two robots. A significant performance increase can be achieved, since a small detection distance doubles robot operation speed while maintaining the same contact force as without Capacitive Proximity Sensor (CPS). This work can serve as a reference guide for designing, configuring and implementing future on-robot CPS.",
        "primary_area": "",
        "author": "Hosam Alagi;Serkan Ergun;Yitao Ding;Tom P. Huck;Ulrike Thomas;Hubert Zangl;Bj\u00f6rn Hein;Hosam Alagi;Serkan Ergun;Yitao Ding;Tom P. Huck;Ulrike Thomas;Hubert Zangl;Bj\u00f6rn Hein",
        "authorids": "/38666348400;/37089000883;/37086576023;/37088590233;/37281523200;/37273010900;/37604448500;/38666348400;/37089000883;/37086576023;/37088590233;/37281523200;/37273010900;/37604448500",
        "aff": "Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Klagenfurt University (AAU), Institute of Smart Systems Technologies (SST), Klagenfurt am W\u00f6rthersee, Austria; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology (TUC), Chemnitz, Germany; Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology (TUC), Chemnitz, Germany; Klagenfurt University (AAU), Institute of Smart Systems Technologies (SST), Klagenfurt am W\u00f6rthersee, Austria; Karlsruhe University of Applied Sciences",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981490/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17679316471293350461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;2;1;3",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Klagenfurt University;Chemnitz University of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;Institute of Smart Systems Technologies;Lab of Robotics and Human-Machine-Interaction;",
        "aff_unique_url": "https://www.kit.edu;https://www.aau.at;https://www.tu-chemnitz.de;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;AAU;TUC;HsKA",
        "aff_campus_unique_index": "0;1;2;0;2;1",
        "aff_campus_unique": "Karlsruhe;Klagenfurt am W\u00f6rthersee;Chemnitz;",
        "aff_country_unique_index": "0;1;0;0;0;1;0",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "9982124",
        "title": "Evaluation of position-keeping strategies for symmetrically-shaped autonomous water-surface robots under disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "Extensive research has been conducted on autonomous surface robots and underwater robots for various tasks in aquatic environments. The duration of the operation of autonomous field robots depends on the capacity of the mounted battery, as they are not typically connected to an external power supply. Therefore, smart strategies which are optimized for each task are required to extend the working time of autonomous field robots. We have developed a symmetrically-shaped au-tonomous surface robot for the long-term monitoring of water quality. In this study, we propose position-keeping strategies to prolong the duration of the symmetrically-shaped surface robot for in-situ monitoring. The proposed position-keeping strategies are evaluated in terms of the power consumption and mean error distance in both practical and simulation environments. The experimental results demonstrate that a robot placed on a water surface with disturbance determines the best course of action to maintain its position based on the environmental conditions and application.",
        "primary_area": "",
        "author": "Yasuyuki Fujii;Dinh Tuan Tran;Joo-Ho Lee;Yasuyuki Fujii;Dinh Tuan Tran;Joo-Ho Lee",
        "authorids": "/37086687715;/38236147000;/37089611788;/37086687715;/38236147000;/37089611788",
        "aff": "Graduate School of Information Science and Engineering, Ritsumeikan University, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982124/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11570441304415052733&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Graduate School of Information Science and Engineering",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981971",
        "title": "Examining Distance in UAV Gesture Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles (UAVs) are becoming more common, presenting the need for effective human-robot communication strategies that address the unique nature of unmanned aerial flight. Visual communication via drone flight paths, also called gestures, may prove to be an ideal method. However, the effectiveness of visual communication techniques is dependent on several factors including an observer's position relative to a UAV. Previous work has studied the maximum line-of-sight at which observers can identify a small UAV [1]. However, this work did not consider how changes in distance may affect an observer's ability to perceive the shape of a UAV's motion. In this study, we conduct a series of online surveys to evaluate how changes in line-of-sight distance and gesture size affect observers' ability to identify and distinguish between UAV gestures. We first examine observers' ability to accurately identify gestures when adjusting a gesture's size relative to the size of a UAV. We then measure how observers' ability to identify gestures changes with respect to varying line-of-sight distances. Lastly, we consider how altering the size of a UAV gesture may improve an observer's ability to identify drone gestures from varying distances. Our results show that increasing the gesture size across varying UAV to gesture ratios did not have a significant effect on participant response accuracy. We found that between 17 m and 75 m from the observer, their ability to accurately identify a drone gesture was inversely proportional to the distance between the observer and the drone. Finally, we found that maintaining a gesture's apparent size improves participant response accuracy over changing line-of-sight distances.",
        "primary_area": "",
        "author": "Karissa Jelonek;Paul Fletcher;Brittany Duncan;Carrick Detweiler;Karissa Jelonek;Paul Fletcher;Brittany Duncan;Carrick Detweiler",
        "authorids": "/37089658455;/37089000102;/37408070300;/38535355300;/37089658455;/37089000102;/37408070300;/38535355300",
        "aff": "NIMBUS Lab in the School of Computing, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the School of Computing, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the School of Computing, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the School of Computing, University of Nebraska, Lincoln, NE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981971/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9604276728865623075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Nebraska",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.unl.edu",
        "aff_unique_abbr": "UNL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lincoln",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981537",
        "title": "Excavation of Fragmented Rocks with Multi-modal Model-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a multi-modal model-based reinforcement learning (MBRL) approach to the excavation of fragmented rocks, which are very challenging to model due to their highly variable sizes and geometries, and visual occlusions. A multi-modal recurrent neural network (RNN) learns the dynamics of bucket-terrain interaction from a small physical dataset, with a discrete set of motion primitives encoded with domain knowledge as the action space. Then a model predictive controller (MPC) tracks a global reference path using multi-modal feedback. We show that our RNN-based dynamics function achieves lower prediction errors compared to a feed-forward neural network baseline, and the MPC is able to significantly outperform manually designed strategies on such a challenging task.",
        "primary_area": "",
        "author": "Yifan Zhu;Liyang Wang;Liangjun Zhang;Yifan Zhu;Liyang Wang;Liangjun Zhang",
        "authorids": "/37088507100;/37089516532;/37088642847;/37088507100;/37089516532;/37088642847",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Baidu Research, Sunnyvale, CA, USA; Robotics and Auto-Driving Lab, Baidu Research, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981537/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6229386626276967064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Baidu",
        "aff_unique_dep": "Department of Computer Science;Research",
        "aff_unique_url": "https://illinois.edu;https://research.baidu.com",
        "aff_unique_abbr": "UIUC;Baidu Res.",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Urbana-Champaign;Sunnyvale",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982128",
        "title": "Experimental Assessment of a Control Strategy for Locomotion Assistance Relying on Simplified Motor Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower-limb exoskeletons are robotic devices that can provide assistance to human locomotion. Since they are expected to be used in ecological environments, their control strategy should handle different kinds of daily-life situations. Taking inspiration from the human neuromuscular system - and particularly from the socalled motor primitives - may help in adapting the type of delivered assistance to different locomotion tasks. In this work, we validated the combination of simplified primitives and a musculoskeletal model for assisting healthy subjects with a hip exoskeleton. This framework showed adaptation to the user's gait for different slope inclinations, although its effects on the subject's speed and their perceived effort showed no significant improvement compared to wearing the device in transparent mode.",
        "primary_area": "",
        "author": "Henri Laloyaux;Clara Beatriz Sanz-Mor\u00e8re;Chiara Livolsi;Andrea Pergolini;Simona Crea;Nicola Vitiello;Renaud Ronsse;Henri Laloyaux;Clara Beatriz Sanz-Mor\u00e8re;Chiara Livolsi;Andrea Pergolini;Simona Crea;Nicola Vitiello;Renaud Ronsse",
        "authorids": "/37088420572;/37086478663;/37088535286;/37088533356;/38557457700;/38506597800;/37299789300;/37088420572;/37086478663;/37088535286;/37088533356;/38557457700;/38506597800;/37299789300",
        "aff": "Institute of Mechanics Materials, and Civil Engineering (iMMC), the Institute of NeuroScience (IoNS) and the Louvain Bionics of UCLouvain, Louvain-la-Neuve, Belgium; The Department of Excellence in Robotics and AI Scuola Superiore Sant'Anna, BioRobotics Institute, Pisa, Italy; The Department of Excellence in Robotics and AI Scuola Superiore Sant'Anna, BioRobotics Institute, Pisa, Italy; The Department of Excellence in Robotics and AI Scuola Superiore Sant'Anna, BioRobotics Institute, Pisa, Italy; IUVO S.r.l., the company that owns the IP rights of the APO technology; IUVO S.r.l., the company that owns the IP rights of the APO technology; Institute of Mechanics Materials, and Civil Engineering (iMMC), the Institute of NeuroScience (IoNS) and the Louvain Bionics of UCLouvain, Louvain-la-Neuve, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982128/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3957774634016496045&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;2;2;0",
        "aff_unique_norm": "UCLouvain;Scuola Superiore Sant'Anna;IUVO S.r.l.",
        "aff_unique_dep": "Institute of Mechanics Materials, and Civil Engineering;Department of Excellence in Robotics and AI, BioRobotics Institute;",
        "aff_unique_url": "https://www.uclouvain.be;https://www.sssup.it;",
        "aff_unique_abbr": "UCL;SSSUP;",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Louvain-la-Neuve;Pisa;",
        "aff_country_unique_index": "0;1;1;1;1;1;0",
        "aff_country_unique": "Belgium;Italy"
    },
    {
        "id": "9981380",
        "title": "Experimental Demonstration of a General Balancing Controller on an Untethered Planar Inverted Double Pendulum",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper demonstrates the practical performance of a new theory of balance control that has been shown in simulation to out-perform earlier balance control theories in the sense of allowing the robot to make larger and faster movements while still maintaining its balance. The case studied here is that of a general planar double inverted pendulum, which resembles a legged robot's behaviour when the polygon of support shrinks to a line. The results show the speed and accuracy of the controller, as well as its robustness to external disturbances and slipping during fast movements.",
        "primary_area": "",
        "author": "Federico Allione;Antonios E. Gkikakis;Roy Featherstone;Federico Allione;Antonios E. Gkikakis;Roy Featherstone",
        "authorids": "/37089224208;/37086576113;/37449492400;/37089224208;/37086576113;/37449492400",
        "aff": "Department of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981380/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5026086146654770658&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS);Department of Advanced Robotics",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981130",
        "title": "Experimental Study on Impact Resistance of Multi-DOF Electro-Hydrostatic Robot Systems Using Hydracer, a 6DOF Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial robots require force controllability and impact resistance to ensure safe physical interactions. An electro-hydrostaic actuator (EHA) is expected to be suitable for such applications because it has high backdrivability which improve both force controllability at contact and impact resistance. However, EHAs had been rarely used in multi-axes robotic systems. The previous works validated the force controllability of the EHA-driven robot Hydra. However, the impact resistance of an EHA-driven robot is still unclear. In order to evaluate the impact resistance of the high-power EHA-driven robot, we developed high-pressure EHAs employing ceramics as rigid material to reduce internal leakage, and developed the EHA-driven 6-DOF robot arm Hydracer as the platform for the evaluation. This paper describes the mechanism of Hydracer especially on the base 3-DOF mechanism, and conducts the backdrivability measurement and the impact resistance evaluation.",
        "primary_area": "",
        "author": "Mitsuo Komagata;Yutaro Imashiro;Ryoya Suzuki;Kento Oishi;Ko Yamamoto;Yoshihiko Nakamura;Mitsuo Komagata;Yutaro Imashiro;Ryoya Suzuki;Kento Oishi;Ko Yamamoto;Yoshihiko Nakamura",
        "authorids": "/37086185509;/37088947101;/37089663375;/37089659548;/37536641800;/37280754600;/37086185509;/37088947101;/37089663375;/37089659548;/37536641800;/37280754600",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-Ku, Tokyo; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-Ku, Tokyo; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-Ku, Tokyo; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-Ku, Tokyo; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-Ku, Tokyo; RACE, Graduate School of Engineering, The University of Tokyo, Bunkyo-Ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981130/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14256581806458841312&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982104",
        "title": "Explainable Knowledge Graph Embedding: Inference Reconciliation for Knowledge Inferences Supporting Robot Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Learned knowledge graph representations supporting robots contain a wealth of domain knowledge that drives robot behavior. However, there does not exist an inference reconciliation framework that expresses how a knowledge graph representation affects a robot's sequential decision making. We use a pedagogical approach to explain the inferences of a learned, black-box knowledge graph representation, a knowledge graph embedding. Our interpretable model uses a decision tree classifier to locally approximate the predictions of the black-box model and provides natural language explanations interpretable by non-experts. Results from our algorithmic evaluation affirm our model design choices, and the results of our user studies with non-experts support the need for the proposed inference reconciliation framework. Critically, results from our simulated robot evaluation indicate that our explanations enable non-experts to correct erratic robot behaviors due to nonsensical beliefs within the black-box.",
        "primary_area": "",
        "author": "Angel Daruna;Devleena Das;Sonia Chernova;Angel Daruna;Devleena Das;Sonia Chernova",
        "authorids": "/37085616620;/37086608011;/37283184200;/37085616620;/37086608011;/37283184200",
        "aff": "Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982104/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11062908514356654623&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982080",
        "title": "Exploring mmWave Radar and Camera Fusion for High-Resolution and Long-Range Depth Imaging",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic geo-fencing and surveillance systems require accurate monitoring of objects if/when they violate perimeter restrictions. In this paper, we seek a solution for depth imaging of such objects of interest at high accuracy (few tens of cm) over extended ranges (up to 300 meters) from a single vantage point, such as a pole mounted platform. Unfortunately, the rich literature in depth imaging using camera, lidar and radar in isolation struggles to meet these tight requirements in real-world conditions. This paper proposes Metamoran, a solution that explores long-range depth imaging of objects of interest by fusing the strengths of two complementary technologies: mmWave radar and camera. Unlike cameras, mmWave radars offer excellent cm-scale depth resolution even at very long ranges. However, their angular resolution is at least 10x worse than camera systems. Fusing these two modalities is natural, but in scenes with high clutter and at long ranges, radar reflections are weak and experience spurious artifacts. Metamoran's core contribution is to leverage image segmentation and monocular depth estimation on camera images to help declutter radar and discover true object reflections. We perform a detailed evaluation of Metamoran's depth imaging capabilities in 400 diverse scenarios. Our evaluation shows that Metamoran estimates the depth of static objects up to 90 m away and moving objects up to 305 m away and with a median error of 28 cm, an improvement of 13 x over a naive radar+camera baseline and 23 x compared to monocular depth estimation.",
        "primary_area": "",
        "author": "Akarsh Prabhakara;Diana Zhang;Chao Li;Sirajum Munir;Aswin C. Sankaranarayanan;Anthony Rowe;Swarun Kumar;Akarsh Prabhakara;Diana Zhang;Chao Li;Sirajum Munir;Aswin C. Sankaranarayanan;Anthony Rowe;Swarun Kumar",
        "authorids": "/37089644683;/37086833759;/37089268497;/37650455600;/37355765800;/37324658900;/37085847897;/37089644683;/37086833759;/37089268497;/37650455600;/37355765800;/37324658900;/37085847897",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Bosch Research and Technology Center, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982080/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3919118229784280755&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Johns Hopkins University;Bosch Research and Technology Center",
        "aff_unique_dep": ";Applied Physics Laboratory;",
        "aff_unique_url": "https://www.cmu.edu;https://www.jhuapl.edu;https://www.bosch.com/research/",
        "aff_unique_abbr": "CMU;JHU APL;Bosch RTC",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh;Laurel",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981570",
        "title": "Extended Time Dependent Vehicle Routing Problem for Joint Task Allocation and Path Planning in Shared Space",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the joint task allocation and path planning problem whereby an operator with a fleet of vehicles must assign multiple tasks to each vehicle, while ensuring collision-free paths for them such that the total travel cost is minimized. Instead of sequentially solving the task allocation problem first, and then resolving all predicted collisions, i.e. conflicts between vehicles, we propose a novel method that solves in a simultaneous way task allocation and multi-agent path planning. Specifically, we introduce an extension of the Time Dependent Vehicle Routing Problem (TDVRP) whereby we propose to integrate conflicts information into a time dependent cost function used in the task allocation resolution. We compare our approach to two baseline approaches that both use a standard Capacitated VRP (CVRP) solver, a \u201cone-shot\u201d method and a \u201cmulti-shot\u201d method. We perform simulations on benchmark realistic warehouse scenarios and the obtained results show that our proposed approach is able to generate improvements in the solutions costs compared to the baseline approaches.",
        "primary_area": "",
        "author": "Aayush Aggarwal;Florence Ho;Shinji Nakadai;Aayush Aggarwal;Florence Ho;Shinji Nakadai",
        "authorids": "/37088686801;/37086639502;/37086612440;/37088686801;/37086639502;/37086612440",
        "aff": "Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Artificial Intelligence Research Center, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Artificial Intelligence Research Center, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981570/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17929963440680796908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "NEC Corporation;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Data Science Research Laboratories;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.nec.com;https://www.aist.go.jp",
        "aff_unique_abbr": "NEC;AIST",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982222",
        "title": "Extending extrapolation capabilities of probabilistic motion models learned from human demonstrations using shape-preserving virtual demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) requires methodologies able to generalize tasks in new situations. This paper studies the use of virtual demonstrations to extend the extrapolation capabilities of probabilistic motion models such as the traPPCA method. Similarly to other LfD methods, traPPCA is able to calculate new trajectories very fast, but does not generalize well outside the area covered by the demonstrations. Another approach, the invariants method, shows outstanding generalization capabilities thanks to its shape-preserving prop-erties, while being limited by long computation times. The pro-posed methodology combines the advantages of the two methods by learning traPPCA models using virtual demonstrations generated by the invariants method. The proposed approach is analyzed in three case studies. Furthermore, a comparison is made between learning with virtual demonstrations and learning with only real demonstrations. The results encourage the use of virtual demonstrations to extend the extrapolation capabilities of probabilistic motion models and hence reduce the required number of real demonstrations. The latter has the potential of reducing the cost of commissioning robot tasks.",
        "primary_area": "",
        "author": "Riccardo Burlizzi;Maxim Vochten;Joris De Schutter;Erwin Aertbeli\u00ebn;Riccardo Burlizzi;Maxim Vochten;Joris De Schutter;Erwin Aertbeli\u00ebn",
        "authorids": "/37089663496;/37085462227;/37283056500;/37449455800;/37089663496;/37085462227;/37283056500;/37449455800",
        "aff": "Department of Mechanical Engineering, KU Leuven & Flanders Make Core Lab ROB, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven & Flanders Make Core Lab ROB, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven & Flanders Make Core Lab ROB, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven & Flanders Make Core Lab ROB, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982222/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2449639248059862142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Leuven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9981529",
        "title": "External load estimation of hydraulically driven construction machinery from cylinder pressures and link accelerations",
        "track": "main",
        "status": "Poster",
        "abstract": "Remotely controlled hydraulically driven robots are expected to play an important role in extreme environments such as disaster sites, and force feedback is effective for improving the fidelity of the remote environment and the work efficiency. However, it is not reasonable to attach a force sensor directly to the end-point of a hydraulically driven robot. In a previous study, the authors showed that the impact forces, which are important information to improve the fidelity of the remote environment and work efficiency, can be estimated by using the information of acceleration of each link in addition to the cylinder pressures. In this paper, we investigated how many accelerometers and where those accelerometers should be attached on each link by using an index called GDOP (Geometric Dilution Of Precision) to improve the accuracy of impact force estimation. The experimental results show that although the estimation accuracy could not be improved significantly by rearranging the accelerometers, the effect of reducing the noise of the estimated load due to the sensor noise was confirmed.",
        "primary_area": "",
        "author": "Naotake Shimamura;Raita Katayama;Hikaru Nagano;Yuichi Tazaki;Yasuyoshi Yokokohji;Naotake Shimamura;Raita Katayama;Hikaru Nagano;Yuichi Tazaki;Yasuyoshi Yokokohji",
        "authorids": "/37089663876;/37088812209;/37711681800;/37540738600;/37273225800;/37089663876;/37088812209;/37711681800;/37540738600;/37273225800",
        "aff": "Department of Mechanical Engineering, Graduate School of Engineering, Kobe University, Kobe, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kobe University, Kobe, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kobe University, Kobe, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kobe University, Kobe, Japan; Department of Mechanical Engineering, Graduate School of Engineering, Kobe University, Kobe, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981529/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11068613205651006466&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Kobe University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kobe-u.ac.jp",
        "aff_unique_abbr": "Kobe U",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kobe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981482",
        "title": "Extrinsic Calibration of a 2D Laser Rangefinder and a Depth-camera Using an Orthogonal Trihedron",
        "track": "main",
        "status": "Poster",
        "abstract": "2D laser range-finders and depth-cameras are usually equipped on service robots. But there are rarely calibration methods of them. This paper proposes an extrinsic calibration method of a 2D laser range-finder and a depth-camera using an orthogonal trihedron. The trihedron with orthogonal assumptions is taken as a reference frame to roughly estimate the relative pose between the sensors by solving a perspective-three-point (P3P) problem and basis-to-basis correspondence. Then, the estimated relative pose is refined via non-linear optimization based on line-to-plane constraints. Unlike other works which require enough motion, only one-shot observation is required, and it is insensitive to sensor ranging noise and the manufacturing errors of calibration targets. Verified by simulation and real experiments, the proposed method is simple, effective and accurate.",
        "primary_area": "",
        "author": "Zhengbin Li;Haiqing Dong;Dong Liu;Yabin Ding;Zhengbin Li;Haiqing Dong;Dong Liu;Yabin Ding",
        "authorids": "/37089664075;/37089660117;/37089662903;/37088267236;/37089664075;/37089660117;/37089662903;/37088267236",
        "aff": "Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, China; AIIC of Midea Group (Shanghai) Co.,Ltd, Shanghai, China; AIIC of Midea Group (Shanghai) Co.,Ltd, Shanghai, China; Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981482/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9122823661413889084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Tianjin University;Midea Group",
        "aff_unique_dep": "Key Laboratory of Mechanism Theory and Equipment Design;AIIC",
        "aff_unique_url": "http://www.tju.edu.cn;",
        "aff_unique_abbr": "Tianjin University;Midea",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Tianjin;Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981569",
        "title": "Extrinsic Dexterous Manipulation with a Direct-drive Hand: A Case Study",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores a novel approach to dexterous manipulation, aimed at levels of speed, precision, robustness, and simplicity suitable for practical deployment. The enabling technology is a Direct-drive Hand (DDHand) comprising two fingers, two DOFs each, that exhibit high speed and a light touch. The test application is the dexterous manipulation of three small and irregular parts, moving them to a grasp suitable for a subsequent assembly operation, regardless of initial presentation. We employed four primitive behaviors that use ground contact as a \u201cthird finger\u201d, prior to or during the grasp process: pushing, pivoting, toppling, and squeeze-grasping. In our experiments, each part was presented from 30 to 90 times randomly positioned in each stable pose. Success rates varied from 83% to 100%. The time to manipulate and grasp was 6.32 seconds on average, varying from 2.07 to 16 seconds. In some cases, performance was robust, precise, and fast enough for practical applications, but in other cases, pose uncertainty required time-consuming vision and arm motions. The paper concludes with a discussion of further improvements required to make the primitives robust, eliminate uncertainty, and reduce this dependence on vision and arm motion.",
        "primary_area": "",
        "author": "Arnav Gupta;Yuemin Mao;Ankit Bhatia;Xianyi Cheng;Jonathan King;Yifan Hou;Matthew T. Mason;Arnav Gupta;Yuemin Mao;Ankit Bhatia;Xianyi Cheng;Jonathan King;Yifan Hou;Matthew T. Mason",
        "authorids": "/37089663678;/37089660743;/37085416761;/37086574792;/37085468448;/37086454260;/37273994200;/37089663678;/37089660743;/37085416761;/37086574792;/37085468448;/37086454260;/37273994200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Berkshire Grey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981569/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11183182210438634719&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Carnegie Mellon University;Berkshire Grey",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.berkshiregrey.com",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981574",
        "title": "FAR Planner: Fast, Attemptable Route Planner using Dynamic Visibility Update",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning in unknown environments remains a challenging problem, as the environment is gradually observed during the navigation, the underlying planner has to update the environment representation and replan, promptly and constantly, to account for the new observations. In this paper, we present a visibility graph-based planning framework capable of dealing with navigation tasks in both known and unknown environments. The planner employs a polygonal representation of the environment and constructs the representation by extracting edge points around obstacles to form enclosed polygons. With that, the method dynamically updates a global visibility graph using a two-layered data structure, expanding the visibility edges along with the navigation, and removing edges that become occluded by newly observed obstacles. When navigating in unknown environments, the method is attemptable in discovering a way to the goal by picking up the environment layout on the fly, updating the visibility graph, and fast replanning corresponding to the newly observed environment. We evaluate the method in simulated and real-world settings. The method shows the capability to attempt and navigate through unknown environments, reducing travel time by up to 12-47% from search-based methods: A*, D* Lite, and more than 24-35% from sampling-based methods: RRT*, BIT*, and SPARS.",
        "primary_area": "",
        "author": "Fan Yang;Chao Cao;Hongbiao Zhu;Jean Oh;Ji Zhang;Fan Yang;Chao Cao;Hongbiao Zhu;Jean Oh;Ji Zhang",
        "authorids": "/37089448792;/37086934694;/37086564449;/37933996900;/38541910000;/37089448792;/37086934694;/37086564449;/37933996900;/38541910000",
        "aff": "CMU Robotics Institute; CMU Robotics Institute; CMU Robotics Institute; CMU Robotics Institute; CMU Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981574/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1647240734440143615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981107",
        "title": "FAST-LIVO: Fast and Tightly-coupled Sparse-Direct LiDAR-Inertial-Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve accurate and robust pose estimation in Simultaneous Localization and Mapping (SLAM) task, multisensor fusion is proven to be an effective solution and thus provides great potential in robotic applications. This paper proposes FAST-LIVO, a fast LiDAR-Inertial-Visual Odometry system, which builds on two tightly-coupled and direct odometry subsystems: a VIO subsystem and a LIO subsystem. The LIO subsystem registers raw points (instead of feature points on e.g., edges or planes) of a new scan to an incrementally-built point cloud map. The map points are additionally attached with image patches, which are then used in the VIO subsystem to align a new image by minimizing the direct photometric errors without extracting any visual features (e.g., ORB or FAST corner features). To further improve the VIO robustness and accuracy, a novel outlier rejection method is proposed to reject unstable map points that lie on edges or are occluded in the image view. Experiments on both open data sequences and our customized device data are conducted. The results show our proposed system outperforms other counterparts and can handle challenging environments at reduced computation cost. The system supports both multi-line spinning LiDARs and emerging solid-state LiDARs with completely different scanning patterns, and can run in real-time on both Intel and ARM processors. We open source our code and dataset of this work on Github22https://github.com/hku-mars/FAST-LIVO to benefit the robotics community.",
        "primary_area": "",
        "author": "Chunran Zheng;Qingyan Zhu;Wei Xu;Xiyuan Liu;Qizhi Guo;Fu Zhang;Chunran Zheng;Qingyan Zhu;Wei Xu;Xiyuan Liu;Qizhi Guo;Fu Zhang",
        "authorids": "/37088928114;/37089660118;/37086942915;/37088689751;/37089659577;/38245883800;/37088928114;/37089660118;/37086942915;/37088689751;/37089659577;/38245883800",
        "aff": "Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981107/",
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2406441262557665880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981501",
        "title": "FBG-Based Variable-Length Estimation for Shape Sensing of Extensible Soft Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel variable-length estimation approach for shape sensing of extensible soft robots utilizing fiber Bragg gratings (FBGs). Shape reconstruction from FBG sensors has been increasingly developed for soft robots, while the narrow stretching range of FBG fiber makes it difficult to acquire accurate sensing results for extensible robots. Towards this limitation, we newly introduce an FBG-based length sensor by leveraging a rigid curved channel, through which FBGs are allowed to slide within the robot following its body extension/compression, hence we can search and match the FBGs with specific constant curvature in the fiber to determine the effective length. From the fusion with the above measurements, a model-free filtering technique is accordingly presented for simultaneous calibration of a variable-length model and temporally continuous length estimation of the robot, enabling its accurate shape sensing using solely FBGs. The performances of the proposed method have been experimentally evaluated on an extensible soft robot equipped with an FBG fiber in both free and unstructured environments. The results concerning dynamic accuracy and robustness of length estimation and shape sensing demonstrate the effectiveness of our approach.",
        "primary_area": "",
        "author": "Yiang Lu;Wei Chen;Zhi Chen;Jianshu Zhou;Yun\u2013hui Liu;Yiang Lu;Wei Chen;Zhi Chen;Jianshu Zhou;Yun\u2013hui Liu",
        "authorids": "/37086614250;/37086608021;/37087246606;/37086011742;/37279412600;/37086614250;/37086608021;/37087246606;/37086011742;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Hong Kong Center for Logistics Robotics, Hong Kong; Hong Kong Center for Logistics Robotics, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981501/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7196742766590308791&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Hong Kong Center for Logistics Robotics",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981758",
        "title": "FC3: Feasibility-Based Control Chain Coordination",
        "track": "main",
        "status": "Poster",
        "abstract": "Hierarchical coordination of controllers often uses symbolic state representations that fully abstract their underlying low-level controllers, treating them as \u201cblack boxes\u201d to the symbolic action abstraction. This paper proposes a framework to realize robust behavior, which we call Feasibility-based Control Chain Coordination (FC3). Our controllers expose the geometric features and constraints they operate on. Based on this, FC3 can reason over the controllers' feasibility and their sequence feasibility. For a given task, FC3 first automatically constructs a library of potential controller chains using a symbolic action tree, which is then used to coordinate controllers in a chain, evaluate task feasibility, as well as switching between controller chains if necessary. In several real-world experiments we demonstrate FC3, s robustness and awareness of the task's feasibility through its own actions and gradual responses to different interferences.",
        "primary_area": "",
        "author": "Jason Harris;Danny Driess;Marc Toussaint;Jason Harris;Danny Driess;Marc Toussaint",
        "authorids": "/37089662131;/37085994159;/37528418600;/37089662131;/37085994159;/37528418600",
        "aff": "Learning & Intelligent Systems Lab, TU, Berlin; Science of Intelligence Excellence Cluster, TU, Berlin; Science of Intelligence Excellence Cluster, TU, Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981758/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Berlin",
        "aff_unique_dep": "Learning & Intelligent Systems Lab",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981413",
        "title": "FEJ-VIRO: A Consistent First-Estimate Jacobian Visual-Inertial-Ranging Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, Visual-Inertial Odometry (VIO) has achieved many significant progresses. However, VIO meth-ods suffer from localization drift over long trajectories. In this paper, we propose a First-Estimates Jacobian Visual-Inertial-Ranging Odometry (FEJ-VIRO) to reduce the localization drifts of VIO by incorporating ultra-wideband (UWB) ranging measurements into the VIO framework consistently. Consid-ering that the initial positions of UWB anchors are usually unavailable, we propose a long-short window structure to initialize the UWB anchors' positions as well as the covariance for state augmentation. After initialization, the FEJ - VIRO estimates the UWB anchors' positions simultaneously along with the robot poses. We further analyze the observability of the visual-inertial-ranging estimators and proved that there are four unobservable directions in the ideal case, while one of them vanishes in the actual case due to the gain of spurious information. Based on these analyses, we leverage the FEJ technique to enforce the unobservable directions, hence reducing inconsistency of the estimator. Finally, we validate our analysis and evaluate the proposed FEJ-VIRO with both simulation and real-world experiments.",
        "primary_area": "",
        "author": "Shenhan Jia;Yanmei Jiao;Zhuqing Zhang;Rong Xiong;Yue Wang;Shenhan Jia;Yanmei Jiao;Zhuqing Zhang;Rong Xiong;Yue Wang",
        "authorids": "/37088073358;/37086475262;/37089236052;/37271511300;/37072299700;/37088073358;/37086475262;/37089236052;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981413/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1626434816557299994&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981271",
        "title": "FIG-OP: Exploring Large-Scale Unknown Environments on a Fixed Time Budget",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for autonomous exploration of large-scale unknown environments under mission time con-straints. We start by proposing the Frontloaded Information Gain Orienteering Problem (FIG-OP) - a generalization of the traditional orienteering problem where the assumption of a reliable environmental model no longer holds. The FIG-OP ad-dresses model uncertainty by frontloading expected information gain through the addition of a greedy incentive, effectively expe-diting the moment in which new area is uncovered. In order to reason across multi-kilometer environments, we solve FIG-OP over an information-efficient world representation, constructed through the aggregation of information from a topological and metric map. Our method was extensively tested and field-hardened across various complex environments, ranging from subway systems to mines. In comparative simulations, we observe that the FIG-OP solution exhibits improved coverage efficiency over solutions generated by greedy and traditional orienteering-based approaches (i.e. severe and minimal model uncertainty assumptions, respectively).",
        "primary_area": "",
        "author": "Oriana Peltzer;Amanda Bouman;Sung-Kyun Kim;Ransalu Senanayake;Joshua Ott;Harrison Delecki;Mamoru Sobue;Mykel J. Kochenderfer;Mac Schwager;Joel Burdick;Ali-akbar Agha-mohammadi;Oriana Peltzer;Amanda Bouman;Sung-Kyun Kim;Ransalu Senanayake;Joshua Ott;Harrison Delecki;Mamoru Sobue;Mykel J. Kochenderfer;Mac Schwager;Joel Burdick;Ali-akbar Agha-mohammadi",
        "authorids": "/37088505805;/37087322528;/37598024600;/38490726500;/37089662054;/37089661116;/37087118270;/37596929200;/37424620600;/37265975700;/38274170800;/37088505805;/37087322528;/37598024600;/38490726500;/37089662054;/37089661116;/37087118270;/37596929200;/37424620600;/37265975700;/38274170800",
        "aff": "Department of Mechanical Engineering, Stanford University; Department of Mechanical and Civil Engineering, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Graduate School of Frontier Sciences, University of Tokyo; Department of Aeronautics and Astronautics, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Mechanical and Civil Engineering, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981271/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10423900939405051303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;1;0;0;0;2;0;0;1;1",
        "aff_unique_norm": "Stanford University;California Institute of Technology;University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Civil Engineering;Graduate School of Frontier Sciences",
        "aff_unique_url": "https://www.stanford.edu;https://www.caltech.edu;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Stanford;Caltech;UTokyo",
        "aff_campus_unique_index": "0;1;1;0;0;0;2;0;0;1;1",
        "aff_campus_unique": "Stanford;Pasadena;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0;0;0;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9981228",
        "title": "FSM: Correspondenceless scan-matching of panoramic 2D range scans",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years have seen the introduction of more affordable but less accurate 2D range sensors whose field of view is 2\\pi2\\pi. Scan-matching with these has been insufficiently researched, while being a challenge due to these sensors' increased measurement uncertainty. This paper proposes a real-time method for matching scans extracted from panoramic 2D LIDAR sensors. The method leverages properties of the Fourier transform which arise due to the periodicity of the range signal. Matching is performed in a correspondenceless manner. The proposed method outperforms established scan-matching methods in terms of pose accuracy and robustness in tests on public domain data, and over noise levels of commercially available sensors. The source code is available for download.",
        "primary_area": "",
        "author": "Alexandros Filotheou;Georgios D. Sergiadis;Antonis G. Dimitriou;Alexandros Filotheou;Georgios D. Sergiadis;Antonis G. Dimitriou",
        "authorids": "/37086524713;/37284183500;/37284184600;/37086524713;/37284183500;/37284184600",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981228/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8918101177612339775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981416",
        "title": "Factorization of Dynamic Games over Spatio-Temporal Resources",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic games feature a state-space complexity that scales superlinearly with the number of players. This makes this class of games often intractable even for a handful of players. We introduce the factorization process of dynamic games as a transformation leveraging the independence of players at equilibrium to build a leaner game graph. When applicable, it yields fewer nodes, fewer players per game node, hence much faster solutions. While for the general case checking for independence of players requires to solve the game itself, we observe that for dynamic games in the robotic domain there exist exact heuristics based on the spatio-temporal occupancy of the individual players. We validate our findings in realistic autonomous driving scenarios showing that already for a 4-player intersection we have a reduction of game nodes and solving time close to 99%.",
        "primary_area": "",
        "author": "Alessandro Zanardi;Saverio Bolognani;Andrea Censi;Florian Dorfler;Emilio Frazzoli;Alessandro Zanardi;Saverio Bolognani;Andrea Censi;Florian Dorfler;Emilio Frazzoli",
        "authorids": "/37086163473;/37404052500;/37398994000;/37545454200;/37283368500;/37086163473;/37404052500;/37398994000;/37545454200;/37283368500",
        "aff": "Institute for Dynamic Systems and Control, ETH Zurich, Switzerland; Automatic Control Lab, ETH Zurich, Switzerland; Institute for Dynamic Systems and Control, ETH Zurich, Switzerland; Automatic Control Lab, ETH Zurich, Switzerland; Institute for Dynamic Systems and Control, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981416/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10928003196042459135&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981291",
        "title": "Fair Planning for Mobility-on-Demand with Temporal Logic Requests",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobility-on-demand systems are transforming the way we think about the transportation of people and goods. Most research effort has been placed on scalability issues for systems with a large number of agents and simple pickup/drop-off demands. In this paper, we consider fair multi-vehicle route planning with streams of complex, temporal logic transportation demands. We consider an approximately envy-free fair allocation of demands to limited-capacity vehicles based on agents' accumulated utility over a finite time horizon, representing for example monetary reward or utilization level. We propose a scalable approach based on the construction of assignment graphs that relate agents to routes and demands, and pose the problem as an Integer Linear Program (ILP). Routes for assignments are computed using automata-based methods for each vehicle and demands sets of size at most the capacity of the vehicle while taking into account their pickup wait time and delay tolerances. In addition, we integrate utility-based weights in the assignment graph and ILP to ensure approximative fair allocation. We demonstrate the computational and operational performance of our methods in ride-sharing case studies over a large environment in mid-Manhattan and Linear Temporal Logic demands with stochastic arrival times. We show that our method significantly decreases the utility deviation between agents and the vacancy rate.",
        "primary_area": "",
        "author": "Kaier Liang;Cristian-Ioan Vasile;Kaier Liang;Cristian-Ioan Vasile",
        "authorids": "/37089663557;/37085532895;/37089663557;/37085532895",
        "aff": "Mechanical Engineering and Mechanics Department at Lehigh University, PA, USA; Mechanical Engineering and Mechanics Department at Lehigh University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981291/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11799461282527771608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Mechanical Engineering and Mechanics",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bethlehem",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981397",
        "title": "Fast 3D Sparse Topological Skeleton Graph Generation for Mobile Robot Global Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, mobile robots are becoming ambitious and deployed in large-scale scenarios. Serving as a high-level understanding of environments, a sparse skeleton graph is beneficial for more efficient global planning. Currently, existing solutions for skeleton graph generation suffer from several major limitations, including poor adaptiveness to different map representations, dependency on robot inspection trajectories and high computational overhead. In this paper, we propose an efficient and flexible algorithm generating a trajectory-independent 3D sparse topological skeleton graph capturing the spatial structure of the free space. In our method, an efficient ray sampling and validating mechanism are adopted to find distinctive free space regions, which contributes to skeleton graph vertices, with traversability between adjacent vertices as edges. A cycle formation scheme is also utilized to maintain skeleton graph compactness. Benchmark comparison with state-of-the-art works demonstrates that our approach generates sparse graphs in a substantially shorter time, giving high-quality global planning paths. Experiments conducted in real-world maps further validate the capability of our method in real-world scenarios. Our method will be made open source to benefit the community.",
        "primary_area": "",
        "author": "Xinyi Chen;Boyu Zhou;Jiarong Lin;Yichen Zhang;Fu Zhang;Shaojie Shen;Xinyi Chen;Boyu Zhou;Jiarong Lin;Yichen Zhang;Fu Zhang;Shaojie Shen",
        "authorids": "/37088661175;/37086574790;/37087012222;/37088504984;/38245883800;/37954847200;/37088661175;/37086574790;/37087012222;/37088504984;/38245883800;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981397/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13500986347753499144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of Hong Kong",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.hku.hk",
        "aff_unique_abbr": "HKUST;HKU",
        "aff_campus_unique_index": "0;0;1;0;1;0",
        "aff_campus_unique": "Hong Kong;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982180",
        "title": "Fast Cost-aware Lazy-Theta over Euclidean distance functions for 3D planning of aerial robots in building-like environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a fast cost-aware any-angle path planning algorithm for aerial robots in 3D building-like environments. The approach integrates Euclidean Distance Fields (EDF) and Lazy Theta* algorithm to compute safe and smooth paths. We show how to consider the analytical proper-ties of EDFs for polygonal obstacles to get an approximation of the cost along the line of sight segments of the planner, reducing the computational requirements. Numerous tests in a realistic building-like environment are performed to evaluate the proposed algorithm with respect to other heuristic search algorithms considering the distance cost by using an EDF. The results show that the proposed algorithm considerably reduces the computation time in indoor and outdoor environments enabling fast, safe and smooth paths.",
        "primary_area": "",
        "author": "Jose A. Cobano;Rafael Rey;L. Merino;F. Caballero;Jose A. Cobano;Rafael Rey;L. Merino;F. Caballero",
        "authorids": "/37948437800;/37087053880;/37282385100;/37282357300;/37948437800;/37087053880;/37282385100;/37282357300",
        "aff": "Service Robotics Lab (SRL), Universidad Pablo de Olavide, Seville, Spain; Service Robotics Lab (SRL), Universidad Pablo de Olavide, Seville, Spain; Service Robotics Lab (SRL), Universidad Pablo de Olavide, Seville, Spain; Department of Systems Engineering and Automation, University of Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982180/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=817242054721037107&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Universidad Pablo de Olavide;University of Seville",
        "aff_unique_dep": "Service Robotics Lab (SRL);Department of Systems Engineering and Automation",
        "aff_unique_url": "https://www.upo.es;https://www.us.es",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seville;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9982239",
        "title": "Fast Detection of Moving Traffic Participants in LiDAR Point Clouds by using Particles augmented with Free Space Information",
        "track": "main",
        "status": "Poster",
        "abstract": "To navigate safely, it is essential for a robot to detect all kinds of moving objects that could possibly interfere with the own trajectory. For common object classes, like cars, regular pedestrians, and trucks, there are large scale datasets as well as corresponding machine learning techniques, which provide remarkable results in commonly available detection benchmarks. A big challenge that remains, are less frequent classes, which are not part of a dataset in a sufficient number and variation. Dynamic occupancy grids are a promising approach for detection of moving objects in point clouds since they impose only a few assumptions about the objects' appearance and shape. Typically, they use particle filters to detect motion of occupancy in the grid. Existing approaches, however, often generate false positives at long obstacles because particles move along them. Therefore we propose a highly efficient approach, which performs the classification in a more structured and conservative way by making extensive use of available free space information. As a result, much less false positives are generated while the number of false negatives remains low. Our approach can be used to complement CNN-based object detections in order to detect both, frequent and uncommon object classes reliably. By using polar data structures that match the polar measurement principle, we are able to process even large point clouds of modern LiDARs with 128 lasers efficiently.",
        "primary_area": "",
        "author": "Andreas Reich;Hans-Joachim Wuensche;Andreas Reich;Hans-Joachim Wuensche",
        "authorids": "/37089177729;/37393701000;/37089177729;/37393701000",
        "aff": "Institute for Autonomous Systems Technology (TAS), Universit\u00e4t der Bundeswehr M\u00fcnchen, Neubiberg, Germany; Institute for Autonomous Systems Technology (TAS), Universit\u00e4t der Bundeswehr M\u00fcnchen, Neubiberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982239/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13237600429704987398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e4t der Bundeswehr M\u00fcnchen",
        "aff_unique_dep": "Institute for Autonomous Systems Technology (TAS)",
        "aff_unique_url": "https://www.unibw.de",
        "aff_unique_abbr": "UniBW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Neubiberg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981327",
        "title": "Fast Hierarchical Learning for Few-Shot Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Transfer learning based approaches have recently achieved promising results on the few-shot detection task. These approaches however suffer from \u201ccatastrophic forgetting\u201d issue due to finetuning of base detector, leading to sub-optimal performance on the base classes. Furthermore, the slow convergence rate of stochastic gradient descent (SGD) results in high latency and consequently restricts real-time applications. We tackle the aforementioned issues in this work. We pose few-shot detection as a hierarchical learning problem, where the novel classes are treated as the child classes of existing base classes and the background class. The detection heads for the novel classes are then trained using a specialized optimization strategy, leading to significantly lower training times compared to SGD. Our approach obtains competitive novel class performance on few-shot MS-COCO benchmark, while completely retaining the performance of the initial model on the base classes. We further demonstrate the application of our approach to a new class-refined few-shot detection task.",
        "primary_area": "",
        "author": "Yihang She;Goutam Bhat;Martin Danelljan;Fisher Yu;Yihang She;Goutam Bhat;Martin Danelljan;Fisher Yu",
        "authorids": "/37089660415;/37086245206;/37085558596;/37086564244;/37089660415;/37086245206;/37085558596;/37086564244",
        "aff": "Computer Vision Lab, ETH Zurich; Computer Vision Lab, ETH Zurich; Computer Vision Lab, ETH Zurich; Computer Vision Lab, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981327/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9715838234184612328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Computer Vision Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981383",
        "title": "Fast Reflexive Grasping with a Proprioceptive Teleoperation Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a proprioceptive teleoperation system that uses a reflexive grasping algorithm to enhance the speed and robustness of pick-and-place tasks. The system consists of two manipulators that use quasi-direct-drive actuation to provide highly transparent force feedback. The end-effector has bimodal force sensors that measure 3-axis force information and 2-dimensional contact location. This information is used for anti-slip and re-grasping reflexes. When the user makes contact with the desired object, the re-grasping reflex aligns the gripper fingers with antipodal points on the object to maximize the grasp stability. The reflex takes only 150ms to correct for inaccurate grasps chosen by the user, so the user's motion is only minimally disturbed by the execution of the re-grasp. Once antipodal contact is established, the anti-slip reflex ensures that the gripper applies enough normal force to prevent the object from slipping out of the grasp. The combination of proprioceptive manipulators and reflexive grasping allows the user to complete teleoperated tasks with precision at high speed.",
        "primary_area": "",
        "author": "Andrew SaLoutos;Elijah Stanger\u2013Jones;Sangbae Kim;Andrew SaLoutos;Elijah Stanger\u2013Jones;Sangbae Kim",
        "authorids": "/37088688960;/37088991680;/37537397200;/37088688960;/37088991680;/37537397200",
        "aff": "Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981383/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14773051035042413020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981143",
        "title": "Fast Scan Context Matching for Omnidirectional 3D Scan",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots need to recognize the environment by identifying the scene. Scan context is one of global descriptors, and it encodes the three-dimensional scan data of the scene for the identification in a matrix form. Scan context is in a matrix form that is simple to store, but the matching of scan contexts can require computational effort because the descriptor is orientation-dependent. Because a scan context of an omnidirectional LiDAR scan becomes periodic in azimuth, this paper proposes to compute the scan context matching efficiently incorporating the cross-correlation with fast Fourier transform, and, hence, the method is named fast scan context matching. The effectiveness of the proposed method for computation time, accuracy, and robustness are reported in this paper. It is also shown that the method was also tested as a loop closure detector of a SLAM package as a practical application and that the proposed method outperformed the conventional scan context matching.",
        "primary_area": "",
        "author": "Hikaru Kihara;Makoto Kumon;Kei Nakatsuma;Tomonari Furukawa;Hikaru Kihara;Makoto Kumon;Kei Nakatsuma;Tomonari Furukawa",
        "authorids": "/37089658749;/37296098600;/37403313000;/37280186200;/37089658749;/37296098600;/37403313000;/37280186200",
        "aff": "Faculty of Engineering, Kumamoto University, Kumamoto, Japan; Faculty of Advanced Science and Technology, Kumamoto University, Kumamoto, Japan; Faculty of Advanced Science and Technology, Kumamoto University, Kumamoto, Japan; VICTOR Laboratory, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981143/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11708345885778399656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Kumamoto University;University of Virginia",
        "aff_unique_dep": "Faculty of Engineering;VICTOR Laboratory",
        "aff_unique_url": "https://www.kumamoto-u.ac.jp;https://www.virginia.edu",
        "aff_unique_abbr": ";UVA",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Kumamoto;Charlottesville",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9981496",
        "title": "Fast Structural Representation and Structure-aware Loop Closing for Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceptual Aliasing is one of the main problems in simultaneous localization and mapping (SLAM). Wrong associations between different places may lead to failure of the whole map. Research on structure information is rarely investigated among existing solutions to this problem. In cases of visual SLAM without sensors, such as LiDAR or Inertial Measurement Unit (IMU), structure information can rarely be obtained due to the sparsity of 3D points, which also makes structure analysis complex. This study provides a spherical harmonics (SH) based fast structural representation (SH-FS) in visual SLAM using sparse point clouds, which extracts the structure information from sparse points into single vector. SH-FS was applied in conventional feature-based loop closing process. Furthermore, a structure-aware loop closing method in visual SLAM was proposed to improve the robustness of SLAM systems. Moreover, our methods show a favorable performance in extensive experiments on different large-scale real world datasets.",
        "primary_area": "",
        "author": "Shuxiang Xie;Ryoichi Ishikawa;Ken Sakurada;Masaki Onishi;Takeshi Oishi;Shuxiang Xie;Ryoichi Ishikawa;Ken Sakurada;Masaki Onishi;Takeshi Oishi",
        "authorids": "/37089661289;/37085623791;/37603745700;/37279716500;/37340441900;/37089661289;/37085623791;/37603745700;/37279716500;/37340441900",
        "aff": "The National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Japan; The National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; The National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981496/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:zVNrzySGm78J:scholar.google.com/&scioq=Fast+Structural+Representation+and+Structure-aware+Loop+Closing+for+Visual+SLAM&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;University of Tokyo",
        "aff_unique_dep": ";Institute of Industrial Science",
        "aff_unique_url": "https://www.aist.go.jp;https://www.iis.u-tokyo.ac.jp",
        "aff_unique_abbr": "AIST;UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981484",
        "title": "Fast and Comfortable Interactive Robot-to-Human Object Handover",
        "track": "main",
        "status": "Poster",
        "abstract": "Transferring tools and objects to human hands is an important ability of collaborative robots. Most of the existing approaches focus on handover affordance, however, the comfort of receiving objects with human hands is often neglected. In this paper, we use advanced deep learning models to pre-generate handover target configurations that are convenient for human grasping based on the characteristics of the objects and tools, and then the robot grasps and passes the objects to the human. Experimental results on a mobile collaborative robot show that our proposed framework can robustly and efficiently deliver different shapes and types of objects to a human hand of any pose within the robot's field of view in a target pose that is convenient for grasping and can quickly deliver objects to a new target location even after the human hand moves to a new position.",
        "primary_area": "",
        "author": "Chongxi Meng;Tianwei Zhang;Tin lun Lam;Chongxi Meng;Tianwei Zhang;Tin lun Lam",
        "authorids": "/37089663585;/37086443242;/37571111600;/37089663585;/37086443242;/37571111600",
        "aff": "The Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS); The Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS); The Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981484/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13840416803606458716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.airs.shenzhen.gov.cn/",
        "aff_unique_abbr": "AIRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981640",
        "title": "Fast and Safe Exploration via Adaptive Semantic Perception in Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous exploration in unknown environments is a fundamental task for robots. Existing approaches mostly were concentrated on the efficiency of the exploration with the assumption of perfect state estimation, but the drift of pose estimation in visual SLAM occurs frequently and is detrimental to robot's localization and exploration performance. In this paper, a perception-aware exploration(PAE) method is proposed for rapidly and safely autonomous exploration in outdoor environments. The adaptive semantic information is proposed to improve the robustness of perception. Based on the perception module, both the selection of exploration goal on a novel weighted information gain and path planning can avoid the areas with high localization uncertainty. In addition, thanks to the proposed pipeline, including scan-based frontier detection, kd-tree based map prediction and suboptimal frontier buffer strategy, the PAE planner can explore the environment with high success rate and high efficiency. Several simulations are performed to verify the effectiveness of our methods.",
        "primary_area": "",
        "author": "Zhihao Wang;Lingxu Chen;Hongjin Chen;Haoyao Chen;Xin Jiang;Zhihao Wang;Lingxu Chen;Hongjin Chen;Haoyao Chen;Xin Jiang",
        "authorids": "/37089347141;/37089659927;/37089662265;/37600762500;/37086028734;/37089347141;/37089659927;/37089662265;/37600762500;/37086028734",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981640/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8783263514798626046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981663",
        "title": "Fast-Replanning Motion Control for Non-Holonomic Vehicles with Aborting A*",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomously driving vehicles must be able to navigate in dynamic and unpredictable environments in a collision-free manner. So far, this has only been partially achieved in driverless cars and warehouse installations where marked structures such as roads, lanes, and traffic signs simplify the motion planning and collision avoidance problem. We are presenting a new control approach for car-like vehicles that is based on an unprecedentedly fast-paced A* implementation that allows the control cycle to run at a frequency of 30 Hz. This frequency enables us to place our A* algorithm as a low-level replanning controller that is well suited for navigation and collision avoidance in virtually any dynamic environment. Due to an efficient heuristic consisting of rotate-translate-rotate motions laid out along the shortest path to the target, our Short-Term Aborting A* (STAA*) converges fast and can be aborted early in order to guarantee a high and steady control rate. While our STAA* expands states along the shortest path, it takes care of collision checking with the environment including predicted states of moving obstacles, and returns the best solution found when the computation time runs out. Despite the bounded computation time, our STAA* does not get trapped in corners due to the following of the shortest path. In simulated and real-robot experiments, we demonstrate that our control approach eliminates collisions almost entirely and is superior to an improved version of the Dynamic Window Approach with predictive collision avoidance capabilities [1].",
        "primary_area": "",
        "author": "Marcell Missura;Arindam Roychoudhury;Maren Bennewitz;Marcell Missura;Arindam Roychoudhury;Maren Bennewitz",
        "authorids": "/37947347600;/37088690601;/37324765000;/37947347600;/37088690601;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981663/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15589821373893045072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981098",
        "title": "FedDrive: Generalizing Federated Learning to Semantic Segmentation in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic Segmentation is essential to make self-driving vehicles autonomous, enabling them to understand their surroundings by assigning individual pixels to known categories. However, it operates on sensible data collected from the users' cars; thus, protecting the clients' privacy becomes a primary concern. For similar reasons, Federated Learning has been recently introduced as a new machine learning paradigm aiming to learn a global model while preserving privacy and leveraging data on millions of remote devices. Despite several efforts on this topic, no work has explicitly addressed the challenges of federated learning in semantic segmentation for driving so far. To fill this gap, we propose FedDrive, a new benchmark consisting of three settings and two datasets, incorporating the real-world challenges of statistical heterogeneity and domain generalization. We benchmark state-of-the-art algorithms from the federated learning literature through an in-depth analysis, combining them with style transfer methods to improve their generalization ability. We demonstrate that correctly handling normalization statistics is crucial to deal with the aforementioned challenges. Furthermore, style transfer improves performance when dealing with significant appearance shifts. Official website: https://feddrive.github.io.",
        "primary_area": "",
        "author": "Lidia Fantauzzo;Eros Fan\u00ec;Debora Caldarola;Antonio Tavera;Fabio Cermelli;Marco Ciccone;Barbara Caputo;Lidia Fantauzzo;Eros Fan\u00ec;Debora Caldarola;Antonio Tavera;Fabio Cermelli;Marco Ciccone;Barbara Caputo",
        "authorids": "/37089662052;/37089661737;/37088951906;/37088447725;/37086174513;/37086142851;/37271024800;/37089662052;/37089661737;/37088951906;/37088447725;/37086174513;/37086142851;/37271024800",
        "aff": "Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; Italian Institute of Technology, Genoa, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981098/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7697706904414790158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Politecnico di Torino;Italian Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.polito.it;https://www.iit.it",
        "aff_unique_abbr": "Polito;IIT",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Turin;Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981998",
        "title": "Federated Learning from Demonstration for Active Assistance to Smart Wheelchair Users",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) is a very appealing approach to empower robots with autonomy. Given some demonstrations provided by a human teacher, the robot can learn a policy to solve the task without explicit programming. A promising use case is to endow smart robotic wheelchairs with active assistance to navigation. By using LfD, it is possible to learn to infer short-term destinations anywhere, without the need of building a map of the environment beforehand. Nevertheless, it is difficult to generalize robot behaviors to environments other than those used for training. We believe that one possible solution is learning from crowds, involving a broad number of teachers (the end users themselves) who perform demonstrations in diverse and real environments. To this end, in this work we consider Federated Learning from Demonstration (FLfD), a distributed approach based on a Federated Learning architecture. Our proposal allows the training of a global deep neural network using sensitive local data (images and laser readings) with privacy guarantees. In our experiments we pose a scenario involving different clients working in heterogeneous domains. We show that the federated model is able to generalize and deal with non Independent and Identically Distributed (non-IID) data.",
        "primary_area": "",
        "author": "Fernando E. Casado;Yiannis Demiris;Fernando E. Casado;Yiannis Demiris",
        "authorids": "/37089660262;/37296338900;/37089660262;/37296338900",
        "aff": "CiTIUS (Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Dept. of Electrical and Electronic Engineering, PRL (Personal Robotics Laboratory), Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981998/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8073245905047978799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Universidade de Santiago de Compostela;Imperial College London",
        "aff_unique_dep": "Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes;Dept. of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.usc.es;https://www.imperial.ac.uk",
        "aff_unique_abbr": "USC;Imperial College",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Santiago de Compostela;London",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Spain;United Kingdom"
    },
    {
        "id": "9981616",
        "title": "Feedback-efficient Active Preference Learning for Socially Aware Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Socially aware robot navigation, where a robot is required to optimize its trajectory to maintain comfortable and compliant spatial interactions with humans in addition to reaching its goal without collisions, is a fundamental yet challenging task in the context of human-robot interaction. While existing learning-based methods have achieved better performance than the preceding model-based ones, they still have drawbacks: reinforcement learning depends on the handcrafted reward that is unlikely to effectively quantify broad social compliance, and can lead to reward exploitation problems; meanwhile, inverse rein-forcement learning suffers from the need for expensive human demonstrations. In this paper, we propose a feedback-efficient active preference learning approach, FAPL, that distills human comfort and expectation into a reward model to guide the robot agent to explore latent aspects of social compliance. We further introduce hybrid experience learning to improve the efficiency of human feedback and samples, and evaluate benefits of robot behaviors learned from FAPL through extensive simulation experiments and a user study (N=10) employing a physical robot to navigate with human subjects in real-world scenarios. Source code and experiment videos for this work are available at: https://sites.google.com/view/san-fapl.",
        "primary_area": "",
        "author": "Ruiqi Wang;Weizheng Wang;Byung-Cheol Min;Ruiqi Wang;Weizheng Wang;Byung-Cheol Min",
        "authorids": "/37089659639;/37089664134;/37711040000;/37089659639;/37089664134;/37711040000",
        "aff": "Department of Computer and Information Technology, SMART Laboratory, Purdue University, West Lafayette, IN, USA; College of Mechanical and Electrical Engineering, Beijing University of Chemical Technology, Beijing (BUCT), China; Department of Computer and Information Technology, SMART Laboratory, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981616/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15006898062548516046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Purdue University;Beijing University of Chemical Technology",
        "aff_unique_dep": "Department of Computer and Information Technology;College of Mechanical and Electrical Engineering",
        "aff_unique_url": "https://www.purdue.edu;http://www.buct.edu.cn",
        "aff_unique_abbr": "Purdue;BUCT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "West Lafayette;Beijing",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9982065",
        "title": "Feel the Tension: Manipulation of Deformable Linear Objects in Environments with Fixtures using Force Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans are able to manipulate Deformable Linear Objects (DLOs) such as cables and wires, with little or no visual information, relying mostly on force sensing. In this work, we propose a reduced DLO model which enables such blind manipulation by keeping the object under tension. Further, an online model estimation procedure is also proposed. A set of elementary sliding and clipping manipulation primitives are defined based on our model. The combination of these primitives allows for more complex motions such as winding of a DLO. The model estimation and manipulation primitives are tested individually but also together in a real-world cable harness production task, using a dual-arm YuMi, thus demonstrating that force-based perception can be sufficient even for such a complex scenario.",
        "primary_area": "",
        "author": "Finn S\u00fcberkr\u00fcb;Rita Laezza;Yiannis Karayiannidis;Finn S\u00fcberkr\u00fcb;Rita Laezza;Yiannis Karayiannidis",
        "authorids": "/37086840733;/37088996941;/37300987100;/37086840733;/37088996941;/37300987100",
        "aff": "TC Plattling, Deggendorf Institute of Technology, Germany; Department of Electrical Engineering, Chalmers University of Technology, Sweden; Department of Automatic Control, Lund University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982065/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7907392139411787306&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Deggendorf Institute of Technology;Chalmers University of Technology;Lund University",
        "aff_unique_dep": ";Department of Electrical Engineering;Department of Automatic Control",
        "aff_unique_url": "https://www.th-deg.de;https://www.chalmers.se;https://www.lunduniversity.lu.se",
        "aff_unique_abbr": ";Chalmers;LU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Plattling;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "9981594",
        "title": "Feeling the Pressure: The Influence of Vibrotactile Patterns on Feedback Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile feedback is necessary for closing the sen-sorimotor loop in prosthetic and tele-operable control, which would allow for more precise manipulation and increased acceptance of use of such devices. Pressure stimuli are commonly presented to users in haptic devices through a sensory substitution to vibration. The precise nature of this substitution affects pressure sensitivity, as well as the comfort and intuitiveness of the device for the user. This study determines the effects of different vibrational encodings for pressure on user-preference and performance in a 4-alternative absolute identification task. 4 different encoding patterns for pressure were examined: short pulse and long pulse amplitude modulation along with sine and square wave frequency modulation. Of the methods examined, frequency modulation methods led to the best discrimination of stimuli (p < 0.001). There was a notable difference in user preference between the two frequency modulated systems, with sinusoidal stimulation being highest ranked across all the preference metrics and square-wave being ranked lowest in two of the three. This difference trended towards, but did not achieve statistical significance (TLX rankings, ppp = 0.098). This suggests that prostheses or teleoperated devices utilising vibrotactile feedback may benefit from implementing a discrete frequency-based sinusoidal pattern to indicate changes in grip force.",
        "primary_area": "",
        "author": "Alexander Smith;Benjamin Ward-Cherrier;Appolinaire Etoundi;Martin J. Pearson;Alexander Smith;Benjamin Ward-Cherrier;Appolinaire Etoundi;Martin J. Pearson",
        "authorids": "/37089492059;/37085617128;/38230488900;/38537899700;/37089492059;/37085617128;/38230488900;/38537899700",
        "aff": "Dept. of Aerospace Engineering, University of Bristol, UK; Dept. of Engineering Mathematics, University of Bristol, UK; Engineering, Design & Mathematics, University of the West of England, UK; Engineering, Design & Mathematics, University of the West of England, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981594/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7599025686599886787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "University of Bristol;University of the West of England",
        "aff_unique_dep": "Dept. of Aerospace Engineering;Engineering, Design & Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.uwe.ac.uk",
        "aff_unique_abbr": "Bristol;UWE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981800",
        "title": "Fidelity Evaluation of Virtual Traffic Based on Anomalous Trajectory Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Measuring the fidelity of synthesized virtual traffic has become an important and fundamental concern for evaluating the performance of different traffic simulation techniques and applications of autonomous vehicle testing. In this work, we propose a novel method to evaluate the fidelity of any trajectory data from the perspective of anomalous trajectory detection. First, given the trajectory data to be evaluated as input, the method learns spatio-temporal traffic features and reconstructs the input trajectory through a Long Short-Term Memory (LSTM)-based autoencoder architecture. Then, the anomalous trajectories are detected by comparing the reconstructed trajectories and the input ones using the reconstruction error as the benchmark. Our method can detect eight different kinds of anomalous trajectory in terms of changes in velocity and moving direction. In order to evaluate the fidelity of the input trajectory, we design a perceptual evaluation on virtual traffic fidelity and derive a mapping from the reconstruction error to the evaluation score. We demonstrated the effectiveness and robustness of our metric through many experiments on real-world and synthetic trajectory data containing different types of motion anomalies.",
        "primary_area": "",
        "author": "Chaoneng Li;Qianwen Chao;Guanwen Feng;Qiongyan Wang;Pengfei Liu;Yunan Li;Qiguang Miao;Chaoneng Li;Qianwen Chao;Guanwen Feng;Qiongyan Wang;Pengfei Liu;Yunan Li;Qiguang Miao",
        "authorids": "/37089658482;/37085800962;/37088649594;/37089664086;/37089658501;/37086001415;/37413486900;/37089658482;/37085800962;/37088649594;/37089664086;/37089658501;/37086001415;/37413486900",
        "aff": "Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China; Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China; Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China; Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, P. R., China; Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China; Department of Computer Science and Technology, Xidian University, Xi'an, P. R., China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981800/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7098919787238292243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Xidian University;Zhejiang University",
        "aff_unique_dep": "Department of Computer Science and Technology;State Key Laboratory of CAD&CG",
        "aff_unique_url": "http://www.xidian.edu.cn;http://www.zju.edu.cn",
        "aff_unique_abbr": "Xidian;ZJU",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Xi'an;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981891",
        "title": "Fisheye object detection based on standard image datasets with 24-points regression strategy",
        "track": "main",
        "status": "Poster",
        "abstract": "Fisheye object detection is a difficult task in robotics and autonomous driving. One of the reasons is that the fisheye datasets are inferior to standard image datasets in scale and quantity, which inspires the idea of using standard image datasets for fisheye object detection. However, the models trained on standard image datasets do not perform well with fisheye data. In this work, we explore the effect of fisheye images on different stages of the YOLOX with published weights generated by standard image datasets. We also propose a new regression strategy for 24-points object representation method, which is insensitive to image distortion. The experiments show that the feature extraction part is robust to fisheye image features, while the regression part of location and category performs poorly. The strategy can achieve the position of discrete points without calculating the IOU of irregular-shaped boxes. Theoretically, the strategy can be widely adopted to regress the irregular bounding boxes composed of discrete points. Source code is at https://github.com/IN2-ViAUn/Exploration-of-Potential.",
        "primary_area": "",
        "author": "Xi Xu;Yu Gao;Hao Liang;Yi Yang;Mengyin Fu;Xi Xu;Yu Gao;Hao Liang;Yi Yang;Mengyin Fu",
        "authorids": "/37089733079;/37088643883;/37089661177;/37899921700;/37271910500;/37089733079;/37088643883;/37089661177;/37899921700;/37271910500",
        "aff": "State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981891/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4497818378241005986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Intelligent Control and Decision of Complex System",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982182",
        "title": "Fixture-Aware DDQN for Generalized Environment-Enabled Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper expands on the problem of grasping an object that can only be grasped by a single parallel gripper when a fixture (e.g., wall, heavy object) is harnessed. Preceding work that tackle this problem are limited in that the employed networks implicitly learn specific targets and fixtures to leverage. However, the notion of a usable fixture can vary in different environments, at times without any outwardly noticeable differences. In this paper, we propose a method to relax this limitation and further handle environments where the fixture location is unknown. The problem is formulated as visual affordance learning in a partially observable setting. We present a self-supervised reinforcement learning algorithm, Fixture-Aware Double Deep Q-Network (FA-DDQN), that processes the scene observation to 1) identify the target object based on a reference image, 2) distinguish possible fixtures based on interaction with the environment, and finally 3) fuse the information to generate a visual affordance map to guide the robot to successful Slide-to-Wall grasps. We demonstrate our proposed solution in simulation and in real robot experiments to show that in addition to achieving higher success than baselines, it also performs zero-shot generalization to novel scenes with unseen object configurations.",
        "primary_area": "",
        "author": "Eddie Sasagawa;Changhyun Choi;Eddie Sasagawa;Changhyun Choi",
        "authorids": "/37089661242;/37085811337;/37089661242;/37085811337",
        "aff": "Minnesota Robotics Institute, Minneapolis, MN, USA; Department of Electrical and Computer Engineering, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982182/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BzT0AX-ouygJ:scholar.google.com/&scioq=Fixture-Aware+DDQN+for+Generalized+Environment-Enabled+Grasping&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Minnesota;University of Minnesota Twin Cities",
        "aff_unique_dep": "Minnesota Robotics Institute;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu;https://www.umn.edu",
        "aff_unique_abbr": "UMN;UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981347",
        "title": "Flash: Fast and Light Motion Prediction for Autonomous Driving with Bayesian Inverse Planning and Learned Motion Profiles",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction of road users in traffic scenes is critical for autonomous driving systems that must take safe and robust decisions in complex dynamic environments. We present a novel motion prediction system for autonomous driving. Our system is based on the Bayesian inverse planning framework, which efficiently orchestrates map-based goal extraction, a classical control-based trajectory generator and a mixture of experts collection of light-weight neural networks specialised in motion profile prediction. In contrast to many alternative methods, this modularity helps isolate performance factors and better interpret results, without compromising performance. This system addresses multiple aspects of interest, namely multi-modality, motion profile uncertainty and trajectory physical feasibility. We report on several experiments with the popular highway dataset NGSIM, demonstrating state-of-the-art performance in terms of trajectory error. We also perform a detailed analysis of our system's components, along with experiments that stratify the data based on behaviours, such as change-lane versus follow-lane, to provide insights into the challenges in this domain. Finally, we present a qualitative analysis to show other benefits of our approach, such as the ability to interpret the outputs.",
        "primary_area": "",
        "author": "Morris Antonello;Mihai Dobre;Stefano V. Albrecht;John Redford;Subramanian Ramamoorthy;Morris Antonello;Mihai Dobre;Stefano V. Albrecht;John Redford;Subramanian Ramamoorthy",
        "authorids": "/37089919054;/37085732104;/37088996736;/37089197964;/37529920500;/37089919054;/37085732104;/37088996736;/37089197964;/37529920500",
        "aff": "Applied Research Team, Five AI, Edinburgh, United Kingdom; Applied Research Team, Five AI, Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Applied Research Team, Five AI, Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981347/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16890450408463160782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Five AI;University of Edinburgh",
        "aff_unique_dep": "Applied Research Team;School of Informatics",
        "aff_unique_url": "https://www.five.ai;https://www.ed.ac.uk",
        "aff_unique_abbr": ";Edinburgh",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981043",
        "title": "Flexible Collision-free Platooning Method for Unmanned Surface Vehicle with Experimental Validations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the flexible formation problem for unmanned surface vehicles in the presence of obstacles. Building upon the leader-follower formation scheme, a hybrid line-of-sight based flexible platooning method is proposed for follower vehicle to keep tracking the leader ship. A fusion artificial potential field collision avoidance approach is tailored to generate optimal collision-free trajectories for the vehicle to track. To steer the vehicle towards and stay within the neighborhood of the generated collision-free trajectory, a nonlinear model predictive controller is designed. Experimental results are presented to validate the efficiency of proposed method, showing that the unmanned surface vehicle is able to track the leader ship without colliding with the surrounded static obstacles in the considered experiments.",
        "primary_area": "",
        "author": "Bin Du;Bin Lin;Wei Xie;Weidong Zhang;Rudy R. Negenborn;Yusong Pang;Bin Du;Bin Lin;Wei Xie;Weidong Zhang;Rudy R. Negenborn;Yusong Pang",
        "authorids": "/37089617072;/37089271456;/37086839260;/37278428200;/37399867800;/37288024600;/37089617072;/37089271456;/37086839260;/37278428200;/37399867800;/37288024600",
        "aff": "Department of Maritime and Transport Technology, Delft University of Technology, Delft, Netherlands; School of Information and Communication Engineering, Hainan University, Haikou, Hainan, China; National Key Laboratory of Science and Technology on Underwater Vehicle, Harbin Engineering University, Harbin, China; School of Information and Communication Engineering, Hainan University, Haikou, Hainan, China; Department of Maritime and Transport Technology, Delft University of Technology, Delft, Netherlands; Department of Maritime and Transport Technology, Delft University of Technology, Delft, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981043/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9448216919739518393&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;0;0",
        "aff_unique_norm": "Delft University of Technology;Hainan University;Harbin Engineering University",
        "aff_unique_dep": "Department of Maritime and Transport Technology;School of Information and Communication Engineering;National Key Laboratory of Science and Technology on Underwater Vehicle",
        "aff_unique_url": "https://www.tudelft.nl;http://www.hainanu.edu.cn;http://www.heu.edu.cn",
        "aff_unique_abbr": "TUDelft;;HEU",
        "aff_campus_unique_index": "0;1;2;1;0;0",
        "aff_campus_unique": "Delft;Haikou;Harbin",
        "aff_country_unique_index": "0;1;1;1;0;0",
        "aff_country_unique": "Netherlands;China"
    },
    {
        "id": "9981639",
        "title": "Flexible and Precision Snap-Fit Peg-in-Hole Assembly Based on Multiple Sensations and Damping Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Snap-fit peg-in-hole assembly widely exists in both industry and daily life, especially for consumer electronics. The buckle mechanism leads to a damping zone inside the port where insertion force needs to be increased. It is much difficult to automate this process by robots, for size and clearance of the components are always small, and the damping buckle should be perceived and distinguished from solid inner walls of the port. End-effector position control might be invalid, since grasping error will make it difficult to locate the plug accurately. In this article, we undertake this assembly challenge by taking advantage of fingertip tactile perception combined with visual images and force feedback. Raw sensor data is collected, processed, and fused together to be state input of a reinforcement learning network, generating continuous action vectors. We also propose a novel damping zone predictor through feature extraction and multimodal fusion, which is able to identify whether the plug has touched the buckle mechanism, so as to adjust the insertion force. The whole framework is implemented through a common USB Type-C insertion experiment on Franka Panda robot platform, reaching a success rate of 88%. Furthermore, system robustness is verified, and comparisons of different modalities are also conducted.",
        "primary_area": "",
        "author": "Ruikai Liu;Xiansheng Yang;Ajian Li;Yunjiang Lou;Ruikai Liu;Xiansheng Yang;Ajian Li;Yunjiang Lou",
        "authorids": "/37089658291;/37086799160;/37088599392;/37279072300;/37089658291;/37086799160;/37088599392;/37279072300",
        "aff": "State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981639/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3685129259942121767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechatronics Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982144",
        "title": "FloorGenT: Generative Vector Graphic Model of Floor Plans for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Floor plans are the basis of reasoning in and communicating about indoor environments. In this paper, we show that by modelling floor plans as sequences of line segments seen from a particular point of view, recent advances in autoregressive sequence modelling can be leveraged to model and predict floor plans. The line segments are canonicalized and translated to sequence of tokens and an attention-based neural network is used to fit a one-step distribution over next tokens. We fit the network to sequences derived from a set of large-scale floor plans, and demonstrate the capabilities of the model in four scenarios: novel floor plan generation, completion of partially observed floor plans, generation of floor plans from simulated sensor data, and finally, the applicability of a floor plan model in predicting the shortest distance with partial knowledge of the environment.",
        "primary_area": "",
        "author": "Ludvig Ericson;Patric Jensfelt;Ludvig Ericson;Patric Jensfelt",
        "authorids": "/37086215136;/37281289200;/37086215136;/37281289200",
        "aff": "Division of Robotics, Perception, and Learning, KTH Royal Institute of Technology; Division of Robotics, Perception, and Learning, KTH Royal Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982144/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1628380603772365339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception, and Learning",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9981148",
        "title": "Floorplan-Aware Camera Poses Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Processing large indoor scenes is a challenging task, as scan registration and camera trajectory estimation methods accumulate errors across time. As a result, the quality of reconstructed scans is insufficient for some applications, such as visual-based localization and navigation, where the correct position of walls is crucial. For many indoor scenes, there exists an image of a technical ftoorplan that contains information about the geometry and main structural elements of the scene, such as walls, partitions, and doors. We argue that such a ftoorplan is a useful source of spatial information, which can guide a 3D model optimization. The standard RGB-D 3D reconstruction pipeline consists of a tracking module applied to an RGB-D sequence and a bundle adjustment (BA) module that takes the posed RGB-D sequence and corrects the camera poses to improve consistency. We propose a novel optimization algorithm expanding conventional BA that leverages the prior knowledge about the scene structure in the form of a ftoorplan. Our experiments on the Redwood dataset and our self-captured data demonstrate that utilizing ftoorplan improves accuracy of 3D reconstructions.",
        "primary_area": "",
        "author": "Anna Sokolova;Filipp Nikitin;Anna Vorontsova;Anton Konushin;Anna Sokolova;Filipp Nikitin;Anna Vorontsova;Anton Konushin",
        "authorids": "/37086881293;/37088199223;/37086880204;/38306221200;/37086881293;/37088199223;/37086880204;/38306221200",
        "aff": "Samsung AI Center, Moscow, Russia; Samsung AI Center, Moscow, Russia; Samsung AI Center, Moscow, Russia; Samsung AI Center, Moscow, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981148/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5097529539955986523&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9981407",
        "title": "FlowBot: Flow-based Modeling for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation among people is a com-plex problem that also exhibits considerable variation depending on the type of environment and people involved. Here we consider navigation among crowds that exhibit flow-like behavior like people moving through a train station. We propose a novel pseudo-fluid model of crowd flow for such problems. These have an intuitive physical interpretation and do not require much tuning. We further formalize an observation model to infer flow properties from discrete sensor observations, including support for partial observability, and pair it with a flow-aware planner. We demonstrate the potential of the approach in simulated navigation scenarios. We achieve state of the art results on the CrowdBot navigation benchmark, and also compare favorably against a standard ROS planner on a partially observable environment, demonstrating that the flow-aware planner successfully estimates and plans around counter-flows in the crowd in real time. We conclude that flow-based planning shows great promise for crowded environments that may exhibit such flow-like behavior.",
        "primary_area": "",
        "author": "Daniel Dugas;Kuanqi Cai;Olov Andersson;Nicholas Lawrance;Roland Siegwart;Jen Jen Chung;Daniel Dugas;Kuanqi Cai;Olov Andersson;Nicholas Lawrance;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37086030360;/37086950580;/37085816587;/37571923900;/37281398300;/37085668354;/37086030360;/37086950580;/37085816587;/37571923900;/37281398300;/37085668354",
        "aff": "ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981407/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4536407128721567588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981047",
        "title": "FocusTR: Focusing on Valuable Feature by Multiple Transformers for Fusing Feature Pyramid on Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The feature pyramid, which is a vital component of the convolutional neural networks, plays a significant role in several perception tasks, including object detection for autonomous driving. However, how to better fuse multi-level and multi-sensor feature pyramids is still a significant challenge, especially for object detection. This paper presents a FocusTR (Focusing on the valuable features by multiple Transformers), which is a simple yet effective architecture, to fuse feature pyramid for the single-stream 2D detector and two-stream 3D detector. Specifically, FocusTR encompasses several novel self-attention mechanisms, including the spatial-wise boxAlign attention (SB) for low-level spatial locations, context-wise affinity attention (CA) for high-level context information, and level-wise attention for the multi-level feature. To alleviate self-attention's computational complexity and slow training convergence, Fo-cusTR introduces a low and high-level fusion (LHF) to reduce the computational parameters, and the Pre- Ln [1]to accelerate the training convergence.",
        "primary_area": "",
        "author": "Bangquan Xie;Liang Yang;Zongming Yang;Ailin Wei;Xiaoxiong Weng;Bing Li;Bangquan Xie;Liang Yang;Zongming Yang;Ailin Wei;Xiaoxiong Weng;Bing Li",
        "authorids": "/37089479613;/37085495533;/37089480564;/37089481312;/37086188826;/37405869400;/37089479613;/37085495533;/37089480564;/37089481312;/37086188826;/37405869400",
        "aff": "Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA; The City College of New York, New York, NY, USA; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA; Department of Bioengineering, Clemson University, Clemson, SC, USA; School of Civil Engineering and Transportation, South China University of Technology, Guangzhou, China; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981047/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7833497380591516442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Clemson University;City College of New York;South China University of Technology",
        "aff_unique_dep": "Department of Automotive Engineering;;School of Civil Engineering and Transportation",
        "aff_unique_url": "https://www.clemson.edu;https://www.ccny.cuny.edu;https://www.scut.edu.cn",
        "aff_unique_abbr": "Clemson;CCNY;SCUT",
        "aff_campus_unique_index": "0;1;0;2;3;0",
        "aff_campus_unique": "Greenville;New York;Clemson;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981031",
        "title": "Fold-based Complex Joints for a 3 DoF 3R Parallel Robot Design",
        "track": "main",
        "status": "Poster",
        "abstract": "This contribution demonstrates the usage of fold-based joints to create a novel 3 DoF 3R(RPaR) parallel robot design. Multiple folding mechanisms are introduced, fulfilling the function of revolute, prismatic, and spherical joints. Folding mechanisms are here tested regarding their applicability in parallel kinematic robots taking advantage of beneficial properties such as increased stiffness, flat-foldability and compressed states, easy cleaning as well as lightweight designs. The designed delta robot structure is then analysed for its motion behaviour, workspace dimensions and validated by a 3D printed model. Further, scalability possibilities are presented.",
        "primary_area": "",
        "author": "Judith U. Merz;Markus M. Huber;Franz Irlinger;Tim C. Lueth;Janik Pfitzner;Burkhard Corves;Judith U. Merz;Markus M. Huber;Franz Irlinger;Tim C. Lueth;Janik Pfitzner;Burkhard Corves",
        "authorids": "/37086445571;/37089658190;/37601829900;/37389804500;/37089659760;/37712488900;/37086445571;/37089658190;/37601829900;/37389804500;/37089659760;/37712488900",
        "aff": "Institute of Mechanism Theory, Machine Dynamics and Robtics (IGMR), RWTH Aachen University, Aachen, Germany; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Garching; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Garching; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Garching; Institute of Mechanism Theory, Machine Dynamics and Robtics (IGMR), RWTH Aachen University, Aachen, Germany; Institute of Mechanism Theory, Machine Dynamics and Robtics (IGMR), RWTH Aachen University, Aachen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981031/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11152933218662366781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;0",
        "aff_unique_norm": "RWTH Aachen University;Technical University of Munich",
        "aff_unique_dep": "Institute of Mechanism Theory, Machine Dynamics and Robotics (IGMR);Institute of Micro Technology and Medical Device Technology (MIMED)",
        "aff_unique_url": "https://www.rwth-aachen.de;https://www.tum.de",
        "aff_unique_abbr": "RWTH;TUM",
        "aff_campus_unique_index": "0;1;1;1;0;0",
        "aff_campus_unique": "Aachen;Garching",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981363",
        "title": "Folding Knots Using a Team of Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "From ancient times, humans have been using cables and ropes to tie, carry, and manipulate objects by folding knots. However, automating knot folding is challenging because it requires dexterity to move a cable over and under itself. In this paper, we propose a method to fold knots in midair using a team of aerial vehicles. We take advantage of the fact that vehicles are able to fly in between cable segments without any re-grasping. So the team grasps the cable from the floor, and releases it once the knot is folded. Based on a composition of catenary curves, we simplify the complexity of dealing with an infinite-dimensional configuration space of the cable, and formally propose a new knot representation. Such representation allows us to design a trajectory that can be used to fold knots using a leader-follower approach. We show that our method works for different types of knots in simulations. Additionally, we show that our solution is also computationally efficient and can be executed in real-time.",
        "primary_area": "",
        "author": "Diego S. D\u2019Antonio;David Salda\u00f1a;Diego S. D\u2019Antonio;David Salda\u00f1a",
        "authorids": "/37088760719;/38543033800;/37088760719;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory -AIRLab-at Lehigh University, Bethlehem, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab-at Lehigh University, Bethlehem, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981363/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=335038180040836713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bethlehem",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981065",
        "title": "Foot-operated Tele-impedance Interface for Robot Manipulation Tasks in Interaction with Unpredictable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Tele-impedance increases interaction performance between a robotic tool and unstructured/unpredictable en-vironments during teleoperation. However, the existing tele-impedance interfaces have several ongoing issues, such as long calibration times and various obstructions for the human operator. In addition, they are all designed to be controlled by the operator's arms, which can cause difficulties when both arms are used, as in bi-manual teleoperation. To resolve these issues, we designed a novel foot-based tele-impedance control method inspired by the human limb stiffness ellipse modulation. The proposed mechanical interface design includes a disc and a foot pressure sensor that controls the orientation and size/shape of the stiffness ellipse, respectively. We evaluated the disc interface control method in an experimental study with 12 participants, who performed a complex drilling task in a virtual environment. The results show the ability of the operator to use the proposed interface in order to dynamically adapt to different phases of the task and changes in the environment. In addition, a comparison with low and high uniform impedance modes demonstrates a superior interaction performance of the proposed method.",
        "primary_area": "",
        "author": "Stijn Klevering;Winfred Mugge;David A. Abbink;Luka Peternel;Stijn Klevering;Winfred Mugge;David A. Abbink;Luka Peternel",
        "authorids": "/37089660237;/37828962200;/37297782000;/37077670700;/37089660237;/37828962200;/37297782000;/37077670700",
        "aff": "Cognitive Robotics and Biomechanical Engineering departments, Delft University of Technology, Delft, The Netherlands; Cognitive Robotics and Biomechanical Engineering departments, Delft University of Technology, Delft, The Netherlands; Cognitive Robotics and Biomechanical Engineering departments, Delft University of Technology, Delft, The Netherlands; Cognitive Robotics and Biomechanical Engineering departments, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981065/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3178260341924948061&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Cognitive Robotics and Biomechanical Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9981393",
        "title": "Force-Guided Alignment and File Feedrate Control for Robot-Assisted Endodontic Treatment",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the precise manipulations required in dental surgery, robotic technologies have been applied to dentistry. So far, most dental robots are designed for implant surgery, helping dentists accurately place the implant to the desired position and depth. This paper presents the DentiBot, the first robot designed for dental endodontic treatment. Without visual feedback, the DentiBot is integrated with a force and torque sensor to monitor the contact between the root canal and endodontic file. Additionally, DentiBot is implemented with force-guided alignment and file feedrate control to autonomously adjust surgical path and compensate for patient movement in real-time while protecting against endodontic file fracture. The feasibility of robot-assisted endodontic treatment is verified by the pre-clinical evaluation performed on acrylic root canal models.",
        "primary_area": "",
        "author": "Hao-Fang Cheng;Yi-Chan Li;Yi-Ching Ho;Cheng-Wei Chen;Hao-Fang Cheng;Yi-Chan Li;Yi-Ching Ho;Cheng-Wei Chen",
        "authorids": "/37089660658;/37086489534;/37089661550;/38026044800;/37089660658;/37086489534;/37089661550;/38026044800",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Dentistry, National Yang Ming Chiao Tung University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981393/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17507609206201816858&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Taiwan University;National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Dentistry",
        "aff_unique_url": "https://www.ntu.edu.tw;https://www.nycu.edu.tw",
        "aff_unique_abbr": "NTU;NYCU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981401",
        "title": "Forest Traversability Mapping (FTM): Traversability estimation using 3D voxel-based Normal Distributed Transform to enable forest navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in dense vegetation remains an open challenge and is an area of major interest for the research community. In this paper we propose a novel traversability estimation method, the Forest Traversability Map, that gives autonomous ground vehicles the ability to navigate in harsh forests or densely vegetated environments. The method estimates travers ability in unstructured environments dominated by vegetation, void of any dominant human structures, gravel or dirt roads, with higher accuracy than the state of the art: we demonstrate an improvement of over 20% F1 score (from 0.71 to 0.91) on challenging real-world data. Our method is based on 3D voxel representation and introduces a robust colour fusion method to overcome occlusion and frequent changes of lighting conditions in these environments. We also introduce and fuse multi-return lidar measurements into our probabilistic map representation in a recursive manner. Finally, we include information of neighboring voxels to increase our ability to assess the terrain travers ability correctly. These measures improve the state-of-the-art results and allow for effective traversability estimation in very challenging, densely vegetated environments.",
        "primary_area": "",
        "author": "Fabio Ruetz;Paulo Borges;Niko Suenderhauf;Emili Hern\u00e1ndez;Thierry Peynot;Fabio Ruetz;Paulo Borges;Niko Suenderhauf;Emili Hern\u00e1ndez;Thierry Peynot",
        "authorids": "/37085790996;/37546547800;/37086454107;/37089548277;/38321139400;/37085790996;/37546547800;/37086454107;/37089548277;/38321139400",
        "aff": "Robotics and Autonomous Systems Group (RASG), CSIRO, Pullenvale, QLD, Australia; Robotics and Autonomous Systems Group (RASG), CSIRO, Pullenvale, QLD, Australia; QUT Centre for Robotics, Queensland University of Technology (QUT), Brisbane, Australia; Emesent, Milton, QLD, Australia; QUT Centre for Robotics, Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981401/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6251327496814725830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "CSIRO;Queensland University of Technology;Emesent",
        "aff_unique_dep": "Robotics and Autonomous Systems Group (RASG);Centre for Robotics;",
        "aff_unique_url": "https://www.csiro.au;https://www.qut.edu.au;",
        "aff_unique_abbr": "CSIRO;QUT;",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Pullenvale;Brisbane;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981593",
        "title": "From Human Walking to Bipedal Robot Locomotion: Reflex Inspired Compensation on Planned and Unplanned Downsteps",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans are able to negotiate downstep behaviors-both planned and unplanned-with remarkable agility and ease. The goal of this paper is to systematically study the translation of this human behavior to bipedal walking robots, even if the morphology is inherently different. Concretely, we begin with human data wherein planned and unplanned downsteps are taken. We analyze this data from the perspective of reduced-order modelling of the human, encoding the center of mass (CoM) kinematics and contact forces, which allows for the translation of these behaviors into the corresponding reduced-order model of a bipedal robot. We embed the resulting behaviors into the full-order dynamics of a bipedal robot via nonlinear optimization-based controllers. The end result is the demonstration of planned and unplanned downsteps in simulation on an underactuated walking robot.",
        "primary_area": "",
        "author": "Joris Verhagen;Xiaobin Xiong;Aaron D. Ames;Ajay Seth;Joris Verhagen;Xiaobin Xiong;Aaron D. Ames;Ajay Seth",
        "authorids": "/37089658794;/37086275102;/37300877900;/37089577110;/37089658794;/37086275102;/37300877900;/37089577110",
        "aff": "Faculty of Mechanical, Maritime, and Materials Engineering (3ME) and with the faculty of Biomechanical Engineering, Delft University of Technology, CD Delft, The Netherlands; Department of Civil and Mechanical Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Civil and Mechanical Engineering, California Institute of Technology, Pasadena, CA, USA; Faculty of Mechanical, Maritime, and Materials Engineering (3ME) and with the faculty of Biomechanical Engineering, Delft University of Technology, CD Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981593/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1143041956547312461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Delft University of Technology;California Institute of Technology",
        "aff_unique_dep": "Faculty of Mechanical, Maritime, and Materials Engineering (3ME);Department of Civil and Mechanical Engineering",
        "aff_unique_url": "https://www.tudelft.nl;https://www.caltech.edu",
        "aff_unique_abbr": "TUDelft;Caltech",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Delft;Pasadena",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Netherlands;United States"
    },
    {
        "id": "9982284",
        "title": "From Local to Holistic: Self-supervised Single Image 3D Face Reconstruction Via Multi-level Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Single image 3D face reconstruction with accurate geometric details is a critical and challenging task due to the similar appearance on the face surface and fine details in organs. In this work, we introduce a self-supervised 3D face reconstruction approach from a single image that can recover detailed textures under different camera settings. The proposed network learns high-quality disparity maps from stereo face images during the training stage, while just a single face image is required to generate the 3D model in real applications. To recover fine details of each organ and facial surface, the framework introduces facial landmark spatial consistency to constrain the face recovering learning process in local point level and segmentation scheme on facial organs to constrain the correspondences at the organ level. The face shape and textures will further be refined by establishing holistic constraints based on the varying light illumination and shading information. The proposed learning framework can recover more accurate 3D facial details both quantitatively and qualitatively compared with state-of-the-art 3DMM and geometry-based reconstruction algorithms based on a single image.",
        "primary_area": "",
        "author": "Yawen Lu;Michel Sarkis;Ning Bi;Guoyu Lu;Yawen Lu;Michel Sarkis;Ning Bi;Guoyu Lu",
        "authorids": "/37087243817;/37295019000;/37087438323;/37086529299;/37087243817;/37295019000;/37087438323;/37086529299",
        "aff": "Rochester Institute of Technology (RIT); Qualcomm Technologies Inc.; Qualcomm Technologies Inc.; University of Georgia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982284/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7963183949440804587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Rochester Institute of Technology;Qualcomm Technologies Inc.;University of Georgia",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.rit.edu;https://www.qualcomm.com;https://www.uga.edu",
        "aff_unique_abbr": "RIT;QTI;UGA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981275",
        "title": "From Timing Variations to Performance Degradation: Understanding and Mitigating the Impact of Software Execution Timing in SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Timing is an important property for robotic systems that continuously interact with our physical world. Variation in program execution time caused by limited computational resources or system resource contention can lead to significant impact on algorithmic result accuracy. Even though recent work has found Simultaneous Localization And Mapping (SLAM) to be timing-sensitive, little exists in understanding the interactions between the timing variations in SLAM systems and the corresponding degradation. In this paper we conduct a systematic analysis of nine state-of-the-art SLAM systems and dissect the root causes of their degradation. We discovered that timing-induced errors are generated either from delayed execution in certain critical tasks, or from desynchronization in sensor fusion. Based on the insights from our analysis, we propose a solution that combines selective fusion on data in the front end and temporal budget optimization on bundle adjust-ment in the backend to mitigate the impacts of unexpected timing variation adaptively. Experimental results show that our proposed method makes it possible to migrate expensive algorithms to low-cost platforms without laborious tuning, while making the SLAM system robust against the effects of abnormal timing.",
        "primary_area": "",
        "author": "Ao Li;Han Liu;Jinwen Wang;Ning Zhang;Ao Li;Han Liu;Jinwen Wang;Ning Zhang",
        "authorids": "/37089463420;/37089658326;/37089465802;/37710689000;/37089463420;/37089658326;/37089465802;/37710689000",
        "aff": "Department of Computer Science and Engineering, Washington University in St. Louis, MO, USA; Department of Computer Science and Engineering, Washington University in St. Louis, MO, USA; Department of Computer Science and Engineering, Washington University in St. Louis, MO, USA; Department of Computer Science and Engineering, Washington University in St. Louis, MO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981275/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16970171431903927095&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Washington University in St. Louis",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://wustl.edu",
        "aff_unique_abbr": "WashU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "St. Louis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981339",
        "title": "Fully Convolutional Transformer with Local-Global Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "In an attempt to imitate the success of transformers in the field of natural language processing into computer vision tasks, vision transformers (ViTs) have recently gained attention. Performance breakthroughs have been achieved in coarse-grained tasks like classification. However, dense prediction tasks, such as detection, segmentation, and depth estimation, require additional modifications and have been tackled only in an ad-hoc manner, by replacing the convolutional neural network encoder backbone of an existing architecture with a ViT. This study proposes a fully convolutional transformer that can perform both coarse and dense prediction tasks. The proposed architecture is, to the best of our knowledge, the first architecture composed of attention layers, even in the decoder part of the network. This is because our newly proposed local-global attention (LGA) can flexibly perform both downsampling and upsampling of spatial features, which are key operations required for dense prediction. Against existing ViTs on classification tasks, our architecture shows a reasonable trade-off between performance and efficiency. In the depth estimation task, our architecture achieves performance comparable to that of state-of-the-art transformer-based methods.",
        "primary_area": "",
        "author": "Sihaeng Lee;Eojindl Yi;Janghyeon Lee;Jinsu Yoo;Honglak Lee;Seung Hwan Kim;Sihaeng Lee;Eojindl Yi;Janghyeon Lee;Jinsu Yoo;Honglak Lee;Seung Hwan Kim",
        "authorids": "/37085492803;/37088689760;/37089262923;/37089661544;/38240379200;/37089776940;/37085492803;/37088689760;/37089262923;/37089661544;/38240379200;/37089776940",
        "aff": "Vision Lab, LG AI Research, Seoul, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; Vision Lab, LG AI Research, Seoul, South Korea; Department of Artificial Intelligence, Hanyang University, Seoul, South Korea; Faculty of the Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA; Vision Lab, LG AI Research, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981339/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12990008261412584289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;0",
        "aff_unique_norm": "LG;KAIST;Hanyang University;University of Michigan",
        "aff_unique_dep": "Vision Lab;School of Electrical Engineering;Department of Artificial Intelligence;Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.lgaires.com;https://www.kaist.ac.kr;http://www.hanyang.ac.kr;https://www.umich.edu",
        "aff_unique_abbr": "LG AI;KAIST;HYU;UM",
        "aff_campus_unique_index": "0;1;0;0;2;0",
        "aff_campus_unique": "Seoul;Daejeon;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9982119",
        "title": "FusionPortable: A Multi-Sensor Campus-Scene Dataset for Evaluation of Localization and Mapping Accuracy on Diverse Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "Combining multiple sensors enables a robot to maximize its perceptual awareness of environments and enhance its robustness to external disturbance, crucial to robotic navigation. This paper proposes the FusionPortable benchmark, a complete multi-sensor dataset with a diverse set of sequences for mobile robots. This paper presents three contributions. We first advance a portable and versatile multi-sensor suite that offers rich sensory measurements: 10Hz LiDAR point clouds, 20Hz stereo frame images, high-rate and asynchronous events from stereo event cameras, 200Hz inertial readings from an IMU, and 10Hz GPS signal. Sensors are already temporally synchronized in hardware. This device is lightweight, self-contained, and has plug-and-play support for mobile robots. Second, we construct a dataset by collecting 17 sequences that cover a variety of environments on the campus by exploiting multiple robot platforms for data collection. Some sequences are challenging to existing SLAM algorithms. Third, we provide ground truth for the decouple localization and mapping performance evaluation. We additionally evaluate state-of-the-art SLAM approaches and identify their limitations. The dataset, consisting of raw sensor measurements, ground truth, calibration data, and evaluated algorithms, will be released.",
        "primary_area": "",
        "author": "Jianhao Jiao;Hexiang Wei;Tianshuai Hu;Xiangcheng Hu;Yilong Zhu;Zhijian He;Jin Wu;Jingwen Yu;Xupeng Xie;Huaiyang Huang;Ruoyu Geng;Lujia Wang;Ming Liu;Jianhao Jiao;Hexiang Wei;Tianshuai Hu;Xiangcheng Hu;Yilong Zhu;Zhijian He;Jin Wu;Jingwen Yu;Xupeng Xie;Huaiyang Huang;Ruoyu Geng;Lujia Wang;Ming Liu",
        "authorids": "/37086552343;/37089658806;/37089660602;/37088955818;/37086964447;/37085684905;/37085846883;/37089658182;/37088810166;/37087103064;/37089001275;/37406752700;/37085398677;/37086552343;/37089658806;/37089660602;/37088955818;/37086964447;/37085684905;/37085846883;/37089658182;/37088810166;/37087103064;/37089001275;/37406752700;/37085398677",
        "aff": "Clear Water Bay Institute of Autonomous Driving, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; Clear Water Bay Institute of Autonomous Driving, Hong Kong, China; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982119/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8031120123397257959&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;1;1;1;1;1;1;2;1;1;1;0;1",
        "aff_unique_norm": "Clear Water Bay Institute of Autonomous Driving;Hong Kong University of Science and Technology;Southern University of Science and Technology",
        "aff_unique_dep": ";;Department of Electronic and Electrical Engineering",
        "aff_unique_url": ";https://www.ust.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": ";HKUST;SUSTech",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;2;1;1;1;0;2",
        "aff_campus_unique": "Clear Water Bay;Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981499",
        "title": "GE-Grasp: Efficient Target-Oriented Grasping in Dense Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping in dense clutter is a fundamental skill for autonomous robots. However, the crowdedness and oc-clusions in the cluttered scenario cause significant difficul-ties to generate valid grasp poses without collisions, which results in low efficiency and high failure rates. To address these, we present a generic framework called GE-Grasp for robotic motion planning in dense clutter, where we leverage diverse action primitives for occluded object removal and present the generator-evaluator architecture to avoid spatial collisions. Therefore, our GE-Grasp is capable of grasping objects in dense clutter efficiently with promising success rates. Specifically, we define three action primitives: target-oriented grasping for target capturing, pushing, and nontarget-oriented grasping to reduce the crowdedness and occlusions. The gen-erators effectively provide various action candidates referring to the spatial information. Meanwhile, the evaluators assess the selected action primitive candidates, where the optimal action is implemented by the robot. Extensive experiments in simulated and real-world environments show that our approach outperforms the state-of-the-art methods of grasping in clutter with respect to motion efficiency and success rates. Moreover, we achieve comparable performance in the real world as that in the simulation environment, which indicates the strong gen-eralization ability of our GE-Grasp. Supplementary material is available at: https://github.com/CaptainWuDaoKou/GE-Grasp.",
        "primary_area": "",
        "author": "Zhan Liu;Ziwei Wang;Sichao Huang;Jie Zhou;Jiwen Lu;Zhan Liu;Ziwei Wang;Sichao Huang;Jie Zhou;Jiwen Lu",
        "authorids": "/37089658593;/37086179280;/37089614130;/37278266700;/37404390100;/37089658593;/37086179280;/37089614130;/37278266700;/37404390100",
        "aff": "Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981499/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9278272752694317490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982138",
        "title": "GESRsim: Gastrointestinal Endoscopic Surgical Robot Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted gastrointestinal endoscopic surgery (GES) as a kind of natural orifice transluminal endoscopic surgery (NOTES) is the next-generation minimally invasive surgery (MIS). Besides, rendering certain autonomy to a Gas-trointestinal Endoscopic Surgical Robot (GESR) is promising but highly challenging. Therefore, to accelerate the development and augment the autonomy of GESR, we use CoppeliaSim to develop the first robotic simulator for the GESR system (GESRsim) based on our previous design. The GESRsim provides several 3D models and kinematics of our designed manipulators and endoscopic snake bone. Additionally, we build several scenes for robotic GES training and then utilize different programming interfaces to perform teleoperation. Furthermore, several advanced control algorithms, including visual servoing (VS) and deep reinforcement learning (DRL), are implemented to verify the performance of the GESRsim.",
        "primary_area": "",
        "author": "Huxin Gao;Zedong Zhang;Changsheng Li;Xiao Xiao;Liang Qiu;Xiaoxiao Yang;Ruoyi Hao;Xiuli Zuo;Yanqing Li;Hongliang Ren;Huxin Gao;Zedong Zhang;Changsheng Li;Xiao Xiao;Liang Qiu;Xiaoxiao Yang;Ruoyi Hao;Xiuli Zuo;Yanqing Li;Hongliang Ren",
        "authorids": "/37088379696;/37089658551;/37086224774;/37086545706;/37086564321;/37089659397;/37089662910;/37088874430;/37088872949;/37287561300;/37088379696;/37089658551;/37086224774;/37086545706;/37086564321;/37089659397;/37089662910;/37088874430;/37088872949;/37287561300",
        "aff": "NUS (Suzhou) Research Institute, Suzhou, China; NUS (Suzhou) Research Institute, Suzhou, China; School of Mechatronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hongkong, China; Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, China; Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, China; NUS (Suzhou) Research Institute, Suzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982138/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17510920161154137642&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;2;3;4;5;4;4;0",
        "aff_unique_norm": "National University of Singapore;Beijing Institute of Technology;Southern University of Science and Technology;Agency for Science, Technology and Research;Shandong University;Chinese University of Hong Kong",
        "aff_unique_dep": "Research Institute;School of Mechatronic Engineering;Department of Electrical and Electronic Engineering;Institute for Infocomm Research;Department of Gastroenterology;Department of Electronic Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;http://www.bit.edu.cn;https://www.sustech.edu.cn;https://www.a-star.edu.sg;http://www.sdu.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUS;BIT;SUSTech;A*STAR;SDU;CUHK",
        "aff_campus_unique_index": "0;0;1;2;4;5;4;4;0",
        "aff_campus_unique": "Suzhou;Beijing;Shenzhen;;Jinan;Hong Kong",
        "aff_country_unique_index": "0;0;1;1;0;1;1;1;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9982026",
        "title": "GPU-Parallelized Iterative LQR with Input Constraints for Fast Collision Avoidance of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision avoidance in emergency situations is a crucial and challenging task in motion planning for autonomous vehicles. Especially in the field of optimization-based planning using nonlinear model predictive control, many efforts to achieve real-time performance are still ongoing. Among various approaches, the iterative linear quadratic regulator (iLQR) is known as an efficient means of nonlinear optimization. Additionally, parallel computing architectures, such as GPUs, are more widely applied in autonomous vehicles. In this paper, we propose 1) a parallel computing framework for iLQR with input constraints considering the characteristics of the problem and 2) a proper environmental formulation that can be covered with single-precision floating-point computation of the GPU. The GPU-accelerated framework was tested on a real-time simulation-in-the-loop system using CarMaker and ROS at a 20 Hz sampling rate on a low-performance mobile computer and was compared against the same framework realized with a CPU.",
        "primary_area": "",
        "author": "Yeongseok Lee;Minsu Cho;Kyung-Soo Kim;Yeongseok Lee;Minsu Cho;Kyung-Soo Kim",
        "authorids": "/37088924577;/37089479516;/37292681500;/37088924577;/37089479516;/37292681500",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982026/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12504572902064819289&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981976",
        "title": "GaSLAM: An Algorithm for Simultaneous Gas Source Localization and Gas Distribution Mapping in 3D",
        "track": "main",
        "status": "Poster",
        "abstract": "Chemical gas dispersion poses considerable threat to humans, animals and the environment. The research areas of gas source localization and gas distribution mapping aim to localize the source of gas leaks and map the gas plume respectively, in order to help the coordination of swift rescue missions. Although very similar, these two areas are often treated separately in literature. In some cases, inferences on the gas distribution are made a posteriori from the source location, or vice-versa. In this paper, we introduce GaSLAM, a methodology that couples the estimation of the gas map and the source location using two state of the art algorithms with a novel navigation strategy based on informative quantities. The synergistic approach allows our algorithm to achieve a good estimation of both objectives and push the navigation strategies towards informative areas of the experimental volume. We validate the algorithm in simulation and with physical experiments in varying environmental conditions. We show that the algorithm improves on the source location estimate compared to a similar approach found in literature, and is able to deliver good quality maps of the gas distribution.",
        "primary_area": "",
        "author": "Chiara Ercolani;Lixuan Tang;Alcherio Martinoli;Chiara Ercolani;Lixuan Tang;Alcherio Martinoli",
        "authorids": "/37086574560;/37089338015;/37325252600;/37086574560;/37089338015;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981976/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7398623477854567763&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981725",
        "title": "Gastrocnemius and Power Amplifier Soleus Spring-Tendons Achieve Fast Human-like Walking in a Bipedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged locomotion in humans is governed by natural dynamics of the human body and neural control. One mechanism that is assumed to contribute to the high efficiency of human walking is the impulsive ankle push-off, which potentially powers the swing leg catapult. However, the mechanics of the human lower leg with its complex muscle-tendon units spanning over single and multiple joints is not yet understood. Legged robots allow testing the interaction between complex leg mechanics, control, and environment in real-world walking gait. We developed a 0.49 m tall, 2.2 kg anthropomorphic bipedal robot with Soleus and Gastrocnemius muscle-tendon units represented by linear springs, acting as mono- and biarticular elastic structures around the robot's ankle and knee joints. We tested the influence of three Soleus and Gastrocnemius spring-tendon configurations on the ankle power curves, the coordination of the ankle and knee joint movements, the total cost of transport, and walking speed. We controlled the robot with a feed-forward central pattern generator, leading to walking speeds between 0.35 m/s and 0.57 m/s at 1.0 Hz locomotion frequency, at 0.35 m leg length. We found differences between all three configurations; the Soleus spring-tendon modulates the robot's speed and energy efficiency likely by ankle power amplification, while the Gastrocnemius spring-tendon changes the movement coordination between ankle and knee joints during push-off.",
        "primary_area": "",
        "author": "Bernadett Kiss;Emre Cemal Gonen;An Mo;Alexander Badri\u2013Spr\u00f6witz;Alexandra Buchmann;Daniel Renjewski;Bernadett Kiss;Emre Cemal Gonen;An Mo;Alexander Badri\u2013Spr\u00f6witz;Alexandra Buchmann;Daniel Renjewski",
        "authorids": "/37089663558;/37086919378;/37089658196;/37088340110;/37089661578;/37394272300;/37089663558;/37086919378;/37089658196;/37088340110;/37089661578;/37394272300",
        "aff": "Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Department of Mechanical Engineering, Chair of Applied Mechanics, TUM School of Engineering & Design, Technical University of Munich, Garching near Munich, Germany; Department of Mechanical Engineering, Chair of Applied Mechanics, TUM School of Engineering & Design, Technical University of Munich, Garching near Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981725/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12311568622186306891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Technical University of Munich",
        "aff_unique_dep": "Dynamic Locomotion Group;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.tum.de",
        "aff_unique_abbr": "MPI-IS;TUM",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "Stuttgart;Garching near Munich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982256",
        "title": "Gathering Physical Particles with a Global Magnetic Field Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "For biomedical applications in targeted therapy delivery and interventions, a large swarm of micro-scale particles (\u201cagents\u201d) has to be moved through a maze-like environment (\u201cvascular system\u201d) to a target region (\u201ctumor\u201d). Due to limited on-board capabilities, these agents cannot move autonomously; instead, they are controlled by an external global force that acts uniformly on all particles. In this work, we demonstrate how to use a time-varying magnetic field to gather particles to a desired location. We use reinforcement learning to train networks to efficiently gather particles. Methods to overcome the simulation-to-reality gap are explained, and the trained networks are deployed on a set of mazes and goal locations. The hardware experiments demonstrate fast convergence, and robustness to both sensor and actuation noise. To encourage extensions and to serve as a benchmark for the reinforcement learning community, the code is available at Github.",
        "primary_area": "",
        "author": "Matthias Konitzny;Yitong Lu;Julien Leclerc;S\u00e1ndor P. Fekete;Aaron T. Becker;Matthias Konitzny;Yitong Lu;Julien Leclerc;S\u00e1ndor P. Fekete;Aaron T. Becker",
        "authorids": "/37089658850;/37088686719;/38246174500;/37300461000;/37588897100;/37089658850;/37088686719;/38246174500;/37300461000;/37588897100",
        "aff": "Department of Computer Science, TU Braunschweig, Germany; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Computer Science, TU Braunschweig, Germany; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982256/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12887986429814324875&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "TU Braunschweig;University of Houston",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://tu-braunschweig.de;https://www.uh.edu",
        "aff_unique_abbr": "TUBS;UH",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Houston",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9981520",
        "title": "Gaussian Variational Inference with Covariance Constraints Applied to Range-only Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and reliable state estimation is becoming increasingly important as robots venture into the real world. Gaussian variational inference (GVI) is a promising alternative for nonlinear state estimation, which estimates a full probability density for the posterior instead of a point estimate as in maximum a posteriori (MAP)-based approaches. GVI works by optimizing for the parameters of a multivariate Gaussian (MVG) that best agree with the observed data. However, such an optimization procedure must ensure the parameter constraints of a MVG are satisfied; in particular, the inverse covariance matrix must be positive definite. In this work, we propose a tractable algorithm for performing state estimation using GVI that guarantees that the inverse covariance matrix remains positive definite and is well-conditioned throughout the optimization procedure. We evaluate our method extensively in both simulation and real-world experiments for range-only localization. Our results show GVI is consistent on this problem, while MAP is over-confident.",
        "primary_area": "",
        "author": "Abhishek Goudar;Wenda Zhao;Timothy D. Barfoot;Angela P. Schoellig;Abhishek Goudar;Wenda Zhao;Timothy D. Barfoot;Angela P. Schoellig",
        "authorids": "/37089198200;/37088814322;/37283734000;/38488605800;/37089198200;/37088814322;/37283734000;/38488605800",
        "aff": "Vector Institute for Artificial Intelligence in Toronto; Vector Institute for Artificial Intelligence in Toronto; Vector Institute for Artificial Intelligence in Toronto; Vector Institute for Artificial Intelligence in Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981520/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12441015387035113703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Vector Institute for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://vectorinstitute.ai",
        "aff_unique_abbr": "Vector Institute",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982036",
        "title": "Gazebo Fluids: SPH-based simulation of fluid interaction with articulated rigid body dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical simulation is an indispensable component of robotics simulation platforms that serves as the basis for a plethora of research directions. Looking strictly at robotics, the common characteristic of the most popular physics engines, such as ODE, DART, MuJoCo, bullet, SimBody, PhysX or RaiSim, is that they focus on the solution of articulated rigid bodies with collisions and contacts problems, while paying less attention to other physical phenomena. This restriction limits the range of addressable simulation problems, rendering applications such as soft robotics, cloth simulation, simulation of viscoelastic materials, and fluid dynamics, especially surface swimming, infeasible. In this work, we present Gazebo Fluids, an open-source extension of the popular Gazebo robotics simulator that enables the interaction of articulated rigid body dynamics with particle-based fluid and deformable solid simulation. We implement fluid dynamics and highly viscous and elastic material simulation capabilities based on the Smoothed Particle Hydrodynamics method. We demonstrate the practical impact of this extension for previously infeasible application scenarios in a series of experiments, showcasing one of the first self-propelled robot swimming simulations with SPH in a robotics simulator.",
        "primary_area": "",
        "author": "Emmanouil Angelidis;Jan Bender;Jonathan Arreguit;Lars Gleim;Wei Wang;Cristian Axenie;Alois Knoll;Auke Ijspeert;Emmanouil Angelidis;Jan Bender;Jonathan Arreguit;Lars Gleim;Wei Wang;Cristian Axenie;Alois Knoll;Auke Ijspeert",
        "authorids": "/37088825719;/37086046324;/37086600379;/37088208936;/37089663926;/37546824200;/37276234100;/37268732300;/37088825719;/37086046324;/37086600379;/37088208936;/37089663926;/37546824200;/37276234100;/37268732300",
        "aff": "Huawei Technologies Munich Research Center, Munich, Germany; RWTH Aachen University, Aachen, Germany; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Huawei Technologies Munich Research Center, Munich, Germany; Huawei Technologies Munich Research Center, Munich, Germany; Huawei Technologies Munich Research Center, Munich, Germany; Technical University of Munich, Munich, Germany; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982036/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8311764784173474800&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;0;3;2",
        "aff_unique_norm": "Huawei;RWTH Aachen University;EPFL;Technical University of Munich",
        "aff_unique_dep": "Munich Research Center;;;",
        "aff_unique_url": "https://www.huawei.com;https://www.rwth-aachen.de;https://www.epfl.ch;https://www.tum.de",
        "aff_unique_abbr": "Huawei;RWTH;EPFL;TUM",
        "aff_campus_unique_index": "0;1;2;0;0;0;0;2",
        "aff_campus_unique": "Munich;Aachen;Lausanne",
        "aff_country_unique_index": "0;0;1;0;0;0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9981096",
        "title": "Generalizability Analysis of Graph-based Trajectory Predictor with Vectorized Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory prediction is one of the essential tasks for autonomous vehicles. Recent progress in machine learning gave birth to a series of advanced trajectory prediction algorithms. Lately, the effectiveness of using graph neural networks (GNNs) with vectorized representations for trajec-tory prediction has been demonstrated by many researchers. Nonetheless, these algorithms either pay little attention to models' generalizability across various scenarios or simply assume training and test data follow similar statistics. In fact, when test scenarios are unseen or Out-of-Distribution (OOD), the resulting train-test domain shift usually leads to significant degradation in prediction performance, which will impact downstream modules and eventually lead to severe accidents. Therefore, it is of great importance to thoroughly investigation of the prediction models in terms of their generalizability, which can not only help identify their weaknesses but also provide insights on how to improve these models. This paper proposes a generalizability analysis framework using feature attribution methods to help interpret black-box models. For the case study, we provide an in-depth generalizability analysis of one of the state-of-the-art graph-based trajectory predictors that utilize vectorized representation. Results show significant performance degradation due to domain shift, and feature attribution provides insights to identify potential causes of these problems. Finally, we conclude the common prediction challenges and how weighting biases induced by the training process can deteriorate the accuracy.",
        "primary_area": "",
        "author": "Juanwu Lu;Wei Zhan;Masayoshi Tomizuka;Yeping Hu;Juanwu Lu;Wei Zhan;Masayoshi Tomizuka;Yeping Hu",
        "authorids": "/37089661682;/37067099600;/37281933000;/37086307227;/37089661682;/37067099600;/37281933000;/37086307227",
        "aff": "Department of Civil and Environmental Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981096/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5156222515942416831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982086",
        "title": "Generalized Laplace Particle Filter on Lie Groups Applied to Ambiguous Doppler Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Particle filters are suited to solve nonlinear and non-Gaussian estimation problems which find numerous applications in autonomous systems navigation. Previous works on Laplace Particle Filter on Lie groups (LG-LPF) demonstrated its robustness and accuracy on challenging navigation scenarios compared to classic particle filters. Nevertheless, LG-LPF is applicable when the prior probability density and the likelihood have a predominant mode, which narrows the scope of applications of this method. Thus, this paper proposes a generalized strategy to use LG-LPF while keeping its benefits. The core idea is to compute an accurate multimodal importance function based on local optimizations and resample the particles accordingly. This approach is compared to a Laplace Particle Filter (LPF) designed in the Euclidean space, on a UAV navigation scenario with ambiguous Doppler measurements. The Lie group approach shows improved accuracy and robustness in every case, even with a reduced number of particles.",
        "primary_area": "",
        "author": "Cl\u00e9ment Chahbazian;Nicolas Merlinge;Karim Dahia;B\u00e9n\u00e9dicte Winter-Bonnet;Aur\u00e9lien Blanc;Christian Musso;Cl\u00e9ment Chahbazian;Nicolas Merlinge;Karim Dahia;B\u00e9n\u00e9dicte Winter-Bonnet;Aur\u00e9lien Blanc;Christian Musso",
        "authorids": "/37088688916;/37086327173;/37085747099;/37089176032;/37089662928;/37328439900;/37088688916;/37086327173;/37085747099;/37089176032;/37089662928;/37328439900",
        "aff": "Information Processing and Systems department, ONERA, the French Aerospace Lab, Palaiseau, France; Information Processing and Systems department, ONERA, the French Aerospace Lab, Palaiseau, France; Information Processing and Systems department, ONERA, the French Aerospace Lab, Palaiseau, France; dpt. of Guidance Control and Navigation, MBDA France, Le Plessis Robinson, France; dpt. of Guidance Control and Navigation, MBDA France, Le Plessis Robinson, France; Information Processing and Systems department, ONERA, the French Aerospace Lab, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982086/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2447290591258752243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "ONERA;MBDA France",
        "aff_unique_dep": "Information Processing and Systems department;Department of Guidance Control and Navigation",
        "aff_unique_url": "https://www.onera.fr;https://www.mbda-systems.com",
        "aff_unique_abbr": "ONERA;MBDA",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Palaiseau;Le Plessis Robinson",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981693",
        "title": "Generating Families of Optimally Actuated Gaits from a Legged System's Energetically Conservative Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a homotopic approach to generating energetically optimal gaits for legged robots that maps passive (i.e., unactuated) gaits of an energetically conservative model of the robot to a model with user-defined target dynamics with dissipation and actuation (i.e., the more \u201crealistic\u201d legged model). Our core contribution is advancing the state-of-the-art towards a turn-key approach where the seed values are known by design and do not rely on domain-specific knowledge to generate or randomly guess across a range of energetic cost functions and desired gait properties (e.g., walking speed, hopping height, etc.), which can limit the usefulness of the typical optimization-based approach. We demonstrate this methodology on a parallel elastic actuated planar monoped with five degrees of freedom. Our work also demonstrates an explicit connection between passive gaits and optimally actuated motions, which has long been an area of interest in the fields of robotics and biome-chanics.",
        "primary_area": "",
        "author": "Maximilian Raff;Nelson Rosa;C. David Remy;Maximilian Raff;Nelson Rosa;C. David Remy",
        "authorids": "/37089446653;/38251723100;/37546418700;/37089446653;/38251723100;/37546418700",
        "aff": "Institute for Nonlinear Mechanic, University of Stuttgart, Germany; Institute for Nonlinear Mechanic, University of Stuttgart, Germany; Institute for Nonlinear Mechanic, University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981693/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=138355913022656578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Stuttgart",
        "aff_unique_dep": "Institute for Nonlinear Mechanic",
        "aff_unique_url": "https://www.uni-stuttgart.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981326",
        "title": "Generating Safe Corridors Roadmap for Urban Air Mobility",
        "track": "main",
        "status": "Poster",
        "abstract": "Personal air transportation on short distances, so-called Urban Air Mobility (UAM), is a trend in modern aviation that raises new challenges as flying in urban areas at low altitudes induces an additional risk to people and properties on the ground. Risk-aware trajectory planning can mitigate the risk by detouring and flying over less populated and thus less risky areas. Existing risk-aware trajectory planning approaches are computationally demanding single-query methods that are impractical for online usage. Moreover, coordinated planning for multiple aircraft is prohibitively expensive. Therefore, we propose to reduce computational demands by determining low-risk areas called safe corridors and creating a roadmap of safe corridors based on multiple least risky trajectories. The created roadmap can be used in graph-based multi-agent planning methods for coordinated trajectory planning. The proposed method has been evaluated in a realistic urban scenario, suggesting a significant computational burden reduction and less risky trajectories than the current state-of-the-art methods.",
        "primary_area": "",
        "author": "Jakub Sl\u00e1ma;Petr V\u00e1\u0148a;Jan Faigl;Jakub Sl\u00e1ma;Petr V\u00e1\u0148a;Jan Faigl",
        "authorids": "/37086236995;/37085751648;/37540566100;/37086236995;/37085751648;/37540566100",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981326/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=245423556524776462&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9981560",
        "title": "GeoROS: Georeferenced Real-time Orthophoto Stitching with Unmanned Aerial Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous orthophoto stitching during the flight of Unmanned Aerial Vehicles (UAV) can greatly promote the practicability and instantaneity of diverse applications such as emergency disaster rescue, digital agriculture, and cadastral survey, which is of remarkable interest in aerial photogrammetry. However, the inaccurately estimated camera poses and the intuitive fusion strategy of existing methods lead to misalignment and distortion artifacts in orthophoto mosaics. To address these issues, we propose a Georeferenced Real-time Orthophoto Stitching method (GeoROS), which can achieve efficient and accurate camera pose estimation through exploiting geolocation information in monocular visual simultaneous localization and mapping (SLAM) and fuse transformed images via orthogonality-preserving criterion. Specifically, in the SLAM process, georeferenced tracking is employed to acquire high-quality initial camera poses with a geolocation based motion model and facilitate non-linear pose optimization. Meanwhile, we design a georeferenced mapping scheme by introducing robust geolocation constraints in joint optimization of camera poses and the position of landmarks. Finally, aerial images warped with localized cameras are fused by considering both the orthogonality of camera orientation relative to the ground plane and the pixel centrality to fulfill global orthorectification. Besides, we construct two datasets with global navigation satellite system (GNSS) information of different scenarios and validate the superiority of our GeoROS method compared with state-of-the-art methods in accuracy and efficiency.",
        "primary_area": "",
        "author": "Guangze Gao;Mengke Yuan;Zhihao Ma;Jiaming Gu;Weiliang Meng;Shibiao Xu;Xiaopeng Zhang;Guangze Gao;Mengke Yuan;Zhihao Ma;Jiaming Gu;Weiliang Meng;Shibiao Xu;Xiaopeng Zhang",
        "authorids": "/37089663608;/37085672246;/37089663812;/37089658666;/37085635951;/37085335553;/37655670400;/37089663608;/37085672246;/37089663812;/37089658666;/37085635951;/37085335553;/37655670400",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981560/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13215399389123480891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Beijing University of Posts and Telecommunications",
        "aff_unique_dep": "School of Artificial Intelligence;School of Artificial Intelligence",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.bupt.edu.cn/",
        "aff_unique_abbr": "UCAS;BUPT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982250",
        "title": "Geometric MPC Techniques for Reduced Attitude Control on Quadrotors with Bidirectional Thrust",
        "track": "main",
        "status": "Poster",
        "abstract": "We present two novel nonlinear MPC formulations for reduced attitude tracking on quadrotors with bidirectional thrust capabilities. Reduced attitude tracking is relevant to recovery from partial thrust loss, which can occur due to the failure of one or more motors. The first formulation builds on a linearization of the quadrotor attitude dynamics on S(2)S(2) to achieve simultaneous tracking of reduced attitude and total thrust targets. The second formulation, meanwhile, accomplishes the same goal using a linearization of the dynamics on the Lie algebra of SO(3)SO(3) and a proposed method for projecting Lie algebra errors onto reduced attitude errors. Both methods achieve global tracking on S(2)S(2) without requiring the use of computationally expensive sequential quadratic program solvers. Through simulations, we show that the second approach generally tracks aggressive attitude references better, while the first controller offers more reliable regulation.",
        "primary_area": "",
        "author": "Jad Wehbeh;Inna Sharf;Jad Wehbeh;Inna Sharf",
        "authorids": "/37088686972;/37283633500;/37088686972;/37283633500",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Professor at the Department of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982250/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14968844836754261602&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981409",
        "title": "Geometric Savitzky-Golay Filtering of Noisy Rotations on SO(3) with Simultaneous Angular Velocity and Acceleration Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on the problem of smoothing a rotation trajectory corrupted by noise, while simultaneously estimating its corresponding angular velocity and angular acceleration. To this end, we develop a geometric version of the Savitzky-Golay filter on SO(3) that avoids following the conventional practice of first converting the rotation trajectory into Euler-like angles, performing the filtering in this new set of local coordinates, and finally converting the result back on SO (3). In particular, the estimation of the angular acceleration requires the computation of the right-trivialized second covariant derivative of the exponential map on SO (3) with respect to the (+) Cartan-Schouten connection. We provide an explicit expression for this derivative, creating a link to seemingly unrelated existing results concerning the first derivative of the exponential map on SE (3). A numerical example is provided in which we demonstrate the effectiveness and straightforward applicability of the proposed approach. An open implementation of the new geometric Savitzky-Golay filter is also provided.",
        "primary_area": "",
        "author": "Maarten Jongeneel;Alessandro Saccon;Maarten Jongeneel;Alessandro Saccon",
        "authorids": "/37089515671;/37296911500;/37089515671;/37296911500",
        "aff": "Department of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands; Department of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981409/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8182743625747371199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Eindhoven University of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tue.nl",
        "aff_unique_abbr": "TU/e",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Eindhoven",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9981117",
        "title": "Gesture2Vec: Clustering Gestures using Representation Learning Methods for Co-speech Gesture Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Co-speech gestures are a principal component in conveying messages and enhancing interaction experiences between humans and critical ingredients in human-agent interaction, including virtual agents and robots. Existing machine learning approaches have yielded only marginal success in learning speech-to-motion at the frame level. Current methods generate repetitive gesture sequences that lack appropriateness with respect to the speech context. To tackle this challenge, we take inspiration from successes in natural language processing on context and long-term dependencies, and propose a new framework that views text-to-gesture as machine translation, where gestures are words in another (non-verbal) language. We propose a vector-quantized variational autoencoder structure as well as training techniques to learn a rigorous representation of gesture sequences. We then translate input text into a discrete sequence of associated gesture chunks in the learned gesture space. Ultimately, we use translated gesture tokens from the input text as an input to the autoencoder's decoder to produce gesture sequences. Subjective and objective evaluations confirm the success of our approach in terms of appropriateness, human-likeness, and diversity. We also introduce new objective metrics using the quantized gesture representation.",
        "primary_area": "",
        "author": "Payam Jome Yazdian;Mo Chen;Angelica Lim;Payam Jome Yazdian;Mo Chen;Angelica Lim",
        "authorids": "/37089662244;/37085494765;/37086880157;/37089662244;/37085494765;/37086880157",
        "aff": "Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981117/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11095467091697502908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981811",
        "title": "Givenness Hierarchy Informed Optimal Document Planning for Situated Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots that use natural language in collaborative tasks must refer to objects in their environment. Recent work has shown the utility of the linguistic theory of the Givenness Hierarchy (GH) in generating appropriate referring forms. But before referring expression generation, collaborative robots must determine the content and structure of a sequence of utterances, a task known as document planning in the natural language generation community. This problem presents additional challenges for robots in situated contexts, where described objects change both physically and in the minds of their interlocutors. In this work, we consider how robots can \u201cthink ahead\u201d about the objects they must refer to and how to refer to them, sequencing object references to form a coherent, easy to follow chain. Specifically, we leverage GH to enable robots to plan their utterances in a way that keeps objects at a high cognitive status, which enables use of concise, anaphoric referring forms. We encode these linguistic insights as a mixed integer program within a planning context, formulating constraints to concisely and efficiently capture GH-theoretic cognitive properties. We demonstrate that this GH-informed planner generates sequences of utterances with high intersentential coherence, which we argue should enable substantially more efficient and natural human-robot dialogue.",
        "primary_area": "",
        "author": "Kevin Spevak;Zhao Han;Tom Williams;Neil T. Dantam;Kevin Spevak;Zhao Han;Tom Williams;Neil T. Dantam",
        "authorids": "/37089661212;/37089551212;/37085468519;/37546520000;/37089661212;/37089551212;/37085468519;/37546520000",
        "aff": "All authors are with the Department of Computer Science, Colorado School of Mines, CO, USA; All authors are with the Department of Computer Science, Colorado School of Mines, CO, USA; All authors are with the Department of Computer Science, Colorado School of Mines, CO, USA; All authors are with the Department of Computer Science, Colorado School of Mines, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981811/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2903573869867698444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981075",
        "title": "Global Data Association for SLAM with 3D Grassmannian Manifold Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Using pole and plane objects in lidar SLAM can increase accuracy and decrease map storage requirements compared to commonly-used point cloud maps. However, place recognition and geometric verification using these landmarks is challenging due to the requirement for global matching without an initial guess. Existing works typically only leverage either pole or plane landmarks, limiting application to a restricted set of environments. We present a global data association method for loop closure in lidar scans using 3D line and plane objects simultaneously and in a unified manner. The main novelty of this paper is in the representation of line and plane objects extracted from Iidar scans on the manifold of affine subspaces, known as the affine Grassmannian. Line and plane correspondences are matched using our graph-based data association framework and subsequently registered in the least-squares sense. Compared to pole-only approaches and plane-only approaches, our 3D affine Grassmannian method yields a 71 % and 325 % increase respectively to loop closure recall at 100 % precision on the KITTI dataset and can provide frame alignment with less than 10 cm and 1 deg of error.",
        "primary_area": "",
        "author": "Parker C. Lusk;Jonathan P. How;Parker C. Lusk;Jonathan P. How",
        "authorids": "/37088441763;/37276347700;/37088441763;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981075/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12931628798840738661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981122",
        "title": "GoferBot: A Visual Guided Human-Robot Collaborative Assembly System",
        "track": "main",
        "status": "Poster",
        "abstract": "The current transformation towards smart manufacturing has led to a growing demand for human-robot collaboration (HRC) in the manufacturing process. Perceiving and understanding the human co-worker's behaviour introduces challenges for collaborative robots to efficiently and effectively perform tasks in unstructured and dynamic environments. Integrating recent data-driven machine vision capabilities into HRC systems is a logical next step in addressing these challenges. However, in these cases, off-the-shelf components struggle due to generalisation limitations. Real-world evaluation is required in order to fully appreciate the maturity and robustness of these approaches. Furthermore, understanding the pure-vision aspects is a crucial first step before combining multiple modalities in order to understand the limitations. In this paper, we propose GoferBot, a novel vision-based semantic HRC system for a real-world assembly task. It is composed of a visual servoing module that reaches and grasps assembly parts in an unstructured multi-instance and dynamic environment, an action recognition module that performs human action prediction for implicit communication, and a visual handover module that uses the perceptual understanding of human behaviour to produce an intuitive and efficient collaborative assembly experience. GoferBot is a novel assembly system that seamlessly integrates all sub-modules by utilising implicit semantic information purely from visual perception.",
        "primary_area": "",
        "author": "Zheyu Zhuang;Yizhak Ben-Shabat;Jiahao Zhang;Stephen Gould;Robert Mahony;Zheyu Zhuang;Yizhak Ben-Shabat;Jiahao Zhang;Stephen Gould;Robert Mahony",
        "authorids": "/37087324996;/37086412430;/37089663155;/37408560000;/37283743600;/37087324996;/37086412430;/37089663155;/37408560000;/37283743600",
        "aff": "The College of Engineering and Computer Science, The Australian National University, Canberra, Australia; The Faculty of Electrical and Computer Engineering, Technion I.I.T, Haifa, Isreal; The College of Engineering and Computer Science, The Australian National University, Canberra, Australia; The College of Engineering and Computer Science, The Australian National University, Canberra, Australia; The College of Engineering and Computer Science, The Australian National University, Canberra, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981122/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12586123912132717691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Australian National University;Technion I.I.T",
        "aff_unique_dep": "College of Engineering and Computer Science;Faculty of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.anu.edu.au;https://www.technion.ac.il",
        "aff_unique_abbr": "ANU;Technion",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Canberra;Haifa",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Australia;Israel"
    },
    {
        "id": "9981924",
        "title": "Going In Blind: Object Motion Classification using Distributed Tactile Sensing for Safe Reaching in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulators navigating cluttered shelves or cabinets may find it challenging to avoid contact with obstacles. Indeed, rearranging obstacles may be necessary to access a target. Rather than planning explicit motions that place obstacles into a desired pose, we suggest allowing incidental contacts to rearrange obstacles while monitoring contacts for safety. Bypassing object identification, we present a method for categorizing object motions from tactile data collected from incidental contacts with a capacitive tactile skin on an Allegro Hand. We formalize tactile cues associated with categories of object motion, demonstrating that they can determine with > 90% accuracy whether an object is movable and whether a contact is causing the object to slide stably (safe contact) or tip (unsafe).",
        "primary_area": "",
        "author": "Rachel Thomasson;Etienne Roberge;Mark R. Cutkosky;Jean-Philippe Roberge;Rachel Thomasson;Etienne Roberge;Mark R. Cutkosky;Jean-Philippe Roberge",
        "authorids": "/37086936973;/37086328583;/37329470000;/37085447697;/37086936973;/37086328583;/37329470000;/37085447697",
        "aff": "Mech. Eng. Dept., Stanford University, Stanford, CA, USA; Command and Robotics Laboratory, \u00c9cole de Technologie Sup\u00e9rieure, Montreal, Quebec, Canada; Mech. Eng. Dept., Stanford University, Stanford, CA, USA; Command and Robotics Laboratory, \u00c9cole de Technologie Sup\u00e9rieure, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981924/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2756467326614575663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Stanford University;\u00c9cole de technologie sup\u00e9rieure",
        "aff_unique_dep": "Mechanical Engineering Department;Command and Robotics Laboratory",
        "aff_unique_url": "https://www.stanford.edu;https://www.etsmtl.ca",
        "aff_unique_abbr": "Stanford;ETS",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Stanford;Montreal",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9981295",
        "title": "Graph-Structured Policy Learning for Multi-Goal Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-goal policy learning for robotic manipu-lation is challenging. Prior successes have used state-based representations of the objects or provided demonstration data to facilitate learning. In this paper, by hand-coding a high-level discrete representation of the domain, we show that policies to reach dozens of goals can be learned with a single network using Q-learning from pixels. The agent focuses learning on simpler, local policies which are sequenced together by planning in the abstract space. We compare our method against standard multi-goal RL baselines, as well as other methods that leverage the discrete representation, on a challenging block construction domain. We find that our method can build more than a hundred different block structures, and demonstrate forward transfer to structures with novel objects. Lastly, we deploy the policy learned in simulation on a real robot.",
        "primary_area": "",
        "author": "David Klee;Ondrej Biza;Robert Platt;David Klee;Ondrej Biza;Robert Platt",
        "authorids": "/37089660130;/37089662122;/37273991200;/37089660130;/37089662122;/37273991200",
        "aff": "Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981295/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4182139881465352718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Khoury College of Computer Sciences",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981784",
        "title": "Graph-based Reinforcement Learning meets Mixed Integer Programs: An application to 3D robot assembly discovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot assembly discovery (RAD) is a challenging problem that lives at the intersection of resource allocation and motion planning. The goal is to combine a predefined set of objects to form something new while considering task execution with the robot-in-the-loop. In this work, we tackle the problem of building arbitrary, predefined target structures entirely from scratch using a set of Tetris-like building blocks and a robotic manipulator. Our novel hierarchical approach aims at efficiently decomposing the overall task into three feasible levels that benefit mutually from each other. On the high level, we run a classical mixed-integer program for global optimization of block-type selection and the blocks' final poses to recreate the desired shape. Its output is then exploited to efficiently guide the exploration of an underlying reinforcement learning (RL) policy. This RL policy draws its generalization properties from a flexible graph-based representation that is learned through Q-learning and can be refined with search. Moreover, it accounts for the necessary conditions of structural stability and robotic feasibility that cannot be effectively reflected in the previous layer. Lastly, a grasp and motion planner transforms the desired assembly commands into robot joint movements. We demonstrate our proposed method's performance on a set of competitive simulated RAD environments, showcase real-world transfer, and report performance and robustness gains compared to an unstructured end-to-end approach.",
        "primary_area": "",
        "author": "Niklas Funk;Svenja Menzenbach;Georgia Chalvatzaki;Jan Peters;Niklas Funk;Svenja Menzenbach;Georgia Chalvatzaki;Jan Peters",
        "authorids": "/37089175184;/37089662194;/37085353493;/37533077600;/37089175184;/37089662194;/37085353493;/37533077600",
        "aff": "Department of Computer Science, Technical University of Darmstadt; Department of Computer Science, Technical University of Darmstadt; Department of Computer Science, Technical University of Darmstadt; Department of Computer Science, Technical University of Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981784/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10495396627353077252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Darmstadt",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981069",
        "title": "Grasp Planning for Occluded Objects in a Confined Space with Lateral View Using Monte Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "In the lateral access environment, the robot be-havior should be planned considering surrounding objects and obstacles because object observation directions and approach angles are limited. To safely retrieve a partially occluded target object in these environments, we have to relocate objects using prehensile actions to create a collision-free path for the target. We propose a learning-based method for object rearrangement planning applicable to objects of various types and sizes in the lateral environment. We plan the optimal rearrangement sequence by considering both collisions and approach angles at which objects can be grasped. The proposed method finds the grasping order through Monte Carlo tree search, significantly reducing the tree search cost using point cloud states. In the experiment, the proposed method shows the best and most stable performance in various scenarios compared to the existing TAMP methods. In addition, we confirm that the proposed method trained in simulation can be easily applied to a real robot without additional fine-tuning, showing the robustness of the proposed method.",
        "primary_area": "",
        "author": "Minjae Kang;Hogun Kee;Junseok Kim;Songhwai Oh;Minjae Kang;Hogun Kee;Junseok Kim;Songhwai Oh",
        "authorids": "/37087323855;/37088506967;/37086427161;/37068116900;/37087323855;/37088506967;/37086427161;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981069/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13409904874739437946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981035",
        "title": "Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared Control on the Hannes Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the task of object grasping with a prosthetic hand capable of multiple grasp types. In this setting, communicating the intended grasp type often requires a high user cognitive load which can be reduced adopting shared autonomy frameworks. Among these, so-called eye-in-hand systems automatically control the hand pre-shaping before the grasp, based on visual input coming from a camera on the wrist. In this paper, we present an eye-in-hand learning-based approach for hand pre-shape classification from RGB sequences. Differently from previous work, we design the system to support the possibility to grasp each considered object part with a different grasp type. In order to overcome the lack of data of this kind and reduce the need for tedious data collection sessions for training the system, we devise a pipeline for rendering synthetic visual sequences of hand trajectories. We develop a sensorized setup to acquire real human grasping sequences for benchmarking and show that, compared on practical use cases, models trained with our synthetic dataset achieve better generalization performance than models trained on real data. We finally integrate our model on the Hannes prosthetic hand and show its practical effectiveness. We make publicly available the code and dataset to reproduce the presented results11https://github.com/hsp-iit/prosthetic-grasping-simulation.",
        "primary_area": "",
        "author": "Federico Vasile;Elisa Maiettini;Giulia Pasquale;Astrid Florio;Nicol\u00f2 Boccardo;Lorenzo Natale;Federico Vasile;Elisa Maiettini;Giulia Pasquale;Astrid Florio;Nicol\u00f2 Boccardo;Lorenzo Natale",
        "authorids": "/37089661281;/37086315907;/37086099680;/37089658611;/37088533991;/37542770000;/37089661281;/37086315907;/37086099680;/37089658611;/37088533991;/37542770000",
        "aff": "DIBRIS, University of Genoa, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Rehab Technologies Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Rehab Technologies Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981035/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12045927600558218677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "DIBRIS;Humanoid Sensing and Perception",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981863",
        "title": "Grasp Stability Prediction with Sim-to-Real Transfer from Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot simulation has been an essential tool for data-driven manipulation tasks. However, most existing simulation frameworks lack either efficient and accurate models of physical interactions with tactile sensors or realistic tactile simulation. This makes the sim-to-real transfer for tactile-based manipulation tasks still challenging. In this work, we integrate simulation of robot dynamics and vision-based tactile sensors by modeling the physics of contact. This contact model uses simulated contact forces at the robot's end-effector to inform the generation of realistic tactile outputs. To eliminate the sim-to-real transfer gap, we calibrate our physics simulator of robot dynamics, contact model, and tactile optical simulator with real-world data, and then we demonstrate the effectiveness of our system on a zero-shot sim-to-real grasp stability prediction task where we achieve an average accuracy of 90.7% on various objects. Experiments reveal the potential of applying our simulation framework to more complicated manipulation tasks. We open-source our simulation framework at https://github.com/CMURoboTouch/Taxim/tree/taxim-robot.",
        "primary_area": "",
        "author": "Zilin Si;Zirui Zhu;Arpit Agarwal;Stuart Anderson;Wenzhen Yuan;Zilin Si;Zirui Zhu;Arpit Agarwal;Stuart Anderson;Wenzhen Yuan",
        "authorids": "/37089194088;/37089659101;/37089000833;/37089001454;/37085486405;/37089194088;/37089659101;/37089000833;/37089001454;/37085486405",
        "aff": "Robotics Institute, Carnegie Mellon University; Department of Electrical Engineering, Tsinghua University; Robotics Institute, Carnegie Mellon University; Meta Reality Labs Research; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981863/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14070150186152421491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Tsinghua University;Meta",
        "aff_unique_dep": "Robotics Institute;Department of Electrical Engineering;Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.tsinghua.edu.cn;https://www.meta.com",
        "aff_unique_abbr": "CMU;THU;MRL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981972",
        "title": "Grasping State Analysis of Soft Manipulator Based on Flexible Tactile Sensor Array",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the grasping state analysis is vital in the study of manipulators, the grasping state analysis of soft manipulators as an independent research topic is not much so far. This paper proposes a novel pneumatic soft manipulator with a flexible tactile sensor array (SM-FTSA). The flexible tactile sensor array comprises piezoresistive materials with a porous structure. An equal potential approach is adopted to realize the collection of tactile signals of the SM-FTSA. Inspired by the grasping analysis of rigid manipulators, we propose 4 grasping states for the SM-FTSA, including inflating, shaking, stable, and slipping. Based on the experimental data, we conduct grasping experiments on 12 objects with SM-FTSA, and we propose 10 features that reflect the grasping state. Several machine learning methods are utilized to classify the grasping state. Among them, the Random Forest method presents the best performance, and the average classification accuracy reaches 99%.",
        "primary_area": "",
        "author": "Haoyuan Wang;Hongge Ru;Hongliang Lei;Chi Zhang;Cheng Han;Hao Wu;Jian Huang;Haoyuan Wang;Hongge Ru;Hongliang Lei;Chi Zhang;Cheng Han;Hao Wu;Jian Huang",
        "authorids": "/37089660937;/37086584399;/37089658288;/37089561376;/37089661349;/37086441517;/37367799000;/37089660937;/37086584399;/37089658288;/37089561376;/37089661349;/37086441517;/37367799000",
        "aff": "School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Mechanical Science and Engineering, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Mechanical Science and Engineering, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), Wuhan, Hubei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981972/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=152857181212731033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Artificial Intelligence and Automation",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981916",
        "title": "Gravity-constrained point cloud registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual and lidar Simultaneous Localization and Mapping (SLAM) algorithms benefit from the Inertial Measurement Unit (IMU) modality. The high-rate inertial data complement the other lower-rate modalities. Moreover, in the absence of constant acceleration, the gravity vector makes two attitude angles out of three observable in the global coordinate frame. In visual odometry, this is already being used to reduce the 6-Degrees Of Freedom (DOF) pose estimation problem to 4-DOF. In lidar SLAM, the gravity measurements are often used as a penalty in the back-end global map optimization to prevent map deformations. In this work, we propose an Iterative Closest Point (ICP)-based front-end which exploits the observable DOF and provides pose estimates aligned with the gravity vector. We believe that this front-end has the potential to support the loop closure identification, thus speeding up convergences of global map optimizations. The presented approach has been extensively tested against accurate ground-truth localization in large-scale outdoor environments as well as in the Subterranean Challenge organized by Defense Advanced Research Projects Agency (DARPA). We show that it can reduce the localization drift by 30% when compared to the standard 6-DOF ICP. Moreover, the code is readily available to the community as a part of the libpointmatcher library.",
        "primary_area": "",
        "author": "Vladim\u00edr Kubelka;Maxime Vaidis;Fran\u00e7ois Pomerleau;Vladim\u00edr Kubelka;Maxime Vaidis;Fran\u00e7ois Pomerleau",
        "authorids": "/38251946200;/37088414805;/37594916100;/38251946200;/37088414805;/37594916100",
        "aff": "Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981916/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9380604318788746639&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Northern Robotics Laboratory",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Qu\u00e9bec City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981515",
        "title": "Grounding Commands for Autonomous Vehicles via Layer Fusion with Region-specific Dynamic Layer Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Grounding a command to the visual environment is an essential ingredient for interactions between autonomous vehicles and humans. In this work, we study the problem of language grounding for autonomous vehicles, which aims to localize a region in a visual scene according to a natural language command from a passenger. Prior work only employs the top layer representations of a vision-and-language pretrained model to predict the region referred to by the command. However, such a method omits the useful features encoded in other layers, and thus results in inadequate understanding of the input scene and command. To tackle this limitation, we present the first layer fusion approach for this task. Since different visual regions may require distinct types of features to disambiguate them from each other, we further propose the region-specific dynamic (RSD) layer attention to adaptively fuse the multimodal information across layers for each region. Extensive experiments on the Talk2Car benchmark demonstrate that our approach helps predict more accurate regions and outperforms state-of-the-art methods.",
        "primary_area": "",
        "author": "Hou Pong Chan;Mingxi Guo;Cheng-Zhong Xu;Hou Pong Chan;Mingxi Guo;Cheng-Zhong Xu",
        "authorids": "/37089628914;/37089659418;/37278305300;/37089628914;/37089659418;/37278305300",
        "aff": "Department of Computer and Information Science, University of Macau, Macau, SAR, China; Department of Computer and Information Science, University of Macau, Macau, SAR, China; Department of Computer and Information Science, University of Macau, Macau, SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981515/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8054271043186741096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Macau",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.um.edu.mo",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Macau",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982057",
        "title": "Group-$k$ Consistent Measurement Set Maximization for Robust Outlier Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for the robust selection of measurements in a simultaneous localization and mapping (SLAM) framework. Existing methods check consistency or compatibility on a pairwise basis, however many measurement types are not sufficiently constrained in a pairwise scenario to determine if either measurement is inconsistent with the other. This paper presents group-kk consistency maximization (\\mathrm{G}k\\text{CM}\\mathrm{G}k\\text{CM}) that estimates the largest set of measurements that is internally group-kk consistent. Solving for the largest set of group-kk consistent measurements can be formulated as an instance of the maximum clique problem on generalized graphs and can be solved by adapting current methods. This paper evaluates the performance of \\mathrm{G}k\\text{CM}\\mathrm{G}k\\text{CM} using simulated data and compares it to pairwise consistency maximization (PCM) presented in previous work.",
        "primary_area": "",
        "author": "Brendon Forsgren;Ram Vasudevan;Michael Kaess;Timothy W. McLain;Joshua G. Mangelson;Brendon Forsgren;Ram Vasudevan;Michael Kaess;Timothy W. McLain;Joshua G. Mangelson",
        "authorids": "/37086695332;/37648237800;/37324200400;/37294472600;/37086109836;/37086695332;/37648237800;/37324200400;/37294472600;/37086109836",
        "aff": "Department of Mechanical Engineering, Brigham Young University; Department of Mechanical Engineering, University of Michigan; Robotics Institute at Carnegie Mellon University; Department of Mechanical Engineering, Brigham Young University; Department of Electrical and Computer Engineering, Brigham Young University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982057/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17780380724958785112&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Brigham Young University;University of Michigan;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering;Robotics Institute",
        "aff_unique_url": "https://www.byu.edu;https://www.umich.edu;https://www.cmu.edu",
        "aff_unique_abbr": "BYU;UM;CMU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Ann Arbor;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981111",
        "title": "H-VLO: Hybrid LiDAR-Camera Fusion For Self-Supervised Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a hybrid visual-LiDAR odometry (H-VLO) framework that fuses predicted visual depth map and completed LiDAR map. Compared to the previous visual-LiDAR odometry methods, our approach leverages 2D feature matching and 3D association by utilizing deep depth map, deep flow map and deep LiDAR depth completion networks. Rather than extraction of the depth values from LiDAR measurements for each visual feature, our method first densifies a LiDAR scan with a deep depth completion network and then fuses it with visual deep depth map estimation in a Bayesian framework. This method reduces pose estimation drift by improving feature-to-feature and point-to-feature matching, as well as scale recovery. The evaluations on the public KITTI odometry benchmark show that our technique achieves better or at least comparable estimates than the state-of-the-art visual-LiDAR and monocular visual odometry approaches.",
        "primary_area": "",
        "author": "Eren Aydemir;Naida Fetic;Mustafa Unel;Eren Aydemir;Naida Fetic;Mustafa Unel",
        "authorids": "/37089250146;/37086446132;/37332142400;/37089250146;/37086446132;/37332142400",
        "aff": "Product Developmen, Ford Otosant, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981111/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9563668040169038709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ford Otosan;Sabanci University",
        "aff_unique_dep": "Product Development;Faculty of Engineering and Natural Sciences",
        "aff_unique_url": "https://www.fordotosan.com.tr;https://www.sabanciuniv.edu/",
        "aff_unique_abbr": ";Sabanci",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Istanbul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "9981756",
        "title": "HD-CCSOM: Hierarchical and Dense Collaborative Continuous Semantic Occupancy Mapping through Label Diffusion",
        "track": "main",
        "status": "Poster",
        "abstract": "The collaborative operation of multiple robots can make up for the shortcomings of a single robot, such as limited field of perception or sensor failure. multirobots collaborative semantic mapping can enhance their comprehensive contextual understanding of the environment. However, existing multirobots collaborative semantic mapping algorithms mainly apply discrete occupancy map inference, and do not compensate for inconsistent labels of local maps caused by differences in robot perspectives, which leads to greatly reduced availability and accuracy of the final global map. To address the challenges of discontinuous maps and inconsistent semantic labels, this paper proposes a novel hierarchical and dense collaborative continuous semantic occupancy mapping algorithm (HD-CCSOM). This work decomposes and formulates robot collaborative continuous semantic occupancy mapping problem at two levels. At the single robot level, the multi-entropy kernel inference method smoothly processes the registered semantic point cloud and infers a local continuous semantic occupancy map for each robot. At the collaborative robots level, the local maps are fused into a global enhanced and consistent semantic map via the label diffusion method based on a graph model. The proposed algorithm has been validated on public datasets and in simulated and real scenes, demonstrating significant improvements in mapping accuracy and efficiency.",
        "primary_area": "",
        "author": "Yinan Deng;Meiling Wang;Yi Yang;Yufeng Yue;Yinan Deng;Meiling Wang;Yi Yang;Yufeng Yue",
        "authorids": "/37089661012;/37406965500;/37899921700;/37086172414;/37089661012;/37406965500;/37899921700;/37086172414",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981756/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17220246240471562996&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.bit.edu.cn",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981037",
        "title": "HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint Sampling for Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectory prediction is of great importance for downstream tasks, such as autonomous driving and mobile robot navigation. Realistic models of the social interactions within the crowd is crucial for accurate pedestrian trajectory prediction. However, most existing methods do not capture group level interactions well, focusing only on pairwise interactions and neglecting group-wise interactions. In this work, we propose a hierarchical graph convolutional network, HGCN-GJS, for trajectory prediction which well leverages group level interactions within the crowd. Furthermore, we introduce a joint sampling scheme that captures co-dependencies between pedestrian trajectories during trajectory generation. Based on group information, this scheme ensures that generated trajectories within each group are consistent with each other, but enables different groups to act more independently. We demonstrate that our proposed network achieves state of the art performance on all datasets we have considered.",
        "primary_area": "",
        "author": "Yuying Chen;Congcong Liu;Xiaodong Mei;Bertram E. Shi;Ming Liu;Yuying Chen;Congcong Liu;Xiaodong Mei;Bertram E. Shi;Ming Liu",
        "authorids": "/37086602838;/37086126145;/37087466301;/37275989700;/37085398677;/37086602838;/37086126145;/37087466301;/37275989700;/37085398677",
        "aff": "The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981037/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12749695521083108785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981367",
        "title": "HI-DWA: Human-Influenced Dynamic Window Approach for Shared Control of a Telepresence Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of enabling the user to modify the path of a telepresence robot. The robot is capable of autonomously navigating to a goal predefined by the user, but the user might still want to modify the path, for example, to go further away from other people, or to go closer to landmarks she wants to see on the way. We propose Human-Influenced Dynamic Window Approach (HI-DWA), a shared control method aimed for telepresence robots based on Dynamic Window Approach (DWA) that allows the user to influence the control input given to the robot. To verify the proposed method, we performed a user study (N=32) in Virtual Reality (VR) to compare HI-DWA with switching between autonomous navigation and manual control for controlling a simulated telepresence robot moving in a virtual environment. Results showed that users reached their goal faster using HI-DWA controller and found it easier to use. Preference between the two methods was split equally. Qualitative analysis revealed that a major reason for the participants that preferred switching between two modes was the feeling of control. We also analyzed the effect of different input methods, joystick and gesture, on the preference and perceived workload.",
        "primary_area": "",
        "author": "Juho Kalliokoski;Basak Sakcak;Markku Suomalainen;Katherine J. Mimnaugh;Alexis P. Chambers;Timo Ojala;Steven M. LaValle;Juho Kalliokoski;Basak Sakcak;Markku Suomalainen;Katherine J. Mimnaugh;Alexis P. Chambers;Timo Ojala;Steven M. LaValle",
        "authorids": "/37089551299;/37086497815;/37086198609;/37088399028;/37089354107;/37329285500;/37280522300;/37089551299;/37086497815;/37086198609;/37088399028;/37089354107;/37329285500;/37280522300",
        "aff": "Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981367/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12167313858311894091&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Oulu",
        "aff_unique_dep": "Center of Ubiquitous Computing",
        "aff_unique_url": "https://www.oulu.fi",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9981740",
        "title": "HIRO: Heuristics Informed Robot Online Path Planning Using Pre-computed Deterministic Roadmaps",
        "track": "main",
        "status": "Poster",
        "abstract": "With the goal of efficiently computing collisionfree robot motion trajectories in dynamically changing environments, we present results of a novel method for Heuristics Informed Robot Online Path Planning (HIRO). Dividing robot environments into static and dynamic elements, we use the static part for initializing a deterministic roadmap, which provides a lower bound of the final path cost as informed heuristics for fast path-finding. These heuristics guide a search tree to explore the roadmap during runtime. The search tree examines the edges using a fuzzy collision checking concerning the dynamic environment. Finally, the heuristics tree exploits knowledge fed back from the fuzzy collision checking module and updates the lower bound for the path cost. As we demonstrate in real-world experiments, the closed-loop formed by these three components significantly accelerates the planning procedure. An additional backtracking step ensures the feasibility of the resulting paths. Experiments in simulation and the real world show that HIRO can find collisionfree paths considerably faster than baseline methods with and without prior knowledge of the environment.",
        "primary_area": "",
        "author": "Xi Huang;Gergely S\u00f3ti;Hongyi Zhou;Christoph Ledermann;Bj\u00f6rn Hein;Torsten Kr\u00f6ger;Xi Huang;Gergely S\u00f3ti;Hongyi Zhou;Christoph Ledermann;Bj\u00f6rn Hein;Torsten Kr\u00f6ger",
        "authorids": "/37089659850;/37089001331;/37089661562;/38468554800;/37604448500;/37283223400;/37089659850;/37089001331;/37089661562;/38468554800;/37604448500;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Robotics and Autonomous Systems, Institute of Applied Research, Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Robotics and Autonomous Systems, Institute of Applied Research, Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981740/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6125708240229134536&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;Robotics and Autonomous Systems, Institute of Applied Research",
        "aff_unique_url": "https://www.kit.edu;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981671",
        "title": "HRI Framework for Continual Learning in Face Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing human partners is an essential social skill for building personalized and long-term human-robot interactions. However, robots deployed in complex, real-world environments have to face several challenges, such as managing unstructured interactions with multiple users, limited computational resources, and intrinsic and continuous variability of their sensory evidence. To cope with these challenges, we propose a framework to perform autonomous incremental learning for open-set face recognition suitable for unconstrained HRI scenarios. We validated the proposed framework in a real-world experiment, demonstrating its suitability to let the robot autonomously interact with multiple people while creating a labeled database of their faces across various encounters. Furthermore, we evaluated how an off-the-shelf model performed with data gathered from the HRI setting and proposed a fine-tuned model obtained with a transfer learning technique. Analyses about automatic threshold determination and rehearsal methods for memory sampling were also proposed. Our preliminary results suggest that exploiting the first-hand robot's experience could be crucial to ensure better models' performance and, therefore, could be advantageous for the acceptance and effectiveness of social robots in the long run. With this work, we aim to provide insights on continual learning approaches in the HRI field to promote autonomous and personalized solutions meaningful for real-world applications.",
        "primary_area": "",
        "author": "Giulia Belgiovine;Jonas Gonzlez-Billandon;Alessandra Sciutti;Giulio Sandini;Francesco Rea;Giulia Belgiovine;Jonas Gonzlez-Billandon;Alessandra Sciutti;Giulio Sandini;Francesco Rea",
        "authorids": "/37087028657;/37089659642;/38190743700;/37295479800;/37948228400;/37087028657;/37089659642;/38190743700;/37295479800;/37948228400",
        "aff": "Universit\u00e1 degli Studi di Genova, Genova, Italy; Huawei Noah's Ark Lab, Paris, France; Cognitive Architecture for Collaborative Technologies lab, Italian Institute of Technology, Genova, Italy; Robotics Brain and Cognitive Science lab, Italian Institute of Technology, Genova, Italy; Robotics Brain and Cognitive Science lab, Italian Institute of Technology, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981671/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1746969922671028010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Universit\u00e1 degli Studi di Genova;Huawei;Italian Institute of Technology",
        "aff_unique_dep": ";Noah's Ark Lab;Cognitive Architecture for Collaborative Technologies lab",
        "aff_unique_url": "https://www.unige.it;https://www.huawei.com;https://www.iit.it",
        "aff_unique_abbr": "UniGe;Huawei;IIT",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Genova;Paris",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Italy;France"
    },
    {
        "id": "9981320",
        "title": "Hand-Crafted Features for Floating Plastic Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Plastic waste is a global concern that has a negative impact on the oceans and wildlife health. This paper focuses on detection of floating plastics in aerial images taken from unmanned aerial vehicles (UAVs). It proposes a new method for plastic detection in marine environments, based on SIFT descriptor and color histograms for feature extraction, as an alternative to state-of-the-art object detectors based on convolutional neural networks (CNNs), Our approach is named SURFACE: \u201cSIFT featURes For plAstiC dEtection\u201d. We investigate how different color-spaces and image resolutions impact the extraction of SIFT features and compare SURFACE to ResNet CNN. Also, we provide a detailed comparison with YOLO and Faster-RCNN object detection models and show that SURFACE achieves approximately the same accuracy while being faster and less memory consuming. The dataset acquired during this research will be publicly available.",
        "primary_area": "",
        "author": "Matija Sukno;Ivana Palunko;Matija Sukno;Ivana Palunko",
        "authorids": "/37089464035;/37568814800;/37089464035;/37568814800",
        "aff": "Department of Electrical Engineering and Computing, Laboratory for Intelligent Autonomous Systems (LARIAT), University of Dubrovnik, Croatia; Department of Electrical Engineering and Computing, Laboratory for Intelligent Autonomous Systems (LARIAT), University of Dubrovnik, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981320/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15226729135969566882&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Dubrovnik",
        "aff_unique_dep": "Department of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.unidu.hr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Croatia"
    },
    {
        "id": "9981419",
        "title": "Handling Non-Convex Constraints in MPC-Based Humanoid Gait Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In most MPC-based schemes used for humanoid gait generation, simple Quadratic Programming (QP) problems are considered for real-time implementation. Since these only allow for convex constraints, the generated gait may be conservative. In this paper we focus on the non-convex reachable region of the swinging foot, also known as Kinematic Admissible Region (KAR), and the corresponding constraint. We represent an approximation of such non-convex region as the union of multiple non-overlapping convex sub-regions. By leveraging the concept of feasibility region, i.e., the subset of the state space for which a QP problem is feasible, and introducing a proper selection criterion, we are able to maintain linearity of the constraints and thus use our Intrinsically Stable Model Predictive Control (IS-MPC) scheme with a negligible additional computational load. This approach allows for a wider range of possible generated motions and is very effective when reacting to a push or avoiding an obstacle, as illustrated in dynamically simulated scenarios.",
        "primary_area": "",
        "author": "Andrew S. Habib;Filippo M. Smaldone;Nicola Scianca;Leonardo Lanari;Giuseppe Oriolo;Andrew S. Habib;Filippo M. Smaldone;Nicola Scianca;Leonardo Lanari;Giuseppe Oriolo",
        "authorids": "/37089659780;/37088339742;/37086072440;/37354641900;/37283188300;/37089659780;/37088339742;/37086072440;/37354641900;/37283188300",
        "aff": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universita di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universita di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universita di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universita di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universita di Roma, Roma, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981419/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2229664765500946346&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Sapienza Universita di Roma",
        "aff_unique_dep": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale",
        "aff_unique_url": "https://www.uniroma1.it",
        "aff_unique_abbr": "Sapienza",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Roma",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981629",
        "title": "Hands-free Telelocomotion of a Wheeled Humanoid",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems capable of Dynamic Mobile Manipulation (DMM) tasks combine dynamic manipulation and locomotion and could facilitate dangerous or physically demanding labor. For instance, firefighter humanoid robots could leverage their body by leaning against collapsed building rubble to push it aside. Here we introduce a teleoperation system that targets the realization of these tasks using human's whole-body motor skills. We describe a new wheeled humanoid platform, SATYRR, and a novel hands-free teleoperation architecture using a whole-body Human Machine Interface (HMI). This system enables telelocomotion of the humanoid robot using the operator's body motion, freeing their arms for manipulation tasks. In this study we evaluate the efficacy of the proposed system on hardware, and explore the control of SATYRR using two teleoperation mappings that map the operators body pitch and yaw to the robot's velocity or acceleration. Through experiments and user feedback we showcase our preliminary findings of the pilot-system response. Results suggest that the HMI is capable of effectively telelocomoting SATYRR, that pilot preferences should dictate the appropriate motion mapping and gains, and finally that the pilot can better learn to control the system over time. This study represents a fundamental step towards the realization of combined manipulation and locomotion via teleoperation.",
        "primary_area": "",
        "author": "Amartya Purushottam;Yeongtae Jung;Kevin Murphy;Donghoon Baek;Joao Ramos;Amartya Purushottam;Yeongtae Jung;Kevin Murphy;Donghoon Baek;Joao Ramos",
        "authorids": "/37089662302;/37073279100;/37089477145;/37086439599;/37085375922;/37089662302;/37073279100;/37089477145;/37086439599;/37085375922",
        "aff": "Department of Electrical and Computer Engineering; Division of Mechanical System Engineering, Jeonbuk National University, Jeollabuk-do, Republic of Korea; Department of Mechanical Science and Engineering, University of Illinois, Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois, Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois, Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981629/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6295546791321374477&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Unknown Institution;Jeonbuk National University;University of Illinois, Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Division of Mechanical System Engineering;Department of Mechanical Science and Engineering",
        "aff_unique_url": ";;https://illinois.edu",
        "aff_unique_abbr": ";;UIUC",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "1;2;2;2",
        "aff_country_unique": ";South Korea;United States"
    },
    {
        "id": "9981392",
        "title": "Haptic Feedback Relocation from the Fingertips to the Wrist for Two-Finger Manipulation in Virtual Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Relocation of haptic feedback from the fingertips to the wrist has been considered as a way to enable haptic interaction with mixed reality virtual environments while leaving the fingers free for other tasks. We present a pair of wrist-worn tactile haptic devices and a virtual environment to study how various mappings between fingers and tactors affect task performance. The haptic feedback rendered to the wrist reflects the interaction forces occurring between a virtual object and virtual avatars controlled by the index finger and thumb. We performed a user study comparing four different finger-to-tactor haptic feedback mappings and one no-feedback condition as a control. We evaluated users' ability to perform a simple pick-and-place task via the metrics of task completion time, path length of the fingers and virtual cube, and magnitudes of normal and shear forces at the fingertips. We found that multiple mappings were effective, and there was a greater impact when visual cues were limited. We discuss the limitations of our approach and describe next steps toward multi-degree-of-freedom haptic rendering for wrist-worn devices to improve task performance in virtual environments.",
        "primary_area": "",
        "author": "Jasmin E. Palmer;Mine Sarac;Aaron A. Garza;Allison M. Okamura;Jasmin E. Palmer;Mine Sarac;Aaron A. Garza;Allison M. Okamura",
        "authorids": "/37089663758;/37061845400;/37089662098;/37276156400;/37089663758;/37061845400;/37089662098;/37276156400",
        "aff": "Department of Mechanical Engineering, Stanford University, CA, USA; Department of Mechatronics Engineering, Kadir Has University, Istanbul, Turkey; Department of Mechanical Engineering, Stanford University, CA, USA; Department of Mechanical Engineering, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981392/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6047465544824792369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Stanford University;Kadir Has University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechatronics Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://www.khas.edu.tr",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Stanford;Istanbul",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;T\u00fcrkiye"
    },
    {
        "id": "9981290",
        "title": "Haptic Teleoperation of High-dimensional Robotic Systems Using a Feedback MPC Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Model Predictive Control (MPC) schemes have proven their efficiency in controlling high degree-of-freedom (DoF) complex robotic systems. However, they come at a high computational cost and an update rate of about tens of hertz. This relatively slow update rate hinders the possibility of stable haptic teleoperation of such systems since the slow feedback loops can cause instabilities and loss of transparency to the operator. This work presents a novel framework for transparent teleoperation of MPC-controlled complex robotic systems. In particular, we employ a feedback MPC approach [1] and exploit its structure to account for the operator input at a fast rate which is independent of the update rate of the MPC loop itself. We demonstrate our framework on a mobile manipulator platform and show that it significantly improves haptic teleoperation's transparency and stability. We also highlight that the proposed feedback structure is constraint satisfactory and does not violate any constraints defined in the optimal control problem. To the best of our knowledge, this work is the first realization of the bilateral teleoperation of a legged manipulator using a whole-body MPC framework.",
        "primary_area": "",
        "author": "Jin Cheng;Firas Abi-Farraj;Farbod Farshidian;Marco Hutter;Jin Cheng;Firas Abi-Farraj;Farbod Farshidian;Marco Hutter",
        "authorids": "/37089659494;/37086034393;/37085428006;/37545251000;/37089659494;/37086034393;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981290/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4436905792994821299&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982283",
        "title": "Heterogeneous-Agent Trajectory Forecasting Incorporating Class Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Reasoning about the future behavior of other agents is critical to safe robot navigation. The multiplicity of plausible futures is further amplified by the uncertainty inherent to agent state estimation from data, including positions, velocities, and semantic class. Forecasting methods, however, typically neglect class uncertainty, conditioning instead only on the agent's most likely class, even though perception models often return full class distributions. To exploit this information, we present HAICU, a method for heterogeneous-agent trajectory forecasting that explicitly incorporates agents' class probabilities. We additionally present PUP, a new challenging real-world autonomous driving dataset, to investigate the im-pact of Perceptual Uncertainty in Prediction. It contains chal-lenging crowded scenes with unfiltered agent class probabilities that reflect the long-tail of current state-of-the-art perception systems. We demonstrate that incorporating class probabilities in trajectory forecasting significantly improves performance in the face of uncertainty, and enables new forecasting capabilities such as counterfactual predictions.",
        "primary_area": "",
        "author": "Boris Ivanovic;Kuan-Hui Lee;Pavel Tokmakov;Blake Wulfe;Rowan Mcllister;Adrien Gaidon;Marco Pavone;Boris Ivanovic;Kuan-Hui Lee;Pavel Tokmakov;Blake Wulfe;Rowan Mcllister;Adrien Gaidon;Marco Pavone",
        "authorids": "/37086527859;/37072359700;/37086255423;/37086192739;/37089659150;/37945420900;/37307912900;/37086527859;/37072359700;/37086255423;/37086192739;/37089659150;/37945420900;/37307912900",
        "aff": "NVIDIA Research; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Department of Aeronautics and Astronautics, NVIDIA Research, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982283/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6316118891711006305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;2",
        "aff_unique_norm": "NVIDIA;Toyota Research Institute;Stanford University",
        "aff_unique_dep": "NVIDIA Research;;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.nvidia.com/research;https://www.tri.global;https://www.stanford.edu",
        "aff_unique_abbr": "NVIDIA;TRI;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982093",
        "title": "Heuristic-free Optimization of Force-Controlled Robot Search Strategies in Stochastic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Benjamin Alt;Darko Katic;Rainer J\u00e4kel;Michael Beetz;Benjamin Alt;Darko Katic;Rainer J\u00e4kel;Michael Beetz",
        "authorids": "/37088995866;/37089002032;/37542755100;/37279125900;/37088995866;/37089002032;/37542755100;/37279125900",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982093/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8426825722290872357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9981369",
        "title": "Hey Haru, Let's Be Friends! Using the Tiers of Friendship to Build Rapport through Small Talk with the Tabletop Robot Haru",
        "track": "main",
        "status": "Poster",
        "abstract": "Conversation can play an essential role in forging bonds between humans and social robots, but participants need to feel like they are being listened to, remembered, and cared about in order to effectively build rapport. In this paper, we propose a novel strategy for conducting small talk with a social robot. Our approach is known as the Tiers of Friendship. It is centered around three core design elements: 1) Persuasive content and character is provided through topic modules created by professional creative writers to ensure engaging conversational content and a compelling personality for the social robot. 2) Conversational memory is achieved by allowing topic modules to specify required information that can be learned through conversation or recalled from previous interactions and organizing topic modules into a hierarchy that enforces information requirements between topics. 3) Dynamicity in conversation is promoted through topic navigation that supports fluid transitions to topics of human interest and employs elements of random ordering to create fresh conversation experiences. In this paper, we show how the Tiers of Friendship can be used to generate conversation content for a social robot that encourages the development of rapport. We describe a working implementation of a small talk system for a social robot based on the Tiers of Friendship that combines off-the-shelf ASR and NLU components and custom robot behavior components implemented via behavior trees on ROS. Finally, in order to evaluate our approach's effectiveness, we conduct an elicitation survey that evaluates conversations in terms of perceived engagement, personality traits, and rapport expectation and discuss the implications for social robotics.",
        "primary_area": "",
        "author": "Eric Nichols;Sarah Rose Siskind;Levko Ivanchuk;Guillermo P\u00e9rez;Waki Kamino;Selma \u0160abanovi\u0107;Randy Gomez;Eric Nichols;Sarah Rose Siskind;Levko Ivanchuk;Guillermo P\u00e9rez;Waki Kamino;Selma \u0160abanovi\u0107;Randy Gomez",
        "authorids": "/324054555661300;/37089661382;/37085751146;/37089663505;/37089659035;/37296282100;/37979526500;/324054555661300;/37089661382;/37085751146;/37089663505;/37089659035;/37296282100;/37979526500",
        "aff": "Honda Research Institute Japan Co., Ltd.; Hello SciCom; Honda Research Institute Japan Co., Ltd.; 4i Intelligent Insights; Indiana University Bloomington; Indiana University Bloomington; Honda Research Institute Japan Co., Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981369/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8541634604984418218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;3;3;0",
        "aff_unique_norm": "Honda Research Institute Japan Co., Ltd.;SciCom;4i Intelligent Insights;Indiana University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.honda-ri.jp/english/;;;https://www.indiana.edu",
        "aff_unique_abbr": "HRI-JP;;;IU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Bloomington",
        "aff_country_unique_index": "0;0;2;2;0",
        "aff_country_unique": "Japan;;United States"
    },
    {
        "id": "9982243",
        "title": "HiddenGems: Efficient safety boundary detection with active learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Evaluating safety performance in a resource-efficient way is crucial for the development of autonomous systems. Simulation of parameterized scenarios is a popular testing strategy but parameter sweeps can be prohibitively expensive. To address this, we propose HiddenGems: a sample-efficient method for discovering the boundary between compliant and non-compliant behavior via active learning. Given a parameterized scenario, one or more compliance metrics, and a simulation oracle, HiddenGems maps the compliant and noncompliant domains of the scenario. The methodology enables critical test case identification, comparative analysis of different versions of the system under test, as well as verification of design objectives. We evaluate HiddenGems on a scenario with a jaywalker crossing in front of an autonomous vehicle and obtain compliance boundary estimates for collision, lane keep, and acceleration metrics individually and in combination, with 6 times fewer simulations than a parameter sweep. We also show how HiddenGems can be used to detect and rectify a failure mode for an unprotected turn with 86% fewer simulations.",
        "primary_area": "",
        "author": "Aleksandar Petrov;Carter Fang;Khang Minh Pham;You Hong Eng;James Guo Ming Fu;Scott Drew Pendleton;Aleksandar Petrov;Carter Fang;Khang Minh Pham;You Hong Eng;James Guo Ming Fu;Scott Drew Pendleton",
        "authorids": "/37089662865;/37089663165;/37089661027;/37085723785;/37089659375;/37085580705;/37089662865;/37089663165;/37089661027;/37085723785;/37089659375;/37085580705",
        "aff": "Motional, Inc., Boston, MA; Motional, Inc., Boston, MA; Motional, Inc., Boston, MA; Motional, Inc., Boston, MA; Motional, Inc., Boston, MA; Motional, Inc., Boston, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982243/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9413977391154942161&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Motional, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.motional.com",
        "aff_unique_abbr": "Motional",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982033",
        "title": "Hierarchical Learning and Control for In-Hand Micromanipulation Using Multiple Laser-Driven Micro-Tools",
        "track": "main",
        "status": "Poster",
        "abstract": "Laser-driven micro-tools are formulated by treating highly-focused laser beams as actuators, to control the tool's motion to contact then manipulate a micro object, which allows it to manipulate opaque micro objects, or large cells without causing photodamage. However, most existing laser-driven tools are limited to relatively simple tasks, such as moving and caging, and cannot carry out in-hand dexterous tasks. This is mainly because in-hand manipulation involves continuously coordinating multiple laser beams, micro-tools, and the object itself, which has high degrees of freedom (DoF) and poses up challenge for planner and controller design. This paper presents a new hierarchical formulation for the grasping and manipulation of micro objects using multiple laser-driven micro-tools. In hardware, multiple laser-driven tools are assembled to act as a robotic hand to carry out in-hand tasks (e.g., rotating); in software, a hierarchical scheme is developed to shrunken the action space and coordinate the motion of multiple tools, subject to both the parametric uncertainty in the tool and the unknown dynamic model of the object. Such a formulation provides potential for achieving robotic in-hand manipulation at a micro scale. The performance of the proposed system is validated in simulation studies under different scenarios.",
        "primary_area": "",
        "author": "Yongyi Jia;Yu Chen;Hao Liu;Xiu Li;Xiang Li;Yongyi Jia;Yu Chen;Hao Liu;Xiu Li;Xiang Li",
        "authorids": "/37089659672;/37089920461;/37090020922;/38667875300;/37280877200;/37089659672;/37089920461;/37090020922;/38667875300;/37280877200",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982033/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9109628617037610730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981695",
        "title": "Hierarchical Model-Based Imitation Learning for Planning in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We demonstrate the first large-scale application of model-based generative adversarial imitation learning (MGAIL) to the task of dense urban self-driving. We augment standard MGAIL using a hierarchical model to enable generalization to arbitrary goal routes, and measure performance using a closed-loop evaluation framework with simulated interactive agents. We train policies from expert trajectories collected from real vehicles driving over 100,000 miles in San Francisco, and demonstrate a steerable policy that can navigate robustly even in a zero-shot setting, generalizing to synthetic scenarios with novel goals that never occurred in real-world driving. We also demonstrate the importance of mixing closed-loop MGAIL losses with open-loop behavior cloning losses, and show our best policy approaches the performance of the expert. We evaluate our imitative model in both average and challenging scenarios, and show how it can serve as a useful prior to plan successful trajectories.",
        "primary_area": "",
        "author": "Eli Bronstein;Mark Palatucci;Dominik Notz;Brandyn White;Alex Kuefler;Yiren Lu;Supratik Paul;Payam Nikdel;Paul Mougin;Hongge Chen;Justin Fu;Austin Abrams;Punit Shah;Evan Racah;Benjamin Frenkel;Shimon Whiteson;Dragomir Anguelov;Eli Bronstein;Mark Palatucci;Dominik Notz;Brandyn White;Alex Kuefler;Yiren Lu;Supratik Paul;Payam Nikdel;Paul Mougin;Hongge Chen;Justin Fu;Austin Abrams;Punit Shah;Evan Racah;Benjamin Frenkel;Shimon Whiteson;Dragomir Anguelov",
        "authorids": "/37086935192;/37089447248;/37086487343;/37089448312;/37086115893;/37089660560;/37088829000;/37086454305;/37089447101;/37089661980;/37089658426;/37846256000;/37089446849;/37086183354;/37089663154;/37269324800;/37278026400;/37086935192;/37089447248;/37086487343;/37089448312;/37086115893;/37089660560;/37088829000;/37086454305;/37089447101;/37089661980;/37089658426;/37846256000;/37089446849;/37086183354;/37089663154;/37269324800;/37278026400",
        "aff": "Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981695/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12676469797860470401&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 34,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Waymo",
        "aff_unique_dep": "Waymo Research",
        "aff_unique_url": "https://waymo.com",
        "aff_unique_abbr": "Waymo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981984",
        "title": "Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of enabling quadrupedal robots to perform precise shooting skills in the real world using reinforcement learning. Developing algorithms to enable a legged robot to shoot a soccer ball to a given target is a challenging problem that combines robot motion control and planning into one task. To solve this problem, we need to consider the dynamics limitation and motion stability during the control of a dynamic legged robot. Moreover, we need to consider motion planning to shoot the hard-to-model deformable ball rolling on the ground with uncertain friction to a desired location. In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion to shoot a soccer ball to a target. We deploy the proposed framework on an A1 quadrupedal robot and enable it to accurately shoot the ball to random targets in the real world.",
        "primary_area": "",
        "author": "Yandong Ji;Zhongyu Li;Yinan Sun;Xue Bin Peng;Sergey Levine;Glen Berseth;Koushil Sreenath;Yandong Ji;Zhongyu Li;Yinan Sun;Xue Bin Peng;Sergey Levine;Glen Berseth;Koushil Sreenath",
        "authorids": "/37087473472;/37088691308;/37089661008;/37086454470;/37085481973;/37085864638;/37563179200;/37087473472;/37088691308;/37089661008;/37086454470;/37085481973;/37085864638;/37563179200",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; Universit\u00e9 de Montr\u00e9al, Mila; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981984/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6386337295917002229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": ";Mila",
        "aff_unique_url": "https://www.berkeley.edu;https://www.umontreal.ca",
        "aff_unique_abbr": "UC Berkeley;UdeM",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9981820",
        "title": "Hierarchical Road Topology Learning for Urban Mapless Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The majority of current approaches in autonomous driving rely on High-Definition (HD) maps which detail the road geometry and surrounding area. Yet, this reliance is one of the obstacles to mass deployment of autonomous vehicles due to poor scalability of such prior maps. In this paper, we tackle the problem of online road map extraction via leveraging the sensory system aboard the vehicle itself. To this end, we design a structured model where a graph representation of the road network is generated in a hierarchical fashion within a fully convolutional network. The method is able to handle complex road topology and does not require a user in the loop.",
        "primary_area": "",
        "author": "Li Zhang;Faezeh Tafazzoli;Gunther Krehl;Runsheng Xu;Timo Rehfeld;Manuel Schier;Arunava Seal;Li Zhang;Faezeh Tafazzoli;Gunther Krehl;Runsheng Xu;Timo Rehfeld;Manuel Schier;Arunava Seal",
        "authorids": "/37088856083;/37085897999;/37085672098;/37089002744;/37085832434;/37087812404;/37088853829;/37088856083;/37085897999;/37085672098;/37089002744;/37085832434;/37087812404;/37088853829",
        "aff": "Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America; Mercedes-Benz Research and Development North America",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981820/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10202100285115415638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Mercedes-Benz Research and Development North America",
        "aff_unique_dep": "Research and Development",
        "aff_unique_url": "https://www.daimler.com",
        "aff_unique_abbr": "MBRDNA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981259",
        "title": "High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate control of robots at high speeds requires a control system that can take into account the kinodynamic interactions of the robot with the environment. Prior works on learning inverse kinodynamic (IKD) models of robots have shown success in capturing the complex kinodynamic effects. However, the types of control problems these approaches can be applied to are limited only to that of following pre-computed kinodynamically feasible trajectories. In this paper we present Optim-FKD, a new formulation for accurate, high-speed robot control that makes use of a learned forward kinodynamic (FKD) model and non-linear least squares optimization. Optim-FKD can be used for accurate, high speed control on any control task specifiable by a non-linear least squares objective. Optim-FKD can solve for control objectives such as path following and time-optimal control in real time, without needing access to pre-computed kinodynamically feasible trajectories. We empirically demonstrate these abilities of our approach through experiments on a scale one-tenth autonomous car. Our results show that Optim-FKD can follow desired trajectories more accurately and can find better solutions to optimal control problems than baseline approaches.",
        "primary_area": "",
        "author": "Pranav Atreya;Haresh Karnan;Kavan Singh Sikand;Xuesu Xiao;Sadegh Rabiee;Joydeep Biswas;Pranav Atreya;Haresh Karnan;Kavan Singh Sikand;Xuesu Xiao;Sadegh Rabiee;Joydeep Biswas",
        "authorids": "/37089661923;/37086310655;/37089193943;/37086258082;/37086933532;/37538259200;/37089661923;/37086310655;/37089193943;/37086258082;/37086933532;/37538259200",
        "aff": "Department of Computer Science, The University of Texas at Austin; Department of Mechanical Engineering, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981259/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5540008257833538118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981070",
        "title": "HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Low-light environments have posed a formidable challenge for robust unmanned aerial vehicle (UAV) tracking even with state-of-the-art (SOTA) trackers since the poten-tial image features are hard to extract under adverse light conditions. Besides, due to the low visibility, accurate online selection of the object also becomes extremely difficult for human monitors to initialize UAV tracking in ground con-trol stations. To solve these problems, this work proposes a novel enhancer, i.e., HighlightNet, to light up potential objects for both human operators and UAV trackers. By employing Transformer, HighlightNet can adjust enhancement parameters according to global features and is thus adaptive for the illumination variation. Pixel-level range mask is introduced to make HighlightNet more focused on the enhancement of the tracking object and regions without light sources. Furthermore, a soft truncation mechanism is built to prevent background noise from being mistaken for crucial features. Evaluations on image enhancement benchmarks demonstrate HighlightNet has advantages in facilitating human perception. Experiments on the public UAVDark135 benchmark show that HightlightNet is more suitable for UAV tracking tasks than other state-of-the-art (SOTA) low-light enhancers. In addition, real-world tests on a typical UAV platform verify HightlightNet's practicability and efficiency in nighttime aerial tracking-related applications. The code and demo videos are available at https://github.com/vision4robotics/HighlightNet.",
        "primary_area": "",
        "author": "Changhong Fu;Haolin Dong;Junjie Ye;Guangze Zheng;Sihang Li;Jilin Zhao;Changhong Fu;Haolin Dong;Junjie Ye;Guangze Zheng;Sihang Li;Jilin Zhao",
        "authorids": "/37086797986;/37089660120;/37088917418;/37088996628;/37089451036;/37089660393;/37086797986;/37089660120;/37088917418;/37088996628;/37089451036;/37089660393",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981070/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1072438526021902508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981978",
        "title": "Highly-Efficient Binary Neural Networks for Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "VPR is a fundamental task for autonomous navigation as it enables a robot to localize itself in the workspace when a known location is detected. Although accuracy is an essential requirement for a VPR technique, computational and energy efficiency are not less important for real-world applications. CNN-based techniques archive state-of-the-art VPR performance but are computationally intensive and energy demanding. Binary neural networks (BNN) have been recently proposed to address VPR efficiently. Although a typical BNN is an order of magnitude more efficient than a CNN, its processing time and energy usage can be further improved. In a typical BNN, the first convolution is not completely binarized for the sake of accuracy. Consequently, the first layer is the slowest network stage, requiring a large share of the entire computational effort. This paper presents a class of BNNs for VPR that combines depthwise separable factorization and binarization to replace the first convolutional layer to improve computational and energy efficiency. Our best model achieves higher VPR performance while spending considerably less time and energy to process an image than a BNN using a non-binary convolution as a first stage.",
        "primary_area": "",
        "author": "Bruno Ferrarini;Michael Milford;Klaus D. McDonald-Maier;Shoaib Ehsan;Bruno Ferrarini;Michael Milford;Klaus D. McDonald-Maier;Shoaib Ehsan",
        "authorids": "/37085669412;/37283633100;/38272117700;/37540520800;/37085669412;/37283633100;/38272117700;/37540520800",
        "aff": "School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; QUT Centre for Robotics, School of Electrical Engineering and Robotics, Brisbane, QLD, Australia; School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981978/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2415303800300470318&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Essex;Queensland University of Technology",
        "aff_unique_dep": "School of Computer Science and Electronic Engineering;School of Electrical Engineering and Robotics",
        "aff_unique_url": "https://www.essex.ac.uk;https://www.qut.edu.au",
        "aff_unique_abbr": "Essex;QUT",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Colchester;Brisbane",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;Australia"
    },
    {
        "id": "9981989",
        "title": "Holo-SpoK: Affordance-Aware Augmented Reality Control of Legged Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Although there is extensive research regarding legged manipulators, comparatively little focuses on their User Interfaces (UIs). Towards extending the state-of-art in this domain, in this work, we integrate a Boston Dynamics (BD) Spot\u00ae with a light-weight 7 DoF Kinova\u00ae robot arm and a Robotiq\u00ae 2F-85 gripper into a legged manipulator. Furthermore, we jointly control the robotic platform using an affordance-aware Augmented Reality (AR) Head-Mounted Display (HMD) UI developed for the Microsoft HoloLens 2. We named the combined platform Holo-SpoK. Moreover, we explain how this manipulator colocalises with the HoloLens 2 for its control through AR. In addition, we present the details of our algorithms for autonomously detecting grasp-ability affordances and for the refinement of the positions obtained via vision-based colocalisation. We validate the suitability of our proposed methods with multiple navigation and manipulation experiments. To the best of our knowledge, this is the first demonstration of an AR HMD UI for controlling legged manipulators.",
        "primary_area": "",
        "author": "Rodrigo Chac\u00f3n Quesada;Yiannis Demiris;Rodrigo Chac\u00f3n Quesada;Yiannis Demiris",
        "authorids": "/37089340834;/37296338900;/37089340834;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, United Kingdom; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981989/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6102223204105560019&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981119",
        "title": "HoloOcean: Realistic Sonar Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Sonar sensors play an integral part in underwater robotic perception by providing imagery at long distances where standard optical cameras cannot. They have proven to be an important part in various robotic algorithms including localization, mapping, and structure from motion. Unfortunately, generating realistic sonar imagery for algorithm development is difficult due to the high cost of field trials and lack of simulation methods. To remove these obstacles, we present various upgrades to the sonar simulation method in HoloOcean, our open-source marine robotics simulator. In particular, we improve the noise modeling using a novel cluster-based multipath ray-tracing algorithm, various probabilistic noise models, and material dependence. We also develop and integrate simulated models for side-scan, single-beam, and multibeam profiling sonars.",
        "primary_area": "",
        "author": "Easton Potokar;Kalliyan Lay;Kalin Norman;Derek Benham;Tracianne B. Neilsen;Michael Kaess;Joshua G. Mangelson;Easton Potokar;Kalliyan Lay;Kalin Norman;Derek Benham;Tracianne B. Neilsen;Michael Kaess;Joshua G. Mangelson",
        "authorids": "/37088598849;/37088552972;/37086885393;/37089646985;/38198418300;/37324200400;/37086109836;/37088598849;/37088552972;/37086885393;/37089646985;/38198418300;/37324200400;/37086109836",
        "aff": "Brigham Young University; Brigham Young University; Brigham Young University; Brigham Young University; Brigham Young University; Carnegie Mellon University; Brigham Young University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981119/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2157714048871804913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Brigham Young University;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.byu.edu;https://www.cmu.edu",
        "aff_unique_abbr": "BYU;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981602",
        "title": "Homology-Class Guided Rapidly-Exploring Random Tree For Belief Space Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, an efficient homology guided belief space planning method for obstacle-cluttered environments is presented. The proposed planner follows a two-step approach. First, a h-signature guided rapidly-exploring random tree (HRRT) algorithm is proposed to provide nominal trajecto-ries in different homology classes by constructing homology aware sub-trees in a parallel manner. The HRRT planner is extended to a h-signature guided RRT* algorithm, where an inter-homology-class rewire procedure is proposed, increasing the probability of discovering homology classes in narrow space/passages. The iLQG-based belief space planning algorithm is then employed to find locally optimal trajectories minimizing uncertainties in each homology class.",
        "primary_area": "",
        "author": "Ran Hao;M. Cenk \u00c7avuso\u011flu;Ran Hao;M. Cenk \u00c7avuso\u011flu",
        "authorids": "/37086454939;/37373298800;/37086454939;/37373298800",
        "aff": "Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981602/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:MIwWmBFRFYAJ:scholar.google.com/&scioq=Homology-Class+Guided+Rapidly-Exploring+Random+Tree+For+Belief+Space+Planning&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Case Western Reserve University",
        "aff_unique_dep": "Department of Electrical, Computer, and Systems Engineering",
        "aff_unique_url": "https://www.case.edu",
        "aff_unique_abbr": "CWRU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cleveland",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981431",
        "title": "Hoverability Analysis and Development of a Quadrotor Only with Clockwise Rotors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents novel quadrotor structures composed of only clockwise rotors. A multirotor unmanned aerial vehicle (UAV) generally has both clockwise and counterclockwise rotors to counteract the torques from the rotors. While the proposed structures have only clockwise rotors, those rotors are tilted to cancel the torques around the yaw angle of the body. This paper investigates the conditions for the proposed structures to achieve static hovering. More specifically, we provide a guideline to design the rotor tilt angles of the proposed structure. Then, this paper presents the design example of the rotor tilt angles and develops a prototype of the proposed quadrotor. The cascaded controller is also developed for the proposed structure. Finally, experimental validation is conducted with a developed prototype and controller.",
        "primary_area": "",
        "author": "Shusuke Mochida;Ryotaro Onuki;Takahiro Kawagoe;Takumi Ito;Tatsuya Ibuki;Riku Funada;Mitsuji Sampei;Shusuke Mochida;Ryotaro Onuki;Takahiro Kawagoe;Takumi Ito;Tatsuya Ibuki;Riku Funada;Mitsuji Sampei",
        "authorids": "/37088978082;/37089659081;/37089659841;/37089663244;/37572237900;/37085406846;/37270726000;/37088978082;/37089659081;/37089659841;/37089663244;/37572237900;/37085406846;/37270726000",
        "aff": "Department of Systems and Control Engineering, Tokyo institute of Technology, Tokyo, Japan; Sony Semiconductor Solutions Corporation, Kanagawa, Japan; Department of Systems and Control Engineering, Tokyo institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, Tokyo institute of Technology, Tokyo, Japan; Department of Electronics and Bioinformatics, Meiji University, Kanagawa, Japan; Department of Systems and Control Engineering, Tokyo institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, Tokyo institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981431/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12270165966236074648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;2;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Sony Semiconductor Solutions Corporation;Meiji University",
        "aff_unique_dep": "Department of Systems and Control Engineering;;Department of Electronics and Bioinformatics",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.sonysemicon.com/;https://www.meiji.ac.jp",
        "aff_unique_abbr": "Titech;Sony Semicom;Meiji",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "Tokyo;;Kanagawa",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981724",
        "title": "How Do We Fail? Stress Testing Perception in Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles (AVs) rely on environment perception and behavior prediction to reason about agents in their surroundings. These perception systems must be robust to adverse weather such as rain, fog, and snow. However, validation of these systems is challenging due to their complexity and dependence on observation histories. This paper presents a method for characterizing failures of LiDAR-based perception systems for AVs in adverse weather conditions. We develop a methodology based in reinforcement learning to find likely failures in object tracking and trajectory prediction due to sequences of disturbances. We apply disturbances using a physics-based data augmentation technique for simulating LiDAR point clouds in adverse weather conditions. Experiments performed across a wide range of driving scenarios from a real-world driving dataset show that our proposed approach finds high likelihood failures with smaller input disturbances compared to baselines while remaining computationally tractable. Identified failures can inform future development of robust perception systems for AVs.",
        "primary_area": "",
        "author": "Harrison Delecki;Masha Itkina;Bernard Lange;Ransalu Senanayake;Mykel J. Kochenderfer;Harrison Delecki;Masha Itkina;Bernard Lange;Ransalu Senanayake;Mykel J. Kochenderfer",
        "authorids": "/37089661116;/37087102957;/37088860729;/38490726500;/37596929200;/37089661116;/37087102957;/37088860729;/38490726500;/37596929200",
        "aff": "Department of Aeronautics and Astronautics, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981724/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5532688976376691569&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981126",
        "title": "How to Spend Your Robot Time: Bridging Kickstarting and Offline Reinforcement Learning for Vision-based Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has been shown to be effective at learning control from experience. However, RL typically requires a large amount of online interaction with the environment. This limits its applicability to real-world settings, such as in robotics, where such interaction is expensive. In this work we investigate ways to minimize online interactions in a target task, by reusing a suboptimal policy we might have access to, for example from training on related prior tasks, or in simulation. To this end, we develop two RL algorithms that can speed up training by using not only the action distributions of teacher policies, but also data collected by such policies on the task at hand. We conduct a thorough experimental study of how to use suboptimal teachers on a challenging robotic manipulation benchmark on vision-based stacking with diverse objects. We compare our methods to offline, online, offline-to-online, and kickstarting RL algorithms. By doing so, we find that training on data from both the teacher and student, enables the best performance for limited data budgets. We examine how to best allocate a limited data budget - on the target task - between the teacher and the student policy, and report experiments using varying budgets, two teachers with different degrees of suboptimality, and five stacking tasks that require a diverse set of behaviors. Our analysis, both in simulation and in the real world, shows that our approach is the best across data budgets, while standard offline RL from teacher rollouts is surprisingly effective when enough data is given.",
        "primary_area": "",
        "author": "Alex X. Lee;Coline Devin;Jost Tobias Springenberg;Yuxiang Zhou;Thomas Lampe;Abbas Abdolmaleki;Konstantinos Bousmalis;Alex X. Lee;Coline Devin;Jost Tobias Springenberg;Yuxiang Zhou;Thomas Lampe;Abbas Abdolmaleki;Konstantinos Bousmalis",
        "authorids": "/37089663088;/37085995906;/38252355500;/37088504091;/37086719504;/37698248100;/37282935000;/37089663088;/37085995906;/38252355500;/37088504091;/37086719504;/37698248100;/37282935000",
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981126/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16625237871604020974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981487",
        "title": "Human-Humanoid Robot Cooperative Load Transportation: Model-based Control Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to properly integrate humanoid robots in real-life situations, they must be able to collaborate with humans in completing tasks. One of these tasks is the cooperative transportation of a heavy object, which has been widely studied in the humanoids literature. However, the proposed methods rely heavily on six-axis force/torque (F/T) sensors at the wrists, which medium-sized or even some full-sized humanoid robots do not have. This paper proposes an observer to overcome the lack of F/T sensors. The observer is then coupled with a simplified dynamic model of the transportation task allowing the humanoid robot to carry out the task in a stable way. The method is tested in simulation using a humanoid robot that does not have F/T sensors, a NAO robot, to demonstrate its performance. These tests pointed out that the proposed method successfully estimated the interaction forces while generating stable walking patterns.",
        "primary_area": "",
        "author": "R\u00e9my Rahem;Christopher Yee Wong;Wael Suleiman;R\u00e9my Rahem;Christopher Yee Wong;Wael Suleiman",
        "authorids": "/37086575953;/37085749678;/37400542000;/37086575953;/37085749678;/37400542000",
        "aff": "Department of Electrical and Computer Engineering, Universit\u00e9 de Sherbrooke, Quebec, Canada; Department of Electrical and Computer Engineering, Universit\u00e9 de Sherbrooke, Quebec, Canada; Department of Electrical and Computer Engineering, Universit\u00e9 de Sherbrooke, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981487/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11017017957580288404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Sherbrooke",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usherbrooke.ca",
        "aff_unique_abbr": "UdeS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sherbrooke",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981948",
        "title": "Human-Robot Collaborative Carrying of Objects with Unknown Deformation Characteristics",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we introduce an adaptive control framework for human-robot collaborative transportation of objects with unknown deformation behaviour. The proposed framework takes as input the haptic information transmitted through the object, and the kinematic information of the human body obtained from a motion capture system to create reactive whole-body motions on a mobile collaborative robot. In order to validate our framework experimentally, we compared its performance with an admittance controller during a co-transportation task of a partially deformable object. We additionally demonstrate the potential of the framework while co-transporting rigid (aluminum rod) and highly deformable (rope) objects. A mobile manipulator which consists of an Omni-directional mobile base, a collaborative robotic arm, and a robotic hand is used as the robotic partner in the experiments. Quantitative and qualitative results of a 12-subjects experiment show that the proposed framework can effectively deal with objects of unknown deformability and provides intuitive assistance to human partners.",
        "primary_area": "",
        "author": "Doganay Sirintuna;Alberto Giammarino;Arash Ajoudani;Doganay Sirintuna;Alberto Giammarino;Arash Ajoudani",
        "authorids": "/37088505677;/37089440546;/37945239900;/37088505677;/37089440546;/37945239900",
        "aff": "Human-Robot Interfaces and physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Human-Robot Interfaces and physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Human-Robot Interfaces and physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981948/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1500416656373400166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Human-Robot Interfaces and physical Interaction (HRI2) Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981568",
        "title": "Human-exoskeleton Cooperative Balance Strategy for a Human-powered Augmentation Lower Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower Limb Exoskeletons (LLE) have received considerable interest in strength augmentation, rehabilitation, and walking assistance scenarios. For strength augmentation, LLE is expected to have the capability of reducing metabolic energy. However, the energy for adjusting Center of Gravity (CoG) is a main part of the total energy consumed during walking. This paper proposes a novel Human-exoskeleton Cooperative Balance (HCB) strategy which gives assistive torques balance ability and combine with the direction selected by the pilot to achieve balance walking of human-exoskeleton systems. In which, a Dynamic Torque Primitive Model (DTPM) is designed to plan a bionic assistive torque, and the balance parameters obtained by an Inverted Pendulum Model (IPM) is superimposed on it. Finally, the performance improved by the HCB strategy can break the limitation of traditional strategies and substantially increase the efficiency of assistance. We demonstrated the effectiveness of the proposed HCB strategy on the HUman-powered Augmentation Lower EXoskeleton (HUALEX) system. Experimental results indicate that the proposed HCB is more efficient than traditional strategies.",
        "primary_area": "",
        "author": "Guangkui Song;Rui Huang;Zhinan Peng;Kecheng Shi;Long Zhang;Rong He;Jing Qiu;Huayi Zhan;Hong Cheng;Guangkui Song;Rui Huang;Zhinan Peng;Kecheng Shi;Long Zhang;Rong He;Jing Qiu;Huayi Zhan;Hong Cheng",
        "authorids": "/37086583854;/37085625169;/37086471879;/37085491942;/37089348379;/37089662595;/37086356733;/37086603828;/37280209600;/37086583854;/37085625169;/37086471879;/37085491942;/37089348379;/37089662595;/37086356733;/37086603828;/37280209600",
        "aff": "Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China; school of Mechanical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Changhong AI Research (CHAIR), Sichuan Changhong Electronic (Group) Co., Ltd., Mianyang, China; Center for Robotics, School of Automation Engineering, University Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981568/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6191182911839679510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Sichuan Changhong Electronic (Group) Co., Ltd.",
        "aff_unique_dep": "School of Automation Engineering;Changhong AI Research (CHAIR)",
        "aff_unique_url": "https://www.uestc.edu.cn;",
        "aff_unique_abbr": "UESTC;SCEG",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Chengdu;Mianyang",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981796",
        "title": "Human-to-Robot Manipulability Domain Adaptation with Parallel Transport and Manifold-Aware ICP",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulability ellipsoids efficiently capture the human pose and reveal information about the task at hand. Their use in task-dependent robot teaching - particularly their transfer from a teacher to a learner - can advance emulation of human-like motion. Although in recent literature focus is shifted towards manipulability transfer between two robots, the adaptation to the capabilities of the other kinematic system is to date not addressed and research in transfer from human to robot is still in its infancy. This work presents a novel manipulability domain adaptation method for the transfer of manipulability information to the domain of another kinematic system. As manipulability matrices/ellipsoids are symmetric positive-definite (SPD) they can be viewed as points on the Riemannian manifold of SPD matrices. We are the first to address the problem of manipulability transfer from the perspective of point cloud registration. We propose a manifold-aware Iterative Closest Point algorithm (ICP) with parallel transport initialization. Furthermore, we introduce a correspondence matching heuristic for manipulability ellipsoids based on inherent geometric features. We confirm our method in simulation experiments with 2-DoF manipulators as well as 7-DoF models representing the human-arm kinematics.",
        "primary_area": "",
        "author": "Anna Reithmeir;Luis Figueredo;Sami Haddadin;Anna Reithmeir;Luis Figueredo;Sami Haddadin",
        "authorids": "/37089658728;/37063909900;/37542865300;/37089658728;/37063909900;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence (MIRMI), Technische Universitat Munchen (TUM), Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technische Universitat Munchen (TUM), Munich, Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technische Universitat Munchen (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981796/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4757362421129599921&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universitat Munchen",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981036",
        "title": "Humanoid Balance Control using Centroidal Angular Momentum based on Hierarchical Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Maintaining balance to external pushes is one of the most important features for a humanoid to walk in a real environment. In particular, methods for counteracting to pushes using the centroidal angular momentum (CAM) control have been actively developed. In this paper, a CAM control scheme based on hierarchical quadratic programming (HQP) is proposed. The scheme of the CAM control consists of CAM tracking control and initial pose return control, which is hierarchically operated based on HQP to ensure the priority of CAM tracking performance. The proposed method is implemented in a capture point (CP) feedback control framework. Through simulations and experiments, the proposed method demonstrated more stable balance control performance than the previous method when the humanoid is walking in the presence of external perturbation.",
        "primary_area": "",
        "author": "Myeong-Ju Kim;Daegyu Lim;Gyeongjae Park;Jaeheung Park;Myeong-Ju Kim;Daegyu Lim;Gyeongjae Park;Jaeheung Park",
        "authorids": "/37089659059;/37086934345;/37089663810;/37281014000;/37089659059;/37086934345;/37089663810;/37281014000",
        "aff": "Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; ASRI, RICS, Seoul National University, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981036/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4836746860012563816&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Intelligence and Information",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981245",
        "title": "Hybrid Approach for Stabilizing Large Time Delays in Cooperative Adaptive Cruise Control with Reduced Performance Penalties",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative adaptive cruise control (CACC) is a smart transportation solution that can mitigate traffic jams and improve road safety. CACC performance is heavily impacted by communication time delay; moreover, control theory solutions generally compromise control performance by tuning control gains in order to maintain plant stability. We propose a control-machine learning hybrid approach called deep time delay filter (DTDF). DTDF predicts the present (un-delayed) car states given time delayed versions. We successfully train a neural network for the DTDF method and use a physical testbed to show that DTDF can mitigate the effects of constant time delays as large as 5s while maintaining superior control performance compared to that of a baseline control algorithm.",
        "primary_area": "",
        "author": "Kuei-Fang Hsueh;Ayleen Farnood;Mohammad Al Janaideh;Deepa Kundur;Kuei-Fang Hsueh;Ayleen Farnood;Mohammad Al Janaideh;Deepa Kundur",
        "authorids": "/37089197342;/37089658334;/37542671600;/37269460100;/37089197342;/37089658334;/37542671600;/37269460100",
        "aff": "Edward S. Rogers Sr. Department of Electrical Computer Engineering, University of Toronto, Toronto, ON, Canada; Edward S. Rogers Sr. Department of Electrical Computer Engineering, University of Toronto, Toronto, ON, Canada; Edward S. Rogers Sr. Department of Electrical Computer Engineering, University of Toronto, Toronto, ON, Canada; Edward S. Rogers Sr. Department of Electrical Computer Engineering, University of Toronto, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981245/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17501982001292156847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Edward S. Rogers Sr. Department of Electrical Computer Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981534",
        "title": "Hybrid Belief Pruning with Guarantees for Viewpoint-Dependent Semantic SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic simultaneous localization and mapping is a subject of increasing interest in robotics and AI that directly influences the autonomous vehicles industry, the army industries, and more. One of the challenges in this field is to obtain object classification jointly with robot trajectory estimation. Considering view-dependent semantic measurements, there is a coupling between different classes, resulting in a combinatorial number of hypotheses. A common solution is to prune hypotheses that have a sufficiently low probability and to retain only a limited number of hypotheses. However, after pruning and renormalization, the updated probability is overconfident with respect to the original probability. This is especially problematic for systems that require high accuracy. If the prior probability of the classes is independent, the original normalization factor can be computed efficiently without pruning hypotheses. To the best of our knowledge, this is the first work to present these results. If the prior probability of the classes is dependent, we propose a lower bound on the normalization factor that ensures cautious results. The bound is calculated incrementally and with similar efficiency as in the independent case. After pruning and updating based on the bound, this belief is shown empirically to be close to the original belief.",
        "primary_area": "",
        "author": "Tuvy Lemberg;Vadim Indelman;Tuvy Lemberg;Vadim Indelman",
        "authorids": "/37089659509;/37541538000;/37089659509;/37541538000",
        "aff": "Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981534/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:yz8QrrGZMcgJ:scholar.google.com/&scioq=Hybrid+Belief+Pruning+with+Guarantees+for+Viewpoint-Dependent+Semantic+SLAM&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981801",
        "title": "Hybrid Discrete-Continuous Path Planning for Lattice Traversal",
        "track": "main",
        "status": "Poster",
        "abstract": "Lattice structures allow robotic systems to operate in complex and hazardous environments, e.g. construction, mining and nuclear plants, reliably and effectively. However, current navigation systems for these structures are neither realistic, as they assume simplistic motion primitives and obstacle-free workspaces, nor efficient as they rely solely on global discrete search in an attempt to leverage the modularity of lattices. This paper tackles this gap and studies how robots can navigate lattice structures efficiently. We present a realistic application environment where robots have to avoid obstacles and the structure itself to reach target locations. Our solution couples discrete optimal search, using a domain-dependent heuristic, and sampling-based motion planning to find feasible trajectories in the discrete search space and in the continuous joint space at the same time. We provide two search graph formulations and a path planning approach. Simulation experiments, based on structures and robots created for the Innovate UK Connect-R project, examine scalability to large grid spaces while maintaining performances close to optimal.",
        "primary_area": "",
        "author": "Santiago Franco;Julius Sustarevas;Sara Bernardini;Santiago Franco;Julius Sustarevas;Sara Bernardini",
        "authorids": "/37089663022;/37086578524;/37088477602;/37089663022;/37086578524;/37088477602",
        "aff": "Royal Holloway University of London; Ross Robotics Ltd; Royal Holloway University of London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981801/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7356482399987998572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Royal Holloway, University of London;Ross Robotics",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.royalholloway.ac.uk;",
        "aff_unique_abbr": "RHUL;Ross Robotics",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981913",
        "title": "Hybrid LMC: Hybrid Learning and Model-based Control for Wheeled Humanoid Robot via Ensemble Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of wheeled humanoid locomotion is a challenging problem due to the nonlinear dynamics and under-actuated characteristics of these robots. Traditionally, feedback controllers have been utilized for stabilization and locomotion. However, these methods are often limited by the fidelity of the underlying model used, choice of controller, and environmental variables considered (surface type, ground inclination, etc). Recent advances in reinforcement learning (RL) offer promising methods to tackle some of these conventional feedback controller issues, but require large amounts of interaction data to learn. Here, we propose a hybrid learning and model-based controller Hybrid LMC that combines the strengths of a classical linear quadratic regulator (LQR) and ensemble deep reinforcement learning. Ensemble deep reinforcement learning is composed of multiple Soft Actor-Critic (SAC) and is utilized in reducing the variance of RL networks. By using a feedback controller in tandem the network exhibits stable performance in the early stages of training. As a preliminary step, we explore the viability of Hybrid LMC in controlling wheeled locomotion of a humanoid robot over a set of different physical parameters in MuJoCo simulator. Our results show that Hybrid LMC achieves better performance compared to other existing techniques and has increased sample efficiency.",
        "primary_area": "",
        "author": "Donghoon Baek;Amartya Purushottam;Joao Ramos;Donghoon Baek;Amartya Purushottam;Joao Ramos",
        "authorids": "/37086439599;/37089662302;/37085375922;/37086439599;/37089662302;/37085375922",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981913/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16189962931370124325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981829",
        "title": "HyperPocket: Generative Point Cloud Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Scanning real-life scenes with modern registration devices typically give incomplete point cloud representations, mostly due to the limitations of the scanning process and 3D occlusions. Therefore, completing such partial representations remains a fundamental challenge of many computer vision applications. Most of the existing approaches aim to solve this problem by learning to reconstruct individual 3D objects in a synthetic setup of an uncluttered environment, which is far from a real-life scenario. In this work, we reformulate the problem of point cloud completion into an objects hallucination task. Thus, we introduce a novel autoencoder-based architecture called HyperPocket that disentangles latent representations and, as a result, enables the generation of multiple variants of the completed 3D point clouds. Furthermore, we split point cloud processing into two disjoint data streams and leverage a hypernetwork paradigm to fill the spaces, dubbed pockets, that are left by the missing object parts. As a result, the generated point clouds are smooth, plausible, and geometrically consistent with the scene. Moreover, our method offers competitive performances to the other state-of-the-art models, enabling a plethora of novel applications.",
        "primary_area": "",
        "author": "P. Spurek;A. Kasymov;M. Mazur;D. Janik;S.K. Tadeja;\u0141. Struski;J. Tabor;T. Trzci\u0144ski;P. Spurek;A. Kasymov;M. Mazur;D. Janik;S.K. Tadeja;\u0141. Struski;J. Tabor;T. Trzci\u0144ski",
        "authorids": "/37085891502;/37089660808;/37089662422;/37089365753;/37088473005;/37089299526;/38242318800;/37586208900;/37085891502;/37089660808;/37089662422;/37089365753;/37088473005;/37089299526;/38242318800;/37586208900",
        "aff": "Jagiellonian University in Krak\u00f3w; Jagiellonian University in Krak\u00f3w; Jagiellonian University in Krak\u00f3w; Jagiellonian University in Krak\u00f3w; University of Cambridge; Jagiellonian University in Krak\u00f3w; Jagiellonian University in Krak\u00f3w; IDEAS NCBR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981829/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15179438538778689411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;0;2",
        "aff_unique_norm": "Jagiellonian University;University of Cambridge;Institute for Development, Economic Analysis, and Simulation (IDEAS)",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uj.edu.pl;https://www.cam.ac.uk;https://www.ideas-ncbr.gov.pl",
        "aff_unique_abbr": "UJ;Cambridge;IDEAS",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Krak\u00f3w;Cambridge;",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0",
        "aff_country_unique": "Poland;United Kingdom"
    },
    {
        "id": "9982183",
        "title": "ICK-Track: A Category-Level 6-DoF Pose Tracker Using Inter-Frame Consistent Keypoints for Aerial Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots that are supposed to interact with or manipulate objects in the world must be able to track the poses of objects in their sensor data. Thus, Detecting and tracking the 6-DoF poses of targeted objects is important for aerial manipulation and is still in the early stage due to the high dynamics and limited onboard capacity of such systems. In this paper, we propose ICK-Track, a novel method for onboard category-level object 6-DoF pose tracking that can be applied to aerial manipulation without using any pre-defined object CAD models. It first utilizes a semi-supervised video segmentation to detect objects in the eye-in-hand RGB-D camera stream to segment the 3D points of objects. Then, canonical keypoints are extracted using iterative farthest point sampling. We propose a novel inter-frame consistent keypoints generation network to generate the corresponding keypoint pairs, which are used together with ICP to estimate the pose changes of objects for tracking. Experimental results show that our method is more robust to viewpoint changes and runs faster than the state-of-the-art methods on category-level pose tracking. We further test our proposed method on a real aerial manipulator. A demo video showing the use of our method on a real aerial manipulator and the implementation of our method are available at: https://github.com/S-JingTao/ICK-Track.",
        "primary_area": "",
        "author": "Jingtao Sun;Yaonan Wang;Mingtao Feng;Danwei Wang;Jiawen Zhao;Cyrill Stachniss;Xieyuanli Chen;Jingtao Sun;Yaonan Wang;Mingtao Feng;Danwei Wang;Jiawen Zhao;Cyrill Stachniss;Xieyuanli Chen",
        "authorids": "/37089663941;/37281429000;/37085751865;/37279547600;/37089450243;/37329668600;/37086247697;/37089663941;/37281429000;/37085751865;/37279547600;/37089450243;/37329668600;/37086247697",
        "aff": "College of Electrical and Information Engineering, and the National Engineering Laboratory for Robot Visual Perception and Control (RVC-NATIONAL ENGNEERING LAB), Hunan University, Changsha, China; College of Electrical and Information Engineering, and the National Engineering Laboratory for Robot Visual Perception and Control (RVC-NATIONAL ENGNEERING LAB), Hunan University, Changsha, China; College of Electrical and Information Engineering, and the National Engineering Laboratory for Robot Visual Perception and Control (RVC-NATIONAL ENGNEERING LAB), Hunan University, Changsha, China; School of Electrical and Electrical Engineering, Nanyang Technological University, Singapore; College of Electrical and Information Engineering, and the National Engineering Laboratory for Robot Visual Perception and Control (RVC-NATIONAL ENGNEERING LAB), Hunan University, Changsha, China; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982183/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2114098991257334592&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;2",
        "aff_unique_norm": "Hunan University;Nanyang Technological University;University of Bonn",
        "aff_unique_dep": "College of Electrical and Information Engineering;School of Electrical and Computer Engineering;",
        "aff_unique_url": "http://www.hnu.edu.cn;https://www.ntu.edu.sg;https://www.uni-bonn.de",
        "aff_unique_abbr": "HNU;NTU;UBonn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha;",
        "aff_country_unique_index": "0;0;0;1;0;2;2",
        "aff_country_unique": "China;Singapore;Germany"
    },
    {
        "id": "9982087",
        "title": "IMU Dead-Reckoning Localization with RNN-IEKF Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "In complex urban environments, the Inertial Navigation System (INS) is important for navigating unmanned ground vehicles (UAVs) for its environment-independency and reliability of real-time localization. It is usually employed as the baseline in the case of other sensors failures, such as the GPS, Lidar, or Cameras. However, one problem for the INS is that its estimation error of localization accumulates over time, and thus the estimated trajectories of the UAVs continue to drift away from their ground truths. To solve this problem, this paper proposes an improved algorithm based on the Invariant Extended Kalman Filter (IEKF) for dead-reckoning of autonomous vehicles, which dynamically adjusts the process noise and the observation noise covariance matrixes through Attention mechanism and Recurrent Neural Network (RNN). The algorithm achieves more robust and accurate dead-reckoning localization in the experiments conducted on the KITTI dataset, reducing the translational error by about 45%compared to the baseline.",
        "primary_area": "",
        "author": "Hang Zhou;Yibo Zhao;Xiaogang Xiong;Yunjiang Lou;Shyam Kamal;Hang Zhou;Yibo Zhao;Xiaogang Xiong;Yunjiang Lou;Shyam Kamal",
        "authorids": "/37089661615;/37089661094;/37086475792;/37279072300;/38263628700;/37089661615;/37089661094;/37086475792;/37279072300;/38263628700",
        "aff": "Harbin Institute of Technology Shenzhen, Shenzhen, P.R. China; Harbin Institute of Technology Shenzhen, Shenzhen, P.R. China; Harbin Institute of Technology Shenzhen, Shenzhen, P.R. China; Harbin Institute of Technology Shenzhen, Shenzhen, P.R. China; Indian Institute of Technology (BHU), Varanasi, Uttar Pradesh, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982087/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1468873053163283364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Indian Institute of Technology (BHU)",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://en.hust.edu.cn/;https://www.iitbhu.ac.in",
        "aff_unique_abbr": "HIT;IIT (BHU)",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Varanasi",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;India"
    },
    {
        "id": "9981876",
        "title": "IMU preintegration for 2D SLAM problems using Lie Groups",
        "track": "main",
        "status": "Poster",
        "abstract": "2D SLAM is useful for mobile robots that are constrained to a 2D plane, for example in a warehouse, simplifying calculations in respect to the 3D case. The use of an IMU in such a context can enrich the estimation and make it more robust. In this paper we reformulate the IMU preintegration widely used in 3D problems for the 2D case, making use of Lie Theory. The Lie theory based formalization, first derived for a perfectly horizontal plane, allows us to easily extend it to problems where the plane is not orthogonal to the gravity vector. We implement the theory in a factor graph based estimation library, and carry out experiments to validate it on a mobile platform. Two experiments are carried out; on a horizontal and a sloped environment, and the sensor data is processed using our two 2D methods and a state-of-the-art 3D method.",
        "primary_area": "",
        "author": "Idril Geer;Joan Vallv\u00e9;Joan Sol\u00e0;Idril Geer;Joan Vallv\u00e9;Joan Sol\u00e0",
        "authorids": "/37089661068;/37085368339;/37407733200;/37089661068;/37085368339;/37407733200",
        "aff": "Mobile Robotics Laboratory, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Universitat Polit\u00e9cnica de Catalunya, Barcelona, Spain; Mobile Robotics Laboratory, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Universitat Polit\u00e9cnica de Catalunya, Barcelona, Spain; Mobile Robotics Laboratory, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Universitat Polit\u00e9cnica de Catalunya, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981876/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12656739398987191459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universitat Polit\u00e9cnica de Catalunya",
        "aff_unique_dep": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_url": "https://www.upc.edu",
        "aff_unique_abbr": "UPC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981673",
        "title": "Imitation Behavior of the Outer Edge of the Foot by Humanoids Using a Simplified Contact State Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a way to utilize humanoid robots to mimic human behavior by taking advantage of their human-like proportions. In general, motion capture is used; in this case, the posture of the body links can be taken. However, this method does not provide detailed information on the contact state, which is important for actions that involve contact with objects. In this study, we focused on the foot, which has not been paid much attention among the parts where contact and manipulation with objects are important, and developed a device to measure the contact pressure distribution at the outer edge of the sole. We proposed an index, SS-COP, which simply reflects the contact on the curved surface of the sole for this device and a robot foot with lateral force sensation and realized a behavior that imitates the foot condition of a humanoid robot by using this index.",
        "primary_area": "",
        "author": "Yoshimoto Ribayashi;Kento Kawaharazuka;Yasunori Toshimitsu;Daiki Kusuyama;Akihiro Miki;Koki Shinjo;Masahiro Baudo;Temma Suzuki;Yuta Kojio;Kei Okada;Masayuki Inaba;Yoshimoto Ribayashi;Kento Kawaharazuka;Yasunori Toshimitsu;Daiki Kusuyama;Akihiro Miki;Koki Shinjo;Masahiro Baudo;Temma Suzuki;Yuta Kojio;Kei Okada;Masayuki Inaba",
        "authorids": "/37089659025;/37086101930;/37086842924;/37088550039;/37089295157;/37087324644;/37089658386;/37089658134;/37086211574;/37280639000;/37286658200;/37089659025;/37086101930;/37086842924;/37088550039;/37089295157;/37087324644;/37089658386;/37089658134;/37086211574;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981673/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:pFx53Sd4sycJ:scholar.google.com/&scioq=Imitation+Behavior+of+the+Outer+Edge+of+the+Foot+by+Humanoids+Using+a+Simplified+Contact+State+Representation&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981220",
        "title": "Imitation Learning and Model Integrated Excavator Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated excavation is promising to improve the safety and efficiency of excavators, and trajectory planning is one of the most important techniques. In this paper, we propose a two-stage method that integrates data-driven imitation learning and model-based trajectory optimization to generate optimal trajectories for autonomous excavators. We firstly train a deep neural network using demonstration data to mimic the operation patterns of human experts under various terrain states including their geometry shape and material type. Then, we use a stochastic trajectory optimization method to improve the trajectory generated by the neural network to guarantee kinematics feasibility, improve smoothness, satisfy hard constraints, and achieve desired excavation volumes. We test the proposed algorithm on a Franka robot arm equipped with a bucket end-effector. We further evaluate our method on different material types, such as sand and rigid blocks. The ex-perimental results show that the proposed two-stage algorithm by combining expert knowledge and model optimization can increase the excavation weights by up to 24.77% meanwhile with low variance.",
        "primary_area": "",
        "author": "Qiangqiang Guo;Zhixian Ye;Liyang Wang;Liangjun Zhang;Qiangqiang Guo;Zhixian Ye;Liyang Wang;Liangjun Zhang",
        "authorids": "/37089659581;/37089515644;/37089516532;/37088642847;/37089659581;/37089515644;/37089516532;/37088642847",
        "aff": "Baidu USA; Robotics and Autonomous Driving Lab., Baidu USA, Sunnyvale, CA, USA; Robotics and Autonomous Driving Lab., Baidu USA, Sunnyvale, CA, USA; Robotics and Autonomous Driving Lab., Baidu USA, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981220/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=945639359094693595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Baidu",
        "aff_unique_url": "https://www.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "USA;Sunnyvale",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981683",
        "title": "Imitation of Manipulation Skills Using Multiple Geometries",
        "track": "main",
        "status": "Poster",
        "abstract": "Daily manipulation tasks are characterized by geometric primitives related to actions and object shapes. Such geometric descriptors are poorly represented by only using Cartesian coordinate systems. In this paper, we propose a learning approach to extract the optimal representation from a dictionary of coordinate systems to encode an observed movement/behavior. This is achieved by using an extension of Gaussian distributions on Riemannian manifolds, which is used to analyse a set of user demonstrations statistically, by considering multiple geometries as candidate representations of the task. We formulate the reproduction problem as a general optimal control problem based on an iterative linear quadratic regulator (iLQR), where the Gaussian distribution in the extracted coordinate systems are used to define the cost function. We apply our approach to object grasping and box opening tasks in simulation and on a 7-axis Franka Emika robot. The results show that the robot can exploit several geometries to execute the manipulation task and generalize it to new situations, by maintaining the invariant characteristics of the task in the coordinate system(s) of interest.",
        "primary_area": "",
        "author": "Boyang Ti;Yongsheng Gao;Jie Zhao;Sylvain Calinon;Boyang Ti;Yongsheng Gao;Jie Zhao;Sylvain Calinon",
        "authorids": "/37086807186;/38469183900;/37279457400;/37295947200;/37086807186;/38469183900;/37279457400;/37295947200",
        "aff": "Idiap Research Institute, Martigny, Switzerland; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Idiap Research Institute, Martigny, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981683/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13570871065016086659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Idiap Research Institute;Harbin Institute of Technology",
        "aff_unique_dep": ";State Key Laboratory of Robotics and System",
        "aff_unique_url": "https://www.idiap.ch;http://www.hit.edu.cn/",
        "aff_unique_abbr": "Idiap;HIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Martigny;Harbin",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Switzerland;China"
    },
    {
        "id": "9981656",
        "title": "Immersive View and Interface Design for Teleoperated Aerial Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent momentum in aerial manipulation has led to an interest in developing virtual reality interfaces for aerial physical interaction tasks with simple, intuitive, and reliable control and perception. However, this requires the use of expensive subsystems and there is still a research gap between interface design, user evaluations and the effect on aerial manipulation tasks. Here, we present a methodology for low-cost available drone systems with a Unity-based interface for immersive FPV teleoperation. We applied our approach in a flight track where a cluttered environment is used to simulate a demanding aerial manipulation task inspired by forestry drones and canopy sampling. Through objective measures of teleoperation performance and subjective questionnaires, we found that operators performed worse using the FPV interface and had higher perceived levels of cognitive load when compared to traditional interface design. Additional analysis of physiological measures highlighted that objective stress levels and cognitive load were also influenced by task duration and perceived performance, providing an insight into what interfaces could target to support teleoperator requirements during aerial manipulation tasks.",
        "primary_area": "",
        "author": "Basaran Bahadir Kocer;Harvey Stedman;Patryk Kulik;Izaak Caves;Nejra Van Zalk;Vijay M. Pawar;Mirko Kovac;Basaran Bahadir Kocer;Harvey Stedman;Patryk Kulik;Izaak Caves;Nejra Van Zalk;Vijay M. Pawar;Mirko Kovac",
        "authorids": "/37072753900;/37089642730;/37089660028;/37089659870;/37088576023;/38191148100;/37085542534;/37072753900;/37089642730;/37089660028;/37089659870;/37088576023;/38191148100;/37085542534",
        "aff": "Aerial Robotics Laboratory, Imperial College London, London, UK; Department of Computer Science, Autonomous Manufacturing Laboratory, University College London, UK; Aerial Robotics Laboratory, Imperial College London, London, UK; Aerial Robotics Laboratory, Imperial College London, London, UK; Dyson School of Design Engineering, Imperial College London, London, UK; Department of Computer Science, Autonomous Manufacturing Laboratory, University College London, UK; Materials and Technology Center of Robotics at the Swiss Federal Laboratories for Materials Science and Technology, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981656/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16794588759569208748&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;1;2",
        "aff_unique_norm": "Imperial College London;University College London;Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Aerial Robotics Laboratory;Department of Computer Science;Materials and Technology Center of Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ucl.ac.uk;https://www.empa.ch",
        "aff_unique_abbr": "ICL;UCL;EMPA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "United Kingdom;Switzerland"
    },
    {
        "id": "9981510",
        "title": "Impact Makes a Sound and Sound Makes an Impact: Sound Guides Representations and Explorations",
        "track": "main",
        "status": "Poster",
        "abstract": "Sound is one of the most informative and abundant modalities in the real world while being robust to sense without contacts by small and cheap sensors that can be placed on mobile devices. Although deep learning is capable of extracting information from multiple sensory inputs, there has been little use of sound for the control and learning of robotic actions. For unsupervised reinforcement learning, an agent is expected to actively collect experiences and jointly learn representations and policies in a self-supervised way. We build realistic robotic manipulation scenarios with physics-based sound simulation and propose the Intrinsic Sound Curiosity Module (ISCM). The ISCM provides feedback to a reinforcement learner to learn robust representations and to reward a more efficient exploration behavior. We perform experiments with sound enabled during pre-training and disabled during adaptation, and show that representations learned by ISCM outperform the ones by vision-only baselines and pre-trained policies can accelerate the learning process when applied to downstream tasks.",
        "primary_area": "",
        "author": "Xufeng Zhao;Cornelius Weber;Muhammad Burhan Hafez;Stefan Wermter;Xufeng Zhao;Cornelius Weber;Muhammad Burhan Hafez;Stefan Wermter",
        "authorids": "/37089658913;/37549767100;/37085587954;/37323875400;/37089658913;/37549767100;/37085587954;/37323875400",
        "aff": "Department of Informatics, Knowledge Technology Group, Universit\u00e4t Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, Universit\u00e4t Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, Universit\u00e4t Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, Universit\u00e4t Hamburg, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981510/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13943072456640052881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg",
        "aff_unique_dep": "Department of Informatics, Knowledge Technology Group",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "UHH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hamburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981772",
        "title": "Implicit-Part Based Context Aggregation for Point Cloud Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Context information is important for instance segmentation on point clouds. Existing methods either only use local surroundings by stacking multiple convolution layers or use non-local methods to model long-range interactions. However, they usually directly operate on points which is an unstructured and low-level representation and is highly dependent on context. To address this issue, we propose an effective framework named Implicit-Part Context Aggregation (IPCA), which adopts implicit parts as an intermediate representation and achieves context aggregation through message passing along the implicit part graph. Specifically, we first organize unstructured points into geometrically consistent implicit parts and construct the implicit part graph according to the geometric adjacency. Then, an initial part embedding is extracted using the proposed Implicit Part Network (IPN) which can aggregate point features and capture the intrinsic geometric shape of the part. We further refine the part embedding by a graph reasoning module named Context Aggregation Network (CAN), which helps to make a more precise prediction by well exploiting the context information. Instance proposals are then generated by grouping implicit parts. Finally, we propose an additional step to attribute the entire instance proposal to a Semantic Criterion Net (SCN) to infer the semantics of the instance. The purpose is to correct the semantic prediction errors caused by not knowing the boundary and overall shape of the object in the previous steps. Extensive experiments on two large datasets, ScanNet and 3RScan, demonstrate the effectiveness of our method. To our knowledge, it yields the highest performance on the ScanNet test benchmark and its AP@50 is 9.5 points higher than the baseline. The code is available at https://github.com/xiaodongww/IPCA",
        "primary_area": "",
        "author": "Xiaodong Wu;Ruiping Wang;Xilin Chen;Xiaodong Wu;Ruiping Wang;Xilin Chen",
        "authorids": "/37089658679;/37085350985;/37278215600;/37089658679;/37085350985;/37278215600",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981772/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Q6ACTD7PXHoJ:scholar.google.com/&scioq=Implicit-Part+Based+Context+Aggregation+for+Point+Cloud+Instance+Segmentation&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.ucas.ac.cn",
        "aff_unique_abbr": "UCAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981448",
        "title": "Impressionist Algorithms for Autonomous Multi-Robot Systems: Flocking as a Case Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot swarms have the potential to revolutionize areas ranging from warehouse management and agriculture to underwater and space exploration. However, there remains a substantial gap between theory and robot implementation. While algorithms might assume reliable communication, perfect sensing, and instantaneous cognition, most robots have lossy or even no communication, imperfect sensing, and limited cognition speed. In our previous work on implicit vision-based coordination, we demonstrated autonomous three-dimensional behaviors underwater by removing the need for radio communication between robots. Here we explore impressionist algorithms, capable of working with even more minimal information where traditional algorithms are prone to fail. Our case study focuses on classic flocking behaviors, where a robot swarm must coordinate group motion. We demonstrate that reliable alignment, dispersion, and milling can be achieved with only infrequent and imperfect sensory impressions. In simulation studies and theoretical analyses, we investigate the effect of systematically reducing spatial and temporal fidelity of individual information on the success metrics for the group; we also demonstrate physical experiments with Blueswarm robots using simple color detection. Our results show the potential of impressionist algorithms that operate on simpler neighborhood-awareness metrics and still achieve desired global goals.",
        "primary_area": "",
        "author": "Florian Berlinger;Julia T. Ebert;Radhika Nagpal;Florian Berlinger;Julia T. Ebert;Radhika Nagpal",
        "authorids": "/37086054307;/37086454657;/37286742900;/37086054307;/37086454657;/37286742900",
        "aff": "Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, New Jersey; John A. Paulson School of Engineering and Applied Science at Harvard University, Cambridge, Massachusetts; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, New Jersey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981448/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9705217310257612796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Princeton University;Harvard University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;John A. Paulson School of Engineering and Applied Science",
        "aff_unique_url": "https://www.princeton.edu;https://www.seas.harvard.edu",
        "aff_unique_abbr": "Princeton;Harvard SEAS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Princeton;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982121",
        "title": "Improved A-Search Guided Tree for Autonomous Trailer Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a motion planning strategy that utilizes the improved A -search guided tree to enable autonomous parking of a general 3-trailer with a car-like tractor. Different from the state-of-the-art state-lattice-based methods, where numerous motion primitives are necessary to ensure successful planning, our work allows quick off-lattice exploration to find a solution. Our treatment brings at least three advantages: fewer and lower design complexity of motion primitives, improved success rate, and increased path quality. Unlike on-lattice exploration, where the cost-to-go is obtained by querying a heuristic look-up table, off-lattice exploration entails the heuristic function being well-defined at off-lattice nodes. We train a neural network through reinforcement learning to model the maneuver costs of the trailer and use it as the heuristic value to better approximate the cost-to-go. Simulations demonstrate the effectiveness of the proposed method in terms of planning speed and path length.",
        "primary_area": "",
        "author": "Jessica Leu;Yebin Wang;Masayoshi Tomizuka;Stefano Di Cairano;Jessica Leu;Yebin Wang;Masayoshi Tomizuka;Stefano Di Cairano",
        "authorids": "/37086917046;/37407582500;/37281933000;/37545385600;/37086917046;/37407582500;/37281933000;/37545385600",
        "aff": "Mitsubishi Electric Research Laboratories; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982121/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10683042555788549686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories;University of California, Berkeley",
        "aff_unique_dep": ";Department of Mechanical Engineering",
        "aff_unique_url": "https://www.merl.com;https://www.berkeley.edu",
        "aff_unique_abbr": "MERL;UC Berkeley",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Cambridge;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981859",
        "title": "Improved Performance of CPG Parameter Inference for Path-following Control of Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The difficulty associated with the coordinated locomotion of legged robots grows quickly as the number of joints increases. Although prior approaches have addressed this problem through sampling-based planners, learning-based techniques have recently been explored as a means to handle such complexity. Among these recent approaches are systems that utilize probabilistic graphical models in order to infer parameters for central pattern generators (CPGs) which enable the path-following locomotion of highly-articulated legged robots through unstructured terrain. This paper presents a novel formulation of a CPG parameter inference-based path-following controller. The new inference process and accompanying CPG formulation enforce oscillator convergence to the limit-cycle specified by the inferred parameters in addition to biasing towards parameters that quickly reach stable-state. This formulation is shown to improve the performance of CPG parameter inference-based path-following control for legged robots across a number of simulated and physical experiments.",
        "primary_area": "",
        "author": "Nathan D. Kent;David Neiman;Matthew Travers;Thomas M. Howard;Nathan D. Kent;David Neiman;Matthew Travers;Thomas M. Howard",
        "authorids": "/37086961409;/37088955090;/37545390200;/37546611500;/37086961409;/37088955090;/37545390200;/37546611500",
        "aff": "Robotics and Artificial Intelligence Laboratory, University of Rochester, Rochester, NY, USA; Biorobotics Lab, Carnegie Mellon University, Pittsburgh, PA, USA; Biorobotics Lab, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics and Artificial Intelligence Laboratory, University of Rochester, Rochester, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981859/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7099459222877449484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Rochester;Carnegie Mellon University",
        "aff_unique_dep": "Robotics and Artificial Intelligence Laboratory;Biorobotics Lab",
        "aff_unique_url": "https://www.rochester.edu;https://www.cmu.edu",
        "aff_unique_abbr": "U of R;CMU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Rochester;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981621",
        "title": "Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement Learning with Prior Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "Meta Reinforcement Learning (Meta-RL) has seen substantial advancements recently. In particular, off-policy methods were developed to improve the data efficiency of Meta-RL techniques. Probabilistic embeddings for actor-critic \\boldsymbol{RL}\\boldsymbol{RL} (PEARL) is a leading approach for multi-MDP adaptation problems. A major drawback of many existing Meta-RL methods, including PEARL, is that they do not explicitly consider the safety of the prior policy when it is exposed to a new task for the first time. Safety is essential for many real world applications, including field robots and Autonomous Vehicles (AVs), In this paper, we develop the PEARL PLUS (PEARL+) algorithm, which optimizes the policy for both prior (pre-adaptation) safety and posterior (after-adaptation) performance. Building on top of PEARL, our proposed PEARL+ algorithm introduces a prior regularization term in the reward function and a new Q-network for recovering the state-action value under prior context assumptions, to improve the robustness to task distribution shift and safety of the trained network exposed to a new task for the first time. The performance of PEARL+ is validated by solving three safety-critical problems related to robots and AVs, including two MuJoCo benchmark problems. From the simulation experiments, we show that safety of the prior policy is significantly improved and more robust to task distribution shift compared to PEARL.",
        "primary_area": "",
        "author": "Lu Wen;Songan Zhang;H. Eric Tseng;Baljeet Singh;Dimitar Filev;Huei Peng;Lu Wen;Songan Zhang;H. Eric Tseng;Baljeet Singh;Dimitar Filev;Huei Peng",
        "authorids": "/37088595919;/37086546502;/37289120000;/37089734856;/37271541000;/37273793500;/37088595919;/37086546502;/37289120000;/37089734856;/37271541000;/37273793500",
        "aff": "Mechanical Engineering, University of Michigan; Ford Research and Advanced Engineering; Ford Research and Advanced Engineering; Ford Research and Advanced Engineering; Ford Research and Advanced Engineering; Mechanical Engineering, University of Michigan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981621/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10586128083824223176&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "University of Michigan;Ford Motor Company",
        "aff_unique_dep": "Mechanical Engineering;Research and Advanced Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.ford.com",
        "aff_unique_abbr": "UM;Ford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981385",
        "title": "Improved Task Space Locomotion Controller for a Quadruped Robot with Parallel Mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, an advanced quadruped robot with abundant kinematic loops and passive joints is introduced. Due to the existence of many closed chains, the robot dynamic model is quite complex, and is derived using the Gauss's principle of least constraint. To explicitly consider the loop-closure constraints, we propose a task-space inverse dynamics based approach to obtain the robot locomotion controller. Besides, to meet the demand of high frequency (\u2265 500Hz) in controller, an alternative method is provided. It uses the projected dynamics to find an analytical mapping from the desired contact force to the desired torque of actuators under full consideration of passive joints and loop-closure constraints. The effectiveness and efficiency of the proposed algorithms in this paper have been validated by simulation with a reliable physical engine MuJoCo.",
        "primary_area": "",
        "author": "Shunpeng Yang;Wenchun Lin;Jaeho Noh;Cheng Luo;Bill Huang;Wei Zhang;Hua Chen;Shunpeng Yang;Wenchun Lin;Jaeho Noh;Cheng Luo;Bill Huang;Wei Zhang;Hua Chen",
        "authorids": "/37088996360;/37089196921;/37086070089;/37089662270;/37089658848;/37089656248;/37086195529;/37088996360;/37089196921;/37086070089;/37089662270;/37089658848;/37089656248;/37086195529",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; CloudMinds Robotics Inc., Shanghai, China; CloudMinds Robotics Inc., Shanghai, China; CloudMinds Robotics Inc., Shanghai, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981385/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3139486056249585352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;CloudMinds Robotics Inc.",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering;",
        "aff_unique_url": "https://www.sustech.edu.cn;",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981193",
        "title": "Improved Zero Step Push Recovery with a Unified Reduced Order Model of Standing Balance",
        "track": "main",
        "status": "Poster",
        "abstract": "Standing balance for legged robots can be achieved through regulating the center of pressure (ankle strategy), the angular momentum about the center of mass (hip strategy), and the magnitude of ground reaction force (variable height strategy). Prevalent reduced order models used to model legged robots at most only capture two of these strategies, and the contribution of the three available strategies is unclear. We propose a unified reduced order model that includes all three standing balance strategies and compared push recovery simulations of the unified model against existing balancing models using a nonlinear model predictive controller. We also developed a full body controller for a simple one legged balancing robot that tracked control from the reduced order models. For both the reduced order model and robot simulations, we found that the unified model could recover successfully from the largest pushes and yielded the smallest center of mass excursions. Between the hip and variable height strategies, the hip had the greatest effect on improving performance. Our results suggest that successful implementation of a unified reduced order model on physical robots would enable a simplified controller that takes advantage of available balancing strategies as needed to recover from larger push disturbances than feasible before.",
        "primary_area": "",
        "author": "Thomas Huckell;Amy R. Wu;Thomas Huckell;Amy R. Wu",
        "authorids": "/37089662434;/37085862075;/37089662434;/37085862075",
        "aff": "Department of Mechanical and Materials Engineering and Ingenuity Labs Research Institute Queen's University, Kingston, Ontario, Canada; Department of Mechanical and Materials Engineering and Ingenuity Labs Research Institute Queen's University, Kingston, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981193/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3849001625931327145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen's University",
        "aff_unique_dep": "Department of Mechanical and Materials Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982027",
        "title": "Improved biped walking performance around the kinematic singularities of biomimetic four-bar knees",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the effects of replacing pin-joint knees in passive dynamic bipedal walkers with biomimetic four-bar knees. The kinetic model of the four-bar knees is presented in detail, and an analytical model of the passive walking dynamics is derived. The resulting four-bar kneed biped is compared with a pin-joint kneed walker, for their passive walking performance. The geometry of the four-bar knees used in the study is based on human anatomical data. It is found that the biomimetic four-bar knee configuration works to the advantage of the biped, especially around the extended-knee singular position. The four-bar knees are found to overperform the pin-joint ones, resulting in significant reduction of peak impact loads and energetic expenditure.",
        "primary_area": "",
        "author": "Aikaterini Smyrli;Evangelos Papadopoulos;Aikaterini Smyrli;Evangelos Papadopoulos",
        "authorids": "/37086455674;/37273090500;/37086455674;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens; School of Mechanical Engineering, National Technical University of Athens",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982027/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4392659719494225149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981746",
        "title": "Improving 3D Markerless Pose Estimation of Animals in the Wild using Low-Cost Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking the 3D motion of agile animals in the wild will enable new insight into the design of robotic controllers. However, in-field 3D pose estimation of high-speed wildlife such as cheetahs is still a challenge [1]. In this work, we aim to solve two of these challenges: unnatural pose estimates during highly occluded sequences and synchronization error between multi-view data. We expand on our previous Full Trajectory Estimation (FTE) method with two significant additions: Pairwise FTE (PW-FTE) and Shutter-delay FTE (SD-FTE). The PW-FTE expands on image-dependent pairwise terms, produced by a convolutional neural network (CNN), to infer occluded 2D keypoints, while SD-FTE uses shutter delay estimation to correct the synchronization error. Lastly, we combine both methods into PW-SD-FTE and perform a quantitative and qualitative analysis on a subset of AcinoSet, the video dataset of rapid and agile motions of cheetahs. We found that SD-FTE has significant benefits in tracking the position of the cheetah in the world frame, while PW-FTE provided a more robust 3D pose estimate during events of high occlusion. The PW-SD-FTE was found to retain both advantages, resulting in an improved baseline for AcinoSet. Code and data can be found at https://github.com/African-Robotics-Unit/AcinoSet/tree/pw_sd_fte.",
        "primary_area": "",
        "author": "Naoya Muramatsu;Zico da Silva;Daniel Joska;Fred Nicolls;Amir Patel;Naoya Muramatsu;Zico da Silva;Daniel Joska;Fred Nicolls;Amir Patel",
        "authorids": "/37088996058;/37089663164;/37089000631;/38667731900;/38029333400;/37088996058;/37089663164;/37089000631;/38667731900;/38029333400",
        "aff": "African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981746/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10726271896966086263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "African Robotics Unit (ARU)",
        "aff_unique_url": "https://www.ru.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9981293",
        "title": "Improving Marine Radar Odometry by Modeling Radar Resolution and Exploiting Additional Temporal Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar odometry may provide valuable input for surface vessels in several marine applications. The vulnerability of global positioning satellite systems to jamming and spoofing motivates the search for alternatives. In this work, we investigate the feasibility of W-band frequency modulated continuous wave radars in marine settings for odometry. A method to model radar resolution is presented and is further extend to include multiple radar frames. Numerical implementation relies on concepts from Lie theory. The proposed methods were evaluated on datasets collected from a ferry in a harbour area, where the average relative translation error was reduced to 3.07% compared to 14.2% of a baseline method.",
        "primary_area": "",
        "author": "Carl H. Schiller;Bruno Arsenali;Deran Maas;Stefano Maran\u00f3;Carl H. Schiller;Bruno Arsenali;Deran Maas;Stefano Maran\u00f3",
        "authorids": "/37089176947;/37085825336;/37544784400;/37089734107;/37089176947;/37085825336;/37544784400;/37089734107",
        "aff": "ABB Corporate Research, Baden-D\u00e4ttwil, Switzerland; ABB Corporate Research, Baden-D\u00e4ttwil, Switzerland; ABB Corporate Research, Baden-D\u00e4ttwil, Switzerland; ABB Corporate Research, Baden-D\u00e4ttwil, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981293/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4979368305046269606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ABB Corporate Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://new.abb.com/research",
        "aff_unique_abbr": "ABB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982024",
        "title": "Improving Single-View Mesh Reconstruction for Unseen Categories via Primitive-Based Representation and Mesh Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "As most existing works of single-view 3D reconstruction aim at learning the better mapping functions to directly transform the 2D observation into the corresponding 3D shape for achieving state-of-the-art performance, there often comes a potential concern on having the implicit bias towards the seen classes learnt in their models (i.e. reconstruction intertwined with the classification) thus leading to poor generalizability for the unseen object categories. Moreover, such implicit bias typically stemmed from adopting the object-centered coordinate in their model designs, in which the reconstructed 3D shapes of the same class are all aligned to the same canonical pose regardless of different view-angles in the 2D observations. To this end, we propose an end-to-end framework to reconstruct the 3D mesh from a single image, where the reconstructed mesh is not only view-centered (i.e. its 3D pose respects the viewpoint of the 2D observation) but also preliminarily represented as a composition of volumetric 3D primitives before being further deformed into the fine-grained mesh to capture the shape details. In particular, the usage of volumetric primitives is motivated from the assumption that there generally exists some similar shape parts shared across various object categories, learning to estimate the primitive-based 3D model thus becomes more generalizable to the unseen categories. Furthermore, we advance to propose a novel mesh augmentation strategy, CvxRearrangement, to enrich the distribution of training shapes, which contributes to increasing the robustness of our proposed model and achieves better generalization. Extensive experiments demonstrate that our proposed method provides superior performance on both unseen and seen classes in comparison to several representative baselines of single-view 3D reconstruction.",
        "primary_area": "",
        "author": "Yu-Liang Kuo;Wei-Jan Ko;Chen-Yi Chiu;Wei-Chen Chiu;Yu-Liang Kuo;Wei-Jan Ko;Chen-Yi Chiu;Wei-Chen Chiu",
        "authorids": "/37089663332;/37086698530;/37089660931;/37086286145;/37089663332;/37086698530;/37089660931;/37086286145",
        "aff": "Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982024/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:q_zZgHDQAjkJ:scholar.google.com/&scioq=Improving+Single-View+Mesh+Reconstruction+for+Unseen+Categories+via+Primitive-Based+Representation+and+Mesh+Augmentation&hl=en&as_sdt=0,14",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NCTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981753",
        "title": "Improving the Efficiency of Sampling-based Motion Planners via Runtime Predictions for Motion-Planning Problems with Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "While sampling-based approaches have made significant progress, motion planning with dynamics still poses significant challenges as the planner has to generate not only collision-free but also dynamically-feasible trajectories that enable the robot to reach its goal. To improve the efficiency of sampling-based motion planners, this paper develops a framework, termed Motion-Planning Runtime Prediction (MPRP), that relies on machine learning to train models to predict the expected runtime of a planner. When solving a new motion-planning problem, the trained model is then incorporated into the motion planner to more effectively guide the search toward parts of the state space that are associated with low expected runtime predictions. This paper applies the MPRP framework to state-of-the-art sampling-based motion planners to obtain new planners, which are shown to be significantly faster.",
        "primary_area": "",
        "author": "Hoang-Dung Bui;Yuanjie Lu;Erion Plaku;Hoang-Dung Bui;Yuanjie Lu;Erion Plaku",
        "authorids": "/37088687696;/37089238232;/37541383900;/37088687696;/37089238232;/37541383900",
        "aff": "Department of Computer Science, George Mason University, VA, USA; Department of Computer Science, George Mason University, VA, USA; Department of Computer Science, George Mason University, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981753/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13375591218016175174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Fairfax",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982281",
        "title": "In-hand Manipulation Exploiting Bending and Compression Deformations of Caterpillar-Locomotion-Inspired Fingers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method of realizing in-hand manipulation inspired by the peristaltic motion of a large-sized caterpillar. The sharp contrast between the proposed soft-bodied finger and the conventional hard/rigid robotic ones is peristaltic motion with compression and bending deformations. The design is based on the biological fact that large-size caterpillars (e.g., Bombyx mori) utilize bending and compression/extension of the body to produce crawling locomotion. Exploiting the multi-modal deformations, we demonstrated that the prototype hand comprising two proposed fingers could rotate and transport grasped objects. We also observed that the time gap of two-finger motion is required to stabilize in-hand manipulation. The design can provide new insights into designing a gripper inspired by soft-bodied creatures.",
        "primary_area": "",
        "author": "Tomoya Onodera;Noriyasu Iwamoto;Takuya Umedachi;Tomoya Onodera;Noriyasu Iwamoto;Takuya Umedachi",
        "authorids": "/37089662032;/37085560254;/37546535500;/37089662032;/37085560254;/37546535500",
        "aff": "Faculty of Textile Science and Technology, Shinshu University, Ueda City, Nagano, Japan; Faculty of Textile Science and Technology, Shinshu University, Ueda City, Nagano, Japan; Faculty of Textile Science and Technology, Shinshu University, Ueda City, Nagano, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982281/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8752959870664748960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shinshu University",
        "aff_unique_dep": "Faculty of Textile Science and Technology",
        "aff_unique_url": "https://www.shinshu-u.ac.jp",
        "aff_unique_abbr": "Shinshu U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ueda City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982178",
        "title": "InCOpt: Incremental Constrained Optimization using the Bayes Tree",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we investigate the problem of incre-mentally solving constrained non-linear optimization problems formulated as factor graphs. Prior incremental solvers were either restricted to the unconstrained case or required periodic batch relinearizations of the objective and constraints which are expensive and detract from the online nature of the algorithm. We present InCOpt, an Augmented Lagrangian-based incremental constrained optimizer that views matrix operations as message passing over the Bayes tree. We first show how the linear system, resulting from linearizing the constrained objective, can be represented as a Bayes tree. We then propose an algorithm that views forward and back substitutions, which naturally arise from solving the Lagrangian, as upward and downward passes on the tree. Using this formulation, In-COpt can exploit properties such as fluid/online relinearization leading to increased accuracy without a sacrifice in runtime. We evaluate our solver on different applications (navigation and manipulation) and provide an extensive evaluation against existing constrained and unconstrained solvers.",
        "primary_area": "",
        "author": "Mohamad Qadri;Paloma Sodhi;Joshua G. Mangelson;Frank Dellaert;Michael Kaess;Mohamad Qadri;Paloma Sodhi;Joshua G. Mangelson;Frank Dellaert;Michael Kaess",
        "authorids": "/37089659857;/38469682300;/37086109836;/37282902200;/37324200400;/37089659857;/38469682300;/37086109836;/37282902200;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA; Electrical and Computer Engineering Department, Brigham Young University, USA; School of Interactive Computing, Georgia Institute of Technology, USA; Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982178/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14128795929314386657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Brigham Young University;Georgia Institute of Technology",
        "aff_unique_dep": "Robotics Institute;Electrical and Computer Engineering Department;School of Interactive Computing",
        "aff_unique_url": "https://www.cmu.edu;https://www.byu.edu;https://www.gatech.edu",
        "aff_unique_abbr": "CMU;BYU;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981252",
        "title": "InCloud: Incremental Learning for Point Cloud Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is a fundamental component of robotics, and has seen tremendous improvements through the use of deep learning models in recent years. Networks can experience significant drops in performance when deployed in unseen or highly dynamic environments, and require additional training on the collected data. However naively fine-tuning on new training distributions can cause severe degradation of performance on previously visited domains, a phenomenon known as catastrophic forgetting. In this paper we address the problem of incremental learning for point cloud place recognition and introduce InCloud, a structure-aware distillation-based approach which preserves the higher-order structure of the network's embedding space. We introduce several challenging new benchmarks on four popular and large-scale LiDAR datasets (Oxford, MulRan, In-house and KITTI) showing broad improvements in point cloud place recognition performance over a variety of network architectures. To the best of our knowledge, this work is the first to effectively apply incremental learning for point cloud place recognition. Data pre-processing, training and evaluation code for this paper can be found at https://github.com/csiro-robotics/InCloud.",
        "primary_area": "",
        "author": "Joshua Knights;Peyman Moghadam;Milad Ramezani;Sridha Sridharan;Clinton Fookes;Joshua Knights;Peyman Moghadam;Milad Ramezani;Sridha Sridharan;Clinton Fookes",
        "authorids": "/37088854855;/37666497200;/37088504403;/37266096100;/37281919100;/37088854855;/37666497200;/37088504403;/37266096100;/37281919100",
        "aff": "Artificial Intelligence and Vision Technologies (SAIVT) at the Queensland University of Technology (QUT), Brisbane, Australia; Artificial Intelligence and Vision Technologies (SAIVT) at the Queensland University of Technology (QUT), Brisbane, Australia; Robotics and Autonomous Systems, DATA61, CSIRO, Brisbane, QLD, Australia; Artificial Intelligence and Vision Technologies (SAIVT) at the Queensland University of Technology (QUT), Brisbane, Australia; Artificial Intelligence and Vision Technologies (SAIVT) at the Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981252/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12520430137393545813&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Queensland University of Technology;CSIRO",
        "aff_unique_dep": "Artificial Intelligence and Vision Technologies;Robotics and Autonomous Systems",
        "aff_unique_url": "https://www.qut.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "QUT;CSIRO",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981379",
        "title": "Incremental Path Planning Algorithm via Topological Mapping with Metric Gluing",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an incremental topology-based motion planner that, while planning paths in the configuration space, performs metric gluing on the constructed Vietoris-Rips simplicial complex of each sub-space (voxel). By incrementally capturing topological and geometric information in batches of voxel graphs, our algorithm avoids the time overhead of analyzing the properties of the entire configuration space. We theoretically prove in this paper that the simplices of all voxel graphs joined together are homotopy-equivalent to the union of the simplices in the configuration space. Experiments were carried out in seven different environments using various robots, including the articulated linkage robot, the Kuka YouBot, and the PR2 robot. In all environments, the results show that our algorithm achieves better convergence for path cost and computation time with a memory-efficient roadmap than state-of-the-art methods.",
        "primary_area": "",
        "author": "Aakriti Upadhyay;Boris Goldfarb;Chinwe Ekenna;Aakriti Upadhyay;Boris Goldfarb;Chinwe Ekenna",
        "authorids": "/37086395279;/37089196391;/37085676589;/37086395279;/37089196391;/37085676589",
        "aff": "Department of Computer Science, University at Albany, SUNY; Department of Mathematics and Statistics, University at Albany, SUNY; Department of Computer Science, University at Albany, SUNY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981379/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5294752400627431049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University at Albany, SUNY",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.albany.edu",
        "aff_unique_abbr": "UAlbany",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Albany",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982106",
        "title": "IndoLayout: Leveraging Attention for Extended Indoor Layout Estimation from an RGB Image",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose IndoLayout, a novel real-time approach for generating high-quality occupancy maps from an RGB image for indoor scenes. Such occupancy maps are often crucial for path-planning and mapping in indoor environments but are often built using only information contained in the ego view. In contrast, our approach also predicts occupancy values beyond immediately visible regions from just a monocular image, leveraging learnt priors from indoor scenes. Hence, our proposed network can produce a hallucinated, amodal scene layout that includes areas occluded in the RGB image, such as a navigable floor behind a desk. Specifically, we propose a novel architecture that uses self-attention and adversarial learning to vastly improve the quality of the predicted layout. We evaluate our model on several photorealistic indoor datasets and outperform previous relevant work on all metrics that measure layout quality, including newly adopted ones. Finally, we demonstrate the effectiveness of our method by showing significant improvements on the PointNav task over similar approaches using IndoLayout. For more details, please refer to the project page: https://indolayout.github.io/.",
        "primary_area": "",
        "author": "Shantanu Singh;Jaidev Shriram;Shaantanu Kulkarni;Brojeshwar Bhowmick;K. Madhava Krishna;Shantanu Singh;Jaidev Shriram;Shaantanu Kulkarni;Brojeshwar Bhowmick;K. Madhava Krishna",
        "authorids": "/37089660241;/37089662742;/37089662574;/37571664300;/38201465600;/37089660241;/37089662742;/37089662574;/37571664300;/38201465600",
        "aff": "IIIT, Robotics Research Center, Hyderabad; IIIT, Robotics Research Center, Hyderabad; IIIT, Robotics Research Center, Hyderabad; TCS Research, Kolkata, India; IIIT, Robotics Research Center, Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982106/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DaRsKGv7e3EJ:scholar.google.com/&scioq=IndoLayout:+Leveraging+Attention+for+Extended+Indoor+Layout+Estimation+from+an+RGB+Image&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "International Institute of Information Technology;Tata Consultancy Services",
        "aff_unique_dep": "Robotics Research Center;Research",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.tcs.com",
        "aff_unique_abbr": "IIIT Hyderabad;TCS",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hyderabad;Kolkata",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9981816",
        "title": "Industrial Robot Parameter Identification using a Constrained Instrumental Variable Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot identification is a prolific topic that has a long history with results spanning recent decades. Recent years have witnessed a renew of interest in this problem due in part to a rapid increase in robotic hardware platforms capable of accurate model-based control. The most popular methods exploit the fact that the inverse dynamic model is linear to the dynamic parameters. Because we identify robots with closed-loop procedures, an Instrumental Variable approach called IDIM-IV (Inverse Dynamic Identification Model with Instrumental Variable estimation) that combines the direct and inverse dynamic models to prevent from correlation between errors has been successfully validated. However, IDIM-IV does not guarantee that the direct dynamic model will be well-posed during its iterations because of possible modeling errors. In this paper, we combine physical constraints and IDIM-IV to address this deficiency for IDIM-IV. This new constrained IV approach, called PC-IDIM-IV (Physically Consistent IDIM-IV), consists of two nested iterative algorithms: an outer one that is IDIM-IV and an inner one that accounts for the physical constraints solved by a Gauss-Newton algorithm. Experimental results and comparisons with other methods carried out with the TX40 robot show the feasibility of PC-IDIM-IV.",
        "primary_area": "",
        "author": "Fabio Ardiani;Alexandre Janot;Mourad Benoussaad;Fabio Ardiani;Alexandre Janot;Mourad Benoussaad",
        "authorids": "/467463310798671;/37546049700;/37586646300;/467463310798671;/37546049700;/37586646300",
        "aff": "LGP-ENIT, University of Toulouse, Tarbes, France; ONERA, the French Aerospace Lab, Toulouse, France; LGP-ENIT, University of Toulouse, Tarbes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981816/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=552212320463150033&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Toulouse;ONERA",
        "aff_unique_dep": "LGP-ENIT;the French Aerospace Lab",
        "aff_unique_url": "https://www.univ-toulouse.fr;https://www.onera.fr",
        "aff_unique_abbr": ";ONERA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tarbes;Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981980",
        "title": "Inertial-measurement-based catenary shape estimation of underwater cables for tethered robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the estimation of the shape of a catenary for a negatively buoyant cable, connecting a pair of underwater robots in a robot chain. The new estimation method proposed here is based on the calculation of local tangents thanks to the data acquired from inertial measurement units (IMUs), which are attached to the cable near its ends. This method is compared with a vision-based estimation method that was developed previously. Experiments are conducted, in the air and in a pool, using a motion capture system for ground truth. The results obtained show that the new method significantly improves the estimation of the catenary height. Furthermore, the identification of the cable shape is not affected by the limits of the camera's field of view and by the image projection, resulting in increased accuracy and range, without singularities.",
        "primary_area": "",
        "author": "Juliette Drupt;Claire Dune;Andrew I. Comport;Sabine Seillier;Vincent Hugel;Juliette Drupt;Claire Dune;Andrew I. Comport;Sabine Seillier;Vincent Hugel",
        "authorids": "/37089664000;/37590091400;/37283708800;/37089662372;/37294135300;/37089664000;/37590091400;/37283708800;/37089662372;/37294135300",
        "aff": "COSMER Laboratory EA7398, Universit\u00e9 de Toulon, France; COSMER Laboratory EA7398, Universit\u00e9 de Toulon, France; CNRS I3S Laboratory, Universit\u00e9 C\u00f4te d'Azur, Sophia Antipolis, France; COSMER Laboratory EA7398, Universit\u00e9 de Toulon, France; COSMER Laboratory EA7398, Universit\u00e9 de Toulon, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981980/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11518989565149363661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Universit\u00e9 de Toulon;CNRS I3S Laboratory",
        "aff_unique_dep": "COSMER Laboratory EA7398;I3S",
        "aff_unique_url": "https://www.univ-toulon.fr;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sophia Antipolis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9982088",
        "title": "Inference of Multi-Class STL Specifications for Multi-Label Human-Robot Encounters",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is interested in formalizing human trajectories in human-robot encounters. Inspired by robot navigation tasks in human-crowded environments, we consider the case where a human and a robot walk towards each other, and where humans have to avoid colliding with the incoming robot. Further, humans may describe different be-haviors, ranging from being in a hurry/minimizing completion time to maximizing safety. We propose a decision tree-based algorithm to extract STL formulae from multi-label data. Our inference algorithm learns STL specifications from data containing multiple classes, where instances can be labelled by one or many classes. We base our evaluation on a dataset of trajectories collected through an online study reproducing human-robot encounters.",
        "primary_area": "",
        "author": "Alexis Linard;Ilaria Torre;Iolanda Leite;Jana Tumova;Alexis Linard;Ilaria Torre;Iolanda Leite;Jana Tumova",
        "authorids": "/37087051755;/38228000400;/38576988500;/38230312900;/37087051755;/38228000400;/38576988500;/38230312900",
        "aff": "Division of Robotics, Perception and Learning and are also affiliated with Digital Futures; Division of Robotics, Perception and Learning and are also affiliated with Digital Futures; Division of Robotics, Perception and Learning and are also affiliated with Digital Futures; Division of Robotics, Perception and Learning and are also affiliated with Digital Futures",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982088/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4480400742481237050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Division of Robotics, Perception and Learning",
        "aff_unique_dep": "Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.kth.se/en/ee/cs/robotics",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9981687",
        "title": "Inferring Articulated Rigid Body Dynamics from RGBD Video",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to reproduce physical phenomena ranging from light interaction to contact mechanics, simulators are becoming increasingly useful in more and more application domains where real-world interaction or labeled data are difficult to obtain. Despite recent progress, significant human effort is needed to configure simulators to accurately reproduce real-world behavior. We introduce a pipeline that combines inverse rendering with differentiable simulation to create digital twins of real-world articulated mechanisms from depth or RGB videos. Our approach automatically discovers joint types and estimates their kinematic parameters, while the dynamic properties of the overall mechanism are tuned to attain physically accurate simulations. Control policies optimized in our derived simulation transfer successfully back to the original system, as we demonstrate on a simulated system. Further, our approach accurately reconstructs the kinematic tree of an articulated mechanism being manipulated by a robot, and highly nonlinear dynamics of a real-world coupled pendulum mechanism. Website: https://eric-heiden.github.io/video2sim",
        "primary_area": "",
        "author": "Eric Heiden;Ziang Liu;Vibhav Vineet;Erwin Coumans;Gaurav S. Sukhatme;Eric Heiden;Ziang Liu;Vibhav Vineet;Erwin Coumans;Gaurav S. Sukhatme",
        "authorids": "/37990849700;/37088505106;/38094245300;/37086455409;/37278934100;/37990849700;/37088505106;/38094245300;/37086455409;/37278934100",
        "aff": "NVIDIA, Santa Clara, USA; Stanford University, Stanford, USA; Microsoft Research, Redmond, USA; NVIDIA, Santa Clara, USA; Google Research, Mountain View, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981687/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17333297562731454083&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "NVIDIA;Stanford University;Microsoft;Google",
        "aff_unique_dep": "NVIDIA;;Microsoft Research;Google Research",
        "aff_unique_url": "https://www.nvidia.com;https://www.stanford.edu;https://www.microsoft.com/en-us/research;https://research.google",
        "aff_unique_abbr": "NV;Stanford;MSR;Google",
        "aff_campus_unique_index": "0;1;2;0;3",
        "aff_campus_unique": "Santa Clara;Stanford;Redmond;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982204",
        "title": "Influence of Variable Leg Elasticity on the Stability of Quadrupedal Gaits",
        "track": "main",
        "status": "Poster",
        "abstract": "Several template models have been developed to facilitate the analysis of limit-cycles for quadrupedal locomotion. The parameters in the model are usually fixed; however, biology shows that animals change their leg stiffness according to the locomotion velocity, and this adaptability invariably affects the stability of the gait. This paper provides an analysis of the influence of this variable leg stiffness on the stability of different quadrupedal gaits. The analysis exploits a simplified quadrupedal model with compliant legs and shoulder joints represented as torsional springs. This model can reproduce the most common quadrupedal gaits observed in nature. The stability of such emerging gaits is then checked. Afterward, an optimization process is used to search for the system parameters that guarantee maximum gait stability. Our study shows that using the highest feasible leg swing frequency and adopting a leg stiffness that increases with the speed of locomotion noticeably improves the gait stability over a wide range of horizontal velocities while reducing the oscillations of the trunk. This insight can be applied in the design of novel elastic quadrupedal robots, where variable stiffness actuators could be employed to improve the overall locomotion behavior.",
        "primary_area": "",
        "author": "Federico Del Fatti;Anna Sesselmann;M\u00e1ximo A. Roa;Federico Del Fatti;Anna Sesselmann;M\u00e1ximo A. Roa",
        "authorids": "/37089658447;/37088806799;/37628512100;/37089658447;/37088806799;/37628512100",
        "aff": "Politecnico di Milano, Milan, Italy; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982204/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:vmFir6WTBNUJ:scholar.google.com/&scioq=Influence+of+Variable+Leg+Elasticity+on+the+Stability+of+Quadrupedal+Gaits&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Politecnico di Milano;German Aerospace Center",
        "aff_unique_dep": ";Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.polimi.it;https://www.dlr.de",
        "aff_unique_abbr": "Polimi;DLR",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Milan;Wessling",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9981709",
        "title": "Information-Aware Guidance for Magnetic Anomaly based Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the absence of an absolute positioning system, such as GPS, autonomous vehicles are subject to accumu-lation of positional error which can interfere with reliable performance. Improved navigational accuracy without GPS enables vehicles to achieve a higher degree of autonomy and reliability, both in terms of decision making and safety. This paper details the use of two navigation systems for autonomous agents using magnetic field anomalies to localize themselves within a map; both techniques use the information content in the environment in distinct ways and are aimed at reducing the localization uncertainty. The first method is based on a nonlinear observability metric of the vehicle model, while the second is an information theory based technique which minimizes the expected entropy of the system. These conditions are used to design guidance laws that minimize the localization uncertainty and are verified both in simulation and hardware experiments are presented for the observability approach.",
        "primary_area": "",
        "author": "J. Humberto Ramos;Jaejeong Shin;Kyle Volle;Paul Buzaud;Kevin Brink;Prashant Ganesh;J. Humberto Ramos;Jaejeong Shin;Kyle Volle;Paul Buzaud;Kevin Brink;Prashant Ganesh",
        "authorids": "/37088221732;/37089658509;/37088365810;/37088842184;/38261288600;/37088365893;/37088221732;/37089658509;/37088365810;/37088842184;/38261288600;/37088365893",
        "aff": "Department of Mechanical and Aerospace Engineering, University of Florida; Department of Mechanical and Aerospace Engineering, University of Florida; Department of Mechanical and Aerospace Engineering, University of Florida; Department of Mechanical and Aerospace Engineering, University of Florida; Air Force Research Lab, Munitions Directorate at Eglin Air Force Base; Department of Mechanical and Aerospace Engineering, University of Florida",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981709/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15330988358558642451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Florida;Air Force Research Lab",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Munitions Directorate",
        "aff_unique_url": "https://www.ufl.edu;https://www.afresearchlab.com",
        "aff_unique_abbr": "UF;AFRL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981738",
        "title": "Informative Path Planning for Active Learning in Aerial Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation of aerial imagery is an important tool for mapping and earth observation. However, supervised deep learning models for segmentation rely on large amounts of high-quality labelled data, which is labour-intensive and time-consuming to generate. To address this, we propose a new approach for using unmanned aerial vehicles (UAVs) to autonomously collect useful data for model training. We exploit a Bayesian approach to estimate model uncertainty in semantic segmentation. During a mission, the semantic predictions and model uncertainty are used as input for terrain mapping. A key aspect of our pipeline is to link the mapped model uncertainty to a robotic planning objective based on active learning. This enables us to adaptively guide a UAV to gather the most informative terrain images to be labelled by a human for model training. Our experimental evaluation on real-world data shows the benefit of using our informative planning approach in comparison to static coverage paths in terms of maximising model performance and reducing labelling efforts.",
        "primary_area": "",
        "author": "Julius R\u00fcckin;Liren Jin;Federico Magistri;Cyrill Stachniss;Marija Popovi\u0107;Julius R\u00fcckin;Liren Jin;Federico Magistri;Cyrill Stachniss;Marija Popovi\u0107",
        "authorids": "/37089433811;/37089432247;/37086805350;/37329668600;/37086001290;/37089433811;/37089432247;/37086805350;/37329668600;/37086001290",
        "aff": "Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Institute for Machine Learning and Artificial Intelligence, Germany; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981738/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10571758891203995591&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Bonn;Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": "Institute of Geodesy and Geoinformation;",
        "aff_unique_url": "https://www.uni-bonn.de;",
        "aff_unique_abbr": "Uni Bonn;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982202",
        "title": "Informed Sampling-based Collision Avoidance with Least Deviation from the Nominal Path",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses local path re-planning for n-dimensional systems by introducing an informed sampling scheme and cost function to achieve collision avoidance with minimum deviation from an (optimal) nominal path. The proposed informed subset consists of the union of ellipsoids along the specified nominal path, such that the subset efficiently encapsulates all points along the nominal path. The cost function penalizes large deviations from the nominal path, thereby ensuring current safety in the face of potential collisions while retaining most of the overall efficiency of the nominal path. The proposed method is demonstrated on scenarios related to the navigation of autonomous marine crafts.",
        "primary_area": "",
        "author": "Thomas T. Enevoldsen;Roberto Galeazzi;Thomas T. Enevoldsen;Roberto Galeazzi",
        "authorids": "/37086448170;/38548724800;/37086448170;/38548724800",
        "aff": "Department of Electrical and Photonics Engineering, Automation and Control Group, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical and Photonics Engineering, Automation and Control Group, Technical University of Denmark, Kgs. Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982202/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13647281337335307903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical and Photonics Engineering",
        "aff_unique_url": "https://www.tek.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kgs. Lyngby",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9981357",
        "title": "Inspection of Ship Hulls with Multiple UAVs: Exploiting Prior Information for Online Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a path planning problem for a fleet of Unmanned Aerial Vehicles (UAVs) that uses both prior information and online gathered data to efficiently inspect large surfaces such as ship hulls and water tanks. UAVs can detect corrosion patches and other defects on the surface from low-resolution images. If defects are detected, they get closer to the surface for a high-resolution inspection. The prior information provides expected defects locations and is affected by both false positives and false negatives. The mission objective is to prioritize the close-up inspection of defected areas while keeping a reasonable time for the coverage of the entire surface. We propose two solutions to this problem: a coverage algorithm that divides the problem into a set of Traveling Salesman Problems (Part-TSP) and a cooperative frontier approach that introduces frontier utilities to incorporate the prior information (Coop-Frontier). We finally provide extensive simulation results to analyze the performance of these approaches and compare them with alternative solutions. These results suggest that both Part-Tspand Coop-Frontier perform better than the baseline solution. Part-Tsphas the best performance in most cases. However, coop-Frontier is preferable in extreme cases because more robust to inhomogeneous corrosion distribution and imperfect information.",
        "primary_area": "",
        "author": "Pasquale Grippa;Alessandro Renzaglia;Antoine Rochebois;Melanie Schranz;Olivier Simonin;Pasquale Grippa;Alessandro Renzaglia;Antoine Rochebois;Melanie Schranz;Olivier Simonin",
        "authorids": "/37086110436;/37590277500;/37089659037;/37089655895;/37329541300;/37086110436;/37590277500;/37089659037;/37089655895;/37329541300",
        "aff": "Lakeside Labs GmbH, Klagenfurt, Austria; Univ Lyon, Inria, INSA Lyon, CITI, Villeurbanne, France; Univ Lyon, Inria, INSA Lyon, CITI, Villeurbanne, France; Lakeside Labs GmbH, Klagenfurt, Austria; Univ Lyon, Inria, INSA Lyon, CITI, Villeurbanne, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981357/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=274229820998993628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Lakeside Labs GmbH;University Lyon",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.univ-lyon.fr",
        "aff_unique_abbr": ";Univ Lyon",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Austria;France"
    },
    {
        "id": "9982286",
        "title": "Instance Segmentation for Autonomous Log Grasping in Forestry Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "Wood logs picking is a challenging task to automate. Indeed, logs usually come in cluttered configurations, randomly orientated and overlapping. Recent work on log picking automation usually assume that the logs' pose is known, with little consideration given to the actual perception problem. In this paper, we squarely address the latter, using a data-driven approach. First, we introduce a novel dataset, named TimberSeg 1.0, that is densely annotated, i.e., that includes both bounding boxes and pixel-level mask annotations for logs. This dataset comprises 220 images with 2500 individually segmented logs. Using our dataset, we then compare three neural network architectures on the task of individual logs detection and segmentation; two region-based methods and one attention-based method. Unsurprisingly, our results show that axis-aligned proposals, failing to take into account the directional nature of logs, underperform with 19.03 mAP. A rotation-aware proposal method significantly improve results to 31.83 mAP. More interestingly, a Transformer-based approach, without any inductive bias on rotations, outperformed the two others, achieving a mAP of 57.53 on our dataset. Our use case demonstrates the limitations of region-based approaches for cluttered, elongated objects. It also highlights the potential of attention-based methods on this specific task, as they work directly at the pixel-level. These encouraging results indicate that such a perception system could be used to assist the operators on the short-term, or to fully automate log picking operations in the future.",
        "primary_area": "",
        "author": "Jean-Michel Fortin;Olivier Gamache;Vincent Grondin;Fran\u00e7ois Pomerleau;Philippe Gigu\u00e8re;Jean-Michel Fortin;Olivier Gamache;Vincent Grondin;Fran\u00e7ois Pomerleau;Philippe Gigu\u00e8re",
        "authorids": "/37089662299;/37089662065;/37088414754;/37594916100;/37560636500;/37089662299;/37089662065;/37088414754;/37594916100;/37560636500",
        "aff": "Northern Robotics Laboratory, Universit\u00c9 Laval, Qu\u00c9bec City, Canada; Northern Robotics Laboratory, Universit\u00c9 Laval, Qu\u00c9bec City, Canada; Northern Robotics Laboratory, Universit\u00c9 Laval, Qu\u00c9bec City, Canada; Northern Robotics Laboratory, Universit\u00c9 Laval, Qu\u00c9bec City, Canada; Northern Robotics Laboratory, Universit\u00c9 Laval, Qu\u00c9bec City, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982286/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3247708490094296385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Northern Robotics Laboratory",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Qu\u00c9bec City",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982285",
        "title": "Instance Segmentation with Cross-Modal Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmenting object instances is a key task in machine perception, with safety-critical applications in robotics and autonomous driving. We introduce a novel approach to instance segmentation that jointly leverages measurements from multiple sensor modalities, such as cameras and LiDAR. Our method learns to predict embeddings for each pixel or point that give rise to a dense segmentation of the scene. Specifically, our technique applies contrastive learning to points in the scene both across sensor modalities and the temporal domain. We demonstrate that this formulation encourages the models to learn embeddings that are invariant to viewpoint variations and consistent across sensor modalities. We further demonstrate that the embeddings are stable over time as objects move around the scene. This not only provides stable instance masks, but can also provide valuable signals to downstream tasks, such as object tracking. We evaluate our method on the Cityscapes and KITTI-360 datasets. We further conduct a number of ablation studies, demonstrating benefits when applying additional inputs for the contrastive loss.",
        "primary_area": "",
        "author": "Alex Zihao Zhu;Vincent Casser;Reza Mahjourian;Henrik Kretzschmar;S\u00f6ren Pirk;Alex Zihao Zhu;Vincent Casser;Reza Mahjourian;Henrik Kretzschmar;S\u00f6ren Pirk",
        "authorids": "/37086104530;/37088364331;/37938208600;/37868427900;/37086343066;/37086104530;/37088364331;/37938208600;/37868427900;/37086343066",
        "aff": "Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Adobe Research (Work done while at Google Research)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982285/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17938301389085985057&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Waymo;Adobe",
        "aff_unique_dep": ";Adobe Research",
        "aff_unique_url": "https://www.waymo.com;https://research.adobe.com",
        "aff_unique_abbr": "Waymo;Adobe",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981208",
        "title": "Integrating Impedance Control and Nonlinear Disturbance Observer for Robot-Assisted Arthroscope Control in Elbow Arthroscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted arthroscopic surgery is transforming the tradition in orthopaedic surgery. Compliance and stability are essential features that a surgical robot must have for safe physical human-robot interaction (PHRI). Surgical tools attached at the robot end-effector and human-robot interaction will affect the robot dynamics inevitably. This could undermine the utility and stability of the robotic system if the varying robot dynamics are not identified and updated in the robot control law. In this paper, an integrated frame-work for robot impedance control and nonlinear disturbance observer (NDOB)-based compensation of uncertain dynamics is proposed, where the former ensures compliant robot behavior and the latter compensates for dynamic uncertainties when necessary. The combination of impedance controller and NDOB is analyzed theoretically in three scenarios. A complete simulation and experimental studies involving three common conditions are then conducted to evaluate the theoretical analyses. A preliminary ppHRI application on arthroscopic surgery is designed to implement the proposed framework on a robotic surgeonassist system and evaluate its effectiveness experimentally. By integrating impedance controller with NDOB, the proposed framework allows an accurate impedance control when dynamic model inaccuracy and external disturbance exist.",
        "primary_area": "",
        "author": "Teng Li;Armin Badre;Hamid D. Taghirad;Mahdi Tavakoli;Teng Li;Armin Badre;Hamid D. Taghirad;Mahdi Tavakoli",
        "authorids": "/37089938702;/37089663492;/38180146500;/37282400400;/37089938702;/37089663492;/38180146500;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, Faculty of Engineering, University of Alberta, Edmonton, Alberta, Canada; Division of Orthopaedic Surgery, Department of Surgery, Faculty of Medicine & Dentistry, University of Alberta, Edmonton, Alberta, Canada; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Faculty of Engineering, University of Alberta, Edmonton, Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981208/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6734814857416863467&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Alberta;K. N. Toosi University of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.ualberta.ca;",
        "aff_unique_abbr": "UAlberta;KNTU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Edmonton;Tehran",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Canada;Iran"
    },
    {
        "id": "9981804",
        "title": "Integration of Variable-height and Hopping Strategies for Humanoid Push Recovery",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we present a framework to en-sure seamless transition in humanoid push recovery involving hopping strategy. We propose a method to adaptively change the time constant that integrated the ankle strategy and variable height strategy. This framework excites a hopping motion against a large disturbance, which provides a seamless transition from the variable height to the hopping strategies. We analyze the applicable region of each strategy based on the simplified model. Moreover, we show that the hopping strategy prevents falling through whole-body dynamic simulations.",
        "primary_area": "",
        "author": "Ko Yamamoto;Naoki Kobayashi;Taiki Ishigaki;Yuichi Sakemi;Ko Yamamoto;Naoki Kobayashi;Taiki Ishigaki;Yuichi Sakemi",
        "authorids": "/37536641800;/37089663257;/37089197618;/37089662538;/37536641800;/37089663257;/37089197618;/37089662538",
        "aff": "Department of Mechano-informatics, Univ. of Tokyo, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, Tokyo, Japan; Department of Mechano-informatics, Univ. of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981804/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12237589207539190373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982249",
        "title": "Intention estimation from gaze and motion features for human-robot shared-control object manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared control can help in teleoperated object manipulation by assisting with the execution of the user's intention. To this end, robust and prompt intention estimation is needed, which relies on behavioral observations. Here, an intention estimation framework is presented, which uses natural gaze and motion features to predict the current action and the target object. The system is trained and tested in a simulated environment with pick and place sequences produced in a relatively cluttered scene and with both hands, with possible hand-over to the other hand. Validation is conducted across different users and hands, achieving good accuracy and earliness of prediction. An analysis of the predictive power of single features shows the predominance of the grasping trigger and the gaze features in the early identification of the current action. In the current framework, the same probabilistic model can be used for the two hands working in parallel and independently, while a rule-based model is proposed to identify the resulting bimanual action. Finally, limitations and perspectives of this approach to more complex, full-bimanual manipulations are discussed.",
        "primary_area": "",
        "author": "Anna Belardinelli;Anirudh Reddy Kondapally;Dirk Ruiken;Daniel Tanneberg;Tomoki Watabe;Anna Belardinelli;Anirudh Reddy Kondapally;Dirk Ruiken;Daniel Tanneberg;Tomoki Watabe",
        "authorids": "/37289967600;/37089661816;/37990697500;/37086139342;/37085687813;/37289967600;/37089661816;/37990697500;/37086139342;/37085687813",
        "aff": "Honda Research Institute EU, Offenbach, Germany; Innovative Research Excellence, Honda R&D Co., Ltd., Japan; Honda Research Institute EU, Offenbach, Germany; Honda Research Institute EU, Offenbach, Germany; Innovative Research Excellence, Honda R&D Co., Ltd., Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982249/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14940626207427644634&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Honda Research Institute EU;Honda R&D Co., Ltd.",
        "aff_unique_dep": ";Innovative Research Excellence",
        "aff_unique_url": "https://honda-ri.de;https://www.honda.com",
        "aff_unique_abbr": "HRI-EU;Honda R&D",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Offenbach;",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "9982123",
        "title": "InterFusion: Interaction-based 4D Radar and LiDAR Fusion for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Many recent works detect 3D objects by several sensor modalities for autonomous driving, where high-resolution cameras and high-line LiDARs are mostly used but relatively expensive. To achieve a balance between overall cost and detection accuracy, many multi-modal fusion techniques have been suggested. In recent years, the fusion of LiDAR and Radar has gained ever-increasing attention, especially 4D Radar, which can adapt to bad weather conditions due to its penetrability. Although features have been fused from multiple sensing modalities, most methods cannot learn interactions from different modalities, which does not make for their best use. Inspired by the self-attention mechanism, we present InterFusion, an interaction-based fusion framework, to fuse 16-line LiDAR with 4D Radar. It aggregates features from two modalities and identifies cross-modal relations between Radar and LiDAR features. In experimental evaluations on the Astyx HiRes 2019 dataset, our method outperformed the baseline by 4.20% mAP in 3D and 10.76% BEV mAP for the car class at the moderate level.",
        "primary_area": "",
        "author": "Li Wang;Xinyu Zhang;Baowei Xv;Jinzhao Zhang;Rong Fu;Xiaoyu Wang;Lei Zhu;Haibing Ren;Pingping Lu;Jun Li;Huaping Liu;Li Wang;Xinyu Zhang;Baowei Xv;Jinzhao Zhang;Rong Fu;Xiaoyu Wang;Lei Zhu;Haibing Ren;Pingping Lu;Jun Li;Huaping Liu",
        "authorids": "/37089442993;/37085619542;/37089658202;/37089662879;/37087006047;/37089661904;/37896154000;/37089542941;/37087995162;/37088999341;/37310126400;/37089442993;/37085619542;/37089658202;/37089662879;/37087006047;/37089661904;/37896154000;/37089542941;/37087995162;/37088999341;/37310126400",
        "aff": "State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; Mogo Auto Intelligence and Telemetics Information Technology Co. Ltd.; Meituan Inc.; University of Michigan; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982123/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7880662480733321940&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;1;2;3;0;0",
        "aff_unique_norm": "Tsinghua University;Mogo Auto Intelligence and Telemetics Information Technology Co. Ltd.;Meituan Inc.;University of Michigan",
        "aff_unique_dep": "School of Vehicle and Mobility;;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;https://www.meituan.com;https://www.umich.edu",
        "aff_unique_abbr": "THU;;Meituan;UM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9982008",
        "title": "InterSim: Interactive Traffic Simulation via Explicit Relation Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive traffic simulation is crucial to autonomous driving systems by enabling testing for planners in a more scalable and safe way compared to real-world road testing. Existing approaches learn an agent model from large-scale driving data to simulate realistic traffic scenarios, yet it remains an open question to produce consistent and diverse multi-agent interactive behaviors in crowded scenes. In this work, we present InterSim, an interactive traffic simulator for testing autonomous driving planners. Given a test plan trajectory from the ego agent, InterSim reasons about the interaction relations between the agents in the scene and generates realistic trajectories for each environment agent that are consistent with the relations. We train and validate our model on a large-scale interactive driving dataset. Experiment results show that InterSim achieves better simulation realism and reactivity in two simulation tasks compared to a state-of-the-art learning-based traffic simulator.",
        "primary_area": "",
        "author": "Qiao Sun;Xin Huang;Brian C. Williams;Hang Zhao;Qiao Sun;Xin Huang;Brian C. Williams;Hang Zhao",
        "authorids": "/37089538291;/37086595235;/37274902300;/37086232492;/37089538291;/37086595235;/37274902300;/37086232492",
        "aff": "IIIS, Tsinghua University; CSAIL, Massachusetts Institute of Technology; CSAIL, Massachusetts Institute of Technology; IIIS, Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982008/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9497303092477136673&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Tsinghua University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.csail.mit.edu",
        "aff_unique_abbr": "THU;MIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981181",
        "title": "Interactive Multi-Robot Aerial Cinematography Through Hemispherical Manifold Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a distributed interactive framework to provide high-level position instructions for multi-robot aerial cinematography based on coverage over a hemisphere. The control strategy based on optimization of the coverage functional and geometric relationships over a hemisphere is presented. It enables multiple Unmanned Aerial Vehicles (UAVs) to coordinate their motion while tracking a dynamic (real or virtual) target, and can accommodate high-level human inputs to influence UAV concentration. In this framework, each UAV uses local information combined with exogenous inputs to determine its motion. The two inputs to the system, i.e., the predicted trajectory of the target and user-defined aesthetic preferences, are agnostic to the size of the multi-robot system (MRS). The proposed framework is validated using the PX4 SITL Autopilot simulator in Gazebo, and the scalability of the framework is verified via simulations.",
        "primary_area": "",
        "author": "Xiaotian Xu;Guangyao Shi;Pratap Tokekar;Yancy Diaz-Mercado;Xiaotian Xu;Guangyao Shi;Pratap Tokekar;Yancy Diaz-Mercado",
        "authorids": "/37087090416;/37089000733;/37546532700;/38352376400;/37087090416;/37089000733;/37546532700;/38352376400",
        "aff": "Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981181/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15512789292182250260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Maryland;University of Maryland, College Park",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www/umd.edu;https://www.umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981524",
        "title": "Interventional Behavior Prediction: Avoiding Overly Confident Anticipation in Interactive Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Conditional behavior prediction (CBP) builds up the foundation for a coherent interactive prediction and plan-ning framework that can enable more efficient and less conser-vative maneuvers in interactive scenarios. In CBP task, we train a prediction model approximating the posterior distribution of target agents' future trajectories conditioned on the future trajectory of an assigned ego agent. However, we argue that CBP may provide overly confident anticipation on how the autonomous agent may influence the target agents' behavior. Consequently, it is risky for the planner to query a CBP model. Instead, we should treat the planned trajectory as an intervention and let the model learn the trajectory distribution under intervention. We refer to it as the interventional behavior prediction (IBP) task. Moreover, to properly evaluate an IBP model with offline datasets, we propose a Shapley-value-based metric to verify if the prediction model satisfies the inherent temporal independence of an interventional distribution. We show that the proposed metric can effectively identify a CBP model violating the temporal independence, which plays an important role when establishing IBP benchmarks.",
        "primary_area": "",
        "author": "Chen Tang;Wei Zhan;Masayoshi Tomizuka;Chen Tang;Wei Zhan;Masayoshi Tomizuka",
        "authorids": "/37086487301;/37067099600;/37281933000;/37086487301;/37067099600;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981524/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10943445492588875389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982003",
        "title": "Introducing Force Feedback in Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In the literature about model predictive control (MPC), contact forces are planned rather than controlled. In this paper, we propose a novel paradigm to incorporate effort measurements into a predictive controller, hence allowing to control them by direct measurement feedback. We first demonstrate why the classical optimal control formulation, based on position and velocity state feedback, cannot handle direct feedback on force information. Following previous approaches in force control, we then propose to augment the classical formulations with a model of the robot actuation, which naturally allows to generate online trajectories that adapt to sensed position, velocity and torques. We propose a complete implementation of this idea on the upper part of a real humanoid robot, and show through hardware experiments that this new formulation incorporating effort feedback outperforms classical MPC in challenging tasks where physical interaction with the environment is crucial.",
        "primary_area": "",
        "author": "S\u00e9bastien Kleff;Ewen Dantec;Guilhem Saurel;Nicolas Mansard;Ludovic Righetti;S\u00e9bastien Kleff;Ewen Dantec;Guilhem Saurel;Nicolas Mansard;Ludovic Righetti",
        "authorids": "/37086163635;/37089000340;/37085810875;/37542913400;/37295828600;/37086163635;/37089000340;/37085810875;/37542913400;/37295828600",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse; Artificial and Natural Intelligence Toulouse Institute (ANITI), Toulouse; Tandon School of Engineering, New York University, Brooklyn, NY; Artificial and Natural Intelligence Toulouse Institute (ANITI), Toulouse; Max Planck Institute for Intelligent Systems, T\u00fcbingen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982003/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5136613579093043374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;3",
        "aff_unique_norm": "LAAS-CNRS;Artificial and Natural Intelligence Toulouse Institute;New York University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";;Tandon School of Engineering;",
        "aff_unique_url": "https://www.laas.fr/;;https://www.nyu.edu;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "LAAS-CNRS;ANITI;NYU;MPI-IS",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Toulouse;Brooklyn;T\u00fcbingen",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "France;United States;Germany"
    },
    {
        "id": "9982251",
        "title": "Intuitive & Efficient Human-robot Collaboration via Real-time Approximate Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes. Approximate Bayesian Computation (ABC) is approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks. In this paper, we formulate human intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's intent improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims.",
        "primary_area": "",
        "author": "Javier Felip;David Gonzalez-Aguirre;Lama Nachman;Javier Felip;David Gonzalez-Aguirre;Lama Nachman",
        "authorids": "/37546464000;/38270651000;/37295494200;/37546464000;/38270651000;/37295494200",
        "aff": "Intel Labs, Intelligent Systems Research Lab.; Intel Labs, Intelligent Systems Research Lab.; Intel Labs, Intelligent Systems Research Lab.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982251/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17224378138113860566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Intel",
        "aff_unique_dep": "Intelligent Systems Research Lab",
        "aff_unique_url": "https://www.intel.com",
        "aff_unique_abbr": "Intel",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981103",
        "title": "Inverse Reinforcement Learning with Hybrid-weight Trust-region Optimization and Curriculum Learning for Autonomous Maneuvering",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite significant advancements, collision-free navigation in autonomous driving is still challenging, considering the navigation module needs to balance learning and planning to achieve efficient and effective control of the vehicle. We propose a novel framework of inverse reinforcement learning with hybrid-weight trust-region optimization and curriculum learning (IRL-HC) for autonomous maneuvering. Our method can incorporate both expert demonstration (from real driving) and domain knowledge (hard constraints such as collision avoidance, goal reaching, etc. encoded in reward functions) to learn an effective control policy. The hybrid-weight trustregion optimization is used to determine the difficulty of the task curriculum for fast incremental curriculum learning and improve the efficiency of inverse reinforcement learning by hybrid weight tuning of different sets of hyperparameters. IRL-HC is also compatible with domain-dependent techniques such as learn-from-accident, which can further boost performance. Overall, IRL-HC can reduce the number of collisions up to 48%, increase the training efficiency by 2.8x, and enable the vehicle to drive 10x further compared to other methods.",
        "primary_area": "",
        "author": "Yu Shen;Weizi Li;Ming C. Lin;Yu Shen;Weizi Li;Ming C. Lin",
        "authorids": "/37088996267;/37085997583;/37278387400;/37088996267;/37085997583;/37278387400",
        "aff": "Department of Computer Science, University of Maryland at College Park; Department of Computer Science, University of Memphis; Department of Computer Science, University of Maryland at College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981103/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11938953139619146632&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Maryland;University of Memphis",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu;https://www.memphis.edu",
        "aff_unique_abbr": "UMD;UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Park;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981638",
        "title": "Investigation of Factorized Optical Flows as Mid-Level Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a new concept of incorporating factorized flow maps as mid-level representations, for bridging the perception and the control modules in modular learning based robotic frameworks. To investigate the advantages of factorized flow maps and examine their interplay with the other types of mid-level representations, we further develop a configurable framework, along with four different environments that contain both static and dynamic objects, for analyzing the impacts of factorized optical flow maps on the performance of deep reinforcement learning agents. Based on this framework, we report our experimental results on various scenarios, and offer a set of analyses to justify our hypothesis. Finally, we validate flow factorization in real world scenarios.",
        "primary_area": "",
        "author": "Hsuan-Kung Yang;Tsu-Ching Hsiao;Ting-Hsuan Liao;Hsu-Shen Liu;Li-Yuan Tsao;Tzu-Wen Wang;Shan-Ya Yang;Yu-Wen Chen;Huang-Ru Liao;Chun-Yi Lee;Hsuan-Kung Yang;Tsu-Ching Hsiao;Ting-Hsuan Liao;Hsu-Shen Liu;Li-Yuan Tsao;Tzu-Wen Wang;Shan-Ya Yang;Yu-Wen Chen;Huang-Ru Liao;Chun-Yi Lee",
        "authorids": "/37086567339;/37089658536;/37089661057;/37089659127;/37089661764;/37089660972;/37089662196;/37089939294;/37089659195;/37086565629;/37086567339;/37089658536;/37089661057;/37089659127;/37089661764;/37089660972;/37089662196;/37089939294;/37089659195;/37086565629",
        "aff": "Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu City, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981638/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1470603947607697292&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "National Tsing Hua University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nthu.edu.tw",
        "aff_unique_abbr": "NTHU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981343",
        "title": "J-RR: Joint Monocular Depth Estimation and Semantic Edge Detection Exploiting Reciprocal Relations",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation and semantic edge detection are two key tasks in computer vision, which have made great progress. To date, how to associatively predict the depth and the semantic edge is rarely explored. In this work, we first propose a flexible two-branch framework that can make the two tasks take advantage of each other, achieving a win-win situation. Specifically, for the semantic edge detection branch, an Enhanced Edge Weighting strategy (EEW) is designed, which learns weight information from the by-product of depth branch, depth edge, to enhance edge perception in features. Meanwhile, we make depth estimation benefit from semantic edge detection through introducing Depth Edge Semantic Classification module (DESC). Furthermore, a double reconstruction (D-reconstruction) approach is presented, together with semantic edge-guided disparity smoothing loss to mitigate the ambiguities of the self-supervised manner for depth estimation. Experiments on the Cityscapes dataset demonstrate that our framework outperforms the state-of-the-art method in depth estimation along with a significant improvement in semantic edge detection.",
        "primary_area": "",
        "author": "Deming Wu;Dongchen Zhu;Guanghui Zhang;Wenjun Shi;Xiaolin Zhang;Jiamao Li;Deming Wu;Dongchen Zhu;Guanghui Zhang;Wenjun Shi;Xiaolin Zhang;Jiamao Li",
        "authorids": "/37089662324;/37086420004;/37086823762;/37086421586;/37085830972;/37086083391;/37089662324;/37086420004;/37086823762;/37086421586;/37085830972;/37086083391",
        "aff": "University of Chinese Academy and Sciences, Beijing, China; University of Chinese Academy and Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; University of Science and Technology of China, Hefei, Anhui, China; Xiongan Institute of Innovation, Xiongan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981343/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9004743248137708682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;2;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Institute of Microsystem and Information Technology;University of Science and Technology of China;Xiongan Institute of Innovation",
        "aff_unique_dep": ";Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.sIMIT.ac.cn;http://www.ustc.edu.cn;",
        "aff_unique_abbr": "UCAS;SIMIT;USTC;",
        "aff_campus_unique_index": "0;0;1;1;2;3",
        "aff_campus_unique": "Beijing;Shanghai;Hefei;Xiongan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982171",
        "title": "Jammkle: Fibre jamming 3D printed multi-material tendons and their application in a robotic ankle",
        "track": "main",
        "status": "Poster",
        "abstract": "Fibre jamming is a new and understudied soft robotic mechanism that has previously found success in stiffness-tunable arms and fingers. However, to date researchers have not fully taken advantage of the freedom offered by contemporary fabrication techniques including multi-material 3D printing in the creation of fibre jamming structures. In this research, we present a novel, modular, multi-material, 3D printed, fibre jamming tendon unit for use in a stiffness-tunable compliant robotic ankle, or Jammkle. Its multimaterial printed design offers unparalleled design freedom, enabling application specific tendon design. We develop analytical and finite element models of the tendon unit, showing good agreement with experimental data and numerically explore the design space. Finally, we demonstrate a practical application by integrating multiple tendon units into a robotic ankle and perform extensive testing and characterisation. We show that the Jammkle outperforms comparative leg structures in terms of compliance, damping, and slip prevention.",
        "primary_area": "",
        "author": "Joshua Pinskier;James Brett;Lauren Hanson;Katrina Lo Surdo;David Howard;Joshua Pinskier;James Brett;Lauren Hanson;Katrina Lo Surdo;David Howard",
        "authorids": "/37085671889;/37088909721;/37089658995;/37089661621;/37086143521;/37085671889;/37088909721;/37089658995;/37089661621;/37086143521",
        "aff": "Robotics and Autonomous Systems Group, Data61, CSIRO, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982171/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11788837394380882140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "CSIRO",
        "aff_unique_dep": "Robotics and Autonomous Systems Group, Data61",
        "aff_unique_url": "https://www.csiro.au",
        "aff_unique_abbr": "CSIRO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981086",
        "title": "Jerk-continuous Online Trajectory Generation for Robot Manipulator with Arbitrary Initial State and Kinematic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents an online trajectory generation algorithm using a sinusoidal jerk profile. The generator takes initial acceleration, velocity and position as input, and plans a multi-segment trajectory to a goal position under jerk, acceleration, and velocity limits. By analyzing the critical constraints and conditions, the corresponding closed-form solution for the time factors and trajectory profiles are derived. The proposed algorithm was first derived in Mathematica and then converted into a C++ implementation. Finally, the algorithm was utilized and demonstrated in ROS & Gazebo using a UR3 robot. Both the Mathematica and C++ implementations can be accessed at https://github.com/Haoran-Zhao/Jerk-continuous-online-trajectory-generator-with-constraints.git",
        "primary_area": "",
        "author": "Haoran Zhao;Nihal Abdurahiman;Nikhil Navkar;Julien Leclerc;Aaron T. Becker;Haoran Zhao;Nihal Abdurahiman;Nikhil Navkar;Julien Leclerc;Aaron T. Becker",
        "authorids": "/37086309754;/37089435036;/37947228700;/38246174500;/37588897100;/37086309754;/37089435036;/37947228700;/38246174500;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Surgery, Hamad Medical Corporation, Doha, Qatar.; Department of Surgery, Hamad Medical Corporation, Doha, Qatar.; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981086/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5116961304111623646&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "University of Houston;Hamad Medical Corporation",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Surgery",
        "aff_unique_url": "https://www.uh.edu;",
        "aff_unique_abbr": "UH;",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Houston;Doha",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "United States;Qatar"
    },
    {
        "id": "9981655",
        "title": "Jumping on Air: Design and Modeling of Latch-mediated, Spring-actuated Air-jumpers",
        "track": "main",
        "status": "Poster",
        "abstract": "Latch-mediated spring-actuation (LaMSA) is utilized in a majority of jumping robots for its ability to slowly load and quickly release energy to generate high-power movement. Such mechanisms are found in robots that jump off of solid surfaces and even off of water. However, no robot currently employs LaMSA to jump on air. This paper presents the design, modeling, and fabrication of the first LaMSA-driven air jumper, capable of jumping mid-air. Our model informs prototype design and provides insight into the scaling properties of the wing area, wing and fuselage mass, and energy. By successfully applying LaMSA to a new domain, this work lays the foundation for future investigations into high-power airreaction maneuvers, such as in fixed-wing unmanned aerial vehicle (UAV) flight, by enabling instantaneous changes in altitude without the addition of extra on-board motors.",
        "primary_area": "",
        "author": "Anna V. Alvarez;Matthew R. Devlin;Nicholas D. Naclerio;Elliot W. Hawkes;Anna V. Alvarez;Matthew R. Devlin;Nicholas D. Naclerio;Elliot W. Hawkes",
        "authorids": "/37089661525;/37088687226;/37086581043;/37681388800;/37089661525;/37088687226;/37086581043;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981655/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14311811871110486363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982282",
        "title": "Keeping Humans in the Loop: Teaching via Feedback in Continuous Action Space Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive Reinforcement Learning (IntRL) allows human teachers to accelerate the learning process of Reinforcement Learning (RL) robots. However, IntRL has largely been limited to tasks with discrete-action spaces in which actions are relatively slow. This limits IntRL's application to more complicated and challenging robotic tasks, the very tasks that modern RL is particularly well-suited for. We seek to bridge this gap by presenting Continuous Action-space Interactive Reinforcement learning (CAIR): the first continuous action-space IntRL algorithm that is capable of using teacher feedback to out-perform state-of-the-art RL algorithms in those tasks. CAIR combines policies learned from the environment and the teacher into a single policy that proportionally weights the two policies based on their agreement. This allows a CAIR agent to learn a relatively stable policy despite potentially noisy or coarse teacher feedback. We validate our approach in two simulated robotics tasks with easy-to-design and - understand heuristic oracle teachers. Furthermore, we validate our approach in a human subjects study through Amazon Mechanical Turk and show CAIR out-performs the prior state-of-the-art in Interactive RL.",
        "primary_area": "",
        "author": "Isaac Sheidlower;Allison Moore;Elaine Short;Isaac Sheidlower;Allison Moore;Elaine Short",
        "authorids": "/37089661971;/37089659469;/37401757800;/37089661971;/37089659469;/37401757800",
        "aff": "Tufts University School of Engineering; Tufts University School of Engineering; Tufts University School of Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982282/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12355517896594528782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981694",
        "title": "Keeping Less is More: Point Sparsification for Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Yeonsoo Park;Soohyun Bae;Yeonsoo Park;Soohyun Bae",
        "authorids": "/37089658329;/37089663420;/37089658329;/37089663420",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981694/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5199035780186428650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9981050",
        "title": "Keyframe Selection with Information Occupancy Grid Model for Long-term Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "As the basics of Visual Simultaneous Localization And Mapping (VSLAM), keyframes play an essential role. In previous works, keyframes are selected according to a series of view change-based strategies for short-term data association (STDA). However, the texture enrichment of frames is always ignored, resulting in the failure of long-term data association (LTDA). In this paper, we propose an information enrichment selection strategy with an information occupancy grid model and a deep descriptor. Frame is expressed by a deep global descriptor for a statistical explainable abstraction, in which the texture enrichment is indicated. Based on the abstraction, an information occupancy grid model is established to measure the information enrichment and the potential LTDA ability. Evaluations on variant datasets are conducted, showing the advantage of our proposed method in terms of keyframe selection and tracking precision. Also, the statistical explainability of the deep descriptor is provided. The proposed keyframe selection strategy can improve LTDA and tracking precision, especially in situations with repeated observations and loop-closures.",
        "primary_area": "",
        "author": "Weinan Chen;Hanjing Ye;Lei Zhu;Chao Tang;Changfei Fu;Yonggang Chen;Hong Zhang;Weinan Chen;Hanjing Ye;Lei Zhu;Chao Tang;Changfei Fu;Yonggang Chen;Hong Zhang",
        "authorids": "/37086099846;/37089346572;/37086573665;/37089661235;/37089659018;/37089661032;/37280789900;/37086099846;/37089346572;/37086573665;/37089661235;/37089659018;/37089661032;/37280789900",
        "aff": "Guangdong University of Technology, Guangzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Guangdong University of Technology, Guangzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; DongGuan Polytechnic, Dongguan, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981050/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4404450193980729763&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;1;2;1",
        "aff_unique_norm": "Guangdong University of Technology;Southern University of Science and Technology;DongGuan Polytechnic",
        "aff_unique_dep": ";Department of Electronic and Electrical Engineering;",
        "aff_unique_url": "http://www.gdut.edu.cn;https://www.sustech.edu.cn;",
        "aff_unique_abbr": "GDUT;SUSTech;",
        "aff_campus_unique_index": "0;1;0;1;1;2;1",
        "aff_campus_unique": "Guangzhou;Shenzhen;Dongguan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981168",
        "title": "Kinematics-Inertial Fusion for Localization of a 4-Cable Underactuated Suspended Robot Considering Cable Sag",
        "track": "main",
        "status": "Poster",
        "abstract": "Suspended Cable-Driven Parallel Robots (SCDPR) have intriguing capabilities on large scales but still have open challenges in precisely estimating the end-effector pose. The cables exhibit a downward curved shape, also known as cable sag which needs to be accounted for in the pose estimation. The catenary equations can accurately describe this phenomenon but are only accurate in equilibrium conditions. Thus, pose estimation for large-scale SCDPR in dynamic motion is an open challenge. This work proposes a real-time pose estimation algorithm for dynamic trajectories of SCDPRs, which is accurate over large areas. We present a novel approach that considers cable sag to reduce the estimation error for large scales while also employing an Inertial Measurement Unit (IMU) to improve estimation accuracy for dynamic motion. Our approach reduces the RMSE to less than a third compared to standard methods not considering cable sag. Similarly, the inclusion of the IMU reduces the RMSE in dynamic situations by 40% compared to non-IMU aided approaches considering cable sag. Further-more, we evaluate our Extended Kalman Filter (EKF) based algorithm on a real system with ground truth pose information.",
        "primary_area": "",
        "author": "Eren Allak;Rooholla Khorrambakht;Christian Brommer;Stephan Weiss;Eren Allak;Rooholla Khorrambakht;Christian Brommer;Stephan Weiss",
        "authorids": "/37086580226;/37086457359;/37086574162;/37535323400;/37086580226;/37086457359;/37086574162;/37535323400",
        "aff": "Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Austria; Faculty of Electrical Engineering and Computer Science, K. N. Toosi University of Technology, Iran; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981168/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1727658615525315133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Klagenfurt;K. N. Toosi University of Technology",
        "aff_unique_dep": "Department of Smart Systems Technologies;Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.uni-klagenfurt.at;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Austria;Iran"
    },
    {
        "id": "9981196",
        "title": "Kinesthetic teaching of bi-manual tasks with known relative constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinesthetic teaching allows the direct skill transfer from the human to the robot and has been widely used to teach single arm tasks intuitively. In the bi-manual case, simultaneously moving both end-effectors is challenging due to the high physical and cognitive load imposed to the user. Thus, previous works on bi-manual task teaching resort to less intuitive methods by teaching each arm separately. This in turn requires motion synthesis and synchronization before execution. In this work, we leverage knowledge from the relative task space to facilitate a kinesthetic demonstration by guiding both end-effectors which is more human-like and intuitive way for performing bi-manual tasks. Our method utilizes the notion of virtual fixtures and inertia minimization in the null space of the task. The controller is experimentally validated in a bi-manual task which involves the drawing of a preset line on a workpiece utilizing two KUKA IIWA7 R800 robots. Results from ten participants were compared with a gravity compensation scheme demonstrating improved performance.",
        "primary_area": "",
        "author": "Sotiris Stavridis;Dimitrios Papageorgiou;Zoe Doulgeri;Sotiris Stavridis;Dimitrios Papageorgiou;Zoe Doulgeri",
        "authorids": "/37086186963;/37449072200;/37274011500;/37086186963;/37449072200;/37274011500",
        "aff": "Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981196/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16234460955540387750&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981556",
        "title": "Kirigami Skin Based Flexible Whisker Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Whiskers are widely used by animals for sensing physical interactions with their environments. By combining the Kirigami skin pop-up feature and flexible conducting layer, we designed a deployable Kirigami whisker sensor. The sensor can deploy from a flat state to a sensing state while whisker stiffness and initial pop-up angle can be tuned by adjusting the pre-stretch strain. Preliminary results show that the sensor works well both in air and underwater. The sensor is capable of measuring both externally applied forces and water flow.",
        "primary_area": "",
        "author": "Bangyuan Liu;Robert Herbert;Woon-Hong Yeo;Frank L. Hammond;Bangyuan Liu;Robert Herbert;Woon-Hong Yeo;Frank L. Hammond",
        "authorids": "/37086840054;/37086948602;/37085849370;/37394264300;/37086840054;/37086948602;/37085849370;/37394264300",
        "aff": "Bangyuan Liu; Robert Herbert; Woon-Hong Yeo; Frank L. Hammond",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981556/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9833498968891768736&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981204",
        "title": "Koopman pose predictions for temporally consistent human walking estimations",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the problem of tracking the human lower body as an initial step toward an automatic motion assessment system for clinical mobility evaluation, using a multimodal system that combines Inertial Measurement Unit (IMU) data, RGB images, and point cloud depth measurements. This system applies the factor graph representation to an optimization problem that provides 3-D skeleton joint estimations. In this paper, we focus on improving the temporal consistency of the estimated human trajectories to greatly extend the range of operability of the depth sensor. More specifically, we introduce a new factor graph factor based on Koopman theory that embeds the nonlinear dynamics of several lower-limb movement activities. This factor performs a two-step process: first, a custom activity recognition module based on spatial temporal graph convolutional networks recognizes the walking activity; then, a Koopman pose prediction of the subsequent skeleton is used as an a priori estimation to drive the optimization problem toward more consistent results. We tested the performance of this module a dataset composed of multiple clinical lower-limb mobility tests, and we show that our approach reduces outliers on the skeleton form by almost 1 m, while preserving natural walking trajectories at depths up to more than 10 m.",
        "primary_area": "",
        "author": "Marc Mitjans;David M. Levine;Louis N. Awad;Roberto Tron;Marc Mitjans;David M. Levine;Louis N. Awad;Roberto Tron",
        "authorids": "/37088997421;/37088996809;/37085644997;/37398528900;/37088997421;/37088996809;/37085644997;/37398528900",
        "aff": "Department of Mechanical Engineering, Boston University, MA, USA; Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Harvard Medical School, MA, USA; College of Health and Rehabilitation Sciences: Sargent College, Boston University, MA, USA; Department of Mechanical Engineering, Boston University, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981204/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7042320148000849485&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Boston University;Harvard Medical School",
        "aff_unique_dep": "Department of Mechanical Engineering;Division of General Internal Medicine and Primary Care",
        "aff_unique_url": "https://www.bu.edu;https://hms.harvard.edu",
        "aff_unique_abbr": "BU;HMS",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "MA;;Sargent College",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981812",
        "title": "L2C2: Locally Lipschitz Continuous Constraint towards Stable and Smooth Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new regularization technique for reinforcement learning (RL) towards making policy and value functions smooth and stable. RL is known for the instability of the learning process and the sensitivity of the acquired policy to noise. Several methods have been proposed to resolve these problems, and in summary, the smoothness of policy and value functions learned mainly in RL contributes to these problems. However, if these functions are extremely smooth, their expressiveness would be lost, resulting in not obtaining the global optimal solution. This paper therefore considers RL under local Lipschitz continuity constraint, so-called L2C2. By designing the spatio-temporal locally compact space for L2C2 from the state transition at each time step, the moderate smoothness can be achieved without loss of expressiveness. Numerical noisy simulations verified that the proposed L2C2 outperforms the task performance while smoothing out the robot action generated from the learned policy.",
        "primary_area": "",
        "author": "Taisuke Kobayashi;Taisuke Kobayashi",
        "authorids": "/38542406800;/38542406800",
        "aff": "Taisuke Kobayashi is with National Institute of Informatics (NII) and with The Graduate University for Advanced Studies (SOK-ENDAI), Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981812/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5964520586623210069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "National Institute of Informatics",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nii.ac.jp",
        "aff_unique_abbr": "NII",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981217",
        "title": "LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras with Negative Plane",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual-inertial-odometry has attracted extensive attention in the field of autonomous driving and robotics. The size of Field of View (FoV) plays an important role in Visual-Odometry (VO) and Visual-Inertial-Odometry (VIO), as a large FoV enables to perceive a wide range of surrounding scene elements and features. However, when the field of the camera reaches the negative half plane, one cannot simply use [u, v, 1]^{T}[u, v, 1]^{T} to represent the image feature points anymore. To tackle this issue, we propose LF-VIO, a real-time VIO framework for cameras with extremely large FoV.We leverage a threedimensional vector with unit length to represent feature points, and design a series of algorithms to overcome this challenge. To address the scarcity of panoramic visual odometry datasets with ground-truth location and pose, we present the PALVIO dataset, collected with a Panoramic Annular Lens (PAL) system with an entire FoV of 36 0^{\\circ}\\times(40^{\\circ}\\sim 120^{\\circ})0^{\\circ}\\times(40^{\\circ}\\sim 120^{\\circ}) and an IMU sensor. With a comprehensive variety of experiments, the proposed LF-VIO is verified on both the established PALVIO benchmark and a public fisheye camera dataset with a FoV of 360^{\\circ}\\times(0^{\\circ}\\sim 93.5^{\\circ})360^{\\circ}\\times(0^{\\circ}\\sim 93.5^{\\circ}). LF-VIO outperforms state-of-the-art visual-inertial-odometry methods. Our dataset and code are made publicly available at https://github.com/flysoaryun/LF-VIO",
        "primary_area": "",
        "author": "Ze Wang;Kailun Yang;Hao Shi;Peng Li;Fei Gao;Kaiwei Wang;Ze Wang;Kailun Yang;Hao Shi;Peng Li;Fei Gao;Kaiwei Wang",
        "authorids": "/37089776917;/37086488716;/37089456386;/37086116065;/37086045143;/37086487662;/37089776917;/37086488716;/37089456386;/37086116065;/37086045143;/37086487662",
        "aff": "Huzhou Institute of Zhejiang University, Zhejiang University, China; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, China; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, China; Huzhou Institute of Zhejiang University, Zhejiang University, China; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981217/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1256274683296261029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Zhejiang University;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Huzhou Institute;Institute for Anthropomatics and Robotics",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.kit.edu",
        "aff_unique_abbr": "ZJU;KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Huzhou;",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9981563",
        "title": "LNC Assisted Localization and Mapping in Pipe Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Regular maintenance of pipelines is an important task to ensure oil transportation and other operation (sewers, nature gas). Precise localization of pipeline damage can greatly improve the efficiency of maintenance work. Since the texture similarity and illumination change of pipe, traditional local descriptors for image matching like SIFT, SURF and ORB are easy to suffer from false correspondences. As to remove the false matches, the local neighborhood constraints (LNC) that contain spatial constructs around feature points are proposed. Good correspondences are essential for the high-accuracy localization and mapping solution given the limited textures and illumination in the pipes. The LNC method is also integrated into the state-of-the-art visual SLAM system. The proposed LNC image matching method and the SLAM system are evaluated on datasets gathered from the pipe environment. Compared with other state-of-the-art methods, our LNC image matching method achieves similar or better performance in precision, recall and runtime. The SLAM system provides state estimation and map reconstruction of the pipe in real-time, and the localization error is within 1%.",
        "primary_area": "",
        "author": "Hongkai Zhang;Jianjun Yuan;Shijie Guo;Hesheng Wang;Shugen Ma;Sheng Bao;Liang Du;Hongkai Zhang;Jianjun Yuan;Shijie Guo;Hesheng Wang;Shugen Ma;Sheng Bao;Liang Du",
        "authorids": "/37089661294;/37293594200;/37086276620;/37089921682;/37280187400;/37088951181;/37087006997;/37089661294;/37293594200;/37086276620;/37089921682;/37280187400;/37088951181;/37087006997",
        "aff": "Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; School of Mechanical Engineering, Heibei University of Technology, Tianjin, China; Dept. of Automation, Shanghai Jiao Tong University, China; Department of Robotics, Ritsumeikan University, Shiga, Japan; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981563/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=686525245294263779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;3;0;0",
        "aff_unique_norm": "Shanghai University;Heibei University of Technology;Shanghai Jiao Tong University;Ritsumeikan University",
        "aff_unique_dep": "Shanghai Robotics Institute;School of Mechanical Engineering;Dept. of Automation;Department of Robotics",
        "aff_unique_url": "https://www.shu.edu.cn;;https://www.sjtu.edu.cn;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SHU;;SJTU;Ritsumeikan",
        "aff_campus_unique_index": "0;0;1;3;0;0",
        "aff_campus_unique": "Shanghai;Tianjin;;Shiga",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9981994",
        "title": "LODM: Large-scale Online Dense Mapping for UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an online large-scale dense mapping method for UAVs with a height of 150\u2013250 meters. We first fuse the GPS with the visual odometry to estimate the scaled poses and sparse points. In order to use the depth of sparse points for depth map, we propose Sparse Confidence Cascade View-Aggregation MVSNet (SCCVA-MVSNet), which projects the depth-converged points in the sliding window on keyframes to obtain a sparse depth map. To weigh the confidence of the depth of each sparse point, we construct sparse confidence by the photometric error. The images of all keyframes, coarse depth, and confidence as the input of CVA-MVSNet to extract features and construct 3D cost volumes with adaptive view aggregation to balance the different stereo baselines between the keyframes. Our proposed network utilizes sparse features point information, the output of the network better maintains the consistency of the scale. Our experiments show that MVSNet using sparse feature point information outperforms image-only MVSNet, and our online reconstruction results are comparable to offline reconstruction methods. To benefit the research community, we open our code at https://github.com/hjxwhy/LODM.git",
        "primary_area": "",
        "author": "Jianxin Huang;Laijian Li;Xiangrui Zhao;Xiaolei Lang;Deye Zhu;Yong Liu;Jianxin Huang;Laijian Li;Xiangrui Zhao;Xiaolei Lang;Deye Zhu;Yong Liu",
        "authorids": "/37089515301;/37089660381;/37087122595;/37088939249;/37089487474;/37066946100;/37089515301;/37089660381;/37087122595;/37088939249;/37089487474;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981994/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BFDbXRrBan8J:scholar.google.com/&scioq=LODM:+Large-scale+Online+Dense+Mapping+for+UAV&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982272",
        "title": "LSDNet: A Lightweight Self-Attentional Distillation Network for Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Place Recognition (VPR) has become an indispensable capacity for mobile robots to operate in large-scale environments. Existing methods in this field mostly focus on exploring high-performance encoding strategies, while few attempts are devoted to lightweight models that balance per-formance and computational cost. In this work, we propose a Lightweight Self-attentional Distillation Network (LSDNet) aiming to obtain advantages of both performance and efficiency. (1) From a performance perspective, an attentional encoding strategy is proposed to integrate crucial information in the scene. It extends the NetVlad architecture with a self-attention module to facilitate non-local information interaction between local features. Through further visual word vector rescaling, the final image representation can benefit from both non-local spatial integration and cluster-wise weighting. (2) From an efficiency perspective, LSDNet is built upon a lightweight back-bone. To maintain comparable performance to large backbone models, a dual distillation strategy is introduced. It prompts LSDNet to learn both encoding patterns in the hidden space and feature distributions in the encoding space from the teacher model. Through distillation-augmented training, LSDNet is able to rival the teacher model and outperform SOTA global representations with the same lightweight backbone.",
        "primary_area": "",
        "author": "Guohao Peng;Yifeng Huang;Heshan Li;Zhenyu Wu;Danwei Wang;Guohao Peng;Yifeng Huang;Heshan Li;Zhenyu Wu;Danwei Wang",
        "authorids": "/37087049757;/37087470827;/37089315207;/37088406849;/37279547600;/37087049757;/37087470827;/37089315207;/37088406849;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982272/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11460097126468733672&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9982237",
        "title": "LTR*: Rapid Replanning in Executing Consecutive Tasks with Lazy Experience Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "In an environment where a manipulator needs to execute multiple consecutive tasks, the act of object manoeuvre will change the underlying configuration space, affecting all subsequent tasks. Previously free configurations might now be occupied by the manoeuvred objects, and previously occupied space might now open up new paths. We propose Lazy Tree-based Replanner (LTR *)-a novel hybrid planner that inherits the rapid planning nature of existing anytime incremental sampling-based planners. At the same time, it allows subsequent tasks to leverage prior experience via a lazy experience graph. Previous experience is summarised in a lazy graph structure, and LTR * is formulated to be robust and beneficial regard-less of the extent of changes in the workspace. Our hybrid approach attains a faster speed in obtaining an initial solution than existing roadmap-based planners and often with a lower cost in trajectory length. Subsequent tasks can utilise the lazy experience graph to speed up finding a solution and take advant-age of the optimised graph to minimise the cost objective. We provide proofs of probabilistic completeness and almost-surely asymptotic optimal guarantees. Experimentally, we show that in repeated pick-and-place tasks, L T R * attains a high gain in performance when planning for subsequent tasks.",
        "primary_area": "",
        "author": "Tin Lai;Fabio Ramos;Tin Lai;Fabio Ramos",
        "authorids": "/37086935412;/37285364500;/37086935412;/37285364500",
        "aff": "School of Computer Science, The University of Sydney, Australia; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982237/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4829747650807221471&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Sydney;NVIDIA",
        "aff_unique_dep": "School of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;NV",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9981034",
        "title": "LaneSNNs: Spiking Neural Networks for Lane Detection on the Loihi Neuromorphic Processor",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Driving (AD) related features represent important elements for the next generation of mobile robots and autonomous vehicles focused on increasingly intelligent, autonomous, and interconnected systems. The applications involving the use of these features must provide, by definition, real-time decisions, and this property is key to avoid catastrophic accidents. Moreover, all the decision processes must require low power consumption, to increase the lifetime and autonomy of battery-driven systems. These challenges can be addressed through efficient implementations of Spiking Neural Networks (SNNs) on Neuromorphic Chips and the use of event-based cameras instead of traditional frame-based cameras. In this paper, we present a new SNN-based approach, called LaneSNN, for detecting the lanes marked on the streets using the event-based camera input. We develop four novel SNN models characterized by low complexity and fast response, and train them using an offline supervised learning rule. Afterward, we implement and map the learned SNNs models onto the Intel Loihi Neuromorphic Research Chip. For the loss function, we develop a novel method based on the linear composition of Weighted binary Cross Entropy (WCE) and Mean Squared Error (MSE) measures. Our experimental results show a maximum Intersection over Union (IoU) measure of about 0.62 and very low power consumption of about 1 W. The best IoU is achieved with an SNN implementation that occupies only 36 neurocores on the Loihi processor while providing a low latency of less than 8 ms to recognize an image, thereby enabling real-time performance. The IoU measures provided by our networks are comparable with the state-of-the-art, but at a much low power consumption of 1 W.",
        "primary_area": "",
        "author": "Alberto Viale;Alberto Marchisio;Maurizio Martina;Guido Masera;Muhammad Shafique;Alberto Viale;Alberto Marchisio;Maurizio Martina;Guido Masera;Muhammad Shafique",
        "authorids": "/37088971681;/37086480693;/37296189500;/37296188300;/37408660000;/37088971681;/37086480693;/37296189500;/37296188300;/37408660000",
        "aff": "Politecnico di Torino, Italy; Technische Universit\u00e4t, Wien, Austria; Politecnico di Torino, Italy; Politecnico di Torino, Italy; New York University, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981034/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4101962616249447397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Politecnico di Torino;Technische Universit\u00e4t Wien;New York University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.polito.it;https://www.tuwien.ac.at;https://nyu.edu",
        "aff_unique_abbr": "Polito;TU Wien;NYU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Wien;Abu Dhabi",
        "aff_country_unique_index": "0;1;0;0;2",
        "aff_country_unique": "Italy;Austria;United Arab Emirates"
    },
    {
        "id": "9981178",
        "title": "LapSeg3D: Weakly Supervised Semantic Segmentation of Point Clouds Representing Laparoscopic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "The semantic segmentation of surgical scenes is a prerequisite for task automation in robot assisted interventions. We propose LapSeg3D, a novel DNN-based approach for the voxel-wise annotation of point clouds representing surgical scenes. As the manual annotation of training data is highly time consuming, we introduce a semi-autonomous clustering-based pipeline for the annotation of the gallbladder, which is used to generate segmented labels for the DNN. When evaluated against manually annotated data, LapSeg3D achieves an F1 score of 0.94 for gallbladder segmentation on various datasets of ex-vivo porcine livers. We show LapSeg3D to generalize accurately across different gallbladders and datasets recorded with different RGB-D camera systems.",
        "primary_area": "",
        "author": "Benjamin Alt;Christian Kunz;Darko Katic;Rayan Younis;Rainer J\u00e4kel;Beat Peter M\u00fcller-Stich;Martin Wagner;Franziska Mathis-Ullrich;Benjamin Alt;Christian Kunz;Darko Katic;Rayan Younis;Rainer J\u00e4kel;Beat Peter M\u00fcller-Stich;Martin Wagner;Franziska Mathis-Ullrich",
        "authorids": "/37088995866;/37088949738;/37089002032;/37089196203;/37542755100;/37085457120;/37085725819;/37088949823;/37088995866;/37088949738;/37089002032;/37089196203;/37542755100;/37085457120;/37085725819;/37088949823",
        "aff": "B. Alt, D. Katic and R. J\u00e4kel are with Artiminds Robotics GmbH, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; B. Alt, D. Katic and R. J\u00e4kel are with Artiminds Robotics GmbH, Karlsruhe, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; B. Alt, D. Katic and R. J\u00e4kel are with Artiminds Robotics GmbH, Karlsruhe, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981178/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12583487284332336919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;0;2;2;1",
        "aff_unique_norm": "Artiminds Robotics GmbH;Karlsruhe Institute of Technology;Heidelberg University Hospital",
        "aff_unique_dep": ";Institute for Anthropomatics and Robotics;Department for General, Visceral and Transplantation Surgery",
        "aff_unique_url": ";https://www.kit.edu;https://www.klinikum.uni-heidelberg.de",
        "aff_unique_abbr": ";KIT;",
        "aff_campus_unique_index": "1;2;2;2;1",
        "aff_campus_unique": ";Karlsruhe;Heidelberg",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981641",
        "title": "Large-Scale ADMM-based Co-Design of Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of designing legged robots for traversing uneven terrain, wherein terrain characteristics represent uncertainty for the design process. When this process encompasses a wider variety of terrains, the likelihood of the designed robot falling in the real world should decrease. However, computational scalability limits the number of terrains that can be taken into account during design. The proposed framework uses the Alternating Direction Method of Multipliers (ADMM) to solve large-scale concurrent design (co-design) problems. The ADMM coordinates the solution of small-size sub-problems and enforces constraints to reach a consensus on the best design. The framework uses stochastic programming (SP) to account for terrain uncertainty and trajectory optimization (TO) to co-optimize a nominal trajectory alongside hardware parameters and a feedback controller. Case studies demonstrate application for a monopod and a quadruped. For the monopod, ADMM facilitated an increase in the number of terrains considered within co-design by 400% compared to SP alone, which contributed to robustifying the design and decreasing its failure probability to under 1% in an anticipated operating space. A multi-scenario co-design implementation for the quadruped had previously been intractable due to scalability limitations. The ADMM framework, by contrast, shows tractability running with 30 terrain types, opening the horizon for designing more complex systems.",
        "primary_area": "",
        "author": "Gabriel Bravo-Palacios;Patrick M. Wensing;Gabriel Bravo-Palacios;Patrick M. Wensing",
        "authorids": "/37087884224;/37946046300;/37087884224;/37946046300",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981641/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6880972823413720831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981492",
        "title": "LayoutSLAM: Object Layout based Simultaneous Localization and Mapping for Reducing Object Map Distortion",
        "track": "main",
        "status": "Poster",
        "abstract": "There is an increasing demand for robots that can be substituted for humans in various tasks. Mobile robots are being introduced in factories, stores, and public facilities for carrying goods and cleaning. In factories and stores, desks and shelves are arranged such that the work and movement of personnel are reduced. The surrounding furniture is also set to ensure that a single task can be performed in the same place. It is essential to study the intelligence of robots using information from such layouts, wherein human labor and movements are optimized. However, There is no method of map construction or location estimation that uses the characteristics of furniture arrangements that facilitate human work in a work space. Therefore, this study proposes a method for object mapping using layouts in crowded workspaces. Graphically represent the characteristics of furniture placement that make it easy for people to work in a workspace. The links in the graph represent the connections between the objects in the layout property. The nodes are the objects, and the weights of the links represent the strength of the layout properties. This graph is optimized by GraphSLAM to construct a map that considers the arrangement's characteristics. Using the graph structure improves the map's accuracy while allowing for relative changes in placement. The results show a 50.44% improvement in accuracy in a space with 18 desks, followed by two variations of similar desk layouts. The same improvement in accuracy was also observed when the relative positioning of objects changed significantly in each variation, such as a change to the left or right on the same side.",
        "primary_area": "",
        "author": "Kenta Gunji;Kazunori Ohno;Shotaro Kojima;Ranulfo Bezerra;Yoshito Okada;Masashi Konyo;Satoshi Tadokoro;Kenta Gunji;Kazunori Ohno;Shotaro Kojima;Ranulfo Bezerra;Yoshito Okada;Masashi Konyo;Satoshi Tadokoro",
        "authorids": "/37089578718;/37285220400;/37086017796;/37089578916;/37402546000;/37296053600;/37296054300;/37089578718;/37285220400;/37086017796;/37089578916;/37402546000;/37296053600;/37296054300",
        "aff": "Tohoku University, Japan; RIKEN Center for Advance Inteligence Project, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981492/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9630440956645872041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University;RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": ";Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.riken.jp/en/cap/",
        "aff_unique_abbr": "Tohoku U;RIKEN CAIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981389",
        "title": "Lazy Lifelong Planning for Efficient Replanning in Graphs with Expensive Edge Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an incremental search algorithm, called Lifelong-GLS, which combines the vertex efficiency of Lifelong Planning A* (LPA*) and the edge efficiency of Generalized Lazy Search (GLS) for efficient replanning on dynamic graphs where edge evaluation is expensive. We use a lazily evaluated LPA* to repair the cost-to-come inconsistencies of the relevant region of the current search tree based on the previous search results, and then we restrict the expensive edge evaluations only to the current shortest subpath as in the GLS framework. The proposed algorithm is complete and correct in finding the optimal solution in the current graph, if one exists. We also show the efficiency of the proposed algorithm compared to the standard LPA* and the GLS algorithms over consecutive search episodes in a dynamic environment.",
        "primary_area": "",
        "author": "Jaein Lim;Siddhartha Srinivasa;Panagiotis Tsiotras;Jaein Lim;Siddhartha Srinivasa;Panagiotis Tsiotras",
        "authorids": "/37088506597;/37339877600;/37330609800;/37088506597;/37339877600;/37330609800",
        "aff": "School of Aerospace Engineering Georgia Institute of Technology, Atlanta, Georgia; School of Computer Science & Engineering University of Washington, Seattle, WA; School of Aerospace Engineering Institute for Robotics & Intelligent Machines Georgia Institute of Technology, Atlanta, Georgia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981389/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3848547793718701972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Washington",
        "aff_unique_dep": "School of Aerospace Engineering;School of Computer Science & Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.washington.edu",
        "aff_unique_abbr": "Georgia Tech;UW",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981530",
        "title": "Learn from Interaction: Learning to Pick via Reinforcement Learning in Challenging Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Bin picking is a challenging problem in robotics due to high dimensional action space, partially visible objects, and contact-rich environments. State-of-the-art methods for bin picking are often simplified as planar manipulation, or learn policy based on human demonstration and motion primitives. The designs have escalated in complexity while still failing to reach the generality and robustness of human picking ability. Here, we present an end-to-end reinforcement learning (RL) framework to produce an adaptable and robust policy for picking objects in diverse real-world environments, including but not limited to tilted bins and corner objects. We present a novel solution to incorporate object interaction in policy learning. The object interaction is represented by the poses of objects. The policy learning is based on two neural networks with asymmetric state inputs. One acts on the object interaction information, while the other acts on the depth observation and proprioceptive signals of robots. The results of experiment shows remarkable zero-shot generalization from simulation to the real world and extensive real-world experiments show the effectiveness of the approach.",
        "primary_area": "",
        "author": "Chao Zhao;Jungwon Seo;Chao Zhao;Jungwon Seo",
        "authorids": "/37089447535;/38252779400;/37089447535;/38252779400",
        "aff": "Electronic and Computer Engineering Department, The Hong Kong University of Science and Technology; Mechanical and Aerospace/Electronic and Computer Engineering Department, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981530/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17419337762254755798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Electronic and Computer Engineering Department",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981092",
        "title": "Learnable Spatio-Temporal Map Embeddings for Deep Inertial Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Indoor localization systems often fuse inertial odometry with map information via hand-defined methods to reduce odometry drift, but such methods are sensitive to noise and struggle to generalize across odometry sources. To address the robustness problem in map utilization, we propose a data-driven prior on possible user locations in a map by combining learned spatial map embeddings and temporal odometry embeddings. Our prior learns to encode which map regions are feasible locations for a user more accurately than previous hand-defined methods. This prior leads to a 49% improvement in inertial-only localization accuracy when used in a particle filter. This result is significant, as it shows that our relative positioning method can match the performance of absolute positioning using bluetooth beacons. To show the gen-eralizability of our method, we also show similar improvements using wheel encoder odometry. Our code will be made publicly available\u20201project page: https://rebrand.ly/learned-map-prior.",
        "primary_area": "",
        "author": "Dennis Melamed;Karnik Ram;Vivek Roy;Kris Kitani;Dennis Melamed;Karnik Ram;Vivek Roy;Kris Kitani",
        "authorids": "/37089662398;/37089194925;/37088400083;/37294510900;/37089662398;/37089194925;/37088400083;/37294510900",
        "aff": "Robotics Institute in Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute in Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute in Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute in Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981092/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10721739709977744440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981572",
        "title": "Learned Depth Estimation of 3D Imaging Radar for Indoor Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "3D imaging radar offers robust perception capability through visually demanding environments due to the unique penetrative and reflective properties of millimeter waves (mmWave). Current approaches for 3D perception with imaging radar require knowledge of environment geometry, accumulation of data from multiple frames for perception, or access to between-frame motion. Imaging radar presents an additional difficulty due to the complexity of its data representation. To address these issues, and make imaging radar easier to use for downstream robotics tasks, we propose a learning-based method that regresses radar measurements into cylindrical depth maps using LiDAR supervision. Due to the limitation of the regression formulation, directions where the radar beam could not reach will still generate a valid depth. To address this issue, our method additionally learns a 3D filter to remove those pixels. Experiments show that our system generates visually accurate depth estimation. Furthermore, we confirm the overall ability to generalize in the indoor scene using the estimated depth for probabilistic occupancy mapping with ground truth trajectory. The code and model will be released11https://github.com/rpl-cmu/learned-depth-imaging-radar.",
        "primary_area": "",
        "author": "Ruoyang Xu;Wei Dong;Akash Sharma;Michael Kaess;Ruoyang Xu;Wei Dong;Akash Sharma;Michael Kaess",
        "authorids": "/37089658686;/37086933483;/37088997026;/37324200400;/37089658686;/37086933483;/37088997026;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University (CMU), Pittsburgh, USA; Robotics Institute, Carnegie Mellon University (CMU), Pittsburgh, USA; Robotics Institute, Carnegie Mellon University (CMU), Pittsburgh, USA; Robotics Institute, Carnegie Mellon University (CMU), Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981572/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12820472933306613016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981900",
        "title": "Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and Visual Affordance",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, task-oriented grasp detection approaches are mostly based on pixel-level affordance detection and semantic segmentation. These pixel-level approaches heavily rely on the accuracy of a 2D affordance mask, and the generated grasp candidates are restricted to a small workspace. To mitigate these limitations, we firstly construct a novel affordance-based grasp dataset and propose a 6-DoF task-oriented grasp detection framework, which takes the observed object point cloud as input and predicts diverse 6-DoF grasp poses for different tasks. Specifically, our implicit estimation network and visual affordance network in this framework could directly predict coarse grasp candidates, and corresponding 3D affordance heatmap for each potential task, respectively. Furthermore, the grasping scores from coarse grasps are combined with heatmap values to generate more accurate and finer candidates. Our proposed framework shows significant improvements compared to baselines for existing and novel objects on our simulation dataset. Although our framework is trained based on the simulated objects and environment, the final generated grasp candidates can be accurately and stably executed in the real robot experiments when the object is randomly placed on a support surface.",
        "primary_area": "",
        "author": "Wenkai Chen;Hongzhuo Liang;Zhaopeng Chen;Fuchun Sun;Jianwei Zhang;Wenkai Chen;Hongzhuo Liang;Zhaopeng Chen;Fuchun Sun;Jianwei Zhang",
        "authorids": "/37089661521;/37086700920;/37404312400;/37279269000;/37281460600;/37089661521;/37086700920;/37404312400;/37279269000;/37281460600",
        "aff": "Department of Informatics, Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg; Department of Informatics, Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg; Agile Robots AG; Department of Computer Science and Technology, State Key Lab on Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University; Department of Informatics, Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981900/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15172650347451677586&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;Agile Robots AG;Tsinghua University",
        "aff_unique_dep": "Department of Informatics, Technical Aspects of Multimodal Systems (TAMS);;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.agilerobots.com;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UHH;Agile Robots;Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9981974",
        "title": "Learning Agile Hybrid Whole-body Motor Skills for Thruster-Aided Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Humanoid robots are versatile platforms with the potential for multiple locomotion skills. However, this contact-switched system with only two contact feet is fragile to keep balance in many scenarios. Inspired by birds combining legs and wings, we propose the novel hybrid locomotion behavior for the humanoid robots with the aid of a thruster suit. To fully leverage their agility while guaranteeing efficient computation, we combine the neural controller based on reinforcement learning to handle the complexity of the highly non-linear system and the optimization-based controller to explicitly handle the constraint conditions of the safety-critical thruster module. Our learning framework is demonstrated on several thruster-aided humanoid platforms with hybrid walking and even dynamic locomotion skills. To our best knowledge, it is the first work that, 1. demonstrates agile hybrid whole-body locomotion skills on the thruster-aided humanoid robot; 2. achieves hybrid locomotion under the reinforcement learning settings.",
        "primary_area": "",
        "author": "Fan Shi;Tomoki Anzai;Yuta Kojio;Kei Okada;Masayuki Inaba;Fan Shi;Tomoki Anzai;Yuta Kojio;Kei Okada;Masayuki Inaba",
        "authorids": "/37086162286;/37086287194;/37086211574;/37280639000;/37286658200;/37086162286;/37086287194;/37086211574;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981974/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17724974913046667873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981648",
        "title": "Learning Coordinated Terrain-Adaptive Locomotion by Imitating a Centroidal Dynamics Planner",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a simple imitation learning procedure for learning locomotion controllers that can walk over very challenging terrains. We use trajectory optimization (TO) to produce a large dataset of trajectories over procedurally generated terrains and use Reinforcement Learning (RL) to imitate these trajectories. We demonstrate with a realistic model of the ANYmal robot that the learned controllers transfer to unseen terrains and provide an effective initialization for fine-tuning on challenging terrains that require exteroception and precise foot placements. Our setup combines TO and RL in a simple fashion that overcomes the computational limitations and need for a robust tracking controller of the former and the exploration and reward-tuning difficulties of the latter.",
        "primary_area": "",
        "author": "Phil\u00e9mon Brakel;Steven Bohez;Leonard Hasenclever;Nicolas Heess;Konstantinos Bousmalis;Phil\u00e9mon Brakel;Steven Bohez;Leonard Hasenclever;Nicolas Heess;Konstantinos Bousmalis",
        "authorids": "/37085772407;/37085637809;/37089663333;/38467156100;/37282935000;/37085772407;/37085637809;/37089663333;/38467156100;/37282935000",
        "aff": "Deepmind, London; Deepmind, London; Deepmind, London; Deepmind, London; Deepmind, London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981648/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14871914326709400710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981748",
        "title": "Learning Coordination Policies over Heterogeneous Graphs for Human-Robot Teams via Recurrent Neural Schedule Propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "As human-robot collaboration increases in the workforce, it becomes essential for human-robot teams to coordinate efficiently and intuitively. Traditional approaches for human-robot scheduling either utilize exact methods that are intractable for large-scale problems and struggle to account for stochastic, time varying human task performance, or application-specific heuristics that require expert domain knowledge to develop. We propose a deep learning-based framework, called HybridNet, combining a heterogeneous graph-based encoder with a recurrent schedule propagator for scheduling stochastic human-robot teams under upper- and lower-bound temporal constraints. The HybridNet's encoder leverages Heterogeneous Graph Attention Networks to model the initial environment and team dynamics while accounting for the constraints. By formulating task scheduling as a sequential decision-making process, the HybridNet's recurrent neural schedule propagator leverages Long Short-Term Memory (LSTM) models to propagate forward consequences of actions to carry out fast schedule generation, removing the need to interact with the environment between every taskagent pair selection. The resulting scheduling policy network provides a computationally lightweight yet highly expressive model that is end-to-end trainable via Reinforcement Learning algorithms. We develop a virtual task scheduling environment for mixed human-robot teams in a multi-round setting, capable of modeling the stochastic learning behaviors of human workers. Experimental results showed that HybridNet outperformed other human-robot scheduling solutions across problem sizes for both deterministic and stochastic human performance, with faster runtime compared to pure-GNN-based schedulers.",
        "primary_area": "",
        "author": "Batuhan Altundas;Zheyuan Wang;Joshua Bishop;Matthew Gombolay;Batuhan Altundas;Zheyuan Wang;Joshua Bishop;Matthew Gombolay",
        "authorids": "/37089662094;/37088481898;/37089664059;/37086326631;/37089662094;/37088481898;/37089664059;/37086326631",
        "aff": "School of Computer Science, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981748/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12757624574655923347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981884",
        "title": "Learning Dynamic Bipedal Walking Across Stepping Stones",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a learning approach for 3D dynamic bipedal walking when footsteps are constrained to stepping stones. While recent work has shown progress on this problem, real-world demonstrations have been limited to relatively simple open-loop, perception-free scenarios. Our main contribution is a more advanced learning approach that enables real-world demonstrations, using the Cassie robot, of closed-loop dynamic walking over moderately difficult stepping-stone patterns. Our approach first uses reinforcement learning (RL) in simulation to train a controller that maps footstep commands onto joint actions without any reference motion information. We then learn a model of that controller's capabilities, which enables prediction of feasible footsteps given the robot's current dynamic state. The resulting controller and model are then integrated with a real-time overhead camera system for detecting stepping stone locations. For evaluation, we develop a benchmark set of stepping stone patterns, which are used to test performance in both simulation and the real world. Overall, we demonstrate that sim-to-real learning is extremely promising for enabling dynamic locomotion over stepping stones. We also identify challenges remaining that motivate important future research directions.",
        "primary_area": "",
        "author": "Helei Duan;Ashish Malik;Mohitvishnu S. Gadde;Jeremy Dao;Alan Fern;Jonathan Hurst;Helei Duan;Ashish Malik;Mohitvishnu S. Gadde;Jeremy Dao;Alan Fern;Jonathan Hurst",
        "authorids": "/37086154386;/37086805622;/38547580600;/37086114282;/37353413400;/37267365600;/37086154386;/37086805622;/38547580600;/37086114282;/37353413400;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981884/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7100045342965491749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981508",
        "title": "Learning Enabled Fast Planning and Control in Dynamic Environments with Intermittent Information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a safe planning and control problem for mobile robots operating in communication- and sensor-limited dynamic environments. In this case the robots cannot sense the objects around them and must instead rely on intermittent, external information about the environment, as e.g., in underwater applications. The challenge in this case is that the robots must plan using only this stale data, while accounting for any noise in the data or uncertainty in the environment. To address this challenge we propose a compositional technique which leverages neural networks to quickly plan and control a robot through crowded and dynamic environments using only intermittent information. Specifically, our tool uses reachability analysis and potential fields to train a neural network that is capable of generating safe control actions. We demonstrate our technique both in simulation with an underwater vehicle crossing a crowded shipping channel and with real experiments with ground vehicles in communication-and sensor-limited environments.",
        "primary_area": "",
        "author": "Matthew Cleaveland;Esen Yel;Yiannis Kantaros;Insup Lee;Nicola Bezzo;Matthew Cleaveland;Esen Yel;Yiannis Kantaros;Insup Lee;Nicola Bezzo",
        "authorids": "/37089281044;/37086422921;/37085499544;/37279665300;/37546843800;/37089281044;/37086422921;/37085499544;/37279665300;/37546843800",
        "aff": "Department of Computer Science and Precise Center, University of Pennsylvania, Philadelphia, PA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Electrical and Systems Engineering, Washington University of St. Louis, MO; Department of Computer Science and Precise Center, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Computer Engineering, Link Lab, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981508/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4000932902841741850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "University of Pennsylvania;Stanford University;Washington University of St. Louis;University of Virginia",
        "aff_unique_dep": "Department of Computer Science and Precise Center;Department of Aeronautics and Astronautics;Department of Electrical and Systems Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.stanford.edu;https://wustl.edu;https://www.virginia.edu",
        "aff_unique_abbr": "UPenn;Stanford;WUSTL;UVA",
        "aff_campus_unique_index": "0;1;2;0;3",
        "aff_campus_unique": "Philadelphia;Stanford;St. Louis;Charlottesville",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981342",
        "title": "Learning Feature Decomposition for Domain Adaptive Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation (MDE) has attracted intense study due to its low cost and critical functions for robotic tasks such as localization, mapping and obstacle detection. Supervised approaches have led to great success with the advance of deep learning, but they rely on large quantities of ground-truth depth annotations that are expensive to acquire. Unsupervised domain adaptation (UDA) transfers knowledge from labeled source data to unlabeled target data, so as to relax the constraint of supervised learning. However, existing UDA approaches may not completely align the domain gap across different datasets because of the domain shift problem. We believe better domain alignment can be achieved via well-designed feature decomposition. In this paper, we propose a novel UDA method for MDE, referred to as Learning Feature Decomposition for Adaptation (LFDA), which learns to decompose the feature space into content and style components. LFDA only attempts to align the content component since it has a smaller domain gap. Meanwhile, it excludes the style component which is specific to the source domain from training the primary task. Furthermore, LFDA uses separate feature distribution estimations to further bridge the domain gap. Extensive experiments on three domain adaptative MDE scenarios show that the proposed method achieves superior accuracy and lower computational cost compared to the state-of-the-art approaches.",
        "primary_area": "",
        "author": "Shao-Yuan Lo;Wei Wang;Jim Thomas;Jingjing Zheng;Vishal M. Patel;Cheng-Hao Kuo;Shao-Yuan Lo;Wei Wang;Jim Thomas;Jingjing Zheng;Vishal M. Patel;Cheng-Hao Kuo",
        "authorids": "/37089226514;/37089664130;/37089661455;/37089663203;/37391395200;/37089661358;/37089226514;/37089664130;/37089661455;/37089663203;/37391395200;/37089661358",
        "aff": "Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Amazon Lab126; Amazon Lab126; Amazon Lab126; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Amazon Lab126",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981342/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8329968902680172482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "Johns Hopkins University;Amazon",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Amazon Lab126",
        "aff_unique_url": "https://www.jhu.edu;https://www.amazon.com",
        "aff_unique_abbr": "JHU;Amazon Lab126",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981873",
        "title": "Learning Goal-Oriented Non-Prehensile Pushing in Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Pushing objects through cluttered scenes is a challenging task, especially when the objects to be pushed have initially unknown dynamics and touching other entities has to be avoided to reduce the risk of damage. In this paper, we approach this problem by applying deep reinforcement learning to generate pushing actions for a robotic manipulator acting on a planar surface where objects have to be pushed to goal locations while avoiding other items in the same workspace. With the latent space learned from a depth image of the scene and other observations of the environment, such as contact information between the end effector and the object as well as distance to the goal, our framework is able to learn contact-rich pushing actions that avoid collisions with other objects. As the experimental results with a six degrees of freedom robotic arm show, our system is able to successfully push objects from start to end positions while avoiding nearby objects. Furthermore, we evaluate our learned policy in comparison to a state-of-the-art pushing controller for mobile robots and show that our agent performs better in terms of success rate, collisions with other objects, and continuous object contact in various scenarios.",
        "primary_area": "",
        "author": "Nils Dengler;David Gro\u00dfklaus;Maren Bennewitz;Nils Dengler;David Gro\u00dfklaus;Maren Bennewitz",
        "authorids": "/37087049550;/37089661992;/37324765000;/37087049550;/37089661992;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981873/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5247386469543009871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982205",
        "title": "Learning High Speed Precision Table Tennis on a Physical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning goal conditioned control in the real world is a challenging open problem in robotics. Reinforcement learning systems have the potential to learn autonomously via trial-and-error, but in practice the costs of manual reward design, ensuring safe exploration, and hyperparameter tuning are often enough to preclude real world deployment. Imitation learning approaches, on the other hand, offer a simple way to learn control in the real world, but typically require costly cu-rated demonstration data and lack a mechanism for continuous improvement. Recently, iterative imitation methods have been shown to be effective at relaxing both these constraints, learning goal directed control from undirected demonstration data, and improving continuously via self-supervised goal reaching. These approaches, however, have not yet been shown to scale beyond simple simulated environments. In this work, we present the first evidence that simple iterative imitation learning can scale to goal-directed behavior on a real robot in a dynamic setting: high speed, precision table tennis (e.g. \u201cland the ball on this particular target\u201d). We find that this approach offers a straightforward way to do continuous on-robot learning, without complexities such as reward design, value function learning, or sim-to-real transfer. We also find that this approach is scalable-sample efficient enough to train on a physical robot in just a few hours. In real world evaluations, we find that that the resulting policy can perform on par or better than amateur humans (with players sampled randomly from a robotics lab) at the task of returning the ball to specific targets on the table. Finally, we analyze the effect of an initial undirected bootstrap dataset size on performance, finding that a modest amount of unstructured demonstration data provided up-front drastically speeds up the convergence of a general purpose goal-reaching policy. See supplementary video for examples of the policy on a physical robot. Show More",
        "primary_area": "",
        "author": "Tianli Ding;Laura Graesser;Saminda Abeyruwan;David B. D'Ambrosio;Anish Shankar;Pierre Sermanet;Pannag R. Sanketi;Corey Lynch;Tianli Ding;Laura Graesser;Saminda Abeyruwan;David B. D'Ambrosio;Anish Shankar;Pierre Sermanet;Pannag R. Sanketi;Corey Lynch",
        "authorids": "/37089659800;/37088691251;/37085777434;/37085839345;/37089661082;/37680831200;/37846225900;/37086099911;/37089659800;/37088691251;/37085777434;/37085839345;/37089661082;/37680831200;/37846225900;/37086099911",
        "aff": "Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States; Robotics at Google, Google Research, Mountain View, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982205/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4955113337400679380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Robotics at Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981264",
        "title": "Learning Implicit Priors for Motion Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion optimization is an effective framework for generating smooth and safe trajectories for robotic manipulation tasks. However, it suffers from local optima that hinder its applicability, especially for multi-objective tasks. In this paper, we study this problem in light of the integration of Energy-Based Models (EBM) as guiding priors in motion optimization. EBMs are probabilistic models with unnormalized energy functions that represent expressive multimodal distributions. Due to their implicit nature, EBMs can easily be integrated as data-driven factors or initial sampling distributions in the motion optimization problem. This work presents a set of necessary modeling and algorithmic choices to effectively learn and integrate EBMs into motion optimization. We present a set of EBM architectures for learning generalizable distributions over trajectories that are important for the subsequent deployment of EBMs. Moreover, we investigate the benefit of including smoothness regularization in the learning process to improve motion optimization. In addition to gradient-based solvers, we also propose a stochastic method for trajectory optimization with learned EBMs. We provide extensive empirical results in a set of representative tasks against competitive baselines that demonstrate the superiority of EBMs as priors in motion optimization scaling up to 7 -dof robot pouring that can be easily transferred to the real robotic system. Videos and additional details are available at https://sites.google.com/view/implicit-priors.",
        "primary_area": "",
        "author": "Julen Urain;An T. Le;Alexander Lambert;Georgia Chalvatzaki;Byron Boots;Jan Peters;Julen Urain;An T. Le;Alexander Lambert;Georgia Chalvatzaki;Byron Boots;Jan Peters",
        "authorids": "/37086435541;/37089776766;/37086452975;/37085353493;/37085459219;/37533077600;/37086435541;/37089776766;/37086452975;/37085353493;/37085459219;/37533077600",
        "aff": "Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt (Germany); Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt (Germany); School of Computer Science and Engineering (CSE), University of Washington (USA); Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt (Germany); School of Computer Science and Engineering (CSE), University of Washington (USA); Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt (Germany)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981264/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1133238330679491074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "Technische Universitat Darmstadt;University of Washington",
        "aff_unique_dep": "Intelligent Autonomous Systems Lab;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.washington.edu",
        "aff_unique_abbr": "TUD;UW",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Seattle",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9981132",
        "title": "Learning Important Regions via Attention for Video Streaming on Cloud Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Cloud robotics, i.e., controlling robots from the cloud, make it possible to perform more complex processes, make robots smaller, and coordinate multi-robots by sharing information between robots and utilizing abundant computing resources. In cloud robotics, robots need to transmit videos to the cloud in real time to recognize their surroundings. Lowering the video quality reduces the bitrate in low bandwidth environments; however, this may lead to control errors and misrecognition due to lack of detailed image features. Even with 5G, bandwidth fluctuates widely, especially in moving robots, making it difficult to upload high quality video consistently. To reduce bitrate while preserving Quality of Control (QoC), we propose a method of learning the important regions for a pretrained autonomous agent using self-attention, and transmitting the video to the agent by controlling the image quality of each region on the basis of the estimated importance. The evaluation results demonstrate that our approach can maintain QoC while reducing the bitrate to 26% by setting important regions to high quality and the rest to low quality.",
        "primary_area": "",
        "author": "Hayato Itsumi;Florian Beye;Vitthal Charvi;Koichi Nihei;Hayato Itsumi;Florian Beye;Vitthal Charvi;Koichi Nihei",
        "authorids": "/37540438200;/37086695215;/37089659223;/37062130200;/37540438200;/37086695215;/37089659223;/37062130200",
        "aff": "System Platform Research Laboratories, NEC Corporation; System Platform Research Laboratories, NEC Corporation; System Platform Research Laboratories, NEC Corporation; System Platform Research Laboratories, NEC Corporation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981132/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10905692104784331640&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "System Platform Research Laboratories",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981346",
        "title": "Learning Moving-Object Tracking with FMCW LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a learning-based moving-object tracking method utilizing the newly developed LiDAR sensor, Frequency Modulated Continuous Wave (FMCW) LiDAR. Compared with most existing commercial LiDAR sensors, FMCW LiDAR can provide additional Doppler velocity information to each 3D point of the point clouds. Benefiting from this, we can generate instance labels as ground truth in a semi-automatic manner. Given the labels, we propose a contrastive learning framework, which pulls together the features from the same instance in embedding space and pushes apart the features from different instances, to improve the tracking quality. Extensive experiments are conducted on the recorded driving data, and the results show that our method outperforms the baseline methods by a large margin.",
        "primary_area": "",
        "author": "Yi Gu;Hongzhi Cheng;Kafeng Wang;Dejing Dou;Chengzhong Xu;Hui Kong;Yi Gu;Hongzhi Cheng;Kafeng Wang;Dejing Dou;Chengzhong Xu;Hui Kong",
        "authorids": "/37089661072;/37089660667;/37089019259;/37545978900;/37278305300;/37061510500;/37089661072;/37089660667;/37089019259;/37545978900;/37278305300;/37061510500",
        "aff": "State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), Faculty of Science and Technology, University of Macau, Macau, China; State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), Faculty of Science and Technology, University of Macau, Macau, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences and University of Chinese Academy of Sciences; Baidu Research; State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), Faculty of Science and Technology, University of Macau, Macau, China; State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), Faculty of Science and Technology, University of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981346/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4271858713926316195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "University of Macau;Shenzhen Institute of Advanced Technology;Baidu",
        "aff_unique_dep": "Faculty of Science and Technology;;Baidu Research",
        "aff_unique_url": "https://www.um.edu.mo;http://www.siat.cas.cn;https://research.baidu.com",
        "aff_unique_abbr": "UMacau;SIAT;Baidu",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Macau;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981440",
        "title": "Learning Neuro-Symbolic Relational Transition Models for Bilevel Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic domains, learning and planning are complicated by continuous state spaces, continuous action spaces, and long task horizons. In this work, we address these challenges with Neuro-Symbolic Relational Transition Models (NSRTs), a novel class of models that are data-efficient to learn, compatible with powerful robotic planning methods, and generalizable over objects. NSRTs have both symbolic and neural components, enabling a bilevel planning scheme where symbolic AI planning in an outer loop guides continuous planning with neural models in an inner loop. Experiments in four robotic planning domains show that NSRTs can be learned very data-efficiently, and then used for fast planning in new tasks that require up to 60 actions and involve many more objects than were seen during training.",
        "primary_area": "",
        "author": "Rohan Chitnis;Tom Silver;Joshua B. Tenenbaum;Tom\u00e1s Lozano-P\u00e9rez;Leslie Pack Kaelbling;Rohan Chitnis;Tom Silver;Joshua B. Tenenbaum;Tom\u00e1s Lozano-P\u00e9rez;Leslie Pack Kaelbling",
        "authorids": "/37085544593;/37088687048;/37622583000;/38273814000;/37269373600;/37085544593;/37088687048;/37622583000;/38273814000;/37269373600",
        "aff": "MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981440/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=542558024187247538&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT CSAIL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982084",
        "title": "Learning Object Manipulation Skills from Video via Approximate Differentiable Physics",
        "track": "main",
        "status": "Poster",
        "abstract": "We aim to teach robots to perform simple object manipulation tasks by watching a single video demonstration. Towards this goal, we propose an optimization approach that outputs a coarse and temporally evolving 3D scene to mimic the action demonstrated in the input video. Similar to previous work, a differentiable renderer ensures perceptual fidelity between the 3D scene and the 2D video. Our key novelty lies in the inclusion of a differentiable approach to solve a set of Ordinary Differential Equations (ODEs) that allows us to approximately model laws of physics such as gravity, friction, and hand-object or object-object interactions. This not only enables us to dramatically improve the quality of estimated hand and object states, but also produces physically admissible trajectories that can be directly translated to a robot without the need for costly reinforcement learning. We evaluate our approach on a 3D reconstruction task that consists of 54 video demonstrations sourced from 9 actions such as pull something from right to left or put something in front of something. Our approach improves over previous state-of-the-art by almost 30%, demonstrating superior quality on especially challenging actions involving physical interactions of two objects such as put something onto something. Finally, we showcase the learned skills on a Franka Emika Panda robot.",
        "primary_area": "",
        "author": "Vladim\u00edr Petr\u00edk;Mohammad Nomaan Qureshi;Josef Sivic;Makar Tapaswi;Vladim\u00edr Petr\u00edk;Mohammad Nomaan Qureshi;Josef Sivic;Makar Tapaswi",
        "authorids": "/37085341098;/37089195208;/37282919700;/37660375500;/37085341098;/37089195208;/37282919700;/37660375500",
        "aff": "CIIRC, Czech Technical University in Prague; CVIT, IIIT, Hyderabad, India; CIIRC, Czech Technical University in Prague; CVIT, IIIT, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982084/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15571619307649342064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Czech Technical University in Prague;International Institute of Information Technology, Hyderabad",
        "aff_unique_dep": "CIIRC;",
        "aff_unique_url": "https://www.ciirc.cvut.cz/;https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "CTU;IIIT Hyderabad",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Prague;Hyderabad",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Czech Republic;India"
    },
    {
        "id": "9981287",
        "title": "Learning Object-Based State Estimators for Household Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot operating in a household makes observations of multiple objects as it moves around over the course of days or weeks. The objects may be moved by inhabitants, but not completely at random. The robot may be called upon later to retrieve objects and will need a long-term object-based memory in order to know how to find them. Existing work in semantic SLAM does not attempt to capture the dynamics of object movement. In this paper, we combine some aspects of classic techniques for data-association filtering with modern attention-based neural networks to construct object-based memory systems that operate on high-dimensional observations and hypotheses. We perform end-to-end learning on labeled observation trajectories to learn both the transition and observation models. We demonstrate the system's effectiveness in maintaining memory of dynamically changing objects in both simulated environment and real images, and demonstrate improvements over classical structured approaches as well as unstructured neural approaches. Additional information available at project website: https://yilundu.github.io/obm/.",
        "primary_area": "",
        "author": "Yilun Du;Tomas Lozano-Perez;Leslie Pack Kaelbling;Yilun Du;Tomas Lozano-Perez;Leslie Pack Kaelbling",
        "authorids": "/37089315638;/38273814000;/37269373600;/37089315638;/38273814000;/37269373600",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981287/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13479622267617549290&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982049",
        "title": "Learning Pseudo Front Depth for 2D Forward-Looking Sonar-based Multi-view Stereo",
        "track": "main",
        "status": "Poster",
        "abstract": "Retrieving the missing dimension information in acoustic images from 2D forward-looking sonar is a well-known problem in the field of underwater robotics. There are works attempting to retrieve 3D information from a single image which allows the robot to generate 3D maps with fly-through motion. However, owing to the unique image formulation principle, estimating 3D information from a single image faces severe ambiguity problems. Classical methods of multi-view stereo can avoid the ambiguity problems, but may require a large number of viewpoints to generate an accurate model. In this work, we propose a novel learning-based multi-view stereo method to estimate 3D information. To better utilize the information from multiple frames, an elevation plane sweeping method is proposed to generate the depth-azimuth-elevation cost volume. The volume after regularization can be considered as a probabilistic volumetric representation of the target. Instead of performing regression on the elevation angles, we use pseudo front depth from the cost volume to represent the 3D information which can avoid the 2D-3D problem in acoustic imaging. High-accuracy results can be generated with only two or three images. Synthetic datasets were generated to simulate various underwater targets. We also built the first real dataset with accurate ground truth in a large scale water tank. Experimental results demonstrate the superiority of our method, compared to other state-of-the-art methods.",
        "primary_area": "",
        "author": "Yusheng Wang;Yonghoon Ji;Hiroshi Tsuchiya;Hajime Asama;Atsushi Yamashita;Yusheng Wang;Yonghoon Ji;Hiroshi Tsuchiya;Hajime Asama;Atsushi Yamashita",
        "authorids": "/37086824838;/37085483676;/37088440072;/37294904700;/37270922900;/37086824838;/37085483676;/37088440072;/37294904700;/37270922900",
        "aff": "Department of Precision Engineering, Graduate School of Engineering, The University of Tokyo, Japan; Graduate School for Advanced Science and Technology, JAIST, Japan; Research Institute, Wakachiku Construction Co., Ltd., Japan; Department of Precision Engineering, Graduate School of Engineering, The University of Tokyo, Japan; Department of Human and Environmental Engineered Studies, Graduate School of Frontier Sciences, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982049/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8348008532576845504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "University of Tokyo;Japan Advanced Institute of Science and Technology;Wakachiku Construction Co., Ltd.",
        "aff_unique_dep": "Department of Precision Engineering;Graduate School for Advanced Science and Technology;Research Institute",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.jaist.ac.jp;",
        "aff_unique_abbr": "UTokyo;JAIST;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981607",
        "title": "Learning Skills to Navigate without a Master: A Sequential Multi-Policy Reinforcement Learning Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving complex problems using reinforcement learning necessitates breaking down the problem into manageable tasks, and learning policies to solve these tasks. These policies, in turn, have to be controlled by a master policy that takes high-level decisions. Hence learning policies involves hierarchical decision structures. However, training such methods in practice may lead to poor generalization, with either sub-policies executing actions for too few time steps or devolving into a single policy altogether. In our work, we introduce an alternative approach to learn such skills sequentially without using an overarching hierarchical policy. We propose this method in the context of environments where a major component of the objective of a learning agent is to prolong the episode for as long as possible. We refer to our proposed method as Sequential Soft Option Critic. We demonstrate the utility of our approach on navigation and goal-based tasks in a flexible simulated 3D navigation environment that we have developed. We also show that our method outperforms prior methods such as Soft Actor-Critic and Soft Option Critic on various environments, including the Atari River Raid environment and the Gym-Duckietown self-driving car simulator.",
        "primary_area": "",
        "author": "Ambedkar Dukkipati;Rajarshi Banerjee;Ranga Shaarad Ayyagari;Dhaval Parmar Udaybhai;Ambedkar Dukkipati;Rajarshi Banerjee;Ranga Shaarad Ayyagari;Dhaval Parmar Udaybhai",
        "authorids": "/37276331600;/37089662687;/37089663096;/37089661680;/37276331600;/37089662687;/37089663096;/37089661680",
        "aff": "Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981607/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=821199130418872582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Department of Computer Science and Automation",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9982211",
        "title": "Learning Suction Cup Dynamics from Motion Capture: Accurate Prediction of an Object's Vertical Motion during Release",
        "track": "main",
        "status": "Poster",
        "abstract": "Suction grippers are the most common pick-and-place end effectors used in industry. However, there is little literature on creating and validating models to predict their force interaction with objects in dynamic conditions. In this paper, we study the interaction dynamics of an active vacuum suction gripper during the vertical release of an object. Object and suction cup motions are recorded using a motion capture system. As the object's mass is known and can be changed for each experiment, a study of the object's motion can lead to an estimate of the interaction force generated by the suction gripper. We show that, by learning this interaction force, it is possible to accurately predict the object's vertical motion as a function of time. This result is the first step toward 3D motion prediction when releasing an object from a suction gripper.",
        "primary_area": "",
        "author": "Menno Lubbers;Job van Voorst;Maarten Jongeneel;Alessandro Saccon;Menno Lubbers;Job van Voorst;Maarten Jongeneel;Alessandro Saccon",
        "authorids": "/37089659172;/37089658695;/37089515671;/37296911500;/37089659172;/37089658695;/37089515671;/37296911500",
        "aff": "Faculty of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands; Faculty of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands; Faculty of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands; Faculty of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982211/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15884721468719855188&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Eindhoven University of Technology",
        "aff_unique_dep": "Faculty of Mechanical Engineering",
        "aff_unique_url": "https://www.tue.nl",
        "aff_unique_abbr": "TU/e",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Eindhoven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9982223",
        "title": "Learning Symbolic Failure Detection for Grasping and Mobile Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to detect failure during task execution and to recover from failure is vital for autonomous robots performing tasks in previously unknown environments. In this paper, we present an approach for failure detection during the execution of grasping and mobile manipulation tasks by a humanoid robot. The approach combines multi-modal sensory information consisting of proprioceptive, force and visual information to learn task models from multiple successful task executions, in order to detect failures and to externalize them for humans in an interpretable way. To this end, we define symbolic action predicates based on multi-modal sensory information to allow high-level state estimation based on action-specific decision trees. To allow symbolic failure detection, we then learn task models that are represented as Markov chains. We evaluated the approach in several pick-and-place and mobile manipulation tasks performed by a humanoid robot in a decommissioning and a household scenario. The evaluation shows that the learned task models are capable of detecting failure with an F1-score of 93 %.",
        "primary_area": "",
        "author": "Patrick Hegemann;Tim Zechmeister;Markus Grotz;Kevin Hitzler;Tamim Asfour;Patrick Hegemann;Tim Zechmeister;Markus Grotz;Kevin Hitzler;Tamim Asfour",
        "authorids": "/37089660969;/37089661222;/37086200970;/37088340636;/37295529100;/37089660969;/37089661222;/37086200970;/37088340636;/37295529100",
        "aff": "High Performance Humanoid Technolo-gies Lab, Institute for Anthropomatics and Robotics, Karlsruhe In-stitute of Technology (KIT), Germany; High Performance Humanoid Technolo-gies Lab, Institute for Anthropomatics and Robotics, Karlsruhe In-stitute of Technology (KIT), Germany; High Performance Humanoid Technolo-gies Lab, Institute for Anthropomatics and Robotics, Karlsruhe In-stitute of Technology (KIT), Germany; High Performance Humanoid Technolo-gies Lab, Institute for Anthropomatics and Robotics, Karlsruhe In-stitute of Technology (KIT), Germany; High Performance Humanoid Technolo-gies Lab, Institute for Anthropomatics and Robotics, Karlsruhe In-stitute of Technology (KIT), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982223/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12088448105208434182&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981068",
        "title": "Learning Temporal Task Models from Human Bimanual Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning temporal relations between actions in a bimanual manipulation task is important for capturing the constraints of actions required to achieve the task's goal. However, given several demonstrations of a bimanual manipulation task, the problem of identifying the true temporal dependencies between actions - if there are any - is very challenging due to contradictions. We propose a model-driven approach for learning temporal task models from multiple bimanual human demonstrations that represents temporal relations on two levels. First, temporal relations between sets of actions that exhibit a tight temporal coupling, and second, temporal relations between these sets of actions. We build on Allen's interval algebra as a representation to express relations between temporal intervals. Semantically defining these interval relations allows us to soften their formulation to deal with inaccuracies in real data obtained when observing humans demonstrating the task. Our temporal task models can be learned incrementally from multiple modalities, and allow us to reason about viable alternatives during task execution in case of unexpected events. We evaluated the approach quantitatively on two datasets and qualitatively on a humanoid robot. The evaluation shows how inherent properties of bimanual human manipulation tasks can be exploited to derive a model useful for the reproduction by humanoid robots.",
        "primary_area": "",
        "author": "Christian R.G. Dreher;Tamim Asfour;Christian R.G. Dreher;Tamim Asfour",
        "authorids": "/37086313722;/37295529100;/37086313722;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981068/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16293464179891162164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982053",
        "title": "Learning Time-optimized Path Tracking with or without Sensory Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a learning-based approach that allows a robot to quickly follow a reference path defined in joint space without exceeding limits on the position, velocity, acceleration and jerk of each robot joint. Contrary to offline methods for time-optimal path parameterization, the reference path can be changed during motion execution. In addition, our approach can utilize sensory feedback, for instance, to follow a reference path with a bipedal robot without losing balance. With our method, the robot is controlled by a neural network that is trained via reinforcement learning using data generated by a physics simulator. From a mathematical perspective, the problem of tracking a reference path in a time-optimized manner is formalized as a Markov decision process. Each state includes a fixed number of waypoints specifying the next part of the reference path. The action space is designed in such a way that all resulting motions comply with the specified kinematic joint limits. The reward function finally reflects the trade-off between the execution time, the deviation from the desired reference path and optional additional objectives like balancing. We evaluate our approach with and without additional objectives and show that time-optimized path tracking can be successfully learned for both industrial and humanoid robots. In addition, we demonstrate that networks trained in simulation can be successfully transferred to a real robot.",
        "primary_area": "",
        "author": "Jonas C. Kiemel;Torsten Kr\u00f6ger;Jonas C. Kiemel;Torsten Kr\u00f6ger",
        "authorids": "/37088504301;/37283223400;/37088504301;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982053/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=118128972347457713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981243",
        "title": "Learning Turn-Taking Behavior from Human Demonstrations for Social Human-Robot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Turn-taking is a fundamental behavior during human interactions and robots must be capable of turn-taking to interact with humans. Current state-of-the-art approaches in turn-taking focus on developing general models to predict the end of turn (EoT) across all contexts. This demands an all-inclusive verbal and non-verbal behavioral dataset from all possible contexts of interaction. Before robot deployment, gathering such a dataset may be infeasible and/or impractical. More importantly, a robot needs to predict the EoT and decide on the best time to take a turn (i.e, start speaking). In this research, we present a learning from demonstration (LfD) system for a robot to learn from demonstrations, after it has been deployed, to make decisions on the appropriate time for taking a turn within specific social interaction contexts. The system captures demonstrations of turn-taking during social interactions and uses these demonstrations to train a LSTM RNN based model to replicate the turn-taking behavior of the demonstrator. We evaluate the system for teaching the turn-taking behavior of an interviewer during a job interview context. Furthermore, we investigate the efficacy of verbal, prosodic, and gestural cues for deciding when to begin a turn.",
        "primary_area": "",
        "author": "Pourya Shahverdi;Alexander Tyshka;Madeline Trombly;Wing-Yue Geoffrey Louie;Pourya Shahverdi;Alexander Tyshka;Madeline Trombly;Wing-Yue Geoffrey Louie",
        "authorids": "/37086087857;/37089552869;/37089550028;/38497604500;/37086087857;/37089552869;/37089550028;/38497604500",
        "aff": "Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981243/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17089618783084620305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oakland University",
        "aff_unique_dep": "Intelligent Robotics Laboratory",
        "aff_unique_url": "https://www.oakland.edu",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Michigan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981376",
        "title": "Learning Visual Feedback Control for Dynamic Cloth Folding",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation of cloth is a challenging task due to the high dimensionality of the configuration space and the complexity of dynamics affected by various material properties. The effect of complex dynamics is even more pronounced in dynamic folding, for example, when a square piece of fabric is folded in two by a single manipulator. To account for the complexity and uncertainties, feedback of the cloth state using e.g. vision is typically needed. However, construction of visual feedback policies for dynamic cloth folding is an open problem. In this paper, we present a solution that learns policies in simulation using Reinforcement Learning (RL) and transfers the learned policies directly to the real world. In addition, to learn a single policy that manipulates multiple materials, we randomize the material properties in simulation. We evaluate the contributions of visual feedback and material randomization in real-world experiments. The experimental results demonstrate that the proposed solution can fold successfully different fabric types using dynamic manipulation in the real world. Code, data, and videos are available at https://sites.google.com/view/dynamic-cloth-folding.",
        "primary_area": "",
        "author": "Julius Hietala;David Blanco\u2013Mulero;Gokhan Alcan;Ville Kyrki;Julius Hietala;David Blanco\u2013Mulero;Gokhan Alcan;Ville Kyrki",
        "authorids": "/37089659876;/37089343389;/37085689166;/37274001900;/37089659876;/37089343389;/37085689166;/37274001900",
        "aff": "Department of Electrical Engineering and Automation (EEA), Intelligent Robotics Group, Aalto University, Espoo, Finland; Department of Electrical Engineering and Automation (EEA), Intelligent Robotics Group, Aalto University, Espoo, Finland; Department of Electrical Engineering and Automation (EEA), Intelligent Robotics Group, Aalto University, Espoo, Finland; Department of Electrical Engineering and Automation (EEA), Intelligent Robotics Group, Aalto University, Espoo, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981376/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8419639040734040605&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "Department of Electrical Engineering and Automation",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Espoo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9981055",
        "title": "Learning Visual Robotic Control Efficiently with Contrastive Pre-training and Data Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in unsupervised representation learning significantly improved the sample efficiency of training Reinforcement Learning policies in simulated environments. However, similar gains have not yet been seen for real-robot reinforcement learning. In this work, we focus on enabling data-efficient real-robot learning from pixels. We present Contrastive Pre-training and Data Augmentation for Efficient Robotic Learning (CoDER), a method that utilizes data augmentation and unsupervised learning to achieve sample-efficient training of real-robot arm policies from sparse rewards. While contrastive pre-training, data augmentation, demonstrations, and reinforcement learning are alone insufficient for efficient learning, our main contribution is showing that the combination of these disparate techniques results in a simple yet data-efficient method. We show that, given only 10 demonstrations, a single robotic arm can learn sparse-reward manipulation policies from pixels, such as reaching, picking, moving, pulling a large object, flipping a switch, and opening a drawer in just 30 minutes of mean real-world training time. We include videos and code on the project website: https://sites.google.com/view/efficient-robotic-manipulation/home.",
        "primary_area": "",
        "author": "Albert Zhan;Ruihan Zhao;Lerrel Pinto;Pieter Abbeel;Michael Laskin;Albert Zhan;Ruihan Zhao;Lerrel Pinto;Pieter Abbeel;Michael Laskin",
        "authorids": "/37089660012;/37089302740;/37085796211;/37542877900;/37085632730;/37089660012;/37089302740;/37085796211;/37542877900;/37085632730",
        "aff": "University of California, Berkeley; University of California, Berkeley; New York University; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981055/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UC Berkeley;NYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981183",
        "title": "Learning a Group-Aware Policy for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-aware robot navigation promises a range of applications in which mobile robots bring versatile assistance to people in common human environments. While prior research has mostly focused on modeling pedestrians as independent, intentional individuals, people move in groups; consequently, it is imperative for mobile robots to respect human groups when navigating around people. This paper explores learning group-aware navigation policies based on dynamic group formation using deep reinforcement learning. Through simulation experiments, we show that group-aware policies, compared to baseline policies that neglect human groups, achieve greater robot navigation performance (e.g., fewer collisions), minimize violation of social norms and discomfort, and reduce the robot's movement impact on pedestrians. Our results contribute to the development of social navigation and the integration of mobile robots into human environments.",
        "primary_area": "",
        "author": "Kapil Katyal;Yuxiang Gao;Jared Markowitz;Sara Pohland;Corban Rivera;I-Jeng Wang;Chien-Ming Huang;Kapil Katyal;Yuxiang Gao;Jared Markowitz;Sara Pohland;Corban Rivera;I-Jeng Wang;Chien-Ming Huang",
        "authorids": "/38228973900;/37089659926;/37086191866;/37088363653;/37089496391;/37268770400;/38548162000;/38228973900;/37089659926;/37086191866;/37088363653;/37089496391;/37268770400;/38548162000",
        "aff": "Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA; Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA; Applied Physics Lab, Johns Hopkins University, Laurel, MD, USA; Dept. of EECS, UC Berkeley, Berkeley, CA, USA; Applied Physics Lab, Johns Hopkins University, Laurel, MD, USA; Applied Physics Lab, Johns Hopkins University, Laurel, MD, USA; Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981183/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6639153166861330697&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Johns Hopkins University;University of California, Berkeley",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.jhu.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "JHU;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;2;1;1;0",
        "aff_campus_unique": "Baltimore;Laurel;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981730",
        "title": "Learning a State Estimator for Tactile In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of estimating the pose of an object which is being manipulated by a multi-fingered robotic hand by only using proprioceptive feedback. To address this challenging problem, we propose a novel variant of differentiable particle filters, which combines two key extensions. First, our learned proposal distribution incorporates recent measurements in a way that mitigates weight degeneracy. Second, the particle update works on non-euclidean manifolds like Lie-groups, enabling learning-based pose estimation in 3D on SE(3). We show that the method can represent the rich and often multi-modal distributions over poses that arise in tactile state estimation. The models are trained in simulation, but by using domain randomization, we obtain state estimators that can be employed for pose estimation on a real robotic hand (equipped with joint torque sensors). Moreover, the estimator runs fast, allowing for online usage with update rates of more than 100 Hz on a single CPU core. We quantitatively evaluate our method and benchmark it against other approaches in simulation. We also show qualitative experiments on the real torque-controlled DLR-Hand II.",
        "primary_area": "",
        "author": "Lennart R\u00f6stel;Leon Sievers;Johannes Pitz;Berthold B\u00e4uml;Lennart R\u00f6stel;Leon Sievers;Johannes Pitz;Berthold B\u00e4uml",
        "authorids": "/37089662539;/37089450909;/37089449984;/37295469600;/37089662539;/37089450909;/37089449984;/37295469600",
        "aff": "DLR Institute of Robotics and Mechatronics and with the Deggendorf Institute of Technology (DIT); DLR Institute of Robotics and Mechatronics and with the Deggendorf Institute of Technology (DIT); DLR Institute of Robotics and Mechatronics and with the Deggendorf Institute of Technology (DIT); DLR Institute of Robotics and Mechatronics and with the Deggendorf Institute of Technology (DIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981730/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4384740469277372379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "DLR Institute of Robotics and Mechatronics",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981142",
        "title": "Learning an Interpretable Model for Driver Behavior Prediction with Inductive Biases",
        "track": "main",
        "status": "Poster",
        "abstract": "To plan safe maneuvers and act with foresight, autonomous vehicles must be capable of accurately predicting the uncertain future. In the context of autonomous driving, deep neural networks have been successfully applied to learning pre-dictive models of human driving behavior from data. However, the predictions suffer from cascading errors, resulting in large inaccuracies over long time horizons. Furthermore, the learned models are black boxes, and thus it is often unclear how they arrive at their predictions. In contrast, rule-based models-which are informed by human experts-maintain long-term coherence in their predictions and are human-interpretable. However, such models often lack the sufficient expressiveness needed to capture complex real-world dynamics. In this work, we begin to close this gap by embedding the Intelligent Driver Model, a popular hand-crafted driver model, into deep neural networks. Our model's transparency can offer considerable advantages, e.g., in debugging the model and more easily interpreting its predictions. We evaluate our approach on a simulated merging scenario, showing that it yields a robust model that is end-to-end trainable and provides greater transparency at no cost to the model's predictive accuracy.",
        "primary_area": "",
        "author": "Salar Arbabi;Davide Tavernini;Saber Fallah;Richard Bowden;Salar Arbabi;Davide Tavernini;Saber Fallah;Richard Bowden",
        "authorids": "/37088771472;/38667687500;/38667400500;/37268872100;/37088771472;/38667687500;/38667400500;/37268872100",
        "aff": "Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981142/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10529303191091702858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Automotive Engineering",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Guildford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981930",
        "title": "Learning from Demonstration using a Curvature Regularized Variational Auto-Encoder (CurvVAE)",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning intricate manipulation skills from human demonstrations requires good sample efficiency. We introduce a novel learning algorithm, the Curvature-regularized Variational Auto-Encoder (CurvVAE), to achieve this goal. The CurvVAE is able to model the natural variations in human-demonstrated trajectory data without overfitting. It does so by regularizing the curvature of the learned manifold. To showcase our algorithm, our robot learns an interpretable model of the variation in how humans acquire soft, slippery banana slices with a fork. We evaluate our learned trajectories on a physical robot system, resulting in banana slice acquisition performance better than current state-of-the-art.",
        "primary_area": "",
        "author": "Travers Rhodes;Tapomayukh Bhattacharjee;Daniel D. Lee;Travers Rhodes;Tapomayukh Bhattacharjee;Daniel D. Lee",
        "authorids": "/37086578712;/37531634500;/37280609600;/37086578712;/37531634500;/37280609600",
        "aff": "Cornell University, USA; Cornell University, USA; Cornell University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981930/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18296010964915301285&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981051",
        "title": "Learning of Balance Controller Considering Changes in Body State for Musculoskeletal Humanoids",
        "track": "main",
        "status": "Poster",
        "abstract": "The musculoskeletal humanoid is difficult to modelize due to the flexibility and redundancy of its body, whose state can change over time, and so balance control of its legs is challenging. There are some cases where ordinary PID controls may cause instability. In this study, to solve these problems, we propose a method of learning a correlation model among the joint angle, muscle tension, and muscle length of the ankle and the zero moment point to perform balance control. In addition, information on the changing body state is embedded in the model using parametric bias, and the model estimates and adapts to the current body state by learning this information online. This makes it possible to adapt to changes in upper body posture that are not directly taken into account in the model, since it is difficult to learn the complete dynamics of the whole body considering the amount of data and computation. The model can also adapt to changes in body state, such as the change in footwear and change in the joint origin due to recalibration. The effectiveness of this method is verified by a simulation and by using an actual musculoskeletal humanoid, Musashi.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Yoshimoto Ribayashi;Akihiro Miki;Yasunori Toshimitsu;Temma Suzuki;Kei Okada;Masayuki Inaba;Kento Kawaharazuka;Yoshimoto Ribayashi;Akihiro Miki;Yasunori Toshimitsu;Temma Suzuki;Kei Okada;Masayuki Inaba",
        "authorids": "/37086101930;/37089659025;/37089295157;/37086842924;/37089658134;/37280639000;/37286658200;/37086101930;/37089659025;/37089295157;/37086842924;/37089658134;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981051/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11017309388454840544&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981373",
        "title": "Learning physics-informed simulation models for soft robotic manipulation: A case study with dielectric elastomer actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft actuators offer a safe, adaptable approach to tasks like gentle grasping and dexterous manipulation. Creating accurate models to control such systems however is challenging due to the complex physics of deformable materials. Accurate Finite Element Method (FEM) models incur prohibitive computational complexity for closed-loop use. Using a differentiable simulator is an attractive alternative, but their applicability to soft actuators and deformable materials remains under-explored. This paper presents a framework that combines the advantages of both. We learn a differentiable model consisting of a material properties neural network and an analytical dynamics model of the remainder of the manipulation task. This physics-informed model is trained using data generated from FEM, and can be used for closed-loop control and inference. We evaluate our framework on a dielectric elastomer actuator (DEA) coin-pulling task. We simulate the task of using DEA to pull a coin along a surface with frictional contact, using FEM, and evaluate the physics-informed model for simulation, control, and inference. Our model attains \u2264 5% simulation error compared to FEM, and we use it as the basis for an MPC controller that requires fewer iterations to converge than model-free actor-critic, PD, and heuristic policies.",
        "primary_area": "",
        "author": "Manu Lahariya;Craig Innes;Chris Develder;Subramanian Ramamoorthy;Manu Lahariya;Craig Innes;Chris Develder;Subramanian Ramamoorthy",
        "authorids": "/37088898632;/37088996171;/37266034400;/37529920500;/37088898632;/37088996171;/37266034400;/37529920500",
        "aff": "IDLab, Ghent University - imec, Ghent, Belgium; School of Informatics, University of Edinburgh, United Kingdom; IDLab, Ghent University - imec, Ghent, Belgium; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981373/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11226781060938906229&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Ghent University;University of Edinburgh",
        "aff_unique_dep": "IDLab;School of Informatics",
        "aff_unique_url": "https://www.ugent.be;https://www.ed.ac.uk",
        "aff_unique_abbr": "UGent;Edinburgh",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Ghent;Edinburgh",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Belgium;United Kingdom"
    },
    {
        "id": "9981261",
        "title": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years have witnessed an emerging paradigm shift toward embodied artificial intelligence, in which an agent must learn to solve challenging tasks by interacting with its environment. There are several challenges in solving embodied multimodal tasks, including long-horizon planning, vision-and-language grounding, and efficient exploration. We focus on a critical bottleneck, namely the performance of planning and navigation. To tackle this challenge, we propose a Neural SLAM approach that, for the first time, utilizes several modalities for exploration, predicts an affordance-aware semantic map, and plans over it at the same time. This signif-icantly improves exploration efficiency, leads to robust long-horizon planning, and enables effective vision-and-language grounding. With the proposed Affordance-aware Multimodal Neural SLAM (AMSLAM) approach, we obtain more than 40% improvement over prior published work on the ALFRED benchmark and set a new state-of-the-art generalization per-formance at a success rate of 23.48% on the test unseen scenes.",
        "primary_area": "",
        "author": "Zhiwei Jia;Kaixiang Lin;Yizhou Zhao;Qiaozi Gao;Govind Thattai;Gaurav S. Sukhatme;Zhiwei Jia;Kaixiang Lin;Yizhou Zhao;Qiaozi Gao;Govind Thattai;Gaurav S. Sukhatme",
        "authorids": "/37089660179;/37089547431;/37088530768;/37089474508;/37089016196;/37278934100;/37089660179;/37089547431;/37088530768;/37089474508;/37089016196;/37278934100",
        "aff": "University of California, San Diego; Amazon Alexa AI; University of California, Los Angeles; Amazon Alexa AI; Amazon Alexa AI; University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981261/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13358599234793030099&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;3",
        "aff_unique_norm": "University of California, San Diego;Amazon;University of California, Los Angeles;University of Southern California",
        "aff_unique_dep": ";Amazon Alexa AI;;",
        "aff_unique_url": "https://www.ucsd.edu;https://www.amazon.com;https://www.ucla.edu;https://www.usc.edu",
        "aff_unique_abbr": "UCSD;Amazon;UCLA;USC",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "San Diego;;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982279",
        "title": "Learning to Assess Danger from Movies for Cooperative Escape Planning in Hazardous Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been a plethora of work towards im-proving robot perception and navigation, yet their application in hazardous environments, like during a fire or an earthquake, is still at a nascent stage. We hypothesize two key challenges here: first, it is difficult to replicate such scenarios in the real world, which is necessary for training and testing purposes. Second, current systems are not fully able to take advantage of the rich multi-modal data available in such hazardous environments. To address the first challenge, we propose to harness the enormous amount of visual content available in the form of movies and TV shows, and develop a dataset that can represent hazardous environments encountered in the real world. The data is annotated with high-level danger ratings for realistic disaster images, and corresponding keywords are provided that summarize the content of the scene. In response to the second challenge, we propose a multi-modal danger estimation pipeline for collaborative human-robot escape scenarios. Our Bayesian framework improves danger estimation by fusing information from robot's camera sensor and language inputs from the human. Furthermore, we augment the estimation module with a risk-aware planner that helps in identifying safer paths out of the dangerous environment. Through extensive simulations, we exhibit the advantages of our multi-modal perception framework that gets translated into tangible benefits such as higher success rate in a collaborative human-robot mission.",
        "primary_area": "",
        "author": "Vikram Shree;Sarah Allen;Beatriz Asfora;Jacopo Banfi;Mark Campbell;Vikram Shree;Sarah Allen;Beatriz Asfora;Jacopo Banfi;Mark Campbell",
        "authorids": "/37086092896;/37089662297;/37088497563;/37085491416;/37272971700;/37086092896;/37089662297;/37088497563;/37085491416;/37272971700",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982279/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4371053445080764729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Cornell University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.cornell.edu;https://www.mit.edu",
        "aff_unique_abbr": "Cornell;MIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Ithaca;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981545",
        "title": "Learning to Complete Object Shapes for Object-level Mapping in Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel object-level mapping system that can simultaneously segment, track, and reconstruct objects in dynamic scenes. It can further predict and complete their full geometries by conditioning on reconstructions from depth inputs and a category-level shape prior with the aim that completed object geometry leads to better object reconstruction and tracking accuracy. For each incoming RGB-D frame, we perform instance segmentation to detect objects and build data associations between the detection and the existing object maps. A new object map will be created for each unmatched detection. For each matched object, we jointly optimise its pose and latent geometry representations using geometric residual and differential rendering residual towards its shape prior and completed geometry. Our approach shows better tracking and reconstruction performance compared to methods using traditional volumetric mapping or learned shape prior approaches. We evaluate its effectiveness by quantitatively and qualitatively testing it in both synthetic and real-world sequences.",
        "primary_area": "",
        "author": "Binbin Xu;Andrew J. Davison;Stefan Leutenegger;Binbin Xu;Andrew J. Davison;Stefan Leutenegger",
        "authorids": "/37086936010;/37293837200;/37698403100;/37086936010;/37293837200;/37698403100",
        "aff": "Department of Computing, Imperial College, London, United Kingdom; Department of Computing, Imperial College, London, United Kingdom; Smart Robotics Lab, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981545/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15910881381754455365&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Imperial College London;Technical University of Munich",
        "aff_unique_dep": "Department of Computing;Smart Robotics Lab",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.tum.de",
        "aff_unique_abbr": "Imperial College;TUM",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "London;Munich",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9981253",
        "title": "Learning to Fold Real Garments with One Arm: A Case Study in Cloud-Based Robotics Research",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous fabric manipulation is a longstanding challenge in robotics, but evaluating progress is difficult due to the cost and diversity of robot hardware. Using Reach, a cloud robotics platform that enables low-latency remote execution of control policies on physical robots, we present the first systematic benchmarking of fabric manipulation al-gorithms on physical hardware. We develop 4 novel learning-based algorithms that model expert actions, keypoints, reward functions, and dynamic motions, and we compare these against 4 learning-free and inverse dynamics algorithms on the task of folding a crumpled T-shirt with a single robot arm. The entire lifecycle of data collection, model training, and policy evaluation was performed remotely without physical access to the robot workcell. Results suggest a new algorithm combining imitation learning with analytic methods achieves human-level performance on the flattening task and 93% of human-level performance on the folding task. See https://sites.google.com/berkeley.edu/ cloudfolding for all data, code, models, and supplemental material.",
        "primary_area": "",
        "author": "Ryan Hoque;Kaushik Shivakumar;Shrey Aeron;Gabriel Deza;Aditya Ganapathi;Adrian Wong;Johnny Lee;Andy Zeng;Vincent Vanhoucke;Ken Goldberg;Ryan Hoque;Kaushik Shivakumar;Shrey Aeron;Gabriel Deza;Aditya Ganapathi;Adrian Wong;Johnny Lee;Andy Zeng;Vincent Vanhoucke;Ken Goldberg",
        "authorids": "/37088687016;/37089659271;/37089440079;/37089431627;/37088688406;/37089663422;/37088438951;/37086217185;/37426058000;/37273026700;/37088687016;/37089659271;/37089440079;/37089431627;/37088688406;/37089663422;/37088438951;/37086217185;/37426058000;/37273026700",
        "aff": "AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; AUTOLAB, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981253/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7803988402588907274&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;1;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": "AUTOLAB;Robotics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com",
        "aff_unique_abbr": "UC Berkeley;Google Robotics",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;1;1;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981661",
        "title": "Learning to Grasp on the Moon from 3D Octree Observations with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Extraterrestrial rovers with a general-purpose robotic arm have many potential applications in lunar and planetary exploration. Introducing autonomy into such systems is desirable for increasing the time that rovers can spend gathering scientific data and collecting samples. This work investigates the applicability of deep reinforcement learning for vision-based robotic grasping of objects on the Moon. A novel simulation environment with procedurally-generated datasets is created to train agents under challenging conditions in unstructured scenes with uneven terrain and harsh illumination. A model-free off-policy actor-critic algorithm is then employed for end-to-end learning of a policy that directly maps compact octree observations to continuous actions in Cartesian space. Experimental evaluation indicates that 3D data representations enable more effective learning of manipulation skills when compared to traditionally used image-based observations. Domain randomization improves the generalization of learned policies to novel scenes with previously unseen objects and different illumination conditions. To this end, we demonstrate zero-shot sim-to-real transfer by evaluating trained agents on a real robot in a Moon-analogue facility. The source code and datasets are available at https://github.com/AndrejOrsula/drl_grasping.",
        "primary_area": "",
        "author": "Andrej Orsula;Simon B\u00f8gh;Miguel Olivares-Mendez;Carol Martinez;Andrej Orsula;Simon B\u00f8gh;Miguel Olivares-Mendez;Carol Martinez",
        "authorids": "/37089659782;/37681256600;/38271290600;/37682080100;/37089659782;/37681256600;/38271290600;/37682080100",
        "aff": "Space Robotics Research Group (SpaceR), Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Department of Materials and Production, Robotics & Automation Group, Aalborg University, Denmark; Space Robotics Research Group (SpaceR), Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Space Robotics Research Group (SpaceR), Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981661/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3525499534462713636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Luxembourg;Aalborg University",
        "aff_unique_dep": "Space Robotics Research Group (SpaceR);Department of Materials and Production, Robotics & Automation Group",
        "aff_unique_url": "https://wwwen.unil.lu;https://www.aau.dk",
        "aff_unique_abbr": "UniLu;AAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Luxembourg;Denmark"
    },
    {
        "id": "9981234",
        "title": "Learning to Guide Online Multi-Contact Receding Horizon Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In Receding Horizon Planning (RHP), it is critical that the motion being executed facilitates the completion of the task, e.g. building momentum to overcome large obstacles. This requires a value function to inform the desirability of robot states. However, given the complex dynamics, value functions are often approximated by expensive computation of trajectories in an extended planning horizon. In this work, to achieve online multi-contact Receding Horizon Planning (RHP), we propose to learn an oracle that can predict local objectives (intermediate goals) for a given task based on the current robot state and the environment. Then, we use these local objectives to construct local value functions to guide a short-horizon RHP. To obtain the oracle, we take a supervised learning approach, and we present an incremental training scheme that can improve the prediction accuracy by adding demonstrations on how to recover from failures. We compare our approach against the baseline (long-horizon RHP) for planning centroidal trajectories of humanoid walking on moderate slopes as well as large slopes where static stability cannot be achieved. We validate these trajectories by tracking them via a whole-body inverse dynamics controller in simulation. We show that our approach can achieve online RHP for 95%-98.6% cycles, outperforming the baseline (8%-51.2%).",
        "primary_area": "",
        "author": "Jiayi Wang;Teguh Santoso Lembono;Sanghyun Kim;Sylvain Calinon;Sethu Vijayakumar;Steve Tonneau;Jiayi Wang;Teguh Santoso Lembono;Sanghyun Kim;Sylvain Calinon;Sethu Vijayakumar;Steve Tonneau",
        "authorids": "/37088686909;/37085616225;/37085583667;/37295947200;/37295595500;/37085790049;/37088686909;/37085616225;/37085583667;/37295947200;/37295595500;/37085790049",
        "aff": "School of Informatics, The University of Edinburgh, United Kingdom; Idiap Research Institute, Switzerland and with EPFL, Switzerland; Dept. of AI Machinery, System Engineering Research Division, Korea Institute of Machinery & Materials, South Korea; Idiap Research Institute, Switzerland and with EPFL, Switzerland; The Alan Turing Institute, United Kingdom; School of Informatics, The University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981234/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9843000040220662105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;3;0",
        "aff_unique_norm": "University of Edinburgh;Idiap Research Institute;Korea Institute of Machinery & Materials;Alan Turing Institute",
        "aff_unique_dep": "School of Informatics;;Dept. of AI Machinery, System Engineering Research Division;",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.idiap.ch;http://www.kimm.co.kr;https://www.turing.ac.uk",
        "aff_unique_abbr": "Edinburgh;Idiap;KIMM;ATI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;1;2;1;0;0",
        "aff_country_unique": "United Kingdom;Switzerland;South Korea"
    },
    {
        "id": "9982269",
        "title": "Learning to Herd Amongst Obstacles from an Optimized Surrogate",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates how a shepherd robot can efficiently steer a coherent group by intelligently moving behind the group in obstacle-filled environments. It was been shown that a model trained by deep reinforcement learning can guide a small number (2\u20134) of agents among obstacles. However, herding a larger group becomes significantly more challenging because it exhibits the characteristics similar to manipulating a deformable object, i.e., the system is dynamic and the problem is highly underactuated. To overcome these challenges, we show that a model can be trained more effectively via an optimized surrogate, such as a potential field that optimizes the control quality of the group without explicitly considering the placement of the shepherd. Our experiments demonstrate that the trained model is robust to noise for group behaviors and environments. Compared to the rule-based method, the proposed approach maintains a higher probability of guiding the sheep and better control quality.",
        "primary_area": "",
        "author": "Jixuan Zhi;Jyh-Ming Lien;Jixuan Zhi;Jyh-Ming Lien",
        "authorids": "/37086943040;/37277182300;/37086943040;/37277182300",
        "aff": "Department of Computer Science, George Mason University, 4400, University Drive MSN 4A5, Fairfax, VA, USA; Department of Computer Science, George Mason University, 4400, University Drive MSN 4A5, Fairfax, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982269/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2878137288334588067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fairfax",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981120",
        "title": "Learning to Simulate Realistic LiDARs",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulating realistic sensors is a challenging part in data generation for autonomous systems, often involving carefully handcrafted sensor design, scene properties, and physics modeling. To alleviate this, we introduce a pipeline for data-driven simulation of a realistic LiDAR sensor. We propose a model that learns a mapping between RGB images and corresponding LiDAR features such as raydrop or perpoint intensities directly from real datasets. We show that our model can learn to encode realistic effects such as dropped points on transparent surfaces or high intensity returns on reflective materials. When applied to naively raycasted point clouds provided by off-the-shelf simulator software, our model enhances the data by predicting intensities and removing points based on the scene's appearance to match a real LiDAR sensor. We use our technique to learn models of two distinct LiDAR sensors and use them to improve simulated LiDAR data accordingly. Through a sample task of vehicle segmentation, we show that enhancing simulated point clouds with our technique improves downstream task performance.",
        "primary_area": "",
        "author": "Beno\u00eet Guillard;Sai Vemprala;Jayesh K. Gupta;Ondrej Miksik;Vibhav Vineet;Pascal Fua;Ashish Kapoor;Beno\u00eet Guillard;Sai Vemprala;Jayesh K. Gupta;Ondrej Miksik;Vibhav Vineet;Pascal Fua;Ashish Kapoor",
        "authorids": "/37089316159;/37085796013;/37089658531;/37945980500;/38094245300;/37281288800;/37397699500;/37089316159;/37085796013;/37089658531;/37945980500;/38094245300;/37281288800;/37397699500",
        "aff": "\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Microsoft Research, Redmond, USA; Microsoft Research, Redmond, USA; Microsoft Mixed Reality & AI Lab, Zurich, Switzerland; Microsoft Research, Redmond, USA; \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Microsoft Research, Redmond, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981120/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3341463179085987638&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.epfl.ch;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "EPFL;MSR",
        "aff_campus_unique_index": "0;1;1;2;1;0;1",
        "aff_campus_unique": "Lausanne;Redmond;Zurich",
        "aff_country_unique_index": "0;1;1;0;1;0;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9981341",
        "title": "Learning to Singulate Layers of Cloth using Tactile Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation of cloth has applications ranging from fabrics manufacturing to handling blankets and laundry. Cloth manipulation is challenging for robots largely due to their high degrees of freedom, complex dynamics, and severe self-occlusions when in folded or crumpled configurations. Prior work on robotic manipulation of cloth relies primarily on vision sensors alone, which may pose challenges for fine-grained manipulation tasks such as grasping a desired number of cloth layers from a stack of cloth. In this paper, we propose to use tactile sensing for cloth manipulation; we attach a tactile sensor (ReSkin) to one of the two fingertips of a Franka robot and train a classifier to determine whether the robot is grasping a specific number of cloth layers. During test-time experiments, the robot uses this classifier as part of its policy to grasp one or two cloth layers using tactile feedback to determine suitable grasping points. Experimental results over 180 physical trials suggest that the proposed method outperforms baselines that do not use tactile feedback and has better generalization to unseen cloth compared to methods that use image classifiers. Code, data, and videos are available at https://sites.google.com/view/reskin-cloth.",
        "primary_area": "",
        "author": "Sashank Tirumala;Thomas Weng;Daniel Seita;Oliver Kroemer;Zeynep Temel;David Held;Sashank Tirumala;Thomas Weng;Daniel Seita;Oliver Kroemer;Zeynep Temel;David Held",
        "authorids": "/37088528657;/37085767512;/37086012763;/37593222300;/37088689031;/37408101800;/37088528657;/37085767512;/37086012763;/37593222300;/37088689031;/37408101800",
        "aff": "The Robotics Institute at Carnegie Mellon University; The Robotics Institute at Carnegie Mellon University; The Robotics Institute at Carnegie Mellon University; The Robotics Institute at Carnegie Mellon University; The Robotics Institute at Carnegie Mellon University; The Robotics Institute at Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981341/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11267681491376630505&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981423",
        "title": "Learning with Yourself: a Tangible Twin Robot System to Promote STEM Education",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a customized programmable robotic system, TanTwin (Tangible Twin), designed to promote STEM education for K-12 children. Firstly, TanTwin is implemented based on a wheel-robot with standard LEGO bricks. With several deep neural networks, a child can convert a captured portrait of himself/herself into standard LEGO bricks, therefore he/she can build a tangible twin robot of him-selflherself automatically. Besides, to adapt to the customized appearance, the corresponding visual element and content of the robotic system were also changed by a rule-based adaption algorithm. To demonstrate the effectiveness of TanTwin and to investigate whether tangible twin robots could contribute to children's learning, we conducted a controlled experimental study to compare learning with a TanTwin and with a standard robot system through measuring students' cognitive learning outcomes. The pre-/post- knowledge test results indicated that learning with a tangible twin robot leads to significantly better learning outcomes. Given the results, we validate our system and customization technology can promote STEM education.",
        "primary_area": "",
        "author": "Jiasi Gao;Jiangtao Gong;Guyue Zhou;Haole Guo;Tong Qi;Jiasi Gao;Jiangtao Gong;Guyue Zhou;Haole Guo;Tong Qi",
        "authorids": "/37088532058;/37089661527;/37085489402;/37089449179;/37089659143;/37088532058;/37089661527;/37085489402;/37089449179;/37089659143",
        "aff": "DISCOVER Lab, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R.China; DISCOVER Lab, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R.China; DISCOVER Lab, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R.China; DISCOVER Lab, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R.China; DISCOVER Lab, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981423/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10436093428218993550&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR)",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982257",
        "title": "Learning-based Localizability Estimation for Robust LiDAR Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-based localization and mapping is one of the core components in many modern robotic systems due to the direct integration of range and geometry, allowing for precise motion estimation and generation of high quality maps in real-time. Yet, as a consequence of insufficient environmental constraints present in the scene, this dependence on geometry can result in localization failure, happening in self-symmetric surroundings such as tunnels. This work addresses precisely this issue by proposing a neural network-based estimation approach for detecting (non-)localizability during robot operation. Special attention is given to the localizability of scan-to-scan registration, as it is a crucial component in many LiDAR odometry estimation pipelines. In contrast to previous, mostly traditional detection approaches, the proposed method enables early detection of failure by estimating the localizability on raw sensor measurements without evaluating the underlying registration optimization. Moreover, previous approaches remain limited in their ability to generalize across environments and sensor types, as heuristic-tuning of degeneracy detection thresholds is required. The proposed approach avoids this problem by learning from a collection of different environments, allowing the network to function over various scenarios. Furthermore, the network is trained exclusively on simulated data, avoiding arduous data collection in challenging and degenerate, often hard-to-access, environments. The presented method is tested during field experiments conducted across challenging environments and on two different sensor types without any modifications. The observed detection performance is on par with state-of-the-art methods after environment-specific threshold tuning11Supplementary Video: https://youtu.be/fm08PFwMO0c.",
        "primary_area": "",
        "author": "Julian Nubert;Etienne Walther;Shehryar Khattak;Marco Hutter;Julian Nubert;Etienne Walther;Shehryar Khattak;Marco Hutter",
        "authorids": "/37088229353;/37089660047;/37086181358;/37545251000;/37088229353;/37089660047;/37086181358;/37545251000",
        "aff": "Max Planck ETH Center for Learning Systems; Robotic Systems Lab; Max Planck ETH Center for Learning Systems; Robotic Systems Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982257/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8177008740186448561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Max Planck ETH Center for Learning Systems;ETH Zurich",
        "aff_unique_dep": "Center for Learning Systems;Robotic Systems Lab",
        "aff_unique_url": "https://learning-systems.org;https://www.ethz.ch",
        "aff_unique_abbr": ";ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981100",
        "title": "Learning-based Six-axis Force/Torque Estimation Using GelStereo Fingertip Visuotactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Visuotactile sensors have recently attracted much attention in robot communities due to the benefit of high spatial resolution sensing. However, force/torque estimation by visuotactile sensors remains a challenging problem. In this paper, we propose a learning-based six-axis force/torque estimation network using GelStereo visuotactile sensor, which can provide two-dimensional (2D) and three-dimensional (3D) displacements of markers embedded in the sensor surface. The convolutional neural networks are employed to extract multi-modal tactile deformation features; and a novel contact positional encoding method is proposed to eliminate the influence of translation invariance in convolutional operators. The well-trained model achieves the best RMSE of 0.290 N in force and 0.0084 Nm in torque. Furthermore, the proposed force/torque estimation network is integrated with a force-feedback policy for adaptive grasping tasks. The experimental results demonstrate the effectiveness of the proposed method and its potential application in robotic grasping and manipulation tasks.",
        "primary_area": "",
        "author": "Chaofan Zhang;Shaowei Cui;Yinghao Cai;Jingyi Hu;Rui Wang;Shuo Wang;Chaofan Zhang;Shaowei Cui;Yinghao Cai;Jingyi Hu;Rui Wang;Shuo Wang",
        "authorids": "/37089731616;/37088377629;/37654083400;/37088452035;/37085388619;/37280458600;/37089731616;/37088377629;/37654083400;/37088452035;/37085388619;/37280458600",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Future Technology, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology Chinese Academy of Sciences, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981100/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16710142104880147240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation;School of Future Technology",
        "aff_unique_url": "http://www.ia.cas.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "CAS;UCAS",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981161",
        "title": "Level Set-Based Camera Pose Estimation From Multiple 2D/3D Ellipse-Ellipsoid Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an object-based camera pose estimation from a single RGB image and a pre-built map of objects, represented with ellipsoidal models. We show that contrary to point correspondences, the definition of a cost function characterizing the projection of a 3D object onto a 2D object detection is not straightforward. We develop an ellipse-ellipse cost based on level sets sampling, demonstrate its nice properties for handling partially visible objects and compare its performance with other common metrics. Finally, we show that the use of a predictive uncertainty on the detected ellipses allows a fair weighting of the contribution of the correspondences which improves the computed pose. The code is released at gitlab.inria.fr/tangram/level-set-based-camera-pose-estimation.",
        "primary_area": "",
        "author": "Matthieu Zins;Gilles Simon;Marie-Odile Berger;Matthieu Zins;Gilles Simon;Marie-Odile Berger",
        "authorids": "/37088360501;/37268825900;/37266139100;/37088360501;/37268825900;/37266139100",
        "aff": "Universit\u00e9 de Lorraine, LORIA, CNRS; Universit\u00e9 de Lorraine, LORIA, CNRS; Universit\u00e9 de Lorraine, LORIA, CNRS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981161/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7471330280354485737&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Lorraine",
        "aff_unique_dep": "LORIA",
        "aff_unique_url": "https://www.univ-lorraine.fr",
        "aff_unique_abbr": "UL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981817",
        "title": "Leveraging Multi-Level Modelling to Automatically Design Behavioral Arbitrators in Robotic Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic control design for robotic systems is becoming more and more popular. However, this usually involves a significant computational cost, due to the expensive and noisy evaluation of candidate solutions through high-fidelity simulation or even real hardware. This work aims at reducing the computational cost of automatic design of behavioral arbitrators through the introduction of a two-step approach. In the first step, the structure of the finite state machine governing the behavioral arbitrator is optimized. To this purpose, a more abstracted model of the robotic system is leveraged in order to significantly reduce the computational cost. In the second step, the close-to-hardware, behavioral parameters are fine-tuned using a high-fidelity model. We show that, for a scenario involving a single robot and multiple tasks to be solved sequentially, using the proposed method results in a significant decrease of the computational cost while reaching the same controller performance both in simulation and reality.",
        "primary_area": "",
        "author": "Cyrill Baumann;Hugo Birch;Alcherio Martinoli;Cyrill Baumann;Hugo Birch;Alcherio Martinoli",
        "authorids": "/37089515928;/37089662417;/37325252600;/37089515928;/37089662417;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981817/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4805827238778713291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981541",
        "title": "Leveraging Publicly Available Textual Object Descriptions for Anthropomorphic Robotic Grasp Predictions",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems using anthropomorphic end-effectors face tremendous challenges choosing a suitable pose for grasping an object. The fact that the choice of a grasp is influenced by the physical properties of an object, the intended task, and the environment results in a considerable amount of variables. The majority of models targeted towards enabling such robots to determine a suitable grasping pose rely on computer vision techniques, sometimes complemented by textual data. This paper investigates the potential of publicly available textual descriptions to predict a suitable grasping pose for anthropomorphic end-effectors. To this end, we have retrieved textual descriptions from Wikipedia, Wiktionary, and WordNet as well as a number of well-known dictionaries for 100 everyday objects. We analyze and compare the prediction quality of multiple learning methods while showing that a support vector machine-based approach can utilize this data for achieving a prediction accuracy above 0.75. Finally, we make our collected data available to the research community.",
        "primary_area": "",
        "author": "Niko Kleer;Martin Feick;Michael Feld;Niko Kleer;Martin Feick;Michael Feld",
        "authorids": "/37089658809;/37088698819;/37684010700;/37089658809;/37088698819;/37684010700",
        "aff": "DFKI, Saarland Informatics Campus, Saarland University, Saarbr\u00fccken, Germany; DFKI, Saarland Informatics Campus, Saarland University, Saarbr\u00fccken, Germany; DFKI, Saarland Informatics Campus, Saarland University, Saarbr\u00fccken, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981541/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11938510368360093707&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dfki.de",
        "aff_unique_abbr": "DFKI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Saarland Informatics Campus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982152",
        "title": "LiDAR-Aided Visual-Inertial Localization with Semantic Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and robust localization is an essential task for autonomous driving systems. In this paper, we propose a novel 3D LiDAR-aided visual-inertial localization method. Our method fully explores the complementarity of visual and LiDAR observations. On the one hand, the association between semantic features in images and a given semantic map provides constraints for the absolute pose. On the other hand, LiDAR odometry (LO) can provide an accurate and robust 6DOF relative pose. The Error State Kalman Filter (ESKF) framework is exploited to estimate the vehicle pose relative to the semantic map, which fuses the global constraints between the image and the semantic map, the relative pose from the LO, and the raw IMU data. The method achieves centimeter-level localization accuracy in a variety of challenging scenarios. We validate the robustness and accuracy of our method in real-world scenes over 50 km. The experimental results show that the proposed method is able to achieve an average lateral accuracy of 0.059 m and longitudinal accuracy of 0.158 m, which demonstrates the practicality of the proposed system in autonomous driving applications.",
        "primary_area": "",
        "author": "Hao Li;Liangliang Pan;Ji Zhao;Hao Li;Liangliang Pan;Ji Zhao",
        "authorids": "/37089263794;/37088997255;/37963498600;/37089263794;/37088997255;/37963498600",
        "aff": "TuSimple, Beijing, China; TuSimple, Beijing, China; TuSimple, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982152/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3266137720529938679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "TuSimple",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982248",
        "title": "LiSnowNet: Real-time Snow Removal for LiDAR Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Light Detection And Rangings (LiDARs) have been widely adopted to modern self-driving vehicles, providing 3D information of the scene and surrounding objects. However, adverser weather conditions still pose significant challenges to LiDARs since point clouds captured during snowfall can easily be corrupted. The resulting noisy point clouds degrade downstream tasks such as mapping. Existing works in de-noising point clouds corrupted by snow are based on nearest-neighbor search, and thus do not scale well with modern LiDARs which usually capture 100k or more points at 10Hz. In this paper, we introduce an unsupervised de-noising algorithm, LiSnowNet, running 52 x faster than the state-of-the-art methods while achieving superior performance in de-noising. Unlike previous methods, the proposed algorithm is based on a deep convolutional neural network and can be easily deployed to hardware accelerators such as GPUs. In addition, we demonstrate how to use the proposed method for mapping even with corrupted point clouds.",
        "primary_area": "",
        "author": "Ming-Yuan Yu;Ram Vasudevan;Matthew Johnson-Roberson;Ming-Yuan Yu;Ram Vasudevan;Matthew Johnson-Roberson",
        "authorids": "/37086548743;/37648237800;/38271635400;/37086548743;/37648237800;/38271635400",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, the University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982248/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=616953941596828438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982048",
        "title": "Lifted contact dynamics for efficient optimal control of rigid body systems with contacts",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel and efficient lifting approach for the optimal control of rigid-body systems with contacts to improve the convergence properties of Newton-type methods. To relax the high nonlinearity, we consider the state, acceleration, contact forces, and control input torques, as optimization variables and the inverse dynamics and acceleration constraints on the contact frames as equality constraints. We eliminate the update of the acceleration, contact forces, and their dual variables from the linear equation to be solved in each Newton-type iteration in an efficient manner. As a result, the computational cost per Newton-type iteration is almost identical to that of the conventional non-lifted Newton-type iteration that embeds contact dynamics in the state equation. We conducted numerical experiments on the whole-body optimal control of various quadrupedal gaits subject to the friction cone constraints considered in interior-point methods and demonstrated that the proposed method can significantly increase the convergence speed to more than twice that of the conventional non-lifted approach.",
        "primary_area": "",
        "author": "Sotaro Katayama;Toshiyuki Ohtsuka;Sotaro Katayama;Toshiyuki Ohtsuka",
        "authorids": "/37086294817;/37270839500;/37086294817;/37270839500",
        "aff": "Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan; Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982048/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5320443642155671945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyoto University",
        "aff_unique_dep": "Department of System Science, Graduate School of Informatics",
        "aff_unique_url": "https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Kyoto U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981202",
        "title": "Light in the Larynx: a Miniaturized Robotic Optical Fiber for In-office Laser Surgery of the Vocal Folds",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports the design, construction, and experimental validation of a novel hand-held robot for inoffice laser surgery of the vocal folds. In-office endoscopic laser surgery is an emerging trend in Laryngology: It promises to deliver the same patient outcomes of traditional surgical treatment (i.e., in the operating room), at a fraction of the cost. Unfortunately, office procedures can be challenging to perform; the optical fibers used for laser delivery can only emit light forward in a line-of-sight fashion, which severely limits anatomical access. The robot we present in this paper aims to overcome these challenges. The end effector of the robot is a steerable laser fiber, created through the combination of a thin optical fiber (\u00d8 0.225 mm) with a tendon-actuated Nickel- Titanium notched sheath that provides bending. This device can be seamlessly used with most commercially available endoscopes, as it is sufficiently small (0\u00d8 1.1 mm) to pass through a working channel. To control the fiber, we propose a compact actuation unit that can be mounted on top of the endoscope handle, so that, during a procedure, the operating physician can operate both the endoscope and the steerable fiber with a single hand. We report simulation and phantom experiments demonstrating that the proposed device substantially enhances surgical access compared to current clinical fibers.",
        "primary_area": "",
        "author": "Alex J. Chiluisa;Nicholas E. Pacheco;Hoang S. Do;Ryan M. Tougas;Emily V. Minch;Rositsa Mihaleva;Yao Shen;Yuxiang Liu;Thomas L. Carroll;Loris Fichera;Alex J. Chiluisa;Nicholas E. Pacheco;Hoang S. Do;Ryan M. Tougas;Emily V. Minch;Rositsa Mihaleva;Yao Shen;Yuxiang Liu;Thomas L. Carroll;Loris Fichera",
        "authorids": "/37088637620;/37089660719;/37089658890;/37089662257;/37089658440;/37089659516;/37089189471;/37715376500;/37089662872;/37089053417;/37088637620;/37089660719;/37089658890;/37089662257;/37089658440;/37089659516;/37089189471;/37715376500;/37089662872;/37089053417",
        "aff": "Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mechanical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mechanical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mechanical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Otolaryngology-Head and Neck Surgery, Harvard Medical School, Boston, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981202/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3302693626625501767&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Worcester Polytechnic Institute;Harvard Medical School",
        "aff_unique_dep": "Department of Robotics Engineering;Department of Otolaryngology-Head and Neck Surgery",
        "aff_unique_url": "https://www.wpi.edu;https://hms.harvard.edu",
        "aff_unique_abbr": "WPI;HMS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Worcester;Boston",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981514",
        "title": "Lightmyography Based Decoding of Human Intention Using Temporal Multi-Channel Transformers",
        "track": "main",
        "status": "Poster",
        "abstract": "For the development of muscle-machine interfaces (MuMIs), researchers have relied mainly on Electromyography (EMG) signals. However, these signals require complex hardware systems, as well as specialized signal processing and feature extraction methods. To overcome these issues, in our previous work, we proposed a novel MuMI for decoding human intention and motion, called Lightmyography (LMG). To improve the performance of this interface even further, in this work, we employ two novel deep learning techniques called Temporal Multi-Channel Transformer (TMC-T) and Temporal Multi-Channel Vision Transformer (TMC-ViT) for the classification of hand gestures based on the LMG data. The performance of these two Transformer-based methods is evaluated and compared with other well-known deep learning and classical machine learning methods. This work also addresses the influence of varying parameters defined during the training phase of decoding models, such as the size and shape of the input data packet. A series of data augmentation techniques were also employed to generate synthetic data and increase the dataset size so as to train deep learning models more efficiently.",
        "primary_area": "",
        "author": "Ricardo V. Godoy;Anany Dwivedi;Mojtaba Shahmohammadi;Minas Liarokapis;Ricardo V. Godoy;Anany Dwivedi;Mojtaba Shahmohammadi;Minas Liarokapis",
        "authorids": "/37087469104;/37086133073;/37089186373;/38558084100;/37087469104;/37086133073;/37089186373;/38558084100",
        "aff": "Department of Me-chanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Anany Dwivedi is with the Institute of Autonomous Systems and Mechatronics, Friedrich-Alexander-Universitat Erlangen-Numberg, Germany; Department of Me-chanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Me-chanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981514/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15680502704080147947&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Auckland;Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg",
        "aff_unique_dep": "Department of Me-chanical and Mechatronics Engineering;Institute of Autonomous Systems and Mechatronics",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www fau.de",
        "aff_unique_abbr": "UoA;FAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "New Zealand;Germany"
    },
    {
        "id": "9982166",
        "title": "Linear MPC-based Motion Planning for Autonomous Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Within the context of Robotic Minimally Invasive Surgery (R-MIS), we propose a novel linear model predictive controller formulation for the coordination of multiple autonomous robotic arms. The controller is synthesized by formulating a linear approximation of non-linear constraints, which allows the controller to be both computationally faster and better performing due to the increased prediction horizon allowed within the real-time control requirements for the proposed surgical application. The solution is validated under the expected constraints of a surgical scenario in which multiple laparoscopic tools must move and coordinate in a shared environment.",
        "primary_area": "",
        "author": "Marco Minelli;Alessio Sozzi;Giacomo De Rossi;Federica Ferraguti;Saverio Farsoni;Francesco Setti;Riccardo Muradore;Marcello Bonf\u00e8;Cristian Secchi;Marco Minelli;Alessio Sozzi;Giacomo De Rossi;Federica Ferraguti;Saverio Farsoni;Francesco Setti;Riccardo Muradore;Marcello Bonf\u00e8;Cristian Secchi",
        "authorids": "/37086036138;/37087322421;/37085759529;/37075262200;/37085440514;/37887481900;/37299825000;/37300903100;/37300905500;/37086036138;/37087322421;/37085759529;/37075262200;/37085440514;/37887481900;/37299825000;/37300903100;/37300905500",
        "aff": "Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Dept. of Engineering, University of Ferrara, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Dept. of Engineering, University of Ferrara, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Engineering, University of Ferrara, Italy; Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982166/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17171004774446719199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;1;2;2;1;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia;University of Ferrara;University of Verona",
        "aff_unique_dep": "Dept. of Sciences and Methods of Engineering;Dept. of Engineering;Dept. of Computer Science",
        "aff_unique_url": "https://www.unimore.it;https://www.unife.it;https://www.univr.it",
        "aff_unique_abbr": ";;UniVR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981880",
        "title": "Linear and Nonlinear Model Predictive Control Strategies for Trajectory Tracking Micro Aerial Vehicles: A Comparative Study",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a comparison of linear and nonlinear Model Predictive Control (MPC) strategies for trajectory tracking Micro Aerial Vehicles (MAVs). In this comparative study, we paid particular attention to establish quantitatively fair metrics and testing conditions for both strategies. In particular, we chose the most suitable numerical algorithms to bridge the gap between linear and nonlinear MPC, leveraged the very same underlying solver and estimation algorithm with identical parameters, and allow both strategies to operate with a similar computational budget. In order to obtain a well-tuned performance from the controllers, we employed the parameter identification results determined in a previous study for the same robotic platform and added a reliable disturbance observer to compensate for model uncertainties. We carried out a thorough experimental campaign involving multiple representative trajectories. Our approach included three different stages for tuning the algorithmic parameters, evaluating the predictive control feasibility, and validating the performances of both MPC-based strategies. As a result, we were able to propose a decisional recipe for selecting a linear or nonlinear MPC scheme that considers the predictive control feasibility for a peculiar trajectory, characterized by specific speed and acceleration requirements, as a function of the available on-board resources.",
        "primary_area": "",
        "author": "I.K. Erunsal;J. Zheng;R. Ventura;A. Martinoli;I.K. Erunsal;J. Zheng;R. Ventura;A. Martinoli",
        "authorids": "/37086099128;/37089538859;/37376311800;/37325252600;/37086099128;/37089538859;/37376311800;/37325252600",
        "aff": "Institute for Systems and Robotics, Instituto Superior T\u00e9cnico, Lisbon, Portugal; Distributed Intelligent Systems and Algorithms Laboratory, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Institute for Systems and Robotics, Instituto Superior T\u00e9cnico, Lisbon, Portugal; Distributed Intelligent Systems and Algorithms Laboratory, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981880/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9999780799720319063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Instituto Superior T\u00e9cnico;EPFL",
        "aff_unique_dep": "Institute for Systems and Robotics;Distributed Intelligent Systems and Algorithms Laboratory",
        "aff_unique_url": "https://www.ist.utl.pt;https://www.epfl.ch",
        "aff_unique_abbr": "IST;EPFL",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Lisbon;Lausanne",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Portugal;Switzerland"
    },
    {
        "id": "9981828",
        "title": "Loading an Autonomous Large-Scale Dump Truck: Path Planning Based on Motion Data from Human-Operated Construction Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "A large-scale dump truck that automatically transports earth and sand in cooperation with a human-operated backhoe is of interest to the construction industry. A human-operated dump truck generally drives slightly past the desired loading position and then backs up to it for loading the sediment. The turning and loading positions are subjectively decided according to the working posture of the backhoe and the surrounding environment, and the safety margin of cooperative works. Backhoe operators want to perform the same maneuvers for human-operated/automated dump trucks. The movements of the autonomous vehicle should be similar to those of a human-operated one. However, it is difficult to derive a human-like path that does more than minimize costs. This study proposes a path-planning method that generates a path including a turning back, according to the changing backhoe position and surrounding conditions. We modeled the positional relationship during loading between a backhoe and dump truck, determining the loading and turning positions and related parameters from operational data collected in trials with human-operated construction vehicles. The proposed method allowed the autonomous dump truck path to resemble a human-like one. The authors have retrofitted an existing large-scale six-wheeled dump truck for automatic operation. Automatic loading in cooperation with a human-operated backhoe was realized all 17 times using the retrofitted dump. The average stopping accuracy was 0.57 m and 9.7\u00b0.",
        "primary_area": "",
        "author": "Tetsu Akegawa;Kazunori Ohno;Shotaro Kojima;Naoto Miyamoto;Taro Suzuki;Tomohiro Komatsu;Takahiro Suzuki;Yukinori Shibata;Kimitaka Asano;Satoshi Tadokoro;Tetsu Akegawa;Kazunori Ohno;Shotaro Kojima;Naoto Miyamoto;Taro Suzuki;Tomohiro Komatsu;Takahiro Suzuki;Yukinori Shibata;Kimitaka Asano;Satoshi Tadokoro",
        "authorids": "/37088808665;/37285220400;/37086017796;/37274290200;/37087323760;/37088375745;/37086052857;/37088691328;/37088377363;/37296054300;/37088808665;/37285220400;/37086017796;/37274290200;/37087323760;/37088375745;/37086052857;/37088691328;/37088377363;/37296054300",
        "aff": "Tohoku University, Japan; RIKEN Center for Advanced Intelligence Project, Japan; Tohoku University, Japan; Tohoku University, Japan; Chiba Institute University, Japan; KOWATECH co., ltd., Japan; Tohoku University, Japan; Sato koumuten Co., Ltd., Japan; Sanyo-Technics Co., Ltd., Japan; Tohoku University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981828/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15551392540911610922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;2;3;0;4;5;0",
        "aff_unique_norm": "Tohoku University;RIKEN Center for Advanced Intelligence Project;Chiba Institute University;KOWATECH co., ltd.;Sato Koumuten Co., Ltd.;Sanyo-Technics Co., Ltd.",
        "aff_unique_dep": ";Center for Advanced Intelligence Project;;;;",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.riken.jp/en/c-aip/;https://www.chiba-u.ac.jp;;;",
        "aff_unique_abbr": "Tohoku U;RIKEN C-AIP;;;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981248",
        "title": "Local Perception-Aware Transformer for Aerial Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformer-based visual object tracking has been utilized extensively. However, the Transformer structure is lack of enough inductive bias. In addition, only focusing on encoding the global feature does harm to modeling local details, which restricts the capability of tracking in aerial robots. Specifically, with local-modeling to global-search mechanism, the proposed tracker replaces the global encoder by a novel local-recognition encoder. In the employed encoder, a local-recognition attention and a local element correction network are carefully designed for reducing the global redundant information interference and increasing local inductive bias. Meanwhile, the latter can model local object details precisely under aerial view through detail-inquiry net. The proposed method achieves competitive accuracy and robustness in several authoritative aerial benchmarks with 316 sequences in total. The proposed tracker's practicability and efficiency have been validated by the real-world tests. The source code is available at https://github.com/vision4robotics/LPAT.",
        "primary_area": "",
        "author": "Changhong Fu;Weiyu Peng;Sihang Li;Junjie Ye;Ziang Cao;Changhong Fu;Weiyu Peng;Sihang Li;Junjie Ye;Ziang Cao",
        "authorids": "/37086797986;/37089659981;/37089451036;/37088917418;/37088997696;/37086797986;/37089659981;/37089451036;/37088917418;/37088997696",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, Chlna; School of Mechanical Engineering, Tongji University, Shanghai, Chlna; School of Mechanical Engineering, Tongji University, Shanghai, Chlna; School of Mechanical Engineering, Tongji University, Shanghai, Chlna; School of Automotive Studies, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981248/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11888528152537109928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981765",
        "title": "Localization of Interaction using Fibre-Optic Shape Sensing in Soft-Robotic Surgery Tools",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimally invasive surgery requires real-time tool tracking to guide the surgeon where depth perception and visual occlusion present navigational challenges. Although vision-based and external sensor-based tracking methods exist, fibre-optic sensing can overcome their limitations as they can be integrated directly into the device, are biocompatible, small, robust and geometrically versatile. In this paper, we integrate a fibre Bragg grating-based shape sensor into a soft robotic device. The soft robot is the pneumatically attachable flexible (PAF) rail designed to act as a soft interface between manipulation tools and intra-operative imaging devices. We demonstrate that the shape sensing fibre can detect the location of the tools paired with the PAF rail, by exploiting the change in curvature sensed by the fibre when a strain is applied to it. We then validate this with a series of grasping tasks and continuous US swipes, using the system to detect in real-time the location of the tools interacting with the PAF rail. The overall location-sensing accuracy of the system is 64.6%, with a margin of error between predicted location and actual location of 3.75 mm.",
        "primary_area": "",
        "author": "Sol\u00e8ne Dietsch;Aoife McDonald\u2013Bowyer;Emmanouil Dimitrakakis;Joanna M. Coote;Lukas Lindenroth;Agostino Stilli;Danail Stoyanov;Sol\u00e8ne Dietsch;Aoife McDonald\u2013Bowyer;Emmanouil Dimitrakakis;Joanna M. Coote;Lukas Lindenroth;Agostino Stilli;Danail Stoyanov",
        "authorids": "/37089658146;/37089661115;/37086177519;/37087053402;/37085842056;/37085447649;/37563622300;/37089658146;/37089661115;/37086177519;/37087053402;/37085842056;/37085447649;/37563622300",
        "aff": "Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981765/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6374597086136116226&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Wellcome/EPSRC Centre for Interventional and Surgical Sciences",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981144",
        "title": "Locally Optimal Estimation and Control of Cable Driven Parallel Robots using Time Varying Linear Quadratic Gaussian Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a locally optimal tracking controller for Cable Driven Parallel Robot (CDPR) control based on a time-varying Linear Quadratic Gaussian (TV-LQG) controller. In contrast to many methods which use fixed feedback gains, our time-varying controller computes the optimal gains depending on the location in the workspace and the future trajectory. Meanwhile, we rely heavily on offline computation to reduce the burden of online implementation and feasibility checking. Following the growing popularity of probabilistic graphical models for optimal control, we use factor graphs as a tool to formulate our controller for their efficiency, intuitiveness, and modularity. The topology of a factor graph encodes the relevant structural properties of equations in a way that facilitates insight and efficient computation using sparse linear algebra solvers. We first use factor graph optimization to compute a nominal trajectory, then linearize the graph and apply variable elimination to compute the locally optimal, time varying linear feedback gains. Next, we leverage the factor graph formulation to compute the locally optimal, time-varying Kalman Filter gains, and finally combine the locally optimal linear control and estimation laws to form a TV-LQG controller. We compare the tracking accuracy of our TV-LQG controller to a state-of-the-art dual-space feed-forward controller on a 2.9m x 2.3m, 4-cable planar robot and demonstrate improved tracking accuracies of 0.8\u00b0 and 11.6 mm root mean square error in rotation and translation respectively.",
        "primary_area": "",
        "author": "Gerry Chen;Seth Hutchinson;Frank Dellaert;Gerry Chen;Seth Hutchinson;Frank Dellaert",
        "authorids": "/37089000441;/37282386200;/37282902200;/37089000441;/37282386200;/37282902200",
        "aff": "Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981144/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8550296272237253164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "College of Computing",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982190",
        "title": "Locomotion Policy Guided Traversability Learning using Volumetric Representations of Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the progress in legged robotic locomotion, autonomous navigation in unknown environments remains an open problem. Ideally, the navigation system utilizes the full potential of the robots' locomotion capabilities while operating within safety limits under uncertainty. The robot must sense and analyze the travers ability of the surrounding terrain, which depends on the hardware, locomotion control, and terrain properties. It may contain information about the risk, energy, or time consumption needed to traverse the terrain. To avoid hand-crafted traversability cost functions we propose to collect traversability information about the robot and locomotion policy by simulating the traversal over randomly generated terrains using a physics simulator. Thousand of robots are simulated in parallel controlled by the same locomotion policy used in reality to acquire 57 years of real-world locomotion experience equivalent. For deployment on the real robot, a sparse convolutional network is trained to predict the simulated traversability cost, which is tailored to the deployed locomotion policy, from an entirely geometric representation of the envi-ronment in the form of a 3D voxel-occupancy map. This rep-resentation avoids the need for commonly used elevation maps, which are error-prone in the presence of overhanging obstacles and multi-floor or low-ceiling scenarios. The effectiveness of the proposed travers ability prediction network is demonstrated for path planning for the legged robot ANY mal in various indoor and natural environments.",
        "primary_area": "",
        "author": "Jonas Frey;David Hoeller;Shehryar Khattak;Marco Hutter;Jonas Frey;David Hoeller;Shehryar Khattak;Marco Hutter",
        "authorids": "/37089524961;/37088846413;/37086181358;/37545251000;/37089524961;/37088846413;/37086181358;/37545251000",
        "aff": "Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; NVIDIA; Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982190/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6503362313762837024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Zurich;NVIDIA",
        "aff_unique_dep": "Department of Mechanical and Process Engineering;NVIDIA Corporation",
        "aff_unique_url": "https://www.ethz.ch;https://www.nvidia.com",
        "aff_unique_abbr": "ETH;NVIDIA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9982099",
        "title": "Low-Latency LiDAR Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Several methods of semantic segmentation using light detection and ranging (LiDAR) sensors have been proposed for the recognition of surrounding objects by autonomous driving cars. LiDAR is a sensor that compensates for the weaknesses of other sensors, such as cameras or radar systems, and semantic segmentation assigns a class label to each point in the LiDAR point cloud. Recently, real-time semantic segmentation methods that are capable of processing LiDAR point clouds at frame rates have been proposed. Real-time semantic segmentation is essential for the autonomous driving system because it can output class labels for LiDAR point clouds at high speeds. However, this segmentation method suffers from a delay equal to processing time. To address this challenge, we propose a novel method that combines SalsaNext [1], a method of real-time LiDAR semantic segmentation, and semantic forecasting, which predicts the results of future semantic segmentation. We quantitatively evaluate our method using the Semantic-KITTI dataset, which comprises point cloud data acquired from the LiDAR sensor in the real world, and compare the latency and accuracy of our method with other semantic segmentation methods. Consequently, our method is found to be capable of operating in real-time and with low-latency, and it can achieve a performance similar to that of previously reported real-time semantic segmentation methods.",
        "primary_area": "",
        "author": "Takahiro Hori;Takehisa Yairi;Takahiro Hori;Takehisa Yairi",
        "authorids": "/37089658407;/37270951700;/37089658407;/37270951700",
        "aff": "Department of Aeronautics and Astronautics, Artificial Intelligence Laboratory, University of Tokyo, Tokyo, Japan; Department of Aeronautics and Astronautics, Artificial Intelligence Laboratory, University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982099/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=676292320310945711&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982264",
        "title": "Low-drift LiDAR-only Odometry and Mapping for UGVs in Environments with Non-level Roads",
        "track": "main",
        "status": "Poster",
        "abstract": "This study focuses on localization and mapping for UGVs when they are deployed in environments with non-level roads. In these scenarios, the vehicles need to travel through flat but not necessarily level grounds, i.e., ascent or descent, which may cause drifts of the robot pose and distortion of the map. We develop a low-drift LiDAR odometry and mapping approach for the UGV with LiDAR as the only exteroceptive sensor. A factor-graph based pose optimization method is developed with a specifically designed factor named slope factor. This factor includes the slope information that is estimated from a real-time LiDAR data stream. The slope information is also used to enhance the loop-closure detection procedure. Moreover, an incremental pitch estimation mechanism is designed to achieve further pose estimation refinement. We demonstrate the effectiveness of the developed framework in real-world environments. The odometry drift is lower and the map is more precise than experiments with the state-of-the-arts. Notably, on the Kitti dataset, our method also exhibits convincing performance, demonstrating its strength in more general application scenarios.",
        "primary_area": "",
        "author": "Xiangyu Chen;Yinchuan Wang;Chaoqun Wang;Rui Song;Yibin Li;Xiangyu Chen;Yinchuan Wang;Chaoqun Wang;Rui Song;Yibin Li",
        "authorids": "/37086420664;/37089664173;/37085492449;/37546859100;/37279897500;/37086420664;/37089664173;/37085492449;/37546859100;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, Ji-nan, China; School of Control Science and Engineering, Shandong University, Ji-nan, China; School of Control Science and Engineering, Shandong University, Ji-nan, China; Shandong Research Institute of Industrial Technology, Shandong Uni-versity, Jinan, China; School of Control Science and Engineering, Shandong University, Ji-nan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982264/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5685688391116756182&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Control Science and Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Ji-nan;Jinan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981150",
        "title": "Lumen Shape Reconstruction using a Soft Robotic Balloon Catheter and Electrical Impedance Tomography",
        "track": "main",
        "status": "Poster",
        "abstract": "Incorrectly sized balloon catheters can lead to increased post-surgical complications, yet even with preoperative imaging, correct selection remains a challenge. With limited feedback during surgery, it is difficult to verify correct deployment. We propose the use of integrated impedance measurements and Electrical Impedance Tomography (EIT) imaging to assess the deformation of the balloon and determine the size and shape of the surrounding lumen. Previous work using single impedance measurements, or pressure data and analytical models, whilst demonstrating high sizing accuracy, have assumed a circular cross section. Here we extend these methods by adding a multitude of electrodes to detect elliptical and occluded lumen and obtain EIT images to localise deformations. Using a 14 Fr (5.3 mm) catheter as an example, numerical simulations were performed to find the optimal electrode configuration of two rings of 8 electrodes spaced 10 mm apart. The simulations predicted that the maximum detectable aspect ratio decreased from 0.9 for a 14mm balloon to 0.5 at 30mm. The sizing and ellipticity detection results were verified experimentally. A prototype robotic balloon catheter was constructed to automatically inflate a compliant balloon while simultaneously recording EIT and pressure data. Data were collected in experiments replicating stenotic vessels with an elliptical and asymmetrical profile, and the widening of a lumen during angioplasty. After calibration, the system was able to correctly localise the occlusion and detect aspect ratios of 0.75. EIT images further localised the occlusion and visualised the dilation of the lumen during balloon inflation.",
        "primary_area": "",
        "author": "James Avery;Mark Runciman;Cristina Fiani;Elena Monfort Sanchez;Saina Akhond;Zhuang Liu;Kirill Aristovich;George Mylonas;James Avery;Mark Runciman;Cristina Fiani;Elena Monfort Sanchez;Saina Akhond;Zhuang Liu;Kirill Aristovich;George Mylonas",
        "authorids": "/38220704400;/37086937762;/37089660774;/37089664041;/37086871295;/37089658475;/38188644600;/37586568800;/38220704400;/37086937762;/37089660774;/37089664041;/37086871295;/37089658475;/38188644600;/37586568800",
        "aff": "Hamlyn Centre, Imperial College London, London, U.K; Hamlyn Centre, Imperial College London, London, U.K; Dept. of Medical Physics and Biomedical Engineering, University College London, London, U.K; Hamlyn Centre, Imperial College London, London, U.K; Hamlyn Centre, Imperial College London, London, U.K; Dept. of Bioengineering, Imperial College London, London; Dept. of Medical Physics and Biomedical Engineering, University College London, London, U.K; Hamlyn Centre, Imperial College London, London, U.K",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981150/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7999990240345696309&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;0;1;0",
        "aff_unique_norm": "Imperial College London;University College London",
        "aff_unique_dep": "Hamlyn Centre;Dept. of Medical Physics and Biomedical Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Imperial College;UCL",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981981",
        "title": "MAPFASTER: A Faster and Simpler take on Multi-Agent Path Finding Algorithm Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Portfolio-based algorithm selection can help in choosing the best suited algorithm for a given task while leveraging the complementary strengths of the candidates. Solving the Multi-Agent Path Finding (MAPF) problem optimally has been proven to be NP-Hard. Furthermore, no single optimal algorithm has been shown to have the fastest runtime for all MAPF problem instances, and there are no proven approaches for when to use each algorithm. To address these challenges, we develop MAPFASTER, a smaller and more accurate deep learning based architecture aiming to be deployed in fleet management systems to select the fastest MAPF solver in a multi-robot setting. MAPF problem instances are encoded as images and passed to the model for classification into one of the portfolio's candidates. We evaluate our model against state-of-the-art Optimal-MAPF-Algorithm selectors, showing +5.42% improvement in accuracy while being 7.1\u00d7 faster to train. The dataset, code and analysis used in this research can be found at https://github.com/jeanmarcalkazzi/mapfaster.",
        "primary_area": "",
        "author": "Jean-Marc Alkazzi;Anthony Rizk;Michel Salomon;Abdallah Makhoul;Jean-Marc Alkazzi;Anthony Rizk;Michel Salomon;Abdallah Makhoul",
        "authorids": "/37089662811;/37089661217;/37425242500;/37300200900;/37089662811;/37089661217;/37425242500;/37300200900",
        "aff": "FEMTO-ST Institute, UMR 6174 CNRS, Univ. Bourgogne Franche-Comt\u00e9, Belfort, France; Faculty of Engineering, Saint Joseph University of Beirut, Beirut, Lebanon; FEMTO-ST Institute, UMR 6174 CNRS, Univ. Bourgogne Franche-Comt\u00e9, Belfort, France; FEMTO-ST Institute, UMR 6174 CNRS, Univ. Bourgogne Franche-Comt\u00e9, Belfort, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981981/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10266894981628563244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "FEMTO-ST Institute;Saint Joseph University of Beirut",
        "aff_unique_dep": "UMR 6174 CNRS;Faculty of Engineering",
        "aff_unique_url": ";https://www.sju.edu.lb",
        "aff_unique_abbr": ";SJU Beirut",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beirut",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;Lebanon"
    },
    {
        "id": "9981147",
        "title": "MD-SLAM: Multi-cue Direct SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) systems are fundamental building blocks for any autonomous robot navigating in unknown environments. The SLAM implementation heavily depends on the sensor modality employed on the mobile platform. For this reason, assumptions on the scene's structure are often made to maximize estimation accuracy. This paper presents a novel direct 3D SLAM pipeline that works independently for RGB-D and LiDAR sensors. Building upon prior work on multi-cue photometric frame-to-frame alignment [4], our proposed approach provides an easy-to-extend and generic SLAM system. Our pipeline requires only minor adaptations within the projection model to handle different sensor modalities. We couple a position tracking system with an appearance-based relocalization mechanism that handles large loop closures. Loop closures are validated by the same direct registration algorithm used for odometry estimation. We present comparative experiments with state-of-the-art approaches on publicly available benchmarks using RGB-D cameras and 3D LiDARs. Our system performs well in heterogeneous datasets compared to other sensor-specific methods while making no assumptions about the environment. Finally, we release an open-source C++ implementation of our system.",
        "primary_area": "",
        "author": "Luca Di Giammarino;Leonardo Brizi;Tiziano Guadagnino;Cyrill Stachniss;Giorgio Grisetti;Luca Di Giammarino;Leonardo Brizi;Tiziano Guadagnino;Cyrill Stachniss;Giorgio Grisetti",
        "authorids": "/37089196483;/37089660806;/37087324270;/37329668600;/37324134600;/37089196483;/37089660806;/37087324270;/37329668600;/37324134600",
        "aff": "Department of Computer, Control, and Management Engineering \u201cAntonio Ruberti\u201d, Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering \u201cAntonio Ruberti\u201d, Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering \u201cAntonio Ruberti\u201d, Sapienza University of Rome, Italy; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Department of Computer, Control, and Management Engineering \u201cAntonio Ruberti\u201d, Sapienza University of Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981147/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7895026633270030736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Sapienza University of Rome;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": "Department of Computer, Control, and Management Engineering \"Antonio Ruberti\";",
        "aff_unique_url": "https://www.uniroma1.it;",
        "aff_unique_abbr": "Sapienza;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9981108",
        "title": "MIMOSA: A Multi-Modal SLAM Framework for Resilient Autonomy against Sensor Degradation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework for Multi-Modal SLAM (MIMOSA) that utilizes a nonlinear factor graph as the underlying representation to provide loosely-coupled fusion of any number of sensing modalities. Tailored to the goal of enabling resilient robotic autonomy in GPS-denied and perceptually-degraded environments, MIMOSA currently contains modules for pointcloud registration, fusion of multiple odometry estimates relying on visible-light and thermal vision, as well as inertial measurement propagation. A flexible back-end utilizes the estimates from various modalities as relative transformation factors. The method is designed to be robust to degeneracy through the maintenance and tracking of modality-specific health metrics, while also being inherently tolerant to sensor failure. We detail this framework alongside our implementation for handling high-rate asynchronous sensor measurements and evaluate its performance on data from autonomous subterranean robotic exploration missions using legged and aerial robots.",
        "primary_area": "",
        "author": "Nikhil Khedekar;Mihir Kulkarni;Kostas Alexis;Nikhil Khedekar;Mihir Kulkarni;Kostas Alexis",
        "authorids": "/37086935230;/37088998874;/37546514600;/37086935230;/37088998874;/37546514600",
        "aff": "Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981108/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2046974684698528975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology",
        "aff_unique_dep": "Autonomous Robots Lab",
        "aff_unique_url": "https://www.ntnu.edu",
        "aff_unique_abbr": "NTNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Trondheim",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9981775",
        "title": "MMFN: Multi-Modal-Fusion-Net for End-to-End Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspired by the fact that humans use diverse sensory organs to perceive the world, sensors with different modalities are deployed in end-to-end driving to obtain the global context of the 3D scene. In previous works, camera and LiDAR inputs are fused through transformers for better driving performance. These inputs are normally further interpreted as high-level map information to assist navigation tasks. Nevertheless, extracting useful information from the complex map input is challenging, for redundant information may mislead the agent and negatively affect driving performance. We propose a novel approach to efficiently extract features from vectorized High-Definition (HD) maps and utilize them in end-to-end driving tasks. In addition, we design a new expert to enhance the model performance by considering multi-road rules. Experimental results prove that both proposed improvements enable our agent to achieve superior performance compared with other methods.",
        "primary_area": "",
        "author": "Qingwen Zhang;Mingkai Tang;Ruoyu Geng;Feiyi Chen;Ren Xin;Lujia Wang;Qingwen Zhang;Mingkai Tang;Ruoyu Geng;Feiyi Chen;Ren Xin;Lujia Wang",
        "authorids": "/37089449650;/37089663065;/37089001275;/37089582115;/37089537784;/37406752700;/37089449650;/37089663065;/37089001275;/37089582115;/37089537784;/37406752700",
        "aff": "Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981775/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13684346527557595176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981837",
        "title": "MO-Transformer: A Transformer-Based Multi-Object Point Cloud Reconstruction Network",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new network for reconstructing multi-object point cloud. Different from previous networks which reconstruct multi-object point cloud as a whole, our network iteratively reconstructs each individual object point cloud from a frame of multi-object point cloud. To achieve this goal, we have designed MO-Transformer, a transformer-based autoregressive network. During training, MO-Transformer takes a frame of multi-object point cloud and individual object point clouds as input. During testing, MO-Transformer iteratively reconstructs individual object point clouds only based on the input multi-object point cloud. To train the proposed MO-Transformer, we design a new loss function called separate Chamfer distance (SCD). In addition, we prove that SCD is an upper bound of the traditional Chamfer distance calculated based on the entire multi-object point cloud. The reconstruction experiment verifies the efficacy of our network in multi-object point cloud reconstruction. Furthermore, the reconstruction experiment also investigates the effect of different dimensions using a series of datasets. The ablation study experiment verifies the necessity of SCD in training MO-Transformer.",
        "primary_area": "",
        "author": "Erli Lyu;Zhengyan Zhang;Wei Liu;Jiaole Wang;Shuang Song;Max Q.-H. Meng;Erli Lyu;Zhengyan Zhang;Wei Liu;Jiaole Wang;Shuang Song;Max Q.-H. Meng",
        "authorids": "/37085567102;/37089016419;/37085479461;/37085418780;/37400326000;/37274117000;/37085567102;/37089016419;/37085479461;/37085418780;/37400326000;/37274117000",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology in Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Shenzhen Research Institute of The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981837/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8781309163399838615&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Harbin Institute of Technology;Southern University of Science and Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Mechanical and Energy Engineering;Shenzhen Research Institute",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.sustech.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HIT;SUSTech;CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982280",
        "title": "MOTSLAM: MOT-assisted monocular dynamic SLAM using single-view depth estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual SLAM systems targeting static scenes have been developed with satisfactory accuracy and robustness. Dynamic 3D object tracking has then become a significant capability in visual SLAM with the requirement of under-standing dynamic surroundings in various scenarios including autonomous driving, augmented and virtual reality. However, performing dynamic SLAM solely with monocular images remains a challenging problem due to the difficulty of asso-ciating dynamic features and estimating their positions. In this paper, we present MOTSLAM, a dynamic visual SLAM system with the monocular configuration that tracks both poses and bounding boxes of dynamic objects. MOTSLAM first performs multiple object tracking (MOT) with associated both 2D and 3D bounding box detection to create initial 3D objects. Then, neural-network-based monocular depth estimation is applied to fetch the depth of dynamic features. Finally, camera poses, object poses, and both static, as well as dynamic map points, are jointly optimized using a novel bundle adjustment. Our experiments on the KITTI dataset demonstrate that our system has reached best performance on both camera ego-motion and object tracking on monocular dynamic SLAM.",
        "primary_area": "",
        "author": "Hanwei Zhang;Hideaki Uchiyama;Shintaro Ono;Hiroshi Kawasaki;Hanwei Zhang;Hideaki Uchiyama;Shintaro Ono;Hiroshi Kawasaki",
        "authorids": "/37089660786;/37596097700;/37553702500;/37270111600;/37089660786;/37596097700;/37553702500;/37270111600",
        "aff": "Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Science and Technology, Nara Institute of Science and Technology, Nara, Japan; Institute of Industrial Science, The University of Tokyo, Tokyo, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982280/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9186333360041708205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Kyushu University;Nara Institute of Science and Technology;University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Electrical Engineering;Graduate School of Science and Technology;Institute of Industrial Science",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.nist.go.jp;https://www.iis.u-tokyo.ac.jp",
        "aff_unique_abbr": "Kyushu U;NIST;UTokyo",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Fukuoka;Nara;Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981046",
        "title": "MPC-PF: Social Interaction Aware Trajectory Prediction of Dynamic Objects for Autonomous Driving Using Potential Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting object motion behaviour is a challenging but crucial task for safe decision making and path planning for an autonomous vehicle. It is challenging in large part due to the uncertain, multi-modal, and practically intractable set of possible agent-agent and agent-space interactions, especially in urban driving settings. Models solely based on constant velocity or social force have an inherent bias and may lead to inaccurate predictions across the prediction horizon whereas purely data driven approaches suffer from a lack of a holistic set of rules governing predictions. We tackle this problem by introducing MPC-PF: a novel potential field-based trajectory predictor that incorporates social interaction and is able to tradeoff between inherent model biases across the prediction horizon. Through evaluation on a variety of common urban driving scenarios, we show that our model is capable of producing accurate predictions for both short and long term timesteps. We also demonstrate the significance of our model architecture through an ablation study.",
        "primary_area": "",
        "author": "Neel P. Bhatt;Amir Khajepour;Ehsan Hashemi;Neel P. Bhatt;Amir Khajepour;Ehsan Hashemi",
        "authorids": "/37088596549;/37442322000;/37085826232;/37088596549;/37442322000;/37085826232",
        "aff": "Mechanical and Mechatronics Eng. Department, University of Waterloo, Waterloo, ON, Canada; Mechanical and Mechatronics Eng. Department, University of Waterloo, Waterloo, ON, Canada; Mechanical Eng. Department, University of Alberta, Edmonton, AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981046/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13438759031821397919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Waterloo;University of Alberta",
        "aff_unique_dep": "Mechanical and Mechatronics Engineering Department;Mechanical Engineering Department",
        "aff_unique_url": "https://uwaterloo.ca;https://www.ualberta.ca",
        "aff_unique_abbr": "UW;UAlberta",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Waterloo;Edmonton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982111",
        "title": "MPNP: Multi-Policy Neural Planner for Urban Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Our goal is to train a neural planner that can capture diverse driving behaviors in complex urban scenarios. We observe that even state-of-the-art neural planners are struggling to perform common maneuvers such as lane change, which is rather natural for human drivers. We propose to explore the multi-modalities in the planning problem and force the neural planner to explicitly consider different policies. This is achieved by generating the future trajectories conditioned on every possible reference line, which could simply be the centerline of the surrounding lanes. We find this simple strategy yet enables the planner to perform rich and complex behaviors. We train our model using real-world driving data and demonstrate the effectiveness of our method through both open-loop and closed-loop evaluations. Project website https://jchengai.github.io/mpnp.",
        "primary_area": "",
        "author": "Jie Cheng;Ren Xin;Sheng Wang;Ming Liu;Jie Cheng;Ren Xin;Sheng Wang;Ming Liu",
        "authorids": "/37088809524;/37089537784;/37089660181;/37085398677;/37088809524;/37089537784;/37089660181;/37085398677",
        "aff": "The Hong Kong University of Science and Technology, Hong Kong, SAR, China; The Hong Kong University of Science and Technology, Hong Kong, SAR, China; The Hong Kong University of Science and Technology, Hong Kong, SAR, China; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982111/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17928810964609702565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981809",
        "title": "MPT-Net: Mask Point Transformer Network for Large Scale Point Cloud Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud semantic segmentation is important for road scene perception, a task for driverless vehicles to achieve full fledged autonomy. In this work, we introduce Mask Point Transformer Network (MPT-Net), a novel architecture for point cloud segmentation that is simple to implement. MPT-Net consists of a local and global feature encoder and a transformer based decoder; a 3D Point-Voxel Convolution encoder backbone with voxel self attention to encode features and a Mask Point Transformer module to decode point features and segment the point cloud. Firstly, we introduce the novel MPT designed to specifically handle point cloud segmentation. MPT offers two benefits. It attends to every point in the point cloud using mask tokens to extract class specific features globally with cross attention, and provide inter-class feature information exchange using self attention on the learned mask tokens. Secondly, we design a backbone to use sparse point voxel convolutional blocks and a self attention block using transformers to learn local and global contextual features. We evaluate MPT-Net on large scale outdoor driving scene point cloud datasets, SemanticKITTI and nuScenes. Our experiments show that by replacing the standard segmentation head with MPT, MPT-Net achieves a state-of-the-art performance over our baseline approach by 3.8% in SemanticKITTI and is highly effective in detecting 'stuffs' in point cloud.",
        "primary_area": "",
        "author": "Zhe Jun Tang;Tat-Jen Cham;Zhe Jun Tang;Tat-Jen Cham",
        "authorids": "/37089658103;/37271823500;/37089658103;/37271823500",
        "aff": "SenseTime Research and with School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981809/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17899085425243767029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981791",
        "title": "MS-cubic: A Modularized Manufacturing System with scalability, portability and parallelism Modular design suitable for drilling, welding and picking and feasibility verification through drilling experiment",
        "track": "main",
        "status": "Poster",
        "abstract": "The existing manufacturing systems based on processes involving the transportation of workpiece are unsuitable for large products such as air mobility systems. This study proposes a novel ultra-complex manufacturing system called the \u201cModularized-Structure and Multiple-Points Simultaneous Machining System (MS-cubic)\u201d based on the concept of intelligent space, which simultaneously performs multiple types of machining processes without moving a workpiece. The system can simultaneously process multiple points and flexibly change its workspace by modularizing its structure. This paper presents a discussion on the requirements and constraints to generate a feasible design of the rail module and the machining unit, which are two main elements of MS-cubic. The performance of the prototype MS-cubic is evaluated, and its stiffness is observed to be sufficient to perform drilling. Furthermore, the modularized design of system enables the fluid and electric power supply for the machining process.",
        "primary_area": "",
        "author": "Takehito Yoshida;Amane Toriyama;Shin'ichi Warisawa;Rui Fukui;Takehito Yoshida;Amane Toriyama;Shin'ichi Warisawa;Rui Fukui",
        "authorids": "/37089195149;/37089662783;/37279811100;/37328184200;/37089195149;/37089662783;/37279811100;/37328184200",
        "aff": "Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981791/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Human and Engineered Environmental Studies",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981504",
        "title": "MT*: Multi-Robot Path Planning for Temporal Logic Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the path planning problem for a team of robots satisfying a complex high-level mission specification given in the form of a Linear Temporal Logic (LTL) formula. The state-of-the-art approach to this problem employs the automata-theoretic model checking technique to solve this problem. This approach involves computation of a product graph of the B\u00fcchi automaton generated from the LTL specification and a joint transition system that captures the collective motion of the robots and then computation of the shortest path using Di-jkstra's shortest path algorithm. We propose MT*, an algorithm that reduces the computation burden for generating such plans for multi-robot systems significantly. Our approach generates a reduced version of the product graph without computing the complete joint transition system, which is computationally expensive. It then divides the complete mission specification among the participating robots and generates the trajectories for the individual robots independently. Our approach demonstrates substantial speedup in terms of computation time over the state-of-the-art approach and scales well with both the number of robots and the size of the workspace.",
        "primary_area": "",
        "author": "Dhaval Gujarathi;Indranil Saha;Dhaval Gujarathi;Indranil Saha",
        "authorids": "/37088505001;/37542496500;/37088505001;/37542496500",
        "aff": "SAP Labs, India; Department of Computer Science and Engineering, IIT, Kanpur, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981504/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15022441063047050603&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "SAP Labs;Indian Institute of Technology Kanpur",
        "aff_unique_dep": ";Department of Computer Science and Engineering",
        "aff_unique_url": "https://labs.sap/;https://www.iitk.ac.in",
        "aff_unique_abbr": "SAP Labs;IIT Kanpur",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9982268",
        "title": "MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating 6D poses of objects is an essential computer vision task. However, most conventional approaches rely on camera data from a single perspective and therefore suffer from occlusions. We overcome this issue with our novel multi-view 6D pose estimation method called MV6D which accurately predicts the 6D poses of all objects in a cluttered scene based on RGB-D images from multiple perspectives. We base our approach on the PVN3D network that uses a single RGB-D image to predict keypoints of the target objects. We extend this approach by using a combined point cloud from multiple views and fusing the images from each view with a DenseFusion layer. In contrast to current multi-view pose detection networks such as CosyPose, our MV6D can learn the fusion of multiple perspectives in an end-to-end manner and does not require multiple prediction stages or subsequent fine tuning of the prediction. Furthermore, we present three novel photorealistic datasets of cluttered scenes with heavy occlusions. All of them contain RGB-D images from multiple perspectives and the ground truth for instance semantic segmentation and 6D pose estimation. MV 6D significantly outperforms the state-of-the-art in multi-view 6D pose estimation even in cases where the camera poses are known inaccurately. Furthermore, we show that our approach is robust towards dynamic camera setups and that its accuracy increases incrementally with an increasing number of perspectives.",
        "primary_area": "",
        "author": "Fabian Duffhauss;Tobias Demmler;Gerhard Neumann;Fabian Duffhauss;Tobias Demmler;Gerhard Neumann",
        "authorids": "/37088687289;/37089661154;/38542033100;/37088687289;/37089661154;/38542033100",
        "aff": "University of T\u00fcbingen, Germany; Robert Bosch GmbH, Stuttgart, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982268/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8793913340219958691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of T\u00fcbingen;Robert Bosch GmbH;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.bosch.com;https://www.kit.edu",
        "aff_unique_abbr": "Uni T\u00fcbingen;Bosch;KIT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stuttgart;Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981433",
        "title": "Magnetic Field Modeling of Linear Halbach Array for Wallclimbing Robot Based on Radial Basis Function Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Aiming at the problem that it is difficult to calculate the force of permanent magnets in the magnetic field, this paper proposes a nonlinear mechanical model of linear array magnetic field based on radial basis function neural network (RBFNN). Combined with the linear Halbach array adsorption module of the wall-climbing robot, the three-dimensional geometric magnetic fields of four typical linear array permanent magnets were constructed, and the theoretical models of the interaction between the magnetic fields were given respectively. Further, the finite element simulation calculation of the magnetic force was carried out using COMSOL Multiphysics. According to the parametric scanning results of the orthogonal test, a nonlinear intelligent prediction model of the force between magnetic fields with local loss sensitivity is established by using the RBFNN numerical fitting method. The average deviation of the network test set is 1.19, and the standard deviation is 0.80. The intelligent prediction model has strong generalization performance, faster convergence speed and stronger flexibility, which provides a theoretical basis for the interaction and control of array magnetic fields.",
        "primary_area": "",
        "author": "Xiaofei Liu;Zhengkun Yi;Xinyu Wu;Wanfeng Shang;Xiaofei Liu;Zhengkun Yi;Xinyu Wu;Wanfeng Shang",
        "authorids": "/37089659360;/37088588468;/37293518700;/37887033400;/37089659360;/37088588468;/37293518700;/37887033400",
        "aff": "Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangdong Provincial Key Lab of Robotics and Intelligent System, and also Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangdong Provincial Key Lab of Robotics and Intelligent System, and also Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangdong Provincial Key Lab of Robotics and Intelligent System, and also Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981433/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4210777179268785979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Advanced Technology",
        "aff_unique_dep": "Chinese Academy of Sciences",
        "aff_unique_url": "http://www.siat.cas.cn",
        "aff_unique_abbr": "SIAT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981438",
        "title": "Magnetic microrobot control using an adaptive fuzzy sliding-mode method",
        "track": "main",
        "status": "Poster",
        "abstract": "The magnetic medical microrobots are influenced by diverse factors such as the medium, the geometry of the microrobot, and the imaging procedure. It is worth noting that the size limitations make it difficult or even impossible to obtain reliable physical properties of the system. In this research, to achieve a precise microrobot control using minimum knowledge about the system, an Adaptive Fuzzy Sliding-Mode Control (AFSMC) scheme is designed for the motion control problem of the magnetically actuated microrobots in presence of input saturation constraint. The AFSMC input consists of a fuzzy system designed to approximate an unknown nonlinear dynamical system and a robust term considered for mismatch compensation. According to the designed adaptation laws, the asymptotic stability is proved based on the Lyapunov theorem and Barbalat's lemma. In order to evaluate the effectiveness of the proposed method, a comparative simulation study is conducted.",
        "primary_area": "",
        "author": "Alireza Mousavi;Hesam Khaksar;Awais Ahmed;Hongsoo Choi;Ali Kafash Hoshiar;Alireza Mousavi;Hesam Khaksar;Awais Ahmed;Hongsoo Choi;Ali Kafash Hoshiar",
        "authorids": "/37089695678;/37088378089;/37086248310;/38469694000;/37085853066;/37089695678;/37088378089;/37086248310;/38469694000;/37085853066",
        "aff": "Iran University of Science and Technology, Tehran, Iran; School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; Department of Robotics Engineering, DGIST-ETH Microrobot Research Center, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; Department of Robotics Engineering, DGIST-ETH Microrobot Research Center, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981438/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8004774408947823594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "Iran University of Science and Technology;University of Essex;Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": ";School of Computer Science and Electronic Engineering;Department of Robotics Engineering",
        "aff_unique_url": "https://www.iust.ac.ir;https://www.essex.ac.uk;https://www.dgist.ac.kr",
        "aff_unique_abbr": "IUST;Essex;DGIST",
        "aff_campus_unique_index": "0;1;2;2;1",
        "aff_campus_unique": "Tehran;Colchester;Daegu",
        "aff_country_unique_index": "0;1;2;2;1",
        "aff_country_unique": "Iran;United Kingdom;South Korea"
    },
    {
        "id": "9981427",
        "title": "Maintaining Robot Localizability with Bayesian Cram\u00e9r-Rao Lower Bounds",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and real-time position estimates are cru-cial for mobile robots. This work focuses on ranging-based positioning systems, which rely on distance measurements between known points, called anchors, and a tag to localize. The topology of the network formed by the anchors strongly influences the tag's localizability, i.e., its ability to be accurately localized. Here, the tag and some anchors are supposed to be carried by robots, which allows enhancing the positioning accuracy by planning the anchors' motions. We leverage Bayesian Cramer-Rao Lower Bounds (CRLBs) on the estimates' covariance in order to quantify the tag's localizability. This class of CRLBs can capture prior information on the tag's position and take it into account when deploying the anchors. We propose a method to decrease a potential function based on the Bayesian CRLB in order to maintain the localizability of the tag while having some prior knowledge about its position distribution. Then, we present a new experiment highlighting the link between the localizability potential and the precision expected in practice. Finally, two real-time anchor motion planners are demonstrated with ranging measurements in the presence or absence of prior information about the tag's position.",
        "primary_area": "",
        "author": "Justin Cano;Corentin Chauffaut;Eric Chaumette;Ga\u00ebl Pages;Jerome Le Ny;Justin Cano;Corentin Chauffaut;Eric Chaumette;Ga\u00ebl Pages;Jerome Le Ny",
        "authorids": "/37086933423;/37085779721;/37285145900;/37299310100;/37546028800;/37086933423;/37085779721;/37285145900;/37299310100;/37546028800",
        "aff": "DEOS, ISAE-Supaero, France; DISC, ISAE-Supaero, Toulouse, France; DEOS, ISAE-Supaero, France; DEOS, ISAE-Supaero, France; Department of Electrical Engineering, Polytechnique Montreal and with GERAD, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981427/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13814537811705595840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "ISAE-SUPAERO;Polytechnique Montreal",
        "aff_unique_dep": "DEOS;Department of Electrical Engineering",
        "aff_unique_url": "https://www.isae-supaero.fr;https://www.polymtl.ca",
        "aff_unique_abbr": ";Polytechnique",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Toulouse;Montreal",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "9981842",
        "title": "Making Robotics Swarm Flow More Smoothly: A Regular Virtual Tube Model",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a model of a class of regular virtual tubes that can generate safe, feasible, and smooth space for a robotics swarm in an obstacle-dense environment, especially for a drone swarm based on the flocking model. The regular principles are first proposed, and the regular conditions are then formulated based on the principles. A method to obtain a regular virtual tube is also presented based on trajectory planning and regular conditions. The proposed method's effectiveness and robustness are comprehensively demonstrated in a simulation environment with random obstacles.",
        "primary_area": "",
        "author": "Pengda Mao;Quan Quan;Pengda Mao;Quan Quan",
        "authorids": "/37089000416;/37406014700;/37089000416;/37406014700",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981842/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6029282584638782830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9982220",
        "title": "Manipulability-Aware Shared Locomanipulation Motion Generation for Teleoperation of Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "The teleoperation of mobile manipulators may pose significant challenges, demanding complex interfaces and causing a substantial burden to the human operator due to the need to switch continuously from the manipulation of the arm to the control of the mobile platform. Hence, several works have considered to exploit shared control techniques to overcome this issue and, in general, to facilitate the task execution. This work proposes a manipulability-aware shared locoma-nipulation motion generation method to facilitate the execution of telemanipulation tasks with mobile manipulators. The method uses the manipulability level of the end-effector to control the generation of the mobile base and manipulator motions, facilitating their simultaneous control by the operator while executing telemanipulation tasks. Therefore, the operator can exclusively control the end -effector, while the underlying ar-chitecture generates the mobile platform commands depending on the end-effector manipulability level. The effectiveness of this approach is demonstrated with a number of experiments in which the CENTAURO robot, a hybrid leg-wheel platform with an anthropomorphic upper body, is teleoperated to execute a set of telemanipulation tasks.",
        "primary_area": "",
        "author": "Davide Torielli;Luca Muratore;Nikos Tsagarakis;Davide Torielli;Luca Muratore;Nikos Tsagarakis",
        "authorids": "/37089227580;/37086139432;/37295830800;/37089227580;/37086139432;/37295830800",
        "aff": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering (DIBRIS), University of Genova, Genova, Italy; Humanoids and Human Centered Mechatronics (HHCM), Istituto italiano di Tecnologia, Genova, Italy; Humanoids and Human Centered Mechatronics (HHCM), Istituto italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982220/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1181091830758571445&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering (DIBRIS);Humanoids and Human Centered Mechatronics (HHCM)",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981864",
        "title": "Manual Maneuverability: Metrics for Analysing and Benchmarking Kinesthetic Robot Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinesthetic teaching of collaborative robots is applied for intuitive and flexible robot programming by demonstration. This enables non-experts to program such robots on the task-level. Multiple strategies exist to teach velocity- or torque-controlled robots and, thus, the maneuverability among commercial robots differs significantly. However, currently there exists no metric that quantifies how \u201cwell\u201d the robot can be guided, e.g., how much effort is required to initiate a motion. In this paper, we propose standardized procedures to quantitatively assess robot manual maneuverability. First, we identify different motion phases during kinesthetic teaching. For each phase, we then propose metrics and experimental setups to evaluate them. The experimental protocols are applied to the proprietary teaching schemes of five commercial robots, namely the KUKA LWR iiwa 14, Yuanda Yu+, Franka Emika robot, and Universal Robot's UR5e and UR10e. The experimental comparison highlights distinct differences between the robots and shows that the proposed methods are a meaningful contribution to the performance and ergonomics assessment of collaborative robots.",
        "primary_area": "",
        "author": "Robin Jeanne Kirschner;Florian Martineau;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin;Robin Jeanne Kirschner;Florian Martineau;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37088861072;/37089660846;/38541896600;/37086148547;/37542865300;/37088861072;/37089660846;/38541896600;/37086148547;/37542865300",
        "aff": "Centre for Tactile Internet with Human-in-the-Loop (CeTI), Institute for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Institute for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Institute for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Institute for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Institute for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981864/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7037957238322986869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Institute for Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981548",
        "title": "Mapping of Spatiotemporal Scalar Fields by Mobile Robots using Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatiotemporal maps are data-driven estimates of time changing phenomena. For environmental science, rather than collect data from an array of static sensors, a mobile sensor platform could reduce setup time and cost, maintain flexibility to be deployed to any area of interest, and provide active feedback during observations. While promising, mapping is challenging with mobile sensors because vehicle constraints limit not only where, but also when observations can be made. By assuming spatial and temporal correlations in the data through kernel functions, this paper uses Gaussian process regression (GPR) to generate a maximum likelihood estimate of the phenomenon while also tracking the estimate uncertainty. Spatiotemporal mapping by GPR is simulated for a single fixed-path mobile robot observing a latent spatiotemporal scalar field. The learned spatiotemporal map captures the structure of the latent scalar field with the largest uncertainties in areas the robot never visited.",
        "primary_area": "",
        "author": "Thomas M. C. Sears;Joshua A. Marshall;Thomas M. C. Sears;Joshua A. Marshall",
        "authorids": "/37089658597;/37269656200;/37089658597;/37269656200",
        "aff": "Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University at Kingston, Ontario, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University at Kingston, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981548/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13884398118068300731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen's University at Kingston",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981966",
        "title": "Markerless Suture Needle 6D Pose Tracking with Robust Uncertainty Estimation for Autonomous Minimally Invasive Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Suture needle localization is necessary for autonomous suturing. Previous approaches in autonomous suturing often relied on fiducial markers rather than markerless detection schemes for localizing a suture needle due to the in-consistency of markerless detections. However, fiducial markers are not practical for real-world applications and can often be occluded from environmental factors in surgery (e.g., blood). Therefore in this work, we present a robust tracking approach for estimating the 6D pose of a suture needle when using inconsistent detections. We define observation models based on suture needles' geometry that captures the uncertainty of the detections and fuse them temporally in a probabilistic fashion. In our experiments, we compare different permutations of the observation models in the suture needle localization task to show their effectiveness. Our proposed method outperforms previous approaches in localizing a suture needle. We also demonstrate the proposed tracking method in an autonomous suture needle regrasping task and ex vivo environments**The code is available at https://github.com/ucsdarclab/suture-needle-tracking..",
        "primary_area": "",
        "author": "Zih-Yun Chiu;Albert Z Liao;Florian Richter;Bjorn Johnson;Michael C. Yip;Zih-Yun Chiu;Albert Z Liao;Florian Richter;Bjorn Johnson;Michael C. Yip",
        "authorids": "/37086357053;/37089659623;/37086936752;/37089662038;/37085382768;/37086357053;/37089659623;/37086936752;/37089662038;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981966/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6433989598082838151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982130",
        "title": "MasKGrasp: Mask-based Grasping for Scenes with Multiple General Real-world Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a mask-based grasping method that discerns multiple objects within the scene regard-less of transparency or specularity and finds the optimal grasp position avoiding clutter. Conventional vision-based robotic grasping approaches often fail to extend to the scenes containing transparent objects due to their different visual appearance. To handle the different visual characteristics, we first segment both transparent and opaque objects into instance masks, which serve as the domain-agnostic intermediate representation of both object types, using a neural network. While there exists no labelled training dataset that strongly represents both object types, we overcome the limitation by augmenting transparent objects on an existing large-scale dataset. Then, given the object instance masks, our method selects the top K discrete masks and robustly estimates grasp poses avoiding clutter. Through experiments, we verify that the instance masks are light-weight yet provide sufficient information for vision-based grasping agnostic of various appearances. On an unseen real-world test environment with complex objects, our method substantially outperforms previous methods without fine-tuning.",
        "primary_area": "",
        "author": "Junho Lee;Junhwa Hur;Inwoo Hwang;Young Min Kim;Junho Lee;Junhwa Hur;Inwoo Hwang;Young Min Kim",
        "authorids": "/37089659171;/37086307423;/37089495519;/37089715090;/37089659171;/37086307423;/37089495519;/37089715090",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Computer Science, TU Darmstadt, Germany; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982130/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7484213576695224985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Seoul National University;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "SNU;TU Darmstadt",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "South Korea;Germany"
    },
    {
        "id": "9981272",
        "title": "Mechanically Programmable Jamming Based on Articulated Mesh Structures for Variable Stiffness Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are capable of effortlessly adapting to their environment using elastic materials that impart structural compliance into their designs, allowing them to execute complex tasks with minimal sensing and control. However, soft robots cannot exert high forces and can only handle low deformation forces. These characteristics typically limit their applicabil-ity to tasks that require delicate interactions. In this work, we present a mechanically programmable, variable stiffness, jamming actuator based on an articulated mesh structure. The proposed actuator can elastically bend when it is not activated but compresses to attain a pre-programmed shape that is determined by the mesh geometry of the multi-layer jamming architecture when pressure is applied to the silicone pouch containing it. Unlike traditional jamming structures the utilisation of the articulated mesh structure facilitates elastic deformations past the yield point when jammed. The actuator can become >27 times stiffer than its relaxed configuration when exposed to only 90 kPa pressure. We demonstrate the efficiency of this actuator by developing variable stiffness joints that can be used to create: i) underactuated, tendon driven robotic grippers and soft, disposable robotic grippers that exhibit increased dexterity and ii) wearable, affordable, lightweight elbow exoskeleton systems that can assist humans in holding heavy objects with minimal effort.",
        "primary_area": "",
        "author": "Geng Gao;Junbang Liang;Minas Liarokapis;Geng Gao;Junbang Liang;Minas Liarokapis",
        "authorids": "/37087027460;/37089661353;/38558084100;/37087027460;/37089661353;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981272/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=276919567349745326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9981544",
        "title": "Meeting-Merging-Mission: A Multi-robot Coordinate Framework for Large-Scale Communication-Limited Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This letter presents a complete framework Meeting-Merging-Mission for multi-robot exploration under communication restriction. Considering communication is limited in both bandwidth and range in the real world, we propose a lightweight environment presentation method and an efficient cooperative exploration strategy. For lower bandwidth, each robot uses specific polytopes to maintain free space and to generate Super Frontier Information (SFI), which serves as the source for exploration decision-making. To reduce repeated exploration, we develop a mission-based protocol that drives robots to share collected information in stable rendezvous. We also design a complete path planning scheme for both centralized and decentralized cases. To validate that our framework is practical and generic, we present an extensive benchmark and deploy our system into multi-UGV and multi-UAV platforms.",
        "primary_area": "",
        "author": "Yuman Gao;Yingjian Wang;Xingguang Zhong;Tiankai Yang;Mingyang Wang;Zhixiong Xu;Yongchao Wang;Yi Lin;Chao Xu;Fei Gao;Yuman Gao;Yingjian Wang;Xingguang Zhong;Tiankai Yang;Mingyang Wang;Zhixiong Xu;Yongchao Wang;Yi Lin;Chao Xu;Fei Gao",
        "authorids": "/37089194623;/37089002292;/37089001168;/37089001320;/37089661315;/37089659900;/37089664138;/37086281245;/37404060100;/37086045143;/37089194623;/37089002292;/37089001168;/37089001320;/37089661315;/37089659900;/37089664138;/37086281245;/37404060100;/37086045143",
        "aff": "State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; Dji Co., Shenzhen, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Huzhou Institute of Zhejiang University, HuZhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981544/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8267413233547588959&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;DJI",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.dji.com",
        "aff_unique_abbr": "ZJU;DJI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Huzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981090",
        "title": "Memory-Augmented Reinforcement Learning for Image-Goal Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a memory-augmented approach for image-goal navigation. Earlier attempts, including RL-based and SLAM-based approaches have either shown poor generalization performance, or are heavily-reliant on pose/depth sensors. Our method is based on an attention-based end-to-end model that leverages an episodic memory to learn to navigate. First, we train a state-embedding network in a self-supervised fashion, and then use it to embed previously-visited states into the agent's memory. Our navigation policy takes advantage of this information through an attention mechanism. We validate our approach with extensive evaluations, and show that our model establishes a new state of the art on the challenging Gibson dataset. Furthermore, we achieve this impressive performance from RGB input alone, without access to additional information such as position or depth, in stark contrast to related work.",
        "primary_area": "",
        "author": "Lina Mezghan;Sainbayar Sukhbaatar;Thibaut Lavril;Oleksandr Maksymets;Dhruv Batra;Piotr Bojanowski;Karteek Alahari;Lina Mezghan;Sainbayar Sukhbaatar;Thibaut Lavril;Oleksandr Maksymets;Dhruv Batra;Piotr Bojanowski;Karteek Alahari",
        "authorids": "/37089662525;/37089659446;/37086862033;/37087233894;/37294512800;/37085750532;/37547153100;/37089662525;/37089659446;/37086862033;/37087233894;/37294512800;/37085750532;/37547153100",
        "aff": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France; Meta AI; Meta AI; Meta AI; Georgia Institute of Technology, Georgia; Meta AI; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981090/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10162337328714546760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;2;1;0",
        "aff_unique_norm": "Universite Grenoble Alpes;Meta;Georgia Institute of Technology",
        "aff_unique_dep": ";Meta AI;",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://meta.com;https://www.gatech.edu",
        "aff_unique_abbr": "UGA;Meta;Georgia Tech",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Grenoble;;Georgia",
        "aff_country_unique_index": "0;1;1;1;1;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "9981129",
        "title": "Metabolic Efficiency Improvement of Human Walking by Shoulder Stress Reduction through Load Transfer Backpack",
        "track": "main",
        "status": "Poster",
        "abstract": "The dynamic load attached to the load gravity imposes an excessive burden to human shoulders during load carriage, resulting in possible muscle injuries and additional physical exertion. This paper proposes an active suspension backpack, capable of transferring partial load from human shoulders to pelvis and alleviating the dynamic load through separated panels and motor actuation, to reduce pressure on human shoulders and improve walking metabolic efficiency. Based on the human body motion in the vertical direction, the dynamical model of the human-backpack system with shoulder interaction force measured by a soft ballonet with an embedded air pressure sensor is introduced, and an impedance controller has been implemented to maintain a relatively small and constant pressure on the shoulder. In an experimental case study, we presents preliminary results of three healthy subjects performing a treadmill walking with a 20kg load in ACTIVE configuration where the shoulder pressure shows a decrease by 30% along with a reduction of the metabolic energy consumption by 16.4%, compared with the load LOCKED case.",
        "primary_area": "",
        "author": "Yu Cao;Jian Huang;Xiaolong Li;Mengshi Zhang;Caihua Xiong;Samer Mohammed;Yaonan Zhu;Yasuhisa Hasegawa;Yu Cao;Jian Huang;Xiaolong Li;Mengshi Zhang;Caihua Xiong;Samer Mohammed;Yaonan Zhu;Yasuhisa Hasegawa",
        "authorids": "/37086598364;/37367799000;/37088964295;/37086602285;/38252051800;/38580067500;/37086591677;/37272575600;/37086598364;/37367799000;/37088964295;/37086602285;/38252051800;/38580067500;/37086591677;/37272575600",
        "aff": "Key Laboratory for Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory for Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory for Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory for Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Laboratory of Image, Signal and Intelligent Systems (LISSI), University Paris Est Crteil (UPEC), Vitry Sur Seine, France; Department of Micro-nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Micro-nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981129/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=991674271709864913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;2",
        "aff_unique_norm": "Huazhong University of Science and Technology;University Paris Est Crteil;Nagoya University",
        "aff_unique_dep": "School of Artificial Intelligence and Automation;Laboratory of Image, Signal and Intelligent Systems (LISSI);Department of Micro-nano Mechanical Science and Engineering",
        "aff_unique_url": "http://www.hust.edu.cn;https://www.u-pec.fr;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "HUST;UPEC;Nagoya U",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;2",
        "aff_campus_unique": "Wuhan;Vitry Sur Seine;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;1;2;2",
        "aff_country_unique": "China;France;Japan"
    },
    {
        "id": "9981672",
        "title": "Metal Wire Manipulation Planning for 3D Curving - A Low Payload Robot that Uses a Bending Machine to Bend High-Stiffness Wire",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a combined task and motion planner for a robot arm to carry out 3D metal wire curving tasks by collaborating with a bending machine. We assume a collaborative robot that is safe to work in a human environment but has a weak payload to bend objects with large stiffness, and developed a combined planner for the robot to use a bending machine. Our method converts a 3D curve to a bending set and generates the feasible bending sequence, machine usage, robotic grasp poses, and pick-and-place arm motion considering the combined task and motion level constraints. Compared with previous deformable linear object shaping work that relied on forces provided by robotic arms, the proposed method is suitable for the material with high stiffness. We evaluate the system using different tasks. The results show that the proposed system is flexible and robust to generate robotic motion to corporate with the designed bending machine.",
        "primary_area": "",
        "author": "Ruishuang Liu;Weiwei Wan;Emiko Isomura;Kensuke Harada;Ruishuang Liu;Weiwei Wan;Emiko Isomura;Kensuke Harada",
        "authorids": "/37089418901;/37085689483;/37089662890;/37277067400;/37089418901;/37085689483;/37089662890;/37277067400",
        "aff": "Department of System Innovation, Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Department of System Innovation, Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; First Department of Oral and Maxillofacial Surgery, Graduate School of Dentistry, Osaka University, Japan; National Inst. of AIST, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981672/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13077233975389429849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of System Innovation;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toyonaka;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981634",
        "title": "Microspine Design for Additive Manufacturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Microspine grippers allow robots to ascend steep rocky slopes and cliff faces, enabling scientific exploration of exposed strata on Earth and other solar system bodies. Historically, the Shape Deposition Manufacturing (SDM) process has been used to fabricate multi-material suspensions for load-sharing among multiple microspines. We instead apply the Hybrid Deposition Manufacturing (HDM) process to microspine fabrication, and we further propose a novel 3D-printed microspine suspension design that can be manufactured via Fused Deposition Manufacturing (FDM) alone, using a single flexible material with an embedded fishhook. We use a model of microspine stiffness that allows designers to compensate for order-of-magnitude changes in material tensile modulus by adjusting geometric parameters of the design. The stiffness model and the FDM microspine design are validated through tensile testing, and mechanical properties of the HDM and FDM designs are compared against a standard SDM microspine design. We demonstrate that the FDM process can produce microspines with equivalent normal and axial stiffness and superior maximum load and fatigue response to SDM microspines, and discuss additional advantages of the FDM process for rapid prototyping and broader accessibility.",
        "primary_area": "",
        "author": "Paul Nadan;Dinesh K. Patel;Catherine Pavlov;Spencer Backus;Aaron M. Johnson;Paul Nadan;Dinesh K. Patel;Catherine Pavlov;Spencer Backus;Aaron M. Johnson",
        "authorids": "/37087323168;/37087324115;/37086935740;/38252603100;/37589025300;/37087323168;/37087324115;/37086935740;/38252603100;/37589025300",
        "aff": "Robotics Institute; Human-Computer Interaction Institute; Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Jet Propulsion Laboratory, California Institute of Technology; Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981634/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12974165102545890313&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Robotics Institute;Carnegie Mellon University;California Institute of Technology",
        "aff_unique_dep": ";Human-Computer Interaction Institute;Jet Propulsion Laboratory",
        "aff_unique_url": ";https://www.hcii.cmu.edu;https://www.caltech.edu",
        "aff_unique_abbr": ";HCII;Caltech",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Pittsburgh;Pasadena",
        "aff_country_unique_index": "1;1;1;1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9981885",
        "title": "Minor Change, Major Gains II: Are Maximal Coordinates the Fastest Choice for Trajectory Optimization?",
        "track": "main",
        "status": "Poster",
        "abstract": "It has been shown that changing the coordinates describing a multi-body system to use absolute rather than relative angles produces a significant improvement in the tractability of trajectory optimization problems. This simplifies the equations of motion when modelling long kinematic chains. In this paper, we extend this idea by investigating whether a maximal coordinate system, which also describes the translational position of bodies using absolute coordinates, might lead to further performance improvements. We compare it to the relative translation, absolute orientation (RTAO) coordinate scheme using a batch of trajectory optimization trials selected with contact-implicit legged locomotion applications in mind. We find that maximal coordinates tend to shorten solving times for spatial problems, while the RTAO formulation still performs best in the case of planar motion.",
        "primary_area": "",
        "author": "Stacey Shield;Amir Patel;Stacey Shield;Amir Patel",
        "authorids": "/37085618790;/38029333400;/37085618790;/38029333400",
        "aff": "Department of Electrical Engineering, University of Cape Town; Department of Electrical Engineering, University of Cape Town",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981885/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13659900878398784047&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.uct.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9981277",
        "title": "Mobile Manipulation Leveraging Multiple Views",
        "track": "main",
        "status": "Poster",
        "abstract": "While both navigation and manipulation are chal-lenging topics in isolation, many tasks require the ability to both navigate and manipulate in concert. To this end, we propose a mobile manipulation system that leverages novel navigation and shape completion methods to manipulate an object with a mobile robot. Our system utilizes uncertainty in the initial estimation of a manipulation target to calculate a predicted next-best-view. Without the need of localization, the robot then uses the predicted panoramic view at the next-best-view location to navigate to the desired location, capture a second view of the object, create a new model that predicts the shape of object more accurately than a single image alone, and uses this model for grasp planning. We show that the system is highly effective for mobile manipulation tasks through simulation experiments using real world data, as well as ablations on each component of our system.",
        "primary_area": "",
        "author": "David Watkins-Valls;Peter K Allen;Henrique Maia;Madhavan Seshadri;Jonathan Sanabria;Nicholas Waytowich;Jacob Varley;David Watkins-Valls;Peter K Allen;Henrique Maia;Madhavan Seshadri;Jonathan Sanabria;Nicholas Waytowich;Jacob Varley",
        "authorids": "/37086934216;/37280851400;/37089662423;/37086122952;/37089660558;/37586656400;/37085632898;/37086934216;/37280851400;/37089662423;/37086122952;/37089660558;/37586656400;/37085632898",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; U.S. Army Research Laboratory, Baltimore, MD, USA; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981277/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2693553921106565725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Columbia University;U.S. Army Research Laboratory;Google",
        "aff_unique_dep": "Department of Computer Science;;Robotics",
        "aff_unique_url": "https://www.columbia.edu;https://www.arl.army.mil;https://www.google.com",
        "aff_unique_abbr": "Columbia;ARL;Google Robotics",
        "aff_campus_unique_index": "0;0;0;0;0;1;2",
        "aff_campus_unique": "New York;Baltimore;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981911",
        "title": "Model Learning and Predictive Control for Autonomous Obstacle Reduction via Bulldozing",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate how employing model learning methods in concert with model predictive control (MPC) can be used to automate obstacle reduction to mitigate risks to Combat Engineers operating construction equipment in an active battlefield. We focus on the task of earthen berm removal using a bladed vehicle. We introduce a novel data-driven formulation for earthmoving dynamics that enables prediction of the vehicle and detailed terrain state over a one second horizon. In a simulation environment, we first record demonstrations from a human operator and then train two different earthmoving models to produce predictions of the high-dimensional state using under six minutes of data. Optimization over the learned model is performed to select an action sequence, constrained to a 2D space of template action trajectories. Simple recovery controllers are implemented to improve controller performance when the model predictions degrade. This system yields near human-level performance on a berm removal task, indicating that model learning and predictive control is a promising data-efficient approach to autonomous earthmoving.",
        "primary_area": "",
        "author": "W. Jacob Wagner;Katherine Driggs-Campbell;Ahmet Soylemezoglu;W. Jacob Wagner;Katherine Driggs-Campbell;Ahmet Soylemezoglu",
        "authorids": "/37089661049;/37085509519;/37567258300;/37089661049;/37085509519;/37567258300",
        "aff": "Department of Electrical and Computer Engineering, Human Centered Autonomy Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, Human Centered Autonomy Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL, USA; ERDC-CERL, Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981911/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3965692841197563793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;U.S. Army Engineer Research and Development Center - Construction Engineering Research Laboratory",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Construction Engineering Research Laboratory",
        "aff_unique_url": "https://illinois.edu;https://www.erdc.usace.army.mil/CERL/",
        "aff_unique_abbr": "UIUC;ERDC-CERL",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Urbana;Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981637",
        "title": "Model-Based Disturbance Estimation for a Fiber-Reinforced Soft Manipulator using Orientation Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "To aid in real-world situations, soft robots need to be able to estimate their state and external interactions based on proprioceptive sensors. Estimating disturbances allows a soft robot to perform desirable force control. However, even in the case of rigid manipulators, force estimation at the end-effector is seen as a non-trivial problem. And indeed, current approaches to address this challenge have shortcomings that prevent their general application. They are often based on simplified soft dynamic models, such as the ones relying on a piece-wise constant curvature approximation or matched rigid-body models that do not represent enough details of the problem. This severely limits applications in complex human-robot interaction. Finite element method (FEM) based modeling allows for predictions of soft robot dynamics in a more generic fashion. Here, using the soft robot modeling capabilities of the frame-work SOFA, we built a detailed FEM model of a multi-segment soft continuum robotic arm composed of compliant deformable materials and fiber-reinforced pressurized actuation chambers. In addition, a model for sensors that provide orientation output is presented. This model is used to establish a state observer for the manipulator. The sensor model is adequate for representing the output of flexible bend sensors as well as orientations provided by IMUs or coming from tracking systems, all of which are popular choices in soft robotics. Model parameters were calibrated to match imperfections of the manual fabrication process using physical experiments. We then solve a quadratic programming inverse statics problem to compute the components of external force that explain the pose mismatch. Our experiments show an average force estimation error of around 1.2%. As the methods proposed are generic, these results are encouraging for the task of building soft robots exhibiting complex, reactive, sensor-based behavior that can be deployed in human-centered environments. Show More",
        "primary_area": "",
        "author": "Barnabas Gavin Cangan;Stefan Escaida Navarro;Bai Yang;Yu Zhang;Christian Duriez;Robert K. Katzschmann;Barnabas Gavin Cangan;Stefan Escaida Navarro;Bai Yang;Yu Zhang;Christian Duriez;Robert K. Katzschmann",
        "authorids": "/37089662892;/38241804400;/37089663495;/37089664176;/37428704500;/37085423557;/37089662892;/38241804400;/37089663495;/37089664176;/37428704500;/37085423557",
        "aff": "Soft Robotics Lab, ETH Zurich, Switzerland; INRIA, Lille, France; TU Berlin, Germany; Soft Robotics Lab, ETH Zurich, Switzerland; INRIA, Lille, France; Soft Robotics Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981637/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10941025001574715706&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;0",
        "aff_unique_norm": "ETH Zurich;INRIA;Technical University of Berlin",
        "aff_unique_dep": "Soft Robotics Lab;;",
        "aff_unique_url": "https://www.ethz.ch;https://www.inria.fr;https://www.tu-berlin.de",
        "aff_unique_abbr": "ETHZ;INRIA;TU Berlin",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Lille;Berlin",
        "aff_country_unique_index": "0;1;2;0;1;0",
        "aff_country_unique": "Switzerland;France;Germany"
    },
    {
        "id": "9981950",
        "title": "Model-Free Unsupervised Anomaly Detection of a General Robotic System Using a Stacked LSTM and Its Application to a Fixed-Wing Unmanned Aerial Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "With the growing application of various robots in real life, the need for an automatic anomaly detection system for robots is necessary for safety. In this paper, we develop an anomaly detection method using a stacked LSTM that can be applied to any robot controlled by a feedback control. Our method does not need installation of additional sensors. Our method is model-free and unsupervised because it does not require the analytical model of the system and the training data does not require faulty operation conditions. We validate our method on real fixed-wing unmanned aerial vehicle flight data containing control surface failure scenarios. We demonstrate the superiority of the proposed algorithm over existing anomaly detection methods in the literature. Our code is available at https://github.com/superhumangod/Model-free-unsupervised-anomaly-detection.",
        "primary_area": "",
        "author": "Jae-Hyeon Park;Soham Shanbhag;Dong Eui Chang;Jae-Hyeon Park;Soham Shanbhag;Dong Eui Chang",
        "authorids": "/37088567355;/37089193021;/37402057700;/37088567355;/37089193021;/37402057700",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981950/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15657228085497098567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981632",
        "title": "Model-free Neural Lyapunov Control for Safe Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-free Deep Reinforcement Learning (DRL) controllers have demonstrated promising results on various challenging non-linear control tasks. While a model-free DRL algorithm can solve unknown dynamics and high-dimensional problems, it lacks safety assurance. Although safety constraints can be encoded as part of a reward function, there still exists a large gap between an RL controller trained with this modified reward and a safe controller. In contrast, instead of implicitly encoding safety constraints with rewards, we explicitly colearn a Twin Neural Lyapunov Function (TNLF) with the control policy in the DRL training loop and use the learned TNLF to build a runtime monitor. Combined with the path generated from a planner, the monitor chooses appropriate waypoints that guide the learned controller to provide collision-free control trajectories. Our approach inherits the scalability advantages from DRL while enhancing safety guarantees. Our experimental evaluation demonstrates the effectiveness of our approach compared to DRL with augmented rewards and constrained DRL methods over a range of high-dimensional safety-sensitive navigation tasks.",
        "primary_area": "",
        "author": "Zikang Xiong;Joe Eappen;Ahmed H. Qureshi;Suresh Jagannathan;Zikang Xiong;Joe Eappen;Ahmed H. Qureshi;Suresh Jagannathan",
        "authorids": "/37089663417;/37089680691;/37086070898;/37275247800;/37089663417;/37089680691;/37086070898;/37275247800",
        "aff": "Computer Science Department, Purdue University, IN, USA; Computer Science Department, Purdue University, IN, USA; Computer Science Department, Purdue University, IN, USA; Computer Science Department, Purdue University, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981632/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10923371417137755174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Indiana",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982055",
        "title": "Model-free and Uncalibrated Visual-feedback Control of Magnetically-Actuated Flexible Endoscopes",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetically-actuated flexible endoscopes (MAFE) have been well used in minimally-invasive surgery because they can be steered by a magnetic field thus more flexible than traditional endoscopes. Model-free and uncalibrated visual-feedback control makes it possible to manipulate MAFE with a magnetic field without external tracking systems. Because no extra sensor is required to obtain position and posture information, the size of MAFE can be made smaller. However, the traditional control method focuses on 2DoF control, which lacks control over the posture of the end of MAFE. This may result in unnecessary contact between MAFE and tissue and cause injury during the advancement of the endoscope. In this letter, we propose algorithms to enhance the pose control of MAFE to 4DoF and 5DoF based on model-free and uncalibrated visual-feedback control. Experiments in structured environments verify that the control algorithms are able to realize 4DoF manual navigation and 5DoF automatic navigation.",
        "primary_area": "",
        "author": "Jiewen Tan;Junnan Xue;Xing Yang;Sishen Yuan;Wei Liu;Hongliang Ren;Shuang Song;Jiaole Wang;Jiewen Tan;Junnan Xue;Xing Yang;Sishen Yuan;Wei Liu;Hongliang Ren;Shuang Song;Jiaole Wang",
        "authorids": "/37088948259;/37088948302;/37086953087;/37087245695;/37085479461;/37287561300;/37400326000;/37085418780;/37088948259;/37088948302;/37086953087;/37087245695;/37085479461;/37287561300;/37400326000;/37085418780",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982055/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4201804758774032052&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;2;1;0;0",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong;Southern University of Science and Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Electronic Engineering;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "HIT;CUHK;SUSTech",
        "aff_campus_unique_index": "0;0;0;1;0;1;0;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981726",
        "title": "Modeling Human Response to Robot Errors for Timely Error Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-robot collaboration, robot errors are inevitable\u2014damaging user trust, willingness to work together, and task performance. Prior work has shown that people naturally respond to robot errors socially and that in social interactions it is possible to use human responses to detect errors. However, there is little exploration in the domain of nonsocial, physical human-robot collaboration such as assembly and tool retrieval. In this work, we investigate how people's organic, social responses to robot errors may be used to enable timely automatic detection of errors in physical human-robot interactions. We conducted a data collection study to obtain facial responses to train a real-time detection algorithm and a case study to explore the generalizability of our method with different task settings and errors. Our results show that natural social responses are effective signals for timely detection and localization of robot errors even in nonsocial contexts and that our method is robust across a variety of task contexts, robot errors, and user responses. This work contributes to robust error detection without detailed task specifications.",
        "primary_area": "",
        "author": "Maia Stiber;Russell Taylor;Chien-Ming Huang;Maia Stiber;Russell Taylor;Chien-Ming Huang",
        "authorids": "/37089660250;/37277162900;/38548162000;/37089660250;/37277162900;/38548162000",
        "aff": "Dept. of Computer Science, Johns Hopkins University, Baltimore, Maryland, USA; Life Fellow, IEEE; Dept. of Computer Science, Johns Hopkins University, Baltimore, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981726/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3439968481014189424&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Johns Hopkins University;IEEE",
        "aff_unique_dep": "Dept. of Computer Science;",
        "aff_unique_url": "https://www.jhu.edu;https://www.ieee.org",
        "aff_unique_abbr": "JHU;IEEE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981435",
        "title": "Modeling and Characterization of Artificial Bacteria Flagella with Micro-structured Soft-magnetic Teeth",
        "track": "main",
        "status": "Poster",
        "abstract": "Sub-structures such as micro-structured magnetic teeth fabricated with an artificial bacteria flagellum (ABF) are designed for achieving more motion modes, higher precision, and better controllability. To achieve these, a more precise model considering the non-circular cross-sectional features is setup without simplifying the structure as a helical filament with a circular cross-section as having been used in previous investigations, making it possible to include the effects of the substructures into the motion equation. Analyses and experiments verified the correctness. Besides of the geometric effects, our experimental observation also shows an anomalous step-out frequency appeared in an ABF. This asynchronous motion is attributed to the lag of magnetization with respect to the external rotating magnetic field due to the geometries and the soft-magnetic materials of the ribbons, which is different from the regular asynchronous motion solely caused by low Reynolds number of fluid to microscopic swimmers. While the lag of magnetization can be further attributed initiatively to the soft magnetic materials adopted, the feasibility to arrange the easy axis will enable many new possibilities, which is of particular interest in generating more modes for swarms such as cascade stepping out of ABFs with the same nominal overall sizes and for more precise positioning using stepping motion.",
        "primary_area": "",
        "author": "Zejie Yu;Chaojian Hou;Shuideng Wang;Kun Wang;Donglei Chen;Wenqi Zhang;Zhi Qu;Zhiyong Sun;Bo Song;Chao Zhou;Lixin Dong;Zejie Yu;Chaojian Hou;Shuideng Wang;Kun Wang;Donglei Chen;Wenqi Zhang;Zhi Qu;Zhiyong Sun;Bo Song;Chao Zhou;Lixin Dong",
        "authorids": "/37089601197;/37086200868;/37089598350;/37089568990;/37089610807;/37087030507;/37089271788;/37085395655;/37400698100;/37876898300;/37275019100;/37089601197;/37086200868;/37089598350;/37089568990;/37089610807;/37087030507;/37089271788;/37085395655;/37400698100;/37876898300;/37275019100",
        "aff": "City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; City University of Hong Kong, Hong Kong, People's Republic of China; Institute of Intelligent Machines, Hefei Institute of Physical Science. CAS, Hefei, China; Institute of Intelligent Machines, Hefei Institute of Physical Science. CAS, Hefei, China; Institute of Plasma Physics, Hefei Institute of Physical Science, CAS, Hefei, China; City University of Hong Kong, Hong Kong, People's Republic of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981435/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7485177280655053954&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;1;1;1;0",
        "aff_unique_norm": "City University of Hong Kong;Hefei Institute of Physical Science",
        "aff_unique_dep": ";Institute of Intelligent Machines",
        "aff_unique_url": "https://www.cityu.edu.hk;",
        "aff_unique_abbr": "CityU;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;1;1;0",
        "aff_campus_unique": "Hong Kong;Hefei",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981411",
        "title": "Modeling, Analysis and Activation of Planar Viscoelastically-combined Rimless Wheels",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes novel passive-dynamic walk-ers formed by two cross-shaped frames and eight viscoelastic elements. Since it is a combination of two four-legged rimless wheels via viscoelastic elements, we call it viscoelastically-combined rimless wheel (VCRW). Two types of VCRWs consisting of different cross-shaped frames are introduced; one is formed by combining two Greek-cross-shaped frames (VCRW1), and the other is formed by combining two-link cross-shaped frames that can rotate freely around the central axis (VCRW2). First, we describe the model assumptions and equations of motion and collision. Second, we numerically analyze the basic gait properties of passive dynamic walking. Furthermore, we consider an activation of VCRW2 for gen-erating a stable level gait, and discuss the significance of the study as a novel walking support device.",
        "primary_area": "",
        "author": "Fumihiko Asano;Yuxuan Xiang;Yanqiu Zheng;Cong Yan;Fumihiko Asano;Yuxuan Xiang;Yanqiu Zheng;Cong Yan",
        "authorids": "/37278753600;/37089224227;/37086076012;/37087242941;/37278753600;/37089224227;/37086076012;/37087242941",
        "aff": "School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981411/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:WkdV3SWWy10J:scholar.google.com/&scioq=Modeling,+Analysis+and+Activation+of+Planar+Viscoelastically-combined+Rimless+Wheels&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Japan Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Information Science",
        "aff_unique_url": "https://www.jaist.ac.jp",
        "aff_unique_abbr": "JAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ishikawa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981474",
        "title": "Modular and Hybrid Numerical-Analytical Approach - A Case Study on Improving Computational Efficiency for Series-Parallel Hybrid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling closed loop mechanisms is a necessity for the control and simulation of various systems and poses a great challenge to rigid body dynamics algorithms. Solving the forward and inverse dynamics for such systems require resolution of loop closure constraints which are often solved via numerical procedures. This brings an additional burden to these algorithms as they have to stabilize and control the loop closure errors. In order to avoid this issue, analytical solutions are preferred for commonly studied parallel mechanisms. This paper has two contributions. Firstly, it reports a case study on a modular and hybrid numerical-analytical approach to model and control series-parallel hybrid robots which are subjected to large number of holonomic constraints. The approach exploits the modularity in the robot design to combine analytical loop closure for the known submechanisms and numerical loop closure for submechanisms where analytical solutions are not available. This offers an edge over purely numerical approach in terms of computational efficiency. Secondly, an adaption of the constraint embedding approach in Articulated Body Algorithm (ABA) is presented which yields a recursive algorithm in minimal coordinates for computing the forward dynamics of series-parallel hybrid systems. The proposed modification exploits the Lie group formulations and allows easy implementation of recursive forward dynamics of constrained systems in state of the art multi-body solvers.",
        "primary_area": "",
        "author": "Rohit Kumar;Shivesh Kumar;Andreas M\u00fcller;Frank Kirchner;Rohit Kumar;Shivesh Kumar;Andreas M\u00fcller;Frank Kirchner",
        "authorids": "/37089658177;/37085850436;/37085636420;/37283559600;/37089658177;/37085850436;/37085636420;/37283559600",
        "aff": "Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH, Robotics Innovation Center, Bremen, Germany; Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH, Robotics Innovation Center, Bremen, Germany; Institute of Robotics, Johannes Kepler University, Linz, Austria; AG Robotik, University of Bremen, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981474/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4400884246403971543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH;Johannes Kepler University;University of Bremen",
        "aff_unique_dep": "Robotics Innovation Center;Institute of Robotics;AG Robotik",
        "aff_unique_url": "https://www.dfki.de;https://www.jku.at;https://www.uni-bremen.de",
        "aff_unique_abbr": "DFKI;JKU;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Bremen;Linz",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "9981688",
        "title": "Modular robot networking: a novel schema and its performance assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular robots (MRs) consist of unique robots which interconnect and work as a collective to perform objectives. Coordinating these robots rely on robust communication, as modules moving independently can lead to damaging behaviour. We present a robust structure for modular robot communication, implemented and tested on a new MR. The structure has different communication protocols depending on the importance and bandwidth of the exchanged information, has fast error responses, and considerations which allow for two modules to actuate the same joint. We evaluate the wireless protocols, novel error response, and coordinated actuation empirically, validating the system on a new modular robot, the Mori3. We find two wireless protocols can be used to balance speed and reliability; transmitting errors through both wireless and serial is more consistent and faster; and sharing motor targets, control variables, and measurements allow for motors to operate a shared joint with equal efforts.",
        "primary_area": "",
        "author": "Kevin Holdcroft;Anastasia Bolotnikova;Christoph Belke;Jamie Paik;Kevin Holdcroft;Anastasia Bolotnikova;Christoph Belke;Jamie Paik",
        "authorids": "/37089660492;/37086303237;/37086077552;/37085372758;/37089660492;/37086303237;/37086077552;/37085372758",
        "aff": "Reconfigurable Robotics Lab (RRL), \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Biorobotics Laboratory (BioRob), \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Reconfigurable Robotics Lab (RRL), \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Reconfigurable Robotics Lab (RRL), \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981688/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14266230716288269763&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "Reconfigurable Robotics Lab",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981983",
        "title": "Modulo Cellulo: Modular Versatile Tangible Educational Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents the novel modular version of the robotic platform Cellulo, a versatile handheld robot initially designed as an educational robot. The use of Cellulo in different contexts and applications over the years has highlighted the need for modularity. Modularity adds versatility by increasing the spectrum of functionalities of the robot, as well as more robustness. Modulo Cellulo consists of three modules: a main module, a battery module, and an interaction module. We describe the new Modulo Cellulo platform, the different modules design, the mechanical and electrical inter-connectivity between them, the new adaptive controller, and the application development framework. As a show case, we present the addition of the reconfigurable robot Mori as a module for Cellulo, in an activity envisioning the collaboration between reconfigurable swarm robots.",
        "primary_area": "",
        "author": "Hala Khodr;Kevin Holdcroft;Yi-Shiun Wu;Victor Borja;Hadrien Sprumont;Barbara Bruno;Jamie Paik;Pierre Dillenbourg;Hala Khodr;Kevin Holdcroft;Yi-Shiun Wu;Victor Borja;Hadrien Sprumont;Barbara Bruno;Jamie Paik;Pierre Dillenbourg",
        "authorids": "/37086940436;/37089660492;/37089663017;/37089660411;/37089658599;/38542353500;/37085372758;/37541818200;/37086940436;/37089660492;/37089663017;/37089660411;/37089658599;/38542353500;/37085372758;/37541818200",
        "aff": "Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Reconfigurable Robotics Laboratory, School of Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Reconfigurable Robotics Laboratory, School of Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Computer Human Interaction for Learning and Instruction Laboratory, Faculty of Computer Science, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981983/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13340681677618574165&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Faculty of Computer Science",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982157",
        "title": "Monocular Depth Estimation for Equirectangular Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation from panoramic imagery has received minimal attention in contrast to standard perspective imagery, which constitutes the majority of the literature on the key research topic. The vast - and frequently complete - field of view provided by such panoramic photographs makes them appealing for a variety of applications, including robots, autonomous vehicles, and virtual reality. Consumer-level camera systems capable of capturing such images are likewise growing more affordable, and may be desirable complements to autonomous systems' sensor packages. They do, however, introduce significant distortions and violate some assumptions regarding perspective view images. Additionally, many state-of-the-art algorithms are not designed for its projection model, and their depth estimation performance tends to degrade when being applied to panoramic imagery. This paper presents a novel technique for adapting view synthesis-based depth estimation models to omnidirectional vision. Specifically, we: 1) integrate a \u201cvirtual\u201d spherical camera model into the training pipeline, facilitating the model training, 2) exploit spherical convolutional layers to perform convolution operations on equirectangular images, handling the severe distortion, and 3) propose an optical flow-based masking scheme to mitigate the effect of unwanted pixels during training. Our qualitative and quantitative results demonstrate that these simple yet efficient designs result in significantly improved depth estimations when compared to previous approaches.",
        "primary_area": "",
        "author": "Helmi Fraser;Sen Wang;Helmi Fraser;Sen Wang",
        "authorids": "/37088854399;/37086278300;/37088854399;/37086278300",
        "aff": "Heriot-Watt University, United Kingdom; Heriot-Watt University, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982157/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16005026290388733872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981970",
        "title": "Monocular Event Visual Inertial Odometry based on Event-corner using Sliding Windows Graph-based Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are biologically-inspired vision sensors that capture pixel-level illumination changes instead of the intensity image at a fixed frame rate. They offer many advantages over the standard cameras, such as high dynamic range, high temporal resolution (low latency), no motion blur, etc. Therefore, developing state estimation algorithms based on event cameras offers exciting opportunities for autonomous systems and robots. In this paper, we propose monocular visual-inertial odometry for event cameras based on event-corner feature detection and matching with well-designed feature management. More specifically, two different kinds of event representations based on time surface are designed to realize event-corner feature tracking (for front-end incremental estimation) and matching (for loop closure detection). Furthermore, the proposed event representations are used to set mask for detecting the event-corner feature based on the raw event-stream, which ensures the uniformly distributed and spatial consistency characteristic of the event-corner feature. Finally, a tightly coupled, graph-based optimization framework is designed to obtain high-accurate state estimation through fusing pre-integrated IMU measurements and event-corner observations. We validate quantitatively the performance of our system on different resolution event cameras: DAVIS240C (240*180, public dataset, achieve state-of-the-art), DAVIS346 (346*240, real-test), DVXplorer (640*480 real-test). Furthermore, we demonstrate qualitatively the accuracy, robustness, loop closure, and re-localization performance of our framework on different large-scale datasets, and an autonomous quadrotor flight using our Event Visual-inertial Odometry (EVIO) framework. Videos of all the evaluations are presented on the project website.",
        "primary_area": "",
        "author": "Weipeng Guan;Peng Lu;Weipeng Guan;Peng Lu",
        "authorids": "/37086247037;/37087243038;/37086247037;/37087243038",
        "aff": "Department of Mechanical Engineering, Faculty of Engineering, The University of Hong Kong, Hong Kong SAR, China; Department of Mechanical Engineering, Faculty of Engineering, The University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981970/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2989437428093294827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981226",
        "title": "Motion Attribute-based Clustering and Collision Avoidance of Multiple In-water Obstacles by Autonomous Surface Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation and obstacle avoidance in aquatic en-vironments for autonomous surface vehicles (ASVs) in high-traffic maritime scenarios is still an open challenge, as the Convention on the International Regulations for Preventing Collisions at Sea (COLREGs) is not defined for multi-encounter situations. Current state-of-the-art methods resolve single-to-single encounters with sequential actions and assume that other obstacles follow COLREGs. Our work proposes a novel real-time non-myopic obstacle avoidance method, allowing an ASV that has only partial knowledge of the surroundings within the sensor radius to navigate in high-traffic maritime scenarios. Specifically, we achieve a holistic view of the feasible ASV action space able to avoid deadlock scenarios, by proposing (1) a clustering method based on motion attributes of other obstacles, (2) a geometric framework for identifying the feasible action space, and (3) a multi-objective optimization to determine the best action. Theoretical analysis and extensive realistic exper-iments in simulation considering real-world traffic scenarios demonstrate that our proposed real-time obstacle avoidance method is able to achieve safer trajectories than other state-of-the-art methods and that is robust to uncertainty present in the current information available to the ASV.",
        "primary_area": "",
        "author": "Mingi Jeong;Alberto Quattrini Li;Mingi Jeong;Alberto Quattrini Li",
        "authorids": "/37087244961;/37085808885;/37087244961;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981226/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15033500987526103384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hanover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981961",
        "title": "Motion Planning by Search in Derivative Space and Convex Optimization with Enlarged Solution Space",
        "track": "main",
        "status": "Poster",
        "abstract": "To efficiently generate safe trajectories for an autonomous vehicle in dynamic environments, a layered motion planning method with decoupled path and speed planning is widely used. This paper studies speed planning, which mainly deals with dynamic obstacle avoidance given a planned path. The main challenges lie in the optimization in a non-convex space and the trade-off between safety, comfort, and efficiency. First, this work proposes to conduct a search in second-order derivative space for generating a comfort-optimal reference trajectory. Second, by combining abstraction and refinement, an algorithm is proposed to construct a convex feasible space for optimization. Finally, a piecewise B\u00e9zier polynomial optimization approach with trapezoidal corridors is presented, which theoretically guarantees safety and significantly enlarges the solution space compared with the existing rectangular corridors-based approach. We validate the efficiency and effectiveness of the proposed approach in simulations.",
        "primary_area": "",
        "author": "Jialun Li;Xiaojia Xie;Qin Lin;Jianping He;John M. Dolan;Jialun Li;Xiaojia Xie;Qin Lin;Jianping He;John M. Dolan",
        "authorids": "/37088484716;/37089661860;/37086031992;/38239084800;/37283756800;/37088484716;/37089661860;/37086031992;/38239084800;/37283756800",
        "aff": "The Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; Megvii (Face++) Technology Inc., Beijing, China; The Electrical Engineering and Computer Science Department, Cleveland State University, Cleveland, OH, USA; The Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981961/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11094844153769314611&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1+2;3;0;4",
        "aff_unique_norm": "Shanghai Jiao Tong University;MEGVII;Technology Inc.;Cleveland State University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Automation;;;Electrical Engineering and Computer Science Department;The Robotics Institute",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.megvii.com;;https://www.csuohio.edu;https://www.cmu.edu",
        "aff_unique_abbr": "SJTU;Megvii;;CSU;CMU",
        "aff_campus_unique_index": "0;;2;0;3",
        "aff_campus_unique": "Shanghai;;Cleveland;Pittsburgh",
        "aff_country_unique_index": "0;0+0;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981903",
        "title": "Motion Planning for Agile Legged Locomotion using Failure Margin Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "The complex dynamics of agile robotic legged locomotion requires motion planning to intelligently adjust footstep locations. Often, bipedal footstep and motion planning use mathematically simple models such as the linear inverted pendulum, instead of dynamically-rich models that do not have closed-form solutions. We propose a real-time optimization method to plan for dynamical models that do not have closed form solutions and experience irrecoverable failure. Our method uses a data-driven approximation of the step-to-step dynamics and of a failure margin function. This failure margin function is an oriented distance function in state-action space where it describes the signed distance to success or failure. The motion planning problem is formed as a nonlinear program with constraints that enforce the approximated forward dynamics and the validity of state-action pairs. For illustration, this method is applied to create a planner for an actuated spring-loaded inverted pendulum model. In an ablation study, the failure margin constraints decreased the number of invalid solutions by between 24 and 47 percentage points across different objectives and horizon lengths. While we demonstrate the method on a canonical model of locomotion, we also discuss how this can be applied to data-driven models and full-order robot models.",
        "primary_area": "",
        "author": "Kevin Green;John Warila;Ross L. Hatton;Jonathan Hurst;Kevin Green;John Warila;Ross L. Hatton;Jonathan Hurst",
        "authorids": "/37087323965;/37089661519;/37542919100;/37267365600;/37087323965;/37089661519;/37542919100;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981903/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12716487562377428710&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981106",
        "title": "Motion Planning for HyTAQs: A Topology-guided Unified NMPC Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a topology-guided unified nonlinear model predictive control (NMPC) approach is proposed for autonomous navigation of a class of Hybrid Terrestrial and Aerial Quadrotors (HyTAQs) in unknown environments. The approach can fully exploit the hybrid terrestrial-aerial locomotion of the vehicle and as such ensure a high navigation efficiency. A unified terrestrial-aerial NMPC is first formulated with a type of complementarity constraints involving the hybrid dynamics, together with the collision avoidance constraints for safety. Further, a topological roadmap with both terrestrial and aerial paths is leveraged to guide the kinodynamic path searching and thus the unified NMPC. Then, a complete and distinctive navigation framework is established and validated on our self-developed HyTAQ. Compared with the existing unified terrestrial-aerial planning methods, ours takes the vehicle dynamics into account for the first attempt and achieves a more reasonable decision of modes switching. Experimental results are presented to demonstrate the effectiveness and superiority of the proposed approach.",
        "primary_area": "",
        "author": "Tong Wu;Yimin Zhu;Lixian Zhang;Jianan Yang;Yihang Ding;Tong Wu;Yimin Zhu;Lixian Zhang;Jianan Yang;Yihang Ding",
        "authorids": "/37089173705;/37089460523;/37406065300;/37088887399;/37089461417;/37089173705;/37089460523;/37406065300;/37088887399;/37089461417",
        "aff": "School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981106/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16254565797607569771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Astronautics",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982005",
        "title": "Multi-Agent Relative Pose Estimation with UWB and Constrained Communications",
        "track": "main",
        "status": "Poster",
        "abstract": "Inter-agent relative localization is critical for any multi-robot system operating in the absence of external positioning infrastructure or prior environmental knowledge. We propose a novel inter-agent relative 2D pose estimation system where each participating agent is equipped with several ultra-wideband (UWB) ranging tags. Prior work typically supplements noisy UWB range measurements with additional continuously transmitted data, such as odometry, making these approaches scale poorly with increased swarm size or decreased communication throughput. This approach addresses these concerns by using only locally collected UWB measurements with no additionally transmitted data. By modeling observed ranging biases and systematic antenna obstructions in our proposed optimization solution, our experimental results demonstrate an improved mean position error (while remaining competitive in other metrics) over a similar state-of-the-art approach that additionally relies on continuously transmitted odometry.",
        "primary_area": "",
        "author": "Andrew Fishberg;Jonathan P. How;Andrew Fishberg;Jonathan P. How",
        "authorids": "/37088579452;/37276347700;/37088579452;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, MIT; Department of Aeronautics and Astronautics, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982005/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6934081772542404329&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981532",
        "title": "Multi-Camera-LiDAR Auto-Calibration by Joint Structure-from-Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiple sensors, especially cameras and LiDARs, are widely used in autonomous vehicles. In order to fuse data from different sensors accurately, precise calibrations are required, including camera intrinsic parameters, and relative poses between multiple cameras and LiDARs. However, most existing camera-LiDAR calibration methods need to place manually designed calibration objects in multiple locations and multiple times, which are time-consuming and labor-intensive, and are not suitable for frequent use. To address that, in this paper we proposed a novel calibration pipeline that can automatically calibrate multiple cameras and multiple LiDARs in a Structure-from-Motion (SfM) process. In our pipeline, we first perform a global SfM on all images with the help of rough LiDAR data to get the initial poses of all sensors. Then, feature points on lines and planes are extracted from both SfM point cloud and LiDARs. With these features, a global Bundle Adjustment is performed to minimize the point reprojection errors, point-to-line errors, and point-to-plane errors together. During this minimization process, camera intrinsic parameters, camera and LiDAR poses, and SfM point cloud are refined jointly. The proposed method uses the characteristics of natural scenes, does not require manually designed calibration objects, and incorporates all calibration parameters into a unified optimization framework. Experiments on autonomous vehicles with different sensor configurations demonstrate the effectiveness and robustness of the proposed method.",
        "primary_area": "",
        "author": "Diantao Tu;Baoyu Wang;Hainan Cui;Yuqian Liu;Shuhan Shen;Diantao Tu;Baoyu Wang;Hainan Cui;Yuqian Liu;Shuhan Shen",
        "authorids": "/37089001615;/37089658716;/37085565903;/37088998282;/37397055200;/37089001615;/37089658716;/37085565903;/37088998282;/37397055200",
        "aff": "CASIA-SenseTime Research Group; CASIA-SenseTime Research Group; CASIA-SenseTime Research Group; SenseTime Research, Hangzhou, China; CASIA-SenseTime Research Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981532/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14606815926772633793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;SenseTime Research",
        "aff_unique_dep": "CASIA-SenseTime Research Group;",
        "aff_unique_url": "http://www.casia.ac.cn;https://www.sensetime.com",
        "aff_unique_abbr": "CASIA;SenseTime",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981444",
        "title": "Multi-DoF Soft Robotic Actuators Based on Spring Reinforce and Particle Jamming",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots have a wide rang of applications due to their compliance, flexibility and low fabrication cost. Compare to rigid robots, soft robots are more safe for human. In this work, we design various multi-DoF actuators with spring reinforce and particle jamming, and two fabrication methods are proposed to make them. Each type of actuator is tested to evaluate the mechanical properties by experiments. Experimental results show that both spring and particle jamming have effect on the stiffness. Besides, Spring reinforced actuator (SRA) increases the maximum allowable inflation pressure, output bending force and gives a good linear relationship of bending. We also integrate spring and particles to fabricate a hybrid actuator whose behaviors are explored by experiments. Finally, we create a snake-like robotic manipulator assembled with two actuators and show its bending motion. Results show that the manipulator is able to achieve several bending shapes steadily and large range of motion.",
        "primary_area": "",
        "author": "Weiwang Fan;He Xu;Haihang Wang;Siqing Chen;Qiandiao Wei;Chaochao You;Weiwang Fan;He Xu;Haihang Wang;Siqing Chen;Qiandiao Wei;Chaochao You",
        "authorids": "/37089345565;/37291049500;/37087179018;/37088504226;/37089345433;/37088946251;/37089345565;/37291049500;/37087179018;/37088504226;/37089345433;/37088946251",
        "aff": "College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China; College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China; College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China; College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China; College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China; College of Mechanical and Electrical Engineering\u2019 Harbin Engineering University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981444/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7572381159928602247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Engineering University",
        "aff_unique_dep": "College of Mechanical and Electrical Engineering",
        "aff_unique_url": "http://www.heu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981805",
        "title": "Multi-Finger Grasping Like Humans",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots with multi-fingered grippers could perform advanced manipulation tasks for us if we were able to properly specify to them what to do. In this study, we take a step in that direction by making a robot grasp an object like a grasping demonstration performed by a human. We propose a novel optimization-based approach for transferring human grasp demonstrations to any multi-fingered grippers, which produces robotic grasps that mimic the human hand orientation and the contact area with the object, while alleviating interpenetration. Extensive experiments with the Allegro and BarrettHand grippers show that our method leads to grasps more similar to the human demonstration than existing approaches, without requiring any gripper-specific tuning. We confirm these findings through a user study and validate the applicability of our approach on a real robot.",
        "primary_area": "",
        "author": "Yuming Du;Philippe Weinzaepfel;Vincent Lepetit;Romain Br\u00e9gier;Yuming Du;Philippe Weinzaepfel;Vincent Lepetit;Romain Br\u00e9gier",
        "authorids": "/37089230658;/37945393000;/37281250600;/37086285831;/37089230658;/37945393000;/37281250600;/37086285831",
        "aff": "LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France; NAVER LABS Europe, Meylan, France; LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France; NAVER LABS Europe, Meylan, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981805/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=25792242306170510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Ecole des Ponts ParisTech;NAVER LABS Europe",
        "aff_unique_dep": "LIGM;",
        "aff_unique_url": "https://www.ponts.fr;https://labs.naver.com",
        "aff_unique_abbr": "ENPC;NAVER LABS Europe",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Marne-la-Vall\u00e9e;Meylan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981785",
        "title": "Multi-Goal Multi-Agent Pickup and Delivery",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we consider the Multi-Agent Pickup-and-Delivery (MAPD) problem, where agents constantly engage with new tasks and need to plan collision-free paths to execute them. To execute a task, an agent needs to visit a pair of goal locations, consisting of a pickup location and a delivery location. We propose two variants of an algorithm that assigns a sequence of tasks to each agent using the anytime algorithm Large Neighborhood Search (LNS) and plans paths using the Multi-Agent Path Finding (MAPF) algorithm Priority-Based Search (PBS). LNS-PBS is complete for well-formed MAPD instances, a realistic subclass of MAPD instances, and empirically more effective than the existing complete MAPD algorithm CENTRAL. LNS-wPBS provides no completeness guarantee but is empirically more efficient and stable than LNS-PBS. It scales to thousands of agents and thousands of tasks in a large warehouse and is empirically more effective than the existing scalable MAPD algorithm HBH+MLA*. LNS-PBS and LNS-wPBS also apply to a more general variant of MAPD, namely the Multi-Goal MAPD (MG-MAPD) problem, where tasks can have different numbers of goal locations.",
        "primary_area": "",
        "author": "Qinghong Xu;Jiaoyang Li;Sven Koenig;Hang Ma;Qinghong Xu;Jiaoyang Li;Sven Koenig;Hang Ma",
        "authorids": "/37089662296;/37089447975;/37284916000;/37088998793;/37089662296;/37089447975;/37284916000;/37088998793",
        "aff": "School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981785/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18380700880286648112&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Simon Fraser University;University of Southern California",
        "aff_unique_dep": "School of Computing Science;Department of Computer Science",
        "aff_unique_url": "https://www.sfu.ca;https://www.usc.edu",
        "aff_unique_abbr": "SFU;USC",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Burnaby;Los Angeles",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9981288",
        "title": "Multi-Level Task Learning Based on Intention and Constraint Inference for Autonomous Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "To perform tasks in unstructured environments, robots need to be able to apply learned skills to different contexts and to autonomously make decisions online. We, therefore, developed a novel data-driven task learning approach that segments a task demonstration into simpler skills and structures them in a high-level task graph. In contrast to other state-of-the-art methods, the presented approach can not only infer the low-level skills and their respective subgoals but also multimodal feature constraints fitted individually to each skill. The inferred feature constraints allow to detect anomalies during autonomous task execution, which can be automatically resolved by a recovery behavior of the task graph. The subgoals encode each skill's intention and thereby enable to flexibly transition between skills and to generalize the behavior to new setups. By separating the subgoal and constraint inference, we achieve a reduced computational complexity and an increased performance compared to state-of-the-art task learning approaches. In a real-world manipulation task, we demonstrate the reusability of skills as well as the autonomous decision-making of our approach.",
        "primary_area": "",
        "author": "Christoph Willibald;Dongheui Lee;Christoph Willibald;Dongheui Lee",
        "authorids": "/37088687395;/37068725100;/37088687395;/37068725100",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Chair of Autonomous Systems, Technische Universitt Wien (TU Wien), Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981288/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13390801052877804594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "German Aerospace Center (DLR);Technische Universitt Wien",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Chair of Autonomous Systems",
        "aff_unique_url": "https://www.dlr.de;https://www.tuwien.ac.at",
        "aff_unique_abbr": "DLR;TU Wien",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Vienna",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "9981078",
        "title": "Multi-Modal Lidar Dataset for Benchmarking General-Purpose Localization and Mapping Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Lidar technology has evolved significantly over the last decade, with higher resolution, better accuracy, and lower cost devices available today. In addition, new scanning modalities and novel sensor technologies have emerged in recent years. Public datasets have enabled benchmarking of algorithms and have set standards for the cutting edge technology. However, existing datasets are not representative of the technological landscape, with only a reduced number of lidars available. This inherently limits the development and comparison of general-purpose algorithms in the evolving landscape. This paper presents a novel multi-modal lidar dataset with sensors showcasing different scanning modalities (spinning and solid-state), sensing technologies, and lidar cameras. The focus of the dataset is on low-drift odometry, with ground truth data available in both indoors and outdoors environment with sub-millimeter accuracy from a motion capture (MOCAP) system. For comparison in longer distances, we also include data recorded in larger spaces indoors and outdoors. The dataset contains point cloud data from spinning lidars and solid-state lidars. Also, it provides range images from high resolution spinning lidars, RGB and depth images from a lidar camera, and inertial data from built-in IMUs. This is, to the best of our knowledge, the lidar dataset with the most variety of sensors and environments where ground truth data is available. This dataset can be widely used in multiple research areas, such as 3D LiDAR simultaneous localization and mapping (SLAM), performance comparison between multi-modal lidars, appearance recognition and loop closure detection. The datasets are available at: https://github.com/TIERS/tiers-lidars-dataset.",
        "primary_area": "",
        "author": "Li Qingqing;Yu Xianjia;Jorge Pe\u00f1a Queralta;Tomi Westerlund;Li Qingqing;Yu Xianjia;Jorge Pe\u00f1a Queralta;Tomi Westerlund",
        "authorids": "/37540873200;/37088905340;/37086828421;/37298877900;/37540873200;/37088905340;/37086828421;/37298877900",
        "aff": "Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland; Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland; Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland; Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981078/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15579610742075828510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Turku",
        "aff_unique_dep": "Turku Intelligent Embedded and Robotic Systems (TIERS) Lab",
        "aff_unique_url": "https://www.utu.fi",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Turku",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9981582",
        "title": "Multi-Modal Multi-Agent Optimization for LIMMS, A Modular Robotics Approach to Delivery Automation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a motion planner for LIMMS, a modular multi-agent, multi-modal package delivery platform. A single LIMMS unit is a robot that can operate as an arm or leg depending on how and what it is attached to, e.g., a manipulator when it is anchored to walls within a delivery vehicle or a quadruped robot when 4 are attached to a box. Coordinating amongst multiple LIMMS, when each one can take on vastly different roles, can quickly become complex. For such a planning problem we first compose the necessary logic and constraints. The formulation is then solved for skill exploration and can be implemented on hardware after refinement. To solve this optimization problem we use alternating direction method of multipliers (ADMM). The proposed planner is experimented under various scenarios which shows the capability of LIMMS to enter into different modes or combinations of them to achieve their goal of moving shipping boxes.",
        "primary_area": "",
        "author": "Xuan Lin;Gabriel I. Fernandez;Yeting Liu;Taoyuanmin Zhu;Yuki Shirai;Dennis Hong;Xuan Lin;Gabriel I. Fernandez;Yeting Liu;Taoyuanmin Zhu;Yuki Shirai;Dennis Hong",
        "authorids": "/37085891795;/37087324390;/37088446251;/37086599307;/37086344073;/37575333900;/37085891795;/37087324390;/37088446251;/37086599307;/37086344073;/37575333900",
        "aff": "RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA; RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA; RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA; RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA; RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA; RoMeLa (the Robotics and Mechanisms Laboratory), University of California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981582/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7976181492715298980&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "RoMeLa (the Robotics and Mechanisms Laboratory)",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981799",
        "title": "Multi-Object Grasping - Efficient Robotic Picking and Transferring Policy for Batch Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "In a typical fulfillment center, the order fulfilling process is managed by a warehouse management system (WMS). For efficiency, WMS usually applies batch picking, also called multi-order picking, to collect the same items for multiple orders. Suppose an item appears in multiple orders, instead of repeatedly revisiting the exact picking location multiple times, a picker will be instructed to pick up multiple same items at once and bring them to a sorting station, also called a re-bin station. It is at the re-bin station, where the workers sort the picked items into separate orders. We have seen many robotic technologies being developed for sorting. However, we have not seen any feasible robotic technology for batch picking. Transferring multiple objects between bins is a common task. In robotics, a standard approach is to transfer a single object at a time. However, grasping multiple objects and transferring them at once is more efficient. This paper presents a set of novel strategies for efficiently grasping and transferring multiple objects. The grasping strategies enable a robotic hand to grasp multiple objects by identifying an optimal ready hand configuration (pre-grasp), calculating a flexion synergy based on the desired quantity of objects to be grasped, and utilizing a deep learning model to signal the completion of a grasp. The transferring strategies demonstrate an approach that models the problem as a Markov decision process (MDP) and defines specific grasping actions to efficiently transfer objects when the required quantity is larger than the capability of a single grasp. Using the MDP model, the approach can generate an optimal pick-transfer policy that minimizes the number of transfers. The complete proposed approach has been evaluated in both a simulation environment and on a real robotic system. The proposed approach reduces the number of transfers by 59% and the number of lifts by 58% compared to an optimal single object pick-transfer solution. Show More",
        "primary_area": "",
        "author": "Adheesh Shenoy;Tianze Chen;Yu Sun;Adheesh Shenoy;Tianze Chen;Yu Sun",
        "authorids": "/37089196538;/37087323523;/37291603500;/37089196538;/37087323523;/37291603500",
        "aff": "Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981799/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12101651658419145261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982094",
        "title": "Multi-Objective Geometric Optimization of A Multi-Link Manipulator Using Parameterized Design Method",
        "track": "main",
        "status": "Poster",
        "abstract": "The performance of a robot is closely related to its structure. From the initial design of link lengths to structural optimization, it is still the research hotspot in recent years. To make the manipulator lightweight and ensure its working range and flexibility, researchers have proposed many optimization methods, most of which are for specific working scenarios, requirements, and robot structures, therefore their generality is limited. The optimization of the manipulator should be a comprehensive method. That is, we should pay attention to the joint configuration and each link length at the beginning of the design. Particularly, the geometric parameters of each link, which not only affect the range of the workspace but also have a direct impact on the working space, working efficiency, and flexibility of the manipulator. In this paper, a generalized optimization framework is proposed for multi-link manipulators. Starting from the optimization of manipulator link lengths, firstly, the geometry of the manipulator and workspace is parameterized; then the performance indicators are established; lastly, the geometric size of the manipulator is optimized according to the workspace limits and task requirements. Besides, we verified its feasibility and generality by applying this method to different TBM scenarios.",
        "primary_area": "",
        "author": "Xiaomeng Hu;Weiwei Wan;Liang Du;Jianjun Yuan;Shugen Ma;Xiaomeng Hu;Weiwei Wan;Liang Du;Jianjun Yuan;Shugen Ma",
        "authorids": "/37089515162;/37085689483;/37087006997;/37293594200;/37280187400;/37089515162;/37085689483;/37087006997;/37293594200;/37280187400",
        "aff": "Shanghai Robotics Institute, Shanghai University, Shanghai, China; Department of System Innovation, Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Department of Robotics, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982094/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16214999035478819462&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Shanghai University;Osaka University;Ritsumeikan University",
        "aff_unique_dep": "Shanghai Robotics Institute;Department of System Innovation;Department of Robotics",
        "aff_unique_url": "https://www.shu.edu.cn;https://www.osaka-u.ac.jp;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SHU;Osaka U;Ritsumeikan",
        "aff_campus_unique_index": "0;1;0;0;2",
        "aff_campus_unique": "Shanghai;Toyonaka;Shiga",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9982278",
        "title": "Multi-Objective Policy Gradients with Topological Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-objective optimization models that encode ordered sequential constraints provide a solution to model various challenging problems including encoding preferences, modeling a curriculum, and enforcing measures of safety. A recently developed theory of topological Markov decision processes (TMDPs) captures this range of problems for the case of discrete states and actions. In this work, we extend TMDPs towards continuous spaces and unknown transition dynamics by formulating, proving, and implementing the policy gradient theorem for TMDPs. This theoretical result enables the creation of TMDP learning algorithms that use function approximators, and can generalize existing deep reinforcement learning (DRL) approaches. Specifically, we present a new algorithm for a policy gradient in TMDPs by a simple extension of the proximal policy optimization (PPO) algorithm. We demonstrate this on a real-world multiple-objective navigation problem with an arbitrary ordering of objectives both in simulation and on a real robot.",
        "primary_area": "",
        "author": "Kyle Hollins Wray;Stas Tiomkin;Mykel J. Kochenderfer;Pieter Abbeel;Kyle Hollins Wray;Stas Tiomkin;Mykel J. Kochenderfer;Pieter Abbeel",
        "authorids": "/37086208879;/38111054100;/37596929200;/37542877900;/37086208879;/38111054100;/37596929200;/37542877900",
        "aff": "Stanford University, Stanford, CA, USA; San Jose State University, CA, USA; Stanford University, Stanford, CA, USA; University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982278/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7225212217893466987&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Stanford University;San Jose State University;University of California, Berkeley",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.sjsu.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;SJSU;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Stanford;San Jose;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981071",
        "title": "Multi-Objective Task Allocation for Multi-Agent Systems using Hierarchical Cost Function",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent systems are deployed to accomplish tasks that take a long time with a single agent. The task allocation problem becomes particularly difficult when the objectives are conflicting with one another (e.g. minimizing the mission time while respecting the task priorities, while simultaneously maximizing agent's fitness for the task). This paper presents an algorithm to create task assignments for a group of autonomous agents with competing objectives. We consider a variety of constraints including agent capabilities to perform tasks, priorities set by a human supervisor, as well as temporal constraints such as arrival time or coalition formation. We propose a multi-objective Particle Swarm Optimization (PSO) that uses a hierarchical cost function by leveraging the paradigm of lexicographic optimization. The particles are driven by higher ranked objectives with lower ranked objectives used to break ties. We demonstrate the effectiveness of this algorithm in a battlefield scenario where sub-teams of aerial vehicles are assigned to perform area reconnaissance, target strikes, and intelligence gathering.",
        "primary_area": "",
        "author": "Navid Dadkhah Tehrani;Andrew Krzywosz;Igor Cherepinsky;Sean Carlson;Navid Dadkhah Tehrani;Andrew Krzywosz;Igor Cherepinsky;Sean Carlson",
        "authorids": "/37088883066;/37088858539;/37424783600;/37088883620;/37088883066;/37088858539;/37424783600;/37088883620",
        "aff": "Sikorsky Aircraft, Lockheed Martin Corporation, Stratford, Connecticut, USA; Sikorsky Aircraft, Lockheed Martin Corporation, Stratford, Connecticut, USA; Sikorsky Aircraft, Lockheed Martin Corporation, Stratford, Connecticut, USA; Sikorsky Aircraft, Lockheed Martin Corporation, Stratford, Connecticut, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981071/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9579669950082956480&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Lockheed Martin Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lockheedmartin.com",
        "aff_unique_abbr": "Lockheed Martin",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981525",
        "title": "Multi-Phase Multi-Modal Haptic Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtual Fixtures facilitate teleoperation, for in-stance by guiding the human operator. Developing these Virtual Fixtures in tasks with tight tolerances remains challenging. Fixtures with a high stiffness allow for more precise guidance, whereas a lower stiffness is required to allow for corrections. We observed that many assembly operations can be split into different phases - approaching, positioning, in-contact manipulation - each with different accuracy requirements. Therefore, we propose to use multi-modal fixtures, satisfying the different requirements of these phases: i.e. a position-based Trajectory Fixture for approaching and a more accurate Visual Servoing Fixture for the positioning phase. A state estimation and arbitration component ensures smooth transitions between the fixtures to provide optimal support for the operator and to achieve global availability paired with local precision at the same time. It also allows a high stiffness to be used throughout, thus achieving good guidance for all phases. The approach is validated in an application from a space scenario, consisting of the assembly of a CubeSat subsystem. The empirical results from a pilot study on this task show that our approach is faster and requires less interaction force from the operator than the baseline method.",
        "primary_area": "",
        "author": "Maximilian M\u00fchlbauer;Franz Steinmetz;Freek Stulp;Thomas Hulin;Alin Albu-Sch\u00e4ffer;Maximilian M\u00fchlbauer;Franz Steinmetz;Freek Stulp;Thomas Hulin;Alin Albu-Sch\u00e4ffer",
        "authorids": "/37089663785;/37085752163;/37681682200;/37546462300;/38270361100;/37089663785;/37085752163;/37681682200;/37546462300;/38270361100",
        "aff": "German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981525/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14110528645617455929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Robotics and Mechatronics Center",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982075",
        "title": "Multi-Robot Dynamic Swarm Disablement",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the use of robots for pest control in agriculture, this work introduces the Multi-Robot Dynamic Swarm Disablement problem, in which a team of robots is required to disable a swarm of agents (for example, locust agents) passing through an area while minimizing the cumulative time of the swarm members (equivalent to the cumulative damage they cause) in the area. Showing that the problem is hard even in naive settings, we turn to examine algorithms seeking to optimize the robots' performance against the swarm by exploiting the known movement pattern of the swarm agents. Motivated by the poor performance when a weak group of robots attempts to catch a large swarm of agents, whether it is a significant numerical minority or poor speed gaps, we suggest the use of blocking lines: the robots form lines that block the agents along their movement in the environment. We show by both theoretical analysis and rigorous empirical evaluation in different settings that these algorithms outperform common task-assignment-based algorithms, especially for limited robots versus a large swarm.",
        "primary_area": "",
        "author": "Ori Fogler;Noa Agmon;Ori Fogler;Noa Agmon",
        "authorids": "/37089661364;/37695468400;/37089661364;/37695468400",
        "aff": "Department of Computer Science, Bar-Ilan University, Israel; Department of Computer Science, Bar-Ilan University, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982075/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rhHR4Pvvjx4J:scholar.google.com/&scioq=Multi-Robot+Dynamic+Swarm+Disablement&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bar-Ilan University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.biu.ac.il",
        "aff_unique_abbr": "BIU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981807",
        "title": "Multi-Robot Path Planning Using Medial-Axis-Based Pebble-Graph Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a centralized algorithm for labeled, disk-shaped Multi-Robot Path Planning (MPP) in a continuous planar workspace with polygonal boundaries. Our method automatically transform the continuous problem into a discrete, graph-based variant termed the pebble motion problem, which can be solved efficiently. To construct the underlying pebble graph, we identify inscribed circles in the workspace via a medial axis transform and organize robots into layers within each inscribed circle. We show that our layered pebble-graph enables collision-free motions, allowing all graph-restricted MPP instances to be feasible. MPP instances with continuous start and goal positions can then be solved via local navigations that route robots from and to graph vertices. We tested our method on several environments with high robot-packing densities (up to 61.6% of the workspace). For environments with narrow passages, such density violates the well-separated assumptions made by state-of-the-art MPP planners, while our method achieves an average success rate of 83%.",
        "primary_area": "",
        "author": "Liang He;Zherong Pan;Kiril Solovey;Biao Jia;Dinesh Manocha;Liang He;Zherong Pan;Kiril Solovey;Biao Jia;Dinesh Manocha",
        "authorids": "/37085756943;/37086067204;/37085671184;/37086454487;/37267825600;/37085756943;/37086067204;/37085671184;/37086454487;/37267825600",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill; Lightspeed & Quantum Studio, Tencent, America; Technion, Israel Institute of Technology; Department of Computer Science and Electrical & Computer Engineering, University of Maryland at College Park; Department of Computer Science and Electrical & Computer Engineering, University of Maryland at College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981807/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13080949177172075660&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;3",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;Tencent;Israel Institute of Technology;University of Maryland",
        "aff_unique_dep": "Department of Computer Science;Lightspeed & Quantum Studio;;Department of Computer Science and Electrical & Computer Engineering",
        "aff_unique_url": "https://www.unc.edu;https://www.tencent.com;https://www.technion.ac.il/en/;https://www.umd.edu",
        "aff_unique_abbr": "UNC Chapel Hill;Tencent;Technion;UMD",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Chapel Hill;;College Park",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9981914",
        "title": "Multi-Robot Unknown Area Exploration Using Frontier Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach for multi-robot unknown area exploration. Recently, the frontier tree data structure was used in single robot exploration to memorize frontiers, their positions, exploration state, and the map. This tree could be queried to decide on further exploration steps. In this paper, we take the concept further for multi-robot exploration by proposing a new abstraction called the \u2018group,\u2019 meant to share information through a common frontier tree, requisite operations at the group level, and a method to assign goals to multiple robots. A group is a set of robots, the union of whose explored regions forms a contiguous region (a single connected region in a topological sense). As a group has precisely one tree, the robots share a common state of the exploration task. We propose techniques to merge groups and their frontier trees once their maps overlap. Finally, we suggest a method to designate and assign exploration goals to the individual robots by choosing nodes from the frontier tree. The proposed approach outperforms seven state-of-the-art research works in simulation.",
        "primary_area": "",
        "author": "Ankit Soni;Chirag Dasannacharya;Avinash Gautam;Virendra Singh Shekhawat;Sudeept Mohan;Ankit Soni;Chirag Dasannacharya;Avinash Gautam;Virendra Singh Shekhawat;Sudeept Mohan",
        "authorids": "/37088986689;/37089659567;/38478674400;/37831134300;/38486412200;/37088986689;/37089659567;/38478674400;/37831134300;/38486412200",
        "aff": "Department of Computer Science and Information Systems, INSPIRE Lab, Birla Institute of Technology and Science, Pilani, Rajasthan, India; Department of Computer Science and Information Systems, INSPIRE Lab, Birla Institute of Technology and Science, Pilani, Rajasthan, India; Department of Computer Science and Information Systems, INSPIRE Lab, Birla Institute of Technology and Science, Pilani, Rajasthan, India; Department of Computer Science and Information Systems, INSPIRE Lab, Birla Institute of Technology and Science, Pilani, Rajasthan, India; Department of Computer Science and Information Systems, INSPIRE Lab, Birla Institute of Technology and Science, Pilani, Rajasthan, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981914/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12081222822023474374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Birla Institute of Technology and Science",
        "aff_unique_dep": "Department of Computer Science and Information Systems",
        "aff_unique_url": "https://www.bits-pilani.ac.in",
        "aff_unique_abbr": "BITS Pilani",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pilani",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9982179",
        "title": "Multi-Scaled and Densely Connected Locally Convolutional Layers for Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "The depth completion task aims to predict a dense depth map from a sparse LiDAR point cloud and an RGB image. This task is critical because an accurate depth map can be used as prior information to solve many computer vision tasks, such as downstream tasks in autonomous vehicles and robot vision. Previous deep learning methods which focus on the local affinity have achieved impressive results. However, an architecture that is directly designed to extract local affinity has not been proposed yet. In this paper, we propose multi-scaled and densely connected locally convolutional layers to learn the affinity of the neighborhood. We set a different grid factor for each step of this module, and each step consists of several convolutional layers applied only to the local area assigned from the grid factor. In addition, each step is densely connected, sequentially, to take advantage of the multi-scale receptive fields. The proposed module effectively learns the neighbor-hood's affinity in a local area with multiple scales, while keeping the network size small. As a result, our architecture achieves state-of-the-art performance compared to published works on the KITTI depth completion benchmark. On the NYU Depth V2 completion benchmark our method achieves performance comparable to state-of-the-art approaches.",
        "primary_area": "",
        "author": "Sihaeng Lee;Eojindl Yi;Janghyeon Lee;Junmo Kim;Sihaeng Lee;Eojindl Yi;Janghyeon Lee;Junmo Kim",
        "authorids": "/37085492803;/37088689760;/37089262923;/37407301400;/37085492803;/37088689760;/37089262923;/37407301400",
        "aff": "Vision Lab of LG AI Research, Seoul, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; Vision Lab of LG AI Research, Seoul, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982179/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18183747087570980993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "LG;KAIST",
        "aff_unique_dep": "Vision Lab;School of Electrical Engineering",
        "aff_unique_url": "https://www.lgaires.com;https://www.kaist.ac.kr",
        "aff_unique_abbr": "LG AI;KAIST",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981074",
        "title": "Multi-Sensor Data Annotation Using Sequence-based Active Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Networks are the state-of-the-art technology for environmental perception in applications such as autonomous driving. However, they require a large amount of training data in order to perform well, making the selection and annotation of sensor data a time-consuming and expensive task. Active learning is a promising approach to reduce the required amount of training data by selecting samples for annotation that are expected to improve the neural network the most. In this work, we propose a sequence-based active learning approach that selects sequences of consecutive frames instead of individual images. This allows to evaluate tracking algorithms and to reduce the annotation effort by interpolating labels between frames. Our approach is compared to a random sampling strategy as baseline. Over 15 iterations, both approaches select 1000 additional images for training in each iteration. The performance of the neural network trained on the data selected by our sequence-based active learning approach is compared to the performance of the network trained on the data select by the baseline approach. The results show that sequence-based active learning can reduce the required amount of training data by up to 25% while reaching a similar performance. Furthermore, sequence-based active learning can improve the neural network's overall performance by 2 % compared to a random sampling strategy. In this work, the proposed method was evaluated with a new dataset consisting of 15 scenes in railway environments. The dataset has 45,888 frames in total, 14,513 frames contain persons on railway stations or close to tracks.",
        "primary_area": "",
        "author": "Patrick Denzler;Markus Ziegler;Arne Jacobs;Volker Eiselein;Philipp Neumaier;Martin K\u00f6ppel;Patrick Denzler;Markus Ziegler;Arne Jacobs;Volker Eiselein;Philipp Neumaier;Martin K\u00f6ppel",
        "authorids": "/37089696226;/37089238055;/37089658745;/37846259800;/38108785600;/37089659435;/37089696226;/37089238055;/37089658745;/37846259800;/38108785600;/37089659435",
        "aff": "DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany; DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany; DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany; DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany; DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany; DB Netz AG/Digitale Schiene Deutschland, Digital Base, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981074/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1133136851179254093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "DB Netz AG",
        "aff_unique_dep": "Digital Base",
        "aff_unique_url": "https://www.dbnetzag.de",
        "aff_unique_abbr": "DB Netz",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981166",
        "title": "Multi-Source Domain Alignment for Domain Invariant Segmentation in Unknown Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation provides scene understanding capability by performing pixel-wise classification of objects within an image. However, the sensitivity of such algorithms towards domain changes requires fine-tuning using an annotated dataset for each novel domain, which is expensive to construct and inefficient. We highlight that irrespective of the training dataset, structural properties of scenes remain the same hence domain sensitivity arises from training methodology. Thus, in this paper, we propose a domain alignment approach wherein multiple synthetic source domains are used to train an underlying segmentation network such that it performs consistently in unknown real target domains. Towards this end, we propose a pixel-wise supervised contrastive learning framework that enforces constraints in latent space resulting in features belonging to the same class being clustered closely and away from different classes. This approach allows for better capturing of global and local semantics while providing domain invariant properties. Our approach can be easily incorporated into prior semantic segmentation approaches without the significant computational overhead. We empirically demonstrate the efficacy of the proposed approach on GTAV \u2192 Cityscapes, GTAV+Synthia \u2192 Cityscapes, and GTAV+Synthia+Synscapes \u2192 Cityscapes scenarios and report state-of-the-art (SoTA) performance without requiring access to images from the target domain.",
        "primary_area": "",
        "author": "Pranjay Shyam;Kuk-Jin Yoon;Kyung-Soo Kim;Pranjay Shyam;Kuk-Jin Yoon;Kyung-Soo Kim",
        "authorids": "/37088503847;/38182036400;/37292681500;/37088503847;/38182036400;/37292681500",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981166/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12098102991915844120&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982096",
        "title": "Multi-UAV Cooperative Short-Range Combat via Attention-Based Reinforcement Learning using Individual Reward Shaping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel distributed method based on attention-based deep reinforcement learning using individual reward shaping, for multiple unmanned aerial vehicles (UAVs) cooperative short-range combat mission. Specifically, a two-level attention distributed policy, composed of observation-level and communication-level attention networks, is designed to enable each UAV to selectively focus on important environmental features and messages, for enhancing the effectiveness of the cooperative policy. Moreover, due to the high complexity and stochasticity of the UAV combat mission, the learning of UAVs is tricky and low efficient. To embed knowledge to accelerate the policy learning, a potential-based individual reward function is constructed by implicitly translating the individual reward into the specific form of dynamic action potentials. In addition, an actor-critic training algorithm based on the centralized training and decentralized execution framework is adopted to train the policy network of UAV maneuver decision. We build a three-dimensional UAV simulation and training platform based on Unity for multi-UAV short-range combat missions. Simulation results demonstrate the effectiveness of the proposed method and the superiority of the attention policy and individual reward shaping.",
        "primary_area": "",
        "author": "Tianle Zhang;Tenghai Qiu;Zhen Liu;Zhiqiang Pu;Jianqiang Yi;Jinying Zhu;Ruiguang Hu;Tianle Zhang;Tenghai Qiu;Zhen Liu;Zhiqiang Pu;Jianqiang Yi;Jinying Zhu;Ruiguang Hu",
        "authorids": "/37088518501;/37087053504;/37085471998;/37956875200;/37277001200;/37089658195;/37086124642;/37088518501;/37087053504;/37085471998;/37956875200;/37277001200;/37089658195;/37086124642",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Key Laboratory of Science and Technology on Aerospace Intelligent Control, Beijing Aerospace Automatic Control Institute, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982096/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6691265761470159264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Chinese Academy of Sciences;Beijing Aerospace Automatic Control Institute",
        "aff_unique_dep": "Institute of Automation;National Key Laboratory of Science and Technology on Aerospace Intelligent Control",
        "aff_unique_url": "http://www.ia.cas.cn;",
        "aff_unique_abbr": "CAS;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982010",
        "title": "Multi-View Guided Multi-View Stereo",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel deep framework for dense 3D reconstruction from multiple image frames, leveraging a sparse set of depth measurements gathered jointly with image acquisition. Given a deep multi-view stereo network, our framework uses sparse depth hints to guide the neural network by modulating the plane-sweep cost volume built during the forward step, enabling us to infer constantly much more accurate depth maps. Moreover, since multiple viewpoints can provide additional depth measurements, we propose a multi-view guidance strategy that increases the density of the sparse points used to guide the network, thus leading to even more accurate results. We evaluate our Multi-View Guided framework within a variety of state-of-the-art deep multi-view stereo networks, demonstrating its effectiveness at improving the results achieved by each of them on BlendedMVG and DTU datasets.",
        "primary_area": "",
        "author": "Matteo Poggi;Andrea Conti;Stefano Mattoccia;Matteo Poggi;Andrea Conti;Stefano Mattoccia",
        "authorids": "/37085848424;/37089815902;/37326275100;/37085848424;/37089815902;/37326275100",
        "aff": "University of Bologna; University of Bologna; University of Bologna",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982010/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9882891023221615463&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bologna",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unibo.it",
        "aff_unique_abbr": "Unibo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981821",
        "title": "Multi-axis Reorientation of a Free-falling Omnidirectional Wheeled Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents reorientation manoeuvres applied to an omnidirectional wheeled robot for impact mitigation during short falls. The proposed robot architecture aims to build upon recent innovations in reorientation robots to attain fast, multi-axis reorientation. Indeed, the use of omnidirectional wheels allows for simplifications to be made with respect to previous mobile robot architectures that make the proposed architecture more efficient for free fall reorientation, while still maintaining free roaming capabilities. To test these improvements, a prototype is built and a free roam and two free fall demonstrations are completed. On the one hand, the free roam demonstration validates that translation along both horizontal axes and rotation about the yaw axis are achieved with the presented prototype. On the other hand, the first free fall demonstration shows that a worst case scenario of a 180-degree reorientation about one axis can be completed in just under 0.45 seconds (one-metre fall) and the second free fall demonstration validates that the prototype is capable of simultaneous reorientation about both the roll and pitch axes. Therefore, the fast, multi-axis reorientation capabilities of the developed prototype are verified.",
        "primary_area": "",
        "author": "Mark Charlet;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin;Mark Charlet;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin",
        "authorids": "/37086486680;/37442629800;/37293911800;/37086486680;/37442629800;/37293911800",
        "aff": "Department of Mechanical Engineering, Laval University Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Qu\u00e9bec, Canada; Department of Mechanical Engineering, Laval University Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Qu\u00e9bec, Canada; Department of Mechanical Engineering, Laval University Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Qu\u00e9bec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981821/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2007730434338779553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "UL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Qu\u00e9bec City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981325",
        "title": "Multi-directional Bicycle Robot for Bridge Inspection with Steel Defect Detection System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel design of a multi-directional bicycle robot, which is developed for the inspection of steel structures, in particular, steel-reinforced bridges. The locomotion concept is based on arranging two magnetic wheels in a bicycle-like configuration with two independent steering actuators. This configuration allows the robot to possess multi-directional mobility. An additional free joint helps the robot adapt naturally to non-flat and complex steel structures. The robot's design provides the advantage of being mechanically simple and providing high-level mobility across diverse steel structures. In addition, a visual sensor is equipped that allows the data collection for steel defect detection with offline training and validation. The paper also provides a novel pipeline for Steel Defect Detection, which utilizes multiple datasets (one for training and one for validation) from real bridges. The quantitative results have been reported for three Deep Encoder-Decoder Networks (i.e., LinkNet, UNet, DeepLab) with their corresponding Encoder modules (i.e., ResNet-18, ResNet-34, RegNet-X2, EfficientNet-B0, and EfficientNet-B2). Due to space concerns, the qualitative results have been outlined in Appendix, with a link in Fig. 11 caption to access the result provided.",
        "primary_area": "",
        "author": "Habib Ahmed;Son Thanh Nguyen;Duc La;Chuong Phuoc Le;Hung Manh La;Habib Ahmed;Son Thanh Nguyen;Duc La;Chuong Phuoc Le;Hung Manh La",
        "authorids": "/37089093434;/37087321874;/37089659359;/37088235131;/37542872700;/37089093434;/37087321874;/37089659359;/37088235131;/37542872700",
        "aff": "Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981325/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17923369991334285700&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981464",
        "title": "Multi-fingered Tactile Servoing for Grasping Adjustment under Partial Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping of objects using multi-fingered robotic hands often fails due to small uncertainties in the hand motion control and the object's pose estimation. To tackle this problem, we propose a grasping adjustment strategy based on tactile seroving. Our technique employs feedback from a sensorized multi-fingered robotic hand to collaboratively servo the fingers and palm to achieve the desired grasp. We demonstrate the performance of our method through simulation and physical experiments by having a robot grasp different objects under conditions of variable uncertainty. The results show that our approach achieved a higher success rate and tolerated greater uncertainty than an open-looped grasp.",
        "primary_area": "",
        "author": "Hanzhong Liu;Bidan Huang;Qiang Li;Yu Zheng;Yonggen Ling;Wangwei Lee;Yi Liu;Ya-Yen Tsai;Chenguang Yang;Hanzhong Liu;Bidan Huang;Qiang Li;Yu Zheng;Yonggen Ling;Wangwei Lee;Yi Liu;Ya-Yen Tsai;Chenguang Yang",
        "authorids": "/37089335052;/37085655047;/38238874000;/37086993722;/37090018583;/37085402629;/37089664163;/37086935862;/37404783000;/37089335052;/37085655047;/38238874000;/37086993722;/37090018583;/37085402629;/37089664163;/37086935862;/37404783000",
        "aff": "South China University of Technology, China; Tencent Robotics X, Shenzhen, Guangdong Province, China; Neuroinformatics Group, Center for Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Tencent Robotics X, Shenzhen, Guangdong Province, China; Tencent Robotics X, Shenzhen, Guangdong Province, China; Tencent Robotics X, Shenzhen, Guangdong Province, China; Guangdong University of Technology, China; South China University of Technology, China; Bristol Robotics Laboratory, the University of the West of England, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981464/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3990433272393816949&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;1;1;1;3;0;4",
        "aff_unique_norm": "South China University of Technology;Tencent;Bielefeld University;Guangdong University of Technology;University of the West of England",
        "aff_unique_dep": ";Robotics X;Neuroinformatics Group, Center for Cognitive Interaction Technology (CITEC);;Bristol Robotics Laboratory",
        "aff_unique_url": "http://www.scut.edu.cn;https://robotics.tencent.com;https://www.uni-bielefeld.de;http://www.gdut.edu.cn;https://www.uwe.ac.uk",
        "aff_unique_abbr": "SCUT;Tencent Robotics X;;GDUT;UWE",
        "aff_campus_unique_index": "1;2;1;1;1;3",
        "aff_campus_unique": ";Shenzhen;Bielefeld;Bristol",
        "aff_country_unique_index": "0;0;1;0;0;0;0;0;2",
        "aff_country_unique": "China;Germany;United Kingdom"
    },
    {
        "id": "9981165",
        "title": "Multi-modal User Interface for Multi-robot Control in Underground Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Leveraging both the autonomy of robots and the expert knowledge of humans can enable a multi-robot system to complete missions in challenging environments with a high degree of adaptivity and robustness. This paper proposes a multi-modal task-based graphical user interface for controlling a heterogeneous multi-robot team. The core of the interface is an integrated multi-robot task allocation system to allow the user to encode his/her intents to guide the heterogeneous multi-robot team. The design of the interface aims to provide the human operator continuous situational awareness and effective control for rapid decision-making in time-critical missions. Team CSIRO Data61 came in second place utilizing this interface for the DARPA Subterranean (SubT) Challenge. The ideas used for this user interface can apply to other multi-robot applications.",
        "primary_area": "",
        "author": "Shengkang Chen;Matthew J. O'Brien;Fletcher Talbot;Jason Williams;Brendan Tidd;Alex Pitt;Ronald C. Arkin;Shengkang Chen;Matthew J. O'Brien;Fletcher Talbot;Jason Williams;Brendan Tidd;Alex Pitt;Ronald C. Arkin",
        "authorids": "/37088863907;/37086024936;/37086162608;/37421663500;/37089198244;/37089775550;/37278162600;/37088863907;/37086024936;/37086162608;/37421663500;/37089198244;/37089775550;/37278162600",
        "aff": "Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, Georgia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, Queensland, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, Queensland, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, Queensland, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, Queensland, Australia; School of Interactive Computing, Georgia Institute of Technology, Atlanta, Georgia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981165/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3919802229331114323&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;CSIRO;Queensland University of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Robotics and Autonomous Systems Group;School of Electrical Engineering and Robotics",
        "aff_unique_url": "https://www.gatech.edu;https://www.csiro.au;https://www.qut.edu.au",
        "aff_unique_abbr": "Georgia Tech;CSIRO;QUT",
        "aff_campus_unique_index": "0;0;1;1;2;1;0",
        "aff_campus_unique": "Atlanta;Pullenvale;Brisbane",
        "aff_country_unique_index": "0;0;1;1;1;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9981477",
        "title": "Multi-purpose Tactile Perception Based on Deep Learning in a New Tendon-driven Optical Tactile Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we create a new tendon-connected multi-functional optical tactile sensor, MechTac, for object perception in the field of view (TacTip) and location of touching points in the blind area of vision (TacSide). In a multi-point touch task, the information of the TacSide and the TacTip are overlapped to commonly affect the distribution of papillae pins on the TacTip. Since the effects of TacSide are much less obvious to those affected on the TacTip, a perceiving out-of-view neural network (O2VNet) is created to separate the mixed information with unequal affection. To reduce the dependence of the O2VNet on the grayscale information of the image, we create one new binarized convolutional (BConv) layer in front of the backbone of the O2VNet. The O2VNet can not only achieve real-time temporal sequence prediction (34 ms per image), but also attain the average classification accuracy of 99.06%. The experimental results show that the O2VNet can hold a high classification accuracy even facing the image contrast changes.",
        "primary_area": "",
        "author": "Zhou Zhao;Zhenyu Lu;Zhou Zhao;Zhenyu Lu",
        "authorids": "/37088854313;/37085393254;/37088854313;/37085393254",
        "aff": "EPITA Research and Development Laboratory (LRDE), France; UWE, Bristol Robotics Laboratory, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981477/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13771246867259951998&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "EPITA;University of the West of England",
        "aff_unique_dep": "Research and Development Laboratory (LRDE);Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.epita.fr;https://www.uwe.ac.uk",
        "aff_unique_abbr": "EPITA;UWE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "9982031",
        "title": "Multical: Spatiotemporal Calibration for Multiple IMUs, Cameras and LiDARs",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatiotemporal calibration of sensors, especially of those which do not share their fields of view, is becoming increasingly important in the fields of autonomous driving and robotics. This paper presents a general sensor calibration method, named Multical, that makes use of multiple planar calibration targets whose poses will be estimated alongside spatiotemporal calibration. Multical exploits continuous-time curves to represent the state of the sensor platform during data collection, and thus is a general framework to calibrate different kinds of sensors and deal with both spatial as well as temporal offsets. Multical includes algorithms to estimate the initial guesses of spatial transformations between sensors, and also the relative poses between calibration targets. Users do not need to provide any extrinsic priors. We apply the proposed calibration approach to both simulated and real-world experiments, and the results demonstrate the high fidelity of the proposed method.",
        "primary_area": "",
        "author": "Xiangyang Zhi;Jiawei Hou;Yiren Lu;Laurent Kneip;S\u00f6ren Schwertfeger;Xiangyang Zhi;Jiawei Hou;Yiren Lu;Laurent Kneip;S\u00f6ren Schwertfeger",
        "authorids": "/37086304709;/37087245958;/37088600247;/37569040300;/37391715800;/37086304709;/37087245958;/37088600247;/37569040300;/37391715800",
        "aff": "NIO Inc.; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; School of Information Science Technology of ShanghaiTech University, China; School of Information Science Technology of ShanghaiTech University, China; School of Information Science Technology of ShanghaiTech University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982031/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18316772866966250861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "NIO Inc.;Shanghai Institute of Microsystem and Information Technology;ShanghaiTech University",
        "aff_unique_dep": ";;School of Information Science Technology",
        "aff_unique_url": "https://www.nio.com;http://www.sim.cas.cn;https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "NIO;SIM;ShanghaiTech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981946",
        "title": "Multimodal Generation of Novel Action Appearances for Synthetic-to-Real Recognition of Activities of Daily Living",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain shifts, such as appearance changes, are a key challenge in real-world applications of activity recognition models, which range from assistive robotics and smart homes to driver observation in intelligent vehicles. For example, while simulations are an excellent way of economical data collection, a Synthetic\u2192Real domain shift leads to > 60% drop in accuracy when recognizing Activities of Daily Living (ADLs). We tackle this challenge and introduce an activity domain generation framework which creates novel ADL appearances (novel domains) from different existing activity modalities (source domains) inferred from video training data. Our frame-work computes human poses, heatmaps of body joints, and optical flow maps and uses them alongside the original RGB videos to learn the essence of source domains in order to generate completely new ADL domains. The model is optimized by maximizing the distance between the existing source appearances and the generated novel appearances while ensuring that the semantics of an activity is preserved through an additional classification loss. While source data multimodality is an important concept in this design, our setup does not rely on multi-sensor setups, (i.e., all source modalities are inferred from a single video only.) The newly created activity domains are then integrated in the training of the ADL classification networks, resulting in models far less susceptible to changes in data distributions. Extensive experiments on the Synthetic\u2192Real benchmark Sims4Action demonstrate the potential of the domain generation paradigm for cross-domain ADL recognition, setting new state-of-the-art results. Our code is publicly available at https://github.com/Zrrr1997/syn2real_DG.",
        "primary_area": "",
        "author": "Zdravko Marinov;David Schneider;Alina Roitberg;Rainer Stiefelhagen;Zdravko Marinov;David Schneider;Alina Roitberg;Rainer Stiefelhagen",
        "authorids": "/37089183123;/37089194574;/37085584903;/37269459200;/37089183123;/37089194574;/37085584903;/37269459200",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981946/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6492638655737136373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981374",
        "title": "Multimodal Object Categorization with Reduced User Load through Human-Robot Interaction in Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling robots to learn from interactions with users is essential to perform service tasks. However, as a robot categorizes objects from multimodal information obtained by its sensors during interactive onsite teaching, the inferred names of unknown objects do not always match the human user's expectation, especially when the robot is introduced to new environments. Confirming the learning results through natural speech interaction with the robot often puts an additional burden on the user who can only listen to the robot to validate the results. Therefore, we propose a human-robot interface to reduce the burden on the user by visualizing the inferred results in mixed reality (MR). In particular, we evaluate the proposed interface on the system usability scale (SUS) and the NASA task load index (NASA-TLX) with three experimental object categorization scenarios based on multimodal latent Dirichlet allocation (MLDA) in which the robot: 1) does not share the inferred results with the user at all, 2) shares the inferred results through speech interaction with the user (baseline), and 3) shares the inferred results with the user through an MR interface (proposed). We show that providing feedback through an MR interface significantly reduces the temporal, physical, and mental burden on the human user compared to speech interaction with the robot.",
        "primary_area": "",
        "author": "Hitoshi Nakamura;Lotfi El Hafi;Akira Taniguchi;Yoshinobu Hagiwara;Tadahiro Taniguchi;Hitoshi Nakamura;Lotfi El Hafi;Akira Taniguchi;Yoshinobu Hagiwara;Tadahiro Taniguchi",
        "authorids": "/37088813652;/37089392529;/37086202886;/37825579700;/37273806600;/37088813652;/37089392529;/37086202886;/37825579700;/37273806600",
        "aff": "Ritsumeikan University, Kusatsu, Shiga, Japan; Ritsumeikan University, Kusatsu, Shiga, Japan; Ritsumeikan University, Kusatsu, Shiga, Japan; Ritsumeikan University, Kusatsu, Shiga, Japan; Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981374/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7817206856499192097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981121",
        "title": "Multimodal aerial-tethered robot for tree canopy exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Forest canopies are the biggest habitat for terrestrial life, yet our understanding of environmental processes and biodiversity inside the canopy continues to be limited due to labour and resource intensive data collection. Existing aerial and climbing robots also struggle to access these complex environments, while animals easily navigate them using multiple means of locomotion. Following this insight we present a robot with multimodal mobility obtained by combining aerial and tethered locomotion. After the robot is deployed at the top of the tree, it can descend with the tether and maneuver around leaves and branches with its thrusters. The tether increases robustness and safety and allows for resting as well as emergency retrieval of the system. The aerial locomotion grants the system the ability to move in a conical 3D space constrained by the tether. We modelled the static system and validated the impact of design parameters on it. A simple control architecture for teleoperation is discussed and its performance is analyzed. The proposed multimodal mobility is demonstrated in preliminary outdoor tests, which show how our robot can move within the canopy while continuously monitoring the environment.",
        "primary_area": "",
        "author": "Steffen Kirchgeorg;Stefano Mintchev;Steffen Kirchgeorg;Stefano Mintchev",
        "authorids": "/37089034874;/37085587624;/37089034874;/37085587624",
        "aff": "Swiss Federal Institute for Forest, Snow and Land-scape Research (WSL), Birmensdorf, Switzerland; Swiss Federal Institute for Forest, Snow and Land-scape Research (WSL), Birmensdorf, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981121/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14715136944505081541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Swiss Federal Institute for Forest, Snow and Landscape Research",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "WSL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Birmensdorf",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982193",
        "title": "Multiple Curvatures in a Tendon-Driven Continuum Robot Using a Novel Magnetic Locking Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Tendon-driven continuum robots show promise for use in surgical applications as they can assume complex configurations to navigate along tortuous paths. However, to achieve these complex robot shapes, multiple segments are required as each robot segment can bend only with a single constant curvature. To actuate these additional robot segments, multiple tendons must typically be added on-board the robot, complicating their integration, robot control, and actuation. This work presents a method of achieving two curvatures in a single tendon-driven continuum robot segment through use of a novel magnetic locking mechanism. Thus, the need for additional robot segments and actuating tendons is eliminated. The resulting two curvatures in a single segment are demonstrated in two and three dimensions. Furthermore, the maximum magnetic field required to actuate the locking mechanism for different robot bending angles is experimentally measured to be 6.1 mT. Additionally, the locking mechanism resists unintentional unlocking unless the robot assumes a 0\u00b0 bending angle and a magnetic field of 18.1 mT is applied, conditions which are not typically reached during routine use of the system. Finally, addressable actuation of two locking mechanisms is achieved, demonstrating the capability of producing multiple curvatures in a single robot segment.",
        "primary_area": "",
        "author": "Chloe Pogue;Priyanka Rao;Quentin Peyron;Jongwoo Kim;Jessica Burgner-Kahrs;Eric Diller;Chloe Pogue;Priyanka Rao;Quentin Peyron;Jongwoo Kim;Jessica Burgner-Kahrs;Eric Diller",
        "authorids": "/37089661182;/37088999633;/37086428635;/37085385839;/37085433359;/37542880000;/37089661182;/37088999633;/37086428635;/37085385839;/37085433359;/37542880000",
        "aff": "Robotics Institute, University of Toronto, Myhal Centre for Engineering Innovation & Entrepreneurship, Toronto, ON, Canada; Robotics Institute, University of Toronto, Myhal Centre for Engineering Innovation & Entrepreneurship, Toronto, ON, Canada; DEFROST team, Inria Lille-Nord Europe and CRIStAL UMR CNRS 9189, University of Lille, Villeneuve d\u2019 Ascq, France; Department of Mechanical Engineering, Biomedical & Intelligent Robotics Laboratory, Kyung Hee University, Republic of Korea; Robotics Institute, University of Toronto, Myhal Centre for Engineering Innovation & Entrepreneurship, Toronto, ON, Canada; Robotics Institute, University of Toronto, Myhal Centre for Engineering Innovation & Entrepreneurship, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982193/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1970350614457411121&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "University of Toronto;University of Lille;Kyung Hee University",
        "aff_unique_dep": "Robotics Institute;Inria Lille-Nord Europe and CRIStAL UMR CNRS 9189;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utoronto.ca;https://www.univ-lille.fr;http://www.khu.ac.kr",
        "aff_unique_abbr": "U of T;ULille;KHU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Toronto;Villeneuve d\u2019Ascq;",
        "aff_country_unique_index": "0;0;1;2;0;0",
        "aff_country_unique": "Canada;France;South Korea"
    },
    {
        "id": "9981306",
        "title": "Multirotor Long-Reach Aerial Pruning with Wire-Suspended Saber Saw",
        "track": "main",
        "status": "Poster",
        "abstract": "Pruning work at high altitude is a dangerous work with a high risk of accidents for human workers. In this research, we propose a multirotor flying robot that is equipped with a wire-suspended device and performs pruning task. We use a saber saw as a cutting tool. If the cutting tool is installed on the body of the multirotor platform, it is difficult for the flying robot to approach the desired work point if there are obstacles such as other branches around the target branch to be pruned. Therefore, in this study, we propose a saber saw suspended from the body of the multirotor platform with two wires. The wire-suspended device is equipped with a saber saw and four ducted fans that produces thrust in any direction on the horizontal plane. This ducted fan system can be used to suppress the swing of the wire-suspended device to make positioning of the saber saw blade to the target point easier, and to improve the efficiency of the cutting and reduce the cutting time by providing a pushing force to the saber saw. As a result, the pruning work could be performed efficiently. Experiments have demonstrated that aerial pruning is possible using the long-reach wire-suspended saber saw.",
        "primary_area": "",
        "author": "Ryo Miyazaki;Wataru Matori;Takamasa Kominami;Hannibal Paul;Kazuhiro Shimonomura;Ryo Miyazaki;Wataru Matori;Takamasa Kominami;Hannibal Paul;Kazuhiro Shimonomura",
        "authorids": "/37086579328;/37089658657;/37088517089;/37086449686;/37296093100;/37086579328;/37089658657;/37088517089;/37086449686;/37296093100",
        "aff": "Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981306/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=465678688167278045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982210",
        "title": "Multiscale Sensor Fusion and Continuous Control with Neural CDEs",
        "track": "main",
        "status": "Poster",
        "abstract": "Though robot learning is often formulated in terms of discrete-time Markov decision processes (MDPs), physical robots require near-continuous multiscale feedback control. Machines operate on multiple asynchronous sensing modalities, each with different frequencies, e.g., video frames at 30Hz, proprioceptive state at 100Hz, force-torque data at 500Hz, etc. While the classic approach is to batch observations into fixed-time windows then pass them through feed-forward encoders (e.g., with deep networks), we show that there exists a more elegant approach - one that treats policy learning as modeling latent state dynamics in continuous-time. Specifically, we present InFuser, a unified architecture that trains continuous time-policies with Neural Controlled Differential Equations (CDEs). InFuser evolves a single latent state representation over time by (In)tegrating and (Fus)ing multi-sensory observations (arriving at different frequencies), and inferring actions in continuous-time. This enables policies that can react to multi-frequency multi-sensory feedback for truly end-to-end visuomotor control, without discrete-time assumptions. Behavior cloning experiments demonstrate that InFuser learns robust policies for dynamic tasks (e.g., swinging a ball into a cup) notably outperforming several baselines in settings where observations from one sensing modality can arrive at much sparser intervals than others.",
        "primary_area": "",
        "author": "Sumeet Singh;Francis McCann Ramirez;Jacob Varley;Andy Zeng;Vikas Sindhwani;Sumeet Singh;Francis McCann Ramirez;Jacob Varley;Andy Zeng;Vikas Sindhwani",
        "authorids": "/37085589975;/37089663117;/37085632898;/37086217185;/37282057000;/37085589975;/37089663117;/37085632898;/37086217185;/37282057000",
        "aff": "Robotics at Google, NYC; Google AI Resident, NYC; Robotics at Google, NYC; Robotics at Google, NYC; Robotics at Google, NYC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982210/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18145316588879926961&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google Robotics",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York City",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982194",
        "title": "NARF22: Neural Articulated Radiance Fields for Configuration-Aware Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "Articulated objects pose a unique challenge for robotic perception and manipulation. Their increased number of degrees-of-freedom makes tasks such as localization computationally difficult, while also making the process of realworld dataset collection unscalable. With the aim of addressing these scalability issues, we propose Neural Articulated Radiance Fields (NARF22), a pipeline which uses a fully-differentiable, configuration-parameterized Neural Radiance Field (NeRF) as a means of providing high quality renderings of articulated objects. NARF22 requires no explicit knowledge of the object structure at inference time. We propose a two-stage partsbased training mechanism which allows the object rendering models to generalize well across the configuration space even if the underlying training data has as few as one configuration represented. We demonstrate the efficacy of NARF22 by training configurable renderers on a real-world articulated tool dataset collected via a Fetch mobile manipulation robot. We show the applicability of the model to gradient-based inference methods through a configuration estimation and 6 degree-of-freedom pose refinement task.",
        "primary_area": "",
        "author": "Stanley Lewis;Jana Pavlasek;Odest Chadwicke Jenkins;Stanley Lewis;Jana Pavlasek;Odest Chadwicke Jenkins",
        "authorids": "/37088686540;/37088689981;/37297252400;/37088686540;/37088689981;/37297252400",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982194/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4258958333565650774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982207",
        "title": "NAUTS: Negotiation for Adaptation to Unstructured Terrain Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots operate in real-world off-road environments with unstructured terrains, the ability to adapt their navigational policy is critical for effective and safe navigation. However, off-road terrains introduce several challenges to robot navigation, including dynamic obstacles and terrain uncertainty, leading to inefficient traversal or navigation failures. To address these challenges, we introduce a novel approach for adaptation by negotiation that enables a ground robot to adjust its navigational behaviors through a negotiation process. Our approach first learns prediction models for various navigational policies to function as a terrain-aware joint local controller and planner. Then, through a new negotiation process, our approach learns from various policies' interactions with the environment to agree on the optimal combination of policies in an online fashion to adapt robot navigation to unstructured off-road terrains on the fly. Additionally, we implement a new optimization algorithm that offers the optimal solution for robot negotiation in real-time during execution. Experimental results have validated that our method for adaptation by negotiation outperforms previous methods for robot navigation, especially over unseen and uncertain dynamic terrains.",
        "primary_area": "",
        "author": "Sriram Siva;Maggie Wigness;John G. Rogers;Long Quang;Hao Zhang;Sriram Siva;Maggie Wigness;John G. Rogers;Long Quang;Hao Zhang",
        "authorids": "/37086453331;/37085661502;/37533731800;/37089663402;/37085545929;/37086453331;/37085661502;/37533731800;/37089663402;/37085545929",
        "aff": "Sriram Siva is with the Computer Science Department, Colorado School of Mines (Mines), Golden, CO, USA; DEV-COM Army Research Laboratory (ARL), Adelphi, MD, USA; DEV-COM Army Research Laboratory (ARL), Adelphi, MD, USA; DEV-COM Army Research Laboratory (ARL), Adelphi, MD, USA; Manning College of Information and Computer Sciences (CICS), University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982207/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12075062324442322406&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Colorado School of Mines;Army Research Laboratory;University of Massachusetts Amherst",
        "aff_unique_dep": "Computer Science Department;;Manning College of Information and Computer Sciences (CICS)",
        "aff_unique_url": "https://www.mines.edu;https://www.arl.army.mil;https://www.umass.edu",
        "aff_unique_abbr": "Mines;ARL;UMass Amherst",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Golden;Adelphi;Amherst",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981180",
        "title": "NDD: A 3D Point Cloud Descriptor Based on Normal Distribution for Loop Closure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection is a key technology for long-term robot navigation in complex environments. In this paper, we present a global descriptor, named Normal Distribution Descriptor (NDD), for 3D point cloud loop closure detection. The descriptor encodes both the probability density score and entropy of a point cloud as the descriptor. We also propose a fast rotation alignment process and use correlation coefficient as the similarity between descriptors. Experimental results show that our approach outperforms the state-of-the-art point cloud descriptors in both accuracy and efficency. The source code is available and can be integrated into existing LiDAR odometry and mapping (LOAM) systems.",
        "primary_area": "",
        "author": "Ruihao Zhou;Li He;Hong Zhang;Xubin Lin;Yisheng Guan;Ruihao Zhou;Li He;Hong Zhang;Xubin Lin;Yisheng Guan",
        "authorids": "/37089663143;/37086300847;/37280789900;/37086355958;/37402001000;/37089663143;/37086300847;/37280789900;/37086355958;/37402001000",
        "aff": "Ruihao Zhou, Xubin Lin and Yisheng Guan is with the Department of Electromechanical Engineering, Guangdong University of technology, China; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology, China; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology, China; Ruihao Zhou, Xubin Lin and Yisheng Guan is with the Department of Electromechanical Engineering, Guangdong University of technology, China; Ruihao Zhou, Xubin Lin and Yisheng Guan is with the Department of Electromechanical Engineering, Guangdong University of technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981180/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3671209794108719888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Guangdong University of Technology;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electromechanical Engineering;Department of Electronic and Electrical Engineering",
        "aff_unique_url": ";https://www.sustech.edu.cn",
        "aff_unique_abbr": ";SUSTech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981177",
        "title": "NMPC-LBF: Nonlinear MPC with Learned Barrier Function for Decentralized Safe Navigation of Multiple Robots in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a decentralized control approach based on a Nonlinear Model Predictive Control (NMPC) method that employs barrier certificates for safe navigation of multiple nonholonomic wheeled mobile robots in unknown environments with static and/or dynamic obstacles. This method incorporates a Learned Barrier Function (LBF) into the NMPC design in order to guarantee safe robot navigation, i.e., prevent robot collisions with other robots and the obstacles. We refer to our proposed control approach as NMPC-LBF. Since each robot does not have a priori knowledge about the obstacles and other robots, we use a Deep Neural Network (DeepNN) running in real-time on each robot to learn the Barrier Function (BF) only from the robot's LiDAR and odometry measurements. The DeepNN is trained to learn the BF that separates safe and unsafe regions. We implemented our proposed method on simulated and actual Turtlebot3 Burger robot(s) in different scenarios. The implementation results show the effectiveness of the NMPC-LBF method at ensuring safe navigation of the robots.",
        "primary_area": "",
        "author": "Amir Salimi Lafmejani;Spring Berman;Georgios Fainekos;Amir Salimi Lafmejani;Spring Berman;Georgios Fainekos",
        "authorids": "/37085690518;/37583148200;/38529834400;/37085690518;/37583148200;/38529834400",
        "aff": "School of Electrical Computer and Energy Engineering, Arizona State University (ASU), Tempe, AZ; School for Engineering of Matter, Transport and Energy, ASU, Tempe, AZ; School of Computing and Augmented Intelligence ASU, Tempe, AZ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981177/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2575265358768904512&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Electrical Computer and Energy Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982045",
        "title": "NavDreams: Towards Camera-Only RL Navigation Among Humans",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomously navigating a robot in everyday crowded spaces requires solving complex perception and planning challenges. When using only monocular image sensor data as input, classical two-dimensional planning approaches cannot be used. While images present a significant challenge when it comes to perception and planning, they also allow capturing potentially important details, such as complex geometry, body movement, and other visual cues. In order to successfully solve the navigation task from only images, algorithms must be able to model the scene and its dynamics using only this channel of information. We investigate whether the world model concept, which has shown state-of-the-art results for modeling and learning policies in Atari games as well as promising results in 2D LiDAR-based crowd navigation, can also be applied to the camera-based navigation problem. To this end, we create simulated environments where a robot must navigate past static and moving humans without colliding in order to reach its goal. We find that state-of-the-art methods are able to achieve success in solving the navigation problem, and can generate dream-like predictions of future image-sequences which show consistent geometry and moving persons. We are also able to show that policy performance in our high-fidelity sim2real simulation scenario transfers to the real world by testing the policy on a real robot. We make our simulator, models and experiments available at https://github.com/danieldugas/NavDreams.",
        "primary_area": "",
        "author": "Daniel Dugas;Olov Andersson;Roland Siegwart;Jen Jen Chung;Daniel Dugas;Olov Andersson;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37086030360;/37085816587;/37281398300;/37085668354;/37086030360;/37085816587;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982045/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15453121987755342929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981766",
        "title": "Navigating to Objects in Unseen Environments by Distance Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Object Goal Navigation (ObjectNav) task is to navigate an agent to an object category in unseen environments without a pre-built map. In this paper, we solve this task by predicting the distance to the target using semantically-related objects as cues. Based on the estimated distance to the target object, our method directly choose optimal midterm goals that are more likely to have a shorter path to the target. Specifically, based on the learned knowledge, our model takes a bird's-eye view semantic map as input, and estimates the path length from the frontier map cells to the target object. With the estimated distance map, the agent could simultaneously explore the environment and navigate to the target objects based on a simple human-designed strategy. Empirical results in visually realistic simulation environments show that the proposed method outperforms a wide range of baselines on success rate and efficiency. Real-robot experiment also demonstrates that our method generalizes well to the real world.",
        "primary_area": "",
        "author": "Minzhao Zhu;Binglei Zhao;Tao Kong;Minzhao Zhu;Binglei Zhao;Tao Kong",
        "authorids": "/37089661535;/37089663774;/37085802024;/37089661535;/37089663774;/37085802024",
        "aff": "ByteDance AI Lab, Beijing, China; ByteDance AI Lab, Beijing, China; ByteDance AI Lab, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981766/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10441785996160238131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ByteDance",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "https://www.bytedance.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981336",
        "title": "Navigating underground environments using simple topological representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Underground environments are some of the most challenging for autonomous navigation. The long, featureless corridors, loose and slippery soils, bad illumination and unavailability of global localization make many traditional approaches struggle. In this work, a topological-based navigation system is presented that enables autonomous navigation of a ground robot in mine-like environments relying exclusively on a high-level topological representation of the tunnel network. The topological representation is used to generate high-level topological instructions used by the agent to navigate through corridors and intersections. A convolutional neural network (CNN) is used to detect all the galleries accessible to a robot from its current position. The use of a CNN proves to be a reliable approach to this problem, capable of detecting the galleries correctly in a wide variety of situations. The CNN is also able to detect galleries even in the presence of obstacles, which motivates the development of a reactive navigation system that can effectively exploit the predictions of the gallery detection.",
        "primary_area": "",
        "author": "Lorenzo Cano;Alejandro R. Mosteo;Danilo Tardioli;Lorenzo Cano;Alejandro R. Mosteo;Danilo Tardioli",
        "authorids": "/37089660318;/37681666900;/37681377900;/37089660318;/37681666900;/37681377900",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981336/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7067631394565804025&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981587",
        "title": "Navigation Among Movable Obstacles with Object Localization using Photorealistic Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "While mobile navigation has been focused on obstacle avoidance, Navigation Among Movable Obstacles (NAMO) via interaction with the environment, is a problem that is still open and challenging. This paper, presents a novel system integration to handle NAMO using visual feedback. In order to explore the capabilities of our introduced system, we explore the solution of the problem via graph-based path planning in a photorealistic simulator (NVIDIA Isaac Sim), in order to identify if the simulation-to-reality (sim2real) problem in robot navigation can be resolved. We consider the case where a wheeled robot navigates in a warehouse, in which movable boxes are common obstacles. We enable online real-time object localization and obstacle movability detection, to either avoid objects or, if it is not possible, to clear them out from the robot planned path by using pushing actions. We firstly test the integrated system in photorealistic environments, and we then validate the method on a real-world mobile wheeled robot (UCL MPPL) and its on-board sensory and computing system.",
        "primary_area": "",
        "author": "Kirsty Ellis;Henry Zhang;Danail Stoyanov;Dimitrios Kanoulas;Kirsty Ellis;Henry Zhang;Danail Stoyanov;Dimitrios Kanoulas",
        "authorids": "/37088991641;/37089660635;/37563622300;/38230575500;/37088991641;/37089660635;/37563622300;/38230575500",
        "aff": "Department of Computer Science, University College London, London, UK; Department of Computer Science, University College London, London, UK; Department of Computer Science, University College London, London, UK; Department of Computer Science, University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981587/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8265881668590378127&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981404",
        "title": "Near Real-Time Vineyard Downy Mildew Detection and Severity Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The global grape and wine industry has been considerably impacted by diseases such as downy mildew (DM). Agricultural robots have demonstrated great potential to accurately and rapidly map DM infection for precision applications. Although the robots can autonomously acquire high-resolution images in the vineyard, data processing is mostly performed offline because of network infrastructure and onboard computing power constraints, limiting the use of agricultural robots for field operations. To address this issue, we developed a semantic segmentation model based on the modified DeepLabv3 network for near real time DM segmentation in high resolution images. Compared with state-of-the-art real time semantic segmentation models, the developed one achieved the best efficiency-accuracy balance on the DM dataset using embedded computing devices that can be easily integrated with commercial robotic platforms. DM severity estimation pipeline based on the model also showed a comparable measurement accuracy and statistical power in differentiation of fungicide treatments as the one based on offline semantic segmentation models. This enables the use of robotic perception systems for field operations.",
        "primary_area": "",
        "author": "Ertai Liu;Kaitlin Gold;Lance Cadle-Davidson;David Combs;Yu Jiang;Ertai Liu;Kaitlin Gold;Lance Cadle-Davidson;David Combs;Yu Jiang",
        "authorids": "/37089659467;/37089662712;/37089661034;/37089661271;/37089661346;/37089659467;/37089662712;/37089661034;/37089661271;/37089661346",
        "aff": "Department of Biological and Environmental Engineering, Cornell University, Ithaca, NY, USA; PPPMB Section, SIPS, Cornell AgriTech, Geneva, NY, USA; USDA ARS Grape Genetics Research Unit, Geneva, NY, USA; PPPMB Section, SIPS, Cornell AgriTech, Geneva, NY, USA; Department of Biological and Environmental Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981404/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10917469174662233877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Cornell University;USDA Agricultural Research Service",
        "aff_unique_dep": "Department of Biological and Environmental Engineering;Grape Genetics Research Unit",
        "aff_unique_url": "https://www.cornell.edu;https://www.ars.usda.gov",
        "aff_unique_abbr": "Cornell;USDA ARS",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Ithaca;Geneva",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981823",
        "title": "Neural-Guided Runtime Prediction of Planners for Improved Motion and Task Planning with Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The past decade has amply demonstrated the remarkable functionality that can be realized by learning complex input/output relationships. Algorithmically, one of the most important and opaque relationships is that between a problem's structure and an effective solution method. Here, we quantitatively connect the structure of a planning problem to the performance of a given sampling-based motion planning (SBMP) algorithm. We demonstrate that the geometric relationships of motion planning problems can be well captured by graph neural networks (GNNs) to predict SBMP runtime. By using an algorithm portfolio we show that GNN predictions of runtime on particular problems can be leveraged to accelerate online motion planning in both navigation and manipulation tasks. Moreover, the problem-to-runtime map can be inverted to identify subproblems easier to solve by particular SBMPs. We provide a motivating example of how this knowledge may be used to improve integrated task and motion planning on simulated examples. These successes rely on the relational structure of GNNs to capture scalable generalization from low-dimensional navigation tasks to high degree-of-freedom manipulation tasks in 3d environments.",
        "primary_area": "",
        "author": "Simon Odense;Kamal Gupta;William G. Macready;Simon Odense;Kamal Gupta;William G. Macready",
        "authorids": "/37085836296;/37279577500;/37088221244;/37085836296;/37279577500;/37088221244",
        "aff": "Sanctuary Cognitive Systems Corp. and School of Engineering Science, Simon Fraser University; School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada; Sanctuary Cognitive Systems Corp., Vancouver, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981823/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9245956856636932015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Simon Fraser University;Sanctuary Cognitive Systems Corp.",
        "aff_unique_dep": "School of Engineering Science;",
        "aff_unique_url": "https://www.sfu.ca;",
        "aff_unique_abbr": "SFU;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Burnaby;Vancouver",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981886",
        "title": "New Objects on the Road? No Problem, We'll Learn Them Too",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection plays an essential role in providing localization, path planning, and decision making capabilities in autonomous navigation systems. However, existing object detection models are trained and tested on a fixed number of known classes. This setting makes the object detection model difficult to generalize well in real-world road scenarios while encountering an unknown object. We address this problem by introducing our framework that handles the issue of unknown object detection and updates the model when unknown object labels are available. Next, our solution includes three major components that address the inherent problems present in the road scene datasets. The novel components are a) Feature-Mix that improves the unknown object detection by widening the gap between known and unknown classes in latent feature space, b) Focal regression loss handling the problem of improving small object detection and intra-class scale variation, and c) Curriculum learning further enhances the detection of small objects. We use Indian Driving Dataset (IDD) and Berkeley Deep Drive (BDD) dataset for evaluation. Our solution provides state-of-the-art performance on open-world evaluation metrics. We hope this work will create new directions for open-world object detection for road scenes, making it more reliable and robust autonomous systems.",
        "primary_area": "",
        "author": "Deepak Kumar Singh;Shyam Nandan Rai;K J Joseph;Rohit Saluja;Vineeth N Balasubramanian;Chetan Arora;Anbumani Subramanian;C.V. Jawahar;Deepak Kumar Singh;Shyam Nandan Rai;K J Joseph;Rohit Saluja;Vineeth N Balasubramanian;Chetan Arora;Anbumani Subramanian;C.V. Jawahar",
        "authorids": "/37085389322;/37088402827;/37086698188;/37086288748;/37409169100;/37282971700;/37086702670;/37270075200;/37085389322;/37088402827;/37086698188;/37086288748;/37409169100;/37282971700;/37086702670;/37270075200",
        "aff": "CVIT - IIIT Hyderabad, India; Politecnico di Torino, Italy; IIT Hyderabad, India; CVIT - IIIT Hyderabad, India; IIT Hyderabad, India; IIT Delhi, India; CVIT - IIIT Hyderabad, India; CVIT - IIIT Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981886/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:W_i6FKEcstMJ:scholar.google.com/&scioq=New+Objects+on+the+Road%3F+No+Problem,+We%27ll+Learn+Them+Too&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;2;3;0;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;Politecnico di Torino;Indian Institute of Technology Hyderabad;Indian Institute of Technology Delhi",
        "aff_unique_dep": "Center for Visual Information Technology;;;",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in;https://www.polito.it;https://www.iith.ac.in;https://www.iitd.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad;Polito;IIT Hyderabad;IITD",
        "aff_campus_unique_index": "0;0;0;0;2;0;0",
        "aff_campus_unique": "Hyderabad;;Delhi",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0",
        "aff_country_unique": "India;Italy"
    },
    {
        "id": "9981922",
        "title": "Newton-PnP: Real-time Visual Navigation for Autonomous Toy-Drones",
        "track": "main",
        "status": "Poster",
        "abstract": "The Perspective-n-Point problem aims to estimate the relative pose between a calibrated monocular camera and a known 3D model, by aligning pairs of 2D captured image points to their corresponding 3D points in the model. We suggest an algorithm that runs on weak IoT devices in real-time but still provides provable theoretical guarantees for both running time and correctness. Existing solvers provide only one of these requirements. Our main motivation was to turn the popular DJI's Tello Drone (<90gr, <100) into an autonomous drone that navigates in an indoor environment with no external human/laptop/sensor, by simply attaching a Raspberry PI Zero (<9gr, <100) into an autonomous drone that navigates in an indoor environment with no external human/laptop/sensor, by simply attaching a Raspberry PI Zero (<9gr, <25) to it. This tiny micro-processor takes as input a real-time video from a tiny RGB camera, and runs our PnP solver on-board. Extensive experimental results, open source code, and a demonstration video are included.",
        "primary_area": "",
        "author": "Ibrahim Jubran;Fares Fares;Yuval Alfassi;Firas Ayoub;Dan Feldman;Ibrahim Jubran;Fares Fares;Yuval Alfassi;Firas Ayoub;Dan Feldman",
        "authorids": "/37088526370;/37089779805;/37088892644;/37089662918;/38540643000;/37088526370;/37089779805;/37088892644;/37089662918;/38540643000",
        "aff": "Computer Science Department, Robotics & Big Data Labs, University of Haifa, Israel; Computer Science Department, Robotics & Big Data Labs, University of Haifa, Israel; Computer Science Department, Robotics & Big Data Labs, University of Haifa, Israel; Computer Science Department, Robotics & Big Data Labs, University of Haifa, Israel; Computer Science Department, Robotics & Big Data Labs, University of Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981922/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3069911076127995991&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Haifa",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.haifa.ac.il",
        "aff_unique_abbr": "UoH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981614",
        "title": "Noisy Agents: Self-supervised Exploration by Predicting Auditory Events",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans integrate multiple sensory modalities (e.g., visual and audio) to build a causal understanding of the physical world. In this work, we propose a novel type of intrinsic motivation for Reinforcement Learning (RL) that encourages the agent to understand the causal effect of its actions through auditory event prediction. First, we allow the agent to collect a small amount of acoustic data and use K-means to discover underlying auditory event clusters. We then train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. We first conduct proof-of-concept experiments using a set of Atari games for an in-depth analysis of our module. We then apply our model to embodied audio-visual exploration using the Habitat simulator and active exploration with a rolling robot using the ThreeDWorld (TDW) simulator. Experimental results demonstrate the advantages of using audio signals over vision-based models as intrinsic rewards to guide RL explorations.",
        "primary_area": "",
        "author": "Chuang Gan;Xiaoyu Chen;Phillip Isola;Antonio Torralba;Joshua B. Tenenbaum;Chuang Gan;Xiaoyu Chen;Phillip Isola;Antonio Torralba;Joshua B. Tenenbaum",
        "authorids": "/37085611353;/37089663510;/37945396900;/38183107900;/37622583000;/37085611353;/37089663510;/37945396900;/38183107900;/37622583000",
        "aff": "MIT-IBM Watson AI Lab; Tsinghua University; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981614/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16431875766027666090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Tsinghua University",
        "aff_unique_dep": "IBM Watson AI Lab;",
        "aff_unique_url": "https://www.mitibmwatsonailab.org;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "MIT-IBM AI Lab;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9982067",
        "title": "Non-Parametric Modeling of Spatio-Temporal Human Activity Based on Mobile Robot Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a non-parametric spatiotemporal model for mapping human activity by mobile autonomous robots in a long-term context. Based on Variational Gaussian Process Regression, the model incorporates prior information of spatial and temporal-periodic dependencies to create a continuous representation of human occurrences. The inhomogeneous data distribution resulting from movements of the robot is included in the model via a heteroscedastic likelihood function and can be accounted for as predictive uncertainty. Using a sparse formulation, data sets over multiple weeks and several hundred square meters can be used for model creation. The experimental evaluation, based on multi-week data sets, demonstrates that the proposed approach outperforms the state of the art both in terms of predictive quality and subsequent path planning.",
        "primary_area": "",
        "author": "Marvin Stuede;Moritz Schappler;Marvin Stuede;Moritz Schappler",
        "authorids": "/37086937070;/37086131932;/37086937070;/37086131932",
        "aff": "Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982067/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6220012272627942451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Mechatronic Systems",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Garbsen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982070",
        "title": "Non-Submodular Maximization via the Greedy Algorithm and the Effects of Limited Information in Multi-Agent Execution",
        "track": "main",
        "status": "Poster",
        "abstract": "We provide theoretical bounds on the worst case performance of the greedy algorithm in seeking to maximize a normalized, monotone, but not necessarily submodular ob-jective function under a simple partition matroid constraint. We also provide worst case bounds on the performance of the greedy algorithm in the case that limited information is available at each planning step. We specifically consider limited information as a result of unreliable communications during distributed execution of the greedy algorithm. We utilize notions of curvature for normalized, monotone set functions to develop the bounds provided in this work. To demonstrate the value of the bounds provided in this work, we analyze a variant of the benefit of search objective function and show, using real-world data collected by an autonomous underwater vehicle, that theoretical approximation guarantees are achieved despite non-submodularity of the objective function.",
        "primary_area": "",
        "author": "Benjamin Biggs;James McMahon;Philip Baldoni;Daniel J. Stilwell;Benjamin Biggs;James McMahon;Philip Baldoni;Daniel J. Stilwell",
        "authorids": "/37087324207;/37085353635;/37086071951;/37283170000;/37087324207;/37085353635;/37086071951;/37283170000",
        "aff": "Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; US Naval Research Laboratory, Acoustics Division, Washington D.C., USA; US Naval Research Laboratory, Acoustics Division, Washington D.C., USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982070/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16347594900405758328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Virginia Tech;US Naval Research Laboratory",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Acoustics Division",
        "aff_unique_url": "https://www.vt.edu;https://www.nrl.navy.mil",
        "aff_unique_abbr": "VT;NRL",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Blacksburg;Washington D.C.",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981333",
        "title": "Non-blocking Asynchronous Training for Reinforcement Learning in Real-World Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Reinforcement Learning (DRL) faces challenges bridging the sim-to-real gap to enable real-world applications. In contrast to the simulated environments used in conventional DRL training, real-world systems are non-linear and evolve in an asynchronous fashion; sensors and actuators have limited precision; communication channels are noisy; and many components introduce variable delays. While these issues are known to many researchers, published methods for systematically tackling the problem of DRL training under these conditions without using simulation are sparse in the field. To this end, this paper proposes a non-blocking and asynchronous DRL training architecture for non-linear, real-time dynamical systems tailored to handling variable delays. Compared to conventional DRL training, we: (i) decouple the RL loop into separate processes run independently at their own frequencies, (ii) further decouple collection of transition tuples (s_{t}, at_{t}, s_{t+1})(s_{t}, at_{t}, s_{t+1}) via asynchronous and independent streaming of both actions and observations, and (iii) mitigate the effects of delays and increase sample efficiency by providing delay-length measurements to the training loop and regular retraining of the DRL network. This allows the action step time to be tuned to find an optimal control frequency for a given system, and handles streamed observations that arrive with random delays and independently of action timing. We demonstrate the efficacy of this architecture with a physical implementations of a commodity-grade swing-up pendulum and a quadrupedal robot. Our architecture achieves the best results balancing the pendulum for almost entire length of the episode, compared to conventional blocking approaches which fail to learn effective policies. Our results show that these techniques scale to more complex tasks such as quadrupedal locomotion.",
        "primary_area": "",
        "author": "Peter B\u00f6hm;Pauline Pounds;Archie C. Chapman;Peter B\u00f6hm;Pauline Pounds;Archie C. Chapman",
        "authorids": "/37089658275;/37571590000;/37078347500;/37089658275;/37571590000;/37078347500",
        "aff": "ITEE, University of Queensland, Australia; ITEE, University of Queensland, Australia; ITEE, University of Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981333/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12487511993683402766&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Queensland",
        "aff_unique_dep": "ITEE",
        "aff_unique_url": "https://www.uq.edu.au",
        "aff_unique_abbr": "UQ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981045",
        "title": "Nonlinear Model Predictive Control for Human-Robot Handover with Application to the Aerial Case",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, we consider the problem of delivering an object to a human coworker by means of an aerial robot (AR). To this aim, we present an ergonomics-aware Nonlinear Model Predictive Control (NMPC) designed to autonomously perform the handover. The method is general enough to be applied to any multi-rotor aerial vehicle (MRAV) with a minimal adaptation of the robot model. The formulation of the optimal control problem steers the AR toward a handover location by optimizing the human coworker ergonomics, which includes the predicted arm joint torques of the human. The motion task is expressed in a frame relative to the human, whose motion model is included in the equations of the NMPC. This allows the controller to promptly adapt to the human movements by predicting her future poses over the horizon. The control framework also accounts for the problem of maintaining visibility on the human coworker, while respecting both the actuation and state limits of the robot. Additionally, a safety barrier is embedded in the controller to avoid any risk of collision with the human partner. Realistic simulations are performed to validate the feasibility of the approach and the source code of the implementation is released open-source.",
        "primary_area": "",
        "author": "Gianluca Corsini;Martin Jacquet;Hemjyoti Das;Amr Afifi;Daniel Sidobre;Antonio Franchi;Gianluca Corsini;Martin Jacquet;Hemjyoti Das;Amr Afifi;Daniel Sidobre;Antonio Franchi",
        "authorids": "/37088507210;/37088506435;/37085997626;/37089004302;/37378284900;/37541446900;/37088507210;/37088506435;/37085997626;/37089004302;/37378284900;/37541446900",
        "aff": "LAAS-CNRS, CNRS, INSA, UPS, Universit\u00e9 de Toulouse, Toulouse, France; LAAS-CNRS, CNRS, INSA, UPS, Universit\u00e9 de Toulouse, Toulouse, France; Robotics and Mechatronics lab, Faculty of Electrical Engineering, Mathematics & Computer Science\u2019, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics lab, Faculty of Electrical Engineering, Mathematics & Computer Science\u2019, University of Twente, Enschede, The Netherlands; LAAS-CNRS, CNRS, INSA, UPS, Universit\u00e9 de Toulouse, Toulouse, France; LAAS-CNRS, CNRS, INSA, UPS, Universit\u00e9 de Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981045/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15903399616749961232&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "LAAS-CNRS;University of Twente",
        "aff_unique_dep": ";Faculty of Electrical Engineering, Mathematics & Computer Science",
        "aff_unique_url": "https://www.laas.fr;https://www.utwente.nl",
        "aff_unique_abbr": "LAAS-CNRS;UT",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Toulouse;Enschede",
        "aff_country_unique_index": "0;0;1;1;0;0",
        "aff_country_unique": "France;Netherlands"
    },
    {
        "id": "9981066",
        "title": "Nonlinear Model Predictive Control with Cost Function Scheduling for a Wheeled Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing a cost function for nonlinear model predictive control (MPC) with a sparse/binary stage cost is challenging. This paper proposes a novel MPC approach with a scheduled quadratic stage cost function that approximates the true stage cost in order to optimally control a nonlinear system with a sparse/binary stage cost. The cost function parameter is optimally scheduled by a parameter scheduling policy obtained by solving a Markov decision process (MDP) constructed from sampled trajectories from any nonlinear MPC solver. The pro-posed approach is implemented into a differential drive wheeled mobile robot (WMR) designed for smart warehousing via the robot operating system (ROS) framework. The simulation and experimental results successfully demonstrate the effectiveness of our MPC approach in cases of the point stabilization problem of a differential drive WMR.",
        "primary_area": "",
        "author": "Jaehyun Lim;Hyeonwoo Lee;Jongeun Choi;Jaehyun Lim;Hyeonwoo Lee;Jongeun Choi",
        "authorids": "/37087407081;/37089658443;/37405969800;/37087407081;/37089658443;/37405969800",
        "aff": "School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981066/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4719665747657116886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yonsei University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.yonsei.ac.kr",
        "aff_unique_abbr": "Yonsei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981932",
        "title": "Novel Supernumerary Robotic Limb based on Variable Stiffness Actuators for Hemiplegic Patients Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Loss of upper extremity motor control and function is an unremitting symptom in post-stroke patients. This would impose hardships on accomplishing their daily life activities. Supernumerary robotic limbs (SRLs) were introduced as a solution to regain the lost Degrees of Freedom (DoFs) by introducing an independent new limb. The actuation systems in SRL can be categorized into rigid and soft actuators. Soft actuators have proven advantageous over their rigid counterparts through intrinsic safety, cost, and energy efficiency. However, they suffer from low stiffness, which jeopardizes their accuracy. Variable Stiffness Actuators (VSAs) are newly developed technologies that have been proven to ensure accuracy and safety. In this paper, we introduce the novel Supernumerary Robotic Limb based on Variable Stiffness Actuators. Based on our knowledge, the proposed proof-of-concept SRL is the first that utilizes Variable Stiffness Actuators. The developed SRL would assist post-stroke patients in bi-manual tasks, e.g., eating with a fork and knife. The modeling, design, and realization of the system are illustrated. The proposed SRL was evaluated and verified for its accuracy via predefined trajectories. The safety was verified by utilizing the momentum observer for collision detection, and several post-collision reaction strategies were evaluated through the Soft Tissue Injury Test. The assistance process is qualitatively verified through standard user-satisfaction questionnaire.",
        "primary_area": "",
        "author": "Basma B. Hasanen;Mohammad I. Awad;Mohamed N. Boushaki;Zhenwei Niu;Mohammed A. Ramadan;Irfan Hussain;Basma B. Hasanen;Mohammad I. Awad;Mohamed N. Boushaki;Zhenwei Niu;Mohammed A. Ramadan;Irfan Hussain",
        "authorids": "/37089661618;/37086120571;/37085570605;/37088954763;/37089663300;/37085379035;/37089661618;/37086120571;/37085570605;/37088954763;/37089663300;/37085379035",
        "aff": "Mechanical Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE; Mechanical Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE; Center of Autonomous Robotics Systems, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE; Mechanical Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE; Mechanical Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE; Mechanical Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981932/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11961988175292440356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Khalifa University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.khalifa.edu",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Abu Dhabi",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Arab Emirates"
    },
    {
        "id": "9982135",
        "title": "OCTOANTS: A Heterogeneous Lightweight Intelligent Multi-Robot Collaboration System with Resource-constrained IoT Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "As the focus on highly intelligent robots continues, a problem that cannot be ignored has emerged: resource con-straints. Considering the game problem of resource limitation and the level of intelligence, we focus on lightweight intelligence. This work is a further refinement of our previous work, a heterogeneous lightweight intelligent multi-robot system. In-spired by the nature creatures \u201coctopus\u201d and \u201cants\u201d. First, we propose a heterogeneous centralized-distributed architecture, which can make robots collaboration more flexible and non-redundant. Second, to reflect lightweight intelligence, we use the Raspberry Pi, a low computing and power consumption internet of things (IoT) device, as a processing platform and first propose a quantitative definition of the lightweight intelligent system. Then, combining the centralized-distributed architecture and the lightweight computing platform, we propose an adapted algorithm called OCTOANTS and apply it to the simultaneous localization and mapping (SLAM) field. The OCTOANTS architecture consists of one brain and eight tentacles, which can achieve complex things with proper collaboration between them. Finally, we use heterogeneous cameras and heterogeneous algorithms to form a lightweight intelligent collaborative system that can run in the real world. On the low-grade platform Raspberry Pi our heterogeneous tentacles frame rate can reach 41fps and 99.8fps respectively, power consumption is only 2W and 1.2W. At the same time, our heterogeneous system is on average 7.2% more accurate than the state-of-the-art homogeneous system and can be applied to a wider range of application scenarios, demonstrating the superiority and feasibility of our OCTOANTS.",
        "primary_area": "",
        "author": "Qian Zhang;Ruiyang Quan;Siqin Qimuge;Peimin Xia;Jiaheng Wang;Xin Zan;Fangshi Wang;Changchuan Chen;Qi Wei;Huichan Zhao;Xinjun Liu;Fei Qiao;Qian Zhang;Ruiyang Quan;Siqin Qimuge;Peimin Xia;Jiaheng Wang;Xin Zan;Fangshi Wang;Changchuan Chen;Qi Wei;Huichan Zhao;Xinjun Liu;Fei Qiao",
        "authorids": "/37087095238;/37089579698;/37089578357;/37089663443;/37089661295;/37086021921;/37290980000;/37088601266;/37582779500;/37088219492;/37085996613;/37272195200;/37087095238;/37089579698;/37089578357;/37089663443;/37089661295;/37086021921;/37290980000;/37088601266;/37582779500;/37088219492;/37085996613;/37272195200",
        "aff": "Tsinghua University, Beijing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; University of Science and Technology Beijing, Beijing, China; Xi'an Jiaotong University, Xi'an, China; Beijing Jiaotong University, Beijing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982135/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=494018695512411511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;2;2;3;4;2;1;0;0;0;0",
        "aff_unique_norm": "Tsinghua University;Chongqing University of Posts and Telecommunications;Beijing Jiao Tong University;University of Science and Technology Beijing;Xi'an Jiao Tong University",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;http://www.bjtu.edu.cn;http://www.ustb.edu.cn;http://en.xjtu.edu.cn/",
        "aff_unique_abbr": "THU;;BJTU;USTB;XJTU",
        "aff_campus_unique_index": "0;1;0;0;0;2;0;1;0;0;0;0",
        "aff_campus_unique": "Beijing;Chongqing;Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981452",
        "title": "Object Pose Estimation using Mid-level Visual Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a novel pose estimation model for object categories that can be effectively transferred to pre-viously unseen environments. The deep convolutional network models (CNN) for pose estimation are typically trained and evaluated on datasets specifically curated for object detection, pose estimation, or 3D reconstruction, which requires large amounts of training data. In this work, we propose a model for pose estimation that can be trained with small amount of data and is built on the top of generic mid-level represen-tations [33] (e.g. surface normal estimation and re-shading). These representations are trained on a large dataset without requiring pose and object annotations. Later on, the predictions are refined with a small CNN neural network that exploits object masks and silhouette retrieval. The presented approach achieves superior performance on the Pix3D dataset [26] and shows nearly 35 % improvement over the existing models when only 25 % of the training data is available. We show that the approach is favorable when it comes to generalization and transfer to novel environments. Towards this end, we introduce a new pose estimation benchmark for commonly encountered furniture categories on challenging Active Vision Dataset [1] and evaluated the models trained on the Pix3D dataset.",
        "primary_area": "",
        "author": "Negar Nejatishahidin;Pooya Fayyazsanavi;Jana Ko\u0161ecka;Negar Nejatishahidin;Pooya Fayyazsanavi;Jana Ko\u0161ecka",
        "authorids": "/37089663802;/37089660165;/37298538900;/37089663802;/37089660165;/37298538900",
        "aff": "George Mason University; George Mason University; George Mason University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981452/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9407008907341436550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981386",
        "title": "Object Surface Recognition using Microphone Array by Acoustic Standing Wave",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a microphone array with a speaker to recognize the shape of the surface of the target object by using the standing wave between the transmitted and the reflected acoustic signals. Because the profile of the distance spectrum encodes both the distance to the target and the distance to the edges of the target's surface, this paper proposes to fuse distance spectra using a microphone array to estimate the three-dimensional structure of the target surface. The proposed approach was verified through numerical simulations and outdoor field experiments. Results showed the effectiveness of the method as it could extract the shape of the board located 2m in front of the microphone array by using a chirp tone with 20kHz bandwidth.",
        "primary_area": "",
        "author": "Tomoya Manabe;Rikuto Fukunaga;Kei Nakatsuma;Makoto Kumon;Tomoya Manabe;Rikuto Fukunaga;Kei Nakatsuma;Makoto Kumon",
        "authorids": "/37089662694;/37089658535;/37403313000;/37296098600;/37089662694;/37089658535;/37403313000;/37296098600",
        "aff": "Graduate School of Science and Technology, Kumamoto University; Graduate School of Science and Technology, Kumamoto University; Faculty of Advanced Science and Technology, Kumamoto University, Kumamoto, Japan; Faculty of Advanced Science and Technology, Kumamoto University, Kumamoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981386/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ybyTuLsOHw0J:scholar.google.com/&scioq=Object+Surface+Recognition+using+Microphone+Array+by+Acoustic+Standing+Wave&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Kumamoto University",
        "aff_unique_dep": "Graduate School of Science and Technology",
        "aff_unique_url": "https://www.kumamoto-u.ac.jp",
        "aff_unique_abbr": "Kumamoto U",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Kumamoto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981858",
        "title": "Obstacle Avoidance of Resilient UAV Swarm Formation with Active Sensing System in the Dense Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a perception-shared and swarm trajectory global optimal (STGO) algorithm fused UAVs formation motion planning framework aided by an active sensing system. First, the point cloud received by each UAV is fit by the gaussian mixture model (GMM) and transmitted in the swarm. Resampling from the received GMM contributes to a global map, which is used as the foundation for consensus. Second, to improve flight safety, an active sensing system is designed to plan the observation angle of each UAV considering the unknown field, overlap of the field of view (FOV), velocity direction and smoothness of yaw rotation, and this planning problem is solved by the distributed particle swarm optimization (DPSO) algorithm. Last, for the formation motion planning, to ensure obstacle avoidance, the formation structure is allowed for affine transformation and is treated as the soft constraint on the control points of the B-spline. Besides, the STGO is introduced to avoid local minima. The combination of GMM communication and STGO guarantees a safe and strict consensus between UAVs. Tests on different formations in the simulation show that our algorithm can contribute to a strict consensus and has a success rate of at least 80% for obstacle avoidance in a dense environment. Besides, the active sensing system can increase the success rate of obstacle avoidance from 50% to 100% in some scenarios.",
        "primary_area": "",
        "author": "Peng Peng;Wei Dong;Gang Chen;Xiangyang Zhu;Peng Peng;Wei Dong;Gang Chen;Xiangyang Zhu",
        "authorids": "/37089620864;/37287161400;/37932918200;/37278847400;/37089620864;/37287161400;/37932918200;/37278847400",
        "aff": "State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiaotong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiaotong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiaotong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiaotong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981858/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17042578507203154931&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981428",
        "title": "Obstacle Aware Sampling for Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many path planning algorithms are based on sampling the state space. While this approach is very simple, it can become costly when the obstacles are unknown, since samples hitting these obstacles are wasted. The goal of this paper is to efficiently identify obstacles in a map and remove them from the sampling space. To this end, we propose a pre-processing algorithm for space exploration that enables more efficient sampling. We show that it can boost the performance of other space sampling methods and path planners. Our approach is based on the fact that a convex obstacle can be approximated provably well by its minimum volume enclosing ellipsoid (MVEE), and a non-convex obstacle may be partitioned into convex shapes. Our main contribution is an al-gorithm that strategically finds a small sample, called the active-coreset, that adaptively samples the space via membership-oracle such that the MVEE of the coreset approximates the MVEE of the obstacle. Experimental results confirm the ef-fectiveness of our approach across multiple planners based on rapidly-exploring random trees, showing significant improve-ment in terms of time and path length.",
        "primary_area": "",
        "author": "Murad Tukan;Alaa Maalouf;Dan Feldman;Roi Poranne;Murad Tukan;Alaa Maalouf;Dan Feldman;Roi Poranne",
        "authorids": "/37089661436;/37089318922;/38540643000;/37085580542;/37089661436;/37089318922;/38540643000;/37085580542",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981428/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3347954340865378516&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9981865",
        "title": "OdomBeyondVision: An Indoor Multi-modal Multi-platform Odometry Dataset Beyond the Visible Spectrum",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a multimodal indoor odometry dataset, OdomBeyondVision, featuring multiple sensors across the different spectrum and collected with different mobile platforms. Not only does OdomBeyondVision contain the traditional navigation sensors, sensors such as IMUs, mechanical LiDAR, RGBD camera, it also includes several emerging sensors such as the single-chip mmWave radar, LWIR thermal camera and solid-state LiDAR. With the above sensors on UAV, UGV and handheld platforms, we respectively recorded the multimodal odometry data and their movement trajectories in various indoor scenes and different illumination conditions. We release the exemplar radar, radar-inertial and thermal-inertial odometry implementations to demonstrate their results for future works to compare against and improve upon. The full dataset including toolkit and documentation is publicly available at: https://github.com/MAPS-Lab/OdomBeyondVision.",
        "primary_area": "",
        "author": "Peize Li;Kaiwen Cai;Muhamad Risqi U. Saputra;Zhuangzhuang Dai;Chris Xiaoxuan Lu;Peize Li;Kaiwen Cai;Muhamad Risqi U. Saputra;Zhuangzhuang Dai;Chris Xiaoxuan Lu",
        "authorids": "/37089659203;/37089489008;/37086934305;/37085774002;/37086107301;/37089659203;/37089489008;/37086934305;/37085774002;/37086107301",
        "aff": "School of Informatics, University of Edinburgh, United Kingdom; University of Liverpool, United Kingdom; Monash University, Indonesia; University of Oxford, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981865/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16589961619396687474&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Edinburgh;University of Liverpool;Monash University;University of Oxford",
        "aff_unique_dep": "School of Informatics;;;",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.liverpool.ac.uk;https://www.monash.edu;https://www.ox.ac.uk",
        "aff_unique_abbr": "Edinburgh;Liv Uni;Monash;Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;Indonesia"
    },
    {
        "id": "9982030",
        "title": "OmniWheg: An Omnidirectional Wheel-Leg Transformable Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design, analysis, and performance evaluation of an omnidirectional transformable wheel-leg robot called OmniWheg. We design a novel mechanism consisting of a separable omni-wheel and 4-bar linkages, allowing the robot to transform between omni-wheeled and legged modes smoothly. In wheeled mode, the robot can move in all directions and efficiently adjust the relative position of its wheels, while it can overcome common obstacles in legged mode, such as stairs and steps. Unlike other articles studying whegs, this implementation with omnidirectional wheels allows the correction of misalignments between right and left wheels before traversing obstacles, which effectively improves the success rate and simplifies the preparation process before the wheel-leg transformation. We describe the design concept, mechanism, and the dynamic characteristic of the wheel-leg structure. We then evaluate its performance in various scenarios, including passing obstacles, climbing steps of different heights, and turning/moving omnidirectionally. Our results confirm that this mobile platform can overcome common indoor obstacles and move flexibly on the flat ground with the new transformable wheel-leg mechanism, while keeping a high degree of stability.",
        "primary_area": "",
        "author": "Ruixiang Cao;Jun Gu;Chen Yu;Andre Rosendo;Ruixiang Cao;Jun Gu;Chen Yu;Andre Rosendo",
        "authorids": "/37089663614;/37089348034;/37089472108;/37845873600;/37089663614;/37089348034;/37089472108;/37845873600",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982030/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12472983475030958742&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "School of Information Science and Technology",
        "aff_unique_url": "https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981314",
        "title": "Omnidirectional walking of a quadruped robot enabled by compressible tendon-driven soft actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Using soft actuators as legs, soft quadruped robots have shown great potential in traversing unstructured and complex terrains and environments. However, unlike rigid robots whose gaits can be generated using foot pattern design and kinematic model of the rigid legs, the gait generation of soft quadruped robots remains challenging due to the high DoFs of the soft actuators and the uncertain deformations during their contact with the ground. This study is based on a quadruped robot using four Compressible Tendon-driven Soft Actuators (CTSAs) as the legs, with the actuator's compression motion being utilized to improve the walking performance of the robot. For the gait design, an inverse kinematics model considering the compression of the CTSA is developed and validated in simulation. Based on this model, walking gaits realizing different motion speeds and directions are generated. Closed loop direction and speed controllers are developed for increasing the robustness and precision of the robot walking. Simulation and experimental results show that omnidirectional locomotion and complex walking tasks can be realized by tuning the gait parameters and the motions are resistant to external disturbances.",
        "primary_area": "",
        "author": "Qinglei Ji;Shuo Fu;Lei Feng;George Andrikopoulos;Xi Vincent Wang;Lihui Wang;Qinglei Ji;Shuo Fu;Lei Feng;George Andrikopoulos;Xi Vincent Wang;Lihui Wang",
        "authorids": "/37088526448;/37089662494;/37290912800;/37947798500;/37086750258;/37085643741;/37088526448;/37089662494;/37290912800;/37947798500;/37086750258;/37085643741",
        "aff": "Department of Machine Design, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Machine Design, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Machine Design, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Machine Design, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981314/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1721136654512612009&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Machine Design",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9982242",
        "title": "On CAD Informed Adaptive Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a robotic assembly system that streamlines the design-to-make workflow for going from a CAD model of a product assembly to a fully programmed and adaptive assembly process. Our system captures (in the CAD tool) the intent of the assembly process for a specific robotic workcell and generates a recipe of task-level instructions. By integrating visual sensing with deep-learned perception models, the robots infer the necessary actions to assemble the design from the generated recipe. The perception models are trained directly from simulation, allowing the system to identify various parts based on CAD information. We demonstrate the system with a workcell of two robots to assemble interlocking 3D part designs. We first build and tune the assembly process in simulation, verifying the generated recipe. Finally, the real robotic workcell assembles the design using the same behavior.",
        "primary_area": "",
        "author": "Yotto Koga;Heather Kerrick;Sachin Chitta;Yotto Koga;Heather Kerrick;Sachin Chitta",
        "authorids": "/37088904896;/37089660004;/37279717300;/37088904896;/37089660004;/37279717300",
        "aff": "Autodesk Research, San Francisco, CA; Autodesk Fusion 360, San Francisco, CA; Autodesk Research, San Francisco, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982242/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4174698034391884842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Autodesk Research;Autodesk",
        "aff_unique_dep": ";Fusion 360",
        "aff_unique_url": "https://research.autodesk.com;https://www.autodesk.com/products/fusion-360",
        "aff_unique_abbr": "Autodesk;Autodesk",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Francisco",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982002",
        "title": "On Coverage Control for Limited Range Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a coverage based control algorithm to coordinate a group of autonomous robots. Most of the solutions presented in the literature rely on an exact Voronoi partitioning, whose computation requires complete knowledge of the environment to be covered. This can be achieved only by robots with unlimited sensing capabilities, or through communication among robots in a limited sensing scenario. To overcome these limitations, we present a distributed control strategy to cover an unknown environment with a group of robots with limited sensing capabilities and in the absence of reliable communication. The control law is based on a limited Voronoi partitioning of the sensing area, and we demonstrate that the group of robots can optimally cover the environment using only information that is locally detected (without communication). The proposed method is validated by means of simulations and experiments carried out on a group of mobile robots.",
        "primary_area": "",
        "author": "Federico Pratissoli;Beatrice Capelli;Lorenzo Sabattini;Federico Pratissoli;Beatrice Capelli;Lorenzo Sabattini",
        "authorids": "/37087091605;/37086348616;/37594737400;/37087091605;/37086348616;/37594737400",
        "aff": "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982002/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1659700797753564034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods for Engineering (DISMI)",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981313",
        "title": "On Robotic Manipulation of Flexible Flat Cables: Employing a Multi-Modal Gripper with Dexterous Tips, Active Nails, and a Reconfigurable Suction Cup Module",
        "track": "main",
        "status": "Poster",
        "abstract": "A popular solution for connecting different components in modern electronics, such as mobile phones, laptops, tablets, etc, is the use of flexible flat cables (FFC). Typically, it takes hours of repetition from a highly trained worker, or a high precision autonomous robot with specialised end effectors to reliably manage the installation of these cables. Human workers are prone to error, and cannot work endlessly without a break, while the robots often come with a significant expense, and require a substantial amount of time to program and reprogram. Additionally, the use of sophisticated sensing elements further increases the complexity of the required control system. As a result, the performance and robustness of such systems is far from sufficient, hindering their mass adoption. The manipulation of FFCs is also quite challenging. In this work, we focus on the robotic manipulation of a plethora of flexible cables, proposing a multi-modal gripper with locally-dexterous tips and active fingernails. The fingers of the gripper are equipped with: i) locally-dexterous fingertips that accommodate manipulation-capable degrees of freedom, ii) a combination of Nitinol-based active fingernails and suction cups that allow picking up and handling of cables that rest on flat surfaces, and iii) compliant finger-pads that conform to the object surface to increase grasping stability. The proposed robotic gripper is equipped with a camera and a perception system that allow for the execution of complex cable manipulation and assembly tasks in dynamic environments.",
        "primary_area": "",
        "author": "Joao Buzzatto;Jayden Chapman;Mojtaba Shahmohammadi;Felipe Sanches;Mahla Nejati;Saori Matsunaga;Rintaro Haraguchi;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis;Joao Buzzatto;Jayden Chapman;Mojtaba Shahmohammadi;Felipe Sanches;Mahla Nejati;Saori Matsunaga;Rintaro Haraguchi;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis",
        "authorids": "/37088599578;/37088482031;/37089186373;/37088226006;/37086828218;/37088580339;/37565174400;/37087323162;/37300950400;/38558084100;/37088599578;/37088482031;/37089186373;/37088226006;/37086828218;/37088580339;/37565174400;/37087323162;/37300950400;/38558084100",
        "aff": "New Dexterity research group, Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand; New Dexterity research group, Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand; New Dexterity research group, Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand; New Dexterity research group, Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, Department of Electrical, Computer and Software Engineering, The University of Auckland, New Zealand; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Advanced Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Centre for Automation and Robotic Engineering Science, Department of Electrical, Computer and Software Engineering, The University of Auckland, New Zealand; New Dexterity research group, Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981313/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2029981740444370444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;1;1;1;0;0",
        "aff_unique_norm": "University of Auckland;Mitsubishi Electric Corporation",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;Information Technology R&D Center",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "UoA;MEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1;1;1;0;0",
        "aff_country_unique": "New Zealand;Japan"
    },
    {
        "id": "9981359",
        "title": "On Safety Testing, Validation, and Characterization with Scenario-Sampling: A Case Study of Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The dynamic response of the legged robot locomotion is non-Lipschitz and can be stochastic due to environmental uncertainties. To test, validate, and characterize the safety performance of legged robots, existing solutions on observed and inferred risk can be incomplete and sampling inefficient. Some formal verification methods suffer from the model precision and other surrogate assumptions. In this paper, we propose a scenario sampling based testing framework that characterizes the overall safety performance of a legged robot by specifying (i) where (in terms of a set of states) the robot is potentially safe, and (ii) how safe the robot is within the specified set. The framework can also help certify the commercial deployment of the legged robot in real-world environment along with human and compare safety performance among legged robots with different mechanical structures and dynamic properties. The proposed framework is further deployed to evaluate a group of state-of-the-art legged robot locomotion controllers from various model-based, deep neural network involved, and reinforcement learning based methods in the literature. Among a series of intended work domains of the studied legged robots (e.g. tracking speed on sloped surface, with abrupt changes on demanded velocity, and against adversarial push-over disturbances), we show that the method can adequately capture the overall safety characterization and the subtle performance insights. Many of the observed safety outcomes, to the best of our knowledge, have never been reported by the existing work in the legged robot literature.",
        "primary_area": "",
        "author": "Bowen Weng;Guillermo A. Castillo;Wei Zhang;Ayonga Hereid;Bowen Weng;Guillermo A. Castillo;Wei Zhang;Ayonga Hereid",
        "authorids": "/37086936098;/37086936437;/37089656248;/37077055000;/37086936098;/37086936437;/37089656248;/37077055000",
        "aff": "Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981359/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15649084654040685252&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Ohio State University;Southern University of Science and Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.osu.edu;https://www.sustech.edu.cn",
        "aff_unique_abbr": "OSU;SUSTech",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Columbus;Shenzhen",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981557",
        "title": "On Stabilizing Communication Law for Bilateral Force-reflecting Teleoperation Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This brief proposes a new stabilizing communication law to allow the wave transformation-based teleoperation architecture to accommodate direct environmental contact force feedback, potentially increasing the human operator's experience of telepresence. Simulation results are provided.",
        "primary_area": "",
        "author": "Ho Duc Tho;Takanori Miyoshi;Ho Duc Tho;Takanori Miyoshi",
        "authorids": "/37086199346;/37276340100;/37086199346;/37276340100",
        "aff": "Department of System Safety, Nagaoka University of Technology, Niigata, Japan; Department of System Safety, Nagaoka University of Technology, Niigata, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981557/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18167186823049167110&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nagaoka University of Technology",
        "aff_unique_dep": "Department of System Safety",
        "aff_unique_url": "https://www.nut.ac.jp",
        "aff_unique_abbr": "NUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Niigata",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981736",
        "title": "On a Balanced Delta Robot for Precise Aerial Manipulation: Implementation, Testing, and Lessons for Future Designs",
        "track": "main",
        "status": "Poster",
        "abstract": "Using a delta-manipulator for stabilisation of an end-effector to perform precise spatial positioning is a current area of interest in aerial manipulation. High speed precision movements of a manipulator can cause disturbances to the aerial platform, which hinders trajectory tracking and in some cases could be sufficient to cause a loss of control of the vehicle. In this paper, a statically balanced delta aerial manipulator is developed and evaluated. The system is balanced using three counter-masses to reduce the force imparted onto the base and thus reduce perturbations to the movement of the drone. The system is thoroughly tested following trajectories while mounted to a force sensor and while on-board an aerial vehicle. Results show that the forces transmitted to the base in all axes are reduced considerably, however improvements in overall flight accuracy are not observed in aerial settings. Design lessons to make a balanced delta-manipulator viable for practical implementation on an aerial vehicle are discussed in depth. A video summarising the flight testing results is available at https://youtu.be/fXKnosnVKCk.",
        "primary_area": "",
        "author": "Angus B. Clark;Nicholas Baron;Lachlan Orr;Mirko Kovac;Nicolas Rojas;Angus B. Clark;Nicholas Baron;Lachlan Orr;Mirko Kovac;Nicolas Rojas",
        "authorids": "/37086808936;/37088416297;/37089004703;/37085542534;/37990657400;/37086808936;/37088416297;/37089004703;/37085542534;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; Ocado Technology, Aquarius House, Welwyn Garden City, UK; Empa, Swiss Federal Laboratories for Materials Science and Technology, D\u00fcbendorf, Switzerland; Empa, Swiss Federal Laboratories for Materials Science and Technology, D\u00fcbendorf, Switzerland; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981736/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14108374484693248340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "Imperial College London;Ocado Technology;Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Dyson School of Design Engineering;;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://technology.ocado.com;https://www.empa.ch",
        "aff_unique_abbr": "ICL;;Empa",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "London;Welwyn Garden City;D\u00fcbendorf",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United Kingdom;Switzerland"
    },
    {
        "id": "9981833",
        "title": "On the Communication Channel in Bilateral Teleoperation: An Experimental Study for Ethernet, WiFi, LTE and 5G",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperated robots are believed to play an important role for future applications in industry, medicine and other domains. Examples for this are remote assembly and maintenance, surgery, diagnosis or deep-sea and space exploration. Such applications are made possible by state-of-the-art tactile manipulators, well-researched control schemes and novel communication technologies such as the fifth generation of mobile communication (5G). The achievable performance is highly dependent on the communication delay and thus on the distance between leader and follower station, as well as the potentially used wireless protocol. Specially in this regard, 5G is a promising technology compared to the other communication protocols for transferring tactile information. In this paper, we introduce our telepresence reference platform, which can be used for empirical evaluation of different algorithms and communications. Comparative analysis are conducted to capture the influence of wireless communication protocols on telepresence systems consisting of complex robotic arms. The experiment compares the influence of 5G, LTE and WiFi communication protocols with regard to the motion and force tracking performance of the system.",
        "primary_area": "",
        "author": "Xiao Chen;Lars Johannsmeier;Hamid Sadeghian;Erfan Shahriari;Martin Danneberg;Anselm Nicklas;Fan Wu;Gerhard Fettweis;Sami Haddadin;Xiao Chen;Lars Johannsmeier;Hamid Sadeghian;Erfan Shahriari;Martin Danneberg;Anselm Nicklas;Fan Wu;Gerhard Fettweis;Sami Haddadin",
        "authorids": "/37088992427;/37085776668;/38539589600;/37085822407;/38234217200;/37085581261;/37086454850;/37271859700;/37542865300;/37088992427;/37085776668;/38539589600;/37085822407;/38234217200;/37085581261;/37086454850;/37271859700;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; University of Isfahan, Isfahan; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Vodafone Chair for Mobile Communications Systems, Technical University of Dresden, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI); Centre for Tactile Internet with Human-in-the-Loop (CeTI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981833/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18429335973175552805&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;2;0;0;3;3",
        "aff_unique_norm": "Technical University of Munich;University of Isfahan;Technical University of Dresden;Centre for Tactile Internet with Human-in-the-Loop",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence;;Vodafone Chair for Mobile Communications Systems;",
        "aff_unique_url": "https://www.tum.de;http://www.ui.ac.ir;https://tu-dresden.de;",
        "aff_unique_abbr": "TUM;;TUD;CeTI",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Munich;Isfahan;",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "Germany;Iran;"
    },
    {
        "id": "9981866",
        "title": "On the Importance of Label Encoding and Uncertainty Estimation for Robotic Grasp Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated grasping of arbitrary objects is an essential skill for many applications such as smart manufacturing and human robot interaction. This makes grasp detection a vital skill for automated robotic systems. Recent work in model-free grasp detection uses point cloud data as input and typically outperforms the earlier work on RGB(D)-based methods. We show that RGB(D)-based methods are being underestimated due to suboptimal label encodings used for training. Using the evaluation pipeline of the GraspNet-1Billion dataset, we investigate different encodings and propose a novel encoding that significantly improves grasp detection on depth images. Additionally, we show shortcomings of the 2D rectangle grasps supplied by the GraspNet-1Billion dataset and propose a filtering scheme by which the ground truth labels can be improved significantly. Furthermore, we apply established methods for uncertainty estimation on our trained models since knowing when we can trust the model's decisions provides an advantage for real-world application. By doing so, we are the first to directly estimate uncertainties of detected grasps. We also investigate the applicability of the estimated aleatoric and epistemic uncertainties based on their theoretical properties. Additionally, we demonstrate the correlation between estimated uncertainties and grasp quality, thus improving selection of high quality grasp detections. By all these modifications, our approach using only depth images can compete with point-cloud-based approaches for grasp detection despite the lower degree of freedom for grasp poses in 2D image space.",
        "primary_area": "",
        "author": "Benedict Stephan;Dustin Aganian;Lars Hinneburg;Markus Eisenbach;Steffen M\u00fcller;Horst-Michael Gross;Benedict Stephan;Dustin Aganian;Lars Hinneburg;Markus Eisenbach;Steffen M\u00fcller;Horst-Michael Gross",
        "authorids": "/37089315589;/37088981497;/37089663460;/37318406900;/37691026700;/37270612700;/37089315589;/37088981497;/37089663460;/37318406900;/37691026700;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981866/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16355279631482891674&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981227",
        "title": "On the Performance and Passivity of Admittance Control with Feed-Forward Input",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper analyzes the effect of control param-eters of feed-forward and inner loop velocity controller in an admittance control scheme on the performance and passivity. The interaction force, inertia, and damping compensation were considered as the feed-forward input. Sufficient conditions and guidelines for each parameter were provided to enable the implementation of a wide range of desired admittance satis-fying passivity. The proposed guidelines were verified through experiments.",
        "primary_area": "",
        "author": "Dongwoo Ko;Donghyeon Lee;Wan Kyun Chung;Keehoon Kim;Dongwoo Ko;Donghyeon Lee;Wan Kyun Chung;Keehoon Kim",
        "authorids": "/37086549660;/37677365900;/37280299100;/37066398600;/37086549660;/37677365900;/37280299100;/37066398600",
        "aff": "Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981227/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16085424689289446542&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982085",
        "title": "On-Device CPU Scheduling for Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots have to take highly responsive real-time actions, driven by complex decisions involving a pipeline of sensing, perception, planning, and reaction tasks. These tasks must be scheduled on resource-constrained devices such that the performance goals and the requirements of the application are met. This is a difficult problem that requires handling multiple scheduling dimensions, and variations in computational resource usage and availability. In practice, system designers manually tune parameters for their specific hardware and application, which results in poor generalization and increases the development burden. In this work, we highlight the emerging need for scheduling CPU resources at runtime in robot systems. We use robot navigation as a case-study to understand the key scheduling requirements for such systems. Armed with this understanding, we develop a CPU scheduling framework, Catan, that dynamically schedules compute resources across different components of an app so as to meet the specified application requirements. Through experiments with a prototype implemented on ROS, we show the impact of system scheduling on meeting the application's performance goals, and how Catan dynamically adapts to runtime variations.",
        "primary_area": "",
        "author": "Aditi Partap;Samuel Grayson;Muhammad Huzaifa;Sarita Adve;Brighten Godfrey;Saurabh Gupta;Kris Hauser;Radhika Mittal;Aditi Partap;Samuel Grayson;Muhammad Huzaifa;Sarita Adve;Brighten Godfrey;Saurabh Gupta;Kris Hauser;Radhika Mittal",
        "authorids": "/37089663518;/37089240300;/37085671025;/37275579100;/37283758700;/37089922149;/37543748800;/37088771985;/37089663518;/37089240300;/37085671025;/37275579100;/37283758700;/37089922149;/37543748800;/37088771985",
        "aff": "Stanford University; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982085/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7762817331549164109&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;1;1",
        "aff_unique_norm": "Stanford University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://illinois.edu",
        "aff_unique_abbr": "Stanford;UIUC",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;1",
        "aff_campus_unique": "Stanford;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981953",
        "title": "One Object at a Time: Accurate and Robust Structure From Motion for Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A gaze-fixating robot perceives distance to the fixated object and relative positions of surrounding objects immediately, accurately, and robustly. We show how fixation, which is the act of looking at one object while moving, exploits regularities in the geometry of 3D space to obtain this information. These regularities introduce rotation-translation couplings that are not commonly used in structure from motion. To validate, we use a Franka Emika Robot with an RGB camera. We a) find that error in distance estimate is less than 5 mm at a distance of 15 cm, and b) show how relative position can be used to find obstacles under challenging scenarios. We combine accurate distance estimates and obstacle information into a reactive robot behavior that is able to pick up objects of unknown size, while impeded by unforeseen obstacles.",
        "primary_area": "",
        "author": "Aravind Battaje;Oliver Brock;Aravind Battaje;Oliver Brock",
        "authorids": "/37089354195;/37279727100;/37089354195;/37279727100",
        "aff": "Science of Intelligence, Research Cluster of Excellence, Berlin; Science of Intelligence, Research Cluster of Excellence, Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981953/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18388446660968580635&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Science of Intelligence",
        "aff_unique_dep": "Research Cluster of Excellence",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981308",
        "title": "One RING to Rule Them All: Radon Sinogram for Place Recognition, Orientation and Translation Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-based global localization is a fundamental problem for mobile robots. It consists of two stages, place recognition and pose estimation, which yields the current orientation and translation, using only the current scan as query and a database of map scans. Inspired by the definition of a recognized place, we consider that a good global localization solution should keep the pose estimation accuracy with a lower place density. Following this idea, we propose a novel framework towards sparse place-based global localization, which utilizes a unified and learning-free representation, Radon sinogram (RING), for all sub-tasks. Based on the theoretical derivation, a translation invariant descriptor and an orientation invariant metric are proposed for place recognition, achieving certifiable robustness against arbitrary orientation and large translation between query and map scan. In addition, we also utilize the property of RING to propose a global convergent solver for both orientation and translation estimation, arriving at global localization. Evaluation of the proposed RING based framework validates the feasibility and demonstrates a superior performance even under a lower place density.",
        "primary_area": "",
        "author": "Sha Lu;Xuecheng Xu;Huan Yin;Zexi Chen;Rong Xiong;Yue Wang;Sha Lu;Xuecheng Xu;Huan Yin;Zexi Chen;Rong Xiong;Yue Wang",
        "authorids": "/37089449878;/37087245452;/37086355830;/37088601253;/37271511300;/37072299700;/37089449878;/37087245452;/37086355830;/37088601253;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong SAR; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981308/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12487877833597001772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Zhejiang University;Hong Kong University of Science and Technology",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control;Department of Electronic and Computer Engineering",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.ust.hk",
        "aff_unique_abbr": "ZJU;HKUST",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Hangzhou;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982095",
        "title": "Online 3D Bin Packing Reinforcement Learning Solution with Buffer",
        "track": "main",
        "status": "Poster",
        "abstract": "The 3D Bin Packing Problem (3D-BPP) is one of the most demanded yet challenging problems in industry, where an agent must pack variable size items delivered in sequence into a finite bin with the aim to maximize the space utilization. It represents a strongly NP-Hard optimization problem such that no solution has been offered to date with high performance in space utilization. In this paper, we present a new reinforcement learning (RL) framework for a 3D-BPP solution for improving performance. First, a buffer is introduced to allow multi-item action selection. By increasing the degree of freedom in action selection, a more complex policy that results in better packing performance can be derived. Second, we propose an agnostic data augmentation strategy that exploits both bin item symmetries for improving sample efficiency. Third, we implement a model-based RL method adapted from the popular algorithm AlphaGo, which has shown superhuman performance in zero-sum games. Our adaptation is capable of working in single-player and score based environments. In spite of the fact that AlphaGo versions are known to be computationally heavy, we manage to train the proposed framework with a single thread and GPU, while obtaining a solution that outperforms the state-of-the-art results in space utilization.",
        "primary_area": "",
        "author": "Aaron Valero Puche;Sukhan Lee;Aaron Valero Puche;Sukhan Lee",
        "authorids": "/37089032900;/37293425600;/37089032900;/37293425600",
        "aff": "Artificial Intelligence School, Sungkyunkwan University, Suwon, South Korea; Artificial Intelligence School, Sungkyunkwan University, Suwon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982095/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7171051757087441001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Sungkyunkwan University",
        "aff_unique_dep": "Artificial Intelligence School",
        "aff_unique_url": "http://www.sungkyunkwan.edu",
        "aff_unique_abbr": "SKKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981680",
        "title": "Online Adaptive Compensation for Model Uncertainty Using Extreme Learning Machine-based Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "A control barrier functions-based quadratic programming (CBF-QP) method has emerged as a controller synthesis tool to assure safety of autonomous systems owing to the appealing safe forward invariant set. However, the provable safety relies on a precisely described dynamic model, which is not always available in practice. Recent works leverage learning to compensate model uncertainty for a CBF controller. However, these approaches based on reinforcement learning or episodic learning are limited to dealing with time-invariant uncertainty. Also, the reinforcement learning approach learns the uncertainty offline, while episodic learning only updates the controller after a batch of data is available by the end of an episode. Instead, we propose a novel tuning extreme learning machine (tELM)-based CBF controller that can compensate time-variant and time-invariant model uncertainty adaptively in an online manner. We validate our approach's effectiveness in a simulation of an Adaptive Cruise Control (ACC) system.",
        "primary_area": "",
        "author": "Emanuel Munoz;Dvij Kalaria;Qin Lin;John M. Dolan;Emanuel Munoz;Dvij Kalaria;Qin Lin;John M. Dolan",
        "authorids": "/37089658735;/37089454263;/37086031992;/37283756800;/37089658735;/37089454263;/37086031992;/37283756800",
        "aff": "Robotics Institute, Carnegie Mellon University; Department of Computer Science and Engineering, IIT Kharagpur, India; Electrical Engineering and Computer Science Department, Cleveland State University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981680/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1631257342137074391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Indian Institute of Technology Kharagpur;Cleveland State University",
        "aff_unique_dep": "Robotics Institute;Department of Computer Science and Engineering;Electrical Engineering and Computer Science Department",
        "aff_unique_url": "https://www.cmu.edu;https://www.iitkgp.ac.in;https://www.csuohio.edu",
        "aff_unique_abbr": "CMU;IIT Kharagpur;CSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Kharagpur;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9981667",
        "title": "Online Complete Coverage Path Planning of a Reconfigurable Robot using Glasius Bio-inspired Neural Network and Genetic Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Area coverage is crucial for robotics applications such as cleaning, painting, exploration, and inspections. Hinged reconfigurable robots have been introduced for these application domains to improve the area coverage performance. However, the existing coverage algorithms of hinged reconfigurable robots require improvements in the aspects; consideration of beyond a limited set of reconfigurable shapes, coordinated reconfiguration and navigation, and online decision-making. Therefore, this paper proposes a novel online Complete Coverage Path Planning (CCPP) method for a hinged reconfigurable robot. The proposed CCPP method is designed with two sub-methods, the Global Coverage Path Planning (GCPP) and Local Coverage Path Planning (LCPP). The GCPP method has been implemented, adapting a Glasius Bio-inspired Neural Network (GBNN) that performs online path planning considering a fixed shape for the robot. Obstacle regions that the GCPP would not adequately cover due to access constraints are covered by the LCPP method that considers concurrent reconfiguration and navigation of the robot. A genetic algorithm determines the reconfiguration parameters that ascertain collision-free coverage and access of obstacle regions. Experimental results validate that the proposed online CCPP method is effective in ascertaining the complete area coverage in heterogeneous environments, including dynamic workspaces. Furthermore, the deployment of the LCPP method can considerably improve the coverage.",
        "primary_area": "",
        "author": "S. M. Bhagya P. Samarakoon;M. A. Viraj J. Muthugala;Mohan Rajesh Elara;S. M. Bhagya P. Samarakoon;M. A. Viraj J. Muthugala;Mohan Rajesh Elara",
        "authorids": "/37086182161;/37085785341;/37546093700;/37086182161;/37085785341;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981667/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12847941502329084322&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981254",
        "title": "Online Extrinsic Correction of Multi-Camera Systems by Low-Dimensional Parameterization of Physical Deformation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose the online extrinsic correction method that effectively optimizes the extrinsic parameters of multi-camera systems used in visual SLAM. In the typical visual SLAM systems that use multi-camera settings, the intrinsic and extrinsic parameters of the cameras are calculated through offline calibration, which is used as the fixed constraints in online execution. However, the camera rig can be physically deformed by shock or vibration, and the deviation from the offline calibration parameters can adversely affect the accuracy of triangulation and pose estimation. Therefore, it is crucial to maintain the accurate calibration of the camera rigs continuously throughout the execution. The previous online calibration methods optimize the extrinsic camera parameters in a full degree of freedom(DoF) by minimizing the reprojection error, but the limited visual information available online may bias the resulting camera poses. From the observation that the cameras are mounted on a physical body and the patterns that the body can be deformed is restricted and not completely free, we propose to model the pattern of physical rig deformation by external forces in advance, and then use the pre-trained low-dimensional deformation model to robustly and accurately estimate the changed camera poses in real-time. The proposed method consists of two steps. First, the physical model of the camera system is constructed in a simulator and the actual deformations by various external disturbances are recorded, and the deformation patterns are modeled by a PCA algorithm to build a low-dimensional model. In online execution, the camera poses are updated by minimizing the reprojection errors of visual features within the pre-trained low-dimensional parameterization, instead of optimizing all camera poses independently. Through the experiments in synthetic environments, the proposed online extrinsic correction method shows that it produces more accurate and robust camera pos... Show More",
        "primary_area": "",
        "author": "Sangheon Yang;Jongwoo Lim;Sangheon Yang;Jongwoo Lim",
        "authorids": "/37089662181;/37075566700;/37089662181;/37075566700",
        "aff": "Department of Artificial Intelligence, Hanyang University, Seoul, Korea; MultiplEYE Co., Ltd., Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981254/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2049152504465855845&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Hanyang University;MultiplEYE Co., Ltd.",
        "aff_unique_dep": "Department of Artificial Intelligence;",
        "aff_unique_url": "http://www.hanyang.ac.kr;",
        "aff_unique_abbr": "HYU;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981052",
        "title": "Online Learning Feedback Control Considering Hysteresis for Musculoskeletal Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "While the musculoskeletal humanoid has various biomimetic benefits, its complex modeling is difficult, and many learning control methods have been developed. However, for the actual robot, the hysteresis of its joint angle tracking is still an obstacle, and realizing target posture quickly and accurately has been difficult. Therefore, we develop a feedback control method considering the hysteresis. To solve the problem in feedback controls caused by the closed-link structure of the musculoskeletal body, we update a neural network representing the relationship between the error of joint angles and the change in target muscle lengths online, and realize target joint angles accurately in a few trials. We compare the performance of several configurations with various network structures and loss definitions, and verify the effectiveness of this study on an actual musculoskeletal humanoid, Musashi.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Kei Okada;Masayuki Inaba;Kento Kawaharazuka;Kei Okada;Masayuki Inaba",
        "authorids": "/37086101930;/37280639000;/37286658200;/37086101930;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981052/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:C08A1I7xykkJ:scholar.google.com/&scioq=Online+Learning+Feedback+Control+Considering+Hysteresis+for+Musculoskeletal+Structures&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981137",
        "title": "Online Localisation and Colored Mesh Reconstruction Architecture for 3D Visual Feedback in Robotic Exploration Missions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an Online Localisation and Colored Mesh Reconstruction (OLCMR) ROS perception architecture for ground exploration robots aiming to perform robust Simultaneous Localisation And Mapping (SLAM) in challenging unknown environments and provide an associated colored 3D mesh representation in real time. It is intended to be used by a remote human operator to easily visualise the mapped environment during or after the mission or as a development base for further researches in the field of exploration robotics. The architecture is mainly composed of carefully-selected open-source ROS implementations of a LiDAR-based SLAM algorithm alongside a colored surface reconstruction procedure using a point cloud and RGB camera images projected into the 3D space. The overall performances are evaluated on the Newer College handheld LiDAR-Vision reference dataset and on two experimental trajectories gathered on board of representative wheeled robots in respectively urban and countryside outdoor environments.",
        "primary_area": "",
        "author": "Quentin Serdel;Christophe Grand;Julien Marzat;Julien Moras;Quentin Serdel;Christophe Grand;Julien Marzat;Julien Moras",
        "authorids": "/37089663467;/38335131900;/37857075800;/37706535000;/37089663467;/38335131900;/37857075800;/37706535000",
        "aff": "DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France; DTIS, ONERA University of Toulouse, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981137/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12051539672659639248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ONERA;ONERA University of Toulouse",
        "aff_unique_dep": "DTIS;DTIS",
        "aff_unique_url": "https://www.onera.fr;https://www.onera.fr",
        "aff_unique_abbr": "ONERA;ONERA",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Palaiseau;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981080",
        "title": "Online Model Learning for Shape Control of Deformable Linear Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional approaches to manipulating the state of deformable linear objects (DLOs) - i.e., cables, ropes - rely on model-based planning. However, constructing an accurate dynamic model of a DLO is challenging due to the complexity of interactions and a high number of degrees of freedom. This renders the task of achieving a desired DLO shape particularly difficult and motivates the use of model-free alternatives, which while maintaining generality suffer from a high sample complexity. In this paper, we bridge the gap between these fundamentally different approaches and propose a framework that learns dynamic models of DLOs through trial-and-error interaction. Akin to model-based reinforcement learning (RL), we interleave learning and exploration to solve a 3D shape control task for a DLO. Our approach requires only a fraction of the interaction samples of the current state-of-the-art model-free RL alternatives to achieve superior shape control performance. Unlike offline model learning, our approach does not require expert knowledge for data collection, retains the ability to explore, and automatically selects relevant experience.",
        "primary_area": "",
        "author": "Yuxuan Yang;Johannes A. Stork;Todor Stoyanov;Yuxuan Yang;Johannes A. Stork;Todor Stoyanov",
        "authorids": "/37088996310;/37544515300;/37601557800;/37088996310;/37544515300;/37601557800",
        "aff": "Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, \u00d6rebro, Sweden; Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, \u00d6rebro, Sweden; Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, \u00d6rebro, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981080/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9600661524145737877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "\u00d6rebro University",
        "aff_unique_dep": "Center for Applied Autonomous Sensor Systems (AASS)",
        "aff_unique_url": "https://www.oru.se",
        "aff_unique_abbr": "\u00d6rebro U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "\u00d6rebro",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9981713",
        "title": "Online Planning for Interactive-POMDPs using Nested Monte Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to make good decisions in partially observed non-cooperative multi-agent scenarios is important for robots to interact effectively in human environments. A robust framework for such decision-making problems is the Interactive Partially Observable Markov Decision Processes (I-POMDPs), which explicitly models the other agents' beliefs up to a finite reasoning level in order to more accurately predict their actions. This paper proposes a new online approximate solver for I-POMDPs, called Interactive Nested Tree Monte-Carlo Planning (I-NTMCP), that combines Monte Carlo Tree Search with the finite nested-reasoning construction of I-POMDPs. Unlike existing full-width I-POMDP planners, I-NTMCP focuses planning on the set of beliefs at each nesting level which are reachable under an optimal policy and uses sampling to construct and update policies at each nesting level, online. This strategy enables I-NTMCP to plan effectively in significantly larger I-POMDP problems and to deeper reasoning levels than has previously been possible. We demonstrate I-NTMCP's effectiveness on two competitive environments. The results indicate that I-NTMCP can generate substantially better policies up to more than 50\u00d7 faster than I-POMDP Lite - one of the fastest I-POMDP solvers today. In the pursuit-evasion domain, we show I-NTMCP can plan effectively in a complex problem with over 88K states, which is two orders of magnitude larger than existing I-POMDP planning benchmark problems.",
        "primary_area": "",
        "author": "Jonathon Schwartz;Ruijia Zhou;Hanna Kurniawati;Jonathon Schwartz;Ruijia Zhou;Hanna Kurniawati",
        "authorids": "/37089661001;/37089663139;/37565882700;/37089661001;/37089663139;/37565882700",
        "aff": "School of Computing, Australian National University; School of Computing, Australian National University; School of Computing, Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981713/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12734560192044592868&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9981703",
        "title": "OpenDR: An Open Toolkit for Enabling High Performance, Low Footprint Deep Learning for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing Deep Learning (DL) frameworks typically do not provide ready-to-use solutions for robotics, where very specific learning, reasoning, and embodiment problems exist. Their relatively steep learning curve and the different methodologies employed by DL compared to traditional approaches, along with the high complexity of DL models, which often leads to the need of employing specialized hardware accelerators, further increase the effort and cost needed to employ DL models in robotics. Also, most of the existing DL methods follow a static inference paradigm, as inherited by the traditional computer vision pipelines, ignoring active perception, which can be employed to actively interact with the environment in order to increase perception accuracy. In this paper, we present the Open Deep Learning Toolkit for Robotics (OpenDR). OpenDR aims at developing an open, non-proprietary, efficient, and modular toolkit that can be easily used by robotics companies and research institutions to efficiently develop and deploy AI and cognition technologies to robotics applications, providing a solid step towards addressing the aforementioned challenges. We also detail the design choices, along with an abstract interface that was created to overcome these challenges. This interface can describe various robotic tasks, spanning beyond traditional DL cognition and inference, as known by existing frameworks, incorporating openness, homogeneity and robotics-oriented perception e.g., through active perception, as its core design principles.",
        "primary_area": "",
        "author": "N. Passalis;S. Pedrazzi;R. Babuska;W. Burgard;D. Dias;F. Ferro;M. Gabbouj;O. Green;A. Iosifidis;E. Kayacan;J. Kober;O. Michel;N. Nikolaidis;P. Nousi;R. Pieters;M. Tzelepi;A. Valada;A. Tefas;N. Passalis;S. Pedrazzi;R. Babuska;W. Burgard;D. Dias;F. Ferro;M. Gabbouj;O. Green;A. Iosifidis;E. Kayacan;J. Kober;O. Michel;N. Nikolaidis;P. Nousi;R. Pieters;M. Tzelepi;A. Valada;A. Tefas",
        "authorids": "/37085793507;/37089661434;/37270682600;/37270485300;/37089659999;/37659768500;/37276556200;/37088712370;/37601485000;/37595300900;/37542833400;/37089660941;/37267383700;/37086233384;/37086512826;/37085385069;/38075825200;/37299690600;/37085793507;/37089661434;/37270682600;/37270485300;/37089659999;/37659768500;/37276556200;/37088712370;/37601485000;/37595300900;/37542833400;/37089660941;/37267383700;/37086233384;/37086512826;/37085385069;/38075825200;/37299690600",
        "aff": "Dept. of Informatics, Aristotle University of Thessaloniki, Greece; Cyberbotics, Switzerland; Dept. of Cognitive Robotics, Delft University of Technology, The Netherlands; Dept. of Computer Science, University of Freiburg, Germany; Cyberbotics, Switzerland; PAL Robotics, Spain; Computing Sciences, and Automation Technology and Mechanical Engineering, Tampere University, Finland; Agrointelli, Denmark; Department of Electrical and Computer Engineering, Aarhus University, Denmark; Department of Electrical and Computer Engineering, Aarhus University, Denmark; Dept. of Cognitive Robotics, Delft University of Technology, The Netherlands; Cyberbotics, Switzerland; Dept. of Informatics, Aristotle University of Thessaloniki, Greece; Dept. of Informatics, Aristotle University of Thessaloniki, Greece; Computing Sciences, and Automation Technology and Mechanical Engineering, Tampere University, Finland; Dept. of Informatics, Aristotle University of Thessaloniki, Greece; Dept. of Computer Science, University of Freiburg, Germany; Dept. of Informatics, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981703/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10627755509533881489&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 36,
        "aff_unique_index": "0;1;2;3;1;4;5;6;7;7;2;1;0;0;5;0;3;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki;Cyberbotics;Delft University of Technology;University of Freiburg;PAL Robotics;Tampere University;Agrointelli;Aarhus University",
        "aff_unique_dep": "Dept. of Informatics;;Dept. of Cognitive Robotics;Dept. of Computer Science;;Computing Sciences, and Automation Technology and Mechanical Engineering;;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr;http://www.cyberbotics.com;https://www.tudelft.nl;https://www.uni-freiburg.de;;https://www.tuni.fi;;https://www.au.dk",
        "aff_unique_abbr": "AUTH;;TUDelft;Uni Freiburg;;Tuni;;AU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Thessaloniki;",
        "aff_country_unique_index": "0;1;2;3;1;4;5;6;6;6;2;1;0;0;5;0;3;0",
        "aff_country_unique": "Greece;Switzerland;Netherlands;Germany;Spain;Finland;Denmark"
    },
    {
        "id": "9981692",
        "title": "Optical Proximity Sensing for Pose Estimation During In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "During in-hand manipulation, robots must be able to continuously estimate the pose of the object in order to generate appropriate control actions. The performance of algorithms for pose estimation hinges on the robot's sensors being able to detect discriminative geometric object features, but previous sensing modalities are unable to make such measurements robustly. The robot's fingers can occlude the view of environment- or robot-mounted image sensors, and tactile sensors can only measure at the local areas of contact. Motivated by fingertip-embedded proximity sensors' robustness to occlusion and ability to measure beyond the local areas of contact, we present the first evaluation of proximity sensor based pose estimation for in-hand manipulation. We develop a novel two-fingered hand with fingertip-embedded optical time-of-flight proximity sensors as a testbed for pose estimation during planar in-hand manipulation. Here, the in-hand manipulation task consists of the robot moving a cylindrical object from one end of its workspace to the other. We demonstrate, with statistical significance, that proximity-sensor based pose estimation via particle filtering during in-hand manipulation: a) exhibits 50% lower average pose error than a tactile-sensor based baseline; b) empowers a model predictive controller to achieve 30% lower final positioning error compared to when using tactile-sensor based pose estimates.",
        "primary_area": "",
        "author": "Patrick Lancaster;Pratik Gyawali;Christoforos Mavrogiannis;Siddhartha S. Srinivasa;Joshua R. Smith;Patrick Lancaster;Pratik Gyawali;Christoforos Mavrogiannis;Siddhartha S. Srinivasa;Joshua R. Smith",
        "authorids": "/37085744215;/37086618257;/37077312800;/37339877600;/37290693300;/37085744215;/37086618257;/37077312800;/37339877600;/37290693300",
        "aff": "Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Electrical and Computer Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981692/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4933637043311966690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Paul G. Allen School of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982017",
        "title": "Optical flow-based branch segmentation for complex orchard environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine vision is a critical subsystem for enabling robots to be able to perform a variety of tasks in orchard environments. However, orchards are highly visually complex environments, and computer vision algorithms operating in them must be able to contend with variable lighting conditions and background noise. Past work on enabling deep learning algorithms to operate in these environments has typically required large amounts of hand-labeled data to train a deep neural network or physically controlling the conditions under which the environment is perceived. In this paper, we train a neural network system in simulation only using simulated RGB data and optical flow. This resulting neural network is able to perform foreground segmentation of branches in a busy orchard environment without additional real-world training or using any special setup or equipment beyond a standard camera. Our results show that our system is highly accurate and, when compared to a network using manually labeled RGBD data, achieves significantly more consistent and robust performance across environments that differ from the training set.",
        "primary_area": "",
        "author": "Alexander You;Cindy Grimm;Joseph R. Davidson;Alexander You;Cindy Grimm;Joseph R. Davidson",
        "authorids": "/37088504678;/37085798146;/37075739400;/37088504678;/37085798146;/37075739400",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982017/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2336777291636138749&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981237",
        "title": "Optimal Constrained Task Planning as Mixed Integer Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to successfully execute tasks as-signed to them, they must be capable of planning the right sequence of actions. These actions must be both optimal with respect to a specified objective and satisfy whatever constraints exist in their world. We propose an approach for robot task planning that is capable of planning the optimal sequence of grounded actions to accomplish a task given a specific objective function while satisfying all specified numerical constraints. Our approach accomplishes this by encoding the entire task planning problem as a single mixed integer convex program, which it then solves using an off-the-shelf Mixed Integer Program-ming solver. We evaluate our approach on several mobile manipulation tasks in both simulation and on a physical humanoid robot. Our approach is able to consistently produce optimal plans while accounting for all specified numerical constraints in the mobile manipulation tasks. Open-source implementations of the components of our approach as well as videos of robots executing planned grounded actions in both simulation and the physical world can be found at this url: https://adubredu.github.io/gtpmip",
        "primary_area": "",
        "author": "Alphonsus Adu-Bredu;Nikhil Devraj;Odest Chadwicke Jenkins;Alphonsus Adu-Bredu;Nikhil Devraj;Odest Chadwicke Jenkins",
        "authorids": "/37088518276;/37089194381;/37297252400;/37088518276;/37089194381;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981237/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2047225787756489296&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981871",
        "title": "Optimal Gait Families using Lagrange Multiplier Method",
        "track": "main",
        "status": "Poster",
        "abstract": "The Robotic locomotion community is interested in optimal gaits for control. Based on the optimization criterion, however, there could be a number of possible optimal gaits. For example, the optimal gait for maximizing displacement with respect to cost is quite different from the maximum displacement optimal gait. Beyond these two general optimal gaits, we believe that the optimal gait should deal with various situations for high-resolution of motion planning, e.g., steering the robot or moving in \u201cbaby steps.\u201d As the step size or steering ratio increases or decreases, the optimal gaits will slightly vary by the geometric relationship and they will form the families of gaits. In this paper, we explored the geometrical framework across these optimal gaits having different step sizes in the family via the Lagrange multiplier method. Based on the structure, we suggest an optimal locus generator that solves all related optimal gaits in the family instead of optimizing each gait respectively. By applying the optimal locus generator to two simplified swimmers in drag-dominated environments, we verify the behavior of the optimal locus generator.",
        "primary_area": "",
        "author": "Jinwoo Choi;Capprin Bass;Ross L. Hatton;Jinwoo Choi;Capprin Bass;Ross L. Hatton",
        "authorids": "/37089659706;/37089449422;/37542919100;/37089659706;/37089449422;/37542919100",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS), Institute at Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS), Institute at Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS), Institute at Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981871/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3804569329671341013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS)",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981371",
        "title": "Optimal Joint TDPA Formulation for Kinematically Redundant Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "The accomplishment of a successful teleoperation task requires guaranteeing system stability and transparency. Communication delay (in particular variable time delay), quantization and discretization negatively affect system stability and might be overcome with Time Domain Passivity Approach (TDPA), a model-free and robust way to cope with energy injection due to communication delay. However, this method degrades the transparency of the teleoperation system and worsens tracking performance, introducing in particular position drift error at the slave side and high frequency vibration (jittering) at the master side. In this work, we propose a new joint passivity controller formulation for kinematically redundant manipulators. Our approach stabilizes the system guaranteeing minimal performance loss by privileging the dissipation of the observed energy in the Jacobian null-space. The residual energy (if any) is dissipated in an orthogonal subspace. This is achieved by the solution of an optimization problem with appropriately defined cost functions and constrained to dissipate the energy observed by the passivity observer, guaranteeing the stability of the system. The effectiveness of our algorithm is tested in simulation with both constant and variable time delays.",
        "primary_area": "",
        "author": "Francesco Porcini;Massimiliano Solazzi;Antonio Frisoli;Francesco Porcini;Massimiliano Solazzi;Antonio Frisoli",
        "authorids": "/37087121821;/37293907000;/37297504100;/37087121821;/37293907000;/37297504100",
        "aff": "Scuola Superiore Sant'Anna, IIM Institute, PERCRO Laboratory, Pisa, Italy; Scuola Superiore Sant'Anna, IIM Institute, PERCRO Laboratory, Pisa, Italy; Scuola Superiore Sant'Anna, IIM Institute, PERCRO Laboratory, Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981371/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12842065760151560370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Scuola Superiore Sant'Anna",
        "aff_unique_dep": "IIM Institute, PERCRO Laboratory",
        "aff_unique_url": "https://www.sssup.it",
        "aff_unique_abbr": "SSSA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pisa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981718",
        "title": "Optimal Localizability Criterion for Positioning with Distance-Deteriorated Relative Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Position estimation in Multi-Robot Systems (MRS) relies on relative angle or distance measurements between the robots, which generally deteriorate as distances increase. Moreover, the localization accuracy is strongly influenced both by the quality of the raw measurements but also by the overall geometry of the network. In this paper, we design a cost function that accounts for these two issues and can be used to develop motion planning algorithms that optimize the localizability in MRS, i.e., the ability of individual robots to localize themselves accurately. This cost function is based on computing new Cram\u00e9r Rao Lower Bounds characterizing the achievable positioning performance with range and angle measurements that deteriorate with increasing distances. We describe a gradient-based motion-planning algorithm for MRS deployment that can be implemented in a distributed manner, as well as a non-myopic strategy to escape local minima. Finally, we test the proposed methodology experimentally for range measurements obtained using ultra-wide band transceivers and illustrate the improvements resulting from leveraging the more accurate measurement model in the robot placement algorithms.",
        "primary_area": "",
        "author": "Justin Cano;Ga\u00ebl Pages;Eric Chaumette;Jerome Le Ny;Justin Cano;Ga\u00ebl Pages;Eric Chaumette;Jerome Le Ny",
        "authorids": "/37086933423;/37299310100;/37285145900;/37546028800;/37086933423;/37299310100;/37285145900;/37546028800",
        "aff": "DEOS, ISAE-Supa\u00e9ro, Toulouse, France; DEOS, ISAE-Supa\u00e9ro, Toulouse, France; DEOS, ISAE-Supa\u00e9ro, Toulouse, France; Department of Electrical Engineering, Polytechnique Montr\u00e9al and with GERAD, Montr\u00e9al, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981718/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13622915458022638235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ISAE-Supa\u00e9ro;Polytechnique Montr\u00e9al",
        "aff_unique_dep": "DEOS;Department of Electrical Engineering",
        "aff_unique_url": "https://www.isae-supaero.fr;https://www.polymtl.ca",
        "aff_unique_abbr": ";Polytechnique",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Toulouse;Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "9981301",
        "title": "Optimal Multi-robot Formations for Relative Pose Estimation Using Range Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "In multi-robot missions, relative position and attitude information between robots is valuable for a variety of tasks such as mapping, planning, and formation control. In this paper, the problem of estimating relative poses from a set of inter-robot range measurements is investigated. Specifically, it is shown that the estimation accuracy is highly dependent on the true relative poses themselves, which prompts the desire to find multi-robot formations that provide the best estimation performance. By direct maximization of Fischer information, it is shown in simulation and experiment that large improvements in estimation accuracy can be obtained by optimizing the formation geometry of a team of robots.",
        "primary_area": "",
        "author": "Charles Champagne Cossette;Mohammed Ayman Shalaby;David Saussi\u00e9;J\u00e9r\u00f4me Le Ny;James Richard Forbes;Charles Champagne Cossette;Mohammed Ayman Shalaby;David Saussi\u00e9;J\u00e9r\u00f4me Le Ny;James Richard Forbes",
        "authorids": "/37087407589;/37089049261;/37547798200;/37299739600;/37543396800;/37087407589;/37089049261;/37547798200;/37299739600;/37543396800",
        "aff": "Department of Mech. Engineering, McGill University; Department of Mech. Engineering, McGill University; Department of Electrical Engineering, Polytechnique Montr\u00e9al.; Department of Mech. Engineering, McGill University; Department of Electrical Engineering, Polytechnique Montr\u00e9al.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981301/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12266256710959350611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "McGill University;Polytechnique Montr\u00e9al",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://www.polymtl.ca",
        "aff_unique_abbr": "McGill;Polytechnique",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981714",
        "title": "Optimal Nonprehensile Interception Strategy for Objects in Flight",
        "track": "main",
        "status": "Poster",
        "abstract": "Intercepting an object in flight through nonpre-hensile manipulation is a challenging problem, which is aimed at catching and stopping a flying object using little contacts without completely restraining its relative motion to the robot. This paper presents a two-stage optimal trajectory generation method to tackle this problem. At the pre-catching stage, optimal position and attitude trajectories of the robot's end-effector to approach the object are generated by a variational method. At the post-catching stage, the end-effector's trajectories are generated to optimally eliminate the translational and rotational motion of the object and a convex-MPC algorithm combined with admittance control is used to realize the trajectory tracking. A series of simulations and experiments have been conducted to verify the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Cheng Zhou;Yanbo Long;Ying Cao;Longfei Zhao;Bidan Huang;Yu Zheng;Cheng Zhou;Yanbo Long;Ying Cao;Longfei Zhao;Bidan Huang;Yu Zheng",
        "authorids": "/37088946786;/37089662991;/37089660664;/37088945859;/37085655047;/37086993722;/37088946786;/37089662991;/37089660664;/37088945859;/37085655047;/37086993722",
        "aff": "Tencent Robotics X, Shenzhen, Guangdong, China; University of Bristol, Bristol, UK; WuHan University, Wuhan, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981714/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16333923596368726669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "Tencent;University of Bristol;Wuhan University",
        "aff_unique_dep": "Robotics X;;",
        "aff_unique_url": "https://robotics.tencent.com;https://www.bristol.ac.uk;http://www.whu.edu.cn/",
        "aff_unique_abbr": "Tencent Robotics X;UoB;WHU",
        "aff_campus_unique_index": "0;1;2;0;0;0",
        "aff_campus_unique": "Shenzhen;Bristol;Wuhan",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9981902",
        "title": "Optimal Shape Servoing with Task-focused Convergence Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Most deformable object manipulation tasks still rely on skillful human operators. To automate such tasks, a robotic system should not only be able to deform an object to a desired shape but also servo its deformation along a specific path towards the desired shape. We propose a shape servoing control scheme to automate such tasks. Our scheme controls the deformation trajectory towards the desired shape by imposing task-focused convergence constraints. The constraints impose how fast the different regions of the object converge to the desired shape. Integrating such a behavior in shape servoing forms our main contribution. Experiments, carried out on rubber layer assembly tasks, show that our control scheme outperforms a state-of-the-art shape servoing scheme.",
        "primary_area": "",
        "author": "Victor H. Giraud;Maxime Padrin;Mohammadreza Shetab-Bushehri;Chedli Bouzgarrou;Youcef Mezouar;Erol Ozgur;Victor H. Giraud;Maxime Padrin;Mohammadreza Shetab-Bushehri;Chedli Bouzgarrou;Youcef Mezouar;Erol Ozgur",
        "authorids": "/37089662159;/37089659914;/37089300606;/37086645113;/37299713100;/37529038900;/37089662159;/37089659914;/37089300606;/37086645113;/37299713100;/37529038900",
        "aff": "Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, CNRS, Institut Pascal, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981902/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14428120118379927316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uca.fr",
        "aff_unique_abbr": "UCA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Clermont-Ferrand",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981179",
        "title": "Optimal and Risk-Aware Path Planning considering Localization Uncertainty for Space Exploration Rovers",
        "track": "main",
        "status": "Poster",
        "abstract": "The reliability of autonomous traverses of rovers is critical. It may be jeopardized by the accumulation of errors and the uncertainty propagation of their localization systems. Moreover, space environments are usually harsh, challenging and unpredictable. Teleoperation is complex due to the significant and unavoidable delay. For these reasons, a path planner that provides some level of autonomy with guarantees could increase the success rate of planetary exploration missions. This paper proposes a path planning solution that tackles increasing localization uncertainty and makes a trade-off between the collision risk and the path length. The planner uses the the Fast Marching Method (FMM) to produce a costmap aware of this uncertainty and calculate the optimal path for a level of confidence. This paper additionally presents several simulation and experimental using a wheeled robotic vehicle within a lunar analogue facility.",
        "primary_area": "",
        "author": "J. Ricardo S\u00e1nchez-Ib\u00e1\u00f1ez;Pedro J. Sanchez-Cuevas;Miguel Olivares-Mendez;J. Ricardo S\u00e1nchez-Ib\u00e1\u00f1ez;Pedro J. Sanchez-Cuevas;Miguel Olivares-Mendez",
        "authorids": "/37088688510;/37086140269;/38271290600;/37088688510;/37086140269;/38271290600",
        "aff": "Space Robotics Laboratory Dpt. of Systems Engineering and Automation, University of Malaga, Malaga, Spain; Advanced Centre for Aerospace Technologies (CATEC) Seville, Spain; Space Robotics (SpaceR) Research Group, Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981179/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12206277747579998087&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Malaga;Advanced Centre for Aerospace Technologies;University of Luxembourg",
        "aff_unique_dep": "Department of Systems Engineering and Automation;;Interdisciplinary Centre for Security, Reliability and Trust (SnT)",
        "aff_unique_url": "https://www.uma.es;;https://wwwen.unil.lu",
        "aff_unique_abbr": "UMA;CATEC;UniLu",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Malaga;Seville;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Spain;Luxembourg"
    },
    {
        "id": "9981236",
        "title": "Optimization of Forcemyography Sensor Placement for Arm Movement Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "How to design an optimal wearable device for human movement recognition is vital to reliable and accurate human-machine collaboration. Previous works mainly fabricate wearable devices heuristically. Instead, this paper raises an academic question: can we design an optimization algorithm to optimize the fabrication of wearable devices such as figuring out the best sensor arrangement automatically? Specifically, this work focuses on optimizing the placement of Forcemyography (FMG) sensors for FMG armbands in the application of arm movement recognition. Firstly, based on graph theory, the arm-band is modeled considering sensors' signals and connectivity. Then, a Graph-based Armband Modeling Network (GAM-Net) is introduced for arm movement recognition. Afterward, the sensor placement optimization for FMG armbands is formu-lated and an optimization algorithm with greedy local search is proposed. To study the effectiveness of our optimization algorithm, a dataset for mechanical maintenance tasks using FMG armbands with 16 sensors is collected. Our experiments show that using only 4 sensors optimized with our algorithm can help maintain a comparable recognition accuracy to using all sensors. Finally, the optimized sensor placement result is verified from a physiological view. This work would like to shed light on the automatic fabrication of wearable devices considering downstream tasks, such as human biological signal collection and movement recognition.",
        "primary_area": "",
        "author": "Xiaohao Xu;Zihao Du;Huaxin Zhang;Ruichao Zhang;Zihan Hong;Qin Huang;Bin Han;Xiaohao Xu;Zihao Du;Huaxin Zhang;Ruichao Zhang;Zihan Hong;Qin Huang;Bin Han",
        "authorids": "/37089387433;/37086799049;/37089660965;/37089663702;/37089660192;/37088689739;/37086433182;/37089387433;/37086799049;/37089660965;/37089663702;/37089660192;/37088689739;/37086433182",
        "aff": "State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Rehabilitation Medicine Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981236/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18196147268594876317&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Mechanical Science and Engineering",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981384",
        "title": "Optimizing Demonstrated Robot Manipulation Skills for Temporal Logic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "For performing robotic manipulation tasks, the core problem is determining suitable trajectories that fulfill the task requirements. Various approaches to compute such trajectories exist, being learning and optimization the main driving techniques. Our work builds on the learning-from-demonstration (LfD) paradigm, where an expert demonstrates motions, and the robot learns to imitate them. However, expert demonstrations are not sufficient to capture all sorts of task specifications, such as the timing to grasp an object. In this paper, we propose a new method that considers formal task specifications within LfD skills. Precisely, we leverage Signal Temporal Logic (STL), an expressive form of temporal properties of systems, to formulate task specifications and use black-box optimization (BBO) to adapt an LfD skill accordingly. We demonstrate our approach in simulation and on a real industrial setting using several tasks that showcase how our approach addresses the LfD limitations using STL and BBO.",
        "primary_area": "",
        "author": "Akshay Dhonthi;Philipp Schillinger;Leonel Rozo;Daniele Nardi;Akshay Dhonthi;Philipp Schillinger;Leonel Rozo;Daniele Nardi",
        "authorids": "/37089662513;/37085798192;/38228060200;/37281906000;/37089662513;/37085798192;/38228060200;/37281906000",
        "aff": "Formal Methods and Tools, University of Twente, Enschede, Netherlands; Bosch Center for AI, Renningen, Germany; Bosch Center for AI, Renningen, Germany; Department of AI and Robotics, Sapienza University, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981384/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14942993678379172343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of Twente;Bosch Center for AI;Sapienza University",
        "aff_unique_dep": "Formal Methods and Tools;AI;Department of AI and Robotics",
        "aff_unique_url": "https://www.utwente.nl;https://www.bosch.com/research/ai/;https://www.uniroma1.it",
        "aff_unique_abbr": "UT;BCAI;Sapienza",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Enschede;Renningen;Rome",
        "aff_country_unique_index": "0;1;1;2",
        "aff_country_unique": "Netherlands;Germany;Italy"
    },
    {
        "id": "9981731",
        "title": "Ordinal Inverse Reinforcement Learning Applied to Robot Learning with Small Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last decade, the ability to teach actions to robots in a user-friendly way has gained relevance, and a practical way of teaching robots a new task is to use Inverse Reinforcement Learning (IRL). In IRL, an expert teacher shows the robot a desired behaviour and an agent builds a model of the reward. The agent can also infer a policy that performs in an optimal way within the limitations of the knowledge provided to it. However, most IRL approaches assume an (almost) optimal performance of the teaching agent, which might become unpractical if the teacher is not actually an expert. In addition, most IRL focus on discrete state-action spaces that limit their applicability to certain real-world problems such as within the context of direct Policy Search (PS) reinforcement learning. Therefore, in this paper we introduce Ordinal Inverse Reinforcement Learning (OrdIRL) for continuous state variables, in which the teacher can qualitatively evaluate robot performance by selecting one among the predefined performance levels (e.g. {bad, medium, good} for three tiers of performance). Once the OrdIRL has fit an ordinal distribution to the data, we propose to use Bayesian Optimization (BO) to either gain knowledge on the inferred model (exploration) or find a policy or action that maximizes the expected reward given the prior knowledge on the reward (exploitation). In the case of large-dimensional state-action spaces, we use Dimensionality Reduction (DR) techniques and perform the BO in the latent space. Experimental results on simulation and with a robot arm show how this approach allows for learning the reward function with small data.",
        "primary_area": "",
        "author": "Adri\u00e0 Colom\u00e9;Carme Torras;Adri\u00e0 Colom\u00e9;Carme Torras",
        "authorids": "/38540317200;/37354713800;/38540317200;/37354713800",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (IRI), CSIC-UPC, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (IRI), CSIC-UPC, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981731/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6861217540331297724&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "IRI",
        "aff_unique_url": "https://www.iri.upc.edu",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981604",
        "title": "Origami Robot Self-folding by Magnetic Induction",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspired by the traditional art of paper folding, origami, autonomous production of 3D structures from 2D sheets can be achieved by the implementation of self-folding techniques. One technique to achieve such transformation is the usage of thermo-responsive smart materials such as self-folding polymeric films, which can be controlled by heat to shrink. Achieving remote self-folding with a practical approach remains a major challenge due to the requirement for specific environments, or having to accompany electronics on origami, which limits the complexity of the origami design. In this paper, we present a wireless method to trigger the thermo-responsive self-folding process of the origami robots through magnetic induction. The proposed method is applicable for all electrically conductive materials and can wirelessly fold a mobile origami robot with a size of 32 \u00d7 30 mm2. This method eliminates the need for inclusion of electronics on the origami or usage of complicated trigger methods and environmental conditions, allowing the robot to fold in a wider range of applications such as in constrained spaces.",
        "primary_area": "",
        "author": "Jialun Liu;Xiao Chen;Quentin Lahondes;Kaan Esendag;Dana Damian;Shuhei Miyashita;Jialun Liu;Xiao Chen;Quentin Lahondes;Kaan Esendag;Dana Damian;Shuhei Miyashita",
        "authorids": "/37088504937;/37089663477;/37089372308;/37089661352;/37587456200;/37672509400;/37088504937;/37089663477;/37089372308;/37089661352;/37587456200;/37672509400",
        "aff": "Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Indigneo Institute for in silico Medicine, University of Sheffield, UK; Indigneo Institute for in silico Medicine, University of Sheffield, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981604/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7150560273601100010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Sheffield",
        "aff_unique_dep": "Automatic Control and Systems Engineering Department",
        "aff_unique_url": "https://www.sheffield.ac.uk",
        "aff_unique_abbr": "Sheffield",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sheffield;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982039",
        "title": "Outdoor evaluation of sound source localization for drone groups using microphone arrays",
        "track": "main",
        "status": "Poster",
        "abstract": "For robot and drone auditions, microphone arrays have been used for estimating sound source directions and sound source locations. By using sound source localization techniques, for example, drones can detect people calling for help even if the target person is not visible. Most sound source localization methods are based on estimated sound source directions and triangulation. However, when it comes to situations using drones, severe drone noise distorts direction estimation results which could worsen the localization results badly due to the discreteness of direction estimation. In this perspective, the authors have proposed a sound source localization method that can omit outlying triangulation points, which could improve its localization performance. In this paper, an outdoor experiment has been held, and the proposed method is evaluated whether it can localize a sound source even if real drone noise is added to the recordings. Experiment results show that the proposed method can localize with 4.15 m of estimation error for a sound source up to 50 m away, suppress the impact of outliers, and use only plausible triangulation points.",
        "primary_area": "",
        "author": "Taiki Yamada;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai;Taiki Yamada;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai",
        "authorids": "/37088235606;/37667838300;/37086508904;/37274046900;/37088235606;/37667838300;/37086508904;/37274046900",
        "aff": "Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Honda Research Institute Japan Co., Ltd., Wako, Saitama, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982039/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9407439741141516481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Honda Research Institute Japan Co., Ltd.",
        "aff_unique_dep": "Department of Systems and Control Engineering;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "Titech;HRI-JP",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Tokyo;Wako",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981888",
        "title": "Output Feedback Tube MPC-Guided Data Augmentation for Robust, Efficient Sensorimotor Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning (IL) can generate computationally efficient sensorimotor policies from demonstrations provided by computationally expensive model-based sensing and control algorithms. However, commonly employed IL methods are often data-inefficient, requiring the collection of a large number of demonstrations and producing policies with limited robustness to uncertainties. In this work, we combine IL with an output feedback robust tube model predictive controller (RTMPC) to co-generate demonstrations and a data augmentation strategy to efficiently learn neural network-based sensorimotor policies. Thanks to the augmented data, we reduce the computation time and the number of demonstrations needed by IL, while providing robustness to sensing and process uncertainty. We tailor our approach to the task of learning a trajectory tracking visuomotor policy for an aerial robot, leveraging a 3D mesh of the environment as part of the data augmentation process. We numerically demonstrate that our method can learn a robust visuomotor policy from a single demonstration\u2014a two-orders of magnitude improvement in demonstration efficiency compared to existing IL methods.",
        "primary_area": "",
        "author": "Andrea Tagliabue;Jonathan P. How;Andrea Tagliabue;Jonathan P. How",
        "authorids": "/37086131568;/37276347700;/37086131568;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, MIT; Department of Aeronautics and Astronautics, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981888/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14996761497148338786&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981332",
        "title": "P2EG: Prediction and Planning Integrated Robust Decision-Making for Automated Vehicle Negotiating in Narrow Lane with Explorative Game",
        "track": "main",
        "status": "Poster",
        "abstract": "In the narrow lane scene of autonomous driving, it is critical for the ego car to recognize the intentions of social vehicles and cooperate with them. However, cooperating with social vehicles is challenging due to insufficient information. This paper proposes an Explorative Game that adopts Participant Game and Perfect Bayesian Equilibrium to exploratively perform some aggressive actions to obtain additional information, thus the autonomous vehicle can cooperate robustly and efficiently. Explorative Game assumes each vehicle maintains a unique belief about the current situation and attributes insecurity and instability to the conflict of various Perfect Bayesian Equilibriums formed by various beliefs. Aggressive actions enable the ego car to proactively guide social vehicles to cooperate as it expects and encourage them to express their intentions as quickly and clearly as possible so that the equilibriums can converge and the conflict can be eliminated. Additional information reduces the error between the actual intentions of social vehicles and the estimated intentions from the ego car, helping rationally prune potential interactions and update parameters of the reward function. We demonstrate our algorithm on recorded data as well as virtual environments with manually controlled social vehicles to prove the efficiency of cooperation and the robustness of decision-making. And it has been running for more than 20 kilometers in the real world.",
        "primary_area": "",
        "author": "Qianyi Zhang;Xiao Li;Ethan He;Shuguang Ding;Naizheng Wang;Jingtai Liu;Qianyi Zhang;Xiao Li;Ethan He;Shuguang Ding;Naizheng Wang;Jingtai Liu",
        "authorids": "/37088525936;/37089661073;/37089660612;/37089663534;/37089659749;/37405237000;/37088525936;/37089661073;/37089660612;/37089663534;/37089659749;/37405237000",
        "aff": "Institute of Robotics and Automatic Information System, Nankai University, Tianjin; Meituan Group; Meituan Group; Meituan Group; Meituan Group; Institute of Robotics and Automatic Information System, Nankai University, Tianjin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981332/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8950255754815545183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Nankai University;Meituan Group",
        "aff_unique_dep": "Institute of Robotics and Automatic Information System;",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.meituan.com",
        "aff_unique_abbr": "Nankai;Meituan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tianjin;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981377",
        "title": "PCBot: a Minimalist Robot Designed for Swarm Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Complexity, cost, and power requirements for the actuation of individual robots can play a large factor in limiting the size of robotic swarms. Here we present PCBot, a minimalist robot that can precisely move on an orbital shake table using a bi-stable solenoid actuator built directly into its PCB. This allows the actuator to be built as part of the automated PCB manufacturing process, greatly reducing the impact it has on manual assembly. Thanks to this novel actuator design, PCBot has merely five major components and can be assembled in under 20 seconds, potentially enabling them to be easily mass-manufactured. Here we present the electro-magnetic and mechanical design of PCBot. Additionally, a prototype robot is used to demonstrate its ability to move in a straight line as well as follow given paths.",
        "primary_area": "",
        "author": "Jingxian Wang;Michael Rubenstein;Jingxian Wang;Michael Rubenstein",
        "authorids": "/37089630350;/37282496500;/37089630350;/37282496500",
        "aff": "Center for Robotics and Biosystems, Northwestern University, Evanston, IL, USA; Center for Robotics and Biosystems, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981377/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16853246419933869113&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Center for Robotics and Biosystems",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981566",
        "title": "PFilter: Building Persistent Maps through Feature Filtering for Fast and Accurate LiDAR-based SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) based on laser sensors has been widely adopted by mobile robots and autonomous vehicles. These SLAM systems are required to support accurate localization with limited computational resources. In particular, point cloud registration, i.e., the process of matching and aligning multiple LiDAR scans collected at multiple locations in a global coordinate framework, has been deemed as the bottleneck step in SLAM. In this paper, we propose a feature filtering algorithm, PFilter, that can filter out invalid features and can thus greatly alleviate this bottleneck. Meanwhile, the overall registration accuracy is also improved due to the carefully curated feature points. We integrate PFilter into the well-established scan-to-map LiDAR odometry framework, F-LOAM, and evaluate its performance on the KITTI dataset. The experimental results show that PFilter can remove about 48.4% of the points in the local feature map and reduce feature points in scan by 19.3% on average, which save 20.9% processing time per frame. In the mean time, we improve the accuracy by 9.4%.",
        "primary_area": "",
        "author": "Yifan Duan;Jie Peng;Yu Zhang;Jianmin Ji;Yanyong Zhang;Yifan Duan;Jie Peng;Yu Zhang;Jianmin Ji;Yanyong Zhang",
        "authorids": "/37086559317;/37088996658;/37676486300;/38100458700;/37279961200;/37086559317;/37088996658;/37676486300;/38100458700;/37279961200",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981566/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2476721364488889876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981952",
        "title": "PI-ARS: Accelerating Evolution-Learned Visual-Locomotion with Predictive Information Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Evolution Strategy (ES) algorithms have shown promising results in training complex robotic control policies due to their massive parallelism capability, simple implementation, effective parameter-space exploration, and fast training time. However, a key limitation of ES is its scalability to large capacity models, including modern neural network architectures. In this work, we develop Predictive Information Augmented Random Search (PI-ARS) to mitigate this limitation by leveraging recent advancements in representation learning to reduce the parameter search space for ES. Namely, PI-ARS combines a gradient-based representation learning technique, Predictive Information (PI), with a gradient-free ES algorithm, Augmented Random Search (ARS), to train policies that can process complex robot sensory inputs and handle highly nonlinear robot dynamics. We evaluate PI-ARS on a set of challenging visual-locomotion tasks where a quadruped robot needs to walk on uneven stepping stones, quincuncial piles, and moving platforms, as well as to complete an indoor navigation task. Across all tasks, PI-ARS demonstrates significantly better learning efficiency and performance compared to the ARS baseline. We further validate our algorithm by demonstrating that the learned policies can successfully transfer to a real quadruped robot, for example, achieving a 100% success rate on the real-world stepping stone environment, dramatically improving prior results achieving 40% success.",
        "primary_area": "",
        "author": "Kuang-Huei Lee;Ofir Nachum;Tingnan Zhang;Sergio Guadarrama;Jie Tan;Wenhao Yu;Kuang-Huei Lee;Ofir Nachum;Tingnan Zhang;Sergio Guadarrama;Jie Tan;Wenhao Yu",
        "authorids": "/37089658874;/37086453227;/37088504200;/37326967700;/37086455820;/37085891022;/37089658874;/37086453227;/37088504200;/37326967700;/37086455820;/37085891022",
        "aff": "Google Research, Mountain View, CA, United States; Google Research, Mountain View, CA, United States; Google Research, Mountain View, CA, United States; Google Research, Mountain View, CA, United States; Google Research, Mountain View, CA, United States; Google Research, Mountain View, CA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981952/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2803997406236217240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982259",
        "title": "PM-FSM: Policies Modulating Finite State Machine for Robust Quadrupedal Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (deep RL) has emerged as an effective tool for developing controllers for legged robots. However, vanilla deep RL often requires a tremendous amount of training samples and is not feasible for achieving robust behaviors. Instead, researchers have investigated a novel policy architecture by incorporating human experts' knowledge, such as Policies Modulating Trajectory Generators (PMTG). This architecture builds a recurrent control loop by combining a parametric trajectory generator (TG) and a feedback policy network to achieve more robust behaviors. In this work, we propose Policies Modulating Finite State Machine (PM-FSM) by replacing TGs with contact-aware finite state machines (FSM), which offers more flexible control of each leg. This invention offers an explicit notion of contact events to the policy to negotiate unexpected perturbations. We demonstrated that the proposed architecture could achieve more robust behaviors in various scenarios, such as challenging terrains or external perturbations, on both simulated and real robots.",
        "primary_area": "",
        "author": "Ren Liu;Nitish Sontakke;Sehoon Ha;Ren Liu;Nitish Sontakke;Sehoon Ha",
        "authorids": "/37088822079;/37089662915;/37086314268;/37088822079;/37089662915;/37086314268",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982259/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17711755253329184566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981274",
        "title": "PSM: A Predictive Safety Model for Body Motion Based On the Spring-Damper Pendulum",
        "track": "main",
        "status": "Poster",
        "abstract": "Quantifying the safety of the human body ori-entation is an important issue in human-robot interaction. Knowing the changing physical constraints on human motion can improve inspection of safe human motions and bring essential information about stability and normality of human body orientations with real-time risk assessment. Also, this information can be used in cooperative robots and monitoring systems to evaluate and interact in the environment more freely. Furthermore, the workspace area can be more deterministic with the known physical characteristics of safety. Based on this motivation, we propose a novel predictive safety model (PSM) that relies on the information of an inertial measurement unit on the human chest. The PSM encompasses a 3-Dofs spring-damper pendulum model that predicts human motion based on a safe motion dataset. The estimated safe orientation of humans is obtained by integrating a safety dataset and an elastic spring-damper model in a way that the proposed approach can realize complex motions at different safety levels. We did experiments in a real-world scenario to verify our novel proposed model. This novel approach can be used in different guidance/assistive robots and health monitoring systems to support and evaluate the human condition, particularly elders.",
        "primary_area": "",
        "author": "Seyed Amir Tafrishi;Ankit A. Ravankar;Yasuhisa Hirata;Seyed Amir Tafrishi;Ankit A. Ravankar;Yasuhisa Hirata",
        "authorids": "/37086457214;/38236067100;/37274134900;/37086457214;/38236067100;/37274134900",
        "aff": "Department of Robotics, Tohoku University, Aoba-ku, Sendai, Japan; Department of Robotics, Tohoku University, Aoba-ku, Sendai, Japan; Department of Robotics, Tohoku University, Aoba-ku, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981274/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=975273068158127879&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981500",
        "title": "PUA-MOS: End-to-End Point-wise Uncertainty Weighted Aggregation for Moving Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmenting moving objects in the 3D LiDAR point cloud can provide important guidance to localization, mapping and decision-making for self-driving vehicles. As for the conventional approaches to point cloud segmentation, they rely on semantic-level information, which makes it inevitable for long-tail problems to arise as there are always unseen types of objects on the road. To achieve moving segmentation while avoiding the reliance on the object category, the point motion is identified in this paper by fully exploring and aggregating the point-level geometric consistency in sequential point clouds. More specifically, an end-to-end point-wise uncertainty weighted aggregation approach known as PUA-MOS is proposed to segment the moving points in 3D LiDAR Data. Our method is applicable to estimate point-wise moving mask, scene flow and rigid-body transformation simultaneously in a coarse- to-fine network, where the relations between each prediction are implicitly learned. To explicitly model the inner and inter relations across these predictions among all points, the point- wise estimation and the average value of the same motion points are aggregated according to a predicted uncertainty. Then, the aggregated estimation is fed again into the next-level fusion, where the points will be re-segmented using the aggregated mask from the last level. Through iterative joint aggregation, our PUA-MOS outperforms the previous methods significantly on both KITTI [4] and Waymo [26] datasets. The code will be provided to generate the moving segmentation labels on both datasets for reproduction.",
        "primary_area": "",
        "author": "Cheng Chi;Peiliang Li;Xiaozhi Chen;Xin Yang;Cheng Chi;Peiliang Li;Xiaozhi Chen;Xin Yang",
        "authorids": "/37089016503;/37086229175;/37085505385;/37534298600;/37089016503;/37086229175;/37085505385;/37534298600",
        "aff": "School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China; Da Jiang innovate technology Ltd, Shenzhen, China; Da Jiang innovate technology Ltd, Shenzhen, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981500/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4075266883791636881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Huazhong University of Science and Technology;Da Jiang Innovate Technology Co., Ltd.",
        "aff_unique_dep": "School of Electronic Information and Communications;",
        "aff_unique_url": "http://www.hust.edu.cn;",
        "aff_unique_abbr": "HUST;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wuhan;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981038",
        "title": "PUTN: A Plane-fitting based Uneven Terrain Navigation Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation of ground robots has been widely used in indoor structured 2D environments, but there are still many challenges in outdoor 3D unstructured environments, especially in rough, uneven terrains. This paper proposed a plane-fitting based uneven terrain navigation framework (PUTN) to solve this problem. The implementation of PUTN is divided into three steps. First, based on Rapidly-exploring Random Trees (RRT), an improved sample-based algorithm called Plane Fitting RRT*(PF- RRT*) is proposed to obtain a sparse trajectory. Each sampling point corresponds to a custom traversability index and a fitted plane on the point cloud. These planes are connected in series to form a traversable \u201cstrip\u201d. Second, Gaussian Process Regression is used to generate traversability of the dense trajectory interpolated from the sparse trajectory, and the sampling tree is used as the training set. Finally, local planning is performed using nonlinear model predictive control (NMPC). By adding the traversability index and uncertainty to the cost function, and adding obstacles generated by the real-time point cloud to the constraint function, a safe motion planning algorithm with smooth speed and strong robustness is available. Experiments in real scenarios are conducted to verify the effectiveness of the method. The source code is released for the reference of the community11Source code: https://github.com/jianzhuozhuTHU/putn..",
        "primary_area": "",
        "author": "Zhuozhu Jian;Zihong Lu;Xiao Zhou;Bin Lan;Anxing Xiao;Xueqian Wang;Bin Liang;Zhuozhu Jian;Zihong Lu;Xiao Zhou;Bin Lan;Anxing Xiao;Xueqian Wang;Bin Liang",
        "authorids": "/37089661474;/37089663701;/37089663110;/37088984476;/37088981835;/37085383477;/37270783900;/37089661474;/37089663701;/37089663110;/37088984476;/37088981835;/37085383477;/37270783900",
        "aff": "Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981038/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=148815015296052532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;2;0;0",
        "aff_unique_norm": "Tsinghua University;Harbin Institute of Technology;Southern University of Science and Technology",
        "aff_unique_dep": "Center for Artificial Intelligence and Robotics;School of Mechanical Engineering and Automation;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.hit.edu.cn/;https://www.sustech.edu.cn",
        "aff_unique_abbr": "Tsinghua;HIT;SUSTech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981511",
        "title": "ParaPose: Parameter and Domain Randomization Optimization for Pose Estimation using Synthetic Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Pose estimation is the task of determining the 6D position of an object in a scene. Pose estimation aid the abilities and flexibility of robotic set-ups. However, the system must be configured towards the use case to perform adequately. This configuration is time-consuming and limits the usability of pose estimation and, thereby, robotic systems. Deep learning is a method to overcome this configuration procedure by learning parameters directly from the dataset. However, obtaining this training data can also be very time-consuming. The use of synthetic training data avoids this data collection problem, but a configuration of the training procedure is necessary to overcome the domain gap problem. Additionally, the pose estimation parameters also need to be configured. This configuration is jokingly known as grad student descent as parameters are manually adjusted until satisfactory results are obtained. This paper presents a method for automatic configuration using only synthetic data. This is accomplished by learning the domain randomization during network training, and then using the domain randomization to optimize the pose estimation parameters. The developed approach shows state-of-the-art performance of 82.0 % recall on the challenging OCCLUSION dataset, outperforming all previous methods with a large margin. These results prove the validity of automatic set-up of pose estimation using purely synthetic data.",
        "primary_area": "",
        "author": "Frederik Hagelskj\u00e6r;Anders Glent Buch;Frederik Hagelskj\u00e6r;Anders Glent Buch",
        "authorids": "/37089661159;/37534052600;/37089661159;/37534052600",
        "aff": "SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense M, Denmark; SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense M, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981511/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6668956671884170553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Odense",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9981962",
        "title": "Parallel Monte Carlo Tree Search with Batched Rigid-body Simulations for Speeding up Long-Horizon Episodic Robot Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel Parallel Monte Carlo tree search with Batched Simulations (PMBS) algorithm for accelerating long-horizon, episodic robotic planning tasks. Monte Carlo tree search (MCTS) is an effective heuristic search algorithm for solving episodic decision-making problems whose underlying search spaces are expansive. Leveraging a GPU-based large-scale simulator, PMBS introduces massive parallelism into MCTS for solving planning tasks through the batched execution of a large number of concurrent simulations, which allows for more efficient and accurate evaluations of the expected cost-to-go over large action spaces. When applied to the challenging manipulation tasks of object retrieval from clutter, PMBS achieves a speedup of over 30\u00d7 with an improved solution quality, in comparison to a serial MCTS implementation. We show that PMBS can be directly applied to real robot hardware with negligible sim-to-real differences. Supplementary material, including video, can be found at https://github.com/arc-l/pmbs.",
        "primary_area": "",
        "author": "Baichuan Huang;Abdeslam Boularias;Jingjin Yu;Baichuan Huang;Abdeslam Boularias;Jingjin Yu",
        "authorids": "/37088981654;/37542596800;/37536570700;/37088981654;/37542596800;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, USA; Department of Computer Science, Rutgers, the State University of New Jersey, USA; Department of Computer Science, Rutgers, the State University of New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981962/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15605432846769133983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981215",
        "title": "Particle Swarm Optimizer-based Attack Strategy with Swarm Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "An environment where a robot swarm attacks a territory protected by another one leads to an attack-defense confrontation problem. Commonly-used deep reinforcement learning-based methods rely on pre-training and become intractable due to the curse of dimensionality. To develop effective attack strategies, inspired by a particle swarm optimizer (PSO), this work proposes a PSO-based strategy for a robot swarm for the first time. During the moving of a robot swarm, each robot obtains situation information through perceiving its nearby peers and enemies and uses such information to construct its fitness function. Then, each robot uses PSO to optimize its fitness function and searches for its optimal attack position, which guides it to move in the next time slot. The experimental analyses show that the PSO-based attack strategy has more potential in solving large-scale confrontational problems than the deep reinforcement learning-based algorithms.",
        "primary_area": "",
        "author": "Huan Liu;JunQi Zhang;MengChu Zhou;Huan Liu;JunQi Zhang;MengChu Zhou",
        "authorids": "/37088880310;/38010290600;/37273591600;/37088880310;/38010290600;/37273591600",
        "aff": "Department of Computer Science and Technology, Key Laboratory of Embedded System and Service Computing, Ministry of Education, Shanghai Electronic Transactions and Information Service Collaborative Innovation Center, Tongji University, Shanghai, China; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Macao Institute of Systems Engineering and Collaborative Laboratory for Intelligent Science and Systems Macau University of Science and Technology, Macao, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981215/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:jQXNywTDnE4J:scholar.google.com/&scioq=Particle+Swarm+Optimizer-based+Attack+Strategy+with+Swarm+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Tongji University;New Jersey Institute of Technology;Macau University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Electrical and Computer Engineering;Macao Institute of Systems Engineering and Collaborative Laboratory for Intelligent Science and Systems",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.njit.edu;https://www.must.edu.mo",
        "aff_unique_abbr": "Tongji;NJIT;MUST",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Shanghai;Newark;Macao",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10569986",
        "title": "Passive compliant foot design for improved micororobotic mobility on rough terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "To deploy robots outside of laboratory environments, they must be able to locomote on natural, unstructured terrain. While perception and control strategies for terrain navigation and obstacle avoidance have been developed for human-scale robots, microrobots are often too small to carry the sensors, computing power, and energy required to implement such techniques. Instead, this work presents passive foot designs for improving open-loop, quasi-static locomotion of a 1.6 g, 45 mm quadruped robot over rough terrains. The feet were evaluated by tracking the distance travelled on an uneven terrain of progressively increasing feature heights. Our insect tarsi inspired rigid foot designs improved performance somewhat, and by adding passive compliance via a viscoelastic hinge on the heel and toe, we increased the distance travelled by 168% over the original design. By exploring the design space of foot geometries and compliance, this work lays the foundation for understanding how passive foot design facilitates locomotion over uneven terrains.",
        "primary_area": "",
        "author": "Pierre-Louis Lech\u00e8re;Perrin E. Schiebel;Michelle C. Yuen;Jennifer Shum;Robert J. Wood;Pierre-Louis Lech\u00e8re;Perrin E. Schiebel;Michelle C. Yuen;Jennifer Shum;Robert J. Wood",
        "authorids": "/328465881597307;/37089663984;/37085376647;/37088418916;/37326227400;/328465881597307;/37089663984;/37085376647;/37088418916;/37326227400",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Institute of Mechanical Engineering, Lausanne, Switzerland; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10569986/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4154175798413668333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "EPFL;Harvard University",
        "aff_unique_dep": "Institute of Mechanical Engineering;School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.epfl.ch;https://www.harvard.edu",
        "aff_unique_abbr": "EPFL;Harvard",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Lausanne;Boston",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9981728",
        "title": "Passivity-Based Skill Motion Learning in Stiffness-Adaptive Unified Force-Impedance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile robots shall be deployed for dynamic task execution in production lines with small batch sizes. Therefore, these robots should have the ability to respond to changing conditions and be easy to (re-)program. Operating under uncertain environments requires unifying subsystems such as robot motion and force policy into one framework, referred to as tactile skills. In this paper, we propose the enhancement of these skills for passivity-based skill motion learning in stiffness-adaptive unified force-impedance control. To achieve the increased level of adaptability, we represent all tactile skills by three basic primitives: contact initiation, manipulation, and contact termination. To ensure passivity and stability, we develop an energy-based approach for unified force-impedance control that allows humans to teach the robot motion through physical interaction during the execution of a tactile task. We incorporate our proposed framework into a tactile robot to experimentally validate the motion adaptation by interaction performance and stability of the control. While the polishing task is presented as our use case through the paper, the experiments can also be carried out with various tactile skills. Finally, the results show the novel controller's stability and passivity to contact-loss and stiffness adaptation, leading to successful programming by interaction.",
        "primary_area": "",
        "author": "K\u00fcbra Karacan;Hamid Sadeghian;Robin Kirschner;Sami Haddadin;K\u00fcbra Karacan;Hamid Sadeghian;Robin Kirschner;Sami Haddadin",
        "authorids": "/37088532694;/38539589600;/37088861072;/37542865300;/37088532694;/38539589600;/37088861072;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany; University of Isfahan, Isfahan; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981728/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8772128835480103460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Technical University of Munich;University of Isfahan;Centre for Tactile Internet with Human-in-the-Loop",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence;;",
        "aff_unique_url": "https://www.tum.de;http://www.ui.ac.ir;",
        "aff_unique_abbr": "TUM;;CeTI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Munich;Isfahan;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;Iran;"
    },
    {
        "id": "9981561",
        "title": "Patchwork++: Fast and Robust Ground Segmentation Solving Partial Under-Segmentation Using 3D Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "In the field of 3D perception using 3D LiDAR sensors, ground segmentation is an essential task for various purposes, such as traversable area detection and object recognition. Under these circumstances, several ground segmentation methods have been proposed. However, some limitations are still encountered. First, some ground segmentation methods require fine-tuning of parameters depending on the surroundings, which is excessively laborious and time-consuming. Moreover, even if the parameters are well adjusted, a partial under-segmentation problem can still emerge, which implies ground segmentation failures in some regions. Finally, ground segmentation methods typically fail to estimate an appropriate ground plane when the ground is above another structure, such as a retaining wall. To address these problems, we propose a robust ground segmentation method called Patchwork++, an extension of Patchwork. Patchwork++ exploits adaptive ground likelihood estimation (A-GLE) to calculate appropriate parameters adaptively based on the previous ground segmentation results. Moreover, temporal ground revert (TGR) alleviates a partial under-segmentation problem by using the temporary ground property. Also, region-wise vertical plane fitting (R-VPF) is introduced to segment the ground plane properly even if the ground is elevated with different layers. Finally, we present reflected noise removal (RNR) to eliminate virtual noise points efficiently based on the 3D LiDAR reflection model. We demonstrate the qualitative and quantitative evaluations using a SemanticKITTI dataset. Our code is available at https://github.com/url-kaist/patchwork-plusplus",
        "primary_area": "",
        "author": "Seungjae Lee;Hyungtae Lim;Hyun Myung;Seungjae Lee;Hyungtae Lim;Hyun Myung",
        "authorids": "/37089453102;/37086920570;/37424926900;/37089453102;/37086920570;/37424926900",
        "aff": "School of Electrical Engineering at KAIST, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; School of Electrical Engineering at KAIST, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; School of Electrical Engineering at KAIST, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981561/",
        "gs_citation": 155,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11499165879408908557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981690",
        "title": "Pedestrian Intention Prediction Based on Traffic-Aware Scene Graph Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Anticipating the future behavior of pedestrians is a crucial part of deploying Automated Driving Systems (ADS) in urban traffic scenarios. Most recent works utilize a convolutional neural network (CNN) to extract visual information, which is then input to a recurrent neural network (RNN) along with pedestrian-specific features like location and speed to obtain temporal features. However, the majority of these approaches lack the ability to parse the relationships of the related objects in the specific traffic scene, which leads to omitting the interactions between the pedestrians and the interactions between the pedestrians and the traffic. For this purpose, we propose a graph-structured model which can dig out pedestrians' dynamic constraints by constructing a traffic-aware scene graph within each frame. In addition, to capture pedestrian movement more effectively, we also introduce a temporal feature representation model, which first uses inter-frame and intra-frame GRU (II-GRU) to mine inter-frame information and intra-frame information together, and then employs a novel attention mechanism to adaptively generate attention weights. Extensive experiments on the JAAD and PIE datasets prove that our proposed model is effective in reaching and enhancing the state-of-the-art performance.",
        "primary_area": "",
        "author": "Xingchen Song;Miao Kang;Sanping Zhou;Jianji Wang;Yishu Mao;Nanning Zheng;Xingchen Song;Miao Kang;Sanping Zhou;Jianji Wang;Yishu Mao;Nanning Zheng",
        "authorids": "/37089661531;/37089581067;/37085995894;/37068400500;/37089660738;/37271536700;/37089661531;/37089581067;/37085995894;/37068400500;/37089660738;/37271536700",
        "aff": "Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Automatic control and detection technology, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981690/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4297931541939208188&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981705",
        "title": "Pedestrian-Robot Interactions on Autonomous Crowd Navigation: Reactive Control Methods and Evaluation Metrics",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in highly populated areas remains a challenging task for robots because of the difficulty in guaranteeing safe interactions with pedestrians in unstructured situations. In this work, we present a crowd navigation control framework that delivers continuous obstacle avoidance and post-contact control evaluated on an autonomous personal mobility vehicle. We propose evaluation metrics for accounting efficiency, controller response and crowd interactions in natural crowds. We report the results of over 110 trials in different crowd types: sparse, flows, and mixed traffic, with low- (< 0.15 ppsm), mid- (< 0.65 ppsm), and high- (< 1 ppsm) pedestrian densities. We present comparative results between two low-level obstacle avoidance methods and a baseline of shared control. Results show a 10% drop in relative time to goal on the highest density tests, and no other efficiency metric decrease. Moreover, autonomous navigation showed to be comparable to shared-control navigation with a lower relative jerk and significantly higher fluency in commands indicating high compatibility with the crowd. We conclude that the reactive controller fulfils a necessary task of fast and continuous adaptation to crowd navigation, and it should be coupled with high-level planners for environmental and situational awareness.",
        "primary_area": "",
        "author": "Diego Paez-Granados;Yujie He;David Gonon;Dan Jia;Bastian Leibe;Kenji Suzuki;Aude Billard;Diego Paez-Granados;Yujie He;David Gonon;Dan Jia;Bastian Leibe;Kenji Suzuki;Aude Billard",
        "authorids": "/37085669907;/37089660670;/37088839883;/37088688308;/37298473000;/37334425200;/37273980800;/37085669907;/37089660670;/37088839883;/37088688308;/37298473000;/37334425200;/37273980800",
        "aff": "SCAI Lab, Swiss Federal School of Technology in Zurich - ETH Zurich and SPZ, Switzerland; LASA Laboratory, Swiss Federal School of Technology in Lausanne - EPFL, Switzerland; LASA Laboratory, Swiss Federal School of Technology in Lausanne - EPFL, Switzerland; Visual Computing Institute, RWTH, Germany; Visual Computing Institute, RWTH, Germany; Artificial Intelligence Lab, University of Tsukuba, Japan; LASA Laboratory, Swiss Federal School of Technology in Lausanne - EPFL, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981705/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2868959833841056331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;2;3;1",
        "aff_unique_norm": "Swiss Federal Institute of Technology in Zurich;Swiss Federal Institute of Technology in Lausanne (EPFL);RWTH Aachen University;University of Tsukuba",
        "aff_unique_dep": "SCAI Lab;LASA Laboratory;Visual Computing Institute;Artificial Intelligence Lab",
        "aff_unique_url": "https://www.ethz.ch;https://www.epfl.ch;https://www.rwth-aachen.de;https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "ETH Zurich;EPFL;RWTH;",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Zurich;Lausanne;",
        "aff_country_unique_index": "0;0;0;1;1;2;0",
        "aff_country_unique": "Switzerland;Germany;Japan"
    },
    {
        "id": "9981788",
        "title": "Perceive, Represent, Generate: Translating Multimodal Information to Robotic Motion Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Perceive-Represent-Generate (PRG), a novel three-stage framework that maps perceptual information of different modalities (e.g., visual or sound), corresponding to a series of instructions, to a sequence of movements to be executed by a robot. In the first stage, we perceive and preprocess the given inputs, isolating individual commands from the complete instruction provided by a human user. In the second stage we encode the individual commands into a multimodal latent space, employing a deep generative model. Finally, in the third stage we convert the latent samples into individual trajectories and combine them into a single dynamic movement primitive, allowing its execution by a robotic manipulator. We evaluate our pipeline in the context of a novel robotic handwriting task, where the robot receives as input a word through different perceptual modalities (e.g., image, sound), and generates the corresponding motion trajectory to write it, creating coherent and high-quality handwritten words.",
        "primary_area": "",
        "author": "F\u00e1bio Vital;Miguel Vasco;Alberto Sardinha;Francisco Melo;F\u00e1bio Vital;Miguel Vasco;Alberto Sardinha;Francisco Melo",
        "authorids": "/37089658110;/37087324547;/37395152200;/37885650900;/37089658110;/37087324547;/37395152200;/37885650900",
        "aff": "INESC-ID & Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID & Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID & Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID & Instituto Superior T\u00e9cnico, University of Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981788/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7043515392863732616&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Lisbon",
        "aff_unique_dep": "INESC-ID & Instituto Superior T\u00e9cnico",
        "aff_unique_url": "https://www.ulusiada.pt",
        "aff_unique_abbr": "ULisbon",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lisbon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9982079",
        "title": "Perception of Mechanical Properties via Wrist Haptics: Effects of Feedback Congruence",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite non-co-location, haptic stimulation at the wrist can potentially provide feedback regarding interactions at the fingertips without encumbering the user's hand. Here we investigate how two types of skin deformation at the wrist (normal and shear) relate to the perception of the mechanical properties of virtual objects. We hypothesized that a congruent mapping (i.e. when the most relevant interaction forces during a virtual interaction spatially match the haptic feedback at the wrist) would result in better perception than other mappings. We performed an experiment where haptic devices at the wrist rendered either normal or shear feedback during manipulation of virtual objects with varying stiffness, mass, or friction properties. Perception of mechanical properties was more accurate with congruent skin stimulation than noncongruent. In addition, discrimination performance and subjective reports were positively influenced by congruence. This study demonstrates that users can perceive mechanical properties via haptic feedback provided at the wrist with a consistent mapping between haptic feedback and interaction forces at the fingertips, regardless of congruence.",
        "primary_area": "",
        "author": "Mine Sarac;Massimiliano Di Luca;Allison M. Okamura;Mine Sarac;Massimiliano Di Luca;Allison M. Okamura",
        "authorids": "/37061845400;/38190695500;/37276156400;/37061845400;/38190695500;/37276156400",
        "aff": "Stanford University, USA; University of Birmingham, UK; Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982079/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4155413173571206488&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;University of Birmingham",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "Stanford;Birmingham",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9981742",
        "title": "Photometric single-view dense 3D reconstruction in endoscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual SLAM inside the human body will open the way to computer-assisted navigation in endoscopy. However, due to space limitations, medical endoscopes only provide monocular images, leading to systems lacking true scale. In this paper, we exploit the controlled lighting in colonoscopy to achieve the first in-vivo 3D reconstruction of the human colon using photometric stereo on a calibrated monocular endoscope. Our method works in a real medical environment, providing both a suitable in-place calibration procedure and a depth estimation technique adapted to the colon's tubular geometry. We validate our method on simulated colonoscopies, obtaining a mean error of 7% on depth estimation, which is below 3 mm on average. Our qualitative results on the EndoMapper dataset show that the method is able to correctly estimate the colon shape in real human colonoscopies, paving the ground for truescale monocular SLAM in endoscopy.",
        "primary_area": "",
        "author": "V\u00edctor M. Batlle;J.M.M. Montiel;Juan D. Tard\u00f3s;V\u00edctor M. Batlle;J.M.M. Montiel;Juan D. Tard\u00f3s",
        "authorids": "/37089658389;/37274019300;/37351680900;/37089658389;/37274019300;/37351680900",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981742/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12192741504201747415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981214",
        "title": "Physical Neural Cellular Automata for 2D Shape Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Materials with the ability to self-classify their own shape have the potential to advance a wide range of engineering applications and industries. Biological systems possess the ability not only to self-reconfigure but also to self-classify themselves to determine a general shape and function. Previous work into modular robotics systems has only enabled self-recognition and self-reconfiguration into a specific target shape, missing the inherent robustness present in nature to self-classify. In this paper we therefore take advantage of recent advances in deep learning and neural cellular automata, and present a simple modular 2D robotic system that can infer its own class of shape through the local communication of its components. Furthermore, we show that our system can be successfully transferred to hardware which thus opens op-portunities for future self-classifying machines. Code available at https://github.com/kattwalker/projectcube. Video available at https://youtu.be/0TCOkE4keyc.",
        "primary_area": "",
        "author": "Kathryn Walker;Rasmus Berg Palm;Rodrigo Moreno;Andres Faina;Kasper Stoy;Sebastian Risi;Kathryn Walker;Rasmus Berg Palm;Rodrigo Moreno;Andres Faina;Kasper Stoy;Sebastian Risi",
        "authorids": "/37088910870;/37086322000;/37969562200;/37571608300;/37333021600;/38230648800;/37088910870;/37086322000;/37969562200;/37571608300;/37333021600;/38230648800",
        "aff": "IT University of Copenhagen; IT University of Copenhagen; IT University of Copenhagen; IT University of Copenhagen; IT University of Copenhagen; IT University of Copenhagen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981214/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9036516761895521728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "IT University of Copenhagen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://itu.dk",
        "aff_unique_abbr": "ITU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9981303",
        "title": "Physics Embedded Neural Network Vehicle Model and Applications in Risk-Aware Autonomous Driving Using Latent Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-holonomic vehicle motion has been studied extensively using physics-based models. Common approaches when using these models interpret the wheel/ground interactions using a linear tire model and thus may not fully capture the nonlinear and complex dynamics under various environments. On the other hand, neural network models have been widely employed in this domain, demonstrating powerful function approximation capabilities. However, these black-box learning strategies completely abandon the existing knowledge of well-known physics. In this paper, we seamlessly combine deep learning with a fully differentiable physics model to endow the neural network with available prior knowledge. The proposed model shows better generalization performance than the vanilla neural network model by a large margin. We also show that the latent features of our model can accurately represent lateral tire forces without the need for any additional training. Lastly, We develop a risk-aware model predictive controller using proprioceptive information derived from the latent features. We validate our idea in two autonomous driving tasks under unknown friction, outperforming the baseline control framework.",
        "primary_area": "",
        "author": "Taekyung Kim;Hojin Lee;Wonsuk Lee;Taekyung Kim;Hojin Lee;Wonsuk Lee",
        "authorids": "/37351131100;/37089468568;/37085438594;/37351131100;/37089468568;/37085438594",
        "aff": "Ground Technology Research Institute, Agency for Defense Development, Daejeon, Republic of Korea; Ground Technology Research Institute, Agency for Defense Development, Daejeon, Republic of Korea; Ground Technology Research Institute, Agency for Defense Development, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981303/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6258711658437730153&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Agency for Defense Development",
        "aff_unique_dep": "Ground Technology Research Institute",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981192",
        "title": "Planar Modeling and Sim-to-Real of a Tethered Multimaterial Soft Swimmer Driven by Peano-HASELs",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotics has the potential to revolutionize robotic locomotion, in particular, soft robotic swimmers offer a minimally invasive and adaptive solution to explore and preserve our oceans. Unfortunately, current soft robotic swimmers are vastly inferior to evolved biological swimmers, especially in terms of controllability, efficiency, maneuverability, and longevity. Additionally, the tedious iterative fabrication and empirical testing required to design soft robots has hindered their optimization. In this work, we tackle this challenge by providing an efficient and straightforward pipeline for designing and fabricating soft robotic swimmers equipped with electrostatic actuation. We streamline the process to allow for rapid additive manufacturing, and show how a differentiable simulation can be used to match a simplified model to the real deformation of a robotic swimmer. We perform several experiments with the fabricated swimmer by varying the voltage and actuation frequency of the swimmer's antagonistic muscles. We show how the voltage and frequency vary the locomotion speed of the swimmer while moving in liquid oil and observe a clear optimum in forward swimming speed. The differentiable simulation model we propose has various downstream applications, such as control and shape optimization of the swimmer; optimization results can be directly mapped back to the real robot through our sim-to-real matching.",
        "primary_area": "",
        "author": "Stephan-Daniel Gravert;Mike Y. Michelis;Simon Rogler;Dario Tscholl;Thomas Buchner;Robert K. Katzschmann;Stephan-Daniel Gravert;Mike Y. Michelis;Simon Rogler;Dario Tscholl;Thomas Buchner;Robert K. Katzschmann",
        "authorids": "/37089660330;/37089338268;/37089658617;/37089658534;/37088539885;/37085423557;/37089660330;/37089338268;/37089658617;/37089658534;/37088539885;/37085423557",
        "aff": "Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland; Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland; Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland; Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland; Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland; Department of Mechanical and Process Engineering, Soft Robotics Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981192/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4882260719574877903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Mechanical and Process Engineering",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981781",
        "title": "Plane-to-Plane Positioning by Proximity-based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider a multi-sensor arrangement of proximity sensors that forms a proximity array. A general modeling methodology is considered within the framework of Sensor-based Control. It incorporates multiple sensor signals from the proximity array by giving primary emphasis on the interaction screw. To prove its effectiveness, modeling approach is applied to the task of plane-to-plane positioning. We discuss the development of two sensor-based task functions for the specific task considered. The validity of the methodology is provided using relevant experimental results.",
        "primary_area": "",
        "author": "John Thomas;Fran\u00e7ois Pasteau;Fran\u00e7ois Chaumette;John Thomas;Fran\u00e7ois Pasteau;Fran\u00e7ois Chaumette",
        "authorids": "/37089661473;/37891636000;/37265186700;/37089661473;/37891636000;/37265186700",
        "aff": "Inria, Univ Rennes, CNRS, IRISA - Rennes, France; INSA, Univ Rennes, Inria, CNRS, IRISA - Rennes, France; Inria, Univ Rennes, CNRS, IRISA - Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981781/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9296896176697355900&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "INRIA;INSA Rennes",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.inria.fr;https://www.insa-rennes.fr",
        "aff_unique_abbr": "Inria;INSA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981988",
        "title": "Planning for Negotiations in Autonomous Driving using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning autonomous driving behaviors in dense traffic is challenging. Human drivers are able to influence their road environment to achieve (otherwise unachievable) goals, by communicating their intents to other drivers. An autonomous system that is required to drive in the presence of human traffic must thus possess this fundamental negotiation capability. This work presents a novel benchmark that includes a stochastic driver negotiation model and a framework for training policies to drive and negotiate based on reinforcement learning. It is shown that driving policies trained in this framework lead to greater safety, higher mission accomplishment rates and more driving comfort, and can generalize across scenarios.",
        "primary_area": "",
        "author": "Roi Reshef;Roi Reshef",
        "authorids": "/37089660495;/37089660495",
        "aff": "NVIDIA, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981988/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14617589424540753142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981999",
        "title": "Planning to Practice: Efficient Online Fine-Tuning by Composing Goals in Latent Space",
        "track": "main",
        "status": "Poster",
        "abstract": "General-purpose robots require diverse repertoires of behaviors to complete challenging tasks in real-world unstructured environments. To address this issue, goal-conditioned reinforcement learning aims to acquire policies that can reach configurable goals for a wide range of tasks on command. However, such goal-conditioned policies are notoriously difficult and time-consuming to train from scratch. In this paper, we propose Planning to Practice (PTP), a method that makes it practical to train goal-conditioned policies for long-horizon tasks that require multiple distinct types of interactions to solve. Our approach is based on two key ideas. First, we decompose the goal-reaching problem hierarchically, with a high-level planner that sets intermediate subgoals using conditional subgoal generators in the latent space for a low-level model-free policy. Second, we propose a hybrid approach which first pre-trains both the conditional subgoal generator and the policy on previously collected data through offline reinforcement learning, and then fine-tunes the policy via online exploration. This fine-tuning process is itself facilitated by the planned subgoals, which breaks down the original target task into short-horizon goal-reaching tasks that are significantly easier to learn. We conduct experiments in both the simulation and real world, in which the policy is pre-trained on demonstrations of short primitive behaviors and fine-tuned for temporally extended tasks that are unseen in the offline data. Our experimental results show that PTP can generate feasible sequences of subgoals that enable the policy to efficiently solve the target tasks. 11Supplementary video: sites.google.com/view/planning-to-practice",
        "primary_area": "",
        "author": "Kuan Fang;Patrick Yin;Ashvin Nair;Sergey Levine;Kuan Fang;Patrick Yin;Ashvin Nair;Sergey Levine",
        "authorids": "/37089658860;/37089661390;/37086106243;/37085481973;/37089658860;/37089661390;/37086106243;/37085481973",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981999/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8889692761740655853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982056",
        "title": "Planning under periodic observations: bounds and bounding-based solutions",
        "track": "main",
        "status": "Poster",
        "abstract": "We study planning problems faced by robots operating in uncertain environments with incomplete knowledge of state, and actions that are noisy and/or imprecise. This paper identifies a new problem sub-class that models settings in which information is revealed only intermittently through some exogenous process that provides state information periodically. Several practical domains fit this model, including the specific scenario that motivates our research: autonomous navigation of a planetary exploration rover augmented by remote imaging. With an eye to efficient specialized solution methods, we examine the structure of instances of this sub-class. They lead to Markov Decision Processes with exponentially large action-spaces but for which, as those actions comprise sequences of more atomic elements, one may establish performance bounds by comparing policies under different information assumptions. This provides a way in which to construct performance bounds systematically. Such bounds are useful because, in conjunction with the insights they confer, they can be employed in bounding-based methods to obtain high-quality solutions efficiently; the empirical results we present demonstrate their effectiveness for the considered problems. The foregoing has also alluded to the distinctive role that time plays for these problems -more specifically: time until information is revealed- and we uncover and discuss several interesting subtleties in this regard.",
        "primary_area": "",
        "author": "Federico Rossi;Dylan A. Shell;Federico Rossi;Dylan A. Shell",
        "authorids": "/37085471827;/37269198900;/37085471827;/37269198900",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Dept. of Comp. Sci. & Eng., Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982056/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3791683913482998836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "California Institute of Technology;Texas A&M University",
        "aff_unique_dep": "Jet Propulsion Laboratory;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.tamu.edu",
        "aff_unique_abbr": "Caltech;TAMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pasadena;College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981883",
        "title": "Planning with Intermittent State Observability: Knowing When to Act Blind",
        "track": "main",
        "status": "Poster",
        "abstract": "Contemporary planning models and methods often rely on constant availability of free state information at each step of execution. However, autonomous systems are increasingly deployed in the open world where state information may be costly or simply unavailable in certain situations. Failing to account for sensor limitations may lead to costly behavior or even catastrophic failure. While the partially observable Markov decision process (POMDP) can be used to model this problem, solving POMDPs is often intractable. We introduce a planning model called a semi-observable Markov decision process (SOMDP) specifically designed for MDPs where state observability may be intermittent. We propose an approach for solving SOMDPs that uses memory states to proactively plan for the potential loss of sensor information while exploiting the unique structure of SOMDPs. Our theoretical analysis and empirical evaluation demonstrate the advantages of SOMDPs relative to existing planning models.",
        "primary_area": "",
        "author": "Connor Basich;John Peterson;Shlomo Zilberstein;Connor Basich;John Peterson;Shlomo Zilberstein",
        "authorids": "/37087105976;/37089658391;/37285091900;/37087105976;/37089658391;/37285091900",
        "aff": "University of Massachusetts Amherst, Amherst, Massachusetts; University of Massachusetts Amherst, Amherst, Massachusetts; University of Massachusetts Amherst, Amherst, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981883/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2400223563891958729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981317",
        "title": "Plate Harmonic Reducer with a Profiled Groove Wave Generator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a mechanism that realizes a novel structural form of the harmonic reducer is introduced. Conventional robots often use various mechanical reducers owing to low torque and high-speed characteristics of electric motors. Among them, harmonic reducers are frequently used because of their compact size and backlash-free precision. The plate harmonic reducer which uses the same topological geometry and reducing mechanism as the conventional harmonic reducer is a novel type of strain gear that changes its shape to a plate form for axial deformation. It has unique differences in terms of axial thickness, torsional stiffness, and efficiency due to its morphological characteristics. This study introduces and analyzes the reducing principle of the plate harmonic reducer and describes the methodological solutions for realization. Finally, the theoretical performance improvement and operating feasibility of the plate harmonic reducer are analyzed using finite element method and a 3D-printed prototype model.",
        "primary_area": "",
        "author": "Seungbin You;Jaesug Jung;Eunho Sung;Jaeheung Park;Seungbin You;Jaesug Jung;Eunho Sung;Jaeheung Park",
        "authorids": "/37088924527;/37085674476;/37088924804;/37281014000;/37088924527;/37085674476;/37088924804;/37281014000",
        "aff": "Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; ASRI, RICS, Seoul National University, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981317/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15538945537424342720&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Intelligence and Information",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981307",
        "title": "Playful Interactions for Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Ahstract- One of the key challenges in visual imitation learning is collecting large amounts of expert demonstrations for a given task. While methods for collecting human demonstrations are becoming easier with teleoperation methods and the use of low-cost assistive tools, we often still require 100\u20131000 demonstrations for every task to learn a visual representation and policy. To address this, we turn to an alternate form of data that does not require task-specific demonstrations - play. Playing is a fundamental method children use to learn a set of skills and behaviors and visual representations in early learning. Importantly, play data is diverse, task-agnostic, and relatively cheap to obtain. In this work, we propose to use playful interactions in a self-supervised manner to learn visual representations for downstream tasks. We collect 2 hours of playful data in 19 diverse environments and use self-predictive learning to extract visual representations. Given these representations, we train policies using imitation learning for two downstream tasks: Pushing and Stacking. We demonstrate that our visual representations generalize better than standard behavior cloning and can achieve similar performance with only half the number of required demonstrations. Our representations, which are trained from scratch, compare favorably against ImageNet pretrained representations. Finally, we provide an experimental analysis on the effects of different pretraining modes on downstream task learning.",
        "primary_area": "",
        "author": "Sarah Young;Jyothish Pari;Pieter Abbeel;Lerrel Pinto;Sarah Young;Jyothish Pari;Pieter Abbeel;Lerrel Pinto",
        "authorids": "/37089659614;/37089662067;/37542877900;/37085796211;/37089659614;/37089662067;/37542877900;/37085796211",
        "aff": "UC Berkeley; NYU; UC Berkeley; NYU",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981307/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8807679239869218128&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UC Berkeley;NYU",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Berkeley;New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982231",
        "title": "Polynomial Time Near-Time-Optimal Multi-Robot Path Planning in Three Dimensions with Applications to Large-Scale UAV Coordination",
        "track": "main",
        "status": "Poster",
        "abstract": "For enabling efficient, large-scale coordination of unmanned aerial vehicles (UAV s) under the labeled setting, in this work, we develop the first polynomial time algorithm for the reconfiguration of many moving bodies in three-dimensional spaces, with provable 1. xx asymptotic makespan optimality guarantee under high robot density. More precisely, on an m_{1} \\times m_{2} \\times m_{3}m_{1} \\times m_{2} \\times m_{3} grid, m_{1}\\geq m_{2}\\geq m_{3}m_{1}\\geq m_{2}\\geq m_{3}, our method computes solutions for routing up to \\displaystyle \\frac{m_{1}m_{2}m_{3}}{3}\\displaystyle \\frac{m_{1}m_{2}m_{3}}{3} uniquely labeled robots with uniformly randomly distributed start and goal configurations within a makespan of m_{1}+2m_{2}+2m_{3}+o(m_{1})m_{1}+2m_{2}+2m_{3}+o(m_{1}), with high probability. Because the makespan lower bound for such instances is m_{1}+m_{2}+m_{3}-o(m_{1})m_{1}+m_{2}+m_{3}-o(m_{1}), also with high probability, as m_{1}\\displaystyle \\rightarrow\\infty, \\frac{m_{1}+2m_{2}+2m_{3}}{m_{1}+m_{2}+m_{3}}m_{1}\\displaystyle \\rightarrow\\infty, \\frac{m_{1}+2m_{2}+2m_{3}}{m_{1}+m_{2}+m_{3}} optimality guarantee is achieved. \\displaystyle \\frac{m_{1}+2 m_{2}+2m_{3}}{m_{1}+m_{2}+m_{3}}\\in\\left(1, \\displaystyle \\frac{5}{3}\\right]\\displaystyle \\frac{m_{1}+2 m_{2}+2m_{3}}{m_{1}+m_{2}+m_{3}}\\in\\left(1, \\displaystyle \\frac{5}{3}\\right], yielding 1. xx optimality. In contrast, it is well-known that multi-robot path planning is NP-hard to optimally solve. In numerical evaluations, our method readily scales to support the motion planning of over 100, 000 robots in 3D while simultaneously achieving 1. xx optimality. We demonstrate the application of our method in coordinating many quadcopters in both simulation and hardware experiments.",
        "primary_area": "",
        "author": "Teng Guo;Si Wei Feng;Jingjin Yu;Teng Guo;Si Wei Feng;Jingjin Yu",
        "authorids": "/37088998158;/37087233222;/37536570700;/37088998158;/37087233222;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982231/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10023381541442305349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981553",
        "title": "Polytopic Planar Region Characterization of Rough Terrains for Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of constructing polytopic representations for planar regions from depth camera readings. This problem is of great importance for terrain mapping in complicated environment and has great potentials in legged locomotion applications. To address the polytopic planar region characterization problem, we propose a two-stage solution scheme. At the first stage, the planar regions embedded within a sequence of depth images are extracted individually and then merged to establish a terrain map containing only planar regions in a selected frame. To simplify the representations of the planar regions that are applicable to foothold planning for legged robots, we further approximate the extracted planar regions via convex polytopes at the second stage. With the polytopic representation, the proposed approach achieves a great balance between accuracy and simplicity. Experimental validations with RGB-D cameras are conducted to demonstrate the performance of the proposed scheme. The proposed scheme successfully characterizes the planar regions via polytopes with acceptable accuracy. More importantly, the run time of the overall scheme is less than 10ms (i.e., > 100Hz) throughout the tests, which strongly illustrates the advantages of our approach developed in this paper.",
        "primary_area": "",
        "author": "Zhi Xu;Hongbo Zhu;Hua Chen;Wei Zhang;Zhi Xu;Hongbo Zhu;Hua Chen;Wei Zhang",
        "authorids": "/37089659915;/37089663279;/37086195529;/37089656248;/37089659915;/37089663279;/37086195529;/37089656248",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981553/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=456863235220748922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981420",
        "title": "Pose Refinement with Joint Optimization of Visual Points and Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "High-precision camera re-localization technology in a pre-established 3D environment map is the basis for many tasks, such as Augmented Reality, Robotics and Autonomous Driving. The point-based visual re-localization approaches are well-developed in recent decades, but are insufficient in some feature-less cases. In this paper, we design a complete pipeline for camera pose refinement with points and lines, which contains the innovatively designed line extracting CNN named VLSE, the line matching and the pose optimization approaches. We adopt a novel line representation and customize a hybrid convolution block based on the Stacked Hourglass network [1], to detect accurate and stable line features on images. Then we apply a geometric-based strategy to obtain precise 2D-3D line correspondences using epipolar constraint and reprojection filtering. A following point-line joint cost function is constructed to optimize the camera pose with the initial coarse pose from the pure point-based localization. Sufficient experiments are conducted on open datasets, i.e, line extractor on Wireframe and YorkUrban, localization performance on InLoc ducl and duc2, to confirm the effectiveness of our point-line joint pose optimization method.",
        "primary_area": "",
        "author": "Shuang Gao;Jixiang Wan;Yishan Ping;Xudong Zhang;Shuzhou Dong;Yuchen Yang;Haikuan Ning;Jijunnan Li;Yandong Guo;Shuang Gao;Jixiang Wan;Yishan Ping;Xudong Zhang;Shuzhou Dong;Yuchen Yang;Haikuan Ning;Jijunnan Li;Yandong Guo",
        "authorids": "/37088995862;/37089659685;/37089660151;/37088687401;/37089663071;/37088996325;/37089661367;/37088999430;/37087008648;/37088995862;/37089659685;/37089660151;/37088687401;/37089663071;/37088996325;/37089661367;/37088999430;/37087008648",
        "aff": "OPPO Research Institute, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981420/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11565854561667840444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;0;0;0;0;0",
        "aff_unique_norm": "OPPO Research Institute;Shanghai Jiao Tong University",
        "aff_unique_dep": ";Department of Automation",
        "aff_unique_url": "https://www.oppo.com;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "OPPO RI;SJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981562",
        "title": "PoseIt: A Visual-Tactile Dataset of Holding Poses for Grasp Stability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans grasp objects in the real world, we often move our arms to hold the object in a different pose where we can use it. In contrast, typical lab settings only study the stability of the grasp immediately after lifting, without any subsequent re-positioning of the arm. However, the grasp stability could vary widely based on the object's holding pose, as the gravitational torque and gripper contact forces could change completely. To facilitate the study of how holding poses affect grasp stability, we present PoseIt, a novel multi-modal dataset that contains visual and tactile data collected from a full cycle of grasping an object, re-positioning the arm to one of the sampled poses, and shaking the object. Using data from PoseIt, we can formulate and tackle the task of predicting whether a grasped object is stable in a particular held pose. We train an LSTM classifier that achieves 85% accuracy on the proposed task. Our experimental results show that multi-modal models trained on PoseIt achieve higher accuracy than using solely vision or tactile data and that our classifiers can also generalize to unseen objects and poses. The PoseIt dataset is publicly released here: https://github.com/CMURoboTouch/PoseIt.",
        "primary_area": "",
        "author": "Shubham Kanitkar;Helen Jiang;Wenzhen Yuan;Shubham Kanitkar;Helen Jiang;Wenzhen Yuan",
        "authorids": "/37089662228;/37089663930;/37085486405;/37089662228;/37089663930;/37085486405",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981562/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3603969131991773517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981711",
        "title": "Position-based Treadmill Drive with Wire Traction for Experience of Level Ground Walking from Gait Acceleration State to Steady State",
        "track": "main",
        "status": "Poster",
        "abstract": "A treadmill system has a large potential to provide humans with an augmented walking experience in real-life without a spatial limitation. However, a treadmill gait is different from walking on level ground. In previous studies, the adaptive belt speed control of a treadmill was developed to achieve a self-paced walking for making the users' treadmill gait similar to their level ground gait. Such studies have focused on steady-state walking and regulating the user's position on the treadmill. A normal gait can be divided into an acceleration state after gait initiation, a steady state, and a deceleration state for stopping. The objective of this study is to develop a treadmill system with a wire tension application enabling a human to experience a similar gait to a level ground gait during the transition phase from an acceleration state to a steady state. We developed a treadmill 4 m long \u00d7 1 m wide. To allow a user to move on the treadmill during the gait acceleration phase, an insensitive zone where a user can move without the treadmill belt drive was set. In addition, the treadmill was equipped with a wire traction system to apply a traction force canceling the effect of the belt floor acceleration of the treadmill when the belt speed of the treadmill changes. Through an experiment with six participants, the proposed treadmill system allowed the users to move in an acceleration state with the same head acceleration pattern as with level ground walking and cancel the inertial effect with the wire traction, which enabled the users to transition to a steady state from an acceleration state.",
        "primary_area": "",
        "author": "Tamon Miyake;Shunya Itano;Mitsuhiro Kamezaki;Shigeki Sugano;Tamon Miyake;Shunya Itano;Mitsuhiro Kamezaki;Shigeki Sugano",
        "authorids": "/37085875459;/37089658987;/37546400600;/37274050800;/37085875459;/37089658987;/37546400600;/37274050800",
        "aff": "Future Robotics Organization, Waseda University, Tokyo, Japan; Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Research Institute for Science and Engineering (RISE), Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981711/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4955939396389392784&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Future Robotics Organization",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981195",
        "title": "PourNet: Robust Robotic Pouring Through Curriculum and Curiosity-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Pouring liquids accurately into containers is one of the most challenging tasks for robots as they are unaware of the complex fluid dynamics and the behavior of liquids when pouring. Therefore, it is not possible to formulate a generic pouring policy for real-time applications. In this paper, we propose PourNet, as a generalized solution to pouring different liquids into containers. PourNet is a hybrid planner that uses deep reinforcement learning, for end-effector planning, and Nonlinear Model Predictive Control, for joint planning. In this work, we introduce a novel simulation environment using Unity3D and NVIDIA-Flex to train our agents. By effective choice of the state space, action space and the reward functions, we allow for a direct sim-to-real transfer of the learned skills without additional training. In the simulation, PourNet outperforms state-of-the-art by an average of 4.9g deviation for water-like, and 9.2g deviation for honey-like liquids. In the real-world scenario using Kinova Movo Platform, PourNet achieves an average pouring deviation of 2.3g for dish soap when using a novel pouring container. The average pouring deviation measured for water was 5.5g. All comprehensive experiments and the simulation environment is available at: http://cxdcxd.github.io/RRS/.",
        "primary_area": "",
        "author": "Edwin Babaians;Tapan Sharma;Mojtaba Karimi;Sahand Sharifzadeh;Eckehard Steinbach;Edwin Babaians;Tapan Sharma;Mojtaba Karimi;Sahand Sharifzadeh;Eckehard Steinbach",
        "authorids": "/37085653235;/37089662190;/38667191100;/37088855885;/37273225600;/37085653235;/37089662190;/38667191100;/37088855885;/37273225600",
        "aff": "Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM); Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM); Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM); Ludwig Maximilian University of Munich (LMU), Germany; Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981195/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7186238759216765391&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Ludwig Maximilian University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.tum.de;https://www.lmu.de",
        "aff_unique_abbr": "TUM;LMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981660",
        "title": "PrePARE: Predictive Proprioception for Agile Failure Event Detection in Robotic Exploration of Extreme Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots can traverse a wide variety of terrains, some of which may be challenging for wheeled robots, such as stairs or highly uneven surfaces. However, quadruped robots face stability challenges on slippery surfaces. This can be resolved by adjusting the robot's locomotion by switching to more conservative and stable locomotion modes, such as crawl mode (where three feet are in contact with the ground always) or amble mode (where one foot touches down at a time) to prevent potential falls. To tackle these challenges, we propose an approach to learn a model from past robot experience for predictive detection of potential failures. Accordingly, we trigger gait switching merely based on proprioceptive sensory information. To learn this predictive model, we propose a semi-supervised process for detecting and annotating ground truth slip events in two stages: We first detect abnormal occurrences in the time series sequences of the gait data using an unsupervised anomaly detector, and then, the anomalies are verified with expert human knowledge in a replay simulation to assert the event of a slip. These annotated slip events are then used as ground truth examples to train an ensemble decision learner for predicting slip probabilities across terrains for traversability. We analyze our model on data recorded by a legged robot on multiple sites with slippery terrain. We demonstrate that a potential slip event can be predicted up to 720 ms ahead of a potential fall with an average precision greater than 0.95 and an average F-score of 0.82. Finally, we validate our approach in real-time by deploying it on a legged robot and switching its gait mode based on slip event detection.",
        "primary_area": "",
        "author": "Sharmita Dey;David Fan;Robin Schmid;Anushri Dixit;Kyohei Otsu;Thomas Touma;Arndt F. Schilling;Ali-Akbar Agha-Mohammadi;Sharmita Dey;David Fan;Robin Schmid;Anushri Dixit;Kyohei Otsu;Thomas Touma;Arndt F. Schilling;Ali-Akbar Agha-Mohammadi",
        "authorids": "/37086921349;/37086010932;/37089663404;/37089224786;/37085558541;/37088472679;/37086155660;/38274170800;/37086921349;/37086010932;/37089663404;/37089224786;/37085558541;/37088472679;/37086155660;/38274170800",
        "aff": "University of Goettingen, University Medical Center, Goettingen, Germany; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Swiss Federal Institute of Technology (ETH Z\u00fcrich), Zurich, Switzerland; Control and Dynamical Systems, California Institute of Technology, Pasadena, CA, USA; Control and Dynamical Systems, California Institute of Technology, Pasadena, CA, USA; Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; University of Goettingen, University Medical Center, Goettingen, Germany; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981660/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11709849968515661394&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;3;3;3;0;3",
        "aff_unique_norm": "University of Goettingen;Georgia Institute of Technology;ETH Zurich;California Institute of Technology",
        "aff_unique_dep": "University Medical Center;Institute for Robotics and Intelligent Machines;;Control and Dynamical Systems",
        "aff_unique_url": "https://www.uni-goettingen.de;https://www.gatech.edu;https://www.ethz.ch;https://www.caltech.edu",
        "aff_unique_abbr": "UG;Georgia Tech;ETH Z\u00fcrich;Caltech",
        "aff_campus_unique_index": "0;1;2;3;3;3;0;3",
        "aff_campus_unique": "Goettingen;Atlanta;Zurich;Pasadena",
        "aff_country_unique_index": "0;1;2;1;1;1;0;1",
        "aff_country_unique": "Germany;United States;Switzerland"
    },
    {
        "id": "9981057",
        "title": "Precise Position Control of a Multi-rotor UAV with a Cable-suspended Mechanism During Water Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of water sampling by using a multirotor UAV with a cable-suspended mechanism. In order to ensure the safe execution of the sampling procedure and the stabilization of the vehicle, the disturbances, induced by the water flow and transferred through the cable, have to be identified. Specifically, an estimate of the disturbances is extracted by integrating a depth sensor, a load cell, an ultrasonic sensor and a downward-looking camera into the UAV's sensor suite and fusing the respective measurements. Gaussian Processes are afterwards employed so as to learn the uncertain disturbances in real time and in a non-parametric manner. The predicted disturbances are incorporated into a geometric control scheme which is capable of stabilizing the UAV above the desired sampling position while compensating for the aforementioned disturbances. The performance of the proposed control strategy is demonstrated through both simulation and experimental results.",
        "primary_area": "",
        "author": "Fotis Panetsos;George C. Karras;Sotirios N. Aspragkathos;Kostas J. Kyriakopoulos;Fotis Panetsos;George C. Karras;Sotirios N. Aspragkathos;Kostas J. Kyriakopoulos",
        "authorids": "/37089472738;/38559666800;/37089474488;/38181756700;/37089472738;/38559666800;/37089474488;/38181756700",
        "aff": "Control Systems Lab, School of Mechanical Engineering, National Technical, University of Athens, Athens, Greece; Dept. of Computer Science and Telecommunications, University of Thessaly, Lamia, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical, University of Athens, Athens, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical, University of Athens, Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981057/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18067593273519549624&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "National Technical University of Athens;University of Thessaly",
        "aff_unique_dep": "School of Mechanical Engineering;Dept. of Computer Science and Telecommunications",
        "aff_unique_url": "https://www.ntua.gr;https://www.uth.gr",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Athens;Lamia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9981716",
        "title": "Predicting fruit-pick success using a grasp classifier trained on a physical proxy",
        "track": "main",
        "status": "Poster",
        "abstract": "Apple picking is a challenging manipulation task, but it is difficult to test solutions due to the limited window of time that apples are in season. Previous methods have built simulations of apple trees, but simulations rarely capture soft contact and deformation well, both of which are common in fruit picking. In this paper we present and validate a physical proxy that replicates the mechanics of a real world apple pick. This proxy, in conjunction with a novel hand with multiple sensors, enables large-scale capture of sensor data for data collection and testing. To validate our approach, we train a Long Short-Term Memory network to classify a pick as successful or failed based on sensor feedback from the robot hand. We show that a network trained on the proxy performs as well, or even better, than a network trained solely on real apple trees, with accuracies up to 90%. We determine which sensors are most important for pick classification and also demonstrate that our proxy preserves the most important sensor feature data for pick classification. For our hand, the most informative sensor was the finger's servomotor effort.",
        "primary_area": "",
        "author": "Alejandro Velasquez;Nigel Swenson;Miranda Cravetz;Cindy Grimm;Joseph R. Davidson;Alejandro Velasquez;Nigel Swenson;Miranda Cravetz;Cindy Grimm;Joseph R. Davidson",
        "authorids": "/37089660773;/37088997404;/37089197002;/37085798146;/37075739400;/37089660773;/37088997404;/37089197002;/37085798146;/37075739400",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981716/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5215146390636913734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981677",
        "title": "Predictive Angular Potential Field-based Obstacle Avoidance for Dynamic UAV Flights",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, unmanned aerial vehicles (UAVs) are used for numerous inspection and video capture tasks. Manually controlling UAVs in the vicinity of obstacles is challenging, however, and poses a high risk of collisions. Even for autonomous flight, global navigation planning might be too slow to react to newly perceived obstacles. Disturbances such as wind might lead to deviations from the planned trajectories. In this work, we present a fast predictive obstacle avoidance method that does not depend on higher-level localization or mapping and maintains the dynamic flight capabilities of UAVs. It directly operates on LiDAR range images in real time and adjusts the current flight direction by computing angular potential fields within the range image. The velocity magnitude is subsequently determined based on a trajectory prediction and time-to-contact estimation. Our method is evaluated using Hardware-in-the-Loop simulations. It keeps the UAV at a safe distance to obstacles, while allowing higher flight velocities than previous reactive obstacle avoidance methods that directly operate on sensor data.",
        "primary_area": "",
        "author": "Daniel Schleich;Sven Behnke;Daniel Schleich;Sven Behnke",
        "authorids": "/37088599582;/37295987100;/37088599582;/37295987100",
        "aff": "Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981677/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7059476456708796860&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981473",
        "title": "Prismatic Soft Actuator Augments the Workspace of Soft Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are promising for manipulation tasks thanks to their compliance, safety, and high degree of freedom. However, the commonly used bidirectional continuum segment design means soft robotic manipulators only function in a limited hemispherical workspace. This work increases a soft robotic arm's workspace by designing, fabricating, and controlling an additional soft prismatic actuator at the base of the soft arm. This actuator consists of pneumatic artificial muscles and a piston, making the actuator back-driveable. We increase the task space volume by 116%, and we are now able to perform manipulation tasks that were previously impossible for soft robots, such as picking and placing objects at different positions on a surface and grabbing an object out of a container. By combining a soft robotic arm with a prismatic joint, we greatly increase the usability of soft robots for object manipulation. This work promotes the use of integrated and modular soft robotic systems for practical manipulation applications in human-centered environments.",
        "primary_area": "",
        "author": "Philipp Wand;Oliver Fischer;Robert K. Katzschmann;Philipp Wand;Oliver Fischer;Robert K. Katzschmann",
        "authorids": "/37089660614;/37089449614;/37085423557;/37089660614;/37089449614;/37085423557",
        "aff": "Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981473/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17811283553645726515&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Soft Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982074",
        "title": "ProTAMP: Probabilistic Task and Motion Planning Considering Human Action for Harmonious Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "For the proper functioning of mobile manipulator-type autonomous robot performing complicated tasks in a human-robot coexistence environment, tasks and motions must be planned simultaneously. In such environments, a human and robot should collaborate with each other. Therefore, the robot must act in accordance with the human and avoid useless actions duplicated with those of humans. However, any action undertaken by a human has uncertainty, and thus, predicting them correctly is challenging. This study proposed probabilistic task and motion planning considering both deterministic and probabilistic environment changes caused by robot and human actions temporarily and spatially, respectively. First, the environmental changes were modeled, where the robot is capable of recognizing the possibility of environmental changes. Second, in task planning, the probabilities of each environmental change owing to human actions was minimized. Finally, in motion planning, a movement path connecting each task in a planned order was planned, thereby enabling the robot to perform actions not duplicated with those by a human. Furthermore, the plans generated were compared without considering possibility of human actions and the effectiveness of the proposed method was verified. Consequently, the proposed method was confirmed to reduce the time required for finishing the tasks.",
        "primary_area": "",
        "author": "Shunsuke Mochizuki;Yosuke Kawasaki;Masaki Takahashi;Shunsuke Mochizuki;Yosuke Kawasaki;Masaki Takahashi",
        "authorids": "/37089002728;/37086581875;/37275389800;/37089002728;/37086581875;/37275389800",
        "aff": "School of Science for Open and Environmental Systems, Keio University, Kohoku-ku, Yokohama, Japan; School of Science for Open and Environmental Systems, Keio University, Kohoku-ku, Yokohama, Japan; Department of System Design Engineering, Faculty of Science and Technology, Keio University, Kohoku-ku, Yokohama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982074/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7952357825555916206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Keio University",
        "aff_unique_dep": "School of Science for Open and Environmental Systems",
        "aff_unique_url": "https://www.keio.ac.jp",
        "aff_unique_abbr": "Keio",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Yokohama",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981627",
        "title": "Proactive Robotic Assistance via Theory of Mind",
        "track": "main",
        "status": "Poster",
        "abstract": "Advanced social cognitive skills enhance the effectiveness of human-robot interactions. Research shows that an important precursor to the development of these abilities in humans is Theory of Mind (ToM) - the ability to attribute mental states to oneself and to others. In this work, we endow robots with ToM abilities and propose a ToM-based approach to proactive robotic assistance by appealing to epistemic planning techniques. Our evaluation shows that robots implementing our approach and demonstrating ToM are measurably more helpful and perceived by humans as more socially intelligent compared to robots with a deficit in ToM.",
        "primary_area": "",
        "author": "Maayan Shvo;Ruthrash Hari;Ziggy O'Reilly;Sophia Abolore;Sze-Yuh Nina Wang;Sheila A. McIlraith;Maayan Shvo;Ruthrash Hari;Ziggy O'Reilly;Sophia Abolore;Sze-Yuh Nina Wang;Sheila A. McIlraith",
        "authorids": "/37089659422;/37089662016;/37089659220;/37089660353;/37089660683;/37330128000;/37089659422;/37089662016;/37089659220;/37089660353;/37089660683;/37330128000",
        "aff": "Schwartz Reisman Institute for Technology and Society; University of Toronto; University of Turin; University of Toronto; University of Toronto; Schwartz Reisman Institute for Technology and Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981627/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2122765000842586198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;0",
        "aff_unique_norm": "Schwartz Reisman Institute for Technology and Society;University of Toronto;University of Turin",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.schwartzreisman.ca;https://www.utoronto.ca;https://www.unito.it",
        "aff_unique_abbr": ";U of T;UNITO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Canada;Italy"
    },
    {
        "id": "9981146",
        "title": "Probabilistic Approach to Online Stiffness Estimation for Robotic Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Information about environmental stiffness is useful for robotic tasks involving interactions with unstructured and unknown environments. However, online estimation remains a challenge. Owing to the nature of its calculation algorithm, a large amount of noise may be generated, depending on the response value of the force and position. In this study, we propose a variable gain filter that predicts the degree of such noise using a probabilistic approach and reflects only reliable data in the estimation. We show experimentally that the proposed method improves the accuracy of the stiffness estimation without degrading the estimation time constant.",
        "primary_area": "",
        "author": "Toshiaki Tsuji;Tsukasa Kusakabe;Toshiaki Tsuji;Tsukasa Kusakabe",
        "authorids": "/37287863900;/37088809178;/37287863900;/37088809178",
        "aff": "Graduate School of Science and Engineering, Saitama University, Saitama; Graduate School of Science and Engineering, Saitama University, Saitama",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981146/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7024019015441615703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Saitama University",
        "aff_unique_dep": "Graduate School of Science and Engineering",
        "aff_unique_url": "https://www.saitama-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Saitama",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981750",
        "title": "Probabilistic Data Association for Semantic SLAM at Scale",
        "track": "main",
        "status": "Poster",
        "abstract": "With advances in image processing and machine learning, it is now feasible to incorporate semantic information into the problem of simultaneous localisation and mapping (SLAM). Previously, SLAM was carried out using lower level geometric features (points, lines, and planes) which are often view-point dependent and error prone in visually repetitive environments. Semantic information can improve the ability to recognise previously visited locations, as well as maintain sparser maps for long term SLAM applications. However, SLAM in repetitive environments has the critical problem of assigning measurements to the landmarks which generated them. In this paper, we use k-best assignment enumeration to compute marginal assignment probabilities for each measurement landmark pair, in real time. We present numerical studies on the KITTI dataset to demonstrate the effectiveness and speed of the proposed framework.",
        "primary_area": "",
        "author": "Elad Michael;Tyler Summers;Tony A. Wood;Chris Manzie;Iman Shames;Elad Michael;Tyler Summers;Tony A. Wood;Chris Manzie;Iman Shames",
        "authorids": "/37086940214;/38574644100;/37085538426;/37299177600;/37400016300;/37086940214;/38574644100;/37085538426;/37299177600;/37400016300",
        "aff": "Department of Electrical and Electronic Engineering, University of Melbourne; Control, Optimization, and Networks Lab, University of Texas at Dallas; SYCAMORE Lab, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland; Department of Electrical and Electronic Engineering, University of Melbourne; CIICADA Lab, School of Engineering, Australian National University, Acton, ACT, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981750/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13451511683026116895&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "University of Melbourne;University of Texas at Dallas;Ecole Polytechnique Federale de Lausanne;Australian National University",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering;Control, Optimization, and Networks Lab;SYCAMORE Lab;School of Engineering",
        "aff_unique_url": "https://www.unimelb.edu.au;https://www.utdallas.edu;https://www.epfl.ch;https://www.anu.edu.au",
        "aff_unique_abbr": "UniMelb;UT Dallas;EPFL;ANU",
        "aff_campus_unique_index": "1;2;3",
        "aff_campus_unique": ";Dallas;Lausanne;Acton",
        "aff_country_unique_index": "0;1;2;0;0",
        "aff_country_unique": "Australia;United States;Switzerland"
    },
    {
        "id": "9981316",
        "title": "Probabilistic Object Maps for Long-Term Robot Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots deployed in settings such as warehouses and parking lots must cope with frequent and substantial changes when localizing in their environments. While many previous localization and mapping algorithms have explored methods of identifying and focusing on long-term features to handle change in such environments, we propose a different approach - can a robot understand the distribution of movable objects and relate it to observations of such objects to reason about global localization? In this paper, we present probabilistic object maps (POMs), which represent the distributions of movable objects using pose-likelihood sample pairs derived from prior trajectories through the environment and use a Gaussian process classifier to generate the likelihood of an object at a query pose. We also introduce POM-Localization, which uses an observation model based on POMs to perform inference on a factor graph for globally consistent long-term localization. We present empirical results showing that POM-Localization is indeed effective at producing globally consistent localization estimates in challenging real-world environments and that POM-Localization improves trajectory estimates even when the POM is formed from partially incorrect data.",
        "primary_area": "",
        "author": "Amanda Adkins;Taijing Chen;Joydeep Biswas;Amanda Adkins;Taijing Chen;Joydeep Biswas",
        "authorids": "/37089662226;/37089662931;/37538259200;/37089662226;/37089662931;/37538259200",
        "aff": "Department of Computer Science, The University of Texas at Austin, Austin, TX; Department of Computer Science, The University of Texas at Austin, Austin, TX; Department of Computer Science, The University of Texas at Austin, Austin, TX",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981316/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10821228777333525396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981460",
        "title": "Probabilistic Planning for AUV Data Harvesting from Smart Underwater Sensor Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Harvesting valuable ocean data, ranging from climate and marine life analysis to industrial equipment monitoring, is an extremely challenging real-world problem. Sparse underwater sensor networks are a promising approach to scale to larger and deeper environments, but these have difficulty offloading their data without external assistance. Traditionally, offloading data has been achieved by costly, fixed communication infrastructure. In this paper, we propose a planning under uncertainty method that enables an autonomous underwater vehicle (AUV) to adaptively collect data from smart sensor networks in underwater environments. Our novel solution exploits the ability of sensor nodes to provide the AUV with time-of-flight acoustic localisation, and is able to prioritise nodes with the most valuable data. In both simulated experiments and a real-world field trial, we demonstrate that our method outperforms the type of hand-designed behaviours that has previously been used in the context of underwater data harvesting.",
        "primary_area": "",
        "author": "Matthew Budd;Georgios Salavasidis;Izzat Karnarudzaman;Catherine A. Harris;Alexander B. Phillips;Paul Duckworth;Nick Hawes;Bruno Lacerda;Matthew Budd;Georgios Salavasidis;Izzat Karnarudzaman;Catherine A. Harris;Alexander B. Phillips;Paul Duckworth;Nick Hawes;Bruno Lacerda",
        "authorids": "/37088687755;/37085814508;/37089660927;/37086000893;/37709361700;/37087188849;/37590842900;/38230417200;/37088687755;/37085814508;/37089660927;/37086000893;/37709361700;/37087188849;/37590842900;/38230417200",
        "aff": "Oxford Robotics Institute, University of Oxford; Marine Autonomous and Robotic Systems, National Oceanography Centre, Southampton; Marine Autonomous and Robotic Systems, National Oceanography Centre, Southampton; Marine Autonomous and Robotic Systems, National Oceanography Centre, Southampton; Marine Autonomous and Robotic Systems, National Oceanography Centre, Southampton; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981460/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14570858258867652405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;0;0;0",
        "aff_unique_norm": "University of Oxford;National Oceanography Centre",
        "aff_unique_dep": "Oxford Robotics Institute;Marine Autonomous and Robotic Systems",
        "aff_unique_url": "https://www.ox.ac.uk;https://noc.ac.uk",
        "aff_unique_abbr": "Oxford;NOC",
        "aff_campus_unique_index": "0;1;1;1;1;0;0;0",
        "aff_campus_unique": "Oxford;Southampton",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982076",
        "title": "ProgressLabeller: Visual Data Stream Annotation for Training Object-Centric 3D Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual perception tasks often require vast amounts of labelled data, including 3D poses and image space segmen-tation masks. The process of creating such training data sets can prove difficult or time-intensive to scale up to efficacy for general use. Consider the task of pose estimation for rigid objects. Deep neural network based approaches have shown good performance when trained on large, public datasets. However, adapting these networks for other novel objects, or fine-tuning existing models for different environments, requires significant time investment to generate newly labelled instances. Towards this end, we propose ProgressLabeller as a method for more efficiently generating large amounts of 6D pose training data from color images sequences for custom scenes in a scalable manner. ProgressLabeller is intended to also support transparent or translucent objects, for which the previous methods based on depth dense reconstruction will fail. We demonstrate the effectiveness of ProgressLabeller by rapidly create a dataset of over 1M samples with which we fine-tune a state-of-the-art pose estimation network in order to markedly improve the downstream robotic grasp success rates. Progresslabeller is open-source at https://github.com/huijieZH/ProgressLabeller",
        "primary_area": "",
        "author": "Xiaotong Chen;Huijie Zhang;Zeren Yu;Stanley Lewis;Odest Chadwicke Jenkins;Xiaotong Chen;Huijie Zhang;Zeren Yu;Stanley Lewis;Odest Chadwicke Jenkins",
        "authorids": "/37087322826;/37089660831;/37089663241;/37088686540;/37297252400;/37087322826;/37089660831;/37089663241;/37088686540;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute at the University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982076/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7816580462241798853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981798",
        "title": "Pseudo-label Guided Cross-video Pixel Contrast for Robotic Surgical Scene Segmentation with Limited Annotations",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical scene segmentation is fundamentally crucial for prompting cognitive assistance in robotic surgery. However, pixel-wise annotating surgical video in a frame-by-frame manner is expensive and time consuming. To greatly reduce the labeling burden, in this work, we study semi-supervised scene segmentation from robotic surgical video, which is practically essential yet rarely explored before. We consider a clinically suitable annotation situation under the equidistant sampling. We then propose PGV-CL, a novel pseudo-label guided cross-video contrast learning method to boost scene segmentation. It effectively leverages unlabeled data for a trusty and global model regularization that produces more discriminative feature representation. Concretely, for trusty representation learning, we propose to incorporate pseudo labels to instruct the pair selection, obtaining more reliable representation pairs for pixel contrast. Moreover, we expand the representation learning space from previous image-level to cross-video, which can capture the global semantics to benefit the learning process. We extensively evaluate our method on a public robotic surgery dataset EndoVis18 and a public cataract dataset CaDIS. Experimental results demonstrate the effectiveness of our method, consistently outperforming the state-of-the-art semi-supervised methods under different labeling ratios, and even surpassing fully supervised training on EndoVis18 with 10.1% labeling. Our code is available at https://github.com/yangyu-cuhk/PGV-CL.",
        "primary_area": "",
        "author": "Yang Yu;Zixu Zhao;Yueming Jin;Guangyong Chen;Qi Dou;Pheng-Ann Heng;Yang Yu;Zixu Zhao;Yueming Jin;Guangyong Chen;Qi Dou;Pheng-Ann Heng",
        "authorids": "/37089578555;/37088904291;/37086369638;/37085726158;/37085465414;/37283077400;/37089578555;/37088904291;/37086369638;/37085726158;/37085465414;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science, Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London; Zhejiang Lab; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence, Synergy SystemsShenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981798/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1826359180558132589&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;3",
        "aff_unique_norm": "Chinese University of Hong Kong;University College London;Zhejiang Lab;Shenzhen Institute of Advanced Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science;;Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk;http://www.zhejianglab.com;http://www.siat.cas.cn",
        "aff_unique_abbr": "CUHK;UCL;;SIAT",
        "aff_campus_unique_index": "0;0;1;0;3",
        "aff_campus_unique": "Hong Kong SAR;London;;Shenzhen",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9981502",
        "title": "Qualitative Belief Space Planning via Compositions",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning under uncertainty is a fundamental problem in robotics. Classical approaches rely on a metrical representation of the world and robot's states to infer the next course of action. While these approaches are considered accurate, they are often susceptible to metric errors and tend to be costly regarding memory and time consumption. However, in some cases, relying on qualitative geometric information alone is sufficient. Hence, the issues described above become an unnecessary burden. This work presents a novel qualitative Belief Space Planning (BSP) approach, highly suitable for platforms with low-cost sensors and particularly appealing in sparse environment scenarios. Our algorithm generalizes its predecessors by avoiding any deterministic assumptions. Moreover, it smoothly incorporates spatial information propagation techniques, known as compositions. We demonstrate our algorithm in simulations and the advantage of using compositions in particular.",
        "primary_area": "",
        "author": "Itai Zilberman;Vadim Indelman;Itai Zilberman;Vadim Indelman",
        "authorids": "/37089278786;/37541538000;/37089278786;/37541538000",
        "aff": "Department of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981502/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3683661547285832553&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981032",
        "title": "Quantifying Changes in Kinematic Behavior of a Human-Exoskeleton Interactive System",
        "track": "main",
        "status": "Poster",
        "abstract": "While human-robot interaction studies are becoming more common, quantification of the effects of repeated interaction with an exoskeleton remains unexplored. We draw upon existing literature in human skill assessment and present extrinsic and intrinsic performance metrics that quantify how the human-exoskeleton system's behavior changes over time. Specifically, in this paper, we present a new performance metric that provides insight into the system's kinematics associated with \u2018successful\u2019 movements resulting in a richer characterization of changes in the system's behavior. A human subject study is carried out wherein participants learn to play a challenging and dynamic reaching game over multiple attempts, while donning an upper-body exoskeleton. The results demonstrate that repeated practice results in learning over time as identified through the improvement of extrinsic performance. Changes in the newly developed kinematics-based measure further illumi-nate how the participant's intrinsic behavior is altered over the training period. Thus, we are able to quantify the changes in the human-exoskeleton system's behavior observed in relation with learning.",
        "primary_area": "",
        "author": "Keya Ghonasgi;Reuth Mirsky;Adrian M. Haith;Peter Stone;Ashish D. Deshpande;Keya Ghonasgi;Reuth Mirsky;Adrian M. Haith;Peter Stone;Ashish D. Deshpande",
        "authorids": "/37086480491;/37089195703;/37947191500;/37269574900;/37405479700;/37086480491;/37089195703;/37947191500;/37269574900;/37405479700",
        "aff": "Mechanical Engineering Department, The University of Texas at Austin; Computer Science Department, Bar Ilan University; Neuroscience Department, Johns Hopkins University; Sony AI; Mechanical Engineering Department, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981032/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13690636834345602862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Texas at Austin;Bar-Ilan University;Johns Hopkins University;Sony",
        "aff_unique_dep": "Mechanical Engineering Department;Computer Science Department;Neuroscience Department;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.biu.ac.il;https://www.jhu.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;BIU;JHU;Sony AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;1;0;2;0",
        "aff_country_unique": "United States;Israel;Japan"
    },
    {
        "id": "9982058",
        "title": "Quantifying Safety of Learning-based Self-Driving Control Using Almost-Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Path-tracking control of self-driving vehicles can benefit from deep learning for tackling longstanding challenges such as nonlinearity and uncertainty. However, deep neural controllers lack safety guarantees, restricting their practical use. We propose a new approach of learning almost-barrier functions, which approximately characterizes the forward invariant set for the system under neural controllers, to quantitatively analyze the safety of deep neural controllers for path-tracking. We design sampling-based learning procedures for constructing candidate neural barrier functions, and certification procedures that utilize robustness analysis for neural networks to identify regions where the barrier conditions are fully satisfied. We use an adversarial training loop between learning and certification to optimize the almost-barrier functions. The learned barrier can also be used to construct online safety monitors through reachability analysis. We demonstrate effectiveness of our methods in quantifying safety of neural controllers in various simulation environments, ranging from simple kinematic models to the TORCS simulator with high-fidelity vehicle dynamics simulation.",
        "primary_area": "",
        "author": "Zhizhen Qin;Tsui-Wei Weng;Sicun Gao;Zhizhen Qin;Tsui-Wei Weng;Sicun Gao",
        "authorids": "/37089659525;/37085781099;/37088349203;/37089659525;/37085781099;/37088349203",
        "aff": "University of California, San Diego; University of California, San Diego; University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982058/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=622108228467599771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982116",
        "title": "Quantity over Quality: Training an AV Motion Planner with Large Scale Commodity Vision Data",
        "track": "main",
        "status": "Poster",
        "abstract": "With the Autonomous Vehicle (AV) industry shifting towards machine-learned approaches for motion plan-ning [1], the performance of self-driving systems is starting to rely heavily on large quantities of expert driving demon-strations. However, collecting this demonstration data typically involves expensive HD sensor suites (LiDAR + RADAR + cameras), which quickly becomes financially infeasible at the scales required. This motivates the use of commodity sensors like cameras for data collection, which are an order of mag-nitude cheaper than HD sensor suites, but offer lower fidelity. Leveraging these sensors for training an AV motion planner opens a financially viable path to observe the \u2018long tail\u2019 of driving events. As our main contribution we show it is possible to train a high-performance motion planner using commodity vision data which outperforms planners trained on HD-sensor data for a fraction of the cost. To the best of our knowledge, we are the first to demonstrate this using real-world data. We compare the performance of the autonomy system on these two different sensor configurations, and show that we can compensate for the lower sensor fidelity by means of increased quantity: a planner trained on 100h of commodity vision data outperforms the one with 25h of expensive HD data (see Fig. 1). We also share the engineering challenges we had to tackle to make this work.",
        "primary_area": "",
        "author": "Lukas Platinsky;Tayyab Naseer;Hui Chen;Ben Haines;Haoyue Zhu;Hugo Grimmett;Luca Del Pero;Lukas Platinsky;Tayyab Naseer;Hui Chen;Ben Haines;Haoyue Zhu;Hugo Grimmett;Luca Del Pero",
        "authorids": "/37086099574;/37085448545;/37089661900;/37089658151;/37089663195;/37076422900;/37075867600;/37086099574;/37085448545;/37089661900;/37089658151;/37089663195;/37076422900;/37075867600",
        "aff": "Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited; Woven Planet United Kingdom Limited",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982116/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12111618852107470242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Woven Planet",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wovenplanet.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981498",
        "title": "Quasistatic contact-rich manipulation via linear complementarity quadratic programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact-rich manipulation is challenging due to dynamically-changing physical constraints by the contact mode changes undergone during manipulation. This paper proposes a versatile local planning and control framework for contact-rich manipulation that determines the continuous control action under variable contact modes online. We model the physical characteristics of contact-rich manipulation by quasistatic dynamics and complementarity constraints. We then propose a linear complementarity quadratic program (LCQP) to efficiently determine the control action that implicitly includes the decisions on the contact modes under these constraints. In the LCQP, we relax the complementarity constraints to alleviate ill-conditioned problems that are typically caused by measure noises or model miss-matches. We conduct dynamical simulations on a 3D physical simulator and demonstrate that the proposed method can achieve various contact-rich manipulation tasks by determining the control action including the contact modes in real-time.",
        "primary_area": "",
        "author": "Sotaro Katayarna;Tatsunori Taniai;Kazutoshi Tanaka;Sotaro Katayarna;Tatsunori Taniai;Kazutoshi Tanaka",
        "authorids": "/37089662381;/37089919100;/37088507484;/37089662381;/37089919100;/37088507484",
        "aff": "Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981498/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12913116945615816895&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Kyoto University;OMRON SINIC X Corporation",
        "aff_unique_dep": "Department of System Science, Graduate School of Informatics;",
        "aff_unique_url": "https://www.kyoto-u.ac.jp;",
        "aff_unique_abbr": "Kyoto U;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Kyoto;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981963",
        "title": "RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous Jumping",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots with high locomotive performance have been extensively studied, and various leg structures have been proposed. Especially, a leg structure that can achieve both continuous and high jumps is advantageous for moving around in a three-dimensional environment. In this study, we propose a parallel wire-driven leg structure, which has one DoF of linear motion and two DoFs of rotation and is controlled by six wires, as a structure that can achieve both continuous jumping and high jumping. The proposed structure can simultaneously achieve high controllability on each DoF, long acceleration distance and high power required for jumping. In order to verify the jumping performance of the parallel wire-driven leg structure, we have developed a parallel wire-driven monopedal robot, RAMIEL. RAMIEL is equipped with quasi-direct drive, high power wire winding mechanisms and a lightweight leg, and can achieve a maximum jumping height of 1.6 m and a maximum of seven continuous jumps.",
        "primary_area": "",
        "author": "Temma Suzuki;Yasunori Toshimitsu;Yuya Nagamatsu;Kento Kawaharazuka;Akihiro Miki;Yoshimoto Ribayashi;Masahiro Bando;Kunio Kojima;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Temma Suzuki;Yasunori Toshimitsu;Yuya Nagamatsu;Kento Kawaharazuka;Akihiro Miki;Yoshimoto Ribayashi;Masahiro Bando;Kunio Kojima;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37089658134;/37086842924;/37086275431;/37086101930;/37089295157;/37089659025;/37086302355;/37085360901;/38242437800;/37280639000;/37286658200;/37089658134;/37086842924;/37086275431;/37086101930;/37089295157;/37089659025;/37086302355;/37085360901;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981963/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6633852001839743122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981580",
        "title": "RANK - Robotic Ankle: Design and testing on irregular terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the large amount of available exoskeletons, their use in daily life is still limited due to the absence of testing in real-life environments. Thus, the present work aims to test on a series of uneven terrains a wearable ankle exoskeleton, named RANK, designed for walking assistance and drop-foot prevention. RANK consists of a 3D-printed brace attached to the user and a piezoresistive insole, to be incorporated into the user's shoe. Real-time analysis of the insole's sensor outputs enables the control system to provide torque assistance to the ankle joint through a four-bar linkage mechanism. Two healthy male subjects were enrollee, asking them to walk on three different terrain conditions (flat, soft, and irregular) with and without exoskeleton. Human kinematics was gathered via inertial measurements units (IMUs). The effects of ankle exoskeleton on lower limb joint angles were assessed in terms of range of motion (ROM), whereas statistical parametric map method was applied to compare joint angle curves. As expected, a reduction of the ankle ROM approximatively of 10\u00b0 was found in all terrain conditions between the trails performed with and without exoskeleton. No effects induced on the hip and knee joint were observed. Moreover, no significant differences were found over the almost totality of the gait cycle regardless the terrain conditions. Results demonstrate the capability of the exoskeleton to work properly regardless the type of walking surface.",
        "primary_area": "",
        "author": "J. Taborri;I. Mileti;G. Mariani;L. Mattioli;L. Liguori;S. Salvatori;E. Palermo;F. Patan\u00e8;S. Rossi;J. Taborri;I. Mileti;G. Mariani;L. Mattioli;L. Liguori;S. Salvatori;E. Palermo;F. Patan\u00e8;S. Rossi",
        "authorids": "/37085722653;/37085851487;/37088439151;/37089663162;/37089658491;/37320373400;/37085737979;/38243184300;/37969941500;/37085722653;/37085851487;/37088439151;/37089663162;/37089658491;/37320373400;/37085737979;/38243184300;/37969941500",
        "aff": "Department of Economics Engineering Business Organization (DEIM), University of Tuscia, Viterbo, Italy; Department of Engineering, Mechanical Measurements and Microelectronics Laboratory (M3-Lab), University Niccol\u00f2 Cusano, Rome, Italy; Department of Economics Engineering Business Organization (DEIM), University of Tuscia, Viterbo, Italy; Department of Mechanical and Aerospace Engineering (DIMA), University of Sapienza, Roma, Italy; Department of Mechanical and Aerospace Engineering (DIMA), University of Sapienza, Roma, Italy; Department of Engineering, Mechanical Measurements and Microelectronics Laboratory (M3-Lab), University Niccol\u00f2 Cusano, Rome, Italy; Department of Mechanical and Aerospace Engineering (DIMA), University of Sapienza, Roma, Italy; Department of Engineering, Mechanical Measurements and Microelectronics Laboratory (M3-Lab), University Niccol\u00f2 Cusano, Rome, Italy; Department of Economics Engineering Business Organization (DEIM), University of Tuscia, Viterbo, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981580/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6701299863261082183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;2;2;1;2;1;0",
        "aff_unique_norm": "University of Tuscia;University Niccol\u00f2 Cusano;University of Sapienza",
        "aff_unique_dep": "Department of Economics Engineering Business Organization (DEIM);Department of Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.unitus.it;https://www.unicusano.it;https://www.uniroma1.it",
        "aff_unique_abbr": "Tuscia;UNICUSANO;Sapienza",
        "aff_campus_unique_index": "0;1;0;2;2;1;2;1;0",
        "aff_campus_unique": "Viterbo;Rome;Roma",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981668",
        "title": "RAPTOR: Rapid Aerial Pickup and Transport of Objects by Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Rapid aerial grasping through robots can lead to many applications that utilize fast and dynamic picking and placing of objects. Rigid grippers traditionally used in aerial manipulators require high precision and specific object geometries for successful grasping. We propose RAPTOR, a quadcopter platform combined with a custom Fin Ray\u00aegripper to enable more flexible grasping of objects with different geometries, leveraging the properties of soft materials to increase the contact surface between the gripper and the objects. To reduce the communication latency, we present a new lightweight middleware solution based on Fast DDS (Data Distribution Service) as an alternative to ROS (Robot Operating System). We show that RAPTOR achieves an average of 83% grasping efficacy in a real-world setting for four different object geometries while moving at an average velocity of 1 m/s during grasping. In a high-velocity setting, RAPTOR supports up to four times the payload compared to previous works. Our results highlight the potential of aerial drones in automated warehouses and other manipulation applications where speed, swiftness, and robustness are essential while operating in hard-to-reach places.11Code: https://github.com/raptor-ethz/raptor_setup",
        "primary_area": "",
        "author": "Aurel X. Appius;Erik Bauer;Marc Bl\u00f6chlinger;Aashi Kalra;Robin Oberson;Arman Raayatsanati;Pascal Strauch;Sarath Suresh;Marco von Salis;Robert K. Katzschmann;Aurel X. Appius;Erik Bauer;Marc Bl\u00f6chlinger;Aashi Kalra;Robin Oberson;Arman Raayatsanati;Pascal Strauch;Sarath Suresh;Marco von Salis;Robert K. Katzschmann",
        "authorids": "/37089660907;/37089662295;/37089663442;/37089658228;/37089660587;/37089661047;/37089659232;/37089658962;/37089661199;/37085423557;/37089660907;/37089662295;/37089663442;/37089658228;/37089660587;/37089661047;/37089659232;/37089658962;/37089661199;/37085423557",
        "aff": "Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland; Soft Robotics Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981668/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4658064110577097524&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Soft Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982066",
        "title": "RARA: Zero-shot Sim2Real Visual Navigation with Following Foreground Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "The gap between simulation and the real-world restrains many machine learning breakthroughs in computer vision and reinforcement learning from being applicable in the real world. In this work, we tackle this gap for the specific case of camera-based navigation, formulating it as following a visual cue in the foreground with arbitrary backgrounds. The visual cue in the foreground can often be simulated realistically, such as a line, gate or cone. The challenge then lies in coping with the unknown backgrounds and integrating both. As such, the goal is to train a visual agent on data captured in an empty simulated environment except for this foreground cue and test this model directly in a visually diverse real world. In order to bridge this big gap, we show it's crucial to combine following techniques namely: Randomized augmentation of the fore- and background, regularization with both deep supervision and triplet loss and finally abstraction of the dynamics by using waypoints rather than direct velocity commands. The various techniques are ablated in our experimental results both qualitatively and quantitatively finally demonstrating a successful transfer from simulation to the real world. Code will be made available on publication22Project page: github.com/kkelchte/tgbg.",
        "primary_area": "",
        "author": "Klaas Kelchtermans;Tinne Tuytelaars;Klaas Kelchtermans;Tinne Tuytelaars",
        "authorids": "/37085991114;/37282935100;/37085991114;/37282935100",
        "aff": "KULeuven, ESAT-PSI, Belgium; KULeuven, ESAT-PSI, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982066/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4278499659852730780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "ESAT-PSI",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9981494",
        "title": "RCA: Ride Comfort-Aware Visual Navigation via Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Under shared autonomy, wheelchair users expect vehicles to provide safe and comfortable rides while following users' high-level navigation plans. To find such a path, vehicles negotiate with different terrains and assess their traversal difficulty. Most prior works model surroundings either through geometric representations or semantic classifications, which do not reflect perceived motion intensity and ride comfort in downstream navigation tasks. We propose to model ride comfort explicitly in traversability analysis using proprioceptive sensing. We develop a self-supervised learning framework to predict traversability costmap from first-person-view images by leveraging vehicle states as training signals. Our approach estimates how the vehicle would \u201cfeel\u201d if traversing over based on terrain appearances. We then show our navigation system provides human-preferred ride comfort through robot experiments together with a human evaluation study. The project could be found at https://sites.google.com/view/rca-navigation.",
        "primary_area": "",
        "author": "Xinjie Yao;Ji Zhang;Jean Oh;Xinjie Yao;Ji Zhang;Jean Oh",
        "authorids": "/37089659003;/38541910000;/37933996900;/37089659003;/38541910000;/37933996900",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981494/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10933629746622347215&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982244",
        "title": "RCare World: A Human-centric Simulation World for Caregiving Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present RCareWorld, a human-centric simulation world for physical and social robotic caregiving designed with inputs from stakeholders. RCareWorld has realistic human models of care recipients with mobility limitations and caregivers, home environments with multiple levels of accessibility and assistive devices, and robots commonly used for caregiving. It interfaces with various physics engines to model diverse material types necessary for simulating caregiving scenarios, and provides the capability to plan, control, and learn both human and robot control policies by integrating with state-of-the-art external planning and learning libraries, and VR devices. We propose a set of realistic caregiving tasks in RCareWorld as a benchmark for physical robotic caregiving and provide baseline control policies for them. We illustrate the high-fidelity simulation capabilities of RCareWorld by demonstrating the execution of a policy learnt in simulation for one of these tasks on a real-world setup. Additionally, we perform a real-world social robotic caregiving experiment using behaviors modeled in RCareWorld. Robotic caregiving, though potentially impactful towards enhancing the quality of life of care recipients and caregivers, is a field with many barriers to entry due to its interdisciplinary facets. RCareWorld takes the first step towards building a realistic simulation world for robotic caregiving that would enable researchers worldwide to contribute to this impactful field. Demo videos and supplementary materials can be found at: https://emprise.cs.cornell.edu/rcareworld/.",
        "primary_area": "",
        "author": "Ruolin Ye;Wenqiang Xu;Haoyuan Fu;Rajat Kumar Jenamani;Vy Nguyen;Cewu Lu;Katherine Dimitropoulou;Tapomayukh Bhattacharjee;Ruolin Ye;Wenqiang Xu;Haoyuan Fu;Rajat Kumar Jenamani;Vy Nguyen;Cewu Lu;Katherine Dimitropoulou;Tapomayukh Bhattacharjee",
        "authorids": "/37089318674;/37088221545;/37089235078;/37089663685;/37089659266;/37085483529;/37089663786;/37531634500;/37089318674;/37088221545;/37089235078;/37089663685;/37089659266;/37085483529;/37089663786;/37531634500",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY, USA; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Columbia University, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982244/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15512881050664298612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;0;1;2;0",
        "aff_unique_norm": "Cornell University;Shanghai Jiao Tong University;Columbia University",
        "aff_unique_dep": "Department of Computer Science;School of Electronic Information and Electrical Engineering;",
        "aff_unique_url": "https://www.cornell.edu;https://www.sjtu.edu.cn;https://www.columbia.edu",
        "aff_unique_abbr": "Cornell;SJTU;Columbia",
        "aff_campus_unique_index": "0;1;1;0;0;1;0",
        "aff_campus_unique": "Ithaca;Shanghai;",
        "aff_country_unique_index": "0;1;1;0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981968",
        "title": "RECALL: Rehearsal-free Continual Learning for Object Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional neural networks show remarkable results in classification but struggle with learning new things on the fly. We present a novel rehearsal-free approach, where a deep neural network is continually learning new unseen object categories without saving any data of prior sequences. Our approach is called RECALL, as the network recalls categories by calculating logits for old categories before training new ones. These are then used during training to avoid changing the old categories. For each new sequence, a new head is added to accommodate the new categories. To mitigate forgetting, we present a regularization strategy where we replace the classification with a regression. Moreover, for the known categories, we propose a Mahalanobis loss that includes the variances to account for the changing densities between known and unknown categories. Finally, we present a novel dataset for continual learning (HOWS-CL-25), especially suited for object recognition on a mobile robot, including 150,795 synthetic images of 25 household object categories. Our approach RECALL outperforms the current state of the art on CORe50 and iCIFAR-100 and reaches the best performance on HOWS-CL-25.",
        "primary_area": "",
        "author": "Markus Knauer;Maximilian Denninger;Rudolph Triebel;Markus Knauer;Maximilian Denninger;Rudolph Triebel",
        "authorids": "/37089659618;/37086577819;/37542908700;/37089659618;/37086577819;/37542908700",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Technical University of Munich (TUM), Germany; Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981968/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14024201997516423060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "German Aerospace Center;Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "DLR;TUM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Oberpfaffenhofen;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982068",
        "title": "RECCraft System: Towards Reliable and Efficient Collective Robotic Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "This research presents a novel Collective Robotic Construction (CRC) system named RECCraft. The RECCraft hardware system is composed of the mobile manipulation vehicles, the cubic blocks, and the folding ramp blocks. Solid connection and easy removal of the blocks are achieved by an electropermanent magnet and silicon steel sheets. With one degree of freedom (DOF) lifting manipulator, the robot can carry a block 3.7 times its volume. An active folding ramp block can provide a robust passage to the upper level for the robot. Our study focuses on systemic improvement of the construction speed and reliability of the robotic construction system. Visual perception system realized by Apritag is adopted, featured by convenient deployment and high precision, to provide a reliable guarantee for robotic construction. RL-based planner provides end-to-end solution for planning tasks of building multi-layer constructions, which is validated by simulation platform and real prototype. Compared with construction speed of existing robotic construction systems, our proposed RECCraft system achieves state-of-the-art level. The robot builds a 2-layer construction by RL-based planner in 4 minutes and 16 seconds, which achieves construction volumetric throughput of 6.7\u00d7105 mm3/s.",
        "primary_area": "",
        "author": "Qiwei Xu;Yizheng Zhang;Shenghao Zhang;Rui Zhao;Zhuoxing Wu;Dongsheng Zhang;Cheng Zhou;Xiong Li;Jiahong Chen;Zengjun Zhao;Luyang Tang;Zhengyou Zhang;Lei Han;Qiwei Xu;Yizheng Zhang;Shenghao Zhang;Rui Zhao;Zhuoxing Wu;Dongsheng Zhang;Cheng Zhou;Xiong Li;Jiahong Chen;Zengjun Zhao;Luyang Tang;Zhengyou Zhang;Lei Han",
        "authorids": "/37089662293;/37086859483;/37089660140;/37089659330;/37089660669;/37089659097;/37089659976;/37089660521;/37089662772;/37089661128;/37089658556;/37089658853;/37089660216;/37089662293;/37086859483;/37089660140;/37089659330;/37089660669;/37089659097;/37089659976;/37089660521;/37089662772;/37089661128;/37089658556;/37089658853;/37089660216",
        "aff": "Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982068/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=632984690534049887&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.tencent.com",
        "aff_unique_abbr": "Tencent",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981860",
        "title": "RGB-X Classification for Electronics Sorting",
        "track": "main",
        "status": "Poster",
        "abstract": "Effectively disassembling and recovering materials from waste electrical and electronic equipment (WEEE) is a critical step in moving global supply chains from carbon-intensive, mined materials to recycled and renewable ones. Conventional recycling processes rely on shredding and sorting waste streams, but for WEEE, which is comprised of numerous dissimilar materials, we explore targeted disassembly of numerous objects for improved material recovery. Many WEEE objects share many key features and therefore can look quite similar, but their material composition and internal component layout can vary, and thus it is critical to have an accurate classifier for subsequent disassembly steps for accurate material separation and recovery. This work introduces RGB-X, a multi-modal image classification approach, that utilizes key features from external RGB images with those generated from X-ray images to accurately classify electronic objects. More specifically, this work develops Iterative Class Activation Mapping (iCAM), a novel network architecture that explicitly focuses on the finer-details in the multi-modal feature maps that are needed for accurate electronic object classification. In order to train a classifier, electronic objects lack large and well annotated X-ray datasets due to expense and need of expert guidance. To overcome this issue, we present a novel way of creating a synthetic dataset using domain randomization applied to the X-ray domain. The combined RGB-X approach gives us an accuracy of 98.6% on 10 generations of modern smartphones, which is greater than their individual accuracies of 89.1% (RGB) and 97.9% (X-ray) independently. We provide experimental results133Experimental work done at Biorobotics Lab, Robotics Institute, Carnegie Mellon University to corroborate our results.",
        "primary_area": "",
        "author": "Abhimanyu Fnu;Tejas Zodage;Umesh Thillaivasan;Xinyue Lai;Rahul Chakwate;Javier Santillan;Emma Oti;Ming Zhao;Ralph Boirum;Howie Choset;Matthew Travers;Abhimanyu Fnu;Tejas Zodage;Umesh Thillaivasan;Xinyue Lai;Rahul Chakwate;Javier Santillan;Emma Oti;Ming Zhao;Ralph Boirum;Howie Choset;Matthew Travers",
        "authorids": "/37089659524;/37088637095;/37089661584;/37089658863;/37088641978;/37089658583;/37089659771;/37089736217;/37089662743;/37281322200;/37545390200;/37089659524;/37088637095;/37089661584;/37089658863;/37088641978;/37089658583;/37089659771;/37089736217;/37089662743;/37281322200;/37545390200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Apple Inc.; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Apple Inc.; Apple Inc.; Apple Inc.; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981860/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5372417848709400514&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;1;0;0;1;1;1;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Apple",
        "aff_unique_dep": "Robotics Institute;Apple Inc.",
        "aff_unique_url": "https://www.cmu.edu;https://www.apple.com",
        "aff_unique_abbr": "CMU;Apple",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981797",
        "title": "RHH-LGP: Receding Horizon And Heuristics-Based Logic-Geometric Programming For Task And Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential decision-making and motion planning for robotic manipulation induce combinatorial complexity. For long-horizon tasks, especially when the environment comprises many objects that can be interacted with, planning efficiency becomes even more important. To plan such long-horizon tasks, we present the RHH-LGP algorithm for combined task and motion planning (TAMP). First, we propose a TAMP approach (based on Logic-Geometric Programming) that effectively uses geometry-based heuristics for solving long-horizon manipulation tasks. The efficiency of this planner is then further improved by a receding horizon formulation, resulting in RHH-LGP. We demonstrate the robustness and effectiveness of our approach on a diverse range of long-horizon tasks that require reasoning about interactions with a large number of objects. Using our framework, we can solve tasks that require multiple robots, including a mobile robot and snake-like walking robots, to form novel heterogeneous kinematic structures autonomously. By combining geometry-based heuristics with iterative planning, our approach brings an order-of-magnitude reduction of planning time in all investigated problems.",
        "primary_area": "",
        "author": "Cornelius V. Braun;Joaquim Ortiz-Haro;Marc Toussaint;Ozgur S. Oguz;Cornelius V. Braun;Joaquim Ortiz-Haro;Marc Toussaint;Ozgur S. Oguz",
        "authorids": "/37089658418;/37088998356;/37528418600;/37085638620;/37089658418;/37088998356;/37528418600;/37085638620",
        "aff": "Imperial College, London, United Kingdom; International Max Planck Research School for Intelligent Systems (IMPRS-IS); Learning and Intelligent Systems Group, TU Berlin, Germany; Bilkent University, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981797/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14025612296206632367&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Imperial College London;Max Planck Institute for Intelligent Systems;Technische Universit\u00e4t Berlin;Bilkent University",
        "aff_unique_dep": ";Intelligent Systems;Learning and Intelligent Systems Group;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.mpituebingen.mpg.de;https://www.tu-berlin.de;https://www.bilkent.edu.tr",
        "aff_unique_abbr": "Imperial;IMPRS-IS;TU Berlin;Bilkent",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "London;;Berlin",
        "aff_country_unique_index": "0;1;1;2",
        "aff_country_unique": "United Kingdom;Germany;T\u00fcrkiye"
    },
    {
        "id": "9982184",
        "title": "RIANet: Road Graph and Image Attention Network for Urban Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel autonomous driving framework, called a road graph and image attention network (RIANet), which computes the attention scores of objects in the image using the road graph feature. The process of the proposed method is as follows: First, the feature encoder module encodes the road graph, image, and additional features of the scene. The attention network module then incorporates the encoded features and computes the scene context feature via the attention mechanism. Finally, the low-level controller mod-ule drives the ego-vehicle based on the scene context feature. In the experiments, we use an urban scene driving simulator named CARLA to train and test the proposed method. The results show that the proposed method outperforms existing autonomous driving methods.",
        "primary_area": "",
        "author": "Timothy Ha;Jeongwoo Oh;Hojun Chung;Gunmin Lee;Songhwai Oh;Timothy Ha;Jeongwoo Oh;Hojun Chung;Gunmin Lee;Songhwai Oh",
        "authorids": "/37086455599;/37089660359;/37089661410;/37087323658;/37068116900;/37086455599;/37089660359;/37089661410;/37087323658;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982184/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15689590582717763381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981601",
        "title": "RILI: Robustly Influencing Latent Intent",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots interact with human partners, often these partners change their behavior in response to the robot. On the one hand this is challenging because the robot must learn to coordinate with a dynamic partner. But on the other hand - if the robot understands these dynamics - it can harness its own behavior, influence the human, and guide the team towards effective collaboration. Prior research enables robots to learn to influence other robots or simulated agents. In this paper we extend these learning approaches to now influence humans. What makes humans especially hard to influence is that - not only do humans react to the robot - but the way a single user reacts to the robot may change over time, and different humans will respond to the same robot behavior in different ways. We therefore propose a robust approach that learns to influence changing partner dynamics. Our method first trains with a set of partners across repeated interactions, and learns to predict the current partner's behavior based on the previous states, actions, and rewards. Next, we rapidly adapt to new partners by sampling trajectories the robot learned with the original partners, and then leveraging those existing behaviors to influence the new partner dynamics. We compare our resulting algorithm to state-of-the-art baselines across simulated environments and a user study where the robot and participants collaborate to build towers. We find that our approach outperforms the alternatives, even when the partner follows new or unexpected dynamics. Videos of the user study are available here: https://youtu.be/1YsWM8An18g",
        "primary_area": "",
        "author": "Sagar Parekh;Soheil Habibian;Dylan P. Losey;Sagar Parekh;Soheil Habibian;Dylan P. Losey",
        "authorids": "/37089612937;/37088483485;/37085812055;/37089612937;/37088483485;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981601/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10596986154010329131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982153",
        "title": "ROLL: Long-Term Robust LiDAR-based Localization With Temporary Mapping in Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-term scene changes pose challenges to localization systems using a pre-built map. This paper presents a LiDAR-based system that provides robust localization against those challenges. Our method starts with activation of a mapping process temporarily when global matching towards the pre-built map is unreliable. The temporary map will be merged onto the pre-built map for later localization sessions once reliable matching is obtained again. We further integrate a LiDAR inertial odometry (LIO) to provide motion-compensated LiDAR scans and a reliable pose initial estimate for the global matching module. To generate a smooth real-time trajectory for navigation purposes, we fuse poses from odometry and global matching by solving a pose graph optimization problem. We evaluate our localization system with extensive experiments on the NCLT dataset including a variety of changing indoor and outdoor environments, and the results demonstrate a robust and accurate long-term localization performance. The implementations are open sourced on GitHub11https://github.com/HaisenbergPeng/ROLL.",
        "primary_area": "",
        "author": "Bin Peng;Hongle Xie;Weidong Chen;Bin Peng;Hongle Xie;Weidong Chen",
        "authorids": "/37089658550;/37088507358;/37279187800;/37089658550;/37088507358;/37279187800",
        "aff": "Key Laboratory of System Control and Information Processing, Institute of Medical Robotics and Department of Automation, Shanghai Jiao Tong University and Ministry of Education, Shanghai, China; Key Laboratory of System Control and Information Processing, Institute of Medical Robotics and Department of Automation, Shanghai Jiao Tong University and Ministry of Education, Shanghai, China; Key Laboratory of System Control and Information Processing, Institute of Medical Robotics and Department of Automation, Shanghai Jiao Tong University and Ministry of Education, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982153/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4658952782140537393&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981471",
        "title": "RPG: Learning Recursive Point Cloud Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel point cloud generator that is able to reconstruct and generate 3D point clouds composed of semantic parts. Given a latent representation of the target 3D model, the generation starts from a single point and gets expanded recursively to produce the high-resolution point cloud via a sequence of point expansion stages. During the recursive procedure of generation, we not only obtain the coarse-to-fine point clouds for the target 3D model from every expansion stage, but also unsupervisedly discover the semantic segmentation of the target model according to the hierarchical/parent-child relation between the points across expansion stages. Moreover, the expansion modules and other elements used in our recursive generator are mostly sharing weights thus making the overall framework light and efficient. Extensive experiments are conducted to show that our point cloud generator has comparable or even superior performance on both generation and reconstruction tasks in comparison to various baselines, and provides the consistent co-segmentation among instances of the same object class.",
        "primary_area": "",
        "author": "Wei-Jan Kol;Chen-Yi Chiu;Yu-Liang Kuo;Wei-Chen Chiu;Wei-Jan Kol;Chen-Yi Chiu;Yu-Liang Kuo;Wei-Chen Chiu",
        "authorids": "/37089658340;/37089660931;/37089663332;/37086286145;/37089658340;/37089660931;/37089663332;/37086286145",
        "aff": "Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981471/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14953027919560264760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NCTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981186",
        "title": "Ranging-Aided Ground Robot Navigation Using UWB Nodes at Unknown Locations",
        "track": "main",
        "status": "Poster",
        "abstract": "Ranging information from ultra-wideband (UWB) ranging radios can be used to improve estimated navigation accuracy of a ground robot with other on-board sensors. However, all ranging-aided navigation methods demand the locations of ranging nodes to be known, which is not suitable for time-pressed situations, dynamic cluttered environments, or collaborative navigation applications. This paper describes a new ranging-aided navigation approach that does not require the locations of ranging radios. Our approach formulates relative pose constraints using ranging readings. The formulation is based on geometric relationships between each stationary ranging node and two ranging antennas on the moving robot across time. Our experiments show that estimated navigation accuracy of the ground robot is substantially enhanced with ranging information using our approach under a variety of scenarios, when ranging nodes are placed at unknown locations. We analyze and compare our performance with a traditional ranging-aided method, which requires mapping the positions of ranging nodes. We also demonstrate the applicability of our approach for collaborative navigation in large-scale unknown environments, by using ranging information from one mobile robot to improve navigation estimation of the other robot. This application does not require the installation of ranging nodes at fixed locations.",
        "primary_area": "",
        "author": "Abhinav Rajvanshi;Han-Pang Chiu;Alex Krasner;Mikhail Sizintsev;Glenn Murray;Supun Samarasekera;Abhinav Rajvanshi;Han-Pang Chiu;Alex Krasner;Mikhail Sizintsev;Glenn Murray;Supun Samarasekera",
        "authorids": "/37086135114;/37596940200;/37089301268;/37419109000;/37085543523;/37326240700;/37086135114;/37596940200;/37089301268;/37419109000;/37085543523;/37326240700",
        "aff": "Center for Vision Technologies, SRI International, Princeton, NJ, USA; Center for Vision Technologies, SRI International, Princeton, NJ, USA; Center for Vision Technologies, SRI International, Princeton, NJ, USA; Center for Vision Technologies, SRI International, Princeton, NJ, USA; Center for Vision Technologies, SRI International, Princeton, NJ, USA; Center for Vision Technologies, SRI International, Princeton, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981186/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6364917339710426505&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "SRI International",
        "aff_unique_dep": "Center for Vision Technologies",
        "aff_unique_url": "https://www.sri.com",
        "aff_unique_abbr": "SRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981777",
        "title": "ReINView: Re-interpreting Views for Multi-view 3D Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-view-based 3D object recognition is important in robot-environment interaction. However, recent methods simply extract features from each view via convolutional neural networks (CNNs) and then fuse these features together to make predictions. These methods ignore the inherent ambiguities of each view caused due to 3D-2D projection. To address this problem, we propose a novel deep framework for multi-view-based 3D object recognition. Instead of fusing the multi-view features directly, we design a re-interpretation module (ReINView) to eliminate the ambiguities at each view. To achieve this, ReINView re-interprets view features patch by patch by using their context from nearby views, considering that local patches are generally co-visible at nearby viewpoints. Since contour shapes are essential for 3D object recognition as well, ReINView further performs view-level re-interpretation, in which we use all the views as context sources since the target contours to be re-interpreted are globally observable. The re-interpreted multi-view features can better reflect the 3D global and local structures of the object. Experiments on both ModelNet40 and ModelNet10 show that the proposed model outperforms state-of-the-art methods in 3D object recognition.",
        "primary_area": "",
        "author": "Ruchang Xu;Wei Ma;Qing Mil;Hongbin Zha;Ruchang Xu;Wei Ma;Qing Mil;Hongbin Zha",
        "authorids": "/37088646990;/37085790935;/37089661976;/37271683200;/37088646990;/37085790935;/37089661976;/37271683200",
        "aff": "Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981777/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5432425098310925080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Beijing University of Technology;Peking University",
        "aff_unique_dep": "Faculty of Information Technology;School of Electronics Engineering and Computer Science",
        "aff_unique_url": "http://www.bit.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "BIT;PKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981212",
        "title": "RePoSt: Distributed Self-Reconfiguration Algorithm for Modular Robots Based on Porous Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new self-reconfiguration scheme for modular robots based on a metamodule design that allows to form a 3D porous structure. The porous structure enables a parallel flow of modules inside it without blocking. The metamodule can also be used to fill its internal volume with an additional number of modules allowing the structure to be compressible and expandable. Hence, it is a potential for improving the self-reconfiguration process. We first present the metamodule model and the porous structure built using it. Then, we describe an algorithm to self-reconfigure the structure from an initial shape to a given goal shape. We evaluated the algorithm in simulation on structures composed of up to 2,700 modules. We studied the performance in term of parallelism, showed that the number of communications is proportional to the number of motions and the execution time varies linearly with the diameter of the configuration.",
        "primary_area": "",
        "author": "Jad Bassil;Beno\u00eet Piranda;Abdallah Makhoul;Julien Bourgeois;Jad Bassil;Beno\u00eet Piranda;Abdallah Makhoul;Julien Bourgeois",
        "authorids": "/37088688543;/38340189300;/37300200900;/37545876400;/37088688543;/38340189300;/37300200900;/37545876400",
        "aff": "Univ. Bourgogne Franche-Comt\u00e9 FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9 FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9 FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9 FEMTO-ST Institute, CNRS, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981212/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3584338009795652249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "FEMTO-ST Institute",
        "aff_unique_url": "https://www.ubfc.fr",
        "aff_unique_abbr": "UBFC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montb\u00e9liard",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981906",
        "title": "Reachability Based Trajectory Generation Combining Global Graph Search in Task Space and Local Optimization in Configuration Space",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a trajectory planning framework for a robot that exploits a pre-computed database of end-effector trajectories as the guidance of optimization-based inverse kinematics. We constructed a reachable graph of a robot offline, which represents feasible end-effector paths with corresponding configurations. When performing the online trajectory planning, we applied A* search to the reachable graph to find a feasible path between input start and goal globally in the task space. Its cost function has the separated term dependent on the robot, which comes from the manipulability of configurations preserved in the reachable graph, and that is dependent on the environment. Then, we solve optimization-based inverse kinematics to generate an optimal joint trajectory while utilizing the end-effector trajectory and its corresponding configurations as the guidance to avoid local optimum. We evaluated our framework quantitatively by comparing it with existing methods to confirm that it achieved a high success rate and quality of results while suppressing its computational time. We also qualitatively proved its practicality by applying it to the material handling task in the real-world. This result shows that it improved the performance of the optimization-based inverse kinematics avoiding local optimum and applicability to the different environments of the pre-computed motion database.",
        "primary_area": "",
        "author": "Iori Kumagai;Masaki Murooka;Mitsuharu Morisawa;Fumio Kanehiro;Iori Kumagai;Masaki Murooka;Mitsuharu Morisawa;Fumio Kanehiro",
        "authorids": "/38542440000;/37085365946;/37295668600;/37283667500;/38542440000;/37085365946;/37295668600;/37283667500",
        "aff": "CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981906/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2709346834539178363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Joint Robotics Laboratory",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981658",
        "title": "Reactive Motion Planning for Rope Manipulation and Collision Avoidance using Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we address the challenging problem of manipulating a flexible link, like a rope, with an aerial robot. Inspired by spraying tasks in construction and maintenance scenarios, we consider the case in which an autonomous end-effector (e.g., a spray nozzle moved by a robot or a human operator) is connected to a fixed point by a rope (e.g., a hose). To avoid collisions between the rope and the environment while the end-effector moves, we propose the use of an aerial robot as a flying companion to properly manipulate the rope away from collisions. The aerial robot is attached to the rope between the end-effector and the fixed point. Assuming no direct control of the end-effector (e.g., when operated by a human), we design a reactive and fast motion planner for the aerial robot. Grounding on the theory of Forced Geometric Fabrics, we design a motion planner that generates trajectories to drive the aerial robot to follow the end-effector, while manipulating the rope to avoid collisions in cluttered environments. To include the complex behavior of the flexible link, we propose a rope model that estimates its real-time state under forces and position-based interactions, as well as collisions with obstacle surfaces. Finally, we evaluate the system behavior and the motion planner performance in simulations, as well as in real-world experiments on an original spray painting application.",
        "primary_area": "",
        "author": "Liping Shi;Michael Pantic;Olov Andersson;Marco Tognon;Roland Siegwart;Rune Hylsberg Jacobsen;Liping Shi;Michael Pantic;Olov Andersson;Marco Tognon;Roland Siegwart;Rune Hylsberg Jacobsen",
        "authorids": "/37087045405;/37087468483;/37085816587;/37085377048;/37281398300;/38350798300;/37087045405;/37087468483;/37085816587;/37085377048;/37281398300;/38350798300",
        "aff": "Department of Electrical and Computer Engineering, Aarhus University, Aarhus, Denmark; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Department of Electrical and Computer Engineering, Aarhus University, Aarhus, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981658/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7416729819677799722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Aarhus University;ETH Zurich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Autonomous Systems Lab",
        "aff_unique_url": "https://www.au.dk;https://www.ethz.ch",
        "aff_unique_abbr": "AU;ETHZ",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Aarhus;Zurich",
        "aff_country_unique_index": "0;1;1;1;1;0",
        "aff_country_unique": "Denmark;Switzerland"
    },
    {
        "id": "9981453",
        "title": "Reactive Neural Path Planning with Dynamic Obstacle Avoidance in a Condensed Configuration Space",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Lea Steffen;Tobias Weyer;Stefan Ulbrich;Arne Roennau;R\u00fcdiger Dillmann;Lea Steffen;Tobias Weyer;Stefan Ulbrich;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37086472171;/37089660147;/38267742000;/37590849800;/37280242100;/37086472171;/37089660147;/38267742000;/37590849800;/37280242100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981453/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10972654722253232628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9982234",
        "title": "Reactive Stepping for Humanoid Robots using Reinforcement Learning: Application to Standing Push Recovery on the Exoskeleton Atalante",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art reinforcement learning is now able to learn versatile locomotion, balancing and push-recovery capabilities for bipedal robots in simulation. Yet, the reality gap has mostly been overlooked and the simulated results hardly transfer to real hardware. Either it is unsuccessful in practice because the physics is over-simplified and hardware limitations are ignored, or regularity is not guaranteed, and unexpected hazardous motions can occur. This paper presents a reinforcement learning framework capable of learning ro-bust standing push recovery for bipedal robots that smoothly transfer to reality, providing only instantaneous proprioceptive observations. By combining original termination conditions and policy smoothness conditioning, we achieve stable learning, sim-to-real transfer and safety using a policy without memory nor explicit history. Reward engineering is then used to give insights into how to keep balance. We demonstrate its performance in reality on the lower-limb medical exoskeleton Atalante.",
        "primary_area": "",
        "author": "Alexis Duburcq;Fabian Schramm;Guilhem Bo\u00e9ris;Nicolas Bredeche;Yann Chevaleyre;Alexis Duburcq;Fabian Schramm;Guilhem Bo\u00e9ris;Nicolas Bredeche;Yann Chevaleyre",
        "authorids": "/37086454579;/37089663737;/37086455317;/37294265100;/37284674900;/37086454579;/37089663737;/37086455317;/37294265100;/37284674900",
        "aff": "Universit\u00e9 Paris-Dauphine, PSL, CNRS, Laboratoire d'analyse et mod\u00e9lisation de syst\u00e8mes pour l, Paris, France; Wandercraft, Paris, France; Wandercraft, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique, ISIR, Paris, France; Universit\u00e9 Paris-Dauphine, PSL, CNRS, Laboratoire d'analyse et mod\u00e9lisation de syst\u00e8mes pour l, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982234/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1852092231439856803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Universit\u00e9 Paris-Dauphine;Wandercraft;Sorbonne Universit\u00e9",
        "aff_unique_dep": "Laboratoire d'analyse et mod\u00e9lisation de syst\u00e8mes pour l;;Institut des Syst\u00e8mes Intelligents et de Robotique",
        "aff_unique_url": "https://www.univ-paris-dauphine.fr;;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "UPD;;Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981262",
        "title": "Real-Time Distributed Multi-Robot Target Tracking via Virtual Pheromones",
        "track": "main",
        "status": "Poster",
        "abstract": "Actively searching for targets using a multi-agent system in an unknown environment poses a two-pronged prob-lem, where on the one hand we need agents to cover as much of the environment as possible and on the other have a higher density of agents where there are potential targets to maximize detection performance. This paper proposes a fully distributed solution for an ad hoc network of agents to cooperatively search an unknown environment and actively track found targets. The solution combines a distributed pheromone-based coverage control strategy with a distributed target selection mechanism.",
        "primary_area": "",
        "author": "Joseph Prince Mathew;Cameron Nowzari;Joseph Prince Mathew;Cameron Nowzari",
        "authorids": "/37089661350;/37944904700;/37089661350;/37944904700",
        "aff": "Department of Electrical and Computer Engineering, George Mason University, Fairfax, VA, USA; Department of Electrical and Computer Engineering, George Mason University, Fairfax, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981262/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11957674666266476729&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fairfax",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982054",
        "title": "Real-Time Hybrid Mapping of Populated Indoor Scenes using a Low-Cost Monocular UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles (UAVs) have been used for many applications in recent years, from urban search and rescue, to agricultural surveying, to autonomous underground mine exploration. However, deploying UAVs in tight, indoor spaces, especially close to humans, remains a challenge. One solution, when limited payload is required, is to use micro-UAVs, which pose less risk to humans and typically cost less to replace after a crash. However, micro-UAVs can only carry a limited sensor suite, e.g. a monocular camera instead of a stereo pair or LiDAR, complicating tasks like dense mapping and markerless multi-person 3D human pose estimation, which are needed to operate in tight environments around people. Monocular approaches to such tasks exist, and dense monocular mapping approaches have been successfully deployed for UAV applications. However, despite many recent works on both marker-based and markerless multi-UAV single-person motion capture, markerless single-camera multi-person 3D human pose estimation remains a much earlier-stage technology, and we are not aware of existing attempts to deploy it in an aerial context. In this paper, we present what is thus, to our knowledge, the first system to perform simultaneous mapping and multi-person 3D human pose estimation from a monocular camera mounted on a single UAV. In particular, we show how to loosely couple state-of-the-art monocular depth estimation and monocular 3D human pose estimation approaches to reconstruct a hybrid map of a populated indoor scene in real time. We validate our component-level design choices via extensive experiments on the large-scale ScanNet and GTA-IM datasets. To evaluate our system-level performance, we also construct a new Oxford Hybrid Mapping dataset of populated indoor scenes.",
        "primary_area": "",
        "author": "Stuart Golodetz;Madhu Vankadari;Aluna Everitt;Sangyun Shin;Andrew Markham;Niki Trigoni;Stuart Golodetz;Madhu Vankadari;Aluna Everitt;Sangyun Shin;Andrew Markham;Niki Trigoni",
        "authorids": "/37938271700;/37086448149;/37089660884;/37089658497;/37410667900;/37297514400;/37938271700;/37086448149;/37089660884;/37089658497;/37410667900;/37297514400",
        "aff": "University of Oxford; University of Oxford; University of Oxford; University of Oxford; University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982054/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14525047319002424735&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981675",
        "title": "Real-Time Predictive Kinematics Control of Redundancy: a Benchmark of Optimal Control Approaches",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern collaborative manipulators operate in unknown environments and share the work space with human coworkers. To ensure flexibility, their kinematic design is redundant which increases the solution space of the inverse kinematics (IK). We propose a real-time capable Predictive Kinematics Controller (PKC) that tracks task space trajectories as a first priority and computes optimal joint trajectories w.r.t. secondary objectives based on model predictive control (MPC). Therefor, the PKC solves a MPC problem in the nullspace of the task space trajectory. We benchmark a direct shooting, a direct collocation and an indirect gradient method in simulation and we identify the direct shooting method as the most efficient. We demonstrate the superior performance of the PKC compared to state-of-the-art local redundancy resolution approaches. In experiments, we show the real-time capability of our implementation.",
        "primary_area": "",
        "author": "Jonas Wittmann;Arian Kist;Daniel J. Rixen;Jonas Wittmann;Arian Kist;Daniel J. Rixen",
        "authorids": "/37088531141;/37089659964;/37393325300;/37088531141;/37089659964;/37393325300",
        "aff": "Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Chair of Applied Mechanics, Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Chair of Applied Mechanics, Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Chair of Applied Mechanics, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981675/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15970007800519778309&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981489",
        "title": "Real-Time Trajectory Planning for Aerial Perching",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel trajectory planning method for aerial perching. Compared with the existing work, the terminal states and the trajectory durations can be adjusted adaptively, instead of being determined in advance. Further-more, our planner is able to minimize the tangential relative speed on the premise of safety and dynamic feasibility. This feature is especially notable on micro aerial robots with low maneuverability or scenarios where the space is not enough. Moreover, we design a flexible transformation strategy to eliminate terminal constraints along with reducing optimization variables. Besides, we take precise SE(3) motion planning into account to ensure that the drone would not touch the landing platform until the last moment. The proposed method is validated onboard by a palm-sized micro aerial robot with quite limited thrust and moment (thrust-to-weight ratio 1.7) perching on a mobile inclined surface. Sufficient experimental results show that our planner generates an optimal trajectory within 20ms, and replans with warm start in 2ms.",
        "primary_area": "",
        "author": "Jialin Ji;Tiankai Yang;Chao Xu;Fei Gao;Jialin Ji;Tiankai Yang;Chao Xu;Fei Gao",
        "authorids": "/37088999913;/37089001320;/37404060100;/37086045143;/37088999913;/37089001320;/37404060100;/37086045143",
        "aff": "Huzhou Institute Zhejiang University, Huzhou, China; Huzhou Institute Zhejiang University, Huzhou, China; Huzhou Institute Zhejiang University, Huzhou, China; Huzhou Institute Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981489/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6239678494723111751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981598",
        "title": "Real-Time Visual Inertial Odometry with a Resource-Efficient Harris Corner Detection Accelerator on FPGA Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Inertial Odometry (VIO) is a widely studied localization technique in robotics. State-of-the-art VIO algorithms are composed of two parts: a frontend which performs visual perception and inertial measurement pre-processing, and a backend which fuses vision and inertial measurements to estimate the robot's pose. Both image processing in the frontend and sensor fusion in the backend are computationally expensive, making it very challenging to run the VIO algorithm, especially the optimization-based VIO algorithm in real time on embedded platforms with limited power budget. In this paper, a real-time optimization-based monocular VIO algorithm is proposed based on algorithm-and-hardware co-design and successfully implemented on an embedded platform with only 2.6W processor power consumption. In particular, the time-consuming Harris corner detection (HCD) is accelerated on Field Programmable Gate Array (FPGA), achieving an average 16 \u00d7 processing time reduction compared with the ARM implementation. Compared with the state-of-the-art HCD accelerator provided by Xilinx, the hardware resource required of our accelerator is largely reduced without any compromise in speed, thanks to the proposed dedicated pruning and paral-lelization techniques. Finally, experiment on the public dataset demonstrates that the proposed real-time VIO algorithm on the FPGA-based platform has comparable accuracy with respect to the existing state-of-the-art VIO algorithm on the desktop, and 3 \u00d7 faster frontend processing speed over the ARM-based implementation.",
        "primary_area": "",
        "author": "Pengfei Gu;Ziyang Meng;Pengkun Zhou;Pengfei Gu;Ziyang Meng;Pengkun Zhou",
        "authorids": "/37089305993;/37392103100;/37089307936;/37089305993;/37392103100;/37089307936",
        "aff": "Department of Precision Instrument, Tsinghua University, Beijing, China; Department of Precision Instrument, Tsinghua University, Beijing, China; Department of Precision Instrument, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981598/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3942289093095303675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Precision Instrument",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981395",
        "title": "Real-time Acoustic Holography with Physics-based Deep Learning for Acoustic Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Acoustic holography is a newly emerging and promising technique to dynamically generate arbitrary desired holographic acoustic field in 3D space for contactless robotic manipulation. The latest technology supporting complex dynamic holographic acoustic field reconstruction is through phased transducer array (PTA), where the phase profile of emitted acoustic wave from discrete transducers is controlled independently by sophisticated circuits to modulate the acoustic interference field. While the forward kinematics of a phased array based robotic manipulation system is simple and straightforward, the inverse kinematics of the required holographic acoustic field is mathematically non-linear and unsolvable, which substantially limits the application of dynamic holographic acoustic field for robot manipulation. In this work, we propose a physics-based deep learning framework for this phase retrieval inverse kinematics problem so that the target complex hologram could be reconstructed precisely with average MAE of 0.022 and in real time with prediction time of 47 milliseconds on GPU. The accuracy and real time of the proposed method for dynamic holographic acoustic field reconstruction from PTA are demonstrated experimentally.",
        "primary_area": "",
        "author": "Chengxi Zhong;Zhenhuan Sun;Kunyong Lyu;Yao Guo;Song Liu;Chengxi Zhong;Zhenhuan Sun;Kunyong Lyu;Yao Guo;Song Liu",
        "authorids": "/37089190390;/37089624706;/37089664005;/37086919325;/37089083036;/37089190390;/37089624706;/37089664005;/37086919325;/37089083036",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Shanghai Engineering Research Center of Intelligent Vision and Imaing, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981395/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7090088887589413117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "ShanghaiTech University;Shanghai Jiao Tong University;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": "School of Information Science and Technology;Institute of Medical Robotics;",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "ShanghaiTech;SJTU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981613",
        "title": "Real-time Digital Double Framework to Predict Collapsible Terrains for Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspired by the digital twinning systems, a novel real-time digital double framework is developed to enhance robot perception of the terrain conditions. Based on the very same physical model and motion control, this work exploits the use of such simulated digital double synchronized with a real robot to capture and extract discrepancy information between the two systems, which provides high dimensional cues in multiple physical quantities to represent differences between the modelled and the real world. Soft, non-rigid terrains cause common failures in legged locomotion, whereby visual perception solely is insufficient in estimating such physical properties of terrains. We used digital double to develop the estimation of the collapsibility, which addressed this issue through physical interactions during dynamic walking. The discrepancy in sensory measurements between the real robot and its digital double are used as input of a learning-based algorithm for terrain collapsibility analysis. Although trained only in simulation, the learned model can perform collapsibility estimation successfully in both simulation and real world. Our evaluation of results showed the generalization to different scenarios and the advantages of the digital double to reliably detect nuances in ground conditions.",
        "primary_area": "",
        "author": "Garen Haddeler;Hari P. Palanivelu;Yung Chuen Ng;Fabien Colonnier;Albertus H. Adiwahono;Zhibin Li;Chee-Meng Chew;Meng Yee Chuah;Garen Haddeler;Hari P. Palanivelu;Yung Chuen Ng;Fabien Colonnier;Albertus H. Adiwahono;Zhibin Li;Chee-Meng Chew;Meng Yee Chuah",
        "authorids": "/37088690155;/37089659885;/37089663490;/37089663403;/37546317700;/37857029500;/37289929100;/38541406400;/37088690155;/37089659885;/37089663490;/37089663403;/37546317700;/37857029500;/37289929100;/38541406400",
        "aff": "National University of Singapore (NUS), Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; Department of Computer Science, University College, London, UK; National University of Singapore (NUS), Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981613/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15310266531410936548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;2;0;1",
        "aff_unique_norm": "National University of Singapore;Institute for Infocomm Research;University College London",
        "aff_unique_dep": ";;Department of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.i2r.a-star.edu.sg;https://www.ucl.ac.uk",
        "aff_unique_abbr": "NUS;I2R;UCL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "Singapore;United Kingdom"
    },
    {
        "id": "9981539",
        "title": "Real-time Footstep Planning and Control of the Solo Quadruped Robot in 3D Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped robots have proved their robustness to cross complex terrain despite little environment knowledge. Yet advanced locomotion controllers are expected to take advantage of exteroceptive information. This paper presents a complete method to plan and control the locomotion of quadruped robots when 3D information about the surrounding obstacles is available, based on several stages of decision. We first propose a contact planner formulated as a mixed-integer program, optimized on-line at each new robot step. It selects a surface from a set of convex surfaces describing the environment for the next footsteps while ensuring kinematic constraints. We then propose to optimize the exact contact location and the feet trajectories at control frequency to avoid obstacles, thanks to an efficient formulation of quadratic programs optimizing Bezier curves. By relying on the locomotion controller of our quadruped robot Solo, we finally implement the complete method, provided as an open-source package. Its efficiency is asserted by statistical evaluation of the importance of each component in simulation. We have a 100% success rate for our framework, and we show that the deactivation of the contact planning, footstep adaptation and collision avoidance, respectively induced a drop to 70%, 62% and 83% success rate in the worst case, justifying the complete architecture.",
        "primary_area": "",
        "author": "Fanny Risbourg;Thomas Corb\u00e8res;Pierre-Alexandre L\u00e9ziart;Thomas Flayols;Nicolas Mansard;Steve Tonneau;Fanny Risbourg;Thomas Corb\u00e8res;Pierre-Alexandre L\u00e9ziart;Thomas Flayols;Nicolas Mansard;Steve Tonneau",
        "authorids": "/37089658111;/37088997400;/37087901433;/37086293347;/37542913400;/37085790049;/37089658111;/37088997400;/37087901433;/37086293347;/37542913400;/37085790049",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; School of Informatics, University of Edinburgh, UK; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France; School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981539/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9347154655211758726&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;1",
        "aff_unique_norm": "LAAS-CNRS;University of Edinburgh;Artificial and Natural Intelligence Toulouse Institute",
        "aff_unique_dep": ";School of Informatics;",
        "aff_unique_url": "https://www.laas.fr/;https://www.ed.ac.uk;",
        "aff_unique_abbr": "LAAS-CNRS;Edinburgh;ANITI",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Toulouse;Edinburgh;",
        "aff_country_unique_index": "0;1;0;0;0;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "9981139",
        "title": "Real-time IMU-Based Learning: a Classification of Contact Materials",
        "track": "main",
        "status": "Poster",
        "abstract": "In modern highly dynamic robot manipulation, collisions between a robot and objects may be intentionally executed to improve performance. To distinguish between these deliberate contacts and accidental collisions beyond the limit of state-of-the-art human-robot interactions, new sensing approaches are required. This work seeks an easy-to-implement and real-time capable solution to detect the identity of the impacted material. We developed an inertial measurement unit (IMU) based setup that records vibration signals occurring after collisions. Furthermore, a data-set was generated in an unsupervised learning manner using the measurements of collision experiments with several materials commonly used in realistic applications. The data-set was used to train an artificial neural network to classify the type of material involved. Our results show that the neural net detects collisions and a detailed distinction between materials is achieved, even with estimating different human body parts. The unsupervised data-set generation allows for a simple integration of new classes, which provides broader applicability of our approach. As the calculations are running faster than the control cycle of the robot, the output of our classifier can be used in real-time to decide about the robots reaction behavior.",
        "primary_area": "",
        "author": "Carlos Magno C. O. Valle;Alexander Kurdas;Edmundo Pozo Fortuni\u0107;Saeed Abdolshah;Sami Haddadin;Carlos Magno C. O. Valle;Alexander Kurdas;Edmundo Pozo Fortuni\u0107;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37086828032;/37088861524;/37086053889;/37086148547;/37542865300;/37086828032;/37088861524;/37086053889;/37086148547;/37542865300",
        "aff": "Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM) Munich Institute of Robotics and Machine Intelligence (MIRMI), Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM) Munich Institute of Robotics and Machine Intelligence (MIRMI), Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM) Munich Institute of Robotics and Machine Intelligence (MIRMI), Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM) Munich Institute of Robotics and Machine Intelligence (MIRMI), Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM) Munich Institute of Robotics and Machine Intelligence (MIRMI), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981139/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13285162501805383178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Robotics and System Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981300",
        "title": "Real-time Semantic 3D Reconstruction for High- Touch Surface Recognition for Robotic Disinfection",
        "track": "main",
        "status": "Poster",
        "abstract": "Disinfection robots have applications in promoting public health and reducing hospital acquired infections and have drawn considerable interest due to the COVID-19 pan-demic. To disinfect a room quickly, motion planning can be used to plan robot disinfection trajectories on a reconstructed 3D map of the room's surfaces. However, existing approaches discard semantic information of the room and, thus, take a long time to perform thorough disinfection. Human cleaners, on the other hand, disinfect rooms more efficiently by prioritizing the cleaning of high-touch surfaces. To address this gap, we present a novel GPU-based volumetric semantic TSDF (Truncated Signed Distance Function) integration system for semantic 3D reconstruction. Our system produces 3D reconstructions that distinguish high-touch surfaces from non-high-touch surfaces at approximately 50 frames per second on a consumer-grade GPU, which is approximately 5 times faster than existing CPU-based TSDF semantic reconstruction methods. In addition, we extend a UV disinfection motion planning algorithm to incorporate semantic awareness for optimizing coverage of disinfection tra-jectories. Experiments show that our semantic-aware planning outperforms geometry-only planning by disinfecting up to 20% more high-touch surfaces under the same time budget. Further, the real-time nature of our semantic reconstruction pipeline enables future work on simultaneous disinfection and mapping. Code is available at: https://github.com/uiuc-iml/RA-SLAM",
        "primary_area": "",
        "author": "Ri-Zhao Qiu;Yixiao Sun;Joao Marcos Correia Marques;Kris Hauser;Ri-Zhao Qiu;Yixiao Sun;Joao Marcos Correia Marques;Kris Hauser",
        "authorids": "/37089661909;/37089661074;/37087111073;/37543748800;/37089661909;/37089661074;/37087111073;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981300/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6037784191573790333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UIUC;Stanford",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Urbana;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982192",
        "title": "Realism Assessment for Synthetic Images in Robot Vision through Performance Characterization",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthetic image generation plays a crucial role in the development of robot vision algorithms, circumventing manual data collection. However, the realism of synthetic images could affect the performance of the algorithms when applied in real-world settings. In this study, we propose a framework to quantitatively assess the realism of synthetic images using a set of realism metrics as a means of performance characterization. We use a commercial rendering engine as a test-bed for generating synthetic images and ascertain that a set of rendering parameters affect specific image metrics through statistical hypothesis testing. We demonstrate that this framework can be used to optimize rendering parameter values and generate synthetic datasets with improved performance on downstream robot vision tasks such as instance segmentation.",
        "primary_area": "",
        "author": "Arturo E. Ceron-Lopez;Rahul Ranjan;Nishanth Koganti;Arturo E. Ceron-Lopez;Rahul Ranjan;Nishanth Koganti",
        "authorids": "/37086676009;/37089661937;/37085559410;/37086676009;/37089661937;/37085559410",
        "aff": "ExaWizards Inc., Japan; ExaWizards India LLP, India; ExaWizards India LLP, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982192/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:EVCQ7X_Oh8YJ:scholar.google.com/&scioq=Realism+Assessment+for+Synthetic+Images+in+Robot+Vision+through+Performance+Characterization&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "ExaWizards Inc.;ExaWizards India LLP",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Japan;India"
    },
    {
        "id": "9982014",
        "title": "Realistic Real-Time Simulation of RGB and Depth Sensors for Dynamic Scenarios using Augmented Image Based Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation remains one of the key methods for testing and validation of robotic perception systems and it also becomes increasingly important for training visuomotor policies for autonomous driving or manipulation. Further, as perception pipelines tend to leverage increasing amounts of modalities, it appears vital to simulate additional cues such as depth maps aside from RGB images. To align simulation with real-world observations, it is key to achieve realistic renderings of these maps, which includes the capability of rendering other dynamic objects in the scene. In this work, we propose an approach to real-time simulation of photo-realistic RGB images and sensor-realistic depth maps, that can contain dynamic objects at user-defined locations. Our method employs a selection of static samples of a pre-recorded database and multimodal cues from CAD models that are fused and warped to synthesize new imagery for a target camera pose. We show the efficacy of our method on newly proposed datasets recorded in a variety of different setups.",
        "primary_area": "",
        "author": "Johan Vertens;Wolfram Burgard;Johan Vertens;Wolfram Burgard",
        "authorids": "/37086088311;/37270485300;/37086088311;/37270485300",
        "aff": "University of Freiburg, Germany; University of Technology, Nuremberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982014/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2473387266222028502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Freiburg;University of Technology, Nuremberg",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-freiburg.de;",
        "aff_unique_abbr": "UoF;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982103",
        "title": "Realization of Seated Walk by a Musculoskeletal Humanoid with Buttock-Contact Sensors From Human Constrained Teaching",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, seated walk, a movement of walking while sitting on a chair with casters, is realized on a musculoskeletal humanoid from human teaching. The body is balanced by using buttock-contact sensors implemented on the planar interskeletal structure of the human mimetic musculoskeletal robot. Also, we develop a constrained teaching method in which one-dimensional control command, its transition, and a transition condition are described for each state in advance, and a threshold value for each transition condition such as joint angles and foot contact sensor values is determined based on human teaching. Complex behaviors can be easily generated from simple inputs. In the musculoskeletal humanoid MusashiOLegs, forward, backward, and rotational movements of seated walk are realized.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Kei Okada;Masayuki Inaba;Kento Kawaharazuka;Kei Okada;Masayuki Inaba",
        "authorids": "/37086101930;/37280639000;/37286658200;/37086101930;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982103/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14732482229182082993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981599",
        "title": "Rearrangement-Based Manipulation via Kinodynamic Planning and Dynamic Planning Horizons",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot manipulation in cluttered environments of-ten requires complex and sequential rearrangement of multiple objects in order to achieve the desired reconfiguration of the target objects. Due to the sophisticated physical interactions involved in such scenarios, rearrangement-based manipulation is still limited to a small range of tasks and is especially vulnerable to physical uncertainties and perception noise. This paper presents a planning framework that leverages the efficiency of sampling-based planning approaches, and closes the manipulation loop by dynamically controlling the planning horizon. Our approach interleaves planning and execution to progressively approach the manipulation goal while correcting any errors or path deviations along the process. Meanwhile, our framework allows the definition of manipulation goals without requiring explicit goal configurations, enabling the robot to flexibly interact with all objects to facilitate the manipulation of the target ones. With extensive experiments both in simulation and on a real robot, we evaluate our framework on three manipulation tasks in cluttered environments: grasping, relocating, and sorting. In comparison with two baseline approaches, we show that our framework can significantly improve planning efficiency, robustness against physical uncertainties, and task success rate under limited time budgets.",
        "primary_area": "",
        "author": "Kejia Ren;Lydia E. Kavraki;Kaiyu Hang;Kejia Ren;Lydia E. Kavraki;Kaiyu Hang",
        "authorids": "/37089696201;/37279015600;/37085393148;/37089696201;/37279015600;/37085393148",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981599/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6680974952910189450&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982062",
        "title": "Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "To collaborate well with robots, we must be able to understand their decision making. Humans naturally infer other agents' beliefs and desires by reasoning about their observable behavior in a way that resembles inverse reinforcement learning (IRL). Thus, robots can convey their beliefs and desires by providing demonstrations that are informative for a human learner's IRL. An informative demonstration is one that differs strongly from the learner's expectations of what the robot will do given their current understanding of the robot's decision making. However, standard IRL does not model the learner's existing expectations, and thus cannot do this counterfactual reasoning. We propose to incorporate the learner's current understanding of the robot's decision making into our model of human IRL, so that a robot can select demonstrations that maximize the human's understanding. We also propose a novel measure for estimating the difficulty for a human to predict instances of a robot's behavior in unseen environments. A user study finds that our test difficulty measure correlates well with human performance and confidence. Interestingly, considering human beliefs and counterfactuals when selecting demonstrations decreases human performance on easy tests, but increases performance on difficult tests, providing insight on how to best utilize such models.",
        "primary_area": "",
        "author": "Michael S. Lee;Henny Admoni;Reid Simmons;Michael S. Lee;Henny Admoni;Reid Simmons",
        "authorids": "/37086574321;/38570430500;/37270716800;/37086574321;/38570430500;/37270716800",
        "aff": "Robotics Institute at Carnegie Mellon University; Robotics Institute at Carnegie Mellon University; Robotics Institute at Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982062/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18048474349306033109&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981611",
        "title": "Recognition and Prediction of Surgical Gestures and Trajectories Using Transformer Models in Robot-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical activity recognition and prediction can help provide important context in many Robot-Assisted Surgery (RAS) applications, for example, surgical progress monitoring and estimation, surgical skill evaluation, and shared control strategies during teleoperation. Transformer models were first developed for Natural Language Processing (NLP) to model word sequences and soon the method gained popularity for general sequence modeling tasks. In this paper, we propose the novel use of a Transformer model for three tasks: gesture recognition, gesture prediction, and trajectory prediction during RAS. We modify the original Transformer architecture to be able to generate the current gesture sequence, future gesture sequence, and future trajectory sequence estimations using only the current kinematic data of the surgical robot end-effectors. We evaluate our proposed models on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS) and use Leave-One-User-Out (LOUO) cross validation to ensure generalizability of our results. Our models achieve up to 89.3% gesture recognition accuracy, 84.6% gesture prediction accuracy (1 second ahead) and 2.71mm trajectory prediction error (1 second ahead). Our models are comparable to and able to outperform state-of-the-art methods while using only the kinematic data channel. This approach can enable near-real time surgical activity recognition and prediction.",
        "primary_area": "",
        "author": "Chang Shi;Yi Zheng;Ann Majewicz Fey;Chang Shi;Yi Zheng;Ann Majewicz Fey",
        "authorids": "/37089660003;/37089228218;/37086366505;/37089660003;/37089228218;/37086366505",
        "aff": "Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Surgery, UT Southwestern Medical Center, Dallas, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981611/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3058687705379436761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;UT Southwestern Medical Center",
        "aff_unique_dep": "Walker Department of Mechanical Engineering;Department of Surgery",
        "aff_unique_url": "https://www.utexas.edu;https://www.utsouthwestern.edu",
        "aff_unique_abbr": "UT Austin;UTSW",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Austin;Dallas",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981578",
        "title": "Recognizing object surface material from impact sounds for robot manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigated the use of impact sounds generated during exploratory behaviors in a robotic manipulation setup as cues for predicting object surface material and for recognizing individual objects. We collected and make available the YCB-impact sounds dataset which includes over 3,000 impact sounds for the YCB set of everyday objects lying on a table. Impact sounds were generated in three modes: (i) human holding a gripper and hitting, scratching, or dropping the object; (ii) gripper attached to a teleoperated robot hitting the object from the top; (iii) autonomously operated robot hitting the objects from the side with two different speeds. A convolutional neural network is trained from scratch to recognize the object material (steel, aluminium, hard plastic, soft plastic, other plastic, ceramic, wood, paper/cardboard, foam, glass, rubber) from a single impact sound. On the manually collected dataset with more variability in the speed of the action, nearly 60% accuracy for the test set (not presented objects) was achieved. On a robot setup and a stereotypical poking action from top, accuracy of 85% was achieved. This performance drops to 79% if multiple exploratory actions are combined. Individual objects from the set of 75 objects can be recognized with a 79% accuracy. This work demonstrates promising results regarding the possibility of using impact sound for recognition in tasks like single-stream recycling where objects have to be sorted based on their material composition.",
        "primary_area": "",
        "author": "Mariella Dimiccoli;Shubhan Patni;Matej Hoffmann;Francesc Moreno-Noguer;Mariella Dimiccoli;Shubhan Patni;Matej Hoffmann;Francesc Moreno-Noguer",
        "authorids": "/37395110600;/37089662870;/37594773300;/38274555200;/37395110600;/37089662870;/37594773300;/38274555200",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e1tica Industrial, CSIC-UPC, Barcelona; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague; Institut de Rob\u00f2tica i Inform\u00e1tica Industrial, CSIC-UPC, Barcelona",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981578/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11263211629028136744&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e1tica Industrial;Czech Technical University",
        "aff_unique_dep": "CSIC-UPC;Department of Cybernetics, Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.iri.upc.edu/;https://www.cvut.cz",
        "aff_unique_abbr": "IRI;CTU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Barcelona;Prague",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Spain;Czech Republic"
    },
    {
        "id": "9981509",
        "title": "Reconstructed Student-Teacher and Discriminative Networks for Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Anomaly detection is an important problem in computer vision; however, the scarcity of anomalous samples makes this task difficult. Thus, recent anomaly detection methods have used only \u201cnormal images\u201d with no abnormal areas for training. In this work, a powerful anomaly detection method is proposed based on student-teacher feature pyramid matching (STPM), which consists of a student and teacher network. Generative models are another approach to anomaly detection. They reconstruct normal images from an input and compute the difference between the predicted normal and the input. Unfortunately, STPM does not have the ability to generate normal images. To improve the accuracy of STPM, this work uses a student network, as in generative models, to reconstruct normal features. This improves the accuracy; however, the anomaly maps for normal images are not clean because STPM does not use anomaly images for training, which decreases the accuracy of the image-level anomaly detection. To further improve accuracy, a discriminative network trained with pseudo-anomalies from anomaly maps is used in our method, which consists of two pairs of student-teacher networks and a discriminative network. The method displayed high accuracy on the MVTec anomaly detection dataset.",
        "primary_area": "",
        "author": "Shinji Yamada;Satoshi Kamiya;Kazuhiro Hotta;Shinji Yamada;Satoshi Kamiya;Kazuhiro Hotta",
        "authorids": "/37089658401;/37089661619;/37270604500;/37089658401;/37089661619;/37270604500",
        "aff": "Meijo University, Nagoya, Japan; Meijo University, Nagoya, Japan; Meijo University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981509/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=836002474389377632&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Meijo University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.meijo-u.ac.jp",
        "aff_unique_abbr": "Meijo U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981128",
        "title": "Reconstructing a Spatial Field with an Autonomous Robot Under a Budget Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we consider the information path-planning problem for a single robot in a stochastic environment with static obstacles subject to a preassigned constraint on the distance it can travel. Given a set of candidate sampling locations, the objective is to determine a path for the robot that allows to visit as many sampling locations as possible to accurately reconstruct an unknown underlying scalar field while not exceeding the assigned travel budget. Starting from the assumption that the phenomenon being measured can be modeled by a Gaussian Process, our algorithm balances exploration and exploitation to determine a sequence of locations ensuring that a preassigned final site is reached before the budget is consumed. Using mutual information as a reward criterion, as well as a generative model to predict consumed energy, the algorithm iteratively determines where to sample next, and when to end the mission. Our findings are validated in simulation in various scenarios and lead to a better reconstruction with less failures when compared with other methods.",
        "primary_area": "",
        "author": "Azin Shamshirgaran;Stefano Carpin;Azin Shamshirgaran;Stefano Carpin",
        "authorids": "/37085778134;/37328709200;/37085778134;/37328709200",
        "aff": "Department of Computer Science and Engineering, University of California, Merced, CA, USA; Department of Computer Science and Engineering, University of California, Merced, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981128/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7966684434287719184&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Merced",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucmerced.edu",
        "aff_unique_abbr": "UC Merced",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981328",
        "title": "Recursive Hierarchical Projection for Whole-Body Control with Task Priority Transition",
        "track": "main",
        "status": "Poster",
        "abstract": "Whole-body control (WBC) with task priority transition is an important technology for robots to switch multiple behaviors, change different objectives, and adapt to various environments. Many methods have solved the problem of control continuity in the priority transition process. However, they either increased the computation consumption or sacrificed the accuracy of tasks in practical application. In this work, we propose a Recursive Hierarchical Projection (RHP) matrix and introduce it in Hierarchical Quadratic Programming (HQP). This RHP-HQP scheme can form continuously changing hierarchical projection and regard the WBC problem with task priority transition as a unified formulation. This unified formulation can be smoothly transitioned without increasing computation consumption and solved without losing task accuracy. The comparative simulations of the reactive collision avoidance verify that this priority transition scheme can guarantee high computational efficiency and task accuracy.",
        "primary_area": "",
        "author": "Gang Han;Jiajun Wang;Xiaozhu Ju;Mingguo Zhao;Gang Han;Jiajun Wang;Xiaozhu Ju;Mingguo Zhao",
        "authorids": "/37089446921;/37089450674;/37089449748;/37336278300;/37089446921;/37089450674;/37089449748;/37336278300",
        "aff": "Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Innovation Center for Future Chips, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981328/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9607281824386066526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "UBTECH Robotics;Tsinghua University",
        "aff_unique_dep": "Research Institute;Beijing Innovation Center for Future Chips",
        "aff_unique_url": "https://www.ubtech.com.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UBTECH;THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982081",
        "title": "Reference Acceleration Model Predictive Control (RA-MPC) for Cable-Driven Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a computationally efficient model predictive control (MPC) is proposed for the trajectory tracking of cable-driven robots subject to state/input constraints. While MPC has been an effective tool in dealing with various constraints, the primary drawback is the high computational load caused by the non-convexity of the corresponding optimization problem. In order to avoid the non-convexity, the prediction model in the proposed reference acceleration MPC (RA-MPC) is simplified into a linear one by assuming the reference accelerations being taken in the future horizon steps. As a result, RA-MPC only optimizes for the instantaneous joint accelerations and the corresponding actuator commands for the current step, resulting in a convex quadratic program that can be efficiently solved. It is further shown that by properly selecting parameters, RA-MPC can be interpreted as \u2018soft-CTC\u2019 and \u2018soft-LQR\u2019, where the joint acceleration is allowed to deviate from the corresponding desired value, computed from a PD gain or an LQR gain. The effectiveness of the proposed RA-MPC are demonstrated in both simulation and hardware experiment using cable-driven robots.",
        "primary_area": "",
        "author": "Chen Song;Darwin Lau;Chen Song;Darwin Lau",
        "authorids": "/37087014932;/37075801900;/37087014932;/37075801900",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982081/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2742092319165407805&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982203",
        "title": "Refining Control Barrier Functions through Hamilton-Jacobi Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety filters based on Control Barrier Functions (CBFs) have emerged as a practical tool for the safety-critical control of autonomous systems. These approaches encode safety through a value function and enforce safety by imposing a constraint on the time derivative of this value function. How-ever, synthesizing a valid CBF that is not overly conservative in the presence of input constraints is a notorious challenge. In this work, we propose refining a candidate CBF using formal verification methods to obtain a valid CBF. In particular, we update an expert-synthesized or backup CBF using dynamic programming (DP) based reachability analysis. Our framework, REFINECBF, guarantees that with every DP iteration the obtained CBF is provably at least as safe as the prior iteration and converges to a valid CBF. Therefore, REFINECBF can be used in-the-loop for robotic systems. We demonstrate the practicality of our method to enhance safety and/or reduce conservativeness on a range of nonlinear control-affine systems using various CBF synthesis techniques in simulation.",
        "primary_area": "",
        "author": "Sander Tonkens;Sylvia Herbert;Sander Tonkens;Sylvia Herbert",
        "authorids": "/37089000808;/37086011005;/37089000808;/37086011005",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, San Diego; Department of Mechanical and Aerospace Engineering, University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982203/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11292937479477064652&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981949",
        "title": "Registering Articulated Objects With Human-in-the-loop Corrections",
        "track": "main",
        "status": "Poster",
        "abstract": "Remotely programming robots to execute tasks often relies on registering objects of interest in the robot's environment. Frequently, these tasks involve articulating objects such as opening or closing a valve. However, existing human-in-the-loop methods for registering objects do not consider articulations and the corresponding impact to the geometry of the object, which can cause the methods to fail. In this work, we present an approach where the registration system attempts to automatically determine the object model, pose, and articulation for user-selected points using nonlinear fitting and the iterative closest point algorithm. When the fitting is incorrect, the operator can iteratively intervene with corrections after which the system will refit the object. We present an implementation of our fitting procedure for one degree-of-freedom (DOF) objects with revolute joints and evaluate it with a user study that shows that it can improve user performance, in measures of time on task and task load, ease of use, and usefulness compared to a manual registration approach. We also present a situated example that integrates our method into an end-to-end system for articulating a remote valve.",
        "primary_area": "",
        "author": "Michael Hagenow;Emmanuel Senft;Evan Laske;Kimberly Hambuchen;Terrence Fong;Robert Radwin;Michael Gleicher;Bilge Mutlu;Michael Zinn;Michael Hagenow;Emmanuel Senft;Evan Laske;Kimberly Hambuchen;Terrence Fong;Robert Radwin;Michael Gleicher;Bilge Mutlu;Michael Zinn",
        "authorids": "/37088814469;/37085768238;/37089661868;/37295398200;/37338020300;/37389499300;/37282585700;/38569363200;/37282367400;/37088814469;/37085768238;/37089661868;/37295398200;/37338020300;/37389499300;/37282585700;/38569363200;/37282367400",
        "aff": "Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; NASA Johnson Space Center, Houston, TX, USA; NASA Johnson Space Center, Houston, TX, USA; Intelligent Robotics Group, NASA Ames Research Center, Mountain View, CA, USA; Department of Industrial and Systems Engineering, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981949/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2867543236267803154&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;2;0;0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison;NASA Johnson Space Center;NASA Ames Research Center",
        "aff_unique_dep": "Department of Mechanical Engineering;;Intelligent Robotics Group",
        "aff_unique_url": "https://www.wisc.edu;https://www.nasa.gov centers/johnson;https://ames.nasa.gov",
        "aff_unique_abbr": "UW\u2013Madison;JSC;NASA Ames",
        "aff_campus_unique_index": "0;0;1;1;2;0;0;0;0",
        "aff_campus_unique": "Madison;Houston;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981456",
        "title": "Regularized Deep Signed Distance Fields for Reactive Motion Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots should operate in real-world dynamic environments and collaborate with humans in tight spaces. A key component for allowing robots to leave structured lab and manufacturing settings is their ability to evaluate online and real-time collisions with the world around them. Distance-based constraints are fundamental for enabling robots to plan their actions and act safely, protecting both humans and their hardware. However, different applications require different distance resolutions, leading to various heuristic approaches for measuring distance fields w.r.t. obstacles, which are computationally expensive and hinder their application in dynamic obstacle avoidance use-cases. We propose Regularized Deep Signed Distance Fields (ReDSDF), a single neural implicit function that can compute smooth distance fields at any scale, with fine-grained resolution over high-dimensional manifolds and articulated bodies like humans, thanks to our effective data generation and a simple inductive bias during training. We demonstrate the effectiveness of our approach in representative simulated tasks for whole-body control (WBC) and safe Human- Robot Interaction (HRI) in shared workspaces. Finally, we provide proof of concept of a real-world application in a HRI handover task with a mobile manipulator robot.",
        "primary_area": "",
        "author": "Puze Liu;Kuo Zhang;Davide Tateo;Snehal Jauhri;Jan Peters;Georgia Chalvatzaki;Puze Liu;Kuo Zhang;Davide Tateo;Snehal Jauhri;Jan Peters;Georgia Chalvatzaki",
        "authorids": "/37089195561;/37089660048;/37086271891;/37089448523;/37533077600;/37085353493;/37089195561;/37089660048;/37086271891;/37089448523;/37533077600;/37085353493",
        "aff": "Computer Science Department, Technische Universitat, Darmstadt, Germany; Computer Science Department, Technische Universitat, Darmstadt, Germany; Computer Science Department, Technische Universitat, Darmstadt, Germany; Computer Science Department, Technische Universitat, Darmstadt, Germany; Computer Science Department, Technische Universitat, Darmstadt, Germany; Computer Science Department, Technische Universitat, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981456/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5718628302004289575&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technische Universitat Darmstadt",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TU Darmstadt",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981960",
        "title": "Relationship Oriented Semantic Scene Understanding for Daily Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive robot systems have been developed to help people accomplish daily manipulation tasks especially for those with disabilities, where scene understanding plays a crucial role in enabling robots to interpret the surroundings and behave accordingly. Most of the current systems approach scene understanding without considering the functional dependencies between objects. However, it is only valuable to interact with some objects when their function-relevant counterparts are considered. In this paper, we augment an assistive robotic arm system with an end-to-end semantic relationship reasoning model. It incorporates functional relationships between pairs of objects for semantic scene understanding. To ensure good generalization to unseen objects and relationships, the model works in a category-agnostic manner. We evaluate our design and three baseline methods on a self-collected benchmark with two levels of difficulty. To further demonstrate the effectiveness, the model is integrated with a symbolic planner for goal-oriented, multi-step manipulation task on a real-world assistive robotic arm platform.",
        "primary_area": "",
        "author": "Chao Tang;Jingwen Yu;Weinan Chen;Bingyi Xia;Hong Zhang;Chao Tang;Jingwen Yu;Weinan Chen;Bingyi Xia;Hong Zhang",
        "authorids": "/37089661235;/37089658182;/37086099846;/37088456500;/37280789900;/37089661235;/37089658182;/37086099846;/37088456500;/37280789900",
        "aff": "Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981960/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8637013971172920206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;Hong Kong University of Science and Technology;Guangdong University of Technology",
        "aff_unique_dep": "Department of Electronic and Electrical Engineering;Department of Electronic and Computer Engineering;Biomimetic and Intelligent Robotics Lab (BIRL)",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.ust.hk;",
        "aff_unique_abbr": "SUSTech;HKUST;",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981105",
        "title": "Renaissance Robot: Optimal Transport Policy Fusion for Learning Diverse Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (RL) is a promising approach to solving complex robotics problems. However, the process of learning through trial-and-error interactions is often highly time-consuming, despite recent advancements in RL algorithms. Additionally, the success of RL is critically dependent on how well the reward-shaping function suits the task, which is also time-consuming to design. As agents trained on a variety of robotics problems continue to proliferate, the ability to reuse their valuable learning for new domains becomes increasingly significant. In this paper, we propose a post-hoc technique for policy fusion using Optimal Transport theory as a robust means of consolidating the knowledge of multiple agents that have been trained on distinct scenarios. We further demonstrate that this provides an improved weights initialisation of the neural network policy for learning new tasks, requiring less time and computational resources than either retraining the parent policies or training a new policy from scratch. Ultimately, our results on diverse agents commonly used in deep RL show that specialised knowledge can be unified into a \u201cRenaissance agent\u201d, allowing for quicker learning of new skills.",
        "primary_area": "",
        "author": "Julia Tan;Ransalu Senanayake;Fabio Ramos;Julia Tan;Ransalu Senanayake;Fabio Ramos",
        "authorids": "/37089658557;/38490726500;/37285364500;/37089658557;/38490726500;/37285364500",
        "aff": "School of Computer Science, University of Sydney, Sydney, Australia; Dept.of Computer Science, Stanford University, Stanford, USA; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981105/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4840266663753043522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Sydney;Stanford University;NVIDIA",
        "aff_unique_dep": "School of Computer Science;Department of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.stanford.edu;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;Stanford;NV",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Sydney;Stanford;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9981810",
        "title": "Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language is the most intuitive medium for us to interact with other people when expressing commands and instructions. However, using language is seldom an easy task when humans need to express their intent towards robots, since most of the current language interfaces require rigid templates with a static set of action targets and commands. In this work, we provide a flexible language-based interface for human-robot collaboration, which allows a user to reshape existing trajectories for an autonomous agent. We take advantage of recent advancements in the field of large language models (BERT and CLIP) to encode the user command, and then combine these features with trajectory information using multi-modal attention transformers. We train the model using imitation learning over a dataset containing robot trajectories modified by language commands, and treat the trajectory generation process as a sequence prediction problem, analogously to how language generation architectures operate. We evaluate the system in multiple simulated trajectory scenarios, and show a significant performance increase of our model over baseline approaches. In addition, our real-world experiments with a robot arm show that users significantly prefer our natural language interface over traditional methods such as kinesthetic teaching or cost-function programming. Our study shows how the field of robotics can take advantage of large pre-trained language models towards creating more intuitive interfaces between robots and machines. Project webpage: https://arthurfenderbucker.github.io/NL_trajectory_reshaper/",
        "primary_area": "",
        "author": "Arthur Bucker;Luis Figueredo;Sami Haddadinl;Ashish Kapoor;Shuang Ma;Rogerio Bonatti;Arthur Bucker;Luis Figueredo;Sami Haddadinl;Ashish Kapoor;Shuang Ma;Rogerio Bonatti",
        "authorids": "/37089000770;/37063909900;/37089659154;/37397699500;/37086565371;/37086934741;/37089000770;/37063909900;/37089659154;/37397699500;/37086565371;/37086934741",
        "aff": "Technische Universit\u00e4t M\u00fcnchen; Technische Universit\u00e4t M\u00fcnchen; Technische Universit\u00e4t M\u00fcnchen; Microsoft; Microsoft; Microsoft",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981810/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14571368971670661074&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;1",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Microsoft",
        "aff_unique_dep": ";Microsoft Corporation",
        "aff_unique_url": "https://www.tum.de;https://www.microsoft.com",
        "aff_unique_abbr": "TUM;Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9981844",
        "title": "Resilient Detection and Recovery of Autonomous Systems Operating under On-board Controller Cyber Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Cyber-attacks, failures, and implementation errors inside the controller of an autonomous system can affect its correct behavior leading to unsafe states and degraded performance. In this paper, we focus on such problems specifically on cyber-attacks that manipulate controller parameters like the gains in a feedback controller or that triggers different behaviors or block inputs based on specific values of the state and tracking error. If such attacks are undetected, they can lead to the partial or complete loss of system's control authority, resulting in a hijacking and leading the autonomous system towards unforeseen states. To deal with this problem, we propose a runtime monitoring and recovery scheme in which: 1) we leverage the residual between the expected and the received measurements to detect inconsistencies in the generated inputs and 2) provide a recovery method for counteracting the malicious effects to allow for resilient operations by manipulating the reference signal and state vector provided to the system to avoid the affected regions in the state and error space. We validate our approach with Matlab simulations and experiments on unmanned ground vehicles resiliently performing operations in the presence of malicious attacks to on-board controllers.",
        "primary_area": "",
        "author": "Paul J Bonczek;Nicola Bezzo;Paul J Bonczek;Nicola Bezzo",
        "authorids": "/37088481021;/37546843800;/37088481021;/37546843800",
        "aff": "Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981844/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1257969957688315515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Charles L. Brown Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982009",
        "title": "Resolved Motion Control for 3D Underactuated Bipedal Walking using Linear Inverted Pendulum Dynamics and Neural Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework to generate periodic trajectory references for a 3D under-actuated bipedal robot, using a linear inverted pendulum (LIP) based controller with adaptive neural regulation. We use the LIP template model to estimate the robot's center of mass (CoM) position and velocity at the end of the current step, and formulate a discrete controller that determines the next footstep location to achieve a desired walking profile. This controller is equipped on the frontal plane with a Neural-Network-based adaptive term that reduces the model mismatch between the template and physical robot that particularly affects the lateral motion. Then, the foot placement location computed for the LIP model is used to generate task space trajectories (CoM and swing foot trajectories) for the actual robot to realize stable walking. We use a fast, real-time QP-based inverse kinematics algorithm that produces joint references from the task space trajectories, which makes the formulation independent of the knowledge of the robot dynamics. Finally, we implemented and evaluated the proposed approach in simulation and hardware experiments with a Digit robot obtaining stable periodic locomotion for both cases.",
        "primary_area": "",
        "author": "Victor C. Paredes;Ayonga Hereid;Victor C. Paredes;Ayonga Hereid",
        "authorids": "/37085706230;/37077055000;/37085706230;/37077055000",
        "aff": "Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982009/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3219681555776373489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981292",
        "title": "Rigid Skeleton Enhanced Dexterous Soft Finger Possessing Proprioception",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a humanoid soft robotics finger design with rigid skeletons and proprioceptive sensors. This 4-DOFs dexterous finger has soft joints and rigid phalanxes, which is about the size of human hand. To enhance the overall stiffness and for human-like behavior and configuration, rigid-soft actuators which we called quasi-joints are introduced. Although their lengths are shortened in this design, the soft actuators can still bend over 90\u00b0, exhibiting joint-like flexion and abduction/adduction. Thus interphalangeal joints (IPs) and metacarpophalangeal joint (MCP) are realized. EGaIn soft sensors are embedded into the structure for bending detection. In addition, multi-step molding fabrication method is introduced for this complex multi-material structure. This rigid-soft finger is a preliminary work and modular part of a highly dexterous humanoid soft robotic hand.",
        "primary_area": "",
        "author": "Ruichen Zhen;Li Jiang;Ruichen Zhen;Li Jiang",
        "authorids": "/37089659437;/37287953000;/37089659437;/37287953000",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981292/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16270428064402029422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982200",
        "title": "Risk-Aware Off-Road Navigation via a Learned Speed Distribution Map",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning in off-road environments re-quires reasoning about both the geometry and semantics of the scene (e.g., a robot may be able to drive through soft bushes but not a fallen log). In many recent works, the world is classified into a finite number of semantic categories that often are not sufficient to capture the ability (i.e., the speed) with which a robot can traverse off-road terrain. Instead, this work proposes a new representation of traversability based exclusively on robot speed that can be learned from data, offers interpretability and intuitive tuning, and can be easily integrated with a variety of planning paradigms in the form of a costmap. Specifically, given a dataset of experienced trajectories, the proposed algorithm learns to predict a distribution of speeds the robot could achieve, conditioned on the environment semantics and commanded speed. The learned speed distribution map is converted into costmaps with a risk-aware cost term based on conditional value at risk (CVaR). Numerical simulations demonstrate that the proposed risk-aware planning algorithm leads to faster average time-to-goals compared to a method that only considers expected behavior, and the planner can be tuned for slightly slower, but less variable behavior. Furthermore, the approach is integrated into a full autonomy stack and demonstrated in a high-fidelity Unity environment and is shown to provide a 30% improvement in the success rate of navigation.",
        "primary_area": "",
        "author": "Xiaoyi Cai;Michael Everett;Jonathan Fink;Jonathan P. How;Xiaoyi Cai;Michael Everett;Jonathan Fink;Jonathan P. How",
        "authorids": "/37087091424;/37418751400;/37528865400;/37276347700;/37087091424;/37418751400;/37528865400;/37276347700",
        "aff": "Dept. of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Dept. of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; U.S. Army Combat Capabilities Development Command Army Research Laboratory, Adelphi, MD, USA; Dept. of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982200/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17597817994232985636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;U.S. Army Research Laboratory",
        "aff_unique_dep": "Dept. of Aeronautics and Astronautics;Army Combat Capabilities Development Command",
        "aff_unique_url": "https://web.mit.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "MIT;ARL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Cambridge;Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981597",
        "title": "Risk-aware Motion Planning for Collision-tolerant Aerial Robots subject to Localization Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper contributes a novel strategy towards risk-aware motion planning for collision-tolerant aerial robots subject to localization uncertainty. Attuned to the fact that micro aerial vehicles are often tasked to navigate within GPS-denied, possibly unknown, confined and obstacle-filled environments the proposed method exploits collision-tolerance at the robot design level to mitigate the risks of collisions especially as their likelihood increases with growing uncertainty. Accounting for the maximum kinetic energy with which an impact is considered safe, alongside the robot dynamics, the planner builds a set of admissible uncertainty-aware and collision-inclusive paths over a horizon involving multiple motion steps. The first step of the best path is executed by the robot, while the procedure is then repeated in a receding horizon manner. Evaluated in extensive simulation studies and experimental results with a collision-tolerant flying robot, the planner successfully considers the interplay between uncertainty and the likelihood of a collision, balances the risks of possible impacts and enables to navigate safely within highly cluttered environments.",
        "primary_area": "",
        "author": "Paolo De Petris;Mihir Dharmadhikari;Huan Nguyen;Kostas Alexis;Paolo De Petris;Mihir Dharmadhikari;Huan Nguyen;Kostas Alexis",
        "authorids": "/37088600627;/37088504973;/37088471319;/37546514600;/37088600627;/37088504973;/37088471319;/37546514600",
        "aff": "Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981597/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5353264771222600819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology",
        "aff_unique_dep": "Autonomous Robots Lab",
        "aff_unique_url": "https://www.ntnu.edu",
        "aff_unique_abbr": "NTNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Trondheim",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9981223",
        "title": "Risk-sensitive MPCs with Deep Distributional Inverse RL for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In robot learning from demonstration (LfD), a visual representation of a cost function inferred from Inverse Reinforcement Learning (IRL) provides an intuitive tool for humans to quickly interpret the underlying objectives of the demonstration. The inferred cost function can be used by controllers, for example, Model Predictive Controllers (MPCs). In this work, we improve the recently developed IRL-MPC framework, by enhancing it in a risk-sensitive formulation to be more applicable for safety-critical applications like autonomous driving. Our risk-sensitive MPCs together with the distributional costmap demonstrate lower collision rates in the CARLA simulator for autonomous driving tasks compared to other learning-based baseline methods.",
        "primary_area": "",
        "author": "Keuntaek Lee;David Isele;Evangelos A. Theodorou;Sangjae Bae;Keuntaek Lee;David Isele;Evangelos A. Theodorou;Sangjae Bae",
        "authorids": "/37086938143;/37086124264;/37546007800;/37086173533;/37086938143;/37086124264;/37546007800;/37086173533",
        "aff": "Amazon Robotics AI; Honda Research Institute USA, Inc.; Georgia Institute of Technology, Atlanta, GA, USA; Honda Research Institute USA, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981223/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1099006427587071835&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Amazon;Honda Research Institute USA;Georgia Institute of Technology",
        "aff_unique_dep": "Amazon Robotics AI;Research Institute;",
        "aff_unique_url": "https://www.amazonrobotics.com;https://honda-ri.com;https://www.gatech.edu",
        "aff_unique_abbr": "Amazon Robotics AI;HRI USA;Georgia Tech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982240",
        "title": "RoBiGAN: A bidirectional Wasserstein GAN approach for online robot fault diagnosis via internal anomaly detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex robots in challenging scenarios require constant monitoring of their state and adaptation of their behavior to ensure robustness, reliability and longevity. While known possible errors can be specifically surveilled, other prob-lems can be fully unforeseen, requiring detection systems able to identify novel faults. We detect possible faults as anomalies on various internal sensor data, utilizing unsupervised learning techniques. A bidirectional Wasserstein GAN approach for anomaly detection on multivariate, highly dependent time-series data is implemented and trained on a small amount of non-anomalous robot sensor data. This model is then used for inference on the on-board hardware of a robot without parallel processing units. We evaluate multiple variants of the architecture using manually introduced anomalies in the form of different weights attached to the robot's legs. Overall we are able to show that RoBiGAN is able to consistently detect and localize small anomalies in an online scenario, with little to no robot specific modeling needed.",
        "primary_area": "",
        "author": "Tristan Schnell;Katrin Bott;Lennart Puck;Timoth\u00e9e Buettner;Arne Roennau;R\u00fcdiger Dillmann;Tristan Schnell;Katrin Bott;Lennart Puck;Timoth\u00e9e Buettner;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37087011877;/37089661922;/37087012686;/37086158340;/37590849800;/37280242100;/37087011877;/37089661922;/37087012686;/37086158340;/37590849800;/37280242100",
        "aff": "Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany; Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982240/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17388596578693476454&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "FZI Research Center for Information Technology",
        "aff_unique_dep": "Department of Interactive Diagnosis and Service Systems (IDS)",
        "aff_unique_url": "https://www.fzi.de",
        "aff_unique_abbr": "FZI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982146",
        "title": "RoSA:A Mechatronically Synthesized Dataset for Rotodynamic System Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The time-series datasets commonly applied for anomaly detection research showcase specific suboptimal properties. This work novelly conceptualizes condition state synthesis to improve the data-synthetic pipeline of an anomalous-event dataset. We demonstrate two technical contributions in this study. First, we propose a methodology to formulate, accelerate and enrich the condition state synthetic process. The proposed method includes three critical phases: analysis of a rotodynamic plant, systematic design of its condition state space, and development of a Markovian model for controlled state transitions. Second, a Rotodynamic System with Synthetic Anomaly dataset is constructed. It is a large-scale time-series dataset featuring controlled, abundant and diverse anomalous condition states, and per-time-step condition state labels. A comprehensive learning-based case study is conducted to illustrate that these unique features tangibly benefit anomaly detection research. Potential usages of the proposed dataset as an anomaly detection study benchmark are discussed.",
        "primary_area": "",
        "author": "Yip Fun Yeung;Alex Paul-Ajuwape;Farida Tahiry;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi;Yip Fun Yeung;Alex Paul-Ajuwape;Farida Tahiry;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi",
        "authorids": "/37088687204;/37089658366;/37089659514;/37086933718;/37086934581;/38271700200;/37088687204;/37089658366;/37089659514;/37086933718;/37086934581;/38271700200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science Department, Wellesley College, Wellesley, MA, USA; The Japan Steel Works, LTD., Japan; The Japan Steel Works, LTD., Japan; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982146/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6668717311008744935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;2;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Wellesley College;Japan Steel Works, LTD.",
        "aff_unique_dep": "Department of Mechanical Engineering;Computer Science Department;",
        "aff_unique_url": "https://web.mit.edu;https://www.wellesley.edu;https://www.jsw.co.jp",
        "aff_unique_abbr": "MIT;Wellesley College;JSW",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Cambridge;Wellesley;",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9982004",
        "title": "Robot Companion, an intelligent interactive robot coworker for the Industry 5.0",
        "track": "main",
        "status": "Poster",
        "abstract": "To overcome the limitations of the so-called Industry 4.0 focusing on mass production and full automation, a novel paradigm was recently introduced, namely Industry 5.0, which aims at an increased collaboration between humans and machines, and particularly robots, instead of replacing the former with the latter. This challenge requires novel interactive intelligent robots able to perform complex tasks easily and efficiently and to collaborate on the fly with humans whenever required, be it for training or working. In this work, the Robot Companion, a novel demonstrator of this paradigm, is introduced. It combines robotics, Artificial Intelligence, software engineering and embedded systems technologies, and targets industrial assembly tasks. First tests show that this robot can efficiently assemble a representative gear system autonomously or in collaboration with human operators.",
        "primary_area": "",
        "author": "F. Gosselin;S. Kchir;G. Acher;F. Keith;O. Lebec;C. Louison;B. Luvison;F. Mayran de Chamisso;B. Meden;M. Morelli;B. Perochon;J. Rabarisoa;C. Vienne;G. Ameyugo;F. Gosselin;S. Kchir;G. Acher;F. Keith;O. Lebec;C. Louison;B. Luvison;F. Mayran de Chamisso;B. Meden;M. Morelli;B. Perochon;J. Rabarisoa;C. Vienne;G. Ameyugo",
        "authorids": "/37297755900;/37085906134;/37089662699;/37089660593;/37086661297;/37089660929;/37086127444;/37088976235;/37089663076;/37078495600;/37089658642;/38093319200;/37089661232;/37087758227;/37297755900;/37085906134;/37089662699;/37089660593;/37086661297;/37089660929;/37086127444;/37088976235;/37089663076;/37078495600;/37089658642;/38093319200;/37089661232;/37087758227",
        "aff": "Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, LIST, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982004/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5802451688884463174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 28,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay",
        "aff_unique_dep": "CEA LIST",
        "aff_unique_url": "https://www.universite-paris-saclay.fr",
        "aff_unique_abbr": "UPS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Palaiseau",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981904",
        "title": "Robot Contact Reflexes: Adaptive Maneuvers in the Contact Reflex Space",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to transform a robot into an intelligent machine it needs to be enabled to react to unforeseen events (most importantly collisions) during task execution and have a plan on how to continue the task afterwards. This requires a flexible operational framework that allows to define adaptive reactions and interactions with the motion generation and task planning stage. Within this work we first reason about the choices the robot has for reactions to unforeseen events such as collisions with respect to safety of humans in the workspace, the robot itself and the environment as well as the successful task execution. We further present a flexible reflex engine together with a concept of integration into the motion generation and control work flow. The reflex engine and it's reflex maneuvers are a combination of state machines and decision trees that take into account the state of the robot and the world. It is capable of choosing safe reactions and can differentiate between different levels of contact severity and according reaction sets. Several reflex maneuvers are evaluated towards safety performance criteria in real robot experiments using an ISO/TS 15066 conform measurement device. Some of the tested reflexes are furthermore integrated into an implementation of the proposed approach for a simple real world example task where the robot needs to pickup a container and dispose it's content into a bin.",
        "primary_area": "",
        "author": "Jonathan Vorndamme;Luis Figueredo;Sami Haddadin;Jonathan Vorndamme;Luis Figueredo;Sami Haddadin",
        "authorids": "/37085761454;/37063909900;/37542865300;/37085761454;/37063909900;/37542865300",
        "aff": "Centre for Tactile Internet with Human-in-the-Loop (CeTI); Centre for Tactile Internet with Human-in-the-Loop (CeTI); Centre for Tactile Internet with Human-in-the-Loop (CeTI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981904/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7449928536624554461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Centre for Tactile Internet with Human-in-the-Loop",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "CeTI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981462",
        "title": "Robot Dance Generation with Music Based Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Musical dancing is an ubiquitous phenomenon in the human society. Providing robots the ability to dance has the potential to make the human robot co-existence more acceptable in our society. Hence, dancing robots have generated a considerable research interest in the recent years. In this paper, we present a novel formalization of robot dancing as planning and control of optimally timed actions based on beat timings and additional features extracted from the music. We showcase the use of this formulation in three different variations: with input of human expert choreography, imitation of a predefined choreography, and automated generation of a novel choreography. Our method has been validated on four different musical pieces, both in simulation and on a real robot, using the upper-body humanoid robot RH5 Manus.",
        "primary_area": "",
        "author": "Melya Boukheddimi;Daniel Harnack;Shivesh Kumar;Rohit Kumar;Shubham Vyas;Octavio Arriaga;Frank Kirchner;Melya Boukheddimi;Daniel Harnack;Shivesh Kumar;Rohit Kumar;Shubham Vyas;Octavio Arriaga;Frank Kirchner",
        "authorids": "/37087244433;/37089658130;/37085850436;/37089658177;/37089775705;/37086855223;/37283559600;/37087244433;/37089658130;/37085850436;/37089658177;/37089775705;/37086855223;/37283559600",
        "aff": "Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; AG Robotik, University of Bremen, Bremen, Germany; AG Robotik, University of Bremen, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981462/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11372296012854110420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;1",
        "aff_unique_norm": "DFKI GmbH;University of Bremen",
        "aff_unique_dep": "Robotics Innovation Center;AG Robotik",
        "aff_unique_url": "https://www.dfki.de;https://www.uni-bremen.de",
        "aff_unique_abbr": "DFKI;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981241",
        "title": "Robot Learning from Demonstration Using Elastic Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) is a popular method of reproducing and generalizing robot skills from human-provided demonstrations. In this paper, we propose a novel optimization-based LfD method that encodes demon-strations as elastic maps. An elastic map is a graph of nodes connected through a mesh of springs. We build a skill model by fitting an elastic map to the set of demonstrations. The formulated optimization problem in our approach includes three objectives with natural and physical interpretations. The main term rewards the mean squared error in the Cartesian coordinate. The second term penalizes the non-equidistant distribution of points resulting in the optimum total length of the trajectory. The third term rewards smoothness while pe-nalizing nonlinearity. These quadratic objectives form a convex problem that can be solved efficiently with local optimizers. We examine nine methods for constructing and weighting the elastic maps and study their performance in robotic tasks. We also evaluate the proposed method in several simulated and real-world experiments using a UR5e manipulator arm, and compare it to other LfD approaches to demonstrate its benefits and flexibility across a variety of metrics.",
        "primary_area": "",
        "author": "Brendan Hertel;Matthew Pelland;S. Reza Ahmadzadeh;Brendan Hertel;Matthew Pelland;S. Reza Ahmadzadeh",
        "authorids": "/37089194524;/37089663198;/38180433100;/37089194524;/37089663198;/38180433100",
        "aff": "Persistent Autonomy and Robot Learning (PeARL) Lab, University of Massachusetts, Lowell, MA; Persistent Autonomy and Robot Learning (PeARL) Lab, University of Massachusetts, Lowell, MA; Persistent Autonomy and Robot Learning (PeARL) Lab, University of Massachusetts, Lowell, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981241/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2144347913810964633&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Massachusetts",
        "aff_unique_dep": "Persistent Autonomy and Robot Learning (PeARL) Lab",
        "aff_unique_url": "https://www.uml.edu",
        "aff_unique_abbr": "UMass Lowell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lowell",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981633",
        "title": "Robot Learning to Paint from Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic painting tasks in the real world are often made complicated by the highly complex and stochastic nature of the dynamics that underlie, e.g., physical contact between the painting tool and a canvas, color blendings between painting mediums, and many more. Simulation-based inverse graphics algorithms, for example, can not be directly transferred to the real-world due in large to the considerable gap in the viable range of painting strokes the robot can accurately generate onto the physical canvas. In this paper, we aim at minimizing this gap by appealing to a data-driven skill learning approach. The core idea lies in allowing the robot to learn continuous stroke-level skills that jointly encodes action trajectories and painted outcomes from an extensive collection of human demonstrations. We demonstrate the efficacy of our method through extensive real-world experiments using a 4-dof torque-controllable manipulator with a digital canvas(iPad).",
        "primary_area": "",
        "author": "Younghyo Park;Seunghun Jeon;Taeyoon Lee;Younghyo Park;Seunghun Jeon;Taeyoon Lee",
        "authorids": "/37089570261;/37088926846;/37086353797;/37089570261;/37088926846;/37086353797",
        "aff": "Seoul National University; Korea Advanced Institude of Science and Technology (KAIST); NAVER LABS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981633/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=516536795625425831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Seoul National University;Korea Advanced Institute of Science and Technology;NAVER Corporation",
        "aff_unique_dep": ";;NAVER LABS",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kaist.ac.kr;https://www.naverlabs.com",
        "aff_unique_abbr": "SNU;KAIST;NAVER LABS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981769",
        "title": "Robot Motion Planning as Video Prediction: A Spatio-Temporal Neural Network-based Motion Planner",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural network (NN)-based methods have emerged as an attractive approach for robot motion planning due to strong learning capabilities of NN models and their inherently high parallelism. Despite the current development in this direction, the efficient capture and processing of important sequential and spatial information, in a direct and simultaneous way, is still relatively under-explored. To overcome the challenge and unlock the potentials of neural networks for motion planning tasks, in this paper, we propose STP-Net, an end-to-end learning framework that can fully extract and leverage important spatio-temporal information to form an efficient neural motion planner. By interpreting the movement of the robot as a video clip, robot motion planning is transformed to a video prediction task that can be performed by STP-Net in both spatially and temporally efficient ways. Empirical evaluations across different seen and unseen environments show that, with nearly 100% accuracy (aka, success rate), STP-Net demonstrates very promising performance with respect to both planning speed and path cost. Compared with existing NN-based motion planners, STP-Net achieves at least 5\u00d7, 2.6\u00d7 and 1.8\u00d7 faster speed with lower path cost on 2D Random Forest, 2D Maze and 3D Random Forest environments, respectively. Furthermore, STP-Net can quickly and simultaneously compute multiple near-optimal paths in multi-robot motion planning tasks.",
        "primary_area": "",
        "author": "Xiao Zang;Miao Yin;Lingyi Huang;Jingjin Yu;Saman Zonouz;Bo Yuan;Xiao Zang;Miao Yin;Lingyi Huang;Jingjin Yu;Saman Zonouz;Bo Yuan",
        "authorids": "/37089538006;/37087137352;/37089205875;/37536570700;/38577393200;/38521367500;/37089538006;/37087137352;/37089205875;/37536570700;/38577393200;/38521367500",
        "aff": "Department of Electrical and Computer Engineering, Rutgers University; Department of Electrical and Computer Engineering, Rutgers University; Department of Electrical and Computer Engineering, Rutgers University; Department of Computer Science, Rutgers University; Department of Electrical and Computer Engineering, Rutgers University; Department of Electrical and Computer Engineering, Rutgers University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981769/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2688945400864168884&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981056",
        "title": "Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning robotic tasks in the real world is still highly challenging and effective practical solutions remain to be found. Traditional methods used in this area are imitation learning and reinforcement learning, but they both have limitations when applied to real robots. Combining reinforcement learning with pre-collected demonstrations is a promising approach that can help in learning control policies to solve robotic tasks. In this paper, we propose an algorithm that uses novel techniques to leverage offline expert data using offline and online training to obtain faster convergence and improved performance. The proposed algorithm (AWET) weights the critic losses with a novel agent advantage weight to improve over the expert data. In addition, AWET makes use of an automatic early termination technique to stop and discard policy rollouts that are not similar to expert trajectories-to prevent drifting far from the expert data. In an ablation study, AWET showed improved and promising performance when compared to state-of-the-art baselines on four standard robotic tasks.",
        "primary_area": "",
        "author": "Abdalkarim Mohtasib;Gerhard Neumann;Heriberto Cuay\u00e1huitl;Abdalkarim Mohtasib;Gerhard Neumann;Heriberto Cuay\u00e1huitl",
        "authorids": "/37086741914;/38542033100;/37298872200;/37086741914;/38542033100;/37298872200",
        "aff": "Lincoln Center for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, United Kingdom; Autonomous Learning Robots, KIT, Karlsruhe, Germany; Lincoln Center for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981056/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5613057357964394332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Lincoln;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Lincoln Center for Autonomous Systems (L-CAS);Autonomous Learning Robots",
        "aff_unique_url": "https://www.lincoln.ac.uk;https://www.kit.edu",
        "aff_unique_abbr": "UoL;KIT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Lincoln;Karlsruhe",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9981933",
        "title": "Robot Skill Learning with Identification of Preconditions and Postconditions via Level Set Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Hierarchical algorithms have often been used to plan and execute complicated robotic sequential manipulation tasks, where an abstract planner searches for a skill sequence in an abstract space, and each skill generates actual motions on the basis of the planned skill sequences. To generate executable plans, the abstract planner should know the pre-/postconditions of each skill and appropriately choose skills so that the generated plan satisfies their pre-/postconditions. For such hierarchical planning, this paper presents a novel method for robot skill learning that learns not only a control policy but also the learned skill's pre-/postconditions to complete a given task. Our method combines an optimal control method and an active learning approach called level set estimation (LSE) to effectively collect training data for learning control policies and pre-/postconditions. Although there exists a LSE-based policy learning algorithm that identifies preconditions, its performance is limited to cases where the dimension of the search space for pre-/postconditions is low. The main contribution of this paper is the proposal of a new learning method that can handle tasks having a high-dimensional search space for pre-/postconditions. We demonstrate our proposed method in two robotic tasks. The results show that our method can more effectively learn a control policy and its pre-/postconditions compared with the existing LSE-based method.",
        "primary_area": "",
        "author": "Rin Takano;Hiroyuki Oyama;Yuki Taya;Rin Takano;Hiroyuki Oyama;Yuki Taya",
        "authorids": "/37086014041;/37085392095;/37087403817;/37086014041;/37085392095;/37087403817",
        "aff": "Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981933/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5308812761971860922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "Data Science Research Laboratories",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kawasaki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981424",
        "title": "Robot Trajectory Adaptation to Optimise the Trade-off between Human Cognitive Ergonomics and Workplace Productivity in Collaborative Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "In hybrid industrial environments, workers' comfort and positive perception of safety are essential requirements for successful acceptance and usage of collaborative robots. This paper proposes a novel human-robot interaction framework in which the robot behaviour is adapted online according to the operator's cognitive workload and stress. The method exploits the generation of B-spline trajectories in the joint space and formulation of a multi-objective optimisation problem to online adjust the total execution time and smoothness of the robot trajectories. The former ensures human efficiency and productivity of the workplace, while the latter contributes to safeguarding the user's comfort and cognitive ergonomics. The performance of the proposed framework was evaluated in a typical industrial task. Results demonstrated its capability to enhance the productivity of the human-robot dyad while mitigating the cognitive workload induced in the worker.",
        "primary_area": "",
        "author": "Marta Lagomarsino;Marta Lorenzini;Elena De Momi;Arash Ajoudani;Marta Lagomarsino;Marta Lorenzini;Elena De Momi;Arash Ajoudani",
        "authorids": "/37088446713;/37086249968;/37947344300;/37945239900;/37088446713;/37086249968;/37947344300;/37945239900",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Human-Robot Interfaces and Physical Interaction Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Human-Robot Interfaces and Physical Interaction Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981424/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13156601376780471411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;Human-Robot Interfaces and Physical Interaction Laboratory",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Milan;Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9982000",
        "title": "Robot-Assisted Drilling on Curved Surfaces with Haptic Guidance under Adaptive Admittance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Drilling a hole on a curved surface with a desired angle is prone to failure when done manually, due to the difficulties in drill alignment and also inherent instabilities of the task, potentially causing injury and fatigue to the workers. On the other hand, it can be impractical to fully automate such a task in real manufacturing environments because the parts arriving at an assembly line can have various complex shapes where drill point locations are not easily accessible, making automated path planning difficult. In this work, an adaptive admittance controller with 6 degrees of freedom is developed and deployed on a KUKA LBR iiwa 7 cobot such that the operator is able to manipulate a drill mounted on the robot with one hand comfortably and open holes on a curved surface with haptic guidance of the cobot and visual guidance provided through an AR interface. Real-time adaptation of the admittance damping provides more transparency when driving the robot in free space while ensuring stability during drilling. After the user brings the drill sufficiently close to the drill target and roughly aligns to the desired drilling angle, the haptic guidance module fine tunes the alignment first and then constrains the user movement to the drilling axis only, after which the operator simply pushes the drill into the workpiece with minimal effort. Two sets of experiments were conducted to investigate the potential benefits of the haptic guidance module quantitatively (Experiment I) and also the practical value of the proposed pHRI system for real manufacturing settings based on the subjective opinion of the participants (Experiment II). The results of Experiment I, conducted with 3 naive participants, show that the haptic guidance improves task completion time by 26% while decreasing human effort by 16% and muscle activation levels by 27% compared to no haptic guidance condition. The results of Experiment II, conducted with 3 experienced industrial workers, show that the propos... Show More",
        "primary_area": "",
        "author": "Alireza Madani;Pouya P. Niaz;Berk Guler;Yusuf Aydin;Cagatay Basdogan;Alireza Madani;Pouya P. Niaz;Berk Guler;Yusuf Aydin;Cagatay Basdogan",
        "authorids": "/37089635226;/37089663013;/37089658941;/37086031961;/37295365600;/37089635226;/37089663013;/37089658941;/37086031961;/37295365600",
        "aff": "Robotics and Mechatronics Laboratory, KUIS AI-Center, Koc University, Istanbul, Turkey; Robotics and Mechatronics Laboratory, KUIS AI-Center, Koc University, Istanbul, Turkey; Robotics and Mechatronics Laboratory, KUIS AI-Center, Koc University, Istanbul, Turkey; Department of Electrical and Electronics Engineering, MEF University, Istanbul, Turkey; Robotics and Mechatronics Laboratory, KUIS AI-Center, Koc University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982000/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17605551281301223421&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Koc University;MEF University",
        "aff_unique_dep": "Robotics and Mechatronics Laboratory;Department of Electrical and Electronics Engineering",
        "aff_unique_url": "https://www.ku.edu.tr;https://www.mef.edu.tr",
        "aff_unique_abbr": "Koc U;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Istanbul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "9981881",
        "title": "Robot-Assisted Nuclear Disaster Response: Report and Insights from a Field Exercise",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports on insights by robotics researchers that participated in a 5-day robot-assisted nuclear disaster response field exercise conducted by Kerntechnische Hilfdienst GmbH (KHG) in Karlsruhe, Germany. The German nuclear industry established KHG to provide a robot-assisted emergency response capability for nuclear accidents. We present a systematic description of the equipment used; the robot operators' training program; the field exercise and robot tasks; and the protocols followed during the exercise. Additionally, we provide insights and suggestions for advancing disaster response robotics based on these observations. Specifically, the main degradation in performance comes from the cognitive and attentional demands on the operator. Furthermore, robotic platforms and modules should aim to be robust and reliable in addition to their ease of use. Last, as emergency response stakeholders are often skeptical about using autonomous systems, we suggest adopting a variable autonomy paradigm to integrate autonomous robotic capabilities with the human-in-the-loop gradually. This middle ground between teleoperation and autonomy can increase end-user acceptance while directly alleviating some of the operator's robot control burden and maintaining the resilience of the human-in-the-loop.",
        "primary_area": "",
        "author": "Manolis Chiou;Georgios-Theofanis Epsimos;Grigoris Nikolaou;Pantelis Pappas;Giannis Petousakis;Stefan M\u00fchl;Rustam Stolkin;Manolis Chiou;Georgios-Theofanis Epsimos;Grigoris Nikolaou;Pantelis Pappas;Giannis Petousakis;Stefan M\u00fchl;Rustam Stolkin",
        "authorids": "/37085708820;/37088600550;/37088515512;/37088600706;/37088518567;/37089662847;/37424300500;/37085708820;/37088600550;/37088515512;/37088600706;/37088518567;/37089662847;/37424300500",
        "aff": "Extreme Robotics Lab, University of Birmingham, UK; University of West Attica, Greece; University of West Attica, Greece; University of West Attica, Greece; Extreme Robotics Lab, University of Birmingham, UK; Kerntechnische Hilfdienst GmbH (KHG), Germany; Extreme Robotics Lab, University of Birmingham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981881/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4236253955920241263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;2;0",
        "aff_unique_norm": "University of Birmingham;University of West Attica;Kerntechnische Hilfdienst GmbH",
        "aff_unique_dep": "Extreme Robotics Lab;;",
        "aff_unique_url": "https://www.birmingham.ac.uk;https://www.uoa.gr;",
        "aff_unique_abbr": ";;KHG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;0;2;0",
        "aff_country_unique": "United Kingdom;Greece;Germany"
    },
    {
        "id": "9981278",
        "title": "Robot-aided Microbial Density Estimation and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the microbial infestation profile of an area is essential for an effective cleaning process. However, current methods used to inspect the microbial infestation within a spatial region are manual and laborious. For large regions that require automated cleaning, conventional methods of microbial examination are not practical. We propose a novel robot-aided microbial density estimation and mapping framework using an in-house developed biosensor payload onboard a mobile robot. The biosensor estimates the degree of microbial infestation in Relative Light Units (RLU) using the natural bio-luminescence reaction. The global distribution of microbial infestation is approximated through the Radial Basis Function (RBF) and Nearest Neighbour (NN) interpolation algorithms. The proposed method is implemented on an in-house developed mobile robot called Beluga. The framework's validation and usefulness are demonstrated quantitatively through real-world experiment trials.",
        "primary_area": "",
        "author": "J. J. J. Pey;A. P. Povendhan;T. Pathmakumar;M. R. Elara;J. J. J. Pey;A. P. Povendhan;T. Pathmakumar;M. R. Elara",
        "authorids": "/37089659537;/37089000428;/37086155469;/37546093700;/37089659537;/37089000428;/37086155469;/37546093700",
        "aff": "J. J. J. Pey; A. P. Povendhan; T. Pathmakumar; M. R. Elara",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981278/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17191307814394469677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9982082",
        "title": "RobotCore: An Open Architecture for Hardware Acceleration in ROS 2",
        "track": "main",
        "status": "Poster",
        "abstract": "Hardware acceleration can revolutionize robotics, enabling new applications by speeding up robot response times while remaining power-efficient. However, the diversity of acceleration options makes it difficult for roboticists to easily deploy accelerated systems without expertise in each specific hardware platform. In this work, we address this challenge with RobotCore, an architecture to integrate hardware acceleration in the widely-used ROS 2 robotics software framework. This architecture is target-agnostic (supports edge, workstation, data center, or cloud targets) and accelerator-agnostic (supports both FPGAs and GPUs). It builds on top of the common ROS 2 build system and tools and is easily portable across different research and commercial solutions through a new firmware layer. We also leverage the Linux Tracing Toolkit next generation (LTTng) to enable low-overhead real-time tracing and benchmarking of accelerated ROS 2 systems. To demonstrate the acceleration enabled by this architecture, we use it to deploy a ROS 2 perception computational graph on a CPU and FPGA. We also employ our integrated tracing and benchmarking to analyze bottlenecks, uncovering insights that guide us to improve FPGA communication efficiency. In particular, we design an intra-FPGA ROS 2 node communication queue template and use it in conjunction with FPGA-accelerated nodes to achieve a 24.42% speedup over a CPU.",
        "primary_area": "",
        "author": "V\u00edctor Mayoral-Vilches;Sabrina M. Neuman;Brian Plancher;Vijay Janapa Reddi;V\u00edctor Mayoral-Vilches;Sabrina M. Neuman;Brian Plancher;Vijay Janapa Reddi",
        "authorids": "/37088594953;/37062893900;/37086069939;/37293801200;/37088594953;/37062893900;/37086069939;/37293801200",
        "aff": "Alias Robotics, Vitoria, Spain; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Barnard College, Columbia University, New York, NY, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982082/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4784590052269596963&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Alias Robotics;Harvard University;Columbia University",
        "aff_unique_dep": ";School of Engineering and Applied Sciences;Barnard College",
        "aff_unique_url": ";https://www.harvard.edu;https://www.columbia.edu",
        "aff_unique_abbr": ";Harvard;Columbia",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Cambridge;New York",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Spain;United States"
    },
    {
        "id": "9981676",
        "title": "Robotic Actuation and Control of a Catheter for Structural Intervention Cardiology",
        "track": "main",
        "status": "Poster",
        "abstract": "Structural intervention cardiology (SIC) interventions are crucial procedures for correcting heart valves, walls, and muscle form defects. However, the possibility of embolization or perforation, as well as the lack of transparent vision and autonomous surgical equipment, make it difficult for the clinician. This paper proposes a robot-assisted tendon-driven catheter and machine learning-based path planner to overcome these challenges. Firstly, an analytical inverse kinematic model is constructed to convert the tip location in the Cartesian space to the tendons' displacement. Then inverse reinforcement learning algorithm is employed to calculate the optimal path to avoid possible collisions between the catheter tip and the atrial wall. Moreover, a closed-loop feedback controller is adopted to improve positioning accuracy in a direct distal position measurement manner. Simulation and experiments are designed and conducted to demonstrate the feasibility and performance of the proposed system.",
        "primary_area": "",
        "author": "Xiu Zhang;Maria Chiara Palumbo;Francesca Perico;Mattia Magro;Andrea Fortuna;Tommaso Magni;Emiliano Votta;Alice Segato;Elena De Momi;Xiu Zhang;Maria Chiara Palumbo;Francesca Perico;Mattia Magro;Andrea Fortuna;Tommaso Magni;Emiliano Votta;Alice Segato;Elena De Momi",
        "authorids": "/37089660195;/37089432452;/37089661441;/37089660427;/37089661187;/37089663952;/37652506700;/37088505401;/37085735806;/37089660195;/37089432452;/37089661441;/37089660427;/37089661187;/37089663952;/37652506700;/37088505401;/37085735806",
        "aff": "Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bio-engineering, Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981676/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15563327238048812100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Department of Electronics, Information and Bio-engineering",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Milan",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981054",
        "title": "Robotic Auscultation over Clothes for Eliminating Gender Bias",
        "track": "main",
        "status": "Poster",
        "abstract": "During auscultation, patients in difficult age often feel embarrassed and uncomfortable when exposing their chests to doctors of the different gender and being touched physically by doctors. We assume that an auscultation with robot technology can address the aforementioned gender-related issue. Toward eliminating gender bias during auscultation exam, this paper proposes a robotic platform which enables to perform the automated auscultation over clothes. Our developed system is comprised of two folds: a depth image-based estimation system of the listening positions over clothes with RGB-D camera and a contact force adjustment system for minimizing the acoustic attenuation due to the clothes with a passive-actuated end-effector. Our preliminary results demonstrated the robotic platform enables to estimate the listening locations to hear the sounds of four cardiac valves over the clothes by combining the estimated skeletal structure with statistical anatomical data and acquire the maximized acoustic quality over the clothes by adjusting the contact force. The developed robotic platform has the potential to address the gender-related issues in auscultation.",
        "primary_area": "",
        "author": "Ryosuke Tsumura;Akihiro Umezawa;Yuko Morishima;Hiroyasu Iwata;Yoshihiko Koseki;Naotaka Nitta;Kiyoshi Yoshinaka;Ryosuke Tsumura;Akihiro Umezawa;Yuko Morishima;Hiroyasu Iwata;Yoshihiko Koseki;Naotaka Nitta;Kiyoshi Yoshinaka",
        "authorids": "/37085879374;/37089518521;/37089660928;/37326645800;/37326145600;/37297847400;/37408303000;/37085879374;/37089518521;/37089660928;/37326645800;/37326145600;/37297847400;/37408303000",
        "aff": "Health and Medical Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Creative Science and Engineering, Waseda University, Tokyo, Japan; Faculty of Medicine, University of Tsukuba, Ibaraki, Japan; Department of Creative Science and Engineering, Waseda University, Tokyo, Japan; Health and Medical Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Health and Medical Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Health and Medical Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981054/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17828159629579764279&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;1;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Waseda University;University of Tsukuba",
        "aff_unique_dep": "Health and Medical Research Institute;Department of Creative Science and Engineering;Faculty of Medicine",
        "aff_unique_url": "https://www.aist.go.jp;https://www.waseda.jp/top;https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "AIST;Waseda;UT",
        "aff_campus_unique_index": "0;1;2;1;0;0;0",
        "aff_campus_unique": "Tsukuba;Tokyo;Ibaraki",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981450",
        "title": "Robotic Detection of a Human-Comprehensible Gestural Language for Underwater Multi-Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a motion-based robotic communication framework that enables non-verbal communication among autonomous underwater vehicles (AUVs) and human divers. We design a gestural language for AUV-to-AUV communication which can be easily understood by divers observing the conversation - unlike typical radio frequency, light, or audio-based AUV communication. To allow AUVs to visually understand a gesture from another AUV, we propose a deep network (RRCommNet) which exploits a self-attention mechanism to learn to recognize each message by extracting maximally discriminative spatio-temporal features. We train this network on diverse simulated and real-world data. Our experimental evaluations, both in simulation and in closed-water robot trials, demonstrate that the proposed RRCommNet architecture is able to decipher gesture-based messages with an average accuracy of 88-94% on simulated data and 73-83% on real data (depending on the version of the model used). Further, by performing a message transcription study with human participants, we also show that the proposed language can be understood by humans with an overall transcription accuracy of 88 %. Finally, we discuss the inference runtime of RRCommNet on embedded GPU hardware, for real-time use on board AUVs in the field.",
        "primary_area": "",
        "author": "Sadman Sakib Enan;Michael Fulton;Junaed Sattar;Sadman Sakib Enan;Michael Fulton;Junaed Sattar",
        "authorids": "/37088690306;/37086541498;/37546394500;/37088690306;/37086541498;/37546394500",
        "aff": "Department of Computer Science & Engineering, Minnesota Robotics Institute University of Minnesota, MN, USA; Department of Computer Science & Engineering, Minnesota Robotics Institute University of Minnesota, MN, USA; Department of Computer Science & Engineering, Minnesota Robotics Institute University of Minnesota, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981450/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=604763404161368676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "MN",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981461",
        "title": "Robotic Interestingness via Human-Informed Few-Shot Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Interestingness recognition is crucial for decision making in autonomous exploration for mobile robots. Previous methods proposed an unsupervised online learning approach that can adapt to environments and detect interesting scenes quickly, but lack the ability to adapt to human-informed interesting objects. To solve this problem, we introduce a human-interactive framework, AirInteraction, that can detect human-informed objects via few-shot online learning. To reduce the communication bandwidth, we first apply an online unsupervised learning algorithm on the unmanned vehicle for interestingness recognition and then only send the potential interesting scenes to a base-station for human inspection. The human operator is able to draw and provide bounding box annotations for particular interesting objects, which are sent back to the robot to detect similar objects via few-shot learning. Only using few human-labeled examples, the robot can learn novel interesting object categories during the mission and detect interesting scenes that contain the objects. We evaluate our method on various interesting scene recognition datasets. To the best of our knowledge, it is the first human-informed few-shot object detection framework for autonomous exploration.",
        "primary_area": "",
        "author": "Seungchan Kim;Chen Wang;Bowen Li;Sebastian Scherer;Seungchan Kim;Chen Wang;Bowen Li;Sebastian Scherer",
        "authorids": "/37089546342;/37089398088;/37089735939;/37584159000;/37089546342;/37089398088;/37089735939;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981461/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17225779133894946901&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981081",
        "title": "Robotic Powder Grinding with a Soft Jig for Laboratory Automation in Material Science",
        "track": "main",
        "status": "Poster",
        "abstract": "Grinding materials into a fine powder is a time-consuming task in material science that is generally performed by hand, as current automated grinding machines might not be suitable for preparing small-sized samples. This study presents a robotic powder grinding system for laboratory automation in material science applications that observe the powder's state to improve the grinding outcome. We developed a soft jig consisting of off-the-shelf gel materials and 3D-printed parts, which can be used with any robot arm to perform powder grinding. The jig's physical softness allows for safe grinding without force sensing. In addition, we developed a visual feedback system that observes the powder distribution and decides where to grind and when to gather. The results showed that our system could grind 79 percent of the powder to a particle size smaller than 200 \u03bcm by using the soft jig and visual feedback. This ratio was 57% when using only the soft jig without feedback. Our system can be used immediately in laboratories to alleviate the workload of researchers.",
        "primary_area": "",
        "author": "Yusaku Nakajima;Masashi Hamaya;Yuta Suzuki;Takafumi Hawai;Felix von Drigalski;Kazutoshi Tanaka;Yoshitaka Ushiku;Kanta Ono;Yusaku Nakajima;Masashi Hamaya;Yuta Suzuki;Takafumi Hawai;Felix von Drigalski;Kazutoshi Tanaka;Yoshitaka Ushiku;Kanta Ono",
        "authorids": "/37089663317;/37085532024;/37089660509;/37089658518;/37088526282;/37088507484;/37602449600;/37085543329;/37089663317;/37085532024;/37089660509;/37089658518;/37088526282;/37088507484;/37602449600;/37085543329",
        "aff": "Institute of Materials Structure Science (IMSS), High Energy Accelerator Research Organization (KEK), Ibaraki, Japan; OMRON SINIC X Corporation (OSX), Tokyo, Japan; Institute of Materials Structure Science (IMSS), High Energy Accelerator Research Organization (KEK), Ibaraki, Japan; Institute of Materials Structure Science (IMSS), High Energy Accelerator Research Organization (KEK), Ibaraki, Japan; OMRON SINIC X Corporation (OSX), Tokyo, Japan; OMRON SINIC X Corporation (OSX), Tokyo, Japan; OMRON SINIC X Corporation (OSX), Tokyo, Japan; Department of Applied Physics, Osaka University, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981081/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16334100246812812443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;1;1;2",
        "aff_unique_norm": "High Energy Accelerator Research Organization (KEK);OMRON SINIC X Corporation;Osaka University",
        "aff_unique_dep": "Institute of Materials Structure Science (IMSS);;Department of Applied Physics",
        "aff_unique_url": "https://www.kek.jp;;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "KEK;OSX;Osaka U",
        "aff_campus_unique_index": "1;1;1;1;2",
        "aff_campus_unique": ";Tokyo;Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981698",
        "title": "Robowflex: Robot Motion Planning with MoveIt Made Easy",
        "track": "main",
        "status": "Poster",
        "abstract": "Robowflex is a software library for robot motion planning in industrial and research applications, leveraging the popular Moveit library and Robot Operating System (ROS) middleware. Robowflex provides an augmented API for crafting and manipulating motion planning queries within a single program, making motion planning with Moveit easy. Robowflex's high-level API simplifies many common use-cases while still providing low-level access to the Moveit library when needed. Robowflex is particularly useful for 1) developing new motion planners, 2) evaluating motion planners, and 3) complex problems that use motion planning as a subroutine (e.g., task and motion planning). Robowflex also provides visualization capabilities, integrations to other robotics libraries (e.g., DART and Tesseract), and is complementary to other robotics packages. With our library, the user does not need to be an expert at ROS or Moveit to set up motion planning queries, extract information from results, and directly interface with a variety of software components. We demonstrate its efficacy through several example use-cases.",
        "primary_area": "",
        "author": "Zachary Kingston;Lydia E. Kavraki;Zachary Kingston;Lydia E. Kavraki",
        "authorids": "/37085542480;/37279015600;/37085542480;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981698/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12243890355819679331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981233",
        "title": "Robust Cartesian Kinematics Estimation for Task-Space Control Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We discuss a novel method for estimating task Cartesian position and velocity in robot manipulators. This is done by model-based fusion of inertial measurement units with motor encoders. The model is developed to robustly handle the uncertainties in the trajectory. Thus, not only the approach benefits from high fidelity and bandwidth thanks to multiple-sensory fusion, but it also enforces stability despite poorly formulated motions. This empowers the method to be utilized in complex closed-loop applications, where both task position and velocity information is required.",
        "primary_area": "",
        "author": "Seyed Ali Baradaran Birjandi;Niels Dehio;Abderrahmane Kheddar;Sami Haddadin;Seyed Ali Baradaran Birjandi;Niels Dehio;Abderrahmane Kheddar;Sami Haddadin",
        "authorids": "/37089196783;/37085760535;/37293875300;/37542865300;/37089196783;/37085760535;/37293875300;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany; CNRS-University of Montpellier, IDH, LIRMM, France; CNRS-University of Montpellier, IDH, LIRMM, France; Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981233/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15974448595080641785&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Technical University of Munich;University of Montpellier",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence;LIRMM",
        "aff_unique_url": "https://www.tum.de;https://www.univ-montp.fr",
        "aff_unique_abbr": "TUM;UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Germany;France"
    },
    {
        "id": "9981246",
        "title": "Robust Change Detection Based on Neural Descriptor Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to reason about changes in the environment is crucial for robots operating over extended periods of time. Agents are expected to capture changes during operation so that actions can be followed to ensure a smooth progression of the working session. However, varying viewing angles and accumulated localization errors make it easy for robots to falsely detect changes in the surrounding world due to low observation overlap and drifted object associations. In this paper, based on the recently proposed category-level Neural Descriptor Fields (NDFs), we develop an object-level online change detection approach that is robust to partially overlapping observations and noisy localization results. Utilizing the shape completion capability and SE(3)-equivariance of NDFs, we represent objects with compact shape codes encoding full object shapes from partial observations. The objects are then organized in a spatial tree structure based on object centers recovered from NDFs for fast queries of object neighborhoods. By associating objects via shape code similarity and comparing local object-neighbor spatial layout, our proposed approach demonstrates robustness to low observation overlap and localization noises. We conduct experiments on both synthetic and real-world sequences and achieve improved change detection results compared to multiple baseline methods. Project web-page: ?http://yilundu.github.io/ndf_change",
        "primary_area": "",
        "author": "Jiahui Fu;Yilun Du;Kurran Singh;Joshua B. Tenenbaum;John J. Leonard;Jiahui Fu;Yilun Du;Kurran Singh;Joshua B. Tenenbaum;John J. Leonard",
        "authorids": "/37089270086;/37089315638;/37088834646;/37622583000;/37329387400;/37089270086;/37089315638;/37088834646;/37622583000;/37329387400",
        "aff": "MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981246/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8959117391486783101&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981354",
        "title": "Robust Contact State Estimation in Humanoid Walking Gaits",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, we propose a deep learning frame-work that provides a unified approach to the problem of leg contact detection in humanoid robot walking gaits. Our formulation accomplishes to accurately and robustly estimate the contact state probability for each leg (i.e., stable or slip/no contact). The proposed framework employs solely propriocep-tive sensing and although it relies on simulated ground-truth contact data for the classification process, we demonstrate that it generalizes across varying friction surfaces and different legged robotic platforms and, at the same time, is readily transferred from simulation to practice. The framework is quantitatively and qualitatively assessed in simulation via the use of ground-truth contact data and is contrasted against state-of-the-art methods with an ATLAS, a NAO, and a TALOS humanoid robot. Furthermore, its efficacy is demonstrated in base estimation with a real TALOS humanoid. To reinforce further research endeavors, our implementation is offered as an open-source ROS/Python package, coined Legged Contact Detection (LCD).",
        "primary_area": "",
        "author": "Stylianos Piperakis;Michael Maravgakis;Dimitrios Kanoulas;Panos Trahanias;Stylianos Piperakis;Michael Maravgakis;Dimitrios Kanoulas;Panos Trahanias",
        "authorids": "/37085813142;/37089659866;/38230575500;/37329551300;/37085813142;/37089659866;/38230575500;/37329551300",
        "aff": "Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science, Heraklion, Greece; Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science, Heraklion, Greece; Computer Science Department, University College London, London, UK; Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science, Heraklion, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981354/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2572726616834830132&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Foundation for Research and Technology - Hellas;University College London",
        "aff_unique_dep": "Institute of Computer Science;Computer Science Department",
        "aff_unique_url": "https://www.forth.gr;https://www.ucl.ac.uk",
        "aff_unique_abbr": "FORTH;UCL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Heraklion;London",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Greece;United Kingdom"
    },
    {
        "id": "9981382",
        "title": "Robust Counterexample-guided Optimization for Planning from Differentiable Temporal Logic",
        "track": "main",
        "status": "Poster",
        "abstract": "Signal temporal logic (STL) provides a powerful, flexible framework for specifying complex autonomy tasks; however, existing methods for planning based on STL specifications have difficulty scaling to long-horizon tasks and are not robust to external disturbances. In this paper, we present an algorithm for finding robust plans that satisfy STL specifications. Our method alternates between local optimization and local falsification, using automatically differentiable temporal logic to iteratively optimize its plan in response to counterexamples found during the falsification process. We benchmark our counterexample-guided planning method against state-of-the-art planning methods on two long-horizon satellite rendezvous missions, showing that our method finds high-quality plans that satisfy STL specifications despite adversarial disturbances. We find that our method consistently finds plans that are robust to adversarial disturbances and requires less than half the time of competing methods. We provide an implementation of our planner at https://github.com/MIT-REALM/architect.",
        "primary_area": "",
        "author": "Charles Dawson;Chuchu Fan;Charles Dawson;Chuchu Fan",
        "authorids": "/37088688620;/38564621900;/37088688620;/38564621900",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981382/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7958641441216177635&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982132",
        "title": "Robust High-Speed Running for Quadruped Robots via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has emerged as a popular and powerful way to develop locomotion controllers for quadruped robots. Common approaches have largely focused on learning actions directly in joint space, or learning to modify and offset foot positions produced by trajectory generators. Both approaches typically require careful reward shaping and training for millions of time steps, and with trajectory generators introduce human bias into the resulting control policies. In this paper, we present a learning framework that leads to the natural emergence of fast and robust bounding policies for quadruped robots. The agent both selects and controls actions directly in task space to track desired velocity commands subject to environmental noise including model uncertainty and rough terrain. We observe that this framework improves sample efficiency, necessitates little reward shaping, leads to the emergence of natural gaits such as galloping and bounding, and eases the sim-to-real transfer at running speeds. Policies can be learned in only a few million time steps, even for challenging tasks of running over rough terrain with loads of over 100% of the nominal quadruped mass. Training occurs in PyBullet, and we perform a sim-to-sim transfer to Gazebo and sim-to-real transfer to the Unitree A1 hardware. For sim-to-sim, our results show the quadruped is able to run at over 4 m/s without a load, and 3.5 m/s with a 10 kg load, which is over 83% of the nominal quadruped mass. For sim-to-real, the Unitree A1 is able to bound at 2 m/s with a 5 kg load, representing 42% of the nominal quadruped mass.",
        "primary_area": "",
        "author": "Guillaume Bellegarda;Yiyu Chen;Zhuochen Liu;Quan Nguyen;Guillaume Bellegarda;Yiyu Chen;Zhuochen Liu;Quan Nguyen",
        "authorids": "/37086456120;/37089197452;/37089658268;/37085362091;/37086456120;/37089197452;/37089658268;/37085362091",
        "aff": "Dynamic Robotics and Control Laboratory, University of Southern California (USC); Dynamic Robotics and Control Laboratory, University of Southern California (USC); Dynamic Robotics and Control Laboratory, University of Southern California (USC); Dynamic Robotics and Control Laboratory, University of Southern California (USC)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982132/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4231068105132800458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Dynamic Robotics and Control Laboratory",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981877",
        "title": "Robust Human Motion Forecasting using Transformer-based Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Comprehending human motion is a fundamental challenge for developing Human-Robot Collaborative applications. Computer vision researchers have addressed this field by only focusing on reducing error in predictions, but not taking into account the requirements to facilitate its implementation in robots. In this paper, we propose a new model based on Transformer that simultaneously deals with the real time 3D human motion forecasting in the short and long term. Our 2-Channel Transformer (2CH-TR) is able to efficiently exploit the spatio-temporal information of a shortly observed sequence (400ms) and generates a competitive accuracy against the current state-of-the-art. 2CH-TR stands out for the efficient performance of the Transformer, being lighter and faster than its competitors. In addition, our model is tested in conditions where the human motion is severely occluded, demonstrating its robustness in reconstructing and predicting 3D human motion in a highly noisy environment. Our experiment results show that the proposed 2CH-TR outperforms the ST-Transformer, which is another state-of-the-art model based on the Transformer, in terms of reconstruction and prediction under the same conditions of input prefix. Our model reduces in 8.89% the mean squared error of ST-Transformer in short-term prediction, and 2.57% in long-term prediction in Human3.6M dataset with 400ms input prefix.",
        "primary_area": "",
        "author": "Esteve Valls Mascaro;Shuo Ma;Hyemin Ahn;Dongheui Lee;Esteve Valls Mascaro;Shuo Ma;Hyemin Ahn;Dongheui Lee",
        "authorids": "/37089661581;/37089663303;/37085492273;/37068725100;/37089661581;/37089663303;/37085492273;/37068725100",
        "aff": "Autonomous Systems, Technische Universit\u00e4t Wien (TU Wien), Austria; Human-centered Assisitve Robotics, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Artificial Intelligence Graduate School, Ulsan National Institute of Science and Technology (UNIST), Korea; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981877/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3850505654446303027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Technische Universit\u00e4t Wien;Technische Universit\u00e4t M\u00fcnchen;Ulsan National Institute of Science and Technology;German Aerospace Center",
        "aff_unique_dep": "Autonomous Systems;Human-centered Assisitve Robotics;Artificial Intelligence Graduate School;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.tum.de;https://www.unist.ac.kr;https://www.dlr.de",
        "aff_unique_abbr": "TU Wien;TUM;UNIST;DLR",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Wien;M\u00fcnchen;",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "Austria;Germany;South Korea"
    },
    {
        "id": "9981410",
        "title": "Robust Humanoid Walking System Considering Recognized Terrain and Robots' Balance",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots walk on uneven terrain, trajectory planning should take into account both the whole-body dy-namics and the ground geometry simultaneously. In uneven terrain environments, there are only a limited number of places where the robot is able to make stable contact with the ground without its feet wobbling or slipping because of the intricate round geometry. In such environments, the optional landing position and time to maintain the robot's balance and stable foot contact are not obvious and computationally expensive. In this study, we propose a robust walking system that integrates environment recognition using steppable regions and walking control for a humanoid robot to walk on uneven terrain. In this paper, a steppable region is defined as a two-dimensional convex hull that represents a region where a robot is capable of landing. We propose a method to compute the steppable region quickly by 2.SD projection of the environment points and spatial filtering. In this system, the walking controller integrates the steppable region with the Capture Region to modify the landing position from a two-dimensional geometric calculation. In addition, to cope with the environment recognition error, we have introduced a trajectory generation that allows the feet to penetrate the ground and hybrid control of position and torque. We verified the effectiveness of the proposed system through experiments in which a life-size humanoid robot walked on uneven terrain and recovered when pushed.",
        "primary_area": "",
        "author": "Shimpei Sato;Yuta Kojio;Yohei Kakiuchi;Kunio Kojima;Kei Okada;Masayuki Inaba;Shimpei Sato;Yuta Kojio;Yohei Kakiuchi;Kunio Kojima;Kei Okada;Masayuki Inaba",
        "authorids": "/37089197675;/37086211574;/38242437800;/37085360901;/37280639000;/37286658200;/37089197675;/37086211574;/38242437800;/37085360901;/37280639000;/37286658200",
        "aff": "Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano- Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981410/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11419895716519856072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981049",
        "title": "Robust Onboard Localization in Changing Environments Exploiting Text Spotting",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust localization in a given map is a crucial component of most autonomous robots. In this paper, we address the problem of localizing in an indoor environment that changes and where prominent structures have no correspondence in the map built at a different point in time. To overcome the discrepancy between the map and the observed environment caused by such changes, we exploit human-readable localization cues to assist localization. These cues are readily available in most facilities and can be detected using RGB camera images by utilizing text spotting. We integrate these cues into a Monte Carlo localization framework using a particle filter that operates on 2D LiDAR scans and camera data. By this, we provide a robust localization solution for environments with structural changes and dynamics by humans walking. We evaluate our localization framework on multiple challenging indoor scenarios in an office environment. The experiments suggest that our approach is robust to structural changes and can run on an onboard computer. We release an open source implementation of our approach11https://github.com/PRBonn/tmcl, which uses off-the-shelf text spotting, written in C++ with a ROS wrapper.",
        "primary_area": "",
        "author": "Nicky Zimmerman;Louis Wiesmann;Tiziano Guadagnino;Thomas L\u00e4be;Jens Behley;Cyrill Stachniss;Nicky Zimmerman;Louis Wiesmann;Tiziano Guadagnino;Thomas L\u00e4be;Jens Behley;Cyrill Stachniss",
        "authorids": "/37089030615;/37088802930;/37087324270;/37086411637;/37593243900;/37329668600;/37089030615;/37088802930;/37087324270;/37086411637;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981049/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13176323032023704359&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Bonn;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982225",
        "title": "Robust Real-time LiDAR-inertial Initialization",
        "track": "main",
        "status": "Poster",
        "abstract": "For most LiDAR-inertial odometry, accurate initial states, including temporal offset and extrinsic transfor-mation between LiDAR and 6-axis IMUs, play a significant role and are often considered as prerequisites. However, such information may not be always available in customized LiDAR-inertial systems. In this paper, we propose LI-Init: a full and real-time LiDAR-inertial system initialization process that calibrates the temporal offset and extrinsic parameter between LiDARs and IMUs, and also the gravity vector and IMU bias by aligning the state estimated from LiDAR measurements with that measured by IMU. We implement the proposed method as an initialization module, which can automatically detects the degree of excitation of the collected data and calibrate, on-the-fly, the temporal offset, extrinsic, gravity vector, and IMU bias, which are then used as high-quality initial state values for real-time LiDAR-inertial odometry systems. Experiments conducted with different types of LiDARs and LiDAR-inertial combinations show the robustness, adaptability and efficiency of our initialization method. The implementation of our LiDAR-inertial initialization procedure LI-Init and test data are open-sourced on Github11https://www.github.com/hku-mars/LiDAR IMU Init and also integrated into a state-of-the-art LiDAR-inertial odometry system FAST-LIO2.",
        "primary_area": "",
        "author": "Fangcheng Zhu;Yunfan Ren;Fu Zhang;Fangcheng Zhu;Yunfan Ren;Fu Zhang",
        "authorids": "/37089661744;/37087243712;/38245883800;/37089661744;/37087243712;/38245883800",
        "aff": "Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982225/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14249116551926105932&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981573",
        "title": "Robust Sim2Real Transfer with the da Vinci Research Kit: A Study On Camera, Lighting, and Physics Domain Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous surgical robotics is a growing area of research, with advances being made in the areas of vision and control. Central to this research is the need for simulations to facilitate data collection and simulate learning environments for Reinforcement Learning (RL) agents. Recent simulators have facilitated RL policy generation, but lack a robust sim2real pipeline and a proven vision-based policy that can use any type of camera including the da Vinci Surgical System (dVSS) Endoscope. To solve this, we build a ROS-based sim2real pipeline that incorporates a Unity3D da Vinci Research Kit (dVRK) simulation, modular kinematics, and shared interfaces. We examine the vision-based task of cube pushing, and train RL policies to execute in real life through Domain Randomization. Our experiments evaluate model success in simulation and two camera systems: OAK-1 and the dVSS Endoscope. Our results indicate that Domain Randomization is effective at bridging the sim2real gap, and even extends to the difficult endoscope scenario. We achieve 100% transfer success rate on both OAK-1 and the dVSS Endoscope, with gains of over 60% compared to a base model with no Domain Randomization. We examine the various randomization parameters, including lighting, camera, and physics variables, and determine that all parameters play a significant role in bridging the sim2real gap. Testing across extreme lighting and camera configurations not seen in simulation, our models continue to perform well, with 85% accuracy on the OAK-1 camera. Our future work will extend to other tasks and more complex policies to take advantage of stereo-camera imaging. Further project information is available at https://medcvr.utm.utoronto.ca/iros2022-sim2real.html",
        "primary_area": "",
        "author": "Mustafa Haiderbhai;Radian Gondokaryono;Thomas Looi;James M. Drake;Lueder A. Kahrs;Mustafa Haiderbhai;Radian Gondokaryono;Thomas Looi;James M. Drake;Lueder A. Kahrs",
        "authorids": "/37088475242;/37086268694;/38498292300;/38512992300;/37303985100;/37088475242;/37086268694;/38498292300;/38512992300;/37303985100",
        "aff": "The Wilfred and Joyce Posluns CIGITI, SickKids, Toronto, Canada; The Wilfred and Joyce Posluns CIGITI, SickKids, Toronto, Canada; The Wilfred and Joyce Posluns CIGITI, SickKids, Toronto, Canada; The Wilfred and Joyce Posluns CIGITI, SickKids, Toronto, Canada; Institute of Biomedical Engineering, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981573/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12830466593681681940&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "SickKids;University of Toronto",
        "aff_unique_dep": "The Wilfred and Joyce Posluns CIGITI;Institute of Biomedical Engineering",
        "aff_unique_url": "https://www.sickkids.ca;https://www.utoronto.ca",
        "aff_unique_abbr": "SickKids;U of T",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982032",
        "title": "Robust Trajectory Planning for Spatial-Temporal Multi-Drone Coordination in Large Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we describe a robust multi-drone planning framework for high-speed trajectories in large scenes. It uses a free-space-oriented map to free the optimization from cumbersome environment data. A capsule-like safety constraint is designed to avoid reciprocal collisions when vehicles deviate from their nominal flight progress under disturbance. We further show the minimum-singularity differential flatness of our drone dynamics with nonlinear drag effects involved. Leveraging the flatness map, trajectory optimization is efficiently conducted on the flat outputs while still subject to physical limits considering drag forces at high speeds. The robustness and effectiveness of our framework are both validated in large-scale simulations. It can compute collision-free trajectories satisfying high-fidelity vehicle constraints for hundreds of drones within 10 minutes.",
        "primary_area": "",
        "author": "Zhepei Wang;Chao Xu;Fei Gao;Zhepei Wang;Chao Xu;Fei Gao",
        "authorids": "/37086601081;/37404060100;/37086045143;/37086601081;/37404060100;/37086045143",
        "aff": "Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982032/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18142107096771771488&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Huzhou Institute",
        "aff_unique_url": "https://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982233",
        "title": "Robustness-based Synthesis for Stochastic Systems under Signal Temporal Logic Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a method for synthesizing control policies for stochastic, linear, time-varying systems that must perform tasks specified in signal temporal logic. We build upon an efficient, sampling-based framework that computes the probability of the system satisfying its specification. By exploiting the properties of linear systems and robustness score in temporal logic specifications, we obtain sample-efficient gradients of the satisfaction probability with respect to con-troller parameters. Therefore, by applying gradient descent we obtain locally optimized controllers that maximize the chances of satisfying the specification. We demonstrate our approach through examples of a mobile robot and a mobile manipulator in simulation.",
        "primary_area": "",
        "author": "Guy Scher;Sadra Sadraddini;Hadas Kress-Gazit;Guy Scher;Sadra Sadraddini;Hadas Kress-Gazit",
        "authorids": "/37088526154;/37085778307;/38307602100;/37088526154;/37085778307;/38307602100",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Dexai Robotics, Boston, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982233/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16897109095879252969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Cornell University;Dexai Robotics",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.cornell.edu;",
        "aff_unique_abbr": "Cornell;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Ithaca;Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982034",
        "title": "Rotor Array Synergies for Aerial Modular Reconfigurable Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial Modular Reconfigurable Robots (AMRRs) are scalable systems consisting of rotor modules capable of rearrangement during flight. The potential to dynamically change any shape for a given task poses the question: what arrangements offer the most aerodynamic benefit for the task of flying? Answering this requires understanding how adjacent rotors in various configurations influence each another. Intuitively, aerodynamic models such as momentum theory suggest that close rotor proximity decreases performance due to the upstream rotor flow fields interacting. However, effects such as vortex interaction or viscous flow entrainment (used by the Dyson bladeless fan) may offer benefits not captured by the modelling assumptions of computational analysis or simulation. Thus, this work takes an experimental approach, testing thrust performance of rotors in independent configurations of lines, square lattices, and hexagons with various inter-rotor spacings. It was found that inter-rotor spacing did not significantly change thrust performance, but that hexagonal arrangements outperformed line and grid lattices. Smoke tests indicated that hexagon configurations entrained air in the central cavity resulting in a thrust improvement. An inter-rotor spacing of 1.51 rotor diameters gave the best performance increase, roughly equal to that of an additional rotor. This suggests that by placing rotors in an array of six hollow hexagonal honeycombs, thrust performance could theoretically be increased by up to 27.3 per cent, for no additional mass.",
        "primary_area": "",
        "author": "Benjamin Moshirian;Pauline E.I. Pounds;Benjamin Moshirian;Pauline E.I. Pounds",
        "authorids": "/37089660985;/37571590000;/37089660985;/37571590000",
        "aff": "Robotics Institute, University of Technology Sydney, Sydney, NSW, Australia; University of Queensland, Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982034/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:YsLTSLJ8_Q4J:scholar.google.com/&scioq=Rotor+Array+Synergies+for+Aerial+Modular+Reconfigurable+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Technology Sydney;University of Queensland",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.uts.edu.au;https://www.uq.edu.au",
        "aff_unique_abbr": "UTS;UQ",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Sydney;Queensland",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9982101",
        "title": "S-MKI: Incremental Dense Semantic Occupancy Reconstruction Through Multi-Entropy Kernel Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots are often required to acquire high-level prior knowledge by continuously reconstructing the semantics and geometry of the surrounding scene, which is the basis of exploration and planning. Most existing continuous semantic mapping algorithms cannot distinguish potential differences in voxels, resulting in an over-inflated map. Furthermore, fixed-size query ranges introduce high computational complexity. Based on the limitation of over-inflation and inefficiency, this paper proposes a novel incremental continuous semantic occupancy mapping algorithm (S-MKI). The key innovation of this work comes from the two models in the preprocessing stage. On the one hand, Redundant Voxel Filter Model utilizes context entropy to filter out redundant voxels to improve the confidence of the final map, where objects have accurate boundaries with sharp edges. On the other hand, Adaptive Kernel Length Model adaptively adjusts the kernel length with class entropy, which reduces the inherent amount of training data. The final multientropy kernel inference function is formulated to integrate these two models to infer sparse noisy sensor data into dense accurate 3D maps. Experimental results conducted in both indoors and outdoors datasets validate that S-MKI outperforms existing methods.",
        "primary_area": "",
        "author": "Yinan Deng;Meiling Wang;Danwei Wang;Yufeng Yue;Yinan Deng;Meiling Wang;Danwei Wang;Yufeng Yue",
        "authorids": "/37089661012;/37406965500;/37279547600;/37086172414;/37089661012;/37406965500;/37279547600;/37086172414",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982101/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5578407364601440831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Beijing Institute of Technology;Nanyang Technological University",
        "aff_unique_dep": "School of Automation;School of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "BIT;NTU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Beijing;Singapore",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9981370",
        "title": "S3LAM: Structured Scene SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new SLAM system that uses the semantic segmentation of objects and structures in the scene. Semantic information is relevant as it contains high level information which may make SLAM more accurate and robust. Our contribution is twofold: i) A new SLAM system based on ORB-SLAM2 that creates a semantic map made of clusters of points corresponding to objects instances and structures in the scene. ii) A modification of the classical Bundle Adjustment formulation to constrain each cluster using geometrical priors, which improves both camera localization and reconstruction and enables a better understanding of the scene. We evaluate our approach on sequences from several public datasets and show that it improves camera pose estimation with respect to state of the art.",
        "primary_area": "",
        "author": "Mathieu Gonzalez;Eric Marchand;Amine Kacete;Jerome Royan;Mathieu Gonzalez;Eric Marchand;Amine Kacete;Jerome Royan",
        "authorids": "/37088810004;/37269970500;/37085785418;/37298463100;/37088810004;/37269970500;/37085785418;/37298463100",
        "aff": "Institute of Research and Technology b<>com; Univ Rennes, Inria, IRISA, CNRS, Rennes, France; Institute of Research and Technology b<>com; Institute of Research and Technology b<>com",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981370/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=299018946457602457&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Institute of Research and Technology;University of Rennes",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.b-com.com;https://www.univ-rennes1.fr",
        "aff_unique_abbr": "b<>com;Univ Rennes",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Rennes",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981555",
        "title": "SCALER: A Tough Versatile Quadruped Free-Climber Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces SCALER, a quadrupedal robot that demonstrates climbing on bouldering walls, over-hangs, ceilings and trotting on the ground. SCALER is one of the first high-degrees of freedom four-limbed robots that can free-climb under the Earth's gravity and one of the most mechanically efficient quadrupeds on the ground. Where other state-of-the-art climbers specialize in climbing, SCALER promises practical free-climbing with payload and ground locomotion, which realizes true versatile mobility. A new climbing gait, SKATE gait, increases the payload by utilizing the SCALER body linkage mechanism. SCALER achieves a maximum normalized locomotion speed of 1.87 /s, or 0.56 m/s on the ground and 1.0 /min, or 0.35 m/min in bouldering wall climbing. Payload capacity reaches 233 % of the SCALER weight on the ground and 35 % on the vertical wall. Our GOAT gripper, a mechanically adaptable underactuated two-finger gripper, successfully grasps convex and non-convex objects and supports SCALER.",
        "primary_area": "",
        "author": "Yusuke Tanaka;Yuki Shirai;Xuan Lin;Alexander Schperberg;Hayato Kato;Alexander Swerdlow;Naoya Kumagai;Dennis Hong;Yusuke Tanaka;Yuki Shirai;Xuan Lin;Alexander Schperberg;Hayato Kato;Alexander Swerdlow;Naoya Kumagai;Dennis Hong",
        "authorids": "/37088439498;/37086344073;/37085891795;/37088689963;/37089659737;/37089662907;/37089659650;/37575333900;/37088439498;/37086344073;/37085891795;/37088689963;/37089659737;/37089662907;/37089659650;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981555/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12135064977990907436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982092",
        "title": "SEED: Series Elastic End Effectors in 6D for Visuotactile Tool Use",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose the framework of Series Elastic End Effectors in 6D (SEED), which combines a spatially compliant element with visuotactile sensing to grasp and manipulate tools in the wild. Our framework generalizes the benefits of series elasticity to 6-dof, while providing an abstraction of control using visuotactile sensing. We propose an algorithm for relative pose estimation from visuotactile sensing, and a spatial hybrid force-position controller capable of achieving stable force interaction with the environment. We demonstrate the effectiveness of our framework on tools that require regulation of spatial forces. Video link: https://youtu.be/2-YuIfspDrk.",
        "primary_area": "",
        "author": "H.J. Terry Suh;Naveen Kuppuswamy;Tao Pang;Paul Mitiguy;Alex Alspach;Russ Tedrake;H.J. Terry Suh;Naveen Kuppuswamy;Tao Pang;Paul Mitiguy;Alex Alspach;Russ Tedrake",
        "authorids": "/37089305651;/37297597200;/37089309719;/37089660946;/37992498900;/37283152200;/37089305651;/37297597200;/37089309719;/37089660946;/37992498900;/37283152200",
        "aff": "Massachusetts Institute of Technology, Cambridge, Massachusetts; Toyota Research Institute, Cambridge, Massachusetts; Massachusetts Institute of Technology, Cambridge, Massachusetts; Toyota Research Institute, Cambridge, Massachusetts; Toyota Research Institute, Cambridge, Massachusetts; Toyota Research Institute, Cambridge, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982092/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13033577083673894122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981645",
        "title": "SESNO: Sample Efficient Social Navigation from Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the Sample Efficient Social Navigation from Observation (SESNO) algorithm that efficiently learns socially-compliant navigation policies from observations of human trajectories. SESNO is an inverse reinforcement learning (IRL)-based algorithm that learns from human trajectory observations without knowledge of their actions. We improve the sample-efficiency over previous IRL-based methods by introducing a shared experience replay buffer that allows reuse of past trajectory experiences to estimate the policy and the reward. We evaluate SESNO using publicly available pedestrian motion data sets and compare its performance to related baseline methods in the literature. We show that SESNO yields performance superior to existing baselines while dramatically improving the sample complexity by using as few as a hundredth of the samples required by existing baselines.",
        "primary_area": "",
        "author": "Bobak H. Baghi;Abhisek Konar;Francois Hogan;Michael Jenkin;Gregory Dudek;Bobak H. Baghi;Abhisek Konar;Francois Hogan;Michael Jenkin;Gregory Dudek",
        "authorids": "/37088652341;/37088652173;/37086455261;/37269066400;/37274057100;/37088652341;/37088652173;/37086455261;/37269066400;/37274057100",
        "aff": "Samsung Electronics SAIC-Montreal, Montreal, QC, Canada; Samsung Electronics SAIC-Montreal, Montreal, QC, Canada; Samsung Electronics SAIC-Montreal, Montreal, QC, Canada; Samsung Electronics SAIC-Montreal, Montreal, QC, Canada; Samsung Electronics SAIC-Montreal, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981645/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2262976807737563337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "SAIC",
        "aff_unique_url": "https://www.samsung.com/ca/",
        "aff_unique_abbr": "Samsung",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981845",
        "title": "SESR: Self-Ensembling Sim-to-Real Instance Segmentation for Auto-Store Bin Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance segmentation is an important task for supporting robotic grasping in auto-store scenarios. Accurate segmentation usually relies on the quantity and quality of available annotated training data. However, it requires tremendous cost to obtain these labels. In this work, without requiring any human annotations on real data, our proposed self-ensembling sim-to-real network, namely SESR, is able to generate precise instance masks for a wide variety of supermarket goods. We design our SESR with a teacher model and a student model trained with a self-ensembling strategy. We adopt different levels of consistency to bridge the sim-to-real gap and boost the model generalization ability. Also, we compile an auto-store bin-picking dataset covering various goods. Extensive experiments on both unseen scenarios and unseen objects validate the effectiveness and superiority of our method over others, and the robot arm demonstrations further show that our segmentation results can support real-time auto-store bin picking.",
        "primary_area": "",
        "author": "Biqi Yang;Xiaojie Gao;Kai Chen;Rui Cao;Yidan Feng;Xianzhi Li;Qi Dou;Chi-Wing Fu;Yun-Hui Liu;Pheng-Ann Heng;Biqi Yang;Xiaojie Gao;Kai Chen;Rui Cao;Yidan Feng;Xianzhi Li;Qi Dou;Chi-Wing Fu;Yun-Hui Liu;Pheng-Ann Heng",
        "authorids": "/37089307076;/37088506701;/37404002500;/37089307526;/37088456659;/37086569101;/37085465414;/37336329800;/37279412600;/37283077400;/37089307076;/37088506701;/37404002500;/37089307526;/37088456659;/37086569101;/37085465414;/37336329800;/37279412600;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, Nanjing University of Aeronautics and Astronautics; School of Computer Science and Technology, Huazhong University of Science and Technology; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Guangdong-Hong Kong-Macao Joint Laboratory, Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981845/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16587131421897297335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;1;2;0;0;0;3",
        "aff_unique_norm": "Chinese University of Hong Kong;Nanjing University of Aeronautics and Astronautics;Huazhong University of Science and Technology;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science and Engineering;School of Computer Science and Technology;Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.nuaa.edu.cn;http://www.hust.edu.cn;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;NUAA;HUST;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;2",
        "aff_campus_unique": "Hong Kong SAR;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981375",
        "title": "SKILL-IL: Disentangling Skill and Knowledge in Multitask Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we introduce a new perspective for learning transferable content in multi-task imitation learning. Humans are capable of transferring skills and knowledge. If we can cycle to work and drive to the store, we can also cycle to the store and drive to work. We take inspiration from this and hypothesize the latent memory of a policy network can be disentangled into two partitions. These contain either the knowledge of the environmental context for the task or the generalisable skill needed to solve the task. This allows an improved training efficiency and better generalization over previously unseen combinations of skills in the same environment, and the same task in unseen environments. We used the proposed approach to train a disentangled agent for two different multi-task IL environments. In both cases, we out-performed the SOTA by 30% in task success rate. We also demonstrated this for navigation on a real robot.",
        "primary_area": "",
        "author": "Bian Xihan;Oscar Mendez;Simon Hadfield;Bian Xihan;Oscar Mendez;Simon Hadfield",
        "authorids": "/37089000191;/37710939600;/38232557500;/37089000191;/37710939600;/38232557500",
        "aff": "Bian Xihan; Oscar Mendez; Simon Hadfield",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981375/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2168825879235740390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9981145",
        "title": "SLAM-Supported Self-Training for 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress in object pose prediction provides a promising path for robots to build object-level scene representations during navigation. However, as we deploy a robot in novel environments, the out-of-distribution data can degrade the prediction performance. To mitigate the domain gap, we can potentially perform self-training in the target domain, using predictions on robot-captured images as pseudo labels to fine-tune the object pose estimator. Unfortunately, the pose predictions are typically outlier-corrupted, and it is hard to quantify their uncertainties, which can result in low-quality pseudo-labeled data. To address the problem, we propose a SLAM-supported self-training method, leveraging robot understanding of the 3D scene geometry to enhance the object pose inference performance. Combining the pose predictions with robot odometry, we formulate and solve pose graph optimization to refine the object pose estimates and make pseudo labels more consistent across frames. We incorporate the pose prediction covariances as variables into the optimization to automatically model their uncertainties. This automatic covariance tuning (ACT) process can fit 6D pose prediction noise at the component level, leading to higher-quality pseudo training data. We test our method with the deep object pose estimator (DOPE) on the YCB video dataset and in real robot experiments. It achieves respectively 34.3% and 17.8% accuracy enhancements in pose prediction on the two tests. Our code is available at https://github.com/520xyxyzq/slam-super-6d.",
        "primary_area": "",
        "author": "Ziqi Lu;Yihao Zhang;Kevin Doherty;Odin Severinsen;Ethan Yang;John Leonard;Ziqi Lu;Yihao Zhang;Kevin Doherty;Odin Severinsen;Ethan Yang;John Leonard",
        "authorids": "/37089194233;/37088999548;/37085769742;/37089660564;/37089658718;/37329387400;/37089194233;/37088999548;/37085769742;/37089660564;/37089658718;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981145/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9729370230767767588&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981459",
        "title": "SMA-NBO: A Sequential Multi-Agent Planning with Nominal Belief-State Optimization in Target Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In target tracking with mobile multi-sensor sys-tems, sensor deployment impacts the observation capabilities and the resulting state estimation quality. Based on a partially observable Markov decision process (POMDP) formulation comprised of the observable sensor dynamics, unobservable target states, and accompanying observation laws, we present a distributed information-driven solution approach to the multi-agent target tracking problem, namely, sequential multi-agent nominal belief-state optimization (SMA-NBO). SMA-NBO seeks to minimize the expected tracking error via receding horizon control including a heuristic expected cost-to-go (HECTG). SMA-NBO incorporates a computationally efficient approximation of the target belief-state over the horizon. The agent-by-agent decision-making is capable of leveraging on-board (edge) compute for selecting (sub-optimal) target-tracking maneuvers exhibiting non-myopic cooperative fleet behavior. The opti-mization problem explicitly incorporates semantic information defining target occlusions from a world model. To illustrate the efficacy of our approach, a random occlusion forest environment is simulated. SMA-NBO is compared to other baseline approaches. The simulation results show SMA-NBO 1) maintains tracking performance and reduces the computational cost by replacing the calculation of the expected target trajectory with a single sample trajectory based on maximum a posteriori estimation; 2) generates cooperative fleet decision by sequentially optimizing single-agent policy with efficient usage of other agents' policy of intent; 3) aptly incorporates the multiple weighted trace penalty (MWTP) HECTG, which improves tracking performance with a computationally efficient heuristic.",
        "primary_area": "",
        "author": "Tianqi Li;Lucas W. Krakow;Swaminathan Gopalswamy;Tianqi Li;Lucas W. Krakow;Swaminathan Gopalswamy",
        "authorids": "/37088806248;/37300549400;/38190877000;/37088806248;/37300549400;/38190877000",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Bush Combat Development Complex (BCDC), Texas A&M University, Bryan, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981459/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1098456428858514262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "College Station;Bryan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981289",
        "title": "SMS-MPC: Adversarial Learning-based Simultaneous Prediction Control with Single Model for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Model predictive control is a promising method in robot control tasks. How to design an effective model structure and efficient prediction framework for model predictive control is still an open challenge. To reduce the time consumption and avoid compounding-error of the multi-step prediction process in model predictive control, we propose a single-model simultaneous framework, which uses single dynamics model to predict the entire prediction horizon simultaneously by taking all control actions with the current state as inputs. Based on this framework, we further propose an adversarial dynamics model that contains two parts. The generator provides a dynamics model for the prediction process, while the discriminator provides constraints that are hard to describe by manually defined loss. This adversarial dynamics model can accelerate training and improve model accuracy in unstructured environments. Experiments conducted in Gazebo simulator and on a real mobile robot demonstrate the efficiency and accuracy of the single-model simultaneous framework with an adversarial dynamics model.",
        "primary_area": "",
        "author": "Andong Yang;Wei Li;Yu Hu;Andong Yang;Wei Li;Yu Hu",
        "authorids": "/37089660032;/37089000125;/37277445400;/37089660032;/37089000125;/37277445400",
        "aff": "Chinese Academy of Sciences, Research Center for Intelligent Computing Systems, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Research Center for Intelligent Computing Systems, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Research Center for Intelligent Computing Systems, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981289/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8459442529090896811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Research Center for Intelligent Computing Systems, Institute of Computing Technology, University of Chinese Academy of Sciences",
        "aff_unique_url": "http://www.cas.ac.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981094",
        "title": "SO-PFH: Semantic Object-based Point Feature Histogram for Global Localization in Parking Lot",
        "track": "main",
        "status": "Poster",
        "abstract": "Global localization is essential for autonomous mobile systems, especially indoor applications where the GPS signal is denied. Although the appearance-based methods have been successfully applied in various localization tasks, they face various challenges such as light variation, viewpoint changing, and dynamic interference. Additionally, the appearance-based methods usually require a visual feature point map, which increases the storage burden. This paper proposes a novel global localization solution that leverages sparse and repetitive semantic object information. The proposal can fulfill global localization based on object-level maps that are self-built or externally provided. In this solution, the semantic objects are firstly modeled with a point cloud. Then, the object's semantic information is embedded into the geometry of the corresponding point, and the Semantic Object-based Point Feature Histogram (SO-PFH) descriptors of the modeled point clouds are estimated. Finally, the global localization is executed by applying a Geometric Consistency Filter-based RANdom SAmple Consensus (GCF-RANSAC) method to match point clouds. Experiments and simulations are conducted in indoor parking lots. The results demonstrate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Jixin Lv;Chao Meng;Yue Wang;Jie Sun;Rong Xiong;Shiliang Pu;Jixin Lv;Chao Meng;Yue Wang;Jie Sun;Rong Xiong;Shiliang Pu",
        "authorids": "/38548389500;/37089663588;/37072299700;/37089315488;/37271511300;/37085657816;/38548389500;/37089663588;/37072299700;/37089315488;/37271511300;/37085657816",
        "aff": "Hikvison Research Institute, Hangzhou Hikvision Digital Technology Co., Ltd., Hangzhou, China; Hikvison Research Institute, Hangzhou Hikvision Digital Technology Co., Ltd., Hangzhou, China; Zhejiang University, Hangzhou, China; Hikvison Research Institute, Hangzhou Hikvision Digital Technology Co., Ltd., Hangzhou, China; Zhejiang University, Hangzhou, China; Hikvison Research Institute, Hangzhou Hikvision Digital Technology Co., Ltd., Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981094/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5561430488041390249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "Hikvision Research Institute;Zhejiang University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.hikvision.com/cn/;http://www.zju.edu.cn",
        "aff_unique_abbr": "HRI;ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981936",
        "title": "SPARCS: Structuring Physically Assistive Robotics for Caregiving with Stakeholders-in-the-loop",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing work in physical robot caregiving is limited in its ability to provide long-term assistance. This is majorly due to (i) lack of well-defined problems, (ii) diversity of tasks, and (iii) limited access to stakeholders from the caregiving community. We propose Structuring Physically Assistive Robotics for Caregiving with Stakeholders-in-the-loop (SPARCS) to address these challenges. SPARCS is a framework for physical robot caregiving comprising (i) Building Blocks, models that define physical robot caregiving scenarios, (ii) Structured Workflows, hierarchical workflows that enable us to answer the Whats and Hows of physical robot caregiving, and (iii) SPARCS-box, a web-based platform to facilitate dialogue between all stakeholders. We collect clinical data for six care recipients with varying disabilities and demonstrate the use of SPARCS in designing well-defined caregiving scenarios and identifying their care requirements. All the data and workflows are available on SPARCS-box. We demonstrate the utility of SPARCS in building a robot-assisted feeding system for one of the care recipients. We also perform experiments to show the adaptability of this system to different caregiving scenarios. Finally, we identify open challenges in physical robot caregiving by consulting care recipients and caregivers. Supplementary material can be found at emprise.cs.cornell.edu/sparcs.",
        "primary_area": "",
        "author": "Rishabh Madan;Rajat Kumar Jenamani;Vy Thuy Nguyen;Ahmed Moustafa;Xuefeng Hu;Katherine Dimitropoulou;Tapomayukh Bhattacharjee;Rishabh Madan;Rajat Kumar Jenamani;Vy Thuy Nguyen;Ahmed Moustafa;Xuefeng Hu;Katherine Dimitropoulou;Tapomayukh Bhattacharjee",
        "authorids": "/37089171750;/37089663685;/37089659266;/37089658439;/37089662049;/37089663786;/37531634500;/37089171750;/37089663685;/37089659266;/37089658439;/37089662049;/37089663786;/37531634500",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Columbia University, New York City, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981936/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3027278829921851651&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Cornell University;Columbia University",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.cornell.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Cornell;Columbia",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Ithaca;New York City",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982129",
        "title": "SROS2: Usable Cyber Security Tools for ROS 2",
        "track": "main",
        "status": "Poster",
        "abstract": "ROS 2 is rapidly becoming a standard in the robotics industry. Built upon DDS as its default communication middleware and used in safety-critical scenarios, adding secu-rity to robots and ROS computational graphs is increasingly becoming a concern. The present work introduces SROS2, a series of developer tools and libraries that facilitate adding security to ROS 2 graphs. Focusing on a usability-centric approach in SROS2, we present a methodology for securing graphs systematically while following the DevSecOps model. We also demonstrate the use of our security tools by presenting an application case study that considers securing a graph using the popular Navigation2 and SLAM Toolbox stacks applied in a TurtieBot3 robot. We analyse the current capabilities of SROS2 and discuss the shortcomings, which provides insights for future contributions and extensions. Ultimately, we present SROS2 as usable security tools for ROS 2 and argue that without usability, security in robotics will be greatly impaired.",
        "primary_area": "",
        "author": "Victor Mayoral-Vilches;Ruffin White;Gianluca Caiazza;Mikael Arguedas;Victor Mayoral-Vilches;Ruffin White;Gianluca Caiazza;Mikael Arguedas",
        "authorids": "/37088594953;/37086290046;/37086579684;/37088811224;/37088594953;/37086290046;/37086579684;/37088811224",
        "aff": "System Security Group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Secura Factors srls, Venice, Italy; Secura Factors srls, Venice, Italy; NeoFarm, Chemin des Quarante Arpents, Saint-Nom-la-Breteche, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982129/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3761987590194812374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt;Secura Factors srls;NeoFarm",
        "aff_unique_dep": "System Security Group;;",
        "aff_unique_url": "https://www.aau.at;;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Klagenfurt;",
        "aff_country_unique_index": "0;1;1;2",
        "aff_country_unique": "Austria;Italy;France"
    },
    {
        "id": "9981506",
        "title": "SSP-Pose: Symmetry-Aware Shape Prior Deformation for Direct Category-Level Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Category-level pose estimation is a challenging problem due to intra-class shape variations. Recent methods deform pre-computed shape priors to map the observed point cloud into the normalized object coordinate space and then retrieve the pose via post-processing, i.e., Umeyama's Algorithm. The shortcomings of this two-stage strategy lie in two aspects: 1) The surrogate supervision on the intermediate results can not directly guide the learning of pose, resulting in large pose error after post-processing. 2) The inference speed is limited by the post-processing step. In this paper, to handle these shortcomings, we propose an end-to-end trainable network SSP-Pose for category-level pose estimation, which integrates shape priors into a direct pose regression network. SSP-Pose stacks four individual branches on a shared feature extractor, where two branches are designed to deform and match the prior model with the observed instance, and the other two branches are applied for directly regressing the totally 9 degrees-of-freedom pose and performing symmetry reconstruction and point-wise inlier mask prediction respectively. Consistency loss terms are then naturally exploited to align the outputs of different branches and promote the performance. During inference, only the direct pose regression branch is needed. In this manner, SSP-Pose not only learns category-level pose-sensitive characteristics to boost performance but also keeps a real-time inference speed. Moreover, we utilize the symmetry information of each category to guide the shape prior deformation, and propose a novel symmetry-aware loss to mitigate the matching ambiguity. Extensive experiments on public datasets demon-strate that SSP-Pose produces superior performance compared with competitors with a real-time inference speed at about 25Hz. The codes will be released soon.",
        "primary_area": "",
        "author": "Ruida Zhang;Yan Di;Fabian Manhardt;Federico Tombari;Xiangyang Ji;Ruida Zhang;Yan Di;Fabian Manhardt;Federico Tombari;Xiangyang Ji",
        "authorids": "/37089540507;/37088505061;/37085664475;/37593332100;/37271425200;/37089540507;/37088505061;/37085664475;/37593332100;/37271425200",
        "aff": "Tsinghua University; Technical University of Munich; Google; Google; Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981506/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7144484251780010252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "Tsinghua University;Technical University of Munich;Google",
        "aff_unique_dep": ";;Google",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.tum.de;https://www.google.com",
        "aff_unique_abbr": "THU;TUM;Google",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;2;2;0",
        "aff_country_unique": "China;Germany;United States"
    },
    {
        "id": "9981279",
        "title": "STEADY: Simultaneous State Estimation and Dynamics Learning from Indirect Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate kinodynamic models play a crucial role in many robotics applications such as off-road navigation and high-speed driving. Many state-of-the-art approaches for learning stochastic kinodynamic models, however, require precise measurements of robot states as labeled input/output examples, which can be hard to obtain in outdoor settings due to limited sensor capabilities and the absence of ground truth. In this work, we propose a new technique for learning neural stochastic kinodynamic models from noisy and indirect observations by performing simultaneous state estimation and dynamics learning. The proposed technique iteratively improves the kinodynamic model in an expectation-maximization loop, where the E Step samples posterior state trajectories using particle filtering, and the M Step updates the dynamics to be more consistent with the sampled trajectories via stochastic gradient ascent. We evaluate our approach on both simulation and real-world benchmarks and compare it with several baseline techniques. Our approach not only achieves significantly higher accuracy but is also more robust to observation noise, thereby showing promise for boosting the performance of many other robotics applications.",
        "primary_area": "",
        "author": "Jiayi Wei;Jarrett Holtz;Isil Dillig;Joydeep Biswas;Jiayi Wei;Jarrett Holtz;Isil Dillig;Joydeep Biswas",
        "authorids": "/37089197655;/37086307815;/37086228218;/37538259200;/37089197655;/37086307815;/37086228218;/37538259200",
        "aff": "Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981279/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7896737982469671325&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981546",
        "title": "STUN: Self-Teaching Uncertainty Estimation for Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is key to Simultaneous Localization and Mapping (SLAM) and spatial perception. However, a place recognition in the wild often suffers from erroneous predictions due to image variations, e.g., changing viewpoints and street appearance. Integrating uncertainty estimation into the life cycle of place recognition is a promising method to mitigate the impact of variations on place recognition performance. However, existing uncertainty estimation approaches in this vein are either computationally inefficient (e.g., Monte Carlo dropout) or at the cost of dropped accuracy. This paper proposes STUN, a self-teaching framework that learns to simultaneously predict the place and estimate the prediction uncertainty given an input image. To this end, we first train a teacher net using a standard metric learning pipeline to produce embedding priors. Then, supervised by the pretrained teacher net, a student net with an additional variance branch is trained to finetune the embedding priors and estimate the uncertainty sample by sample. During the online inference phase, we only use the student net to generate a place prediction in conjunction with the uncertainty. When compared with place recognition systems that are ignorant of the uncertainty, our framework features the uncertainty estimation for free without sacrificing any prediction accuracy. Our experimental results on the large-scale Pittsburgh30k dataset demonstrate that STUN outperforms the state-of-the-art methods in both recognition accuracy and the quality of uncertainty estimation.",
        "primary_area": "",
        "author": "Kaiwen Cai;Chris Xiaoxuan Lu;Xiaowei Huang;Kaiwen Cai;Chris Xiaoxuan Lu;Xiaowei Huang",
        "authorids": "/37089489008;/37086107301;/37086944121;/37089489008;/37086107301;/37086944121",
        "aff": "University of Liverpool; University of Edinburgh; University of Liverpool",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981546/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18400406595017144770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Liverpool;University of Edinburgh",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "Liv Uni;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981857",
        "title": "STheReO: Stereo Thermal Dataset for Research in Odometry and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a stereo thermal camera dataset (STheReO) with multiple navigation sensors to encourage thermal SLAM researches. A thermal camera measures infrared rays beyond the visible spectrum therefore it could provide a simple yet robust solution to visually degraded environments where existing visual sensor-based SLAM would fail. Existing thermal camera datasets mostly focused on monocular configuration using the thermal camera with RGB cameras in a visually challenging environment. A few stereo thermal rig were examined but in computer vision perspective without supporting sequential images for state estimation algorithms. To encourage the academia for the evolving stereo thermal SLAM, we obtain nine sequences in total across three spatial locations and three different times per location (e.g., morning, day, and night) to capture the variety of thermal characteristics. By using the STheReO dataset, we hope diverse types of researches will be made, including but not limited to odometry, mapping, and SLAM (e.g., thermal-LiDAR mapping or long-term thermal localization). Our datasets are available at https://sites.google.com/view/rpmsthereo/.",
        "primary_area": "",
        "author": "Seungsang Yun;Minwoo Jung;Jeongyun Kim;Sangwoo Jung;Younghun Cho;Myung-Hwan Jeon;Giseop Kim;Ayoung Kim;Seungsang Yun;Minwoo Jung;Jeongyun Kim;Sangwoo Jung;Younghun Cho;Myung-Hwan Jeon;Giseop Kim;Ayoung Kim",
        "authorids": "/37089356085;/37089663635;/37089355774;/37089663895;/37085469522;/37088439542;/37086578593;/37403315600;/37089356085;/37089663635;/37089355774;/37089663895;/37085469522;/37088439542;/37086578593;/37403315600",
        "aff": "Depart. of Mech. Eng., SNU, S. Korea; Depart. of Mech. Eng., SNU, S. Korea; Depart. of Mech. Eng., SNU, S. Korea; Depart. of Mech. Eng., SNU, S. Korea; Depart. of Civil and Env. Eng., KAIST, S. Korea; Robotics Program, KAIST, Daejeon, S. Korea; NAVER LABS, Autonomous Driving Group, S. Korea; Depart. of Mech. Eng., SNU, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981857/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12557150637944576703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;2;0",
        "aff_unique_norm": "Seoul National University;KAIST;NAVER LABS",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Civil and Environmental Engineering;Autonomous Driving Group",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kaist.ac.kr;https://www.naverlabs.com",
        "aff_unique_abbr": "SNU;KAIST;NAVER LABS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981741",
        "title": "Safe Drone Flight with Time-Varying Backup Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "The weight, space, and power limitations of small aerial vehicles often prevent the application of modern control techniques without significant model simplifications. Moreover, high-speed agile behavior, such as that exhibited in drone racing, make these simplified models too unreliable for safety-critical control. In this work, we introduce the concept of time-varying backup controllers (TBCs): user-specified maneuvers combined with backup controllers that generate reference trajectories which guarantee the safety of nonlinear systems. TBCs reduce conservatism when compared to traditional backup controllers and can be directly applied to multi-agent coordination to guarantee safety. Theoretically, we provide conditions under which TBCs strictly reduce conservatism, describe how to switch between several TBC's and show how to embed TBCs in a multi-agent setting. Experimentally, we verify that TBCs safely increase operational freedom when filtering a pilot's actions and demonstrate robustness and computational efficiency when applied to decentralized safety filtering of two quadrotors.",
        "primary_area": "",
        "author": "Andrew Singletary;Aiden Swann;Ivan Dario Jimenez Rodriguez;Aaron D. Ames;Andrew Singletary;Aiden Swann;Ivan Dario Jimenez Rodriguez;Aaron D. Ames",
        "authorids": "/37086449553;/37089280441;/37089197749;/37300877900;/37086449553;/37089280441;/37089197749;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A.; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A.; Deparment of Computational Math and Science, California Institute of Technology, Pasadena, CA, U.S.A.; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981741/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14411633521302040141&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982038",
        "title": "Safe Reinforcement Learning for Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing control policies for legged locomotion11In this work, we specifically consider quadruped locomotion. is complex due to the under-actuated and non-continuous robot dynamics. Model-free reinforcement learning provides promising tools to tackle this challenge. However, a major bottleneck of applying model-free reinforcement learning in real world is safety. In this paper, we propose a safe reinforcement learning framework that switches between a safe recovery policy that prevents the robot from entering unsafe states, and a learner policy that is optimized to complete the task. The safe recovery policy takes over the control when the learner policy violates safety constraints, and hands over the control back when there are no future safety violations. We design the safe recovery policy so that it ensures safety of quadruped locomotion while minimally intervening in the learning process. Furthermore, we theoretically analyze the proposed framework and provide an upper bound on the task performance. We verify the proposed framework in four tasks on a simulated and real quadrupedal robot: efficient gait, catwalk, two-leg balance, and pacing. On average, our method achieves 48.6% fewer falls and comparable or better rewards than the baseline methods in simulation. When deployed it on real-world quadruped robot, our training pipeline enables 34% improvement in energy efficiency for the efficient gait, 40.9% narrower of the feet placement in the catwalk, and two times more jumping duration in the two-leg balance. Our method achieves less than five falls over the duration of 115 minutes of hardware time.22Video is included in the submission and the project website: https://sites.google.com/view/saferlleggedlocomotion/",
        "primary_area": "",
        "author": "Tsung-Yen Yang;Tingnan Zhang;Linda Luu;Sehoon Ha;Jie Tan;Wenhao Yu;Tsung-Yen Yang;Tingnan Zhang;Linda Luu;Sehoon Ha;Jie Tan;Wenhao Yu",
        "authorids": "/37086035363;/37088504200;/37089659014;/37086314268;/37086455820;/37085891022;/37086035363;/37088504200;/37089659014;/37086314268;/37086455820;/37085891022",
        "aff": "Google Research; Google Research; Google Research; Georgia Institute of Technology; Google Research; Google Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982038/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=738500526414025852&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Google;Georgia Institute of Technology",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://www.gatech.edu",
        "aff_unique_abbr": "Google Research;Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981763",
        "title": "Safe adaptation in multiagent competition",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving the capability of adapting to ever-changing environments is a critical step towards building fully autonomous robots that operate safely in complicated scenarios. In multiagent competitive scenarios, agents may have to adapt to new opponents with previously unseen behaviors by learning from the interaction experiences between the ego-agent and the opponent. However, this adaptation is susceptible to opponent exploitation. As the ego-agent updates its own behavior to exploit the opponent, its own behavior could become more exploitable as a result of overfitting to this specific opponent's behavior. To overcome this difficulty, we developed a safe adaptation approach in which the ego-agent is trained against a regularized opponent model, which effectively avoids overfitting and consequently improves the robustness of the ego-agent's policy. We evaluated our approach in the Mujoco domain with two competing agents. The experiment results suggest that our approach effectively achieves both adaptation to the specific opponent that the ego-agent is interacting with and maintaining low exploitability to other possible opponent exploitation.",
        "primary_area": "",
        "author": "Macheng Shen;Jonathan P. How;Macheng Shen;Jonathan P. How",
        "authorids": "/37086159756;/37276347700;/37086159756;/37276347700",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981763/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14453592901519563873&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981085",
        "title": "Safe and Efficient Exploration of Human Models During Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Many collaborative human-robot tasks require the robot to stay safe and work efficiently around humans. Since the robot can only stay safe with respect to its own model of the human, we want the robot to learn a good model of the human in order to act both safely and efficiently. This paper studies methods that enable a robot to safely explore the space of a human-robot system to improve the robot's model of the human, which will consequently allow the robot to access a larger state space and better work with the human. In particular, we introduce active exploration under the framework of energy-function based safe control, investigate the effect of different active exploration strategies, and finally analyze the effect of safe active exploration on both analytical and neural network human models.",
        "primary_area": "",
        "author": "Ravi Pandya;Changliu Liu;Ravi Pandya;Changliu Liu",
        "authorids": "/37086455359;/37085543217;/37086455359;/37085543217",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981085/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2894145751223478196&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981469",
        "title": "Safe and Ergonomic Human-Drone Interaction in Warehouses",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an application of human-drone interaction (HDI) for inventory management in a ware-house 4.0 that aims at improving the operators' safety and well-being together with increasing efficiency and reducing production costs. In our work, the speed and separation monitoring (SSM) methodology is applied for the first time to HDI, in analogy to the human-robot interaction (HRI) ISO safety requirements as well as the rapid upper limb assessment (RULA), for evaluating the operator's ergonomic posture during the interaction with the drone. With the aim of validating the proposed approach in a realistic scenario, a quadrotor is controlled to perform a pick and place task along a desired trajectory, from the picking bay to the palletizing area where the operator is located, avoiding collisions with the warehouse shelves by implementing the artificial potential field technique (APF) for planning and the linear quadratic regulator (LQR) and iterative LQR (iLQR) algorithms for tracking. The obtained results of the HDI architecture simulations are presented and discussed in detail proving the effectiveness of the proposed method for a safe and ergonomic HDI.",
        "primary_area": "",
        "author": "Silvia Proia;Graziana Cavone;Antonio Camposeo;Fabio Ceglie;Raffaele Carli;Mariagrazia Dotoli;Silvia Proia;Graziana Cavone;Antonio Camposeo;Fabio Ceglie;Raffaele Carli;Mariagrazia Dotoli",
        "authorids": "/37088985107;/37085402888;/37283676900;/37089658765;/37085348833;/37300909600;/37088985107;/37085402888;/37283676900;/37089658765;/37085348833;/37300909600",
        "aff": "Department of Electrical and Information Engineering, Polytechnic of Bari, Italy; Department of Engineering, University of Roma, Tre, Italy; Department of Electrical and Information Engineering, Polytechnic of Bari, Italy; Department of Electrical and Information Engineering, Polytechnic of Bari, Italy; Department of Electrical and Information Engineering, Polytechnic of Bari, Italy; Department of Electrical and Information Engineering, Polytechnic of Bari, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981469/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2239364039352825685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Polytechnic of Bari;University of Roma Tre",
        "aff_unique_dep": "Department of Electrical and Information Engineering;Department of Engineering",
        "aff_unique_url": "https://www.poliba.it;https://www.uniroma3.it",
        "aff_unique_abbr": ";UniRoma3",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Roma",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9982140",
        "title": "SafeTAC: Safe Tsallis Actor-Critic Reinforcement Learning for Safer Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Satisfying safety constraints is the top priority in safe reinforcement learning (RL). However, without proper exploration, an overly conservative policy such as freezing at the same position can be generated. To this end, we utilize maximum entropy RL methods for exploration. In particular, an RL method with Tsallis entropy maximization, called Tsallis actor-critic (TAC), is used to synthesize policies which can explore with more promising actions. In this paper, we propose a Tsallis entropy-regularized safe RL method for safer exploration, called SafeTAC. For more expressiveness, we extend the TAC to use a Gaussian mixture model policy, which improves the safety performance. To stabilize the training process, the retrace estimators for safety critics are formulated, and a safe policy update rule using a trust region method is proposed.",
        "primary_area": "",
        "author": "Dohyeong Kim;Jaeseok Heo;Songhwai Oh;Dohyeong Kim;Jaeseok Heo;Songhwai Oh",
        "authorids": "/37088687766;/37089662179;/37068116900;/37088687766;/37089662179;/37068116900",
        "aff": "Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982140/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=254532772005839499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981831",
        "title": "Safety Correction from Baseline: Towards the Risk-aware Policy in Robotics via Dual-agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning a risk-aware policy is essential but rather challenging in unstructured robotic tasks. Safe reinforcement learning methods open up new possibilities to tackle this problem. However, the conservative policy updates make it intractable to achieve sufficient exploration and desirable performance in complex, sample-expensive environments. In this paper, we propose a dual-agent safe reinforcement learning strategy consisting of a baseline and a safe agent. Such a decoupled framework enables high flexibility, data efficiency and risk-awareness for RL-based control. Concretely, the baseline agent is responsible for maximizing rewards under standard RL settings. Thus, it is compatible with off-the-shelf training techniques of unconstrained optimization, exploration and exploitation. On the other hand, the safe agent mimics the baseline agent for policy improvement and learns to fulfill safety constraints via off-policy RL tuning. In contrast to training from scratch, safe policy correction requires significantly fewer interactions to obtain a near-optimal policy. The dual policies can be optimized synchronously via a shared replay buffer, or leveraging the pre-trained model or the non-learning-based controller as a fixed baseline agent. Experimental results show that our approach can learn feasible skills without prior knowledge as well as deriving risk-averse counterparts from pre-trained unsafe policies. The proposed method outperforms the state-of-the-art safe RL algorithms on difficult robot locomotion and manipulation tasks with respect to both safety constraint satisfaction and sample efficiency.",
        "primary_area": "",
        "author": "Linrui Zhang;Zichen Yan;Li Shen;Shoujie Li;Xueqian Wang;Dacheng Tao;Linrui Zhang;Zichen Yan;Li Shen;Shoujie Li;Xueqian Wang;Dacheng Tao",
        "authorids": "/37087124260;/37086111584;/37088876322;/37089229975;/37085383477;/37269935500;/37087124260;/37086111584;/37088876322;/37089229975;/37085383477;/37269935500",
        "aff": "Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; JD Explore Academy, Beijing, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; JD Explore Academy, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981831/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1097243311512195258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;1",
        "aff_unique_norm": "Tsinghua University;JD",
        "aff_unique_dep": "Center for Intelligent Control and Telescience;JD Explore Academy",
        "aff_unique_url": "http://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "Tsinghua;",
        "aff_campus_unique_index": "0;0;1;0;0;1",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981030",
        "title": "Safety Guided Policy Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "In reinforcement learning (RL), exploration is essential to achieve a globally optimal policy but unconstrained exploration can cause damages to robots and nearby people. To handle this safety issue in exploration, safe RL has been proposed to keep the agent under the specified safety constraints while maximizing cumulative rewards. This paper introduces a new safe RL method which can be applied to robots to operate under the safety constraints while learning. The key component of the proposed method is the safeguard module. The safeguard predicts the constraints in the near future and corrects actions such that the predicted constraints are not violated. Since actions are safely modified by the safeguard during exploration and policies are trained to imitate the corrected actions, the agent can safely explore. Additionally, the safeguard is sample efficient as it does not require long horizontal trajectories for training, so constraints can be satisfied within short time steps. The proposed method is extensively evaluated in simulation and experiments using a real robot. The results show that the proposed method achieves the best performance while satisfying safety constraints with minimal interaction with environments in all experiments.",
        "primary_area": "",
        "author": "Dohyeong Kim;Yunho Kim;Kyungjae Lee;Songhwai Oh;Dohyeong Kim;Yunho Kim;Kyungjae Lee;Songhwai Oh",
        "authorids": "/37088687766;/37089659045;/176686969759170;/37068116900;/37088687766;/37089659045;/176686969759170;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Mechanical Engineering, Robotics and Artificial Intelligence Lab, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Artificial Intelligence, Chung-Ang University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981030/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11917006647873898636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Seoul National University;Korea Advanced Institute of Science and Technology;Chung-Ang University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Mechanical Engineering;Department of Artificial Intelligence",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kaist.ac.kr;http://www.cau.ac.kr",
        "aff_unique_abbr": "SNU;KAIST;CAU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981366",
        "title": "Safety-based Dynamic Task Offloading for Human-Robot Collaboration using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots with constrained hardware resources usually rely on Multi-access Edge Computing infrastructures to offload computationally expensive tasks to meet real-time and safety requirements. Offloading every task might not be the best option due to dynamic changes in the network conditions and can result in network congestion or failures. This work proposes a task offloading strategy for mobile robots in a Human-Robot Collaboration scenario that optimizes the edge resource usage and reduces network delays, leading to safety enhancement. The solution utilizes a Deep Reinforcement Learning (DRL) agent that observes safety and network metrics to dynamically decide at runtime if (i) a less accurate model should run on the robot; (ii) a more complex model should run on the edge; or (iii) the previous output should be reused through temporal coherence verification. Experiments are performed in a simulated warehouse where humans and robots have close interactions and safety needs are high. Our results show that the proposed DRL solution outperforms the baselines in several aspects. The edge is used only when the network performance is reliable, reducing the number of failures (up to 47 %). The latency is not only decreased (up to 68 %) but also adapted to the safety requirements (risk \u00d7 latency reduced up to 48 %), avoiding unnecessary network congestion in safe situations and letting other devices use the network. Overall, the safety metrics get improved, such as the increased time in the safe zone by up to 3.1%.",
        "primary_area": "",
        "author": "Franco Ruggeri;Ahmad Terra;Alberto Hata;Rafia Inam;Iolanda Leite;Franco Ruggeri;Ahmad Terra;Alberto Hata;Rafia Inam;Iolanda Leite",
        "authorids": "/37089658817;/37088415878;/37411423000;/38018310200;/38576988500;/37089658817;/37088415878;/37411423000;/38018310200;/38576988500",
        "aff": "Ericsson Research AI, Stockholm, AB, Sweden; Ericsson Research AI, Stockholm, AB, Sweden; Ericsson Research AI, Ericsson Telecomunica\u00e7\u00f5es S/A, Indaiatuba, Brazil; Ericsson Research AI, Stockholm, AB, Sweden; Division of Robotics, Perception and Learning, Kungliga Tekniska H\u00f6gskolan, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981366/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17583509559926549944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Ericsson Research AI;Ericsson Telecomunica\u00e7\u00f5es S/A;Kungliga Tekniska H\u00f6gskolan",
        "aff_unique_dep": "Research AI;Ericsson Research AI;Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.ericsson.com/research;https://www.ericsson.com;https://www.kth.se",
        "aff_unique_abbr": "Ericsson AI;Ericsson;KTH",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Stockholm;Indaiatuba",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Sweden;Brazil"
    },
    {
        "id": "9981941",
        "title": "Sampling-Based View Planning for MAVs in Active Visual-inertial State Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro aerial vehicles usually have strap-down sensors on the vehicle body, leading to the severe coupling effect between perception and trajectory planning. As a result, visual-inertial simultaneous localization and mapping (VI-SLAM) technologies implemented on MAVs suffer from tracking failure problems, especially in featureless environments. To overcome these challenges, based on MAVs with movable camera mechanisms (e.g., gimbal stabilizer, pan-tilt, or bionic neck-eye system), we proposed two sampling-based algorithms for known and unknown environments respectively. The first active perception planning algorithm based on a scene richness model is developed with a built feature map for the environment. Differ from the first algorithm, the second one is modified for active localization in unknown 3D space. It is basically a time-based sampling-based approach that uses the same scene richness model. In addition, it also achieved a balance between exploitation and exploration. With the above solutions, the robustness of visual perception is improved while avoiding over-exploitation of known information. Simulation and real-world experiments are performed to verify the feasibility of our algorithms.",
        "primary_area": "",
        "author": "Zhengyu Hua;Fengyu Quan;Haoyao Chen;Jiabi Sun;Jianheng Liu;Yunhui Liu;Zhengyu Hua;Fengyu Quan;Haoyao Chen;Jiabi Sun;Jianheng Liu;Yunhui Liu",
        "authorids": "/37089659157;/37086798144;/37600762500;/37086600514;/37089197631;/37279412600;/37089659157;/37086798144;/37600762500;/37086600514;/37089197631;/37279412600",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981941/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7180183209189679246&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HIT;CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981917",
        "title": "SanitizerBot: How Human-in-the-Loop Social Robots Can Playfully Support Humans",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper evaluates a robot that distributed hand-sanitizer over an eight month period (October 2020-June 2021) in public places on the Oregon State University campus. During COVID times, many robots have been deployed in public places as social distancing enforcers, food delivery robots, UV-sanitation robots and more, but few studies have assessed the social situations of these robots. Using the context of robot distributing hand sanitizer, this work explores the benefits that social robots may provide to encouraging healthy human activities, as well as ways in which street-performance inspired approaches and a bit of humor might improve the quality and experience of functional human-robot interactions. After gaining human-in-the-loop deployment experience with a customized interface to enable both planned and improvized responses to human bystanders, we run two sub-studies. In the first, we compare the performance of the robot (moving or still) relative to a traditional hand sanitizer dispenser stick (N=2048\\mathrm{N}=2048, 3 week data collection period). In the second, we evaluate how varied utterance strategies further impact the interaction results (N=185\\mathrm{N}=185, 2 week data collection period). The robot dramatically outperforms the stick dispenser across all tracked behavioral variables, cuing high levels of positive social engagement. This work finds the utterance design is more complex socially, and offer insights to future robot designers about how to integrate helpful and playful speech into service robot interactions. Finally, across both sub-studies, the work shows that people in groups are more likely to engage with the robot and each other, as well as sanitize their hands.",
        "primary_area": "",
        "author": "Yao-Lin Tsai;Parthasarathy Reddy Bana;Sierra Loiselle;Heather Knight;Yao-Lin Tsai;Parthasarathy Reddy Bana;Sierra Loiselle;Heather Knight",
        "authorids": "/37089552438;/37089662152;/37089659846;/37682412600;/37089552438;/37089662152;/37089659846;/37682412600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; Faculty of Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981917/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=853060396422269003&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute (CoRIS)",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981079",
        "title": "Scalable Fiducial Tag Localization on a 3D Prior Map via Graph-Theoretic Global Tag-Map Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an accurate and scalable method for fiducial tag localization on a 3D prior environmental map. The proposed method comprises three steps: 1) visual odometry-based landmark SLAM for estimating the relative poses between fiducial tags, 2) geometrical matching-based global tag-map registration via maximum clique finding, and 3) tag pose refinement based on direct camera-map alignment with normalized information distance. Through simulation-based evaluations, the proposed method achieved a 98 % global tag-map registration success rate and an average tag pose estimation accuracy of a few centimeters. Experimental results in a real environment demonstrated that it enables to localize over 110 fiducial tags placed in an environment in 25 minutes for data recording and post-processing.",
        "primary_area": "",
        "author": "Kenji Koide;Shuji Oishi;Masashi Yokozuka;Atsuhiko Banno;Kenji Koide;Shuji Oishi;Masashi Yokozuka;Atsuhiko Banno",
        "authorids": "/37086179385;/37085895378;/38230409400;/37391486400;/37086179385;/37085895378;/38230409400;/37391486400",
        "aff": "Department of Information Technology and Human Factors, The National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, The National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, The National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, The National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981079/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2758897021301205420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982253",
        "title": "Scalable Model-based Policy Optimization for Decentralized Networked Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning algorithms require a large amount of samples; this often limits their real-world applications on even simple tasks. Such a challenge is more outstanding in multi-agent tasks, as each step of operation is more costly, requiring communications or shifting or resources. This work aims to improve data efficiency of multi-agent control by model-based learning. We consider networked systems where agents are cooperative and communicate only locally with their neighbors, and propose the decentralized model-based policy optimization framework (DMPO). In our method, each agent learns a dynamic model to predict future states and broadcast their predictions by communication, and then the policies are trained under the model rollouts. To alleviate the bias of model-generated data, we restrain the model usage for generating myopic rollouts, thus reducing the compounding error of model generation. To pertain the independence of policy update, we introduce extended value function and theoretically prove that the resulting policy gradient is a close approximation to true policy gradients. We evaluate our algorithm on several benchmarks for intelligent transportation systems, which are connected autonomous vehicle control tasks (Flow and CACC) and adaptive traffic signal control (ATSC). Empirical results show that our method achieves superior data efficiency and matches the performance of model-free methods using true models. The source code of our algorithm and baselines can be found at https://github.com/PKU-MARL/Model-Based-MARL.",
        "primary_area": "",
        "author": "Yali Du;Chengdong Ma;Yuchen Liu;Runji Lin;Hao Dong;Jun Wang;Yaodong Yang;Yali Du;Chengdong Ma;Yuchen Liu;Runji Lin;Hao Dong;Jun Wang;Yaodong Yang",
        "authorids": "/37089527976;/37089662549;/37089195112;/37089662934;/37088968899;/37086377041;/37089659781;/37089527976;/37089662549;/37089195112;/37089662934;/37088968899;/37086377041;/37089659781",
        "aff": "King's College London, London, UK; Xiamen University, Xiamen, China; Peking University, Beijing, China; Chinese Academy of Sciences, Beijing, China; CFCS, School of CS, Peking University; University College London, London, UK; Institute for AI, Peking University & BIGAI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982253/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8110114527734012882&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;2;4;2",
        "aff_unique_norm": "King's College London;Xiamen University;Peking University;Chinese Academy of Sciences;University College London",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.xmu.edu.cn;http://www.pku.edu.cn;https://www.cas.cn;https://www.ucl.ac.uk",
        "aff_unique_abbr": "KCL;XMU;Peking U;CAS;UCL",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "London;Xiamen;Beijing;",
        "aff_country_unique_index": "0;1;1;1;1;0;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9981213",
        "title": "Scalable Online Coverage Path Planning for Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Online coverage path planning to explore an unknown workspace with multiple homogeneous robots could be either centralized or distributed. While distributed planners are computationally faster, centralized planners can produce more efficient paths, reducing the duration of completing a coverage mission significantly. To exploit the power of a centralized framework, we propose a receding horizon centralized online multi-robot planner. In each planning horizon, it generates collision-free paths that guide the robots to visit some obstacle-free locations (aka goals) not visited so far, which in turn help them explore some new regions with their laser rangefinders. We formally prove that, under reasonable conditions, it enables the robots to cover a workspace completely and subsequently analyze its time complexity. We evaluate our planner for ground and aerial robots by performing experiments with up to 128 robots on six 2D grid-based benchmark obstacle maps, establishing scalability. We also perform Gazebo simulations with 10 quadcopters and real experiments with 2 four-wheel ground robots, demonstrating its practical feasibility. Further-more, a comparison with a state-of-the-art distributed planner establishes its superiority in coverage completion time.",
        "primary_area": "",
        "author": "Ratijit Mitra;Indranil Saha;Ratijit Mitra;Indranil Saha",
        "authorids": "/37089658453;/37542496500;/37089658453;/37542496500",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981213/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6122845312240957159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9981867",
        "title": "Scalable Safety-Critical Policy Evaluation with Accelerated Rare Event Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Evaluating rare but high-stakes events is one of the main challenges in obtaining reliable reinforcement learning policies, especially in large or infinite state/action spaces where limited scalability dictates a prohibitively large number of testing iterations. On the other hand, a biased or inaccurate policy evaluation in a safety-critical system could potentially cause unexpected catastrophic failures during deployment. This paper proposes the Accelerated Policy Evaluation (APE) method, which simultaneously uncovers rare events and estimates the rare event probability in Markov decision processes. The APE method treats the environment nature as an adversarial agent and learns towards, through adaptive importance sampling, the zero-variance sampling distribution for the policy evaluation. Moreover, APE is scalable to large discrete or continuous spaces by incorporating function approximators. We investigate the convergence property of APE in the tabular setting. Our empirical studies show that APE can estimate the rare event probability with a smaller bias while only using orders of magnitude fewer samples than baselines in multi-agent and single-agent environments.",
        "primary_area": "",
        "author": "Mengdi Xu;Peide Huang;Fengpei Li;Jiacheng Zhu;Xuewei Qi;Kentaro Oguchi;Zhiyuan Huang;Henry Lam;Ding Zhao;Mengdi Xu;Peide Huang;Fengpei Li;Jiacheng Zhu;Xuewei Qi;Kentaro Oguchi;Zhiyuan Huang;Henry Lam;Ding Zhao",
        "authorids": "/37088505867;/37089580750;/37086611954;/37086544946;/37085388277;/37086487789;/37086011727;/37085669790;/37085680141;/37088505867;/37089580750;/37086611954;/37086544946;/37085388277;/37086487789;/37086011727;/37085669790;/37085680141",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Morgan Stanley Machine Learning Research; Carnegie Mellon University; Toyota Motor North America R&D; Toyota Motor North America R&D; Tongji University; Columbia University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981867/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8473307188899715871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;2;2;3;4;0",
        "aff_unique_norm": "Carnegie Mellon University;Morgan Stanley;Toyota Motor North America;Tongji University;Columbia University",
        "aff_unique_dep": ";Machine Learning Research;R&D;;",
        "aff_unique_url": "https://www.cmu.edu;https://www.morganstanley.com;https://www.toyota.com;https://www.tongji.edu.cn;https://www.columbia.edu",
        "aff_unique_abbr": "CMU;MS;Toyota;Tongji;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981937",
        "title": "Scalable and Modular Ultra-Wideband Aided Inertial Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating accurately in potentially GPS-denied environments is a perquisite of autonomous systems. Relative localization based on ultra-wideband (UWB) is - especially indoors - a promising technology. In this paper, we present a probabilistic filter based Modular Multi-Sensor Fusion (MMSF) approach with the capability of using efficiently all information in a fully meshed UWB ranging network. This allows an accurate mobile agent state estimation and the calibration of the ranging network's spatial constellation. We advocate a new paradigm that includes elements from Collaborative State Estimation (CSE) and allows us considering all stationary UWB anchors and the mobile agent as a decentralized set of estimtors/filters. With this, our method can include all meshed (inter-)sensor observations tightly coupled in a modular estimator. We show that the application of our CSE-inspired method in such a context breaks the computational barrier. Otherwise, it would, for the sakeof complexity-reduction, prohibit the use of all available information or would lead to significant estimator inconsistencies due to coarse approximations. We compare the proposed approach against different MMSF strategies in terms of execution time, accuracy, and filter credibility on both synthetic data and on a dataset from real Unmanned Aerial Vehicles (UAVs).",
        "primary_area": "",
        "author": "Roland Jung;Stephan Weiss;Roland Jung;Stephan Weiss",
        "authorids": "/37087323495;/37535323400;/37087323495;/37535323400",
        "aff": "Department of Smart Systems Technologies, Control of Networked Systems Group, University of Klagenfurt, Austria; Department of Smart Systems Technologies, Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981937/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12220103973552417184&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Department of Smart Systems Technologies",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9981901",
        "title": "Scalable probabilistic gas distribution mapping using Gaussian belief propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper advocates the Gaussian belief propagation solver for factor graphs in the case of gas distribution mapping to support an olfactory sensing robot. The local message passing of belief propagation moves away from the standard Cholesky decomposition technique, which avoids solving the entire factor graph at once and allows for only areas of interest to be updated more effectively. Implementing a local solver means that iterative updates to the distribution map can be achieved orders of magnitude quicker than conventional direct solvers which scale computationally to the size of the map. After defining the belief propagation algorithm for gas mapping, several state of the art message scheduling algorithms are tested in simulation against the standard Cholesky solver for their ability to converge to the exact solution. Testing shows that under the wildfire scheduling method for a large urban scenario, that distribution maps can be iterated at least 10 times faster whilst still maintaining exact solutions. This move to an efficient local framework allows future works to consider 3D mapping, predictive utility and multi-robot distributed mapping.",
        "primary_area": "",
        "author": "Callum Rhodes;Cunjia Liu;Wen-Hua Chen;Callum Rhodes;Cunjia Liu;Wen-Hua Chen",
        "authorids": "/37088687600;/38195632200;/37279192700;/37088687600;/38195632200;/37279192700",
        "aff": "Department of Aeronautical and Automotive Engineering, Loughborough University, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981901/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16075247587643075249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Loughborough University",
        "aff_unique_dep": "Department of Aeronautical and Automotive Engineering",
        "aff_unique_url": "https://www.lboro.ac.uk",
        "aff_unique_abbr": "Loughborough",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981554",
        "title": "Scale Estimation with Dual Quadrics for Monocular Object SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "The scale ambiguity problem is inherently unsolvable to monocular SLAM without the metric baseline between moving cameras. In this paper, we present a novel scale estimation approach based on an object-level SLAM system. To obtain the absolute scale of the reconstructed map, we formulate an optimization problem to make the scaled dimensions of objects conform to the distribution of their sizes in the physical world, without relying on any prior information about gravity direction. The dual quadric is adopted to represent objects for its ability to describe objects compactly and accurately, thus providing reliable dimensions for scale estimation. In the proposed monocular object-level SLAM system, semantic objects are initialized first from fitted 3-D oriented bounding boxes and then further optimized under constraints of 2-D detections and 3-D map points. Experiments on indoor and outdoor public datasets show that our approach outperforms existing methods in terms of accuracy and robustness.",
        "primary_area": "",
        "author": "Shuangfu Song;Junqiao Zhao;Tiantian Feng;Chen Ye;Lu Xiong;Shuangfu Song;Junqiao Zhao;Tiantian Feng;Chen Ye;Lu Xiong",
        "authorids": "/37088839524;/37086158636;/38247262700;/37085492264;/37401835800;/37088839524;/37086158636;/38247262700;/37085492264;/37401835800",
        "aff": "School of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Department of Computer Science and Technology, School of Electronics and Information Engineering, Tongji University, Shanghai, China; School of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Department of Computer Science and Technology, School of Electronics and Information Engineering, Tongji University, Shanghai, China; Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981554/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2073923683928407655&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Surveying and Geo-Informatics",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982173",
        "title": "Scale-aware direct monocular odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a generic framework for scale-aware direct monocular odometry based on depth prediction from a deep neural network. In contrast with previous methods where depth information is only partially exploited, we formulate a novel depth prediction residual which allows us to incorporate multi-view depth information. In addition, we propose to use a truncated robust cost function which prevents considering inconsistent depth estimations. The photometric and depth-prediction measurements are integrated into a tightly-coupled optimization leading to a scale-aware monocular system which does not accumulate scale drift. Our proposal does not particularize for a concrete neural network, being able to work along with the vast majority of the existing depth prediction solutions. We demonstrate the validity and generality of our proposal evaluating it on the KITTI odometry dataset, using two publicly available neural networks and comparing it with similar approaches and the state-of-the-art for monocular and stereo SLAM. Experiments show that our proposal largely outperforms classic monocular SLAM, being 5 to 9 times more precise, beating similar approaches and having an accuracy which is closer to that of stereo systems.",
        "primary_area": "",
        "author": "Carlos Campos;Juan D. Tard\u00f3s;Carlos Campos;Juan D. Tard\u00f3s",
        "authorids": "/38273781200;/37351680900;/38273781200;/37351680900",
        "aff": "Instituto de Investigati\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Spain; Instituto de Investigati\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982173/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8205055730281610612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigati\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9982158",
        "title": "Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Studies in robot teleoperation have been centered around action specifications-from continuous joint control to discrete end-effector pose control. However, these \u201crobot-centric\u201d interfaces often require skilled operators with extensive robotics expertise. To make teleoperation accessible to nonexpert users, we propose the framework \u201cScene Editing as Teleoperation\u201d (SEaT), where the key idea is to transform the traditional \u201crobot-centric\u201d interface into a \u201cscene-centric\u201d interface-instead of controlling the robot, users focus on specifying the task's goal by manipulating digital twins of the real-world objects. As a result, a user can perform teleoperation without any expert knowledge of the robot hardware. To achieve this goal, we utilize a category-agnostic scene-completion algorithm that translates the real-world workspace (with unknown objects) into a manipulable virtual scene representation and an action-snapping algorithm that refines the user input before generating the robot's action plan. To train the algorithms, we procedurely generated a large-scale, diverse kit-assembly dataset that contains object-kit pairs that mimic real-world object-kitting tasks. Our experiments in simulation and on a real-world system demonstrate that our framework improves both the efficiency and success rate for 6DoF kit-assembly tasks. A user study demonstrates that SEaT framework participants achieve a higher task success rate and report a lower subjective workload compared to an alternative robot-centric interface.",
        "primary_area": "",
        "author": "Yulong Li;Shubham Agrawal;Jen-Shuo Liu;Steven K. Feiner;Shuran Song;Yulong Li;Shubham Agrawal;Jen-Shuo Liu;Steven K. Feiner;Shuran Song",
        "authorids": "/37089663664;/37088998130;/37089010960;/37266699900;/37085613509;/37089663664;/37088998130;/37089010960;/37266699900;/37085613509",
        "aff": "Columbia University; Samsung AI Center, NY; Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982158/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11429274869083298918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Columbia University;Samsung",
        "aff_unique_dep": ";AI Center",
        "aff_unique_url": "https://www.columbia.edu;https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Columbia;SAC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982159",
        "title": "Scene-level Tracking and Reconstruction without Object Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first real-time system capable of tracking and reconstructing, individually, every visible object in a given scene, without any form of prior on the rigidness of the objects, texture existence, or object category. In contrast with previous methods such as Co-Fusion and MaskFusion that first segment the scene into individual objects and then process each object independently, the proposed method dynamically segments the non-rigid scene as part of the tracking and reconstruction process. When new measurements indicate topology change, reconstructed models are updated in real-time to reflect that change. Our proposed system can provide the live geometry and deformation of all visible objects in a novel scene in real-time, which makes it possible to be integrated seamlessly into numerous existing robotics applications that rely on object models for grasping and manipulation. The capabilities of the proposed system are demonstrated in challenging scenes that contain multiple rigid and non-rigid objects. Supplementary material, including video, can be found at https://github.com/changhaonan/STAR-no-prior.",
        "primary_area": "",
        "author": "Haonan Chang;Abdeslam Boularias;Haonan Chang;Abdeslam Boularias",
        "authorids": "/37087323802;/37542596800;/37087323802;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982159/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=578439282236695102&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981605",
        "title": "SectionKey: 3-D Semantic Point Cloud Descriptor for Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is seen as a crucial factor to correct cumulative errors in Simultaneous Localization and Mapping (SLAM) applications. Most existing studies focus on visual place recognition, which is inherently sensitive to environmental changes such as illumination, weather and seasons. Considering these facts, more recent attention has been attracted to use 3-D Light Detection and Ranging (LiDAR) scans for place recognition, which demonstrates more credibility by exerting accurate geometric information. Different from pure geometric-based studies, this paper proposes a novel global descriptor, named SectionKey, which leverages both semantic and geometric information to tackle the problem of place recognition in large-scale urban environments. The proposed descriptor is robust and invariant to viewpoint changes. Specifically, the encoded three-layers key serves as a pre-selection step and a \u2018candidate center\u2019 selection strategy is deployed before calculating the similarity score, thus improving the accuracy and efficiency significantly. Then, a two-step semantic iterative closest point (ICP) algorithm is applied to acquire the 3-D pose (x, y, \u03b8) that is used to align the candidate point clouds with the query frame and calculate the similarity score. Extensive experiments have been conducted on public Semantic KITTI dataset to demonstrate the superior performance of our proposed system over state-of-the-art baselines.",
        "primary_area": "",
        "author": "Shutong Jin;Zhenyu Wu;Chunyang Zhao;Jun Zhang;Guohao Peng;Danwei Wang;Shutong Jin;Zhenyu Wu;Chunyang Zhao;Jun Zhang;Guohao Peng;Danwei Wang",
        "authorids": "/37089659071;/37088406849;/37088406475;/37086009222;/37087049757;/37279547600;/37089659071;/37088406849;/37088406475;/37086009222;/37087049757;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981605/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10023793559171206899&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981612",
        "title": "Selecting the Partial State Abstractions of MDPs: A Metareasoning Approach with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Markov decision processes (MDPs) are a common general-purpose model used in robotics for representing sequential decision-making problems. Given the complexity of robotics applications, a popular approach for approximately solving MDPs relies on state aggregation to reduce the size of the state space but at the expense of policy fidelity-offering a trade-off between policy quality and computation time. Naturally, this poses a challenging metareasoning problem: how can an autonomous system dynamically select different state abstractions that optimize this trade-off as it operates online? In this paper, we formalize this metareasoning problem with a notion of time-dependent utility and solve it using deep reinforcement learning. To do this, we develop several general, cheap heuristics that summarize the reward structure and transition topology of the MDP at hand to serve as effective features. Empirically, we demonstrate that our metareasoning approach outperforms several baseline approaches and a strong heuristic approach on a standard benchmark domain.",
        "primary_area": "",
        "author": "Samer B. Nashed;Justin Svegliato;Abhinav Bhatia;Stuart Russell;Shlomo Zilberstein;Samer B. Nashed;Justin Svegliato;Abhinav Bhatia;Stuart Russell;Shlomo Zilberstein",
        "authorids": "/37086198158;/37072711700;/37089659343;/37349960100;/37285091900;/37086198158;/37072711700;/37089659343;/37349960100;/37285091900",
        "aff": "University of Massachusetts, Amherst, MA, USA; University of California, Berkeley, CA, USA; University of Massachusetts, Amherst, MA, USA; University of California, Berkeley, CA, USA; University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981612/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3467143429860373407&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Massachusetts Amherst;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.umass.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UMass Amherst;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Amherst;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981879",
        "title": "Selective Self-Assembly using Re-Programmable Magnetic Pixels",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a method to generate highly selective encodings that can be magnetically \u201cprogrammed\u201d onto physical modules to enable them to self-assemble in chosen configurations. We generate these encodings based on Hadamard matrices, and show how to design the faces of modules to be maximally attractive to their intended mate, while remaining maximally agnostic to other faces. We derive guarantees on these bounds, and verify their attraction and agnosticism experimentally. Using cubic modules whose faces have been covered in soft magnetic material, we show how inexpensive, passive modules with planar faces can be used to selectively self-assemble into target shapes without geometric guides. We show that these modules can be easily re-programmed for new target shapes using a CNC-based magnetic plotter, and demonstrate self-assembly of 8 cubes in a water tank.",
        "primary_area": "",
        "author": "Martin Nisser;Yashaswini Makaram;Faraz Faruqi;Ryo Suzuki;Stefanie Mueller;Martin Nisser;Yashaswini Makaram;Faraz Faruqi;Ryo Suzuki;Stefanie Mueller",
        "authorids": "/37086210728;/37089450450;/37089662338;/37086092004;/37086319276;/37086210728;/37089450450;/37089662338;/37086092004;/37086319276",
        "aff": "MIT CSAIL; MIT CSAIL; MIT CSAIL; University of Calgary; MIT CSAIL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981879/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16237134713142101894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Calgary",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.ucalgary.ca",
        "aff_unique_abbr": "MIT CSAIL;U of C",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9981793",
        "title": "Self Supervised Learning for Multiple Object Tracking in 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiple object tracking in 3D point clouds has applications in mobile robots and autonomous driving. This is a challenging problem due to the sparse nature of the point clouds and the added difficulty of annotation in 3D for supervised learning. To overcome these challenges, we propose a neural network architecture that learns effective object features and their affinities in a self supervised fashion for multiple object tracking in 3D point clouds captured with LiDAR sensors. For self supervision, we use two approaches. First, we generate two augmented LiDAR frames from a single real frame by applying translation, rotation and cutout to the objects. Second, we synthesize a LiDAR frame using CAD models or primitive geometric shapes and then apply the above three augmentations to them. Hence, the ground truth object locations and associations are known in both frames for self supervision. This removes the need to annotate object associations in real data, and additionally the need for training data collection and annotation for object detection in synthetic data. To the best of our knowledge, this is the first self supervised multiple object tracking method for 3D data. Our model achieves state of the art results.",
        "primary_area": "",
        "author": "Aakash Kumar;Jyoti Kini;Ajmal Mian;Mubarak Shah;Aakash Kumar;Jyoti Kini;Ajmal Mian;Mubarak Shah",
        "authorids": "/37089662746;/37086798996;/37283914600;/37275509600;/37089662746;/37086798996;/37283914600;/37275509600",
        "aff": "Center for Research in Computer Vision, University of Central Florida, USA; Center for Research in Computer Vision, University of Central Florida, USA; University of Western Australia; Center for Research in Computer Vision, University of Central Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981793/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5986242808692115667&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Central Florida;University of Western Australia",
        "aff_unique_dep": "Center for Research in Computer Vision;",
        "aff_unique_url": "https://www.ucf.edu;https://www.uwa.edu.au",
        "aff_unique_abbr": "UCF;UWA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Central Florida;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9981175",
        "title": "Self-Propelled Soft Everting Toroidal Robot for Navigation and Climbing in Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "There are many spaces inaccessible to humans where robots could help deliver sensors and equipment. Many of these spaces contain three-dimensional passageways and uneven terrain that pose challenges for robot design and control. Everting toroidal robots, which move via simultaneous eversion and inversion of their body material, are promising for navigation in these types of spaces. We present a novel soft everting toroidal robot that propels itself using a motorized device inside an air-filled membrane. Our robot requires only a single control signal to move, can conform to its environment, and can climb vertically with a motor torque that is independent of the force used to brace the robot against its environment. We derive and validate models of the forces involved in its motion, and we demonstrate the robot's ability to navigate a maze and climb a pipe.",
        "primary_area": "",
        "author": "Nelson G. Badillo Perez;Margaret M. Coad;Nelson G. Badillo Perez;Margaret M. Coad",
        "authorids": "/37089658466;/37086124465;/37089658466;/37086124465",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981175/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17526011484717114157&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981390",
        "title": "Self-Supervised Feature Learning from Partial Point Clouds via Pose Disentanglement",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised learning on point clouds has gained a lot of attention recently, since it addresses the label-efficiency and domain-gap problems on point cloud tasks. In this paper, we propose a novel self-supervised framework to learn informative features from partial point clouds. We leverage partial point clouds scanned by LiDAR that contain both content and pose attributes, and we show that disentangling such two factors from partial point clouds enhances feature learning. To this end, our framework consists of three main parts: 1) a completion network to capture holistic semantics of point clouds; 2) a pose regression network to understand the viewing angle where partial data is scanned from; 3) a partial reconstruction network to encourage the model to learn content and pose features. To demonstrate the robustness of the learnt feature representations, we conduct several downstream tasks including classification, part segmentation, and registration, with comparisons against state-of-the-art methods. Our method not only outperforms existing self-supervised methods, but also shows a better generalizability across synthetic and real-world datasets.",
        "primary_area": "",
        "author": "Meng-Shiun Tsai;Pei-Ze Chiang;Yi-Hsuan Tsai;Wei-Chen Chiu;Meng-Shiun Tsai;Pei-Ze Chiang;Yi-Hsuan Tsai;Wei-Chen Chiu",
        "authorids": "/37089302636;/37089300692;/37085759166;/37086286145;/37089302636;/37089300692;/37085759166;/37086286145",
        "aff": "Department of Computer Science, National Chiao Tung University; Department of Computer Science, National Chiao Tung University; Phiar Technologies; Department of Computer Science, National Chiao Tung University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981390/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7630808888568281840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Chiao Tung University;Phiar Technologies",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.nctu.edu.tw;",
        "aff_unique_abbr": "NCTU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981099",
        "title": "Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain adaptation is an important property in robot vision, which enables the neural networks pre-trained on source domains to adapt target domains automatically without any annotation efforts. During this process, source data is not always accessible due to the constraints of expensive storage overhead and data privacy protection. Therefore, the source domain pre-trained model is expected to optimize with only unlabeled target data, termed as source-free unsupervised domain adaptation. In this paper, we view this problem as a special case of noisy label learning, since the given pre-trained model can generate noisy labels for unlabeled target data via network inference. The potential semantic cues for unsupervised domain adaptation exactly lie on these noisy labels. Inspired by this problem modeling, we propose a simple yet effective Self-Supervised Noisy Label Learning method, which injects self-supervised learning to impose the intrinsic data structure and facilitate label-denoising. Extensive experiments have been conducted on diverse benchmarks to validate the effectiveness. Our method achieves state-of-the-art performance.",
        "primary_area": "",
        "author": "Weijie Chen;Luojun Lin;Shicai Yang;Di Xie;Shiliang Pu;Yueting Zhuang;Weijie Chen;Luojun Lin;Shicai Yang;Di Xie;Shiliang Pu;Yueting Zhuang",
        "authorids": "/37087230653;/37086342224;/37089320178;/37086055192;/37085657816;/37275441700;/37087230653;/37086342224;/37089320178;/37086055192;/37085657816;/37275441700",
        "aff": "Hikvision Research Institute, Hangzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China; Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981099/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9226043255157191357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;2",
        "aff_unique_norm": "Hikvision Research Institute;Fuzhou University;Zhejiang University",
        "aff_unique_dep": ";College of Computer and Data Science;College of Computer Science and Technology",
        "aff_unique_url": "https://www.hikvision.com/cn/;https://www.fzu.edu.cn;http://www.zju.edu.cn",
        "aff_unique_abbr": "HRI;FZU;ZJU",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Hangzhou;Fuzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981368",
        "title": "Self-Supervised Traversability Prediction by Learning to Reconstruct Safe Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating off-road with a fast autonomous vehicle depends on a robust perception system that differentiates traversable from non-traversable terrain. Typically, this depends on a semantic understanding which is based on supervised learning from images annotated by a human expert. This requires a significant investment in human time, assumes correct expert classification, and small details can lead to misclassification. To address these challenges, we propose a method for predicting high- and low-risk terrains from only past vehicle experience in a self-supervised fashion. First, we develop a tool that projects the vehicle trajectory into the front camera image. Second, occlusions in the 3D representation of the terrain are filtered out. Third, an autoencoder trained on masked vehicle trajectory regions identifies low- and high-risk terrains based on the reconstruction error. We evaluated our approach with two models and different bottleneck sizes with two different training and testing sites with a four-wheeled off-road vehicle. Comparison with two independent test sets of semantic labels from similar terrain as training sites demonstrates the ability to separate the ground as low-risk and the vegetation as high-risk with 81.1% and 85.1% accuracy.",
        "primary_area": "",
        "author": "Robin Schmid;Deegan Atha;Frederik Sch\u00f6ller;Sharmita Dey;Seyed Fakoorian;Kyohei Otsu;Barry Ridge;Marko Bjelonic;Lorenz Wellhausen;Marco Hutter;Ali-akbar Agha-mohammadi;Robin Schmid;Deegan Atha;Frederik Sch\u00f6ller;Sharmita Dey;Seyed Fakoorian;Kyohei Otsu;Barry Ridge;Marko Bjelonic;Lorenz Wellhausen;Marco Hutter;Ali-akbar Agha-mohammadi",
        "authorids": "/37089663404;/37088951939;/37089213113;/37086921349;/37085784984;/37085558541;/37546416900;/37085993346;/37086200470;/37545251000;/38274170800;/37089663404;/37088951939;/37089213113;/37086921349;/37085784984;/37085558541;/37546416900;/37085993346;/37086200470;/37545251000;/38274170800",
        "aff": "Swiss Federal Institute of Technology (ETH Z\u00fcrich), Robotic Systems Lab, Switzerland; Jet Propulsion Laboratory (JPL), California Institute of Technology (Caltech), Pasadena, CA, United States of America; Department of Electrical Engineering and Photonics, Technical University of Denmark, Denmark; Department of Computer Science, University of Goettingen, Germany; Jet Propulsion Laboratory (JPL), California Institute of Technology (Caltech), Pasadena, CA, United States of America; Jet Propulsion Laboratory (JPL), California Institute of Technology (Caltech), Pasadena, CA, United States of America; Jet Propulsion Laboratory (JPL), California Institute of Technology (Caltech), Pasadena, CA, United States of America; Swiss Federal Institute of Technology (ETH Z\u00fcrich), Robotic Systems Lab, Switzerland; Swiss Federal Institute of Technology (ETH Z\u00fcrich), Robotic Systems Lab, Switzerland; Swiss Federal Institute of Technology (ETH Z\u00fcrich), Robotic Systems Lab, Switzerland; Jet Propulsion Laboratory (JPL), California Institute of Technology (Caltech), Pasadena, CA, United States of America",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981368/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9661897623072253284&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;2;3;1;1;1;0;0;0;1",
        "aff_unique_norm": "ETH Zurich;California Institute of Technology;Technical University of Denmark;University of Goettingen",
        "aff_unique_dep": "Robotic Systems Lab;Jet Propulsion Laboratory;Department of Electrical Engineering and Photonics;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.caltech.edu;https://www.tek.dk;https://www.uni-goettingen.de",
        "aff_unique_abbr": "ETH Z\u00fcrich;Caltech;DTU;Uni G\u00f6ttingen",
        "aff_campus_unique_index": "0;1;1;1;1;0;0;0;1",
        "aff_campus_unique": "Z\u00fcrich;Pasadena;",
        "aff_country_unique_index": "0;1;2;3;1;1;1;0;0;0;1",
        "aff_country_unique": "Switzerland;United States;Denmark;Germany"
    },
    {
        "id": "9981267",
        "title": "Self-morphing Soft Parallel-and-coplanar Electroadhesive Grippers Based on Laser-scribed Graphene Oxide Electrodes",
        "track": "main",
        "status": "Poster",
        "abstract": "Electroadhesion is a versatile and controllable adhesion mechanism that has been used extensively in robotics. Soft electroadhesion embodies electrostatic adhesion in soft materials and is required for shape-adaptive and safe grasping of curved objects and delicate materials. In this work, we present a soft electroadhesive fabrication method based on laser scribing graphene oxide on a silicone film, which is cost-effective, facile and green. The method can be used to generate complex electroadhesive patterns without molds or stencils. We then present a 2D finite element model to demonstrate the shape-changing behavior and electric field distributions of a dual-mode parallel dielectric elastomer actuation and coplanar electroadhesion structure. The soft electroadhesive fabrication method based on laser-scribed graphene oxide electrodes and its experimental characterization results, together with its shape-morphing simulation model are expected to enable the wider adoption of soft electroadhesion in future robotics.",
        "primary_area": "",
        "author": "Jianglong Guo;Djen Kuhnel;Qiukai Qi;Chaoqun Xiang;Van Anh Ho;Charl Faul;Jonathan Rossiter;Jianglong Guo;Djen Kuhnel;Qiukai Qi;Chaoqun Xiang;Van Anh Ho;Charl Faul;Jonathan Rossiter",
        "authorids": "/37086384672;/37089662832;/37086695987;/37086356104;/37529964700;/37089662692;/37271190700;/37086384672;/37089662832;/37086695987;/37086356104;/37529964700;/37089662692;/37271190700",
        "aff": "School of Science, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Soft Transducers Laboratory (LMTS), Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Neuch\u00e2tel, Switzerland; SoftLab, Bristol Robotics Laboratory, University of Bristol, Bristol, UK; SoftLab, Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Soft Haptics Laboratory, Japan Advanced Institute of Science and Technology, Nomi, Japan; School of Chemistry, University of Bristol, Bristol, UK; SoftLab, Bristol Robotics Laboratory, University of Bristol, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981267/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:93srmvJvktYJ:scholar.google.com/&scioq=Self-morphing+Soft+Parallel-and-coplanar+Electroadhesive+Grippers+Based+on+Laser-scribed+Graphene+Oxide+Electrodes&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;3;2;2",
        "aff_unique_norm": "Harbin Institute of Technology;EPFL;University of Bristol;Japan Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Science;Soft Transducers Laboratory (LMTS);Bristol Robotics Laboratory;Soft Haptics Laboratory",
        "aff_unique_url": "http://en.hhit.edu.cn/;https://www.epfl.ch;https://www.bristol.ac.uk;https://www.jaist.ac.jp",
        "aff_unique_abbr": "HIT;EPFL;UoB;JAIST",
        "aff_campus_unique_index": "0;1;2;2;3;2;2",
        "aff_campus_unique": "Shenzhen;Neuch\u00e2tel;Bristol;Nomi",
        "aff_country_unique_index": "0;1;2;2;3;2;2",
        "aff_country_unique": "China;Switzerland;United Kingdom;Japan"
    },
    {
        "id": "9981907",
        "title": "Self-supervised Wide Baseline Visual Servoing via 3D Equivariance",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the challenging input settings for visual servoing is when the initial and goal camera views are far apart. Such settings are difficult because the wide baseline can cause drastic changes in object appearance and cause occlusions. This paper presents a novel self-supervised visual servoing method for wide baseline images which does not require 3D ground truth supervision. Existing approaches that regress absolute camera pose with respect to an object require 3D ground truth data of the object in the forms of 3D bounding boxes or meshes. We learn a coherent visual representation by leveraging a geometric property called 3D equivariance\u2014the representation is transformed in a predictable way as a function of 3D transformation. To ensure that the feature-space is faithful to the underlying geodesic space, a geodesic preserving constraint is applied in conjunction with the equivariance. We design a Siamese network that can effectively enforce these two geometric properties without requiring 3D supervision. With the learned model, the relative transformation can be inferred simply by following the gradient in the learned space and used as feedback for closed-loop visual servoing. Our method is evaluated on objects from the YCB dataset, showing meaningful outperformance on a visual servoing task, or object alignment task with respect to state-of-the-art approaches that use 3D supervision. Ours yields more than 35% average distance error reduction and more than 90% success rate with 3cm error tolerance.",
        "primary_area": "",
        "author": "Jinwook Huh;Jungseok Hong;Suveer Garg;Hyun Soo Park;Volkan Isler;Jinwook Huh;Jungseok Hong;Suveer Garg;Hyun Soo Park;Volkan Isler",
        "authorids": "/37085775953;/37088505608;/37088809621;/37086214937;/37298487800;/37085775953;/37088505608;/37088809621;/37086214937;/37298487800",
        "aff": "Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981907/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10182059130266720682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981517",
        "title": "Semantic Scene Completion through Multi-Level Feature Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Partial observation of indoor scenes (single-viewed RGB-D) carries insufficient spatial information for complex tasks such as autonomous navigation and virtual reality, thus many learning-based methods are proposed to realize semantic scene completion (SSC) from single-viewed input. However, most of them only extract scene-level features of input to generate output, which might lose details. In this paper, a new method that fully utilizes both instance-level and scene-level features is proposed. Firstly, an object detection module is pre-trained to localize indoor objects. Secondly, coarse completion result is obtained from scene-level feature using an encoder-decoder structure. Finally, based on the pre-trained bounding boxes, coarse completion result is refined using a geometric refinement module. Our network's performance is evaluated on both real and synthetic datasets. The results demonstrate that our network is able to reconstruct indoor scenes with more geometric details, get clearer boundaries between instances and outperform most existing SSC methods both intuitively and quantitatively.",
        "primary_area": "",
        "author": "Ruochong Fu;Hang Wu;Mengxiang Hao;Yubin Miao;Ruochong Fu;Hang Wu;Mengxiang Hao;Yubin Miao",
        "authorids": "/37089661114;/37088856069;/37089661761;/37086136079;/37089661114;/37088856069;/37089661761;/37086136079",
        "aff": "School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981517/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7556272395700559740&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981965",
        "title": "Semantic Topological Descriptor for Loop Closure Detection within 3D Point Clouds In Outdoor Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection has the potential to correct the drift of trajectories and build a global consistent map in LiDAR SLAM, however it remains a challenging problem in outdoor environment due to the sparsity of 3D point clouds data, large-scale scenes and moving objects. Inspired by the way humans perceive the environment through recognizing objects and identifying their relations, this paper presents a novel descriptor that contains semantic and topological information for loop closure detection. Unlike most existing methods that extract features from the raw point clouds or use all semantic objects, we directly discard point clouds representing pedestrians and vehicles after semantic segmentation. Then, we propose a semantic topological graph representation from the remaining point clouds and convert this graph into a descriptor. Additionally, we propose a two-stage algorithm for matching descriptors to efficiently determine the loop. Our method has been extensively evaluated using the KITTI dataset and outperforms state-of-the-art methods, especially in the challenging situations such as viewpoint changes and dynamic scenes.",
        "primary_area": "",
        "author": "Ming Liao;Yunzhou Zhang;Jinpeng Zhang;Liang Liang;Sonya Coleman;Dermot Kerr;Ming Liao;Yunzhou Zhang;Jinpeng Zhang;Liang Liang;Sonya Coleman;Dermot Kerr",
        "authorids": "/37089661475;/37310459100;/37089734487;/37089662255;/37269140600;/37295244700;/37089661475;/37310459100;/37089734487;/37089662255;/37269140600;/37295244700",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; SIASUN Robot & Automation CO., Ltd., China; School of Computing, Engineering and Intelligent Systems, Ulster University, N. Ireland, UK; School of Computing, Engineering and Intelligent Systems, Ulster University, N. Ireland, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981965/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17846710810640132721&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;2",
        "aff_unique_norm": "Northeastern University;SIASUN Robot & Automation CO., Ltd.;Ulster University",
        "aff_unique_dep": "College of Information Science and Engineering;;School of Computing, Engineering and Intelligent Systems",
        "aff_unique_url": "http://www.neu.edu.cn/;;https://www.ulster.ac.uk",
        "aff_unique_abbr": "NEU;;Ulster",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenyang;",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9982215",
        "title": "Semi-Automatic Infrared Calibration for Augmented Reality Systems in Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Augmented reality (AR) has the potential to improve the immersion and efficiency of computer-assisted orthopaedic surgery (CAOS) by allowing surgeons to maintain focus on the operating site rather than external displays in the operating theatre. Successful deployment of AR to CAOS requires a calibration that can accurately calculate the spatial relationship between real and holographic objects. Several studies attempt this calibration through manual alignment or with additional fiducial markers in the surgical scene. We propose a calibration system that offers a direct method for the calibration of AR head-mounted displays (HMDs) with CAOS systems, by using infrared-reflective marker-arrays widely used in CAOS. In our fast, user-agnostic setup, a HoloLens 2 detected the pose of marker arrays using infrared response and time-of-flight depth obtained through sensors onboard the HMD. Registration with a commercially available CAOS system was achieved when an IR marker-array was visible to both devices. Study tests found relative-tracking mean errors of 2.03 mm and 1.12\u00b0 when calculating the relative pose between two static marker-arrays at short ranges. When using the calibration result to provide in-situ holographic guidance for a simulated wire- insertion task, a pre-clinical test reported mean errors of 2.07 mm and 1.54\u00b0 when compared to a pre-planned trajectory.",
        "primary_area": "",
        "author": "Hisham Iqbal;Ferdinando Rodriguez y Baena;Hisham Iqbal;Ferdinando Rodriguez y Baena",
        "authorids": "/37089663733;/37085615495;/37089663733;/37085615495",
        "aff": "Dept. of Mechanical Engineering, Mechatronics in Medicine Laboratory, Imperial College, London; Dept. of Mechanical Engineering, Mechatronics in Medicine Laboratory, Imperial College, London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982215/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=399901222476553178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982165",
        "title": "Semi-Supervised Disentanglement of Tactile Contact Geometry from Sliding-Induced Shear",
        "track": "main",
        "status": "Poster",
        "abstract": "The sense of touch is fundamental to human dexterity. When mimicked in robotic touch, particularly by use of soft optical tactile sensors, it suffers from distortion due to motion-dependent shear. This complicates tactile tasks like shape reconstruction and exploration that require information about contact geometry. In this work, we pursue a semi-supervised approach to remove shear while preserving contact-only information. We validate our approach by showing a match between the model-generated unsheared images with their counterparts from vertically tapping onto the object. The model-generated unsheared images give faithful reconstruction of contact-geometry otherwise masked by shear, along with robust estimation of object pose then used for sliding exploration and full reconstruction of several planar shapes. We show that our semi-supervised approach achieves comparable performance to its fully supervised counterpart across all validation tasks with an order of magnitude less supervision. The semi-supervised method is thus more computational and labeled sample-efficient. We expect it will have broad applicability to wide range of complex tactile exploration and manipulation tasks performed via a shear-sensitive sense of touch.",
        "primary_area": "",
        "author": "Anupam K. Gupta;Alex Church;Nathan F. Lepora;Anupam K. Gupta;Alex Church;Nathan F. Lepora",
        "authorids": "/37086799220;/37086700597;/37399610200;/37086799220;/37086700597;/37399610200",
        "aff": "Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, UK; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, UK; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982165/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6802825627388692262&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Engineering Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982209",
        "title": "Sensor Observability Index: Evaluating Sensor Alignment for Task-Space Observability in Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a preliminary definition and analysis of the novel concept of sensor observability index. The goal is to analyse and evaluate the performance of distributed directional or axial-based sensors to observe specific axes in task space as a function of joint configuration in serial robot manipulators. For example, joint torque sensors are often used in serial robot manipulators and assumed to be perfectly capable of estimating end effector forces, but certain joint configurations may cause one or more task-space axes to be unobservable as a result of how the joint torque sensors are aligned. The proposed sensor observability provides a method to analyse the quality of the current robot configuration to observe the task space. Parallels are drawn between sensor observability and the traditional kinematic Jacobian for the particular case of joint torque sensors in serial robot manipulators. Although similar information can be retrieved from kinematic analysis of the Jacobian transpose in serial manipulators, sensor observability is shown to be more generalizable in terms of analysing non-joint-mounted sensors and other sensor types. In addition, null-space analysis of the Jacobian transpose is susceptible to false observability singularities. Simulations and experiments using the robot Baxter demonstrate the importance of maintaining proper sensor observability in physical interactions.",
        "primary_area": "",
        "author": "Christopher Yee Wong;Wael Suleiman;Christopher Yee Wong;Wael Suleiman",
        "authorids": "/37085749678;/37400542000;/37085749678;/37400542000",
        "aff": "Universit\u00e9 de Sherbooke, Sherbrooke, Canada; Universit\u00e9 de Sherbooke, Sherbrooke, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982209/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15515742511019464019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 de Sherbooke",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usherbrooke.ca",
        "aff_unique_abbr": "UdeS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sherbrooke",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981608",
        "title": "Sensor-Based Reconstruction of Slender Flexible Beams Undergoing Large-scale Deflection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a model-based approach to reconstructing the large deformations of slender flexible beams through strain-gauge deflection sensors. Using the principal axes decomposition of structural compliance, a closed-form kinetostatics model can be obtained to characterize the non-linear force-deformation behavior of the flexible beams under-going large-scale deflection. Owing to analytical derivation of the system Jacobian, the efficient Newton-Raphson method is employed to determine the equilibrium configuration of the flexible beams, as well as the corresponding reaction force. To verify the correctness and effectiveness of the proposed method, an experimental apparatus is built up, on which a variety of experiments are conducted. The results show that for a 300 mm long beam, the tip position can be predicted with an accuracy of 1.27 mm, 4.42 mm, and 1.17\u00b0, respectively, for the x, y directions and rotation. Accordingly, the estimation errors for the planar forces and torque are 0.075 N (3.33%), 0.155 N (14.23%), and 0.027 Nm (26.84%), respectively.",
        "primary_area": "",
        "author": "Junjie Luo;Yuanhao Xun;Jiaji Yao;Genliang Chen;Hao Wang;Junjie Luo;Yuanhao Xun;Jiaji Yao;Genliang Chen;Hao Wang",
        "authorids": "/37088911030;/37089660771;/37089661304;/37085416387;/37085421631;/37088911030;/37089660771;/37089661304;/37085416387;/37085421631",
        "aff": "State Key Laboratory of Mechanical System and Vibration, Meta Robotics Institute, Shanghai Jiao Tong University, Shanghai, P. R. China; State Key Laboratory of Mechanical System and Vibration and the Shanghai Key Laboratory of Digital Manufacture for Thin-Walled Structures, Shanghai Jiao Tong University, Shanghai, P. R. China; UM-SJTU Joint Institute, Shanghai Jiao Tong University, Shanghai, P. R. China; State Key Laboratory of Mechanical System and Vibration, Meta Robotics Institute, Shanghai Jiao Tong University, Shanghai, P. R. China; State Key Laboratory of Mechanical System and Vibration and the Shanghai Key Laboratory of Digital Manufacture for Thin-Walled Structures, Shanghai Jiao Tong University, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981608/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17021603651997520248&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "State Key Laboratory of Mechanical System and Vibration",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982236",
        "title": "Sequence-of-Constraints MPC: Reactive Timing-Optimal Control of Sequential Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Task and Motion Planning has made great progress in solving hard sequential manipulation problems. However, a gap between such planning formulations and control methods for reactive execution remains. In this paper we pro-pose a model predictive control approach dedicated to robustly execute a single sequence of constraints, which corresponds to a discrete decision sequence of a TAMP plan. We decompose the overall control problem into three sub-problems (solving for sequential waypoints, their timing, and a short receding horizon path) that each is a non-linear program solved online in each MPC cycle. The resulting control strategy can account for long-term interdependencies of constraints and reactively plan for a timing-optimal transition through all constraints. We additionally propose phase backtracking when running constraints of the current phase cannot be fulfilled, leading to a fluent re-initiation behavior that is robust to perturbations and interferences by an experimenter.",
        "primary_area": "",
        "author": "Marc Toussaint;Jason Harris;Jung-Su Ha;Danny Driess;Wolfgang H\u00f6nig;Marc Toussaint;Jason Harris;Jung-Su Ha;Danny Driess;Wolfgang H\u00f6nig",
        "authorids": "/37528418600;/37089662131;/38543013300;/37085994159;/37543456200;/37528418600;/37089662131;/38543013300;/37085994159;/37543456200",
        "aff": "Science of Intelligence Excellence Cluster, TU Berlin; Learning & Intelligent Systems Lab, TU Berlin; Learning & Intelligent Systems Lab, TU Berlin; Science of Intelligence Excellence Cluster, TU Berlin; Learning & Intelligent Systems Lab, TU Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982236/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11258137034601688427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Science of Intelligence Excellence Cluster",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981735",
        "title": "Sequential Manipulation Planning on Scene Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "We devise a 3D scene graph representation, contact graph+ (cg+), for efficient sequential manipulation planning. Augmented with predicate-like attributes, this contact graph-based representation abstracts scene layouts with succinct geometric information and valid robot-scene interactions. Goal configurations, naturally specified on contact graphs, can be produced by a genetic algorithm with a stochastic optimization method. A task plan is then initialized by computing the Graph Editing Distance (GED) between the initial contact graph and the goal configuration, which generates graph edit operations corresponding to possible robot actions. We finalize the task plan by imposing constraints to regulate the temporal feasibility of graph edit operations, ensuring valid task and motion correspondences. In a series of simulated and real experiments, robots successfully complete complex sequential object rearrangement tasks that are difficult to specify using conventional planning language like Planning Domain Definition Language (PDDL), demonstrating high potential of planning sequential manipulation tasks on cg+.",
        "primary_area": "",
        "author": "Ziyuan Jiao;Yida Niu;Zeyu Zhang;Song-Chun Zhu;Yixin Zhu;Hangxin Liu;Ziyuan Jiao;Yida Niu;Zeyu Zhang;Song-Chun Zhu;Yixin Zhu;Hangxin Liu",
        "authorids": "/37085784268;/37089661698;/37086938580;/37281407500;/37086172463;/37086274715;/37085784268;/37089661698;/37086938580;/37281407500;/37086172463;/37086274715",
        "aff": "Institute for Artificial Intelligence, Peking University; Beijing Institute for General Artificial Intelligence (BIGAI); Beijing Institute for General Artificial Intelligence (BIGAI); Department of Automation, Tsinghua University; School of Artificial Intelligence, Peking University; Beijing Institute for General Artificial Intelligence (BIGAI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981735/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15835355995111146173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;1",
        "aff_unique_norm": "Peking University;Beijing Institute for General Artificial Intelligence;Tsinghua University",
        "aff_unique_dep": "Institute for Artificial Intelligence;;Department of Automation",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.bigmodel.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "PKU;BIGAI;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982115",
        "title": "Sequential thermal image-based adult and baby detection robust to thermal residual heat marks",
        "track": "main",
        "status": "Poster",
        "abstract": "The awareness for preserving privacy in in-home monitoring robots is increasing. Although several studies have proposed privacy-preserved in-home monitoring robot systems for adults, only a limited amount of attention has been paid attention to research on privacy-preserved in-home monitoring of babies. Like previous studies, thermal infrared image-based methods could ensure a privacy-preserved monitoring of babies, yet when existing detection methods were applied to thermal images to detect babies and adults, we discovered a frequent occurrence of misdetection due to the presence of thermal residual heat marks. In this research, we propose a sequential thermal image-based detection that conjugated the characteristics of thermal residual heat marks. The proposed detection reduced misdetection caused by thermal residual heat marks by 98.7% when compared to RetinaNet. In addition, we open-source our collected thermal image-based baby and adult dataset via: https://github.com/donkeymouse/ThermalAdultandBaby.",
        "primary_area": "",
        "author": "Dong-Guw Lee;Kyu-Seob Song;Young-Hoon Nho;Ayoung Kim;Dong-Soo Kwon;Dong-Guw Lee;Kyu-Seob Song;Young-Hoon Nho;Ayoung Kim;Dong-Soo Kwon",
        "authorids": "/37089256320;/37086071536;/37085387267;/37403315600;/37278487100;/37089256320;/37086071536;/37085387267;/37403315600;/37278487100",
        "aff": "Department of Mechanical Engineering, Seoul National University, Seoul, Republic of Korea; Robotics Program, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Neurosurgery, University of Pennsylvania, Philadelphia, PA, USA; Department of Mechanical Engineering, SNU, Seoul, Republic of Korea; CEO of EasyEndo Surgical Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982115/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8470852365081892653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "Seoul National University;Korea Advanced Institute of Science and Technology;University of Pennsylvania;EasyEndo Surgical Inc",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Program;Department of Neurosurgery;",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kaist.ac.kr;https://www.upenn.edu;",
        "aff_unique_abbr": "SNU;KAIST;UPenn;",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Seoul;Daejeon;Philadelphia;",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9981439",
        "title": "Service Robots in a Bakery Shop: A Field Study",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we report on a field study in which we employed two service robots in a bakery store as a sales promotion. Previous studies have explored public applications of service robots public such as shopping malls. However, more evidence is needed that service robots can contribute to sales in real stores. Moreover, the behaviors of customers and service robots in the context of sales promotions have not been examined well. Hence, the types of robot behavior that can be considered effective and the customers' responses to these robots remain unclear. To address these issues, we installed two tele-operated service robots in a bakery store for nearly 2 weeks, one at the entrance as a greeter and the other one inside the store to recommend products. The results show a dramatic increase in sales during the days when the robots were applied. Furthermore, we annotated the video recordings of both the robots' and customers' behavior. We found that although the robot placed at the entrance successfully attracted the interest of the passersby, no apparent increase in the number of customers visiting the store was observed. However, we confirmed that the recommendations of the robot operating inside the store did have a positive impact. We discuss our findings in detail and provide both theoretical and practical recommendations for future research and applications.",
        "primary_area": "",
        "author": "Sichao Song;Baba Jun;Junya Nakanishi;Yuichiro Yoshikawa;Hiroshi Ishiguro;Sichao Song;Baba Jun;Junya Nakanishi;Yuichiro Yoshikawa;Hiroshi Ishiguro",
        "authorids": "/37086301679;/37089660559;/37085769525;/37286859300;/37274136400;/37086301679;/37089660559;/37085769525;/37286859300;/37274136400",
        "aff": "CyberAgent Inc., Tokyo, Japan; CyberAgent Inc., Tokyo, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981439/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3249781037405083202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "CyberAgent Inc.;Osaka University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cyberagent.co.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": ";Osaka U",
        "aff_campus_unique_index": "0;0;1;1;1",
        "aff_campus_unique": "Tokyo;Osaka",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981358",
        "title": "Set-point Control for a Ground-based Reconfigurable Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Reconfigurable mobile robots are well suited for inspection tasks in legacy nuclear facilities where access is restricted and the environment is often cluttered. A reconfig-urable snake robot, MIRRAX, has previously been developed to investigate such facilities. The joints used for the robot's reconfiguration introduce additional constraints on the robot's control, such as balance, on top of the existing actuator and collision constraints. This paper presents a set-point controller for MIRRAX using vector-field inequalities to enforce hard constraints on the robot's balance, actuator limits, and collision avoidance in a single quadratic programming formulation. The controller has been evaluated in simulation and early experiments in some scenarios. The results show that the controller generates feasible control inputs that enable the robot to retain its balance while moving with less oscillation and operating within the actuation and collision constraints.",
        "primary_area": "",
        "author": "Wei Cheah;Bruno Vilhena Adorno;Simon Watson;Barry Lennox;Wei Cheah;Bruno Vilhena Adorno;Simon Watson;Barry Lennox",
        "authorids": "/37086576110;/37586973200;/38185385000;/37299751200;/37086576110;/37586973200;/38185385000;/37299751200",
        "aff": "Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981358/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9816988634065494931&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981097",
        "title": "Sex Parity in Cognitive Fatigue Model Development for Effective Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, robots have become vital to achieving manufacturing competitiveness. Especially in industrial environments, a strong level of interaction is reached when humans and robots form a dynamic system that works together towards achieving a common goal or accomplishing a task. However, the human-robot collaboration can be cognitively demanding, potentially contributing to cognitive fatigue. Therefore, the consideration of cognitive fatigue becomes particularly important to ensure the efficiency and safety in the overall human-robot collaboration. Additionally, sex is an inevitable human factor that needs further investigation for machine learning model development given the perceptual and physiological differences between the sexes in responding to fatigue. As such, this study explored sex differences and labeling strategies in the development of machine learning models for cognitive fatigue detection. Sixteen participants, balanced by sex, recruited to perform a surface finishing task with a UR10 collaborative robot under fatigued and non-fatigued states. Fatigue perception and heart rate activity data collected throughout to create a dataset for cognitive fatigue detection. Equitable machine learning models developed based on perception (survey responses) and condition (fatigue manipulation). The labeling approach had a significant impact on the accuracy and F1-score, where perception-based labels lead to lower accuracy and F1-score for females likely due to sex differences in reporting of fatigue. Additionally, we observed a relationship between heart rate, algorithm type, and labeling approach, where heart rate was the most significant predictor for the two labeling approaches and for all the algorithms utilized. Understanding the implications of label type, algorithm type, and sex on the design of fatigue detection algorithms is essential to designing equitable fatigue-adaptive human-robot collaborations across the sexes. Show More",
        "primary_area": "",
        "author": "Apostolos Kalatzis;Sarah Hopko;Ranjana K. Mehta;Laura Stanley;Mike P. Wittie;Apostolos Kalatzis;Sarah Hopko;Ranjana K. Mehta;Laura Stanley;Mike P. Wittie",
        "authorids": "/37087225681;/37088810823;/37086925023;/37087137972;/37945801800;/37087225681;/37088810823;/37086925023;/37087137972;/37945801800",
        "aff": "School of Computing, Montana State University, Bozeman, MT, USA; Department of Industrial and System Engineering, Texas AM University, College Station, TX, USA; Department of Industrial and System Engineering, Texas AM University, College Station, TX, USA; School of Computing, Montana State University, Bozeman, MT, USA; School of Computing, Montana State University, Bozeman, MT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981097/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=900197593462819383&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Montana State University;Texas A&M University",
        "aff_unique_dep": "School of Computing;Department of Industrial and Systems Engineering",
        "aff_unique_url": "https://www.montana.edu;https://www.tamu.edu",
        "aff_unique_abbr": "MSU;TAMU",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Bozeman;College Station",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982174",
        "title": "Shape Estimation of Concentric Tube Robots Using Single Point Position Measurement",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate shape estimation of concentric tube robots (CTRs) using mathematical models remains a challenge, reinforcing the need to develop techniques for accurate and real-time shape sensing of CTRs. In this paper, we develop a fusion algorithm that predicts the robot's shape by combining a mathematical model of the CTR with a measurement of the Cartesian coordinates of the robot's tip using an electro-magnetic sensor. We experimentally validated our method in static and dynamic scenarios with and without external loading. Results demonstrated that the fusion algorithm improves the error of model-based shape prediction by an average of 44.3%, corresponding to 2.43% of the robot's arc length. Furthermore, we demonstrate that our method can be used in real-time to simultaneously track the robot's tip position and predict its shape.",
        "primary_area": "",
        "author": "Emile Mackute;Balint Thamo;Kevin Dhaliwal;Mohsen Khadem;Emile Mackute;Balint Thamo;Kevin Dhaliwal;Mohsen Khadem",
        "authorids": "/37089663123;/37089001416;/37086204046;/37085447737;/37089663123;/37089001416;/37086204046;/37085447737",
        "aff": "The Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen's Medical Research Institute, University of Edinburgh, UK; The Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen's Medical Research Institute, University of Edinburgh, UK; The Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen's Medical Research Institute, University of Edinburgh, UK; The Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen's Medical Research Institute, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982174/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11016729328952199387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "Centre for Inflammation Research",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981918",
        "title": "Shape and Motion Optimization of Rigid Planar Effectors for Contact Trajectory Satisfaction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework for co-optimizing the shape and motion of rigid robotic effectors for planar tasks. While planning object and robot-object contact trajectories is extensively studied, designing an effector that can execute the planned trajectories receives less attention. As such, our framework synthesizes an object trajectory and object-effector contact trajectory into an effector trajectory and shape that (a) does not penetrate the object, (b) makes contact with the object as specified, and (c) optimizes a user-specified objective. This simplifies manipulator control by encoding task-specific contact information in the effector's geometry. Our key insight is posing these requirements as constraints in the effector's reference frame, preventing the need for explicit parameterization of the effector shape. This prevents artificial restrictions on the shape design space. Importantly, it also facilitates posing the shape and motion design problem as a tractable nonlinear program. Our method is particularly useful for problems where the shape of the effector surface must be precisely chosen to achieve a task. We apply our method to several such problems, including jar-opening and picking up objects in constrained spaces. We evaluate the performance and computational cost of our method, and provide a physical experiment of a robotic arm picking up a screwdriver from a table with a designed tool.",
        "primary_area": "",
        "author": "Rebecca H. Jiang;Neel Doshi;Ravi Gondhalekar;Alberto Rodriguez;Rebecca H. Jiang;Neel Doshi;Ravi Gondhalekar;Alberto Rodriguez",
        "authorids": "/37089660391;/37085537968;/37398489900;/38194796600;/37089660391;/37085537968;/37398489900;/38194796600",
        "aff": "Department of Aeronautics and Astronautics, The Charles Stark Draper Laboratory, Inc., Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology; The Charles Stark Draper Laboratory, Inc.; Department of Mechanical Engineering, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981918/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2426725143846834910&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Charles Stark Draper Laboratory",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;",
        "aff_unique_url": "https://web.mit.edu;https://www.draper.com",
        "aff_unique_abbr": "MIT;Draper Lab",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981935",
        "title": "Shape memory polymer variable stiffness magnetic catheters with hybrid stiffness control",
        "track": "main",
        "status": "Poster",
        "abstract": "Variable stiffness catheters typically rely on thermally induced stiffness transitions with a transition temperature above body temperature. This imposes considerable safety limitations for medical applications. In this work, we present a variable stiffness catheter using a hybrid control strategy capable of actively heating and actively cooling the catheter material. The proposed catheter is made of a single biocompatible shape memory polymer, which significantly increases its manufacturability and scalability compared to existing designs. Potentially increased safety is obtained by ensuring a lower-risk compliant state at body temperature while maintaining higher stiffness ranges in actively controlled states. Additionally, the combined use of variable stiffness and magnetic actuation increases the dexterity and steerability of the device compared to existing robotic tools.",
        "primary_area": "",
        "author": "Michael Mattmann;Quentin Boehler;Xiang-Zhong Chen;Salvador Pan\u00e9;Bradley J. Nelson;Michael Mattmann;Quentin Boehler;Xiang-Zhong Chen;Salvador Pan\u00e9;Bradley J. Nelson",
        "authorids": "/37089663575;/37085792451;/37088907677;/37570330100;/37278736300;/37089663575;/37085792451;/37088907677;/37570330100;/37278736300",
        "aff": "Multi-Scale Robotics Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Multi-Scale Robotics Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Multi-Scale Robotics Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Multi-Scale Robotics Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Multi-Scale Robotics Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981935/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5340759352565335302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Multi-Scale Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981872",
        "title": "Shared Autonomy for Safety Between a Self-reconfigurable Robot and a Teleoperator Using Multi-layer Fuzzy Logic",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles are designed to elevate the efficiency of assigned tasks and ensure the safety of the environment in which they operate. This paper presents a research study focused on shared autonomy using a multi-layer fuzzy logic framework to build a relationship between an autonomous self-reconfigurable robot and a human user by switching control to the teleoperator to assist the robot when it faces challenging scenarios while keeping a good performance and maintaining a safe environment. A novel multi-layer fuzzy logic decision process with shared autonomy for a safety framework is proposed. It evaluates safety based on the robot's multi-sensor inputs, the teleoperator's attention level, and the configuration state of the self-reconfigurable robot and switches the operation mode, robot speed gain, and configuration state for performance and safety without compromises. The experimental outcome successfully demonstrates the self-reconfigurable robot's capability to navigate safely using shared autonomy in real-world pavement scenarios using the proposed algorithm during autonomous navigation.",
        "primary_area": "",
        "author": "Raul F.G. Azcarate;S.C. Daniela;A.A. Hayat;Lim Yi;M. A. Viraj J. Muthugala;Q.R Tang;A.P. Povendhan;K.J.K. Leong;M.R. Elara;Raul F.G. Azcarate;S.C. Daniela;A.A. Hayat;Lim Yi;M. A. Viraj J. Muthugala;Q.R Tang;A.P. Povendhan;K.J.K. Leong;M.R. Elara",
        "authorids": "/37089663597;/37089661848;/37085563101;/37088429249;/37085785341;/37089658568;/37089000428;/37089450481;/37546093700;/37089663597;/37089661848;/37085563101;/37088429249;/37085785341;/37089658568;/37089000428;/37089450481;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981872/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5444082030749031865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981755",
        "title": "Should a Robot Follow Social Norms? Human-Robot Interaction Design for Social Relations in Mixed Age Group",
        "track": "main",
        "status": "Poster",
        "abstract": "Social relations within a group are one of the factors that build the social context. Less attention has been paid to social relations within a group for human-robot interaction design. In this study, we designed different types of service behaviors for social relations in a mixed age group and conducted an experiment to investigate the effect of service behavior types (serving the elderly first versus serving the young first versus serving without priority) on a user's evaluation of a service robot. We only found that service evaluation and appropriateness of the robot were rated less positively under the condition of serving the young first than under other conditions. In addition, we found that the participants evaluated the robot serving the young first as impolite. The effect of the robot's behaviors on service evaluation and appropriateness was mediated by politeness. The current study provides an initial basis for human-robot interaction design for social norms in group-robot interaction.",
        "primary_area": "",
        "author": "Sangmin Kim;Jongsuk Choi;Yoonseob Lim;Sonya S. Kwak;Sangmin Kim;Jongsuk Choi;Yoonseob Lim;Sonya S. Kwak",
        "authorids": "/37089195721;/37292544300;/37695437400;/37398989100;/37089195721;/37292544300;/37695437400;/37398989100",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Department of HY-KIST Bio-convergence, Hanyang University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981755/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7366608366350223554&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;Hanyang University",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Department of HY-KIST Bio-convergence",
        "aff_unique_url": "https://www.kist.re.kr;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "KIST;HYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982189",
        "title": "Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the manipulating of the unmanned aerial manipulator (UAM) has been widely studied, vision-based UAM approaching, which is crucial to the subsequent manipulating, generally lacks effective design. The key to the visual UAM approaching lies in object tracking, while current UAM tracking typically relies on costly model-based methods. Besides, UAM approaching often confronts more severe object scale variation issues, which makes it inappro-priate to directly employ state-of-the-art model-free Siamese-based methods from the object tracking field. To address the above problems, this work proposes a novel Siamese network with pairwise scale-channel attention (SiamSA) for vision-based UAM approaching. Specifically, SiamSA consists of a pairwise scale-channel attention network (PSAN) and a scale-aware anchor proposal network (SA-APN). PSAN acquires valuable scale information for feature processing, while SA-APN mainly attaches scale awareness to anchor proposing. Moreover, a new tracking benchmark for UAM approaching, namely UAMT100, is recorded with 35K frames on a flying UAM platform for evaluation. Exhaustive experiments on the benchmarks and real-world tests validate the efficiency and practicality of SiamSA with a promising speed. Both the code and UAMT100 benchmark are now available at https://github.com/vision4robotics/SiamSA.",
        "primary_area": "",
        "author": "Guangze Zheng;Changhong Fu;Junjie Ye;Bowen Li;Geng Lu;Jia Pan;Guangze Zheng;Changhong Fu;Junjie Ye;Bowen Li;Geng Lu;Jia Pan",
        "authorids": "/37088996628;/37086797986;/37088917418;/37089000657;/38237039900;/37535628800;/37088996628;/37086797986;/37088917418;/37089000657;/38237039900;/37535628800",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Department of Automation, Tsinghua University, Beijing, China; Department of Computer Science, University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982189/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16983859799887715603&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Tongji University;Tsinghua University;University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Automation;Department of Computer Science",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.tsinghua.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "Tongji;THU;HKU",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Shanghai;Beijing;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982168",
        "title": "Sim-to-Real Transfer of Image-Based Autonomous Guidewire Navigation Trained by Deep Deterministic Policy Gradient with Behavior Cloning for Fast Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Percutaneous coronary intervention (PCI) is a frequently used surgical treatment for cardiovascular disease, one of the leading cause of death in the world. In traditional PCI, a doctor navigates a thin guidewire in a patient's vessel toward a target location by looking into live X-ray angiogram images of the patient. Recently, researchers are using reinforcement learning to automate this guidewire navigation process without attaching any sensor to the guidewire tip. These researchers use a real vessel phantom to train their behavior policy using reinforcement learning. Training a reinforcement learning algorithm on a real setup can give a good guidewire control on that setup, but it is under question whether the trained algorithm can be applied to other vessel structures. We can make various vessel phantoms and train the algorithm on the setups, but it can be really time and money consuming. In this paper, we devise a method for sim-to-real transfer of a guidewire navigation trained by reinforcement learning using only images. We pretrain our behavior policy using data collected by running an expert algorithm in the virtual environment. Then, we train the behavior policy by deep deterministic policy gradient (DDPG) in a virtual environment. With behavior cloning, our method learns to successfully navigate a guidewire in much shorter time than training DDPG from scratch without behavior cloning. After done with the training, we transfer the behavior policy trained in the virtual environment to the guidewire navigation in a real vessel phantom. Our trained behavior policy navigates the guidewire to destinations successfully in all test episodes and navigates faster than the expert algorithm. Experiment video is available at: https: //youtu.be/HCEbIhZsXqw",
        "primary_area": "",
        "author": "Yongjun Cho;Jae-Hyeon Park;Jaesoon Choi;Dong Eui Chang;Yongjun Cho;Jae-Hyeon Park;Jaesoon Choi;Dong Eui Chang",
        "authorids": "/37089190567;/37088567355;/37075160100;/37402057700;/37089190567;/37088567355;/37075160100;/37402057700",
        "aff": "Control Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Republic of Korea; Control Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Republic of Korea; Department of Biomedical Engineering, University of Ulsan College of Medicine, Republic of Korea; Control Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982168/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12363249643034096318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;University of Ulsan College of Medicine",
        "aff_unique_dep": "School of Electrical Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981878",
        "title": "Sim2Real Instance-Level Style Transfer for 6D Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, synthetic data has been widely used in the training of 6D pose estimation networks, in part because it automatically provides perfect annotation at low cost. However, there are still non-trivial domain gaps, such as differences in textures/materials, between synthetic and real data. These gaps have a measurable impact on performance. To solve this problem, we introduce a simulation to reality (sim2real) instance-level style transfer for 6D pose estimation network training. Our approach transfers the style of target objects individually, from synthetic to real, without human intervention. This improves the quality of synthetic data for training pose estimation networks. We also propose a complete pipeline from data collection to the training of a pose estimation network and conduct extensive evaluation on a real-world robotic platform. Our evaluation shows significant improvement achieved by our method in both pose estimation performance and the realism of images adapted by the style transfer.",
        "primary_area": "",
        "author": "Takuya Ikeda;Suomi Tanishige;Ayako Amma;Michael Sudano;Herv\u00e9 Audren;Koichi Nishiwaki;Takuya Ikeda;Suomi Tanishige;Ayako Amma;Michael Sudano;Herv\u00e9 Audren;Koichi Nishiwaki",
        "authorids": "/38548213300;/37089662147;/37088856033;/37089659852;/37085360230;/37089658862;/38548213300;/37089662147;/37088856033;/37089659852;/37085360230;/37089658862",
        "aff": "Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981878/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4136287524876467077&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Woven Planet Holdings, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wovenplanet.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981338",
        "title": "Sim2Real for Soft Robotic Fish via Differentiable Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate simulation of soft mechanisms under dynamic actuation is critical for the design of soft robots. We address this gap with our differentiable simulation tool by learning the material parameters of our soft robotic fish. On the example of a soft robotic fish, we demonstrate an experimentally-verified, fast optimization pipeline for learning the material parameters from quasi-static data via differentiable simulation and apply it to the prediction of dynamic performance. Our method identifies physically plausible Young's moduli for various soft silicone elastomers and stiff acetal copolymers used in creation of our three different robotic fish tail designs. We show that our method is compatible with varying internal geometry of the actuators, such as the number of hollow cavities. Our framework allows high fidelity prediction of dynamic behavior for composite bi-morph bending structures in real hardware to millimeter-accuracy and within 3% error normalized to actuator length. We provide a differentiable and robust estimate of the thrust force using a neural network thrust predictor; this estimate allows for accurate modeling of our experimental setup measuring bollard pull. This work presents a prototypical hardware and simulation problem solved using our differentiable framework; the framework can be applied to higher dimensional parameter inference, learning control policies, and computational design due to its differentiable character.",
        "primary_area": "",
        "author": "John Z. Zhang;Yu Zhang;Pingchuan Ma;Elvis Nava;Tao Du;Philip Arm;Wojciech Matusik;Robert K. Katzschmann;John Z. Zhang;Yu Zhang;Pingchuan Ma;Elvis Nava;Tao Du;Philip Arm;Wojciech Matusik;Robert K. Katzschmann",
        "authorids": "/37089663961;/37089664176;/37089448038;/37089663399;/37088842690;/37086936504;/37295070400;/37085423557;/37089663961;/37089664176;/37089448038;/37089663399;/37088842690;/37086936504;/37295070400;/37085423557",
        "aff": "Mechanical Engineering, MIT, USA; Soft Robotics Lab, ETH Zurich, Switzerland; Computer Science and AI Lab, MIT, USA; ETH AI Center, ETH Zurich, Switzerland; Computer Science and AI Lab, MIT, USA; Soft Robotics Lab, ETH Zurich, Switzerland; Computer Science and AI Lab, MIT, USA; ETH AI Center, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981338/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13611510726280809842&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;0;1;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;ETH Zurich",
        "aff_unique_dep": "Mechanical Engineering;Soft Robotics Lab",
        "aff_unique_url": "https://web.mit.edu;https://www.ethz.ch",
        "aff_unique_abbr": "MIT;ETHZ",
        "aff_campus_unique_index": "1;2;1;1;2",
        "aff_campus_unique": ";Cambridge;Zurich",
        "aff_country_unique_index": "0;1;0;1;0;1;0;1",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9982212",
        "title": "Simulation-based Learning of the Peg-in-Hole Process Using Robot-Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Increasingly volatile markets challenge companies and demand flexible production systems that can be quickly adapted to new conditions. Machine Learning has proven to show significant potential in supporting the human operator during the time-consuming and complex task of robot pro-gramming by identifying relevant parameters of the underlying robot control program. We present a solution to learn these parameters for contact-rich, force-controlled assembly tasks from a simulation using hardware-independent robot skills. We show that successful learning and real-world execution are possible even under process deviation and tolerances utilizing the designed learning system. We present learning skill param-eters as high-level robot control, evaluation and comparison of extensive simulations, and preliminary experiments on a physical robot test-bed. The developed solution approach is evaluated and discussed using the Peg-in-Hole process, a typical benchmark process in force-controlled assembly.",
        "primary_area": "",
        "author": "Arik L\u00e4mmle;Philipp Tenbrock;Bal\u00e1zs B\u00e1lint;Frank N\u00e4gele;Werner Kraus;J\u00f3zsef V\u00e1ncza;Marco F. Huber;Arik L\u00e4mmle;Philipp Tenbrock;Bal\u00e1zs B\u00e1lint;Frank N\u00e4gele;Werner Kraus;J\u00f3zsef V\u00e1ncza;Marco F. Huber",
        "authorids": "/37088523487;/37086454874;/37089658788;/37086454281;/37357181400;/37085414012;/37392400600;/37088523487;/37086454874;/37089658788;/37086454281;/37357181400;/37085414012;/37392400600",
        "aff": "Department of Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA.; Department of Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA.; Department of Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA.; Department of Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA.; Department of Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA.; Research Laboratory on Engineering and Management Intelligence, Institute for Computer Science and Control SZTAKI; Centre of Cyber Cognitive Intelligence, Fraunhofer Institute for Manufacturing Engineering and Automation IPA and with the Institute of Industrial Manufacturing and Management IFF, University of Stuttgart",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982212/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8527558862953970520&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;Institute for Computer Science and Control SZTAKI",
        "aff_unique_dep": "Department of Robot and Assistive Systems;Research Laboratory on Engineering and Management Intelligence",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.sztaki.hu",
        "aff_unique_abbr": "Fraunhofer IPA;SZTAKI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "Germany;Hungary"
    },
    {
        "id": "9981762",
        "title": "Simultaneous Contact Location and Object Pose Estimation Using Proprioception and Tactile Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Joint estimation of grasped object pose and extrinsic contacts is central to robust and dexterous manipulation. In this paper, we propose a novel state-estimation algorithm that jointly estimates contact location and object pose in 3D using exclusively proprioception and tactile feedback. Our approach leverages two complementary particle filters: one to estimate contact location (CPFGrasp) and another to estimate object poses (SCOPE). We implement and evaluate our approach on real-world single-arm and dual-arm robotic systems. We demonstrate that by bringing two objects into contact, the robots can infer contact location and object poses simultaneously. Our proposed method can be applied to a number of downstream tasks that require accurate pose estimates, such as tool use and assembly. Code and data can be found at https://github.com/MMintLab/scope.",
        "primary_area": "",
        "author": "Andrea Sipos;Nima Fazeli;Andrea Sipos;Nima Fazeli",
        "authorids": "/37089658283;/37072790600;/37089658283;/37072790600",
        "aff": "Department of Robotics at the University of Michigan, Hayward Drive, Ann Arbor, USA; Department of Robotics at the University of Michigan, Hayward Drive, Ann Arbor, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981762/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10163631236979698829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981579",
        "title": "Simultaneous Contact-Rich Grasping and Locomotion via Distributed Optimization Enabling Free-Climbing for Multi-Limbed Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "While motion planning of locomotion for legged robots has shown great success, motion planning for legged robots with dexterous multi-finger grasping is not mature yet. We present an efficient motion planning framework for simultaneously solving locomotion (e.g., centroidal dynamics), grasping (e.g., patch contact), and contact (e.g., gait) problems. To accelerate the planning process, we propose distributed optimization frameworks based on Alternating Direction Methods of Multipliers (ADMM) to solve the original large-scale Mixed-Integer NonLinear Programming (MINLP). The resulting frameworks use Mixed-Integer Quadratic Programming (MIQP) to solve contact and NonLinear Programming (NLP) to solve nonlinear dynamics, which are more computationally tractable and less sensitive to parameters. Also, we explicitly enforce patch contact constraints from limit surfaces with micro-spine grippers. We demonstrate our proposed framework in the hardware experiments, showing that the multi-limbed robot is able to realize various motions including free-climbing at a slope angle 45\u00b0 with a much shorter planning time.",
        "primary_area": "",
        "author": "Yuki Shirai;Xuan Lin;Alexander Schperberg;Yusuke Tanaka;Hayato Kato;Varit Vichathorn;Dennis Hong;Yuki Shirai;Xuan Lin;Alexander Schperberg;Yusuke Tanaka;Hayato Kato;Varit Vichathorn;Dennis Hong",
        "authorids": "/37086344073;/37085891795;/37088689963;/37088439498;/37089659737;/37089662839;/37575333900;/37086344073;/37085891795;/37088689963;/37088439498;/37089659737;/37089662839;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981579/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14076339335355705618&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982228",
        "title": "Simultaneous Depth Estimation and Localization for Cell Manipulation Based on Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization, which is a key technology to realize the automation of cell manipulation, has been widely studied. Since the depth of field of the microscope is narrow, the planar localization and depth estimation are usually coupled together. At present, most methods adopt the serial working mode of focusing first and then planar localization, but they usually do not have good real-time performance and stability. In this paper, a simultaneous depth estimation and localization network was developed for cell manipulation. The network takes a focused image and a defocus-offset image as inputs, and outputs the defocus in the depth direction and the offset in the plane at the same time after going through defocus-offset information extraction, defocus classification mapping and offset regression mapping. To train and test our network, we also create two datasets: An Adherent Cell dataset and an Injection Micropipette dataset. The experimental results demonstrated that the proposed method achieves the detection of all test samples with a frame rate of more than 40Hz, and the maximum errors of depth estimation and localization are \\boldsymbol{2.44\\mu m}\\boldsymbol{2.44\\mu m} and \\boldsymbol{0.49\\mu m}\\boldsymbol{0.49\\mu m}, respectively. The proposed method has good stability, which is mainly reflected in its strong generalization ability and anti-noise ability.",
        "primary_area": "",
        "author": "Zengshuo Wang;Huiying Gong;Ke Li;Bin Yang;Yue Du;Yaowei Liu;Xin Zhao;Mingzhu Sun;Zengshuo Wang;Huiying Gong;Ke Li;Bin Yang;Yue Du;Yaowei Liu;Xin Zhao;Mingzhu Sun",
        "authorids": "/37089664147;/37088941945;/37089662430;/37089663475;/37088913488;/37086173893;/37293143500;/37536498500;/37089664147;/37088941945;/37089662430;/37089663475;/37088913488;/37086173893;/37293143500;/37536498500",
        "aff": "Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982228/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11619699401686498670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Intelligence Technology and Robotic Systems",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981666",
        "title": "Simultaneous Gesture Classification and Speed Control for Myoelectric Prosthetic Hand Using Joint-Loss Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Gesture classification and motion speed regression are always two major issues in myoelectrical prosthetic hand research. However, there is little research considering these two issues in conjunction. Some shared EMG feature information in these two processing tasks is promising to improve the performance of prosthetic hand control. In this study, a joint-loss (JL) neural network architecture is proposed to implement gesture classification and motion speed regression problems in parallel by sharing the hidden neural units in the training process and optimizing the joint loss function. We evaluated the proposed control system through motion experiments performed on six participants. The experiment result shows that the classification and regression models can successfully reproduce smooth movement based on EMG measurement with high accuracy. Furthermore, the possibility of clinical application is demonstrated through the online movement of the real prosthetic hand.",
        "primary_area": "",
        "author": "Hashimoto Naoki;Zhenzhi Ying;Nakashima Koki;Liming Shu;Naohiko Sugita;Hashimoto Naoki;Zhenzhi Ying;Nakashima Koki;Liming Shu;Naohiko Sugita",
        "authorids": "/37089661561;/37088534892;/37089662626;/37088533346;/37353189300;/37089661561;/37088534892;/37089662626;/37088533346;/37353189300",
        "aff": "Department of Mechanical Engineering, Manufacturing Laboratory, The University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, Manufacturing Laboratory, The University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, Manufacturing Laboratory, The University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, Manufacturing Laboratory, The University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, Manufacturing Laboratory, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981666/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11000840686620889143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981955",
        "title": "Simultaneous Object Reconstruction and Grasp Prediction using a Camera-centric Object Shell Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to grasp objects is a fundamental component of most robotic manipulation systems. In this paper, we present a new approach to simultaneously reconstruct a mesh and a dense grasp quality map of an object from a depth image. At the core of our approach is a novel camera-centric object representation called the \u201cobject shell\u201d which is composed of an observed \u201centry image\u201d and a predicted \u201cexit image\u201d. We present an image-to-image residual ConvNet architecture in which the object shell and a grasp-quality map are predicted as separate output channels. The main advantage of the shell representation and the corresponding neural network architecture, ShellGrasp-Net, is that the input-output pixel correspondences in the shell representation are explicitly represented in the architecture. We show that this coupling yields superior generalization capabilities for object reconstruction and accurate grasp quality estimation implicitly considering the object geometry. Our approach yields an efficient dense grasp quality map and an object geometry estimate in a single forward pass. Both of these outputs can be used in a wide range of robotic manipulation applications. With rigorous experimental validation, both in simulation and on a real setup, we show that our shell-based method can be used to generate precise grasps and the associated grasp quality with over 90% accuracy. Diverse grasps computed on shell reconstructions allow the robot to select and execute grasps in cluttered scenes with more than 93% success rate.",
        "primary_area": "",
        "author": "Nikhil Chavan-Dafle;Sergiy Popovych;Shubham Agrawal;Daniel D. Lee;Volkan Isler;Nikhil Chavan-Dafle;Sergiy Popovych;Shubham Agrawal;Daniel D. Lee;Volkan Isler",
        "authorids": "/37085487604;/37087461200;/37088998130;/37280609600;/37298487800;/37085487604;/37087461200;/37088998130;/37280609600;/37298487800",
        "aff": "Samsung AI Center, New York, NY; Princeton University, Princeton, NJ; Samsung AI Center, New York, NY; Samsung AI Center, New York, NY; Samsung AI Center, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981955/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=894409436833207010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Samsung;Princeton University",
        "aff_unique_dep": "AI Center;",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/;https://www.princeton.edu",
        "aff_unique_abbr": "SAC;Princeton",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "New York;Princeton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981331",
        "title": "Single-Rod Brachiation Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new brachiation robot, a single-rod brachiation robot. Brachiation is a method of locomotion that makes clever use of gravity and has been tried to apply to robots. Conventional brachiation robots are multiple-pendulum-like robots that mimic a gibbon. Although the multiple-pendulum-like robot can easily change the length of one brachiation step by joints, it has complex structures and generates aperiodic motions such as chaos. In contrast, the single-rod brachiation robot has the advantages of simple structure and the ability to suppress complex multiple-pendulum trajectories. The single-rod brachiation robot has a disadvantage because it is difficult to adjust the distance to the next bar. However, we can solve it by aerial brachiation, which includes an aerial phase before grasping the next bar. Using the actual robot, we showed that the swinging amplitude could be increased by appropriately moving its center of gravity like a trapeze motion. In addition, using this, we achieved continuous brachiation across three bars and brachiation including the aerial phase with a flight distance of 140 mm.",
        "primary_area": "",
        "author": "Hijiri Akahane;Ikuo Mizuuchi;Hijiri Akahane;Ikuo Mizuuchi",
        "authorids": "/37089585740;/37295606700;/37089585740;/37295606700",
        "aff": "Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, Koganei-city, Tokyo, Japan; Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, Koganei-city, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981331/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14322770419033407357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tokyo University of Agriculture and Technology",
        "aff_unique_dep": "Department of Mechanical Systems Engineering",
        "aff_unique_url": "https://www.tuat.ac.jp",
        "aff_unique_abbr": "TUAT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Koganei-city, Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981159",
        "title": "Skeleton-based Adaptive Visual Servoing for Control of Robotic Manipulators in Configuration Space",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel visual servoing method that controls a robotic manipulator in the configuration space as opposed to the classical vision-based control methods solely focusing on the end effector pose. We first extract the robot's shape from depth images using a skeletonization algorithm and represent it using parametric curves. We then adopt an adaptive visual servoing scheme that estimates the Jacobian online relating the changes of the curve parameters and the joint velocities. The proposed scheme does not only enable controlling a manipulator in the configuration space, but also demonstrates a better transient response while converging to the goal configuration compared to the classical adaptive visual servoing methods. We present simulations and real robot experiments that demonstrate the capabilities of the proposed method and analyze its performance, robustness, and repeatability compared to the classical algorithms.",
        "primary_area": "",
        "author": "Abhinav Gandhi;Sreejani Chatterjee;Berk Calli;Abhinav Gandhi;Sreejani Chatterjee;Berk Calli",
        "authorids": "/37087233321;/37089663379;/37681653300;/37087233321;/37089663379;/37681653300",
        "aff": "Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981159/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4879003013613790380&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982077",
        "title": "Skill-CPD: Real-time Skill Refinement for Shared Autonomy in Manipulator Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Edwin Babaians;Dong Yang;Mojtaba Karimi;Xiao Xu;Serkut Ayvasik;Eckehard Steinbach;Edwin Babaians;Dong Yang;Mojtaba Karimi;Xiao Xu;Serkut Ayvasik;Eckehard Steinbach",
        "authorids": "/37085653235;/37089660575;/38667191100;/38238310400;/37088764988;/37273225600;/37085653235;/37089660575;/38667191100;/38238310400;/37088764988;/37273225600",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982077/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4880439639655727827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "9981174",
        "title": "Slip Anticipation for Grasping Deformable Objects Using a Soft Force Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots using classical control have revolutionised assembly lines where the environment and manipulated objects are restricted and predictable. However, they have proven less effective when the manipulated objects are deformable due to their complex and unpredictable behaviour. The use of tactile sensors and continuous monitoring of tactile feedback is there-fore particularly important for pick-and-place tasks using these materials. This is in part due to the need to use multiple points of contact for the manipulation of deformable objects which can result in slippage with inadequate coordination between manipulators. In this paper, continuous monitoring of tactile feedback, using a liquid metal soft force sensor, for grasping deformable objects is presented. The trained data-driven model distinguishes between successful grasps, slippage and failure during a manipulation task for multiple deformable objects. Slippage could be anticipated before failure occurred using data acquired over a 30 ms period with a greater than 95% accuracy using a random forest classifier. The results were achieved using a single sensor that can be mounted on the fingertips of existing grippers and contributes to the development of an automated pick-and-place process for deformable objects.",
        "primary_area": "",
        "author": "Euan Judd;Bekir Aksoy;Krishna Manaswi Digumarti;Herbert Shea;Dario Floreano;Euan Judd;Bekir Aksoy;Krishna Manaswi Digumarti;Herbert Shea;Dario Floreano",
        "authorids": "/37086562696;/37089659210;/37086145365;/37284098900;/37282168700;/37086562696;/37089659210;/37086145365;/37284098900;/37282168700",
        "aff": "Laberatory of Intelligent Systems, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; LMTS: Soft Transducers Lab, Ecole Polytechnique F\u00e9d\u00e9rale de Lau-sanne, Switzerland; LMTS: Soft Transducers Lab, Ecole Polytechnique F\u00e9d\u00e9rale de Lau-sanne, Switzerland; LMTS: Soft Transducers Lab, Ecole Polytechnique F\u00e9d\u00e9rale de Lau-sanne, Switzerland; Laberatory of Intelligent Systems, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981174/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=77437299921091262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Laberatory of Intelligent Systems",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981813",
        "title": "Smart Explorer: Recognizing Objects in Dense Clutter via Interactive Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing objects in dense clutter accurately plays an important role to a wide variety of robotic manipulation tasks including grasping, packing, rearranging and many others. However, conventional visual recognition models usually miss objects because of the significant occlusion among instances and causes incorrect prediction due to the visual ambiguity with the high object crowdedness. In this paper, we propose an interactive exploration framework called Smart Explorer for recognizing all objects in dense clutters. Our Smart Explorer physically interacts with the clutter to maximize the recognition performance while minimize the number of motions, where the false positives and negatives can be alleviated effectively with the optimal accuracy-efficiency trade-offs. Specifically, we first collect the multi-view RGB-D images of the clutter and reconstruct the corresponding point cloud. By aggregating the instance segmentation of RGB images across views, we acquire the instance-wise point cloud partition of the clutter through which the existed classes and the number of objects for each class are predicted. The pushing actions for effective physical interaction are generated to sizably reduce the recognition uncertainty that consists of the instance segmentation entropy and multi-view object disagreement. Therefore, the optimal accuracy-efficiency trade-off of object recognition in dense clutter is achieved via iterative instance prediction and physical interaction. Extensive experiments demonstrate that our Smart Explorer acquires promising recognition accuracy with only a few actions, which also outperforms the random pushing by a large margin.",
        "primary_area": "",
        "author": "Zhenyu Wu;Ziwei Wang;Zibu Wei;Yi Wei;Haibin Yan;Zhenyu Wu;Ziwei Wang;Zibu Wei;Yi Wei;Haibin Yan",
        "authorids": "/37597233600;/37086179280;/37089662326;/37087233204;/37958629300;/37597233600;/37086179280;/37089662326;/37087233204;/37958629300",
        "aff": "School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; Department of Automation, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Department of Automation, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Department of Automation, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981813/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14883089853396337046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications;Tsinghua University",
        "aff_unique_dep": "School of Automation;Department of Automation",
        "aff_unique_url": "http://www.bupt.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BUPT;Tsinghua",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982016",
        "title": "Smart Visual Beacons with Asynchronous Optical Communications using Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Ziwei Wang;Yonhon Ng;Jack Henderson;Robert Mahony;Ziwei Wang;Yonhon Ng;Jack Henderson;Robert Mahony",
        "authorids": "/37089197011;/37086203065;/37088758464;/37283743600;/37089197011;/37086203065;/37088758464;/37283743600",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982016/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12690003737623492578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9982160",
        "title": "Sociable and Ergonomic Human-Robot Collaboration through Action Recognition and Augmented Hierarchical Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "The recognition of actions performed by humans and the anticipation of their intentions are important enablers to yield sociable and successful collaboration in human-robot teams. Meanwhile, robots should have the capacity to deal with multiple objectives and constraints, arising from the collaborative task or the human. In this regard, we propose vision techniques to perform human action recognition and image classification, which are integrated into an Augmented Hierarchical Quadratic Programming (AHQP) scheme to hierarchically optimize the robot's reactive behavior and human ergonomics. The proposed framework allows one to intuitively command the robot in space while a task is being executed. The experiments confirm increased human ergonomics and usability, which are fundamental parameters for reducing musculoskeletal diseases and increasing trust in automation.",
        "primary_area": "",
        "author": "Francesco Tassi;Francesco Iodice;Elena De Momi;Arash Ajoudani;Francesco Tassi;Francesco Iodice;Elena De Momi;Arash Ajoudani",
        "authorids": "/37086861229;/37089617816;/37947344300;/37945239900;/37086861229;/37089617816;/37947344300;/37945239900",
        "aff": "Department of Electronics Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics Information and Bioengineering, Politecnico di Milano, Milan, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982160/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4275617051786590942&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Electronics Information and Bioengineering;HRI2 Lab",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Milan;Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981486",
        "title": "Social-PatteRNN: Socially-Aware Trajectory Prediction Guided by Motion Patterns",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots across domains start collaborating with humans in shared environments, algorithms that enable them to reason over human intent are important to achieve safe inter-play. In our work, we study human intent through the problem of predicting trajectories in dynamic environments. We explore domains where navigation guidelines are relatively strictly defined but not clearly marked in their physical environments. We hypothesize that within these domains, agents tend to exhibit short-term motion patterns that reveal context information related to the agent's general direction, intermediate goals and rules of motion, e.g., social behavior. From this intuition, we propose Social-PatteRNN, an algorithm for recurrent, multi-modal trajectory prediction that exploits motion patterns to encode the aforesaid contexts. Our approach guides long-term trajectory prediction by learning to predict short-term motion patterns. It then extracts sub-goal information from the patterns and aggregates it as social context. We assess our approach across three domains: humans crowds, humans in sports and manned aircraft in terminal airspace, achieving state-of-the-art performance.",
        "primary_area": "",
        "author": "Ingrid Navarro;Jean Oh;Ingrid Navarro;Jean Oh",
        "authorids": "/37089659460;/37933996900;/37089659460;/37933996900",
        "aff": "The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981486/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18433407055520555066&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982021",
        "title": "SocialGym: A Framework for Benchmarking Social Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots moving safely and in a socially compliant manner in dynamic human environments is an essential benchmark for long-term robot autonomy. However, it is not feasible to learn and benchmark social navigation behaviors entirely in the real world, as learning is data-intensive, and it is challenging to make safety guarantees during training. Therefore, simulation-based benchmarks that provide abstractions for social navigation are required. A framework for these benchmarks would need to support a wide variety of learning approaches, be extensible to the broad range of social navigation scenarios, and abstract away the perception problem to focus on social navigation explicitly. While there have been many proposed solutions, including high fidelity 3D simulators and grid world approximations, no existing solution satisfies all of the aforementioned properties for learning and evaluating social navigation behaviors. In this work, we propose SocialGym, a lightweight 2D simulation environment for robot social navigation designed with extensibility in mind, and a benchmark scenario built on SocialGym. Further, we present benchmark results that compare and contrast human-engineered and model-based learning approaches to a suite of off-the-shelf Learning from Demonstration (LfD) and Reinforcement Learning (RL) approaches applied to social robot navigation. These results demonstrate the data efficiency, task performance, social compliance, and environment transfer capabilities for each of the policies evaluated to provide a solid grounding for future social navigation research.",
        "primary_area": "",
        "author": "Jarrett Holtz;Joydeep Biswas;Jarrett Holtz;Joydeep Biswas",
        "authorids": "/37086307815;/37538259200;/37086307815;/37538259200",
        "aff": "Computer Science, University of Texas, Austin, TX, USA; Computer Science, University of Texas, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982021/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1555376729800174622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982089",
        "title": "Soft Actuators for Facial Reanimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Facial paralysis is a challenging condition that alters a patient's ability to express emotion and communicate. Restoring facial movements thus has crucial implications for the patients' quality of life. This publication introduces an approach for artificial muscles implementation targeting facial reanimation, as well as the challenges and limitations of the proposed strategy. The aim is to develop a Dielectric Elastomer Actuator (DEA) prosthesis for patients suffering from facial paralysis. DEAs are chosen as they are soft, have large strain (up to 200%) and high dynamic behaviour (up to 20 kHz), making them a promising actuator for the application. Myo-electric signals are extracted using electromyography sensors from the Zygomaticus Major muscle, and they are processed in order to emphasize the activation phases. The resulting actuating signal is used to control a high voltage power supply to operate the DEA in an open loop. The resulting induced movement qualitatively matches the myoelectric signal, showing great potential of the proposed approach for facial paralysis reanimation.",
        "primary_area": "",
        "author": "Stefania Konstantinidi;Thomas Martinez;Amine Benouhiba;Yoan Civet;Yves Perriard;Stefania Konstantinidi;Thomas Martinez;Amine Benouhiba;Yoan Civet;Yves Perriard",
        "authorids": "/37089196122;/37088458171;/37086579608;/37393197200;/37267563900;/37089196122;/37088458171;/37086579608;/37393197200;/37267563900",
        "aff": "Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Integrated Actuators Laboratory (LAI), Neuchatel, Switzerland; Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Integrated Actuators Laboratory (LAI), Neuchatel, Switzerland; Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Integrated Actuators Laboratory (LAI), Neuchatel, Switzerland; Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Integrated Actuators Laboratory (LAI), Neuchatel, Switzerland; Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Integrated Actuators Laboratory (LAI), Neuchatel, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982089/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3025363928834439362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ecole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL)",
        "aff_unique_dep": "Integrated Actuators Laboratory (LAI)",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9982071",
        "title": "Soft Tactile Contour Following for Robot-Assisted Wiping and Bathing",
        "track": "main",
        "status": "Poster",
        "abstract": "The automated cleaning of surfaces such as furniture, bathroom sinks, and even human bodies is challenging due to the three-dimensional nature of their geometries. Yet, enabling robots to effectively and safely perform these tasks would not only reduce user efforts spent on household cleaning chores, but would also alleviate the strenuous workload of caretakers as the elderly population continues to grow at an unprecedented rate. In this work, we unify the applications of wiping objects and bathing humans as a general contour-following problem. To this end, we utilize a depth camera-based soft tactile sensor to extract the contact geometries and force-correlated measures during interaction between the robot and the target object or body part, and design a general contour-following controller that not only maintains contact with the target throughout the cleaning process, but also regulates the amount of force applied. Our system enables successful cleaning of pipes, shelving, and even human limbs and torsos without the need for data-driven methods such as deep learning, upon which the majority of existing works have relied.",
        "primary_area": "",
        "author": "Isabella Huang;Dylan Chow;Ruzena Bajcsy;Isabella Huang;Dylan Chow;Ruzena Bajcsy",
        "authorids": "/37086538069;/37089659134;/37298488400;/37086538069;/37089659134;/37298488400",
        "aff": "Department of Electrical Engineering and Computer Sciences, Human Assistive Robotics Technology Lab, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, Human Assistive Robotics Technology Lab, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, Human Assistive Robotics Technology Lab, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982071/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16464590883682366486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981625",
        "title": "Soft, Multi-Layer, Disposable, Kirigami Based Robotic Grippers: On Handling of Delicate, Contaminated, and Everyday Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping and manipulation are complex and demanding tasks, especially when executed in dynamic and unstructured environments. Typically, such tasks are executed by rigid articulated end-effectors, with a plethora of actuators that need sophisticated sensing and complex control laws to execute them efficiently. Soft robotics offers an alternative that allows for simplified execution of these demanding tasks, enabling the creation of robust, efficient, lightweight, and affordable solutions that are easy to control and operate. In this work, we introduce a new class of soft, kirigami-based robotic grippers, we study their post-contact behavior, and we investigate different cut patterns for their development. We follow an experimental approach in which several designs are proposed and employed in a series of grasping and force exertion tests to compare their capabilities and post-contact behavior. The results of such experiments indicate a clear relationship between degree of reconfiguration and grasping force, and provide key insights into the effect of the cut patterns in the performance of the designs. These findings are then used in the design process of an improved version of multi-layer, disposable kirigami grippers that are fabricated employing simple 3D printed layers and silicone rubber using the concept of Hybrid Deposition Manufacturing (HDM). A series of experimental results demonstrate that the proposed design and manufacturing methods can enable the creation of soft, kirigami-based grippers with superior grasping capabilities that can handle delicate, contaminated, and everyday life objects and can even be disposed off in an automated way (e.g., after handling hazardous materials, such as medical waste).",
        "primary_area": "",
        "author": "Joao Buzzatto;Mojtaba Shahmohammadi;Junbang Liang;Felipe Sanches;Saori Matsunaga;Rintaro Haraguchi;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis;Joao Buzzatto;Mojtaba Shahmohammadi;Junbang Liang;Felipe Sanches;Saori Matsunaga;Rintaro Haraguchi;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis",
        "authorids": "/37088599578;/37089186373;/37089661353;/37088226006;/37088580339;/37565174400;/37087323162;/37300950400;/38558084100;/37088599578;/37089186373;/37089661353;/37088226006;/37088580339;/37565174400;/37087323162;/37300950400;/38558084100",
        "aff": "Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Advanced Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Department of Electrical, Computer and Software Engineering, Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981625/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10756715432037994094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;1;1;1;0;0",
        "aff_unique_norm": "University of Auckland;Mitsubishi Electric Corporation",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;Information Technology R&D Center",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "UoA;MEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;1;1;0;0",
        "aff_country_unique": "New Zealand;Japan"
    },
    {
        "id": "9981745",
        "title": "Soft-Skin Actuator Capable of Seawater Propulsion based on MagnetoHydroDynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater robots have a variety of potential uses, including marine resource research, ecological research, and disaster relief. Most of the underwater robots currently in practical use have screw propulsion systems, which have several noises, collision, and entrainment problems. There is a lot of research on underwater robots using soft actuators to solve these problems. However, current soft actuators have disadvantages, such as the need for special fluids, pressure sources, and high voltage circuits. Therefore, we have developed a soft-skin actuator based on magnetohydrodynamics (MHD). The soft-skin MHD actuator is made of soft material and the structure is prepared as thin, which allows it to attach to the surface of an object, including curved surfaces, to provide the object with a propulsive function in the sea. Since it has no moving parts, it does not generate mechanical noise, and there is no danger of entrapment. Because it can pump seawater directly, it does not require a special working fluid, and its structure is simple and easy to miniaturize. This paper investigates the thrust and power consumption of the developed soft-skin MHD actuator when attached to a flat surface. As a result, we obtained a thrust of 1.37 mN from a single soft-skin MHD actuator with a maximum power of about 140 W. We also measured the thrust force by attaching it to a curved surface. We obtained a higher thrust on a curved surface by adjusting the crossing of the magnetic field and the current than when using a flat surface. We developed an untethered robot that can remove oil from the sea using soft-skin MHD actuators. We demonstrated the adaptability of the soft-skin MHD actuator by attaching it to a commercial underwater camera weighing about 253.5 g and providing propulsion.",
        "primary_area": "",
        "author": "Mutsuki Matsumoto;Yu Kuwajima;Hiroki Shigemune;Mutsuki Matsumoto;Yu Kuwajima;Hiroki Shigemune",
        "authorids": "/37089658434;/37086311848;/37085364472;/37089658434;/37086311848;/37085364472",
        "aff": "Shibaura Institute of Technology, Tokyo, Japan; Shibaura Institute of Technology, Tokyo, Japan; Shibaura Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981745/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=892085327647986966&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shibaura Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.shibaura-it.ac.jp",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981550",
        "title": "Sparse PointPillars: Maintaining and Exploiting Input Sparsity to Improve Runtime on Embedded Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Bird's Eye View (BEV) is a popular representation for processing 3D point clouds, and by its nature is fundamentally sparse. Motivated by the computational limitations of mobile robot platforms, we create a fast, high-performance BEV 3D object detector that maintains and exploits this input sparsity to decrease runtimes over non-sparse baselines and avoids the tradeoff between pseudoimage area and runtime. We present results on KITTI, a canonical 3D detection dataset, and Matterport-Chair, a novel Matterport3D-derived chair detection dataset from scenes in real furnished homes. We evaluate runtime characteristics using a desktop GPU, an embedded ML accelerator, and a robot CPU, demonstrating that our method results in significant detection speedups (2 \u00d7 or more) for embedded systems with only a modest decrease in detection quality. Our work represents a new approach for practitioners to optimize models for embedded systems by maintaining and exploiting input sparsity throughout their entire pipeline to reduce runtime and resource usage while preserving detection performance. All models, weights, experimental configurations, and datasets used are publicly available11https://vedder.io/sparse_point_pillars.",
        "primary_area": "",
        "author": "Kyle Vedder;Eric Eaton;Kyle Vedder;Eric Eaton",
        "authorids": "/37089659308;/37671820200;/37089659308;/37671820200",
        "aff": "Dept. of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA; Dept. of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981550/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1308804932982845541&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Dept. of Computer and Information Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981958",
        "title": "Spatio-Temporal Graph Localization Networks for Image-based Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization in topological maps is essential for image-based navigation using an RGB camera. Localization using only one camera can be challenging in medium-to-large-sized environments because similar-looking images are often observed repeatedly, especially in indoor environments. To overcome this issue, we propose a learning-based localization method that simultaneously utilizes the spatial consistency from topological maps and the temporal consistency from time-series images captured by a robot. Our method combines a convolutional neural network (CNN) to embed image features and a recurrent-type graph neural network to perform accurate localization. When training our model, it is difficult to obtain the ground truth (GT) pose of the robot when capturing images in real-world environments. Hence, we propose a sim2real transfer approach with semi-supervised learning that leverages simulator images with the GT pose in addition to real images. We evaluated the proposed method quantitatively and qualitatively and compared it with several state-of-the-art baselines. The proposed method outperformed the baselines in environments where the map contained similar images. Moreover, we evaluated an image-based navigation system incorporating our localization method and confirmed that navigation accuracy significantly improved in the simulator and real environments compared to the other baseline methods.",
        "primary_area": "",
        "author": "Takahiro Niwa;Shun Taguchi;Noriaki Hirose;Takahiro Niwa;Shun Taguchi;Noriaki Hirose",
        "authorids": "/37088547673;/37391684000;/37574851500;/37088547673;/37391684000;/37574851500",
        "aff": "Toyota Central R&D Labs., INC, Japan; Toyota Central R&D Labs., INC, Japan; Toyota Central R&D Labs., INC, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981958/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6299319646940621791&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com/company/profile",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981595",
        "title": "Spatiotemporally Enhanced Photometric Loss for Self-Supervised Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recovering depth information from a single image is a long-standing challenge, and self-supervised depth estimation methods have gradually attracted attention due to not relying on high-cost ground truth. Constructing an accurate photometric loss based on photometric consistency is crucial for these self-supervised methods to obtain high-quality depth maps. However, the photometric loss in most studies treats all pixels indiscriminately, resulting in poor performance. In this paper, we propose two modules based on the spatial and temporal cues to refine the photometric loss. Delving into the geometric model of photometric consistency, we introduce a depth-aware pixel correspondence module (DPC) inside the monocular depth estimation pipeline. It reduces the uncertainty of photometric errors by applying the homography matrix to the projection of corresponding pixels in far regions instead of the fundamental matrix. Furthermore, we design an omnidirectional auto-masking module (OA) to boost the robustness of our model, which utilizes temporal sequences to generate disturbance poses and hypothetical views to distin-guish dynamic objects with different directions that violate the photometric consistency. Experiments on the KITTI and the Make3d datasets reveal that our framework achieves state-of-the-art performance.",
        "primary_area": "",
        "author": "Tianyu Zhang;Dongchen Zhu;Guanghui Zhang;Wenjun Shi;Yanqing Liu;Xiaolin Zhang;Jiamao Li;Tianyu Zhang;Dongchen Zhu;Guanghui Zhang;Wenjun Shi;Yanqing Liu;Xiaolin Zhang;Jiamao Li",
        "authorids": "/37089709069;/37086420004;/37086823762;/37086421586;/37086418759;/37085830972;/37086083391;/37089709069;/37086420004;/37086823762;/37086421586;/37086418759;/37085830972;/37086083391",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; University of Science and Technology of China, Hefei, Anhui, China; Xiongan Institute of Innovation, Xiongan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981595/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14497931970708280330&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;2;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Institute of Microsystem and Information Technology;University of Science and Technology of China;Xiongan Institute of Innovation",
        "aff_unique_dep": ";Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.sIMIT.ac.cn;http://www.ustc.edu.cn;",
        "aff_unique_abbr": "UCAS;SIMIT;USTC;",
        "aff_campus_unique_index": "0;0;1;1;1;2;3",
        "aff_campus_unique": "Beijing;Shanghai;Hefei;Xiongan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981584",
        "title": "Spectral Measurement Sparsification for Pose-Graph SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) is a critical capability in autonomous navigation, but in order to scale SLAM to the setting of \u201clifelong\u201d SLAM, particularly under memory or computation constraints, a robot must be able to determine what information should be retained and what can safely be forgotten. In graph-based SLAM, the number of edges (measurements) in a pose graph determines both the memory requirements of storing a robot's observations and the computational expense of algorithms deployed for performing state estimation using those observations; both of which can grow unbounded during long-term navigation. To address this, we propose a spectral approach for pose graph sparsification which maximizes the algebraic connectivity of the sparsified measurement graphs, a key quantity which has been shown to control the estimation error of pose graph SLAM solutions. Our algorithm, MAC (for maximizing algebraic connectivity), which is based on convex relaxation, is simple and computationally inexpensive, and admits formal post hoc performance guarantees on the quality of the solutions it provides. In experiments on benchmark pose-graph SLAM datasets, we show that our approach quickly produces high-quality sparsification results which retain the connectivity of the graph and, in turn, the quality of corresponding SLAM solutions, as compared to a baseline approach which does not consider graph connectivity.",
        "primary_area": "",
        "author": "Kevin J. Doherty;David M. Rosen;John J. Leonard;Kevin J. Doherty;David M. Rosen;John J. Leonard",
        "authorids": "/37085769742;/38252288400;/37329387400;/37085769742;/38252288400;/37329387400",
        "aff": "Massachusetts Institute of Technology (MIT), Boston, MA; Northeastern University, Boston, MA; Massachusetts Institute of Technology (MIT), Boston, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981584/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4196894481259474802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Northeastern University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "MIT;NEU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982255",
        "title": "Speed up of Wave-Driven Unmanned Surface Vehicle Using Passively Transformable Two-segment Foils",
        "track": "main",
        "status": "Poster",
        "abstract": "For wave-driven unmanned surface vehicles (WUSVs), utilizing oscillating foils is the most straightforward and common wave energy conversion mechanism. Improving the thrust of the oscillating foil to increase its speed can help WUSVs improve their maneuverability and shorten the completion of ocean missions. This paper proposes a novel transformable two-segment foil, improving the wave energy-converting efficiency to provide more average thrust in every wave cycle. We estimate their working effectiveness numerically with a simple model to verify that the design enhances foils' thrust force. The thrust enhancement was further confirmed by computational fluid dynamic (CFD) simulations, and we estimated the suitable values of parameters of the foils in several different common sea conditions in coastal waters by CFD simulations. We design and make two wave gliders with traditional and transformable two-segment foils and finish the speed enhancement experiments. The speed enhancement is verified, and transformable two-segment foils can increase the speed of WUSVs by 10% in similar sea conditions in experiments.",
        "primary_area": "",
        "author": "Lyucheng Xie;Hongzheng Cui;Tin Lun Lam;Lyucheng Xie;Hongzheng Cui;Tin Lun Lam",
        "authorids": "/37088996514;/37089662720;/37571111600;/37088996514;/37089662720;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, Guangdong, P.R.China; Engineering Faculty in Monash University, Melbourne, Australia; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, Guangdong, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982255/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9496608010581567546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Monash University",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS);Engineering Faculty",
        "aff_unique_url": "https://www.cuhk.edu.cn;https://www.monash.edu",
        "aff_unique_abbr": "CUHK;Monash",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Melbourne",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9981402",
        "title": "SpeedFolding: Learning Efficient Bimanual Folding of Garments",
        "track": "main",
        "status": "Poster",
        "abstract": "Folding garments reliably and efficiently is a long standing challenge in robotic manipulation due to the complex dynamics and high dimensional configuration space of garments. An intuitive approach is to initially manipulate the garment to a canonical smooth configuration before folding. In this work, we develop SpeedFolding, a reliable and efficient bimanual system, which given user-defined instructions as folding lines, manipulates an initially crumpled garment to (1) a smoothed and (2) a folded configuration. Our primary contribution is a novel neural network architecture that is able to predict pairs of gripper poses to parameterize a diverse set of bimanual action primitives. After learning from 4300 human- annotated and self-supervised actions, the robot is able to fold garments from a random initial configuration in under 120 s on average with a success rate of 93 %. Real-world experiments show that the system is able to generalize to unseen garments of different color, shape, and stiffness. While prior work achieved 3\u20136 Folds Per Hour (FPH), SpeedFolding achieves 30\u201340 FPH. See https://pantor.github.io/speedfolding for code, videos, and datasets.",
        "primary_area": "",
        "author": "Yahav Avigal;Lars Berscheid;Tamim Asfour;Torsten Kr\u00f6ger;Ken Goldberg;Yahav Avigal;Lars Berscheid;Tamim Asfour;Torsten Kr\u00f6ger;Ken Goldberg",
        "authorids": "/37088504860;/37085380166;/37295529100;/37283223400;/37273026700;/37088504860;/37085380166;/37295529100;/37283223400;/37273026700",
        "aff": "AUTOLab at UC Berkeley; Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); AUTOLab at UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981402/",
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5124394880990551681&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Karlsruhe Institute of Technology",
        "aff_unique_dep": "AUTOLab;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.kit.edu",
        "aff_unique_abbr": "UC Berkeley;KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9981717",
        "title": "Speeding Up Optimization-based Motion Planning through Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning collision-free motions for robots with many degrees of freedom is challenging in environments with complex obstacle geometries. Recent work introduced the idea of speeding up the planning by encoding prior experience of successful motion plans in a neural network. However, this \u201cneural motion planning\u201d did not scale to complex robots in unseen 3D environments as needed for real-world applications. Here, we introduce \u201cbasis point set\u201d, well-known in computer vision, to neural motion planning as a modern compact environment encoding enabling efficient supervised training networks that generalize well over diverse 3D worlds. Combined with a new elaborate training scheme, we reach a planning success rate of 100 %. We use the network to predict an educated initial guess for an optimization-based planner (OMP), which quickly converges to a feasible solution, massively outperforming random multi-starts when tested on previously unseen environments. For the DLR humanoid Agile Justin with 19 DoF and in challenging obstacle environments, optimal paths can be generated in 200 ms using only a single CPU core. We also show a first successful real-world experiment based on a high-resolution world model from an integrated 3D sensor.",
        "primary_area": "",
        "author": "Johannes Tenhumberg;Darius Burschka;Berthold B\u00e4uml;Johannes Tenhumberg;Darius Burschka;Berthold B\u00e4uml",
        "authorids": "/37088991157;/37267429200;/37295469600;/37088991157;/37267429200;/37295469600",
        "aff": "Deggendorf Institute of Technology, Germany; Technical University of Munich, Germany; Deggendorf Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981717/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6978415979922729273&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Deggendorf Institute of Technology;Technical University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.dit.de;https://www.tum.de",
        "aff_unique_abbr": "DIT;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981442",
        "title": "Speeding up POMDP Planning via Simplification",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider online planning in par-tially observable domains. Solving the corresponding POMDP problem is a very challenging task, particularly in an online setting. Our key contribution is a novel algorithmic approach, Simplified Information Theoretic Belief Space Planning (SITH-BSP), which aims to speed up POMDP planning considering belief-dependent rewards, without compromising the solution's accuracy. We do so by mathematically relating the simplified el-ements of the problem to the corresponding counterparts of the original problem. Specifically, we focus on belief simplification and use it to formulate bounds on the corresponding original belief-dependent rewards. These bounds in turn are used to perform branch pruning over the belief tree, in the process of extracting the optimal policy from this existing belief tree. We further introduce the notion of adaptive simplification, while re-using calculations between different simplification levels, and exploit it to prune, at each level in the belief tree, all branches but one. Therefore, our approach is guaranteed to find the optimal solution (policy) that corresponds to the given belief tree but with substantial speedup. As a second key contribution, we derive novel analytical bounds for differential entropy, considering a sampling-based belief representation, which we believe are of interest on their own. We validate our approach in simulation using these bounds and where simplification corresponds to reducing the number of samples, exhibiting a significant computational speedup while yielding the optimal solution for the given belief tree.",
        "primary_area": "",
        "author": "Ori Sztyglic;Vadim Indelman;Ori Sztyglic;Vadim Indelman",
        "authorids": "/37089659368;/37541538000;/37089659368;/37541538000",
        "aff": "Department of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981442/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3875047356829550807&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981808",
        "title": "Spotforming by NMF Using Multiple Microphone Arrays",
        "track": "main",
        "status": "Poster",
        "abstract": "Sound source separation is a method to extract a target sound source from a mixture of various sound sources and noises. One of the typical sound source separation methods is beamforming, which can separate sound sources by direction based on the phase difference between channels from the recorded signal of a microphone array, a multi-channel recording system. However, beamforming is a direction-based method and cannot separate multiple sources in the same direction. In this paper, we propose a method for separating sources in the same direction using multiple microphone arrays. The proposed method performs beamforming using multiple microphone arrays and extracts only the target sound source from the separated sound by the Non-negative Matrix Factorization (NMF), thus reducing the influence of other sources in the same direction. In this paper, to investigate the effectiveness of the proposed method, experiments were conducted assuming the presence of another sound source in the same direction from an arbitrary microphone array. The results show that the proposed method outperforms the delay-sum method in a simulation environment. In addition, experiments were conducted in a real environment to verify the effect of reverberation.",
        "primary_area": "",
        "author": "Yasuhiro Kagimoto;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai;Yasuhiro Kagimoto;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai",
        "authorids": "/37089660584;/37667838300;/37086508904;/37274046900;/37089660584;/37667838300;/37086508904;/37274046900",
        "aff": "Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Honda Research Institute Japan Co., Ltd., Saitama, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981808/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4373285180843644905&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Honda Research Institute Japan Co., Ltd.",
        "aff_unique_dep": "Department of Systems and Control Engineering;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "Titech;HRI-JP",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Tokyo;Saitama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981890",
        "title": "Stabilization of Tangent and Normal Contact Forces for a Quadrotor subject to Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "Force exertion, object manipulation, and interaction are novel trending research topics of autonomous flying robots that can yield hoovering. Moreover, specifically with quadrotors, the vibration caused by the high natural frequency of rotating propellers exacerbates the problem of maintaining contact and exerting force against a rigidly fixed object. This contact vibration transfers back kinetic energy to the quadrotor that, in worst-case scenarios, surpasses its flying capabilities, which may lead to a crash. This paper studies the problem of aerial contact stabilization of a quadrotor equipped with a hemispherical deformable tip, which accommodates contact forces at a lower frequency. Thus two phenomena not studied in the literature arise: the rolling motion, and the deformation at contact. The contact force stabilization restores the effects of deformation while simultaneously endowing rolling by controlling a tangent constrained force. A model-free continuous attitude fractional controller to guarantee finite-time attitude stabilization is proposed. The residual coupled nonlinear dynamics yields the desired attitude corresponding to a given contact force; thus, force stabilization is achieved. Finally, experimental results are presented to assess the performance of the proposed approach.",
        "primary_area": "",
        "author": "C. Izaguirre-Espinosa;A. Mu\u00f1oz-Vazquez;A. S\u00e1nchez-Orta;V. Parra-Vega;R. Garcia-Rodriguez;P. Castillo;D. Arregu\u00edn-Jasso;C. Izaguirre-Espinosa;A. Mu\u00f1oz-Vazquez;A. S\u00e1nchez-Orta;V. Parra-Vega;R. Garcia-Rodriguez;P. Castillo;D. Arregu\u00edn-Jasso",
        "authorids": "/38488444400;/37072033500;/37085499832;/38273688800;/38273643000;/37273262000;/37089659605;/38488444400;/37072033500;/37085499832;/38273688800;/38273643000;/37273262000;/37089659605",
        "aff": "Faculty of Chemistry Sciences, Autonomous University of Nuevo Leon, Mexico; College of Engineering, Texas A&M Univ., McAllen, USA; Robotics and Advanced Manufacturing Division, Center for Research and Advanced Studies (Cinvestav), Saltillo, Mexico; Robotics and Advanced Manufacturing Division, Center for Research and Advanced Studies (Cinvestav), Saltillo, Mexico; Aeronautical Engineering Program and Postgraduate Program in Aerospacial Engineering, Universidad Politecnica Metropolitana de Hidalgo, Mexico; CNRS UMR 7253 Heudiasyc Lab., CS 60319, Sorbonne Universit\u00e9s, Universit\u00e9 deTechnologie de Compi\u00e9gne, Compi\u00e9gne Cedex, France; Robotics and Advanced Manufacturing Division, Center for Research and Advanced Studies (Cinvestav), Saltillo, Mexico",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981890/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10883517447030317695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;3;4;2",
        "aff_unique_norm": "Autonomous University of Nuevo Leon;Texas A&M University;Center for Research and Advanced Studies (Cinvestav);Universidad Politecnica Metropolitana de Hidalgo;CNRS UMR 7253 Heudiasyc Lab",
        "aff_unique_dep": "Faculty of Chemistry Sciences;College of Engineering;Robotics and Advanced Manufacturing Division;Aeronautical Engineering Program and Postgraduate Program in Aerospacial Engineering;Heudiasyc Lab",
        "aff_unique_url": "https://www.uanl.mx;https://engineering.tamu.edu;https://www.cinvestav.mx;;",
        "aff_unique_abbr": "UANL;TAMU;Cinvestav;;",
        "aff_campus_unique_index": "1;2;2;3;2",
        "aff_campus_unique": ";McAllen;Saltillo;Compi\u00e9gne",
        "aff_country_unique_index": "0;1;0;0;0;2;0",
        "aff_country_unique": "Mexico;United States;France"
    },
    {
        "id": "9981109",
        "title": "State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections",
        "track": "main",
        "status": "Poster",
        "abstract": "Traversing intersections is a challenging problem for autonomous vehicles, especially when the intersections do not have traffic control. Recently deep reinforcement learning has received massive attention due to its success in dealing with autonomous driving tasks. In this work, we address the problem of traversing unsignalized intersections using a novel curriculum for deep reinforcement learning. The proposed curriculum leads to: 1) A faster training process for the reinforcement learning agent, and 2) Better performance compared to an agent trained without curriculum. Our main contribution is two-fold: 1) Presenting a unique curriculum for training deep reinforcement learning agents, and 2) demonstrating the performance improvement using the proposed curriculum in the unsignalized intersection traversal task. The framework expects processed observations of the surroundings from the perception system of the autonomous vehicle. We test our method in the CommonRoad motion planning simulator on T-intersections and four-way intersections.",
        "primary_area": "",
        "author": "Shivesh Khaitan;John M. Dolan;Shivesh Khaitan;John M. Dolan",
        "authorids": "/37088994385;/37283756800;/37088994385;/37283756800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981109/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14252974820456663164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981899",
        "title": "Steady-State Manifold of Riderless Motorcycles",
        "track": "main",
        "status": "Poster",
        "abstract": "Keeping balance is one of the most important tasks of a motorcycle. The steady-state manifold is proposed in this paper to explore the inherent dynamics and the balance properties of a riderless motorcycle. The dynamic and kinematic characteristics are analyzed based on the manifold and are validated by simulation. Comparing to traditional control method, the usefulness of the manifold in control is shown through the design of a novel control strategy. Furthermore, based on the analysis and the simulation, the potential applications of the manifold for control and planning are summarized.",
        "primary_area": "",
        "author": "Yu Tian;Zhang Chen;Yang Deng;Boyi Wang;Bin Liang;Yu Tian;Zhang Chen;Yang Deng;Boyi Wang;Bin Liang",
        "authorids": "/37088843469;/37086021314;/37086955857;/37088642120;/37270783900;/37088843469;/37086021314;/37086955857;/37088642120;/37270783900",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981899/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3934327459120113108&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982011",
        "title": "Stochastic Games with Stopping States and their Application to Adversarial Motion Planning Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "We model a finite horizon decision making process between an ego and a non-ego vehicle, where the non-ego vehicle has a certain probability of moving adversarially over each planning stage. The adversarial intent of the non-ego vehicle is inferred only when a particular set of actions are performed by both vehicles, thereby creating a stopping state. We term such a decision-making process as a multi-stage stochastic zero-sum game (SSG) with stopping states, i.e., once adversarial intent is ascertained, the non-ego vehicle continues to choose its actions adversarially for the remaining stages of the interaction. We analytically characterize the Nash equilibria of this game for the case of two actions per player. We then demonstrate this approach via two autonomous motion planning applications. The first involves maintaining a safe distance from a non-ego vehicle ahead, modeled using fixed stage costs. The second involves safe lane-changing with costs that are stage dependent. In both scenarios, we provide a comparison between the analytic/simulated and experimental results using ground robots.",
        "primary_area": "",
        "author": "Sandeep Banik;Shaunak D. Bopardikar;Sandeep Banik;Shaunak D. Bopardikar",
        "authorids": "/37086851355;/37076274700;/37086851355;/37076274700",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982011/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5448233403773261618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981646",
        "title": "Stubborn: A Strong Baseline for Indoor Object Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a strong baseline that surpasses the performance of previously published methods on the Habitat Challenge task of navigating to a target object in indoor environments. Our method is motivated from primary failure modes of prior state-of-the-art: poor exploration, inaccurate object identification, and agent getting trapped due to imprecise map construction. We make three contributions to mitigate these issues: (i) First, we show that existing map-based methods fail to effectively use semantic clues for exploration. We present a semantic-agnostic exploration strategy (called Stubborn) without any learning that surprisingly outperforms prior work. (ii) We propose a strategy for integrating temporal information to improve object identification. (iii) Lastly, due to inaccurate depth observation the agent often gets trapped in small regions. We develop a multi-scale collision map for obstacle identification that mitigates this issue. Website: https://github.com/Improbable-AI/Stubborn",
        "primary_area": "",
        "author": "Haokuan Luo;Albert Yue;Zhang-Wei Hong;Pulkit Agrawal;Haokuan Luo;Albert Yue;Zhang-Wei Hong;Pulkit Agrawal",
        "authorids": "/37089661386;/37089660374;/37089660194;/37085611190;/37089661386;/37089660374;/37089660194;/37085611190",
        "aff": "Department of Electrical Engineering and Computer Science at MIT, Improbable AI Lab; Department of Electrical Engineering and Computer Science at MIT, Improbable AI Lab; Department of Electrical Engineering and Computer Science at MIT, Improbable AI Lab; Department of Electrical Engineering and Computer Science at MIT, Improbable AI Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981646/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6158635867528490217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981324",
        "title": "Subspace-based Feature Alignment for Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous agents need to perceive the world in a robust way, such that the shift in data distribution does not lead to faulty perception results. When agents cannot be trained with abundant data, agents may need to operate on real world environments while trained on simulated data, and suffer from domain shift. This paper proposes an effective and robust unsupervised domain adaptation (UDA) method that can resolve these situations. In the UDA setup, we are given a labeled source domain and an unlabeled target domain that share the same set of classes but are sampled from different distributions. This domain shift prevents agents which employ deep neural networks from generalizing well on the target domain. Recent methods adopt the strategy of self-training the networks with pseudo labeled target samples. However, falsely labeled samples cause negative transfer and deteriorate generalization of a network. to reduce negative transfer we propose an algorithm that can filter the pseudo labels, and use the filtered labels to align the domains in the feature space. The samples whose labels have not passed the filtering process can be used as an index to tune the hyperparameters of our method. Across various benchmarks, we validate the performance of our method. Especially, our method achieves strong performance on the synthetic-to-real adaptation scenario.",
        "primary_area": "",
        "author": "Eojindl Yi;Junmo Kim;Eojindl Yi;Junmo Kim",
        "authorids": "/37088689760;/37407301400;/37088689760;/37407301400",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), Korea; Korea Advanced Institute of Science and Technology (KAIST), Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981324/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:wzSuEtUTQmoJ:scholar.google.com/&scioq=Subspace-based+Feature+Alignment+for+Unsupervised+Domain+Adaptation&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981943",
        "title": "Suppressing Delay-Induced Oscillations in Physical Human-Robot Interaction with an Upper-Limb Exoskeleton using Rate-Limiting",
        "track": "main",
        "status": "Poster",
        "abstract": "In physical human-robot interaction (pHRI) enabled by admittance control, delay-induced oscillations arising from both the neuromuscular time-delays of the human and electromechanical delays of the robot can cause unsafe instability in the system. This study presents and evaluates rate-limiting as a means to overcome such instability, and provides a new perspective on how rate-limiting can benefit pHRI. Specifically, a rate-limited and time-delayed human-in-the-loop (HITL) model is analyzed to show not only how the rate-limiter can transform an unstable equilibrium (due to time-delay) into a stable limit-cycle, but also how a desired upper-bound on the range of persistent oscillations can be achieved by appropriately setting the rate-limiter threshold. In addition, a study involving 10 subjects and the EXO-UL8 upper-limb exoskeleton, and consisting of 16 trials - 4 rate-limiter thresholds by 4 time-delays - is performed to: (1) validate the relationships between time-delays, rate-limits, and position bounds on persistent oscillations, and (2) demonstrate the effectiveness of rate-limiting for recovery from delay-induced oscillations without interfering with regular operation. Agreement of experimental results with the theoretical developments supports the feasibility of incorporating rate-limiting in admittance-controlled pHRI systems as a safety mechanism.",
        "primary_area": "",
        "author": "Jianwei Sun;Peter Walker Ferguson;Jacob Rosen;Jianwei Sun;Peter Walker Ferguson;Jacob Rosen",
        "authorids": "/37086921387;/37086069264;/37283876400;/37086921387;/37086069264;/37283876400",
        "aff": "Department of Mechanical and Aeropsace Engineering, University of California, Los Angeles (UCLA), USA; Department of Mechanical and Aeropsace Engineering, University of California, Los Angeles (UCLA), USA; Department of Mechanical and Aeropsace Engineering, University of California, Los Angeles (UCLA), USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981943/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9761471285776290536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981722",
        "title": "SwitchHit: A Probabilistic, Complementarity-Based Switching System for Improved Visual Place Recognition in Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Maria Waheed;Michael Milford;Klaus McDonald-Maier;Shoaib Ehsan;Maria Waheed;Michael Milford;Klaus McDonald-Maier;Shoaib Ehsan",
        "authorids": "/37086943325;/37283633100;/38272117700;/37540520800;/37086943325;/37283633100;/38272117700;/37540520800",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981722/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8355330586887861997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9981064",
        "title": "Systematic Evaluation and Analysis on Hybrid Strategies of Automatic Agent Last-mile Delivery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on problems associated with the deployment of automatic agents for last-mile delivery. We propose a framework and methodology to systematically evaluate and compare different hybrid strategies. Performance metrics in agent noise, delivery time, energy consumption, coverage rate, package throughput, and system costs are defined rigorously and modeled mathematically. Using the methodology, we conduct a case study in the city of Boston for four agent delivery strategies, including a hybrid strategy proposed in this paper. The proposed strategy utilizes available space in public transits' cabins during off-peak hours to relocate the agent traveling start locations. Simulations and analyses show that hybrid strategies outperform the Agent-Only delivery strategy in terms of noise exposure, energy consumption, and coverage rate. The performance of hybrid strategies highly depends on the characteristics of the ground transportation methods accompanying agents. Thus, the methods of ground transportation should carefully be examined and selected for each case and strategy in real-world applications.",
        "primary_area": "",
        "author": "Xiaotong Zhang;Abdullatif Al Alsheikh;Kamal Youcef-Toumi;Xiaotong Zhang;Abdullatif Al Alsheikh;Kamal Youcef-Toumi",
        "authorids": "/37089637191;/37089659048;/38271700200;/37089637191;/37089659048;/38271700200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Center for Complex Engineering Systems at KACST and MIT, Riyadh, Saudi Arabia; Center for Complex Engineering Systems at KACST and MIT, Riyadh, Saudi Arabia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981064/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12407367031267973338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;King Abdulaziz City for Science and Technology (KACST)",
        "aff_unique_dep": "Department of Mechanical Engineering;Center for Complex Engineering Systems",
        "aff_unique_url": "https://web.mit.edu;https://www.kacst.edu.sa",
        "aff_unique_abbr": "MIT;KACST",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;Riyadh",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;Saudi Arabia"
    },
    {
        "id": "9981739",
        "title": "T-PRM: Temporal Probabilistic Roadmap for Path Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planners are widely used in robotics due to their simplicity, flexibility and computational efficiency. However, in their most basic form, these algorithms operate under the assumption of static scenes and lack the ability to avoid collisions with dynamic (i.e. moving) obstacles. This raises safety concerns, limiting the range of possible applications of mobile robots in the real world. Motivated by these challenges, in this work we present Temporal-PRM, a novel sampling-based path-planning algorithm that performs obstacle avoidance in dynamic environments. The proposed approach extends the original Probabilistic Roadmap (PRM) with the notion of time, generating an augmented graph-like structure that can be efficiently queried using a time-aware variant of the A* search algorithm, also introduced in this paper. Our design maintains all the properties of PRM, such as the ability to perform multiple queries and to find smooth paths, while circumventing its downside by enabling collision avoidance in highly dynamic scenes with a minor increase in the computational cost. Through a series of challenging experiments in highly cluttered and dynamic environments, we demonstrate that the proposed path planner outperforms other state-of-the-art sampling-based solvers. Moreover, we show that our algorithm can run onboard a flying robot, performing obstacle avoidance in real time.",
        "primary_area": "",
        "author": "Matthias H\u00fcppi;Luca Bartolomei;Ruben Mascaro;Margarita Chli;Matthias H\u00fcppi;Luca Bartolomei;Ruben Mascaro;Margarita Chli",
        "authorids": "/37089660916;/37087322350;/37086455262;/37546501900;/37089660916;/37087322350;/37086455262;/37546501900",
        "aff": "Vision For Robotics Lab, ETH, Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH, Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH, Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981739/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3753986445847570826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision For Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981187",
        "title": "T3VIP: Transformation-based $3\\mathrm{D}$ Video Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous skill acquisition, robots have to learn about the physical rules governing the 3D world dynamics from their own past experience to predict and reason about plausible future outcomes. To this end, we propose a transformation-based 3D video prediction (T3VIP) approach that explicitly models the 3D motion by decomposing a scene into its object parts and predicting their corresponding rigid transformations. Our model is fully unsupervised, captures the stochastic nature of the real world, and the observational cues in image and point cloud domains constitute its learning signals. To fully leverage all the 2D and 3D observational signals, we equip our model with automatic hyperparameter optimization (HPO) to interpret the best way of learning from them. To the best of our knowledge, our model is the first generative model that provides an RGB-D video prediction of the future for a static camera. Our extensive evaluation with simulated and real-world datasets demonstrates that our formulation leads to interpretable 3D models that predict future depth videos while achieving on-par performance with 2D models on RGB video prediction. Moreover, we demonstrate that our model outperforms 2D baselines on visuomotor control. Videos, code, dataset, and pre-trained models are available at http://t3vip.cs.uni-freiburg.de.",
        "primary_area": "",
        "author": "Iman Nematollahi;Erick Rosete-Beas;Seyed Mahdi B. Azad;Raghu Rajan;Frank Hutter;Wolfram Burgard;Iman Nematollahi;Erick Rosete-Beas;Seyed Mahdi B. Azad;Raghu Rajan;Frank Hutter;Wolfram Burgard",
        "authorids": "/37086495410;/37089427788;/37089660570;/37089659668;/37270484900;/37270485300;/37086495410;/37089427788;/37089660570;/37089659668;/37270484900;/37270485300",
        "aff": "University of Freiburg; University of Freiburg; University of Freiburg; University of Freiburg; Bosch Center for AI; University of Technology Nuremberg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981187/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "University of Freiburg;Bosch Center for AI;Nuremberg University of Technology",
        "aff_unique_dep": ";Center for AI;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.bosch-ai.com;https://www.tu-nuernberg.de",
        "aff_unique_abbr": "UoF;BCAI;TUN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981029",
        "title": "TAE: A Semi-supervised Controllable Behavior-aware Trajectory Generator and Predictor",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory generation and prediction are two in-terwoven tasks that play important roles in planner evaluation and decision making for intelligent vehicles. Most existing methods focus on one of the two and are optimized to directly output the final generated/predicted trajectories, which only contain limited information for critical scenario augmentation and safe planning. In this work, we propose a novel behavior-aware Trajectory Autoencoder (TAE) that explicitly models drivers' behavior such as aggressiveness and intention in the latent space, using semi-supervised adversarial autoencoder and domain knowledge in transportation. Our model addresses trajectory generation and prediction in a unified architecture and benefits both tasks: the model can generate diverse, controllable and realistic trajectories to enhance planner op-timization in safety-critical and long-tailed scenarios, and it can provide prediction of critical behavior in addition to the final trajectories for decision making. Experimental results demonstrate that our method achieves promising performance on both trajectory generation and prediction.",
        "primary_area": "",
        "author": "Ruochen Jiao;Xiangguo Liu;Bowen Zheng;Dave Liang;Qi Zhu;Ruochen Jiao;Xiangguo Liu;Bowen Zheng;Dave Liang;Qi Zhu",
        "authorids": "/37088564560;/37088644108;/37085556082;/37089659778;/37085340663;/37088564560;/37088644108;/37085556082;/37089659778;/37085340663",
        "aff": "Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL, USA; Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL, USA; Pony.ai, Fremont, CA, USA; Pony.ai, Fremont, CA, USA; Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981029/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15326213427902881841&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Northwestern University;Pony.ai",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.northwestern.edu;https://www.pony.ai",
        "aff_unique_abbr": "NU;Pony.ai",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Evanston;Fremont",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981651",
        "title": "TEScalib: Targetless Extrinsic Self-Calibration of LiDAR and Stereo Camera for Automated Driving Vehicles with Uncertainty Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present TEScalib, a novel extrinsic self-calibration approach of LiDAR and stereo camera using the geometric and photometric information of surrounding environments without any calibration targets for automated driving vehicles. Since LiDAR and stereo camera are widely used for sensor data fusion on automated driving vehicles, their extrinsic calibration is highly important. However, most of the LiDAR and stereo camera calibration approaches are mainly target-based and therefore time consuming. Even the newly developed targetless approaches in last years are either inaccurate or unsuitable for driving platforms. To address those problems, we introduce TEScalib. By applying a 3D mesh reconstruction-based point cloud registration, the geometric information is used to estimate the LiDAR to stereo camera extrinsic parameters accurately and robustly. To calibrate the stereo camera, a photometric error function is builded and the LiDAR depth is involved to transform key points from one camera to another. During driving, these two parts are processed iteratively. Besides that, we also propose an uncertainty analysis for reflecting the reliability of the estimated extrinsic parameters. Our TEScalib approach evaluated on the KITTI dataset achieves very promising results.",
        "primary_area": "",
        "author": "Haohao Hu;Fengze Han;Frank Bieder;Jan-Hendrik Pauls;Christoph Stiller;Haohao Hu;Fengze Han;Frank Bieder;Jan-Hendrik Pauls;Christoph Stiller",
        "authorids": "/37086351628;/37089659173;/37088649040;/37086547128;/37284652100;/37086351628;/37089659173;/37088649040;/37086547128;/37284652100",
        "aff": "Institute of Measurement and Control, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Measurement and Control, Karlsruhe Institute of Technology, Karlsruhe, Germany; Mobile Perception Systems Department, FZI Research Center for Information Technology, Karlsruhe, Germany; Institute of Measurement and Control, Karlsruhe Institute of Technology, Karlsruhe, Germany; Mobile Perception Systems Department, FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981651/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6427240824731750592&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;FZI Research Center for Information Technology",
        "aff_unique_dep": "Institute of Measurement and Control;Mobile Perception Systems Department",
        "aff_unique_url": "https://www.kit.edu;https://www.fzi.de",
        "aff_unique_abbr": "KIT;FZI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981992",
        "title": "TIGRIS: An Informed Sampling-based Algorithm for Informative Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Informative path planning is an important and challenging problem in robotics that remains to be solved in a manner that allows for wide-spread implementation and real-world practical adoption. Among various reasons for this, one is the lack of approaches that allow for informative path planning in high-dimensional spaces and non-trivial sensor constraints. In this work we present a sampling-based approach that allows us to tackle the challenges of large and high-dimensional search spaces. This is done by performing informed sampling in the high-dimensional continuous space and incorporating potential information gain along edges in the reward estimation. This method rapidly generates a global path that maximizes information gain for the given path budget constraints. We discuss the details of our implementation for an example use case of searching for multiple objects of interest in a large search space using a fixed-wing UAV with a forward-facing camera. We compare our approach to a sampling-based planner baseline and demonstrate how our contributions allow our approach to consistently out-perform the baseline by 18.0%. With this we thus present a practical and generalizable informative path planning framework that can be used for very large environments, limited budgets, and high dimensional search spaces, such as robots with motion constraints or high-dimensional configuration spaces. [Code]aaCodebase: https://github.com/castacks/tigris [Video]bbVideo: https://youtu.be/bMw5nUGL5GQ",
        "primary_area": "",
        "author": "Brady Moon;Satrajit Chatterjee;Sebastian Scherer;Brady Moon;Satrajit Chatterjee;Sebastian Scherer",
        "authorids": "/37086448648;/37089663371;/37584159000;/37086448648;/37089663371;/37584159000",
        "aff": "Robotics Institute, School of Computer Science at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981992/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16002954547985317432&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982100",
        "title": "TIP: Task-Informed Motion Prediction for Intelligent Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "When predicting trajectories of road agents, motion predictors often approximate the future distribution by a limited number of samples. This constraint requires the predictors to generate samples that best support the task given task specifications. However, existing predictors are often optimized and evaluated via task-agnostic measures without accounting for the use of predictions in downstream tasks, and thus could result in sub-optimal task performance. In this paper, we propose a task-informed motion prediction model that better supports the tasks through its predictions by jointly reasoning about prediction accuracy and the utility of the downstream tasks during training. The task utility function is commonly used to evaluate task performance. It does not require the full task information, but rather a specification of the utility of the task, resulting in predictors that are tailored to different downstream tasks. We demonstrate our approach on two use cases of common decision making tasks and their utility functions, in the context of autonomous driving and parallel autonomy. Experiment results show that our predictor produces accurate predictions that improve the task performance by a large margin in both tasks when compared to task-agnostic baselines on the Waymo Open Motion dataset.",
        "primary_area": "",
        "author": "Xin Huang;Guy Rosman;Ashkan Jasour;Stephen G. McGill;John J. Leonard;Brian C. Williams;Xin Huang;Guy Rosman;Ashkan Jasour;Stephen G. McGill;John J. Leonard;Brian C. Williams",
        "authorids": "/37086595235;/37393688300;/37078643400;/37089259672;/37329387400;/37274902300;/37086595235;/37393688300;/37078643400;/37089259672;/37329387400;/37274902300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982100/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18344630526191615689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981062",
        "title": "Tactile Pattern Super Resolution with Taxel-based Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "In contrast to sophisticated means of visual su-per resolution (SR), not much work has been done in the tactile SR field. Existing tactile SR algorithms for taxel-based sensors mainly focus on enhancing the localization accuracy, and generally associate with a specific type of hardware, sometimes not applicable to generic taxel-based tactile sensors. Inspired by image SR, we investigate the tactile pattern SR in this paper, and present how to transform successful image SR schemes, e.g. Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN) to serve the tactile SR. We propose two tactile SR models, i.e. TactileSRCNN and TactileSRGAN, and establish a new tactile pattern SR dataset for model learning. The ground truth of high resolution (HR) tactile patterns in the dataset is obtained via multi-sampling (i.e. overlapping reception) and registration of low resolution (LR) sensor. One key contribution of this research lies in achieving \u00d7100 (from 3\u00d74\u00d74 to 40\u00d740) times tactile pattern SR with a one-time tapping of 3-axis taxel-based sensor. Different from existing tactile SR algorithms which improves the localization accuracy of a single contact point, the proposed scheme can provide multi-point contact detection to robotic applications.",
        "primary_area": "",
        "author": "Bing Wu;Qian Liu;Qiang Zhang;Bing Wu;Qian Liu;Qiang Zhang",
        "authorids": "/37089659851;/37713756900;/37307998800;/37089659851;/37713756900;/37307998800",
        "aff": "Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981062/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1487524998445518787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Dalian University of Technology",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "http://en.dlut.edu.cn/",
        "aff_unique_abbr": "DUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Dalian",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981273",
        "title": "Tactile Perception for Growing Robots via Discrete Curvature Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft, growing robots have the ability to conform to their environment and traverse highly curved paths that would typically prove challenging for other robot designs. As they navigate through these constrained and cluttered environments, there is often significant interaction between the robot and its surroundings. In this work, we propose a method to enable tactile perception for growing robots, which utilizes commercially available, flexible sensors that measure the curvature of the robot shape at multiple locations. Our method consists of both a pouch design to enable seamless integration of the sensors with the material of the growing robot, as well as an algorithm for determining the location of point contacts along the robot body. We validate our proposed approach experimentally using a 3.5 cm robot that can grow to be 53 cm long. We show that we can localize a force applied to various locations along its length with an average error of 3.444\\pm1.383.444\\pm1.38 cm when the robot is unactuated and 4.62\\pm 0.954.62\\pm 0.95 cm when the robot is actuated. Additionally, we characterize the minimum distance required for our tactile sensing approach to discriminate between two separate contact points along the robot body to be 23.5 cm. Finally, we apply our method to a growing robot exploring an unknown environment and show that we are able to effectively determine when and where the growing robot collides with an unknown obstacle.",
        "primary_area": "",
        "author": "Micah Bryant;Connor Watson;Tania K. Morimoto;Micah Bryant;Connor Watson;Tania K. Morimoto",
        "authorids": "/37089661583;/37088215479;/37085803241;/37089661583;/37088215479;/37085803241",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering and the Department of Surgery, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981273/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10614092854370506422&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981270",
        "title": "Tactile-Guided Dynamic Object Planar Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Planar pushing is a fundamental robot manipulation task with most algorithms built upon the quasi-static as-sumption. Under this assumption the end-effector should apply force on the pushed object along the full moving trajectory. This means that the target position must lie in the robot's workspace. To enable a robot to deliver objects outside of its workspace and facilitate faster delivery, the quasi-static assumption should be lifted in favour of dynamical manipulation. In this work, we propose a two-staged data-driven manipulation method to hit an unknown object to reach a target position. This expands the reachability of the manipulated object beyond the robot's workspace. The robot equipped with a tactile sensor first explores for the stable pushing region (SPR) on the given object by using a gain-scheduling PD control with the contact centre estimated to maintain full contact between the object and the end-effector. In the second stage, a learning-based approach is used to generate the impulse the object should receive at the SPR to reach a target sliding distance. The performance of proposed method is evaluated on a KUKA LBR iiwa 14 R820 robot manipulator and a XELA tactile sensor.",
        "primary_area": "",
        "author": "Boyuan Liang;Wenyu Liang;Yan Wu;Boyuan Liang;Wenyu Liang;Yan Wu",
        "authorids": "/37089230663;/37598507800;/37085344977;/37089230663;/37598507800;/37085344977",
        "aff": "A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981270/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7134347139313581002&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "A*STAR Institute for Infocomm Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aistar.edu.sg",
        "aff_unique_abbr": "A*STAR I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981610",
        "title": "Tactile-Sensitive NewtonianVAE for High-Accuracy Industrial Connector Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "An industrial connector insertion task requires submillimeter positioning and grasp pose compensation for a plug. Thus, highly accurate estimation of the relative pose between a plug and socket is fundamental for achieving the task. World models are promising technologies for visuomotor control because they obtain appropriate state representation to jointly optimize feature extraction and latent dynamics model. Recent studies show that the Newto-nianVAE, a type of the world model, acquires latent space equivalent to mapping from images to physical coordinates. Proportional control can be achieved in the latent space of NewtonianVAE. However, applying NewtonianVAE to high-accuracy industrial tasks in physical environments is an open problem. Moreover, the existing framework does not consider the grasp pose compensation in the obtained latent space. In this work, we proposed tactile-sensitive Newtonian-VAE and applied it to a USB connector insertion with grasp pose variation in the physical environments. We adopted a GelSight-type tactile sensor and estimated the insertion position compensated by the grasp pose of the plug. Our method trains the latent space in an end-to-end manner, and no additional engineering and annotation are required. Simple proportional control is available in the obtained latent space. Moreover, we showed that the original NewtonianVAE fails in some situations, and demonstrated that domain knowledge induction improves model accuracy. This domain knowledge can be easily obtained using robot specification and grasp pose error measurement. We demonstrated that our proposed method achieved a 100% success rate and 0.3 mm positioning accuracy in the USB connector insertion task in the physical environment. It outperformed SOTA CNN-based two-stage goal pose regression with grasp pose compensation using coordinate transformation.",
        "primary_area": "",
        "author": "Ryo Okumura;Nobuki Nishio;Tadahiro Taniguchi;Ryo Okumura;Nobuki Nishio;Tadahiro Taniguchi",
        "authorids": "/37089696496;/37089663449;/37273806600;/37089696496;/37089663449;/37273806600",
        "aff": "Technology Division, Digital&AI Technology Center, Panasonic Holdings Corporation, Japan; R&D Division, Panasonic Connect Co., Ltd., Japan; Ritsumeikan University, College of Information Science and Engineering, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981610/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11218720944539566609&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Panasonic Holdings Corporation;Panasonic Connect Co., Ltd.;Ritsumeikan University",
        "aff_unique_dep": "Technology Division, Digital&AI Technology Center;R&D Division;College of Information Science and Engineering",
        "aff_unique_url": "https://www.panasonic.com;https://panasonic-connect.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Panasonic;Panasonic Connect;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981681",
        "title": "Tasho: A Python Toolbox for Rapid Prototyping and Deployment of Optimal Control Problem-Based Complex Robot Motion Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Tasho (Task specification for receding horizon control), an open-source Python toolbox that facilitates systematic programming of optimal control problem (OCP)-based robot motion skills. Separation-of-concerns is followed while designing the components of a motion skill, which promotes their modularity and reusability. This allows us to program complex motion tasks by configuring and composing simpler tasks. We provide templates for several basic tasks like point-to-point and end-effector path-following tasks to speed up prototyping. Internally, the task's symbolic expressions are computed using CasADi and the resulting OCP is transcribed using Rockit. A wide and growing range of mature open-source optimization solvers are supported for solving the OCP. Monitor functions can be easily specified and are automatically deployed with the motion skill, so that the generated motion skills can be easily embedded in a larger control architecture involving higher-level discrete controllers. The motion skills thus programmed can be directly deployed on robot platforms using the C-code generation capabilities of CasADi. The toolbox has been validated through several experiments both in simulation and on physical robot systems. The open-source toolbox can be accessed at: https://gitlab.kuleuven.be/meco-software/tasho",
        "primary_area": "",
        "author": "Ajay Suresha Sathya;Alejandro Astudillo;Joris Gillis;Wilm Decr\u00e9;Goele Pipeleers;Jan Swevers;Ajay Suresha Sathya;Alejandro Astudillo;Joris Gillis;Wilm Decr\u00e9;Goele Pipeleers;Jan Swevers",
        "authorids": "/37086528446;/37089308153;/38488765600;/37571970600;/37322615600;/37322616700;/37086528446;/37089308153;/38488765600;/37571970600;/37322615600;/37322616700",
        "aff": "Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium; Department of Mechanical Engineering, KU Leuven and the DMMS-M Core Lab, MECO Research Team, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981681/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5230759550951848348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Leuven",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9981076",
        "title": "Task Decoupling in Preference-based Reinforcement Learning for Personalized Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent robots designed to interact with hu-mans in the real world need to adapt to the preferences of different individuals. Preference-based reinforcement learning (RL) has shown great potential for teaching robots to learn personalized behaviors from interacting with humans with-out a meticulous, hand-crafted reward function, replaced by learning reward based on a human's preferences between two robot trajectories. However, poor feedback efficiency and poor exploration in the state and reward spaces make current preference-based RL algorithms perform poorly in complex interactive tasks. To improve the performance of preference-based RL, we incorporate prior knowledge of the task into preference-based RL. Specifically, we decouple the task from preference in human-robot interaction. We utilize a sketchy task reward derived from task priori to instruct robots to conduct more effective task exploration. Then a learned reward from preference-based RL is used to optimize the robot's policy to align with human preferences. In addition, these two parts are combined organically via reward shaping. The experimental results show that our method is a practical and effective solution for personalized human-robot interaction. Code is available at https://github.com/Wenminggong/PbRL_for_PHRI.",
        "primary_area": "",
        "author": "Mingjiang Liu;Chunlin Chen;Mingjiang Liu;Chunlin Chen",
        "authorids": "/37089603494;/37539322300;/37089603494;/37539322300",
        "aff": "Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing, China; Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981076/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18420525448885300477&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "Department of Control and Systems Engineering",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982177",
        "title": "Task-Oriented Contact Optimization for Pushing Manipulation with Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the problem of transporting an object along a desired planar trajectory by pushing with mobile robots. More specifically, we concentrate on establishing optimal contacts between the object and the robots to execute the given task with minimum effort. We present a task-oriented contact placement optimization strategy for object pushing that allows calculating optimal contact points minimizing the amplitude of forces required to execute the task. Exploiting the optimized contact configuration, a motion controller uses the computed contact forces in feed-forward and position error feedback terms to realize the desired trajectory tracking task. Simulations and real experiments results confirm the validity of our approach.",
        "primary_area": "",
        "author": "Filippo Bertoncelli;Mario Selvaggio;Fabio Ruggiero;Lorenzo Sabattini;Filippo Bertoncelli;Mario Selvaggio;Fabio Ruggiero;Lorenzo Sabattini",
        "authorids": "/37088507540;/37085859695;/37368775100;/37594737400;/37088507540;/37085859695;/37368775100;/37594737400",
        "aff": "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio, Emilia, Italy; Department of Electrical Engineering and Information Technology, University of Naples Fed-erico II, Napoli, Italy; Department of Electrical Engineering and Information Technology, University of Naples Fed-erico II, Napoli, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio, Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982177/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=212994371163250440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia;University of Naples Federico II",
        "aff_unique_dep": "Department of Sciences and Methods for Engineering (DISMI);Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.unimore.it;https://www.unina.it",
        "aff_unique_abbr": ";UNINA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Napoli",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9982271",
        "title": "Task-Space Control of Continuum Robots using Underactuated Discrete Rod Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Underactuation is a core challenge associated with controlling soft and continuum robots, which possess theoreti-cally infinite degrees of freedom, but few actuators. However, mm actuators may still be used to control a dynamic soft robot in an m-dimensional output task space. In this paper we develop a task-space control approach for planar continuum robots that is robust to modeling error and requires very little sensor information. The controller is based on a highly underactuated discrete rod mechanics model in maximal coordinates and does not require conversion to a classical robot dynamics model form. This promotes straightforward control design, implementation and efficiency. We perform input-output feedback linearization on this model, apply sliding mode control to increase robustness, and formulate an observer to estimate the full state from sparse output measurements. Simulation results show exact task-space reference tracking behavior can be achieved even in the presence of significant modeling error, inaccurate initial conditions, and output-only sensing.",
        "primary_area": "",
        "author": "Caleb Rucker;Eric J. Barth;Joshua Gaston;James C. Gallentine;Caleb Rucker;Eric J. Barth;Joshua Gaston;James C. Gallentine",
        "authorids": "/37086408294;/37285712300;/37089777587;/37089658864;/37086408294;/37285712300;/37089777587;/37089658864",
        "aff": "Department of Mechanical, Aerospace, and Biomedical Engineering, The University of Tennessee, Knoxville; Department of Mechanical Engineering, Vanderbilt University, Nashville; Department of Mechanical, Aerospace, and Biomedical Engineering, The University of Tennessee, Knoxville; Department of Mechanical Engineering, Vanderbilt University, Nashville",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982271/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5112145806007407309&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Tennessee;Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical, Aerospace, and Biomedical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utk.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "UT Knoxville;Vanderbilt",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Knoxville;Nashville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982216",
        "title": "Teaching Agents how to Map: Spatial Reasoning for Multi-Object Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of visual navigation, the capacity to map a novel environment is necessary for an agent to exploit its observation history in the considered place and efficiently reach known goals. This ability can be associated with spatial rea-soning, where an agent is able to perceive spatial relationships and regularities, and discover object characteristics. Recent work introduces learnable policies parametrized by deep neural networks and trained with Reinforcement Learning (RL). In classical RL setups, the capacity to map and reason spatially is learned end-to-end, from reward alone. In this setting, we introduce supplementary supervision in the form of auxiliary tasks designed to favor the emergence of spatial perception capabilities in agents trained for a goal-reaching downstream objective. We show that learning to estimate metrics quantifying the spatial relationships between an agent at a given location and a goal to reach has a high positive impact in Multi-Object Navigation settings. Our method significantly improves the performance of different baseline agents, that either build an explicit or implicit representation of the environment, even matching the performance of incomparable oracle agents taking ground-truth maps as input. A learning-based agent from the literature trained with the proposed auxiliary losses was the winning entry to the Multi-Object Navigation Challenge, part of the CVPR 2021 Embodied AI Workshop.",
        "primary_area": "",
        "author": "Pierre Marza;Laetitia Matignon;Olivier Simonin;Christian Wolf;Pierre Marza;Laetitia Matignon;Olivier Simonin;Christian Wolf",
        "authorids": "/37088454525;/38308049100;/37329541300;/37285119900;/37088454525;/38308049100;/37329541300;/37285119900",
        "aff": "LIRIS, UMR CNRS 5205, Universit\u00e9 de Lyon, INSA-Lyon, Villeurbanne, France; UCBL, CNRS, INSA-Lyon, LIRIS, UMR5205, Univ Lyon, Villeurbanne, France; INSA Lyon, CITI Lab, INRIA Chroma team, Villeurbanne, France; Naver Labs Europe, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982216/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18348417535253727914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Universit\u00e9 de Lyon;Universite Claude Bernard Lyon 1;INSA Lyon;NAVER LABS Europe",
        "aff_unique_dep": "LIRIS;;CITI Lab, INRIA Chroma team;",
        "aff_unique_url": "https://www.universite-lyon.fr;https://www.ucbl.fr;https://www.insa-lyon.fr;https://labs.naver.com",
        "aff_unique_abbr": "UDL;UCBL;INSA Lyon;NLE",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Lyon;Villeurbanne;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981964",
        "title": "Teaching Robots to Span the Space of Functional Expressive Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Our goal is to enable robots to perform functional tasks in emotive ways, be it in response to their users' emotional states, or expressive of their confidence levels. Prior work has proposed learning independent cost functions from user feedback for each target emotion, so that the robot may optimize it alongside task and environment specific objectives for any situation it encounters. However, this approach is inefficient when modeling multiple emotions and unable to generalize to new ones. In this work, we leverage the fact that emotions are not independent of each other: they are related through a latent space of Valence-Arousal-Dominance (VAD). Our key idea is to learn a model for how trajectories map onto VAD with user labels. Considering the distance between a trajectory's mapping and a target VAD allows this single model to represent cost functions for all emotions. As a result 1) all user feedback can contribute to learning about every emotion; 2) the robot can generate trajectories for any emotion in the space instead of only a few predefined ones; and 3) the robot can respond emotively to user-generated natural language by mapping it to a target VAD. We introduce a method that interactively learns to map trajectories to this latent space and test it in simulation and in a user study. In experiments, we use a simple vacuum robot as well as the Cassie biped.",
        "primary_area": "",
        "author": "Arjun Sripathy;Andreea Bobu;Zhongyu Li;Koushil Sreenath;Daniel S. Brown;Anca D. Dragan;Arjun Sripathy;Andreea Bobu;Zhongyu Li;Koushil Sreenath;Daniel S. Brown;Anca D. Dragan",
        "authorids": "/37088999177;/37088414876;/37088691308;/37563179200;/38478370100;/37960625200;/37088999177;/37088414876;/37088691308;/37563179200;/38478370100;/37960625200",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; University of Utah; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981964/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3329304827961277063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;University of Utah",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.utah.edu",
        "aff_unique_abbr": "UC Berkeley;Utah",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982043",
        "title": "Temporal Context for Robust Maritime Obstacle Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust maritime obstacle detection is essential for fully autonomous unmanned surface vehicles (USVs). The currently widely adopted segmentation-based obstacle detection methods are prone to misclassification of object reflections and sun glitter as obstacles, producing many false positive detections, effectively rendering the methods impractical for USV navigation. However, water-turbulence-induced temporal appearance changes on object reflections are very distinctive from the appearance dynamics of true objects. We harness this property to design WaSR-T, a novel maritime obstacle detection network, that extracts the temporal context from a sequence of recent frames to reduce ambiguity. By learning the local temporal characteristics of object reflection on the water surface, WaSR-T substantially improves obstacle detection accuracy in the presence of reflections and glitter. Compared with existing single-frame methods, WaSR-T reduces the number of false positive detections by 41% overall and by over 53% within the danger zone of the boat, while preserving a high recall, and achieving new state-of-the-art performance on the challenging MODS maritime obstacle detection benchmark. The code, pretrained models and extended datasets are available at: https://github.com/lojzezust/WaSR-T",
        "primary_area": "",
        "author": "Lojze \u017dust;Matej Kristan;Lojze \u017dust;Matej Kristan",
        "authorids": "/37089300749;/37395968400;/37089300749;/37395968400",
        "aff": "Faculty of Computer and Information Science, University of Ljubljana, Slovenia; Faculty of Computer and Information Science, University of Ljubljana, Slovenia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982043/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8935909483316081725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Ljubljana",
        "aff_unique_dep": "Faculty of Computer and Information Science",
        "aff_unique_url": "https://www.fcis.unilj.si",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Slovenia"
    },
    {
        "id": "9981624",
        "title": "Temporal Logic Path Planning under Localization Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to find the optimal control strategy for a robot using prior information of localization that maximizes the probability of satisfaction of a temporal logic specification while considering the uncertainty in both motion and sensing, two major causes for localization uncertainty. The specifications are given in the probabilistic computation tree logic (PCTL) formulae over a set of propositions, which capture the presence of the robot in some key locations in the environment. A computation model that can deal with the uncertainty in both motion and sensing is the Partially Observable Markov Decision Process (POMDP), which is computationally expensive. We approximate the underlying POMDP using Augmented Markov Decision Process (AMDP) and present a control synthesis algorithm for AMDP. We carry out numerous experiments on workspaces with sizes up to 100 \u00d7 100 and three different PCTL specifications to evaluate the efficacy of our technique. Experimental results show that our technique for computing robot control policy using localization prior can deal with localization uncertainty effectively and scale to large environments.",
        "primary_area": "",
        "author": "Amit Dhyani;Indranil Saha;Amit Dhyani;Indranil Saha",
        "authorids": "/37089659913;/37542496500;/37089659913;/37542496500",
        "aff": "Department of Computer Science and Engineering, IIT Kanpur, India; Department of Computer Science and Engineering, IIT Kanpur, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981624/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:sQ4kGejb8KIJ:scholar.google.com/&scioq=Temporal+Logic+Path+Planning+under+Localization+Uncertainty&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9981942",
        "title": "TerraPN: Unstructured Terrain Navigation using Online Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present TerraPN, a novel method that learns the surface properties (traction, bumpiness, deformability, etc.) of complex outdoor terrains directly from robot-terrain interactions through self-supervised learning, and uses it for autonomous robot navigation. Our method uses RGB images of terrain surfaces and the robot's velocities as inputs, and the IMU vibrations and odometry errors experienced by the robot as labels for self-supervision. Our method computes a surface cost map that differentiates smooth, high-traction surfaces (low navigation costs) from bumpy, slippery, deformable surfaces (high navigation costs). We compute the cost map by non-uniformly sampling patches from the input RGB image by detecting boundaries between surfaces resulting in low inference times (47.27% lower) compared to uniform sampling and existing segmentation methods. We present a novel navigation algorithm that accounts for a surface's cost, computes cost-based acceleration limits for the robot, and dynamically feasible, collision-free trajectories. TerraPN's surface cost prediction can be trained in \u223c 25 minutes for five different surfaces, compared to several hours for previous learning-based segmentation methods. In terms of navigation, our method outperforms previous works in terms of success rates (up to 35.84% higher), vibration cost of the trajectories (up to 21.52% lower), and slowing the robot on bumpy, deformable surfaces (up to 46.76% slower) in different scenarios.",
        "primary_area": "",
        "author": "Adarsh Jagan Sathyamoorthy;Kasun Weerakoon;Tianrui Guan;Jing Liang;Dinesh Manocha;Adarsh Jagan Sathyamoorthy;Kasun Weerakoon;Tianrui Guan;Jing Liang;Dinesh Manocha",
        "authorids": "/37086924122;/37089653638;/37088414623;/37088504802;/37267825600;/37086924122;/37089653638;/37088414623;/37088504802;/37267825600",
        "aff": "Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981942/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3824427282601282550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "University of Maryland, College Park;University of Maryland",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu;https://www/umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981969",
        "title": "Terrain-Adaptive, ALIP-Based Bipedal Locomotion Controller via Model Predictive Control and Virtual Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a gait controller for bipedal robots to achieve highly agile walking over various terrains given local slope and friction cone information. Without these considerations, untimely impacts can cause a robot to trip and inadequate tangential reaction forces at the stance foot can cause slippages. We address these challenges by combining, in a novel manner, a model based on an Angular Momentum Linear Inverted Pendulum (ALIP) and a Model Predictive Control (MPC) foot placement planner that is executed by the method of virtual constraints. The process starts with abstracting from the full dynamics of a Cassie 3D bipedal robot, an exact low-dimensional representation of its center of mass dynamics, parameterized by angular momentum. Under a piecewise planar terrain assumption and the elimination of terms for the angular momentum about the robot's center of mass, the centroidal dynamics about the contact point become linear and have dimension four. Importantly, we include the intra-step dynamics at uniformly-spaced intervals in the MPC formulation so that realistic workspace constraints on the robot's evolution can be imposed from step-to-step. The output of the low-dimensional MPC controller is directly implemented on a high-dimensional Cassie robot through the method of virtual constraints. In experiments, we validate the performance of our control strategy for the robot on a variety of surfaces with varied inclinations and textures.",
        "primary_area": "",
        "author": "Grant Gibson;Oluwami Dosunmu-Ogunbi;Yukai Gong;Jessy Grizzle;Grant Gibson;Oluwami Dosunmu-Ogunbi;Yukai Gong;Jessy Grizzle",
        "authorids": "/37089661000;/37089661655;/37086962231;/37277141500;/37089661000;/37089661655;/37086962231;/37277141500",
        "aff": "Robotics Department, College of Engineering, University of Michigan, Ann Arbor, MI, USA; Robotics Department, College of Engineering, University of Michigan, Ann Arbor, MI, USA; Robotics Department, College of Engineering, University of Michigan, Ann Arbor, MI, USA; Robotics Department, College of Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981969/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3394564676260501049&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Department",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982136",
        "title": "Terrain-Aware Learned Controllers for Sampling-Based Kinodynamic Planning over Physically Simulated Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores learning an effective controller for improving the efficiency of kinodynamic planning for vehicular systems navigating uneven terrains. It describes the pipeline for training the corresponding controller and using it for motion planning purposes. The training process uses a soft actor-critic approach with hindsight experience replay to train a model, which is parameterized by the incline of the robot's local terrain. This trained model is then used during the expansion process of an asymptotically optimal kinodynamic planner to generate controls that allow the robot to reach desired local states. It is also used to define a heuristic cost-to-go function for the planner via a wavefront operation that estimates the cost of reaching the global goal. The cost-to-go function is used both for selecting nodes for expansion as well as for generating local goals for the controller to expand towards. The accompanying experimental section applies the integrated planning solution on models of all-terrain robots in a variety of physically simulated terrains. It shows that the proposed terrain-aware controller and the proposed wavefront function based on the cost-to-go model enable motion planners to find solutions in less time and with lower cost than alternatives. An ablation study emphasizes the benefits of a learned controller that is parameterized by the incline of the robot's local terrain as well as of an incremental training process for the controller.",
        "primary_area": "",
        "author": "Troy McMahon;Aravind Sivaramakrishnan;Kushal Kedia;Edgar Granados;Kostas E. Bekris;Troy McMahon;Aravind Sivaramakrishnan;Kushal Kedia;Edgar Granados;Kostas E. Bekris",
        "authorids": "/37085505504;/37089195641;/37089661780;/37088505477;/37282424700;/37085505504;/37089195641;/37089661780;/37088505477;/37282424700",
        "aff": "Dept. of Computer Science, Rutgers University, NJ, USA; Dept. of Computer Science, Rutgers University, NJ, USA; Indian Institute of Technology, Kharagpur; Dept. of Computer Science, Rutgers University, NJ, USA; Dept. of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982136/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10787176268796190609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Rutgers University;Indian Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.rutgers.edu;https://www.iitkgp.ac.in",
        "aff_unique_abbr": "Rutgers;IIT Kharagpur",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "New Brunswick;Kharagpur",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9981789",
        "title": "Testing Service Robots in the Field: An Experience Report",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots are mobile autonomous robots, often operating in uncertain and difficult environments. While being increasingly popular, engineering service robots is challenging. Especially, evolving them from prototype to deployable product requires effective validation and verification, assuring the robot's correct and safe operation in the target environment. While testing is the most common validation and verification technique used in practice, surprisingly little is known about the actual testing practices and technologies used in the service robotics domain. We present an experience report on field testing of an industrial-strength service robot, as it transitions from lab experiments to an operational environment. We report challenges and solutions, and reflect on their effectiveness. Our long-term goal is to establish empirically-validated testing techniques for service robots. This experience report constitutes a necessary, but self-contained first step, exploring field testing practices in detail. Our data sources are detailed test artifacts and developer interviews. We model the field testing process and describe test-case design practices. We discuss experiences from performing these field tests over a 10-month test campaign.",
        "primary_area": "",
        "author": "Argentina Ortega;Nico Hochgeschwender;Thorsten Berger;Argentina Ortega;Nico Hochgeschwender;Thorsten Berger",
        "authorids": "/37089659579;/38228828900;/38625890400;/37089659579;/38228828900;/38625890400",
        "aff": "Ruhr University, Bochum, Germany; Hochschule Bonn-Rhein-Sieg, Germany; Ruhr University, Bochum, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981789/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2392846774482123983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ruhr University Bochum;Hochschule Bonn-Rhein-Sieg",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ruhr-uni-bochum.de;https://www.h-brs.de",
        "aff_unique_abbr": "RUB;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bochum;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982155",
        "title": "The Flatworm-like Mesh Robot WORMESH-II: Steering Control of Pedal Wave Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "WORMESH is a unique robot concept inspired by flatworm locomotion and its key feature is the use of multiple traveling waves for locomotion. This paper presents the steering method for anisotropic module configuration (AMC) of WORMESH-II based on the kinematics of skid steering of mobile robots. AMC of WORMESH-II used two parallel pedal waves to generate locomotion. The kinematic model of WORMESH-II shows its longitudinal and angular velocities depend on the summation and the difference of two synchronous left and right pedal waves amplitudes A_{l}A_{l} and A_{r}A_{r} respectively. When both pedal waves have the same amplitude, the robot moves on a straight line, whereas the trajectory becomes a curve for different wave amplitudes. The radius of curve trajectory is inversely proportional to \\vert A_{l}-A_{r}\\vert\\vert A_{l}-A_{r}\\vert. The proposed method was ineffective when A_{i}\\approx 0(i=l,\\ r)A_{i}\\approx 0(i=l,\\ r). The proposed method was confirmed by the dynamic simulation of WORMESH-II using a physics engine. Moreover, the recommended skid steering method was tested using the prototype and verified.",
        "primary_area": "",
        "author": "G.V.C. Rasanga;K. Hirashi;R. Hodoshima;S. Kotosaka;G.V.C. Rasanga;K. Hirashi;R. Hodoshima;S. Kotosaka",
        "authorids": "/37088812972;/37089507388;/37320222900;/37086731819;/37088812972;/37089507388;/37320222900;/37086731819",
        "aff": "Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, Saitama, JAPAN; Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, Saitama, JAPAN; Department of Mechanical Engineering, Saitama University, Saitama, JAPAN; Department of Mechanical Engineering, Saitama University, Saitama, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982155/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17814886590406244774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Saitama University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.saitama-u.ac.jp",
        "aff_unique_abbr": "Saitama U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Saitama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981360",
        "title": "The Good Grasp, the Bad Grasp, and the Plateau in Tactile-Based Grasp Stability Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Research around tactile sensing for grasp stability prediction in robotic manipulators continues to be popular, however few works are able to achieve a high classification accuracy. Due to simulation complexity, data-driven methods are often forced to rely on experimental data, yielding small, often unbalanced, data sets. In this work, the authors use a 3972 sample data set to explore the effects of the data set composition on the performance of a classifier. While maintaining a similar overall accuracy, the ability to recognize a grasp failure was significantly impacted by the composition of the data set. The authors propose an autonomous pipeline designed to generate more diverse failure grasps. On failure-rich data, a tactile-based classifier with a balanced training set achieved a classification accuracy of 84.68% while maintaining a recall of the grasp failure class of 76%. This represents a 71.79% improvement in recall over a model trained on a larger but unbalanced data set.",
        "primary_area": "",
        "author": "Jennifer Kwiatkowski;Mohammad Jolaei;Alexandre Bernier;Vincent Duchaine;Jennifer Kwiatkowski;Mohammad Jolaei;Alexandre Bernier;Vincent Duchaine",
        "authorids": "/37086302783;/37086938451;/37089447059;/37293913400;/37086302783;/37086938451;/37089447059;/37293913400",
        "aff": "Dept. of Automated Manufacturing Engineering, Ecole de technologie superieure, Montreal, Quebec, Canada; Dept. of Automated Manufacturing Engineering, Ecole de technologie superieure, Montreal, Quebec, Canada; Dept. of Automated Manufacturing Engineering, Ecole de technologie superieure, Montreal, Quebec, Canada; Dept. of Automated Manufacturing Engineering, Ecole de technologie superieure, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981360/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17865760383891929955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ecole de technologie superieure",
        "aff_unique_dep": "Dept. of Automated Manufacturing Engineering",
        "aff_unique_url": "https://www.etsmtl.ca",
        "aff_unique_abbr": "ETS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982150",
        "title": "The Predictive Kinematic Control Tree: Enhancing Teleoperation of Redundant Robots through Probabilistic User Models",
        "track": "main",
        "status": "Poster",
        "abstract": "When teleoperating complex robotic manipula-tors, operators often find it most natural to issue commands that dictate end effector movements in task space. If the robot has redundant degrees of freedom, the translation of this com-mand from task space into configuration space can affect the robot's maneuverability, smoothness of motion, and the general precision of the teleoperated system. In this paper, we propose a novel method for performing this translation that predicts future operator commands in order to choose joint motions that maintain maneuverability in future timesteps. We introduce a Predictive Kinematic Control Tree (PrediKCT) that optimizes joint movement in the nullspace of the Jacobian over multiple future timesteps by reasoning over probabilistic models of the human operator. In essence, PrediKCT builds out and evaluates a tree of possible future commands. We implement this system on two simulated and one physical 7 -degree-of-freedom robotic arms and characterize performance by analyzing robot motions produced through multiple command trajectories with differing user model accuracies and tree parameters, demonstrating benefits to path accuracy over both a minimum-norm joint velocity solution and local optimization of joint movement.",
        "primary_area": "",
        "author": "Connor Brooks;Daniel Szafir;Connor Brooks;Daniel Szafir",
        "authorids": "/37086576242;/37086231248;/37086576242;/37086231248",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of North Carolina at Chapel Hill",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982150/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13936817921483942889&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Colorado Boulder;University of North Carolina at Chapel Hill",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.unc.edu",
        "aff_unique_abbr": "CU Boulder;UNC Chapel Hill",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Boulder;Chapel Hill",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981399",
        "title": "The Probabilistic Robot Kinematics Model and its Application to Sensor Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots with elasticity in structural components can suffer from undesired end-effector positioning imprecision, which exceeds the accuracy requirements for successful manipulation. We present the Probabilistic-Product-Of-Exponentials robot model, a novel approach for kinematic modeling of robots. It does not only consider the robot's deterministic geometry but additionally models time-varying and configuration-dependent errors in a probabilistic way. Our robot model allows to propagate the errors along the kinematic chain and to compute their influence on the end-effector pose. We apply this model in the context of sensor fusion for manipulator pose correction for two different robotic systems. The results of a simulation study, as well as of an experiment, demonstrate that probabilistic configuration-dependent error modeling of the robot kinematics is crucial in improving pose estimation results.",
        "primary_area": "",
        "author": "Lukas Meyer;Klaus H. Strobl;Rudolph Triebel;Lukas Meyer;Klaus H. Strobl;Rudolph Triebel",
        "authorids": "/37086575022;/37273199100;/37542908700;/37086575022;/37273199100;/37542908700",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981399/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10000162402145919311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981657",
        "title": "The Relationship Between Incremental Changes in Orientation and Slip Speed Estimation Using the Fingerprint Effect",
        "track": "main",
        "status": "Poster",
        "abstract": "The fingerprint effect, wherein vibrations are produced with frequencies related to the speed of a surface sliding across fingerprint ridges and the period of those ridges, has been studied for use in both slip detection and texture recognition. Here, we use a simple bioinspired sensor with parallel, straight, fingerprint-like ridges and a single ferroelectric ceramic transducer to show that the fingerprint effect is orientation dependent and that, if the orientation is known, it can be used to estimate slip speed. Our results, obtained at sliding speeds of 15 mm/s, 20 mm/s, and 25 mm/s and orientations from 0\u00b0 \u2013 90\u00b0, clearly demonstrate this dependence. Additionally, we use our results to run a simulation, using MATLAB software, of real-time slip speed estimation. The simulation shows that the fingerprint effect can be used for real-time slip-speed estimation.",
        "primary_area": "",
        "author": "Robert Kovenburg;Andrew Slezak;Chase George;Richard Gale;Burak Aksak;Robert Kovenburg;Andrew Slezak;Chase George;Richard Gale;Burak Aksak",
        "authorids": "/37088851169;/37089658422;/37089661675;/37284854900;/37947759800;/37088851169;/37089658422;/37089661675;/37284854900;/37947759800",
        "aff": "Electrical and Computer Engineering Department, Texas Tech University, Lubbock, TX, USA; Mechanical Engineering Department, Texas Tech University, Lubbock, TX, USA; Mechanical Engineering Department, Texas Tech University, Lubbock, TX, USA; Electrical and Computer Engineering Department, Texas Tech University, Lubbock, TX, USA; Mechanical Engineering Department, Texas Tech University, Lubbock, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981657/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1868774151684261213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Texas Tech University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.ttu.edu",
        "aff_unique_abbr": "TTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lubbock",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981915",
        "title": "The Role of Tactile Sensing in Learning and Deploying Grasp Refinement Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "A long-standing question in robot hand design is how accurate tactile sensing must be. This paper uses simulated tactile signals and the reinforcement learning (RL) framework to study the sensing needs in grasping systems. Our first experiment investigates the need for rich tactile sensing in the rewards of RL-based grasp refinement algorithms for multi-fingered robotic hands. We systematically integrate different levels of tactile data into the rewards using analytic grasp stability metrics. We find that combining information on contact positions, normals, and forces in the reward yields the highest average success rates of 95.4% for cuboids, 93.1% for cylinders, and 62.3% for spheres across wrist position errors between 0 and 7 centimeters and rotational errors between 0 and 14 degrees. This contact-based reward outperforms a non-tactile binary-reward baseline by 42.9%. Our follow-up experiment shows that when training with tactile-enabled rewards, the use of tactile information in the control policy's state vector is drastically reducible at only a slight performance decrease of at most 6.6% for no tactile sensing in the state. Since policies do not require access to the reward signal at test time, our work implies that models trained on tactile-enabled hands are deployable to robotic hands with a smaller sensor suite, potentially reducing cost dramatically.",
        "primary_area": "",
        "author": "Alexander Koenig;Zixi Liu;Lucas Janson;Robert Howe;Alexander Koenig;Zixi Liu;Lucas Janson;Robert Howe",
        "authorids": "/37275595300;/37089658506;/37085552349;/37279555200;/37275595300;/37089658506;/37085552349;/37279555200",
        "aff": "School of Engineering and Applied Sciences, Harvard University; School of Engineering and Applied Sciences, Harvard University; Department of Statistics, Harvard University; RightHand Robotics, Inc., Somerville, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981915/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7915715396392547480&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Harvard University;RightHand Robotics, Inc.",
        "aff_unique_dep": "School of Engineering and Applied Sciences;",
        "aff_unique_url": "https://www.harvard.edu;",
        "aff_unique_abbr": "Harvard;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981218",
        "title": "The Uncertainty Aware Salted Kalman Filter: State Estimation for Hybrid Systems with Uncertain Guards",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a method for updating robotic state belief through contact with uncertain surfaces and apply this update to a Kalman filter for more accurate state estimation. Examining how guard surface uncertainty affects the time spent in each mode, we derive a novel guard saltation matrix- which maps perturbations prior to hybrid events to perturbations after - accounting for additional variation in the resulting state. Additionally, we propose the use of parame-terized reset functions - capturing how unknown parameters change how states are mapped from one mode to the next - the Jacobian of which accounts for additional uncertainty in the resulting state. The accuracy of these mappings is shown by simulating sampled distributions through uncertain transition events and comparing the resulting covariances. Finally, we integrate these additional terms into the \u201cuncertainty aware Salted Kalman Filter\u201d, uaSKF, and show a peak reduction in average estimation error by 24\u201360% on a variety of test conditions and systems.",
        "primary_area": "",
        "author": "J. Joe Payne;Nathan J. Kong;Aaron M. Johnson;J. Joe Payne;Nathan J. Kong;Aaron M. Johnson",
        "authorids": "/37089448713;/37089281130;/37589025300;/37089448713;/37089281130;/37589025300",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981218/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13976036773777102833&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981887",
        "title": "The concept of rod-driven locomotion for spherical lunar exploration robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A spherical robotic probe has several advantages in rough environments and has therefore raised interest for application in planetary exploration. A sphere is well-suited to protect high-sensitive payloads, however, the locomotion system for planetary surfaces raises several challenges. This paper presents a novel locomotion system consisting of linear actuators which are usable in a multi-functional fashion. Apart from pushing and bringing leverage for locomotion the extendable rods enable a tripod mode for improved sensing. The developed solutions offer a mathematical-physical system description, simple algorithms for the control of locomotion and balancing as well as general calculations for determining the maximum achievable performance parameters of such a robot. The first built prototype shows the basic suitability of the system and reveals directions for further research.",
        "primary_area": "",
        "author": "Jasper Zevering;Dorit Borrmann;Anton Bredenbeck;Andreas N\u00fcchter;Jasper Zevering;Dorit Borrmann;Anton Bredenbeck;Andreas N\u00fcchter",
        "authorids": "/37089033550;/37591151900;/37088754079;/37273297900;/37089033550;/37591151900;/37088754079;/37273297900",
        "aff": "Informatics VII: Robotics and Telematics - University of Wuerzburg; Informatics VII: Robotics and Telematics - University of Wuerzburg; Informatics VII: Robotics and Telematics - University of Wuerzburg; Informatics VII: Robotics and Telematics - University of Wuerzburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981887/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13079797375995495458&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Wuerzburg",
        "aff_unique_dep": "Informatics VII: Robotics and Telematics",
        "aff_unique_url": "https://www.uni-wuerzburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981516",
        "title": "Three-Dimensional Dynamic Running with a Point-Foot Biped based on Differentially Flat SLIP",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel framework for point- foot biped running in three-dimensional space. The proposed approach generates center of mass (CoM) reference trajectories based on a differentially flat spring-loaded inverted pendulum (SLIP) model. A foothold planner is used to select touch down location that renders optimal CoM trajectory for upcoming step in real time. Dynamically feasible trajectories of CoM and orientation are subsequently generated by a simplified single rigid body (SRB) model based model predictive control (MPC). A task-space controller is then applied online to compute whole- body joint torques which embeds these target dynamics into the robot. The proposed approach is evaluated on physical simulation of a 12 degree-of-freedom (DoF), 7.95 kg point-foot bipedal robot. The robot achieves stable running at at varying speeds with maximum value of 1.1 m/s. The proposed scheme is shown to be able to reject vertical disturbances of 8 N. s and lateral disturbance of 6.5 N. s applied at the robot base.",
        "primary_area": "",
        "author": "Zejun Hong;Hua Chen;Wei Zhang;Zejun Hong;Hua Chen;Wei Zhang",
        "authorids": "/37088653661;/37086195529;/37089656248;/37088653661;/37086195529;/37089656248",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981516/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7878423357593720783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981396",
        "title": "Tightly-Coupled EKF-Based Radar-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Multicopter Unmanned Aerial Vehicles (UAV) are small and agile robots with the potential to become prominent in performing autonomous tasks in various Global Navigation Satellite System (GNSS)-denied environments. These environments can potentially be rendered even more challenging due to external factors impairing the robot's perception, such as low or too bright light, permeation with aerosols or smoke. A precondition of autonomous operation, though, is the ability of a robot to accurately localize itself in the surrounding environment. Millimeter-wave Frequency Modulated Continuous Wave (FMCW) radar sensors are resilient to the aforementioned factors while being lightweight, inexpensive and highly accurate. In this paper, we present a Radar-Inertial Odometry (RIO) method for estimating the full 6DoF pose and 3D velocity of a UAV. In an Extended Kalman Filter (EKF) framework, we fuse range measurements and velocity measurements of 3D points detected by an FMCW radar sensor together with Inertial Measurement Unit (IMU) readings. In real experiments we show that our approach enables accurate state estimation of a UAV and that it exhibits improvements over similar existing state-of-the-art method.",
        "primary_area": "",
        "author": "Jan Michalczyk;Roland Jung;Stephan Weiss;Jan Michalczyk;Roland Jung;Stephan Weiss",
        "authorids": "/37089462521;/37087323495;/37535323400;/37089462521;/37087323495;/37535323400",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981396/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15677640122251141495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9982044",
        "title": "Time-Optimal Synchronous Terminal Trajectory Planning for Coupling Motions of Robotic Flexible Endoscope",
        "track": "main",
        "status": "Poster",
        "abstract": "The robotic flexible endoscope is developed rapidly in the field of surgery robots due to its high flexibility and safety. However, some inherent features, e.g., high nonlinearity, material creep, complex dynamic hysteresis behaviors, and the unknown coupling effects between bending and twisting motions, can lead to the significant degradation on three-dimensional (3-D) positioning performance of the endoscope. Aiming at these challenges, this paper built a practical multi-motion hysteresis phenomenon model for the bending and twisting motions of the robotic flexible endoscope with consideration of the coupling effects. Then, the time-optimal synchronous terminal motion planner is first proposed for the 3-D motions of the robotic endoscope to decouple the coupling effects in an intuitive separate control scheme. Finally, a series of hardware experiments are conducted on a robotic flexible ureteroscope platform. The accuracy of the proposed model and the trajectory-planning-based decoupling strategy is comprehensively validated. Particularly, the experimental results with the proposed trajectory planner show the satisfactory performance of vibration suppression and over-shoot suppression.",
        "primary_area": "",
        "author": "Xiangyu Wang;Ningbo Yu;Jianda Han;Yongchun Fang;Xiangyu Wang;Ningbo Yu;Jianda Han;Yongchun Fang",
        "authorids": "/37086288964;/37085356485;/37290381900;/37293583100;/37086288964;/37085356485;/37290381900;/37293583100",
        "aff": "Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982044/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18247887423286553248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Intelligence Technology and Robotic Systems",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981351",
        "title": "Timestamp-Supervised Action Segmentation with Graph Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a novel approach for temporal activity segmentation with timestamp supervision. Our main contribution is a graph convolutional network, which is learned in an end-to-end manner to exploit both frame features and connections between neighboring frames to generate dense framewise labels from sparse timestamp labels. The gener-ated dense framewise labels can then be used to train the segmentation model. In addition, we propose a framework for alternating learning of both the segmentation model and the graph convolutional model, which first initializes and then iteratively refines the learned models. Detailed experiments on four public datasets, including 50 Salads, GTEA, Breakfast, and Desktop Assembly, show that our method is superior to the multi-layer perceptron baseline, while performing on par with or better than the state of the art in temporal activity segmentation with timestamp supervision.",
        "primary_area": "",
        "author": "Hamza Khan;Sanjay Haresh;Awais Ahmed;Shakeeb Siddiqui;Andrey Konin;M. Zeeshan Zia;Quoc-Huy Tran;Hamza Khan;Sanjay Haresh;Awais Ahmed;Shakeeb Siddiqui;Andrey Konin;M. Zeeshan Zia;Quoc-Huy Tran",
        "authorids": "/37089660356;/37088754216;/37086690780;/37089640340;/37089015117;/37574817500;/37086180008;/37089660356;/37088754216;/37086690780;/37089640340;/37089015117;/37574817500;/37086180008",
        "aff": "Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA; Retrocausal, Inc., Redmond, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981351/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17653384844025264693&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Retrocausal, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Redmond",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981679",
        "title": "To ask for help or not to ask: A predictive approach to human-in-the-loop motion planning for robot manipulation tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a predictive system for non-prehensile, physics-based motion planning in clutter with a human-in-the-loop. Recent shared-autonomous systems present motion planning performance improvements when high-level reasoning is provided by a human. Humans are usually good at quickly identifying high-level actions in high-dimensional spaces, and robots are good at converting high-level actions into valid robot trajectories. In this paper, we present a novel framework that permits a single human operator to effectively guide a fleet of robots in a virtual warehouse. The robots are tackling the problem of Reaching Through Clutter (RTC), where they are reaching onto cluttered shelves to grasp a goal object while pushing other obstacles out of the way. We exploit information from the motion planning algorithm to predict which robot requires human help the most and assign that robot to the human. With twenty virtual robots and a single human-operator, the results suggest that this approach improves the system's overall performance compared to a baseline with no predictions. The results also show that there is a cap on how many robots can effectively be guided simultaneously by a single human operator.",
        "primary_area": "",
        "author": "Rafael Papallas;Mehmet R. Dogar;Rafael Papallas;Mehmet R. Dogar",
        "authorids": "/37086603559;/37591140400;/37086603559;/37591140400",
        "aff": "School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981679/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5037524051520701752&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Leeds",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.leeds.ac.uk",
        "aff_unique_abbr": "Leeds",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9981230",
        "title": "Toolbox Release: A WiFi-Based Relative Bearing Framework for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the WiFi-Sensor-for-Robotics (WSR) open-source toolbox111Code: https://github.com/Harvard-REACT/WSR-Toolbox Dataset: https://github.com/Harvard-REACT/WSR-Toolbox-Dataset Demo: https://github.com/Harvard-REACT/WSR-Toolbox/wiki/Demo. It enables robots in a team to obtain relative bearing to each other, even in nonline-of-sight (NLOS) settings which is a very challenging problem in robotics. It does so by analyzing the phase of their communicated WiFi signals as the robots traverse the environment. This capability, based on the theory developed in our prior works, is made available for the first time as an open-source toolbox. It is motivated by the lack of easily deployable solutions that use robots' local resources (e.g WiFi) for sensing in NLOS. This has implications for multi-robot mapping and rendezvous, ad-hoc robot networks, and security in multi-robot teams, amongst other applications. The toolbox is designed for distributed and online deployment on robot platforms using commodity hardware and on-board sensors. We also release datasets demonstrating its performance in NLOS and line-of-sight (LOS) settings and for a multi-robot localization use case. Empirical results for hardware experiments show that the bearing estimation from our toolbox achieves accuracy with mean and standard deviation of 1.13 degrees, 11.07 degrees in LOS and 6.04 degrees, 26.4 degrees for NLOS, respectively, in an indoor office environment.",
        "primary_area": "",
        "author": "Ninad Jadhav;Weiying Wang;Diana Zhang;Swarun Kumar;Stephanie Gil;Ninad Jadhav;Weiying Wang;Diana Zhang;Swarun Kumar;Stephanie Gil",
        "authorids": "/37089434094;/37089664062;/37086833759;/37085847897;/37396689900;/37089434094;/37089664062;/37086833759;/37085847897;/37396689900",
        "aff": "REACT Lab, Harvard; REACT Lab, Harvard; WiTech Lab, CMU; WiTech Lab, CMU; REACT Lab, Harvard",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981230/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17694218336892216307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Harvard University;Carnegie Mellon University",
        "aff_unique_dep": "REACT Lab;WiTech Lab",
        "aff_unique_url": "https://www.harvard.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Harvard;CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981297",
        "title": "Topology optimized multi-material self-healing actuator with reduced out of plane deformation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in soft robotics in academia have led to the adoption of soft grippers in industrial settings. Due to their soft bending actuators, these grippers can handle delicate objects with great care. However, due to their flexibility, the actuators are prone to out-of-plane deformations upon asymmetric loading. These undesired deformations lead to reduced grasp performance and may cause instability or failure of the grip. While the state-of-the-art contributions describe complex designs to limit those deformations, this work focuses on a complementary path investigating the material distribution. In this paper, a novel bending actuator is developed with improved out-of-plane deformation resistance by optimizing the material distribution in multi-material designs composed of two polymers with different mechanical properties. This is made possible by the strong interfacial strength of Diels-Alder chemical bonds in the used polymers, which have a self-healing capability. A Solid Isotropic Material with Penalization (SIMP) topology optimization is performed to increase the out-of-plane resistance. The actuator is simulated using FEA COMSOL in which the (hyper) elastic materials are simulated by Mooney-Rivlin models, fitted on experimental uniaxial tensile test data. This multi-material actuator and a reference single material actuator were manufactured and modeled. Via experimental characterization and validation in FEA simulations, it is shown that the actuator out-of-plane stiffness, characterized by the in-plane bending angle and out-of-plane bending angle, can be increased by an optimized multi-material composition, without changing the geometrical shape of the actuator.",
        "primary_area": "",
        "author": "Zhanwei Wang;Seppe Terryn;Julie Legrand;Pasquale Ferrentino;Seyedreza Kashef Tabrizian;Joost Brancart;Ellen Roels;Guy Van Assche;Bram Vanderborght;Zhanwei Wang;Seppe Terryn;Julie Legrand;Pasquale Ferrentino;Seyedreza Kashef Tabrizian;Joost Brancart;Ellen Roels;Guy Van Assche;Bram Vanderborght",
        "authorids": "/856292054663631;/37085396860;/37086448266;/37088698626;/37089317465;/37085374998;/37086840282;/37089523166;/37295389300;/856292054663631;/37085396860;/37086448266;/37088698626;/37089317465;/37085374998;/37086840282;/37089523166;/37295389300",
        "aff": "Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Physical Chemistry and Polymer Science, Vrije Universiteit Brussel, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium; Physical Chemistry and Polymer Science, Vrije Universiteit Brussel, Elsene, Belgium; Brubotics, Vrije Universiteit Brussel and Imec, Elsene, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981297/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3065944345722921644&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Vrije Universiteit Brussel",
        "aff_unique_dep": "Brubotics",
        "aff_unique_url": "https://www.vub.be",
        "aff_unique_abbr": "VUB",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;1;0",
        "aff_campus_unique": "Brussel;Elsene",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9982162",
        "title": "Toroidal Origami Monotrack: Mechanism to Realize Smooth Driving and Bending for Closed-Skin-Drive Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel toroidal origami monotrack capable of smooth-skin driving and bending for closed-skin-drive robots. Monotracks are a promising solution for achieving high mobility in unstructured environments. Toroidal-drive mechanisms enable whole skin drive; however, conventional methods experience unexpected wrinkling and buckles that lead to a large resistance. In this study, we propose an origami bellows structure with multiple rollers that can maintain the skin tension and deal with the cause of large friction between the skin and the body. The origami structure design method is presented, and the bending angle range and required drive force were derived through a theoretical analysis. The validity of the effectiveness of the concept was verified through prototype testing.",
        "primary_area": "",
        "author": "Masahiro Watanabe;Yuto Kemmotsu;Kenjiro Tadakuma;Kazuki Abe;Masashi Konyo;Satoshi Tadokoro;Masahiro Watanabe;Yuto Kemmotsu;Kenjiro Tadakuma;Kazuki Abe;Masashi Konyo;Satoshi Tadokoro",
        "authorids": "/37403419100;/37089660273;/38534909200;/37088811757;/37296053600;/37296054300;/37403419100;/37089660273;/38534909200;/37088811757;/37296053600;/37296054300",
        "aff": "Tough Cyberphysical AI Research Center, Tohoku University; Graduation School of Information Sciences, Tohoku University, Sendai, Japan; Tough Cyberphysical AI Research Center, Graduation School of Information Sciences, Tohoku University; Tough Cyberphysical AI Research Center, Tohoku University; Graduation School of Information Sciences, Tohoku University, Sendai, Japan; Graduation School of Information Sciences, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982162/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8445289155679355196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Tough Cyberphysical AI Research Center",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Sendai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981211",
        "title": "Torque Control of Hydraulic Pressure Servo Valve Driven Actuator with Deep Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-linear dynamics, model uncertainties due to hydraulic fluid, and disturbances in hydraulic systems make it difficult to obtain accurate torque tracking performance. In this study, a learning-based torque-tracking method is proposed, which does not require approximating the torque dynamics. The proposed method can capture disturbances and model uncertainties of system. The applied neural network comprises a nonlinear autoregressive model with exogenous inputs (NARX) and a long shortterm neural network (LSTM). NARX is employed due to its ability to predict time series control input from the states of system, and LSTM is used to overcome the vanishing and exploding gradient, which causes long-term memory loss in NARX, leading to inaccurate torque tracking performance. LSTM with NARX achieved a better prediction performance with a mean square error and standard deviation of 0.0015 \\pm 0.4\\times 1030.0015 \\pm 0.4\\times 103 compared to only NARX with a mean square error of 0.004 \\pm 1.0\\times 1030.004 \\pm 1.0\\times 103 at 10 K training data size.",
        "primary_area": "",
        "author": "Kamgang Blaise Tcheumchoua;Seokho Nam;Wan Kyun Chung;Kamgang Blaise Tcheumchoua;Seokho Nam;Wan Kyun Chung",
        "authorids": "/37089662803;/37088234579;/37280299100;/37089662803;/37088234579;/37280299100",
        "aff": "Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981211/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4766798491409811780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981041",
        "title": "Torque-Actuated Multimodal Locomotion of Ferrofluid Robot With Environment and Task Adaptability",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft microrobotics have recently been an active field that advances microrobotics with new robot design, locomotion, and applications. In this paper, we study the ferrofluid robot (FR), which has soft nature and exhibits paramagnetism. Currently, the FR locomotion is usually realized by magnetic force. To enable the FR with more locomotion modes for environment and task adaptability, we program three dynamic field forms and realize three corresponding torque-actuated locomotion modes: Rolling, Wobbling, and Oscillating. The torque actuation of the FR is formulated, and the three locomotion modes are characterized. With the implementation of automated tracking and control algorithms, the controllability of these modes is testified. We then fabricate different environments to validate the adaptability of the FR that can switch its locomotion mode accordingly. Finally, utilizing the oscillating mode and wobbling mode, we demonstrate the transport of lipophilic and hydrophilic cargoes, respectively, showing the task adaptability.",
        "primary_area": "",
        "author": "Lidong Yang;Mengmeng Sun;Li Zhang;Lidong Yang;Mengmeng Sun;Li Zhang",
        "authorids": "/37086079463;/37086409122;/37085379138;/37086079463;/37086409122;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; CUHK T Stone Robotics Institute, The Chinese University of Hong Kong, Shatin NT, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981041/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6637457344413060795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shatin NT",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981990",
        "title": "Toward Dexterous Flapping Flight: Effective Large Yaw Torque Generation by $2\\times 2$-Degrees-of-Freedom Flapping Wings",
        "track": "main",
        "status": "Poster",
        "abstract": "Through the efforts of robotic engineers and inspired by the flapping flight of smaller creatures (e.g., insects and hummingbirds), the untethered stable hovering of flapping micro-aerial vehicles (FMAVs) has been achieved. Now, engineers are evaluating how to improve the mobility of these vehicles. The maneuverability of insects and birds in flight, such as their sharp turns and their takeoffs and landings from vertical walls, is what researchers originally expected from FMAVs. However, in previous studies, just one active (or one active plus one passive) degree of freedom (DoF) was given to the main actuation of the wing, and the range of movement of the wings was small. In addition, the magnitude of the attitude control torque that could be generated was relatively small when compared with multi-rotors. However, with the recent developments of small motors and drive-circuit technology, the realization of untethered flight by FMAVs equipped with four or more motors seems possible. This study utilized numerical calculation to investigate the advantage of a flapping-flight robot equipped with two pairs of left and right wings capable of stroke and twisting movements with two independent DoFs (2\\times 22\\times 2-DoF FMAV). The results of the numerical studies confirmed that, compared with the split-factor method widely used in past studies, the 2\\times 22\\times 2-DoF FMAV can generate higher yaw torque without the need for additional large driving torque. This shows that various agile flight functions are possible.",
        "primary_area": "",
        "author": "M. Hamamoto;M. Hamamoto",
        "authorids": "/37089659630;/37089659630",
        "aff": "R&D Office of the Corporate Planning Department, Nakakita Seisakusho Co. Ltd., Daito, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981990/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ev8qul5XbeMJ:scholar.google.com/&scioq=Toward+Dexterous+Flapping+Flight:+Effective+Large+Yaw+Torque+Generation+by+%242%5Ctimes+2%24-Degrees-of-Freedom+Flapping+Wings&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Nakakita Seisakusho Co. Ltd.",
        "aff_unique_dep": "R&D Office of the Corporate Planning Department",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981715",
        "title": "Toward Efficient Task Planning for Dual-Arm Tabletop Object Rearrangement",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the problem of coordinating two robot arms to solve non-monotone tabletop multi-object re- arrangement tasks. In a non-monotone rearrangement task, complex object-object dependencies exist that require moving some objects multiple times to solve an instance. In working with two arms in a large workspace, some objects must be handed off between the robots, which further complicates the planning process. For the challenging dual-arm tabletop rearrangement problem, we develop effective task planning algorithms for scheduling the pick-n-place sequence that can be properly distributed between the two arms. We show that, even without using a sophisticated motion planner, our method achieves significant time savings in comparison to greedy approaches and naive parallelization of single-robot plans.",
        "primary_area": "",
        "author": "Kai Gao;Jingjin Yu;Kai Gao;Jingjin Yu",
        "authorids": "/37088997464;/37536570700;/37088997464;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981715/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14069746864498360484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981856",
        "title": "Toward FBG-Sensorized Needle Shape Prediction in Tissue Insertions",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex needle shape prediction remains an issue for planning of surgical interventions of flexible needles. In this paper, we validate a theoretical method for flexible needle shape prediction allowing for non-uniform curvatures, extending upon a previous sensor-based model which combines curvature measurements from fiber Bragg grating (FBG) sensors and the mechanics of an inextensible elastic rod to determine and predict the 3D needle shape during insertion. We evaluate the model's effectiveness in single-layer isotropic tissue for shape sensing and shape prediction capabilities. Experiments on a four-active area, FBG-sensorized needle were performed in varying single-layer isotropic tissues under stereo vision to provide 3D ground truth of the needle shape. The results validate a viable 3D needle shape prediction model accounting for non-uniform curvatures in flexible needles with mean needle shape sensing and prediction root-mean-square errors of 0.479 mm and 0.892 mm, respectively.",
        "primary_area": "",
        "author": "Dimitri A. Lezcano;Min Jung Kim;Iulian I. Iordachita;Jin Seob Kim;Dimitri A. Lezcano;Min Jung Kim;Iulian I. Iordachita;Jin Seob Kim",
        "authorids": "/37088574641;/37089520806;/37330620500;/38259425900;/37088574641;/37089520806;/37330620500;/38259425900",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981856/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11769057040920250422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982246",
        "title": "Toward Global Sensing Quality Maximization: A Configuration Optimization Scheme for Camera Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The performance of a camera network monitoring a set of targets depends crucially on the configuration of the cameras. In this paper, we investigate the reconfiguration strategy for the parameterized camera network model, with which the sensing qualities of the multiple targets can be optimized globally and simultaneously. We first propose to use the number of pixels occupied by a unit-length object in image as a metric of the sensing quality of the object, which is determined by the parameters of the camera, such as intrinsic, extrinsic, and distortional coefficients. Then, we form a single quantity that measures the sensing quality of the targets by the camera network. This quantity further serves as the objective function of our optimization problem to obtain the optimal camera configuration. We verify the effectiveness of our approach through extensive simulations and experiments, and the results reveal its improved performance on the AprilTag detection tasks. Codes and related utilities for this work are open-sourced and available at https://github.com/sszxc/MultiCam-Simulation.",
        "primary_area": "",
        "author": "Xuechao Zhang;Xuda Ding;Yi Ren;Yu Zheng;Chongrong Fang;Jianping He;Xuechao Zhang;Xuda Ding;Yi Ren;Yu Zheng;Chongrong Fang;Jianping He",
        "authorids": "/37089660579;/37088752297;/37088490171;/37086993722;/37085544238;/38239084800;/37089660579;/37088752297;/37088490171;/37086993722;/37085544238;/38239084800",
        "aff": "Dept. of Automation, Shanghai Jiao Tong University, Shanghai, China; Dept. of Automation, Shanghai Jiao Tong University, Shanghai, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; Dept. of Automation, Shanghai Jiao Tong University, Shanghai, China; Dept. of Automation, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982246/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BBjZp0fcggYJ:scholar.google.com/&scioq=Toward+Global+Sensing+Quality+Maximization:+A+Configuration+Optimization+Scheme+for+Camera+Networks&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Tencent",
        "aff_unique_dep": "Dept. of Automation;Robotics",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.tencent.com",
        "aff_unique_abbr": "SJTU;Tencent",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Shanghai;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981335",
        "title": "Towards Adaptive Continuous Control of Soft Robotic Manipulator using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the soft robot is gaining considerable popularity in dexterous and safe manipulation, accurate motion control is still an open problem to be explored. Recent investigations suggest that reinforcement learning (RL) is a promising solution but lacks efficient adaptability for Sim2Real transfer or environment variations. In this paper, we present a deep deterministic policy gradient (DDPG)-based control system for the continuous task-space manipulation of soft robots. Domain randomization is adopted in simulation for fast control-policy initialization, while an offline retraining strategy is utilized to update the controller parameters for incremental learning. The experiments demonstrate that the proposed RL controller can track a moving target accurately (with RMSE of 1.26 mm), and accommodate to external varying load effectively (with ~30% RMSE reduction after retraining). Comparisons among the proposed RL controller and other supervised-learning-based controllers in handling additional tip load were also conducted. The results support that our RL method is appropriate for automatic learning such that there is no need of manual interference for data processing, particularly in cases with external disturbances and actuation redundancy.",
        "primary_area": "",
        "author": "Yingqi Li;Xiaomei Wang;Ka-Wai Kwok;Yingqi Li;Xiaomei Wang;Ka-Wai Kwok",
        "authorids": "/37088849382;/37086690237;/37085400834;/37088849382;/37086690237;/37085400834",
        "aff": "Department of Mechanical Engineering, The University of Hong Kong, Hong Kong; Multi-scale Medical Robotics Center (MRC) Limited; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981335/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15956041451920215742&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Hong Kong;Multi-scale Medical Robotics Center",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.hku.hk;",
        "aff_unique_abbr": "HKU;MRC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "9981141",
        "title": "Towards Autonomous Control of Surgical Instruments using Adaptive-Fusion Tracking and Robot Self-Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to track surgical instruments in realtime is crucial for autonomous Robotic Assisted Surgery (RAS). Recently, the fusion of visual and kinematic data has been proposed to track surgical instruments. However, these methods assume that both sensors are equally reliable, and cannot successfully handle cases where there are significant perturbations in one of the sensors' data. In this paper, we address this problem by proposing an enhanced fusion-based method. The main advantage of our method is that it can adjust fusion weights to adapt to sensor perturbations and failures. Another problem is that before performing an autonomous task, these robots have to be repetitively recalibrated by a human for each new patient to estimate the transformations between the different robotic arms. To address this problem, we propose a self-calibration algorithm that empowers the robot to autonomously calibrate the transformations by itself in the beginning of the surgery. We applied our fusion and selfcalibration algorithms for autonomous ultrasound tissue scanning and we showed that the robot achieved stable ultrasound imaging when using our method. Our performance evaluation shows that our proposed method outperforms the state-of-art both in normal and challenging situations.",
        "primary_area": "",
        "author": "Chiyu Wang;Jo\u00e3o Cartucho;Daniel Elson;Ara Darzi;Stamatia Giannarou;Chiyu Wang;Jo\u00e3o Cartucho;Daniel Elson;Ara Darzi;Stamatia Giannarou",
        "authorids": "/37089663491;/37086579198;/37284478800;/37571992600;/37891118000;/37089663491;/37086579198;/37284478800;/37571992600;/37891118000",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981141/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8318749165508959856&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982114",
        "title": "Towards Autonomous Grading In The Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "Surface grading is an integral part of the construction pipeline. Here, a bulldozer, which is a key machinery tool at any construction site, is required to level an uneven area containing pre-dumped sand piles. In this work, we aim to tackle the problem of autonomous surface grading on real-world scenarios. We design both a realistic physical simulation and a scaled real-world prototype environment mimicking real bulldozer dynamics and sensory information. In addition, we establish heuristics and learning strategies in order to solve the problem. Through extensive experiments, we show that although heuristics are capable of tackling the problem in a clean and noise-free simulated environment, they fail catastrophically when facing real-world scenarios. However, we show that the simulation can be leveraged to guide a learning agent, which can generalize and solve the task both in simulation and in a scaled prototype environment.",
        "primary_area": "",
        "author": "Yakov Miron;Chana Ross;Yuval Goldfracht;Chen Tessler;Dotan Di Castro;Yakov Miron;Chana Ross;Yuval Goldfracht;Chen Tessler;Dotan Di Castro",
        "authorids": "/37089615142;/37089614444;/37089614709;/37089661258;/37062208100;/37089615142;/37089614444;/37089614709;/37089661258;/37062208100",
        "aff": "The Hatter Department of Marine Technologies, The Autonomous Navigation and Sensor Fusion Lab, University of Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel; Bosch Center for Artificial Intelligence (BCAI), Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982114/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16754775450150745427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Haifa;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Hatter Department of Marine Technologies;Artificial Intelligence",
        "aff_unique_url": "https://www.haifa.ac.il;https://www.bosch-ai.com",
        "aff_unique_abbr": ";BCAI",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Haifa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9981299",
        "title": "Towards Autonomous Visual Navigation in Arable Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation of a robot in agricultural fields is essential for every task from crop monitoring to weed management and fertilizer application. Many current approaches rely on accurate GPS, however, such technology is expensive and can be impacted by lack of coverage. As such, autonomous navigation through sensors that can interpret their environment (such as cameras) is important to achieve the goal of autonomy in agriculture. In this paper, we introduce a purely vision-based navigation scheme that is able to reliably guide the robot through row-crop fields using computer vision and signal processing techniques without manual intervention. Independent of any global localization or mapping, this approach is able to accurately follow the crop-rows and switch between the rows, only using onboard cameras. The proposed navigation scheme can be deployed in a wide range of fields with different canopy shapes in various growth stages, creating a crop agnostic navigation approach. This was completed under various illumination conditions using simulated and real fields where we achieve an average navigation accuracy of 3.82cm with minimal human intervention (hyper-parameter tuning) on BonnBot-I.",
        "primary_area": "",
        "author": "Alireza Ahmadi;Michael Halstead;Chris McCool;Alireza Ahmadi;Michael Halstead;Chris McCool",
        "authorids": "/37085486371;/37085368005;/38274733400;/37085486371;/37085368005;/38274733400",
        "aff": "University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981299/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15935287742286860358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bonn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981110",
        "title": "Towards Defensive Autonomous Driving: Collecting and Probing Driving Demonstrations of Mixed Qualities",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing or learning an autonomous driving policy is undoubtedly a challenging task as the policy has to maintain its safety in all corner cases. In order to secure safety in autonomous driving, the ability to detect hazardous situations, which can be seen as an out-of-distribution (OOD) detection problem, becomes crucial. However, conventional datasets often only contain expert driving demonstrations, although some non-expert or uncommon driving behavior data are needed to implement a safety guaranteed autonomous driving platform. To this end, we present a dataset called the R3 Driving Dataset, composed of driving data with different qualities. The dataset categorizes abnormal driving behaviors into eight categories and 369 different detailed situations. The situations include dangerous lane changes and near-collision situations. To further enlighten how these abnormal driving behaviors can be detected, we utilize different uncertainty estimation and anomaly detection methods for the proposed dataset. From the results of the proposed experiment, it can be inferred that by using both uncertainty estimation and anomaly detection, most of the abnormal cases in the proposed dataset can be discriminated. https://rllab-snu.github.io/projects/R3-Driving-Dataset/doc.html",
        "primary_area": "",
        "author": "Jeongwoo Oh;Gunmin Lee;Jeongeun Park;Wooseok Oh;Jaeseok Heo;Hojun Chung;Do Hyung Kim;Byungkyu Park;Chang-Gun Lee;Sungjoon Choi;Songhwai Oh;Jeongwoo Oh;Gunmin Lee;Jeongeun Park;Wooseok Oh;Jaeseok Heo;Hojun Chung;Do Hyung Kim;Byungkyu Park;Chang-Gun Lee;Sungjoon Choi;Songhwai Oh",
        "authorids": "/37089660359;/37087323658;/37089447938;/37088689519;/37089662179;/37089661410;/37088356204;/37089658102;/37280420900;/37085405040;/37068116900;/37089660359;/37087323658;/37089447938;/37088689519;/37089662179;/37089661410;/37088356204;/37089658102;/37280420900;/37085405040;/37068116900",
        "aff": "Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981110/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8870595358035253821&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;1;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Seoul National University;Korea University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Artificial Intelligence",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.korea.ac.kr",
        "aff_unique_abbr": "SNU;KU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982050",
        "title": "Towards High-Definition Maps: a Framework Leveraging Semantic Segmentation to Improve NDT Map Compression and Descriptivity",
        "track": "main",
        "status": "Poster",
        "abstract": "High-Definition (HD) maps are needed for robust navigation of autonomous vehicles, limited by the on-board storage capacity. To solve this, we propose a novel framework, Environment-Aware Normal Distributions Transform (EA-NDT), that significantly improves compression of standard NDT map representation. The compressed representation of EA-NDT is based on semantic-aided clustering of point clouds resulting in more optimal cells compared to grid cells of standard NDT. To evaluate EA-NDT, we present an open-source implementation that extracts planar and cylindrical primitive features from a point cloud and further divides them into smaller cells to represent the data as an EA-NDT HD map. We collected an open suburban environment dataset and evaluated EA-NDT HD map representation against the standard NDT representation. Compared to the standard NDT, EA-NDT achieved consistently at least 1.5\u00d7 higher map compression while maintaining the same descriptive capability. Moreover, we showed that EA-NDT is capable of producing maps with significantly higher descriptivity score when using the same number of cells than the standard NDT.",
        "primary_area": "",
        "author": "Petri Manninen;Heikki Hyyti;Ville Kyrki;Jyri Maanp\u00e4\u00e4;Josef Taher;Juha Hyypp\u00e4;Petri Manninen;Heikki Hyyti;Ville Kyrki;Jyri Maanp\u00e4\u00e4;Josef Taher;Juha Hyypp\u00e4",
        "authorids": "/37088853554;/37085347129;/37274001900;/37088854552;/37088854852;/37301215900;/37088853554;/37085347129;/37274001900;/37088854552;/37088854852;/37301215900",
        "aff": "Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute (FGI), National Land Survey of Finland (NLS), Espoo, Finland; Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute (FGI), National Land Survey of Finland (NLS), Espoo, Finland; School of Electrical Engineering, Aalto University, Espoo, Finland; Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute (FGI), National Land Survey of Finland (NLS), Espoo, Finland; Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute (FGI), National Land Survey of Finland (NLS), Espoo, Finland; Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute (FGI), National Land Survey of Finland (NLS), Espoo, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982050/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13302617718276931575&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Finnish Geospatial Research Institute;Aalto University",
        "aff_unique_dep": "Department of Remote Sensing and Photogrammetry;School of Electrical Engineering",
        "aff_unique_url": ";https://www.aalto.fi",
        "aff_unique_abbr": "FGI;Aalto",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Espoo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9982252",
        "title": "Towards Inclusive HRI: Using Sim2Real to Address Underrepresentation in Emotion Expression Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots and artificial agents that interact with humans should be able to do so without bias and inequity, but facial perception systems have notoriously been found to work more poorly for certain groups of people than others. In our work, we aim to build a system that can perceive humans in a more transparent and inclusive manner. Specifically, we focus on dynamic expressions on the human face, which are difficult to collect for a broad set of people due to privacy concerns and the fact that faces are inherently identifiable. Furthermore, datasets collected from the Internet are not necessarily representative of the general population. We address this problem by offering a Sim2Real approach in which we use a suite of 3D simulated human models that enables us to create an auditable synthetic dataset covering 1) underrepresented facial expressions, outside of the six basic emotions, such as confusion; 2) ethnic or gender minority groups; and 3) a wide range of viewing angles that a robot may encounter a human in the real world. By augmenting a small dynamic emotional expression dataset containing 123 samples with a synthetic dataset containing 4536 samples, we achieved an improvement in accuracy of 15% on our own dataset and 11 % on an external benchmark dataset, compared to the performance of the same model architecture without synthetic training data. We also show that this additional step improves accuracy specifically for racial minorities when the architecture's feature extraction weights are trained from scratch.",
        "primary_area": "",
        "author": "Saba Akhyani;Mehryar Abbasi;Mo Chen;Angelica Lim;Saba Akhyani;Mehryar Abbasi;Mo Chen;Angelica Lim",
        "authorids": "/37089662481;/37089335037;/37085494765;/37086880157;/37089662481;/37089335037;/37085494765;/37086880157",
        "aff": "Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982252/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9308130323860476737&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981221",
        "title": "Towards Learning to Play Piano with Dexterous Hands and Touch",
        "track": "main",
        "status": "Poster",
        "abstract": "As Liszt once said \u201c(a virtuoso) must call up scent and blossom, and breathe the breath of life\u201d, a virtuoso plays the piano with passion, poetry, and extraordinary technical ability. Hence, piano playing, being a task that is quintessentially human, becomes a hallmark for roboticians and artificial intelligence researchers to pursue. In this paper, we advocate an end-to-end reinforcement learning (RL) paradigm to demonstrate how an agent can learn directly from machine-readable music score to play the piano with touch-augmented dexterous hands on a simulated piano. To achieve the desired tasks, we design useful touch- and audio-based reward functions and a series of tasks. Empirical results show that the RL agent can not only find the correct key position but also deal with the various rhythmic, volume, and fingering requirements. As a result, the agent demonstrates its effectiveness in playing simple pieces that have different musical requirements which show the potential of leveraging reinforcement learning approach for the piano playing tasks.",
        "primary_area": "",
        "author": "Huazhe Xu;Yuping Luo;Shaoxiong Wang;Trevor Darrell;Roberto Calandra;Huazhe Xu;Yuping Luo;Shaoxiong Wang;Trevor Darrell;Roberto Calandra",
        "authorids": "/37086242886;/37089663675;/37086252778;/37282910600;/38540170300;/37086242886;/37089663675;/37086252778;/37282910600;/38540170300",
        "aff": "IIIS, Tsinghua University; Princeton University; MIT; UC Berkeley; Meta AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981221/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18400496622724859793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Tsinghua University;Princeton University;Massachusetts Institute of Technology;University of California, Berkeley;Meta",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;;;;Meta AI",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.princeton.edu;https://web.mit.edu;https://www.berkeley.edu;https://meta.com",
        "aff_unique_abbr": "THU;Princeton;MIT;UC Berkeley;Meta",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981123",
        "title": "Towards Reproducible Evaluations for Flying Drone Controllers in Virtual Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Research attention on natural user interfaces (NUIs) for drone flights are rising. Nevertheless, NUIs are highly diversified, and primarily evaluated by different physical environments leading to hard-to-compare performance between such solutions. We propose a virtual environment, namely VRFlightSim, enabling comparative evaluations with enriched drone flight details to address this issue. We first replicated a state-of-the-art (SOTA) interface and designed two tasks (crossing and pointing) in our virtual environment. Then, two user studies with 13 participants demonstrate the necessity of VRFlightSim and further highlight the potential of open-data interface designs.",
        "primary_area": "",
        "author": "Zheng Li;Yiming Huang;Yui-Pan Yau;Pan Hui;Lik-Hang Lee;Zheng Li;Yiming Huang;Yui-Pan Yau;Pan Hui;Lik-Hang Lee",
        "authorids": "/37089664091;/37089659351;/37086915636;/37285417200;/37086914873;/37089664091;/37089659351;/37086915636;/37285417200;/37086914873",
        "aff": "Fudan University, Shanghai, China; The Hong Kong University of Science and Technology, HKSAR, China; The Hong Kong University of Science and Technology, HKSAR, China; The Hong Kong University of Science and Technology, HKSAR, China; KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981123/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:JXmqEO0LS0wJ:scholar.google.com/&scioq=Towards+Reproducible+Evaluations+for+Flying+Drone+Controllers+in+Virtual+Environments&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Fudan University;Hong Kong University of Science and Technology;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.fudan.edu.cn;https://www.ust.hk;https://www.kaist.ac.kr",
        "aff_unique_abbr": "Fudan;HKUST;KAIST",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Shanghai;;Daejeon",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9982258",
        "title": "Towards Robot Avatars: Systems and Methods for Teleinteraction at Avatar XPRIZE Semi-Finals",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been a drastic shift to remote interaction for professional, industrial and personal interactions. Improving the overall quality of these interactions by removing any sense of distance between the users is the ultimate goal. Video conferencing has been widely adopted as an improvement to audio-only interactions. Having added visuals to audio communication, the next frontier is to add physical interaction to this remote communication. In this paper, we present an avatar system with the aim of tackling these necessities. The proposed system includes both hardware and software designs to ensure a real-time telemanipulation experience with tactile force feedback. We present a coupled hydrostatic actuated gripper and glove with high system bandwidth to reduce the inherent latency of the mechanical system. To account for latency over the network, the wave variable based method is adopted to maintain the stability of the closed-loop gripper control even under hundreds of milliseconds of delay. A bidirectional audiovisual communication system comprised of off-the-shelf hardware and software is incorporated to allow realtime conversation between the operator and the recipient for collaborative tasks. the proposed system has been validated in lab experiments and the global ana avatar xprize challenge semifinal.",
        "primary_area": "",
        "author": "Rui Luo;Chunpeng Wang;Eric Schwarm;Colin Keil;Evelyn Mendoza;Pushyami Kaveti;Stephen Alt;Hanumant Singh;Ta\u015ekin Padir;John Peter Whitney;Rui Luo;Chunpeng Wang;Eric Schwarm;Colin Keil;Evelyn Mendoza;Pushyami Kaveti;Stephen Alt;Hanumant Singh;Ta\u015ekin Padir;John Peter Whitney",
        "authorids": "/37088687913;/37089663306;/37086937639;/37088688648;/37086914411;/37086536726;/37089195748;/37281490600;/38496444600;/37409281700;/37088687913;/37089663306;/37086937639;/37088688648;/37086914411;/37086536726;/37089195748;/37281490600;/38496444600;/37409281700",
        "aff": "Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982258/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5990764811250715056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Institute for Experiential Robotics",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981664",
        "title": "Towards Robust Visual-Inertial Odometry with Multiple Non-Overlapping Monocular Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a Visual-Inertial Odometry (VIO) algorithm with multiple non-overlapping monocular cameras aiming at improving the robustness of the VIO algorithm. An initialization scheme and tightly-coupled bundle adjustment for multiple non-overlapping monocular cameras are proposed. With more stable features captured by multiple cameras, VIO can maintain stable state estimation, especially when one of the cameras tracked unstable or limited features. We also address the high CPU usage rate brought by multiple cameras by proposing a GPU-accelerated frontend. Finally, we use our pedestrian carried system to evaluate the robustness of the VIO algorithm in several challenging environments. The results show that the multi-camera setup yields significantly higher estimation robustness than a monocular system while not increasing the CPU usage rate (reducing the CPU resource usage rate and computational latency by 40.4% and 50.6% on each camera). A demo video can be found at https://youtu.be/r7QvPth1m10.",
        "primary_area": "",
        "author": "Yao He;Huai Yu;Wen Yang;Sebastian Scherer;Yao He;Huai Yu;Wen Yang;Sebastian Scherer",
        "authorids": "/37089660662;/37086223088;/37290575900;/37584159000;/37089660662;/37086223088;/37290575900;/37584159000",
        "aff": "Electronic Information School, Wuhan University, Wuhan, China; AirLab, Carnegie Mellon University, Pittsburgh, PA, USA; Electronic Information School, Wuhan University, Wuhan, China; AirLab, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981664/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11898518751274655611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Wuhan University;Carnegie Mellon University",
        "aff_unique_dep": "Electronic Information School;AirLab",
        "aff_unique_url": "http://www.whu.edu.cn/;https://www.cmu.edu",
        "aff_unique_abbr": "WHU;CMU",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Wuhan;Pittsburgh",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981309",
        "title": "Towards Safety-Aware Pedestrian Detection in Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a framework to assess the quality of a pedestrian detector in an autonomous driving scenario. To do this, we exploit performance metrics from the domain of computer vision on one side and so-called threat metrics from the motion planning domain on the other side. Based on a reachability analysis that accounts for the uncertainty in future motions of other traffic participants, we can determine the worst-case threat from the planning domain and relate it to the corresponding detection from the visual input. Our evaluation results for a RetinaNet on the Argoverse 1.1 [1] dataset show that already a rather simple threat metric such as time-to-collision (TTC) allows to select potentially dangerous interactions between the ego vehicle and a pedestrian when purely vision-based detections fail, even if they are passed to a subsequent object tracker. In addition, our results show that two different DNNs (Deep Neural Networks) with comparable performance differ significantly in the number of critical scenarios that we can identify with our method.",
        "primary_area": "",
        "author": "Maria Lyssenko;Christoph Gladisch;Christian Heinzemann;Matthias Woehrle;Rudolph Triebel;Maria Lyssenko;Christoph Gladisch;Christian Heinzemann;Matthias Woehrle;Rudolph Triebel",
        "authorids": "/37088954313;/37871053300;/37312476400;/37089309046;/37542908700;/37088954313;/37871053300;/37312476400;/37089309046;/37542908700",
        "aff": "Technical University of Munich, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981309/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7206805752962192021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Technical University of Munich;Robert Bosch GmbH;German Aerospace Center",
        "aff_unique_dep": ";Corporate Research;",
        "aff_unique_url": "https://www.tum.de;https://www.bosch.com;https://www.dlr.de",
        "aff_unique_abbr": "TUM;Bosch;DLR",
        "aff_campus_unique_index": "1;1;1;2",
        "aff_campus_unique": ";Renningen;Wessling",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982046",
        "title": "Towards Specialized Hardware for Learning-based Visual Odometry on the Edge",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based visual odometry (VO) has gained increasing popularity in autonomous navigation of small robots. However, most methods in the category require computation resources not normally available on edge systems. We contend that specialized hardware accelerators are ideal solutions to this problem because of their superior energy efficiency. In this paper, we first propose a model to derive compute specifications for VO from physical characteristics of unmanned aerial vehicles (UAVs). These specifications serve as the basis to guide our accelerator design process. Based on the specifications derived from the DJI Mavic Air 2 and Crazyflie 2.0 UAVs, we explore the speed/flight-time design spaces for three target VO algorithms on two NVIDIA Jetson systems. Then, we propose a hardware accelerator architecture and present prototype implementations based on FPGAs. Additionally, we illustrate the algorithm/hardware co-design approach with a series of hardware-aware algorithmic redesigns targeting the FPGA prototypes, and quantify the throughput-accuracy tradeoff of them. Our FPGA implementation of DFVO is 2.7x more energy efficient compared to off-the-shelf embedded computers.",
        "primary_area": "",
        "author": "Siyuan Chen;Ken Mai;Siyuan Chen;Ken Mai",
        "authorids": "/37089585034;/37270361300;/37089585034;/37270361300",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982046/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4218713396572319417&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981630",
        "title": "Towards Two-view 6D Object Pose Estimation: A Comparative Study on Fusion Strategy",
        "track": "main",
        "status": "Poster",
        "abstract": "Current RGB-based 6D object pose estimation methods have achieved noticeable performance on datasets and real world applications. However, predicting 6D pose from single 2D image features is susceptible to disturbance from changing of environment and textureless or resemblant object surfaces. Hence, RGB-based methods generally achieve less competitive results than RGBD-based methods, which deploy both image features and 3D structure features. To narrow down this performance gap, this paper proposes a framework for 6D object pose estimation that learns implicit 3D information from 2 RGB images. Combining the learned 3D information and 2D image features, we establish more stable correspondence between the scene and the object models. To seek for the methods best utilizing 3D information from RGB inputs, we conduct an investigation on three different approaches, including Early-Fusion, Mid-Fusion, and Late-Fusion. We ascertain the Mid-Fusion approach is the best approach to restore the most precise 3D keypoints useful for object pose estimation. The experiments show that our method outperforms state-of-the-art RGB-based methods, and achieves comparable results with RGBD-based methods.",
        "primary_area": "",
        "author": "Jun Wu;Lilu Liu;Yue Wang;Rong Xiong;Jun Wu;Lilu Liu;Yue Wang;Rong Xiong",
        "authorids": "/37279167900;/37088997987;/37072299700;/37271511300;/37279167900;/37088997987;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control Technology, Institue of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology, Institue of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology, Institue of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology, Institue of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981630/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14114429929943920482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institue of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zhejiang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981628",
        "title": "Towards accurate modeling of modular soft pneumatic robots: from volume FEM to Cosserat rod",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared to their rigid counterparts, soft material robotic systems offer great advantages when it comes to flexibility and adaptability. Despite their advantages, modeling of soft systems is still a challenging task, due to the continuous and often highly nonlinear nature of deformation these systems exhibit. Tasks like motion planning or design optimization of soft robots require computationally cheap models of the system's behavior. In this paper we address this need by deriving operational point dependent Cosserat rod models from detailed volume finite element models (FEM). While the latter offer detailed simulations, they generally come with high computational burden that hinders them from being used in time critical model-based methods like motion planning or control. Basic Cosserat rod models promise to provide computationally efficient mechanical models of soft continuum robots. By using a detailed FE model in an offline stage to identify operational point dependent Cosserat rod models, we bring together the accuracy of volumetric FEM with the efficiency of Cosserat rod models. We apply the approach to a fiber reinforced soft pneumatic bending actuator module (SPA module) and evaluate the model's predictive capabilities for a single module as well as a two-module robot.",
        "primary_area": "",
        "author": "Mats Wiese;Benjamin-Hieu Cao;Annika Raatz;Mats Wiese;Benjamin-Hieu Cao;Annika Raatz",
        "authorids": "/37086148951;/37088910682;/37394383100;/37086148951;/37088910682;/37394383100",
        "aff": "Institute of Assembly Technology Leibniz University, Hannover, Germany; Institute of Assembly Technology Leibniz University, Hannover, Germany; Institute of Assembly Technology Leibniz University, Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981628/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5883542097549825605&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Assembly Technology",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hannover",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981956",
        "title": "Towards edible drones for rescue missions: design and flight of nutritional wings",
        "track": "main",
        "status": "Poster",
        "abstract": "Drones have shown to be useful aerial vehicles for unmanned transport missions such as food and medical supply delivery. This can be leveraged to deliver life-saving nutrition and medicine for people in emergency situations. However, commercial drones can generally only carry 10 %\u201330 % of their own mass as payload, which limits the amount of food delivery in a single flight. One novel solution to noticeably increase the food-carrying ratio of a drone, is recreating some structures of a drone, such as the wings, with edible materials. We thus propose a drone, which is no longer only a food-transporting aircraft, but itself is partially edible, increasing its food-carrying mass ratio to 50 %, owing to its edible wings. Furthermore, should the edible drone be left behind in the environment after performing its task in an emergency situation, it will be more biodegradable than its non-edible counterpart, leaving less waste in the environment. Here we describe the choice of materials and scalable design of edible wings, and validate the method in a flight-capable prototype that can provide 300 kcal and carry a payload of 80 g of water.",
        "primary_area": "",
        "author": "Bokeon Kwak;Jun Shintake;Lu Zhang;Dario Floreano;Bokeon Kwak;Jun Shintake;Lu Zhang;Dario Floreano",
        "authorids": "/37089663382;/37590896900;/37089663507;/37282168700;/37089663382;/37590896900;/37089663507;/37282168700",
        "aff": "Laboratory of Intelligent Systems, School of Engineering, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland; Shintake Research Group, School of Informatics and Engineering, The University of Electro-Communications, Tokyo, Japan; Laboratory of Food Process Engineering, Wageningen University and Research, Wageningen, the Netherlands; Laboratory of Intelligent Systems, School of Engineering, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981956/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11375917746996549627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne;University of Electro-Communications;Wageningen University and Research",
        "aff_unique_dep": "School of Engineering;School of Informatics and Engineering;Laboratory of Food Process Engineering",
        "aff_unique_url": "https://www.epfl.ch;https://www.uec.ac.jp;https://www.wur.nl",
        "aff_unique_abbr": "EPFL;UEC;WUR",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Lausanne;Tokyo;Wageningen",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Switzerland;Japan;Netherlands"
    },
    {
        "id": "9981156",
        "title": "Towards holistic autonomous obstacle detection in railways by complementing of on-board vision with UAV-based object localization",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Marten Franke;Chaitra Reddy;Danijela Risti\u0107-Durrant;Jehan Jayawardana;Kai Michels;Milan Bani\u0107;Milo\u0161 Simonovi\u0107;Marten Franke;Chaitra Reddy;Danijela Risti\u0107-Durrant;Jehan Jayawardana;Kai Michels;Milan Bani\u0107;Milo\u0161 Simonovi\u0107",
        "authorids": "/37089159809;/37089160051;/38276922900;/37089662672;/37085544539;/37089659361;/37089658413;/37089159809;/37089160051;/38276922900;/37089662672;/37085544539;/37089659361;/37089658413",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981156/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16996649286151095226&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14
    },
    {
        "id": "9981203",
        "title": "Tracking monocular camera pose and deformation for SLAM inside the human body",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular SLAM in deformable scenes will open the way to multiple medical applications like computer-assisted navigation in endoscopy, automatic drug delivery or autonomous robotic surgery. In this paper we propose a novel method to simultaneously track the camera pose and the 3D scene deformation, without any assumption about environment topology or shape. The method uses an illumination-invariant photometric method to track image features and estimates camera motion and deformation combining reprojection error with spatial and temporal regularization of deformations. Our results in simulated colonoscopies show the method's accuracy and robustness in complex scenes under increasing levels of deformation. Our qualitative results in human colonoscopies from Endomapper dataset show that the method is able to successfully cope with the challenges of real endoscopies: deformations, low texture and strong illumination changes. We also compare with previous tracking methods in simpler scenarios from Hamlyn dataset where we obtain competitive performance, without needing any topological assumption.",
        "primary_area": "",
        "author": "Juan J. G\u00f3mez Rodr\u00edguez;J.M.M. Montiel;Juan D. Tard\u00f3s;Juan J. G\u00f3mez Rodr\u00edguez;J.M.M. Montiel;Juan D. Tard\u00f3s",
        "authorids": "/37088999448;/37274019300;/37351680900;/37088999448;/37274019300;/37351680900",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981203/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12352662849512494790&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9981112",
        "title": "Training Dynamic Motion Primitives using Deep Reinforcement Learning to Control a Robotic Tadpole",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing a good control strategy for biomimetic robots is challenging. Robust control methods require an accurate model of the robot. Nowadays, model-free methods are being extensively explored for the control and navigation of terrestrial robots. In this paper, we consider a novel deep reinforcement learning-based model-free swimming control for our bio-inspired robotic tadpole. To realize this, we utilize dynamic motion primitives, which can represent a large range of motion behaviors, and combine them with a decoupled reinforcement learning framework. The proposed architecture optimizes the motion primitives first to develop a travelling wave undulation pattern in the tail and then to navigate the robot along different predefined paths. Through this framework, effective swimming gait emerges, and the robot is able to navigate well on the surface of water. This framework combines the optimization potential of deep reinforcement learning with stability and generalization properties of dynamic motion primitives. We train and test our method on a simulated model of the robot to demonstrate the effectiveness of the method and also conduct experimental testing on the real robot to verify the results.",
        "primary_area": "",
        "author": "Imran Hameed;Xu Chao;David Navarro-Alarcon;Xingjian Jing;Imran Hameed;Xu Chao;David Navarro-Alarcon;Xingjian Jing",
        "authorids": "/37089190082;/37089661745;/38271697000;/37710156400;/37089190082;/37089661745;/38271697000;/37710156400",
        "aff": "Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong, China; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong, China; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981112/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3821999719175427308&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Hong Kong Polytechnic University;City University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.cityu.edu.hk",
        "aff_unique_abbr": "PolyU;CityU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981294",
        "title": "Trajectory Optimization and Following for a Three Degrees of Freedom Overactuated Floating Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Space robotics applications, such as Active Space Debris Removal (ASDR), require representative testing before launch. A commonly used approach to emulate the microgravity environment in space is air-bearing based platforms on flat-floors, such as the European Space Agency's Orbital Robotics and GNC Lab (ORGL). This work proposes a control architecture for a floating platform at the ORGL, equipped with eight solenoid-valve-based thrusters and one reaction wheel. The control architecture consists of two main components: a trajectory planner that finds optimal trajectories connecting two states and a trajectory follower that follows any physically feasible trajectory. The controller is first evaluated within an introduced simulation, achieving a 100% success rate at finding and following trajectories to the origin within a Monte-Carlo test. Individual trajectories are also successfully followed by the physical system. In this work, we showcase the ability of the controller to reject disturbances and follow a straight-line trajectory within tens of centimeters.",
        "primary_area": "",
        "author": "A. Bredenbeck;S. Vyas;M. Zwick;D. Borrmann;M.A. Olivares-Mendez;A. N\u00fcchter;A. Bredenbeck;S. Vyas;M. Zwick;D. Borrmann;M.A. Olivares-Mendez;A. N\u00fcchter",
        "authorids": "/37088754079;/37089662208;/37089657510;/37591151900;/38271290600;/37273297900;/37088754079;/37089662208;/37089657510;/37591151900;/38271290600;/37273297900",
        "aff": "Automation and Robotics Group, ESA, Noordwijk, Netherlands; Robotics Innovation Center (RIC), DFKI Bremen, Germany; Automation and Robotics Group, ESA, Noordwijk, Netherlands; Informatics VII, University of W\u00fcrzburg, Germany; SpaceR-SnT, University of Luxembourg, Luxembourg; Informatics VII, University of W\u00fcrzburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981294/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7078602225877603531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;2",
        "aff_unique_norm": "European Space Agency;German Research Center for Artificial Intelligence;University of W\u00fcrzburg;University of Luxembourg",
        "aff_unique_dep": "Automation and Robotics Group;Robotics Innovation Center;Informatics VII;SpaceR-SnT",
        "aff_unique_url": "https://www.esa.int;https://www.dfki.de;https://www.uni-wuerzburg.de;https://wwwen.unil.lu",
        "aff_unique_abbr": "ESA;DFKI;;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Noordwijk;Bremen;",
        "aff_country_unique_index": "0;1;0;1;2;1",
        "aff_country_unique": "Netherlands;Germany;Luxembourg"
    },
    {
        "id": "9981923",
        "title": "Trajectory Prediction with Graph-based Dual-scale Context Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction for traffic participants is essential for a safe and robust automated driving system, especially in cluttered urban environments. However, it is highly challenging due to the complex road topology as well as the uncertain intentions of the other agents. In this paper, we present a graph-based trajectory prediction network named the Dual Scale Predictor (DSP), which encodes both the static and dynamical driving context in a hierarchical manner. Different from methods based on a rasterized map or sparse lane graph, we consider the driving context as a graph with two layers, focusing on both geometrical and topological features. Graph neural networks (GNNs) are applied to extract features with different levels of granularity, and features are subsequently aggregated with attention-based inter-layer networks, realizing better local-global feature fusion. Following the recent goal-driven trajectory prediction pipeline, goal candidates with high likelihood for the target agent are extracted, and predicted trajectories are generated conditioned on these goals. Thanks to the proposed dual-scale context fusion network, our DSP is able to generate accurate and human-like multi-modal trajectories. We evaluate the proposed method on the large-scale Argoverse motion forecasting benchmark, and it achieves promising results, outperforming the recent state-of-the-art methods. We release the code on our project website. 11https://github.com/HKUST-Aerial-Robotics/DSP",
        "primary_area": "",
        "author": "Lu Zhang;Peiliang Li;Jing Chen;Shaojie Shen;Lu Zhang;Peiliang Li;Jing Chen;Shaojie Shen",
        "authorids": "/37086877483;/37086229175;/37085773294;/37954847200;/37086877483;/37086229175;/37085773294;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; DJI Technology Company, Ltd., Shenzhen, China; DJI Technology Company, Ltd., Shenzhen, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981923/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7321353001379859894&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;DJI Technology Company, Ltd.",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;",
        "aff_unique_url": "https://www.ust.hk;https://www.dji.com",
        "aff_unique_abbr": "HKUST;DJI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981445",
        "title": "TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional video-based human activity recognition has experienced remarkable progress linked to the rise of deep learning, but this effect was slower as it comes to the downstream task of driver behavior understanding. Understanding the situation inside the vehicle cabin is essential for Advanced Driving Assistant System (ADAS) as it enables identifying distraction, predicting driver's intent and leads to more convenient human-vehicle interaction. At the same time, driver observation systems face substantial obstacles as they need to capture different granularities of driver states, while the complexity of such secondary activities grows with the rising automation and increased driver freedom. Furthermore, a model is rarely deployed under conditions identical to the ones in the training set, as sensor placements and types vary from vehicle to vehicle, constituting a substantial obstacle for real-life deployment of data-driven models. In this work, we present a novel vision-based framework for recognizing secondary driver behaviours based on visual transformers and an additional augmented feature distribution calibration module. This module operates in the latent feature-space enriching and diversifying the training set at feature-level in order to improve generalization to novel data appearances, (e.g., sensor changes) and general feature quality. Our framework consistently leads to better recognition rates, surpassing previous state-of-the-art results of the public Drive&Act benchmark on all granularity levels. Our code will be made publicly available at https://github.com/KPeng9510/TransDARC.",
        "primary_area": "",
        "author": "Kunyu Peng;Alina Roitberg;Kailun Yang;Jiaming Zhang;Rainer Stiefelhagen;Kunyu Peng;Alina Roitberg;Kailun Yang;Jiaming Zhang;Rainer Stiefelhagen",
        "authorids": "/37089161139;/37085584903;/37086488716;/37088953062;/37269459200;/37089161139;/37085584903;/37086488716;/37088953062;/37269459200",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981445/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10678332842388514167&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981089",
        "title": "Transactional Transform Library for ROS",
        "track": "main",
        "status": "Poster",
        "abstract": "In the Robot Operating System (ROS), a major middleware for robots, the Transform Library (TF) is a mandatory package that manages transformation information between coordinate systems by using a single-rooted directed tree and providing methods for registering and computing the information. However, the tree has two fundamental problems. The first is its poor scalability: since it accepts only a single thread at a time due to using a single giant lock for mutual exclusion, the access to the tree is sequential. Second, there is a lack of data freshness: it retrieves non-latest synthetic data when computing coordinate transformations because it prioritizes temporal consistency over data freshness. In this paper, we propose methods to solve these problems. First, we decentralize the giant lock to provide performance scalability and show that this results in a throughput 243 times higher than conventional TF on a read-only workload. Second, we design transactional methods based on serializable protocols that prevent anomalies, thus retrieving the freshest data. These transactional methods show a freshness up to 1276 times higher than the conventional one on a read-write combined workload.",
        "primary_area": "",
        "author": "Yushi Ogiwara;Ayanori Yorozu;Akihisa Ohya;Hideyuki Kawashima;Yushi Ogiwara;Ayanori Yorozu;Akihisa Ohya;Hideyuki Kawashima",
        "authorids": "/37089431694;/37085523671;/37294387000;/37287160400;/37089431694;/37085523671;/37294387000;/37287160400",
        "aff": "Graduate School of Media and Governance, Keio University, Keio; Faculty of Engineering, Information and Systems, University of Tsukuba, Tsukuba; Faculty of Engineering, Information and Systems, University of Tsukuba, Tsukuba; Faculty of Environment and Information Studies, Keio University, Keio",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981089/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3516220468107060012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Keio University;University of Tsukuba",
        "aff_unique_dep": "Graduate School of Media and Governance;Faculty of Engineering, Information and Systems",
        "aff_unique_url": "https://www.keio.ac.jp;https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "Keio;UT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Keio;Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981082",
        "title": "Transfer Learning for Machine Learning-based Detection and Separation of Entanglements in Bin-Picking Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a Domain Randomization and a Domain Adaptation approach to transfer experience for entanglement detection and separation from simulation into a real-world bin-picking application. We investigate the influence of different randomization options in image processing and use a CycleGAN as a further Domain Adaptation method to synthesize simulation data as realistically as possible. On the basis of this adapted data we re-train our detection and separation methods and validate the usefulness of these Sim-to-Real methods. In numerous real-world experiments we show that we achieve a significant increase of up to 71.74 % in the performance of the overall system by using the Sim-to-Real approaches as opposed to the direct transfer.",
        "primary_area": "",
        "author": "Marius Moosmann;Felix Spenrath;Johannes Rosport;Philipp Melzer;Werner Kraus;Richard Bormann;Marco F. Huber;Marius Moosmann;Felix Spenrath;Johannes Rosport;Philipp Melzer;Werner Kraus;Richard Bormann;Marco F. Huber",
        "authorids": "/37088690603;/37086008958;/37089662923;/37086548880;/37357181400;/38541025900;/37392400600;/37088690603;/37086008958;/37089662923;/37086548880;/37357181400;/38541025900;/37392400600",
        "aff": "Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Center for Cyber Cognitive Intelligence (CCI), Fraunhofer IPA, Stuttgart, Germany, Institute of Industrial Manufacturing and Management IFF, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981082/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13486002372974104332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;Fraunhofer IPA",
        "aff_unique_dep": "Department Robot and Assistive Systems;Center for Cyber Cognitive Intelligence (CCI)",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": "Fraunhofer IPA;Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981458",
        "title": "Transferring Dexterous Manipulation from GPU Simulation to a Remote Real-World TriFinger",
        "track": "main",
        "status": "Poster",
        "abstract": "In-hand manipulation of objects is an important capability to enable robots to carry-out tasks which demand high levels of dexterity. This work presents a robot systems approach to learning dexterous manipulation tasks involving moving objects to arbitrary 6-DoF poses. We show empirical benefits, both in simulation and sim - to- real transfer, of using keypoint-based representations for object pose in policy observations and reward calculation to train a model-free reinforcement learning agent. By utilizing domain randomization strategies and large-scale training, we achieve a high success rate of 83 % on a real TriFinger system, with a single policy able to perform grasping, ungrasping, and finger gaiting in order to achieve arbitrary poses within the workspace. We demonstrate that our policy can generalise to unseen objects, and success rates can be further improved through finetuning. With the aim of assisting further research in learning in-hand manipulation, we provide a detailed exposition of our system and make the codebase of our system available, along with checkpoints trained on billions of steps of experience, at https://s2r2-ig.github.io",
        "primary_area": "",
        "author": "Arthur Allshire;Mayank MittaI;Varun Lodaya;Viktor Makoviychuk;Denys Makoviichuk;Felix Widmaier;Manuel W\u00fcthrich;Stefan Bauer;Ankur Handa;Animesh Garg;Arthur Allshire;Mayank MittaI;Varun Lodaya;Viktor Makoviychuk;Denys Makoviichuk;Felix Widmaier;Manuel W\u00fcthrich;Stefan Bauer;Ankur Handa;Animesh Garg",
        "authorids": "/37089002143;/37089662864;/37088926869;/37086938547;/37089659184;/37085619493;/38251664400;/37087095662;/37546502600;/37086330576;/37089002143;/37089662864;/37088926869;/37086938547;/37089659184;/37085619493;/38251664400;/37087095662;/37546502600;/37086330576",
        "aff": "Nvidia; ETH Zurich; University of Toronto, Vector Institute; Nvidia; Snap; MPI Tubingen; MPI Tubingen; KTH; Nvidia; Nvidia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981458/",
        "gs_citation": 77,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15269767142297414777&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;2;0;3;4;4;5;0;0",
        "aff_unique_norm": "NVIDIA;ETH Zurich;University of Toronto;Snap Inc.;Max Planck Institute for Biological Cybernetics;KTH Royal Institute of Technology",
        "aff_unique_dep": "NVIDIA Corporation;;;;;",
        "aff_unique_url": "https://www.nvidia.com;https://www.ethz.ch;https://www.utoronto.ca;https://www.snap.com;https://www.cbs.mpg.de;https://www.kth.se",
        "aff_unique_abbr": "NVIDIA;ETHZ;U of T;Snap;MPI CBS;KTH",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";Toronto;T\u00fcbingen",
        "aff_country_unique_index": "0;1;2;0;0;3;3;4;0;0",
        "aff_country_unique": "United States;Switzerland;Canada;Germany;Sweden"
    },
    {
        "id": "9981319",
        "title": "Transferring Multi-Agent Reinforcement Learning Policies for Autonomous Driving using Sim-to-Real",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Driving requires high levels of coordination and collaboration between agents. Achieving effective coordination in multi-agent systems is a difficult task that remains largely unresolved. Multi-Agent Reinforcement Learning has arisen as a powerful method to accomplish this task because it considers the interaction between agents and also allows for decentralized training\u2014which makes it highly scalable. However, transferring policies from simulation to the real world is a big challenge, even for single-agent applications. Multi-agent systems add additional complexities to the Sim-to-Real gap due to agent collaboration and environment synchronization. In this paper, we propose a method to transfer multi-agent autonomous driving policies to the real world. For this, we create a multi-agent environment that imitates the dynamics of the Duckietown multi-robot testbed, and train multi-agent policies using the MAPPO algorithm with different levels of domain randomization. We then transfer the trained policies to the Duckietown testbed and show that when using our method, domain randomization can reduce the reality gap by 90%. Moreover, we show that different levels of parameter randomization have a substantial impact on the Sim-to-Real gap. Finally, our approach achieves significantly better results than a rule-based benchmark.",
        "primary_area": "",
        "author": "Eduardo Candela;Leandro Parada;Luis Marques;Tiberiu-Andrei Georgescu;Yiannis Demiris;Panagiotis Angeloudis;Eduardo Candela;Leandro Parada;Luis Marques;Tiberiu-Andrei Georgescu;Yiannis Demiris;Panagiotis Angeloudis",
        "authorids": "/37088595600;/37089662586;/205824351841654;/37089662230;/37296338900;/37086543442;/37088595600;/37089662586;/205824351841654;/37089662230;/37296338900;/37086543442",
        "aff": "Department of Civil and Environmental Engineering, Centre for Transport Studies, Imperial College London, UK; Department of Civil and Environmental Engineering, Centre for Transport Studies, Imperial College London, UK; Department of Civil and Environmental Engineering, Centre for Transport Studies, Imperial College London, UK; Department of Civil and Environmental Engineering, Centre for Transport Studies, Imperial College London, UK; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, UK; Department of Civil and Environmental Engineering, Centre for Transport Studies, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981319/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4434346053586286322&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9982083",
        "title": "Transmissibility-based DAgger For Fault Classification in Connected Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Fault mitigation in Connected Autonomous Vehicle (CAV) platoons is faster and more reliable if the fault structure is known. In this paper we propose using transmissibility operators, which are relationships that relate a set of velocities with another in the platoon, to classify the faults. Transmissibility operators were shown to be exceptional in signals estimation; however, its also shown to be noncausal and thus can only be used offline. To this end, we propose using Data Aggregation (DAgger), which is an extension in imitation learning to transfer the classification experience from transmissibility operators to a novice machine learning agent to be used online. A heterogeneous CAV platoon was modeled with three different faults separately. These faults are actuator disturbances, false data injection attacks, and communication time delay. The proposed algorithm is then tested on the platoon model and then applied to an experimental setup that consists of three autonomous robots. The overall classification accuracy achieved was 95.8% for the experiment.",
        "primary_area": "",
        "author": "Abdelrahman Khalil;Mohammad Al Janaideh;Lourdes Pe\u00f1a Castillo;Octavia A. Dobre;Abdelrahman Khalil;Mohammad Al Janaideh;Lourdes Pe\u00f1a Castillo;Octavia A. Dobre",
        "authorids": "/37088482852;/37657960900;/37089663842;/37276617100;/37088482852;/37657960900;/37089663842;/37276617100",
        "aff": "Memorial University of Newfoundland, St. John's, Canada; Memorial University of Newfoundland, St. John's, Canada; Memorial University of Newfoundland, St. John's, Canada; Memorial University of Newfoundland, St. John's, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982083/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:_7FgyY5PlMkJ:scholar.google.com/&scioq=Transmissibility-based+DAgger+For+Fault+Classification+in+Connected+Autonomous+Vehicles&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Memorial University of Newfoundland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "MUN",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "St. John's",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9981832",
        "title": "Transporters with Visual Foresight for Solving Unseen Rearrangement Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Rearrangement tasks have been identified as a crucial challenge for intelligent robotic manipulation, but few methods allow for precise construction of unseen structures. We propose a visual foresight model for pick-and-place rearrangement manipulation which is able to learn efficiently. In addition, we develop a multi-modal action proposal module which builds on the Goal-Conditioned Transporter Network, a state-of-the-art imitation learning method. Our image-based task planning method, Transporters with Visual Foresight, is able to learn from only a handful of data and generalize to multiple unseen tasks in a zero-shot manner. TVF is able to improve the performance of a state-of-the-art imitation learning method on unseen tasks in simulation and real robot experiments. In particular, the average success rate on unseen tasks improves from 55.4% to 78.5% in simulation experiments and from 30% to 63.3% in real robot experiments when given only tens of expert demonstrations. Video and code are available on our project website: https://chirikjianlab.github.io/tvf/",
        "primary_area": "",
        "author": "Hongtao Wu;Jikai Ye;Xin Meng;Chris Paxton;Gregory S. Chirikjian;Hongtao Wu;Jikai Ye;Xin Meng;Chris Paxton;Gregory S. Chirikjian",
        "authorids": "/37087010228;/37089661046;/37089450929;/37085403975;/37283175100;/37087010228;/37089661046;/37089450929;/37085403975;/37283175100",
        "aff": "The Johns Hopkins University, Baltimore, MD, USA; National University of Singapore, Singapore; National University of Singapore, Singapore; NVIDIA, USA; National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981832/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8722123492771124711&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Johns Hopkins University;National University of Singapore;NVIDIA",
        "aff_unique_dep": ";;NVIDIA",
        "aff_unique_url": "https://www.jhu.edu;https://www.nus.edu.sg;https://www.nvidia.com",
        "aff_unique_abbr": "JHU;NUS;NV",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9981481",
        "title": "Trifocal Tensor and Relative Pose Estimation from 8 Lines and Known Vertical Direction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a relative pose estimation algorithm based on lines knowing the vertical direction associated to each image. We demonstrate that a closed-form solution requiring only eight lines between three views is possible. As a linear solution, it is shown that our approach outperforms the standard trifocal estimation based on 13 triplets of lines and can be efficiently inserted into an hypothesize-and-test framework such as RANSAC. We also study our approach on different singular configurations of lines. The method is evaluated on both synthetic data and real-world sequences from KITTI and the Z\u00fcrich Urban Micro Aerial Vehicle datasets. Our method is compared to 13 lines algorithm as well to points based methods such as 7-points, 5-points and 3-points.",
        "primary_area": "",
        "author": "Banglei Guan;Pascal Vasseur;C\u00e9dric Demonceaux;Banglei Guan;Pascal Vasseur;C\u00e9dric Demonceaux",
        "authorids": "/37086452960;/37395435900;/37265984700;/37086452960;/37395435900;/37265984700",
        "aff": "College of Aerospace Science and Engineering, National University of Defense Technology, China; MIS (Mod\u00e9lisation, Information & Syst\u00e8mes), Universit\u00e9 de Picardie Jules Verne, France; ImViA, Universit\u00e9 Bourgogne Franche-Comt\u00e9, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981481/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17433833762140391794&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "National University of Defense Technology;Universit\u00e9 de Picardie Jules Verne;Universit\u00e9 Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "College of Aerospace Science and Engineering;MIS (Mod\u00e9lisation, Information & Syst\u00e8mes);ImViA",
        "aff_unique_url": ";https://www.univ-ji.fr;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;France"
    },
    {
        "id": "9981957",
        "title": "UAV-miniUGV Hybrid System for Hidden Area Exploration and Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel hybrid system (both hardware and software) of an Unmanned Aerial Vehicle (UAV) carrying a miniature Unmanned Ground Vehicle (miniUGV) to perform a complex search and manipulation task. This system leverages the heterogeneous robots to accomplish a task that cannot be done using a single robot system. It enables the UAV to explore a hidden space with a narrow opening through which the miniUGV can easily enter and escape. The hidden space is assumed to be navigable for the miniUGV. The miniUGV uses Infrared (IR) sensors and a monocular camera to search an object in the hidden space. The proposed system takes advantage of a wider field of view (fov) of camera as well as the stochastic nature of the object detection algorithms to guide the miniUGV in the hidden space to find the object. Upon finding the object the miniUGV grabs it using visual servoing and then returns back to its start point from where the UAV retracts it back and transports the object to a safe place. In case there is no object found in the hidden space, UAV continues the aerial search. The tethered miniUGV gives the UAV an ability to act beyond its reach and perform a search and manipulation task which was not possible before for any of the robots individually. The system has a wide range of applications and we have demonstrated its feasibility through repetitive experiments.",
        "primary_area": "",
        "author": "Durgakant Pushp;Swapnil Kalhapure;Kaushik Das;Lantao Liu;Durgakant Pushp;Swapnil Kalhapure;Kaushik Das;Lantao Liu",
        "authorids": "/37086945943;/37089663715;/37086084983;/37085785167;/37086945943;/37089663715;/37086084983;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA; Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; TCS Research, India; Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981957/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5457769009793692367&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Indiana University;University of Sheffield;Tata Consultancy Services",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;Automatic Control and Systems Engineering Department;Research",
        "aff_unique_url": "https://www.indiana.edu;https://www.sheffield.ac.uk;https://www.tcs.com",
        "aff_unique_abbr": "IU;Sheffield;TCS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Bloomington;Sheffield;",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;United Kingdom;India"
    },
    {
        "id": "9982170",
        "title": "ULSM: Underground Localization and Semantic Mapping with Salient Region Loop Closure under Perceptually-Degraded Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) has greatly assisted in exploring perceptually-degraded underground environments, such as human-made tunnels, mine tunnels, and caves. However, the recurring sensor failures and spurious loop closures in these scenes bring significant challenges to applying SLAM. This paper proposes an architecture for underground localization and semantic mapping (ULSM) that promotes the robustness of odometry estimation and map-building. In this architecture, a two-stage robust motion compensation method is proposed to adapt to sensor-failure situations. The proposed salient region loop closure detection contributes to avoiding spurious loop closures. Meanwhile, the 2D pose as the initial value for point cloud registration is estimated without additional input. We also design a multi-robot cooperative mapping scheme based on descriptors of the salient region. Extensive experiments are conducted on datasets collected in the Tunnel Circuit of DARPA Subterranean Challenge.",
        "primary_area": "",
        "author": "Junhui Wang;Bin Tian;Rui Zhang;Long Chen;Junhui Wang;Bin Tian;Rui Zhang;Long Chen",
        "authorids": "/37089582584;/37968848300;/37089583850;/37085668482;/37089582584;/37968848300;/37089583850;/37085668482",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Waytous Inc., Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982170/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14347870881653623468&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Waytous Inc.",
        "aff_unique_dep": "School of Artificial Intelligence;",
        "aff_unique_url": "http://www.ucas.ac.cn;",
        "aff_unique_abbr": "UCAS;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981364",
        "title": "UWRange: An Open ROS Framework for Simulating Acoustic Ranging and Localization for Underwater Robots under Realistic Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Considering realistic characteristics of acoustic localization methods is crucial for roboticists when developing guidance and control algorithms for small and agile underwater robots. Current simulators either rely purely on geometric distancing, i.e. do not consider dynamic effects such as robot motion during acoustic signal propagation, or they are too complex for usage by non-communication experts and, thus, vulnerable to misconfiguration. We propose an open ROS-based framework that extends existing robot simulators (e. g. Gazebo) by simulating the effects of realistic acoustic ranging for underwater robot localization. Thus, our simulator enables realistic real-time analysis and evaluation of guidance, navigation, and control algorithms in software in-the-loop systems. For this purpose, we incorporate and encapsulate the non-trivial characteristics of acoustic communication and ranging such as robot motion during signal propagation, packet reception failure, and modem timings. This ensures the applicability of the tool by roboticists who are typically non-experts in acoustic communication and guarantees accurate and realistic simulation results. We demonstrate the functionality and performance of our framework and validate it on real-world experimental data on the example of a two-way ranging method. Our open-source release includes well-defined interfaces and parameters as well as a tutorial. This targets other roboticists who can either use our framework directly or easily adapt it to their individual setup, e. g., by adding further acoustic-ranging protocols.",
        "primary_area": "",
        "author": "Fabian Steinmetz;Daniel A Duecker;Nils Sichert;Christian Busse;Edwin Kreuzer;Bernd-Christian Renner;Fabian Steinmetz;Daniel A Duecker;Nils Sichert;Christian Busse;Edwin Kreuzer;Bernd-Christian Renner",
        "authorids": "/37086585785;/37086262227;/37089662327;/37089299318;/37622316900;/37685162600;/37086585785;/37086262227;/37089662327;/37089299318;/37622316900;/37685162600",
        "aff": "Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981364/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7450765630833694205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hamburg University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tuhh.de/",
        "aff_unique_abbr": "TUHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981635",
        "title": "Ultrasound Tracking and Closed-Loop Control of a Magnetically-Actuated Biomimetic Soft Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Small untethered soft robots have potential for diverse applications, particularly in constrained spaces where the use of a tethered device would be infeasible. Examples include biomedical applications such as brachytherapy, fine-needle biospy and micro-needle drug delivery. To advance soft robots towards these applications, there is a need to establish methods for tracking and control using clinically-relevant methods. This study demonstrates motion planning and magnetic control of a soft untethered robot, using ultrasound images as feedback. The closed-loop control of the Millipede soft robot is first validated using a camera-based tracker, where the deviation between the planned path and the trajectory of the robot is 1.71 mm. Afterwards, two methods for ultrasound-based tracking capable of estimating the pose of the robot are proposed, a geometric approach and a convolutional neural network (CNN), and their performance is compared using a video camera as ground truth. Following this, the CNN method replaces the camera tracker to estimate the position and orientation of the robot. The closed-loop system using ultrasound images guides the robot through the workspace while avoiding virtual obstacles, and achieves an average tracking error of 1.59 mm and an angle error of 2.24\u00b0.",
        "primary_area": "",
        "author": "Artur Jo\u00e3o Anjos de Oliveira;Jorge Batista;Sarthak Misra;Venkatasubramanian Kalpathy Venkiteswaran;Artur Jo\u00e3o Anjos de Oliveira;Jorge Batista;Sarthak Misra;Venkatasubramanian Kalpathy Venkiteswaran",
        "authorids": "/37089661351;/37356292400;/37536488800;/37086693104;/37089661351;/37356292400;/37536488800;/37086693104",
        "aff": "Department of Electrical Engineering and Computers, University of Coimbra, Institute of Systems and Robotics, Coimbra, Portugal; Department of Electrical Engineering and Computers, University of Coimbra, Institute of Systems and Robotics, Coimbra, Portugal; Department of Biomedical Engineering, University of Groningen and University Medical Centre Groningen, Groningen, GZ, The Netherlands; Department of Biomechanical Engineering, Surgical Robotics Laboratory, University of Twente, Enschede, AE, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981635/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7314401440197425960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Coimbra;University of Groningen;University of Twente",
        "aff_unique_dep": "Department of Electrical Engineering and Computers;Department of Biomedical Engineering;Department of Biomechanical Engineering",
        "aff_unique_url": "https://www.uc.pt;https://www.rug.nl;https://www.utwente.nl",
        "aff_unique_abbr": "UC;RUG;UT",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Coimbra;Groningen;Enschede",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "Portugal;Netherlands"
    },
    {
        "id": "9981095",
        "title": "Unbiased Active Inference for Classical Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Active inference is a mathematical framework that originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behavior in robotics. Specifically, the active inference controller (AIC) has been successful on several continuous control and state-estimation tasks. Despite its relative success, some established design choices lead to a number of practical limitations for robot control. These include having a biased estimate of the state, and only an implicit model of control actions. In this paper, we highlight these limitations and propose an extended version of the unbiased active inference controller (u-AIC). The u-AIC maintains all the compelling benefits of the AIC and removes its limitations. Simulation results on a 2-DOF arm and experiments on a real 7-DOF manipulator show the improved performance of the u-AIC with respect to the standard AIC. The code can be found at https://github.com/cpezzato/unbiasedaic.",
        "primary_area": "",
        "author": "Mohamed Baioumy;Corrado Pezzato;Riccardo Ferrari;Nick Hawes;Mohamed Baioumy;Corrado Pezzato;Riccardo Ferrari;Nick Hawes",
        "authorids": "/37086937698;/37088230141;/37841777200;/37590842900;/37086937698;/37088230141;/37841777200;/37590842900",
        "aff": "Oxford Robotics Institute, Oxford University; Cognitive Robotics Department, TU Delft; Department of Systems and Control, TU Delft; Oxford Robotics Institute, Oxford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981095/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15610042257049646625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Oxford University;Delft University of Technology",
        "aff_unique_dep": "Oxford Robotics Institute;Cognitive Robotics Department",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.tudelft.nl",
        "aff_unique_abbr": "Oxford;TU Delft",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Oxford;Delft",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "9981053",
        "title": "Understanding Acoustic Patterns of Human Teachers Demonstrating Manipulation Tasks to Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans use audio signals in the form of spoken language or verbal reactions effectively when teaching new skills or tasks to other humans. While demonstrations allow humans to teach robots in a natural way, learning from trajectories alone does not leverage other available modalities including audio from human teachers. To effectively utilize audio cues accompanying human demonstrations, first it is important to understand what kind of information is present and conveyed by such cues. This work characterizes audio from human teachers demonstrating multi-step manipulation tasks to a situated Sawyer robot along three dimensions: (1) duration of speech used, (2) expressiveness in speech or prosody, and (3) semantic content of speech. We analyze these features for four different independent variables and find that teachers convey similar semantic content via spoken words for different conditions of (1) demonstration types, (2) audio usage instructions, (3) subtasks, and (4) errors during demonstrations. However, differentiating properties of speech in terms of duration and expressiveness are present for the four independent variables, highlighting that human audio carries rich information, potentially beneficial for technological advancement of robot learning from demonstration methods.",
        "primary_area": "",
        "author": "Akanksha Saran;Kush Desai;Mai Lee Chang;Rudolf Lioutikov;Andrea Thomaz;Scott Niekum;Akanksha Saran;Kush Desai;Mai Lee Chang;Rudolf Lioutikov;Andrea Thomaz;Scott Niekum",
        "authorids": "/37085716426;/37089661406;/37088529346;/37085362450;/37296354000;/37395003900;/37085716426;/37089661406;/37088529346;/37085362450;/37296354000;/37395003900",
        "aff": "Microsoft Research, University of Texas at Austin, New York, NY, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Karlsruhe Institute of Technology, Karl-sruhe, BW, Germany; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981053/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14000639229131748250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.utexas.edu;https://www.kit.edu",
        "aff_unique_abbr": "UT Austin;KIT",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Austin;Karlsruhe",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9981771",
        "title": "Understanding Spatio-Temporal Relations in Human-Object Interaction using Pyramid Graph Convolutional Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Human activities recognition is an important task for an intelligent robot, especially in the field of human-robot collaboration, it requires not only the label of sub-activities but also the temporal structure of the activity. In order to automatically recognize both the label and the temporal structure in sequence of human-object interaction, we propose a novel Pyramid Graph Convolutional Network (PGCN), which employs a pyramidal encoder-decoder architecture consisting of an attention based graph convolution network and a temporal pyramid pooling module for downsampling and upsampling interaction sequence on the temporal axis, respectively. The system represents the 2D or 3D spatial relation of human and objects from the detection results in video data as a graph. To learn the human-object relations, a new attention graph convolutional network is trained to extract condensed information from the graph representation. To segment action into sub-actions, a novel temporal pyramid pooling module is proposed, which upsamples compressed features back to the original time scale and classifies actions per frame. We explore various attention layers, namely spatial attention, temporal attention and channel attention, and combine different upsampling decoders to test the performance on action recognition and segmentation. We evaluate our model on two challenging datasets in the field of human-object interaction recognition, i.e. Bimanual Actions and IKEA Assembly datasets. We demonstrate that our classifier significantly improves both framewise action recognition and segmentation, e.g., F1 micro and F1@50 scores on Bimanual Actions dataset are improved by 4.3% and 8.5% respectively.",
        "primary_area": "",
        "author": "Hao Xing;Darius Burschka;Hao Xing;Darius Burschka",
        "authorids": "/37089197003;/37267429200;/37089197003;/37267429200",
        "aff": "Department of Computer Science, Machine Vision and Perception Group, Technical University of Munich, Munich, Germany; Department of Computer Science, Machine Vision and Perception Group, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981771/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=996362910344739940&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981206",
        "title": "Uniform Global Exponential Stabilizing Passivity-Based Tracking Controller Applied to Planar Biped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel control approach, based on the interconnection and damping-assignment passivity-based control (IDA-PBC), to achieve stable and periodic walking for underactuated planar biped robots with one degree of underactuation. The system's physical structure is preserved by assigning a target port-Hamiltonian dynamics to the closed-loop system, which also ensures passivity. The control design ensures that the tracking error to the desired periodic gait converges exponentially to zero, and the convergence rate can be adjusted via gain tuning. Besides, through the hybrid zero dynamics, the stability of the full-order system can be retrieved from the stability of the orbit created in a lower-dimensional manifold. The proposed approach is the first example of a tracking controller based on the IDA-PBC applied to underactuated biped robots. Numerical simulations on a five-link planar biped robot with unactuated ankles validate the approach and show the performance of the closed-loop system.",
        "primary_area": "",
        "author": "Pierluigi Arpenti;Alejandro Donaire;Fabio Ruggiero;Vincenzo Lippiello;Pierluigi Arpenti;Alejandro Donaire;Fabio Ruggiero;Vincenzo Lippiello",
        "authorids": "/37086806035;/38152314000;/37368775100;/37328749600;/37086806035;/38152314000;/37368775100;/37328749600",
        "aff": "PRISMA Lab,Department of Electrical Engineering and Information Technologies University of Naples Federico II, Via Claudio 21, Naples, Italy; The University of Newcastle,University Drive, Callaghan, NSW, Australia; PRISMA Lab,Department of Electrical Engineering and Information Technologies University of Naples Federico II, Via Claudio 21, Naples, Italy; PRISMA Lab,Department of Electrical Engineering and Information Technologies University of Naples Federico II, Via Claudio 21, Naples, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981206/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18000173245271061924&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Naples Federico II;University of Newcastle",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technologies;",
        "aff_unique_url": "https://www.unina.it;https://www.newcastle.edu.au",
        "aff_unique_abbr": ";UON",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Naples;Callaghan",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Italy;Australia"
    },
    {
        "id": "9981067",
        "title": "Unilateral stiffness modulation with a robotic hip exoskeleton elicits adaptation during gait",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robotic exoskeletons show promise in their ability to provide gait assistance and rehabilitation in real-world contexts. However, a better understanding is needed of how exoskeletons contribute to neural adaptation in locomotion, a critical component of neurological gait rehabilitation. We tested whether unilateral perturbations elicit neural adaptation in healthy participants using a novel robotic hip exoskeleton, taking inspiration from asymmetry augmentation strategies used in split-belt treadmill training. We found that applying a virtual stiffness parallel to the hip joint on one side elicited changes in hip range of motion and step length, and that these changes were time varying, indicating an adaptation response. However, participants converged on asymmetric hip ranges of motion and step lengths both with and without applied stiffness from the exoskeleton. These results suggest that while adaptation appears to have occurred, it was not solely driven by the nervous system reducing gait asymmetry. Our findings indicate that applying mechanical impedance asymmetrically to the joints may be an effective gait training and rehabilitation approach, as well as a method to elicit a novel adaptation response to further study neuromotor control of locomotion.",
        "primary_area": "",
        "author": "Mark Price;Banu Abdikadirova;Dominic Locurto;Jonaz Moreno Jaramillo;Nicholas Cline;Wouter Hoogkamer;Meghan E. Huber;Mark Price;Banu Abdikadirova;Dominic Locurto;Jonaz Moreno Jaramillo;Nicholas Cline;Wouter Hoogkamer;Meghan E. Huber",
        "authorids": "/37085821829;/37088537667;/37089658741;/37089663331;/37089662998;/37089661883;/37085363999;/37085821829;/37088537667;/37089658741;/37089663331;/37089662998;/37089661883;/37085363999",
        "aff": "Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA; Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA; Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981067/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14593524151350292604&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "Department of Kinesiology",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981415",
        "title": "Unmanned Aircraft System-Based Radiological Mapping of Buildings",
        "track": "main",
        "status": "Poster",
        "abstract": "The article focuses on acquiring a 3D radiation map of a building via a two-phase survey performed with an unmanned aircraft system (UAS). First, a model of the stud-ied building is created by means of photogrammetry. Then, radiation data are collected using a 2-inch NaI(Tl) detector in a regular grid at a distance of 2 m from all accessible surfaces of the building (i.e., the walls and the roof). The data are then georeferenced, filtered, projected to the building model, and interpolated to yield the detailed radiation map. A method to estimate the parameters of the radiation sources located inside is introduced and successfully tested, providing a localization accuracy in the order of meters. This task is aimed to deliver the proof of concept for employing such a mapping technique within nuclear safeguards. The acquisition of the radiation data was performed via a manual flight to ensure an appropriate safety level; in this context, it should be noted that the autonomous flight mode still requires major improvements in terms of safety.",
        "primary_area": "",
        "author": "Tomas Lazna;Petr Gabrlik;Petr Sladek;Tomas Jilek;Ludek Zalud;Tomas Lazna;Petr Gabrlik;Petr Sladek;Tomas Jilek;Ludek Zalud",
        "authorids": "/37086408379;/37086407956;/37089661461;/37085498919;/37662582100;/37086408379;/37086407956;/37089661461;/37085498919;/37662582100",
        "aff": "Central European Institute of Technology, Brno University of Technology, Brno, Czech Republic; Central European Institute of Technology, Brno University of Technology, Brno, Czech Republic; Department of Nuclear Sciences and Applications, Division of Physical and Chemical Sciences, Nuclear Science and Instrumentation Laboratory, International Atomic Energy Agency, Seibersdorf, Austria; Central European Institute of Technology, Brno University of Technology, Brno, Czech Republic; Central European Institute of Technology, Brno University of Technology, Brno, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981415/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8706125086911996784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Brno University of Technology;International Atomic Energy Agency",
        "aff_unique_dep": "Central European Institute of Technology;Nuclear Science and Instrumentation Laboratory",
        "aff_unique_url": "https://www.but.cz;https://www.iaea.org",
        "aff_unique_abbr": "BUT;IAEA",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Brno;Seibersdorf",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Czech Republic;Austria"
    },
    {
        "id": "9982125",
        "title": "Unsteady aerodynamic modeling of Aerobat using lifting line theory and Wagner's function",
        "track": "main",
        "status": "Poster",
        "abstract": "Flying animals possess highly complex physical characteristics and are capable of performing agile maneuvers using their wings. The flapping wings generate complex wake structures that influence the aerodynamic forces, which can be difficult to model. While it is possible to model these forces using fluidstructure interaction, it is very computationally expensive and difficult to formulate. In this paper, we follow a simpler approach by deriving the aerodynamic forces using a relatively small number of states and presenting them in a simple state-space form. The formulation utilizes Prandtl's lifting line theory and Wagner's function to determine the unsteady aerodynamic forces acting on the wing in a simulation, which then are compared to experimental data of the bat-inspired robot called the Aerobat. The simulated trailingedge vortex shedding can be evaluated from this model, which then can be analyzed for a wake-based gait design approach to improve the aerodynamic performance of the robot.",
        "primary_area": "",
        "author": "Eric Sihite;Paul Ghanem;Adarsh Salagame;Alireza Ramezani;Eric Sihite;Paul Ghanem;Adarsh Salagame;Alireza Ramezani",
        "authorids": "/37088452718;/37086417802;/37089658180;/37398489300;/37088452718;/37086417802;/37089658180;/37398489300",
        "aff": "Department of Aerospace, California Institute of Technology, Pasadena, CA, USA; Department of Electrical and Computer Engineering, SiliconSynapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, SiliconSynapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, SiliconSynapse Laboratory, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982125/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2983003226589385152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "California Institute of Technology;Northeastern University",
        "aff_unique_dep": "Department of Aerospace;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "Caltech;NU",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Pasadena;Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981603",
        "title": "Unsupervised Domain Adaptation for Point Cloud Semantic Segmentation via Graph Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation for point cloud semantic segmentation has attracted great attention due to its effectiveness in learning with unlabeled data. Most of existing methods use global-level feature alignment to transfer the knowledge from the source domain to the target domain, which may cause the semantic ambiguity of the feature space. In this paper, we propose a graph-based framework to explore the local-level feature alignment between the two domains, which can reserve semantic discrimination during adaptation. Specifically, in order to extract local-level features, we first dynamically construct local feature graphs on both domains and build a memory bank with the graphs from the source domain. In particular, we use optimal transport to generate the graph matching pairs. Then, based on the assignment matrix, we can align the feature distributions between the two domains with the graph-based local feature loss. Furthermore, we consider the correlation between the features of different categories and formulate a category-guided contrastive loss to guide the segmentation model to learn discriminative features on the target domain. Extensive experiments on different synthetic-to-real and real-to-real domain adaptation scenarios demonstrate that our method can achieve state-of-the-art performance. Our code is available at https://github.com/BianYikai/PointUDA.",
        "primary_area": "",
        "author": "Yikai Bian;Le Hui;Jianjun Qian;Jin Xie;Yikai Bian;Le Hui;Jianjun Qian;Jin Xie",
        "authorids": "/37089662719;/37086381563;/37651446800;/37085622059;/37089662719;/37086381563;/37651446800;/37085622059",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981603/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15369895294666962017&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.nust.edu.cn",
        "aff_unique_abbr": "NJUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982213",
        "title": "Unsupervised Simultaneous Learning for Camera Re-Localization and Depth Estimation from Video",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an unsupervised simultaneous learning framework for the task of monocular camera re-localization and depth estimation from unlabeled video sequences. Monocular camera re-localization refers to the task of estimating the absolute camera pose from an instance image in a known environment, which has been intensively studied for alternative localization in GPS-denied environments. In recent works, cam-era re-localization methods are trained via supervised learning from pairs of camera images and camera poses. In contrast to previous works, we propose a completely unsupervised learning framework for camera re-localization and depth estimation, requiring only monocular video sequences for training. In our framework, we train two networks that estimate the scene coordinates using directions and the depth map from each image which are then combined to estimate the camera pose. The networks can be trained through the minimization of loss functions based on our loop closed view synthesis. In experiments with the 7-scenes dataset, the proposed method outperformed the re-localization of the state-of-the-art visual SLAM, ORB-SLAM3. Our method also outperforms state-of-the-art monocular depth estimation in a trained environment.",
        "primary_area": "",
        "author": "Shun Taguchi;Noriaki Hirose;Shun Taguchi;Noriaki Hirose",
        "authorids": "/37391684000;/37574851500;/37391684000;/37574851500",
        "aff": "Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan; Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982213/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12724271741995470084&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagakute",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981654",
        "title": "Unsupervised confidence for LiDAR depth maps and applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Consequently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks.",
        "primary_area": "",
        "author": "Andrea Conti;Matteo Poggi;Filippo Aleotti;Stefano Mattoccia;Andrea Conti;Matteo Poggi;Filippo Aleotti;Stefano Mattoccia",
        "authorids": "/37089815902;/37085848424;/37086576459;/37326275100;/37089815902;/37085848424;/37086576459;/37326275100",
        "aff": "University of Bologna; University of Bologna; University of Bologna; University of Bologna",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981654/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1964465151653985909&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bologna",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unibo.it",
        "aff_unique_abbr": "Unibo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9982102",
        "title": "Upper Limb Movement Estimation and Function Evaluation of the Shoulder Girdle by Multi-Sensing Flexible Sensor Wear",
        "track": "main",
        "status": "Poster",
        "abstract": "To extend the coverage of people able to receive high-quality rehabilitation, remote rehabilitation is required in addition to traditional face-to-face rehabilitation. Although remote rehabilitation using video conferencing systems has been realized to date, communication through physical sensations such as detailed patient motoring information and manual instructions from the therapist has not yet been realized. Therefore, the ultimate goal of this study was to develop multimodal wearable sensor system to support remote rehabilitation with a somatosensory system. To this end, we conducted a basic study of sensing technology in multimodal wear. Multiple strain sensors were attached to the shoulder to digitize the detailed behavior of the shoulder girdle. It was confirmed that the movement of the scapula can be acquired by this strain sensor. Furthermore, it was confirmed that the combination of strain sensors and an inertia measurement unit can be applied for the motion estimation of the entire upper limb.",
        "primary_area": "",
        "author": "Kunihiro Ogata;Shusuke Kanazawa;Hideyuki Tanaka;Takeshi Kurata;Kunihiro Ogata;Shusuke Kanazawa;Hideyuki Tanaka;Takeshi Kurata",
        "authorids": "/37647366000;/37085999998;/37676195700;/37265772400;/37647366000;/37085999998;/37676195700;/37265772400",
        "aff": "Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982102/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13808870596551020375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Human Augmentation Research Center",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982091",
        "title": "Use of Action Label in Deep Predictive Learning for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Various forms of human knowledge can be explicitly used to enhance deep robot learning from demonstrations. Annotation of subtasks from task segmentation is one type of human symbolism and knowledge. Annotated subtasks can be referred to as action labels, which are more primitive symbols that can be building blocks for more complex human reasoning, like language instructions. However, action labels are not widely used to boost learning processes because of problems that include (1) real-time annotation for online manipulation, (2) temporal inconsistency by annotators, (3) difference in data characteristics of motor commands and action labels, and (4) annotation cost. To address these problems, we propose the Gated Action Motor Predictive Learning (GAMPL) framework to leverage action labels for improved performance. GAMPL has two modules to obtain soft action labels compatible with motor commands and to generate motion. In this study, GAMPL is evaluated for towel-folding manipulation tasks in a real environment with a six degrees-of-freedom (6 DoF) robot and shows improved generalizability with action labels.",
        "primary_area": "",
        "author": "Kei Kase;Chikara Utsumi;Yukiyasu Domae;Tetsuya Ogata;Kei Kase;Chikara Utsumi;Yukiyasu Domae;Tetsuya Ogata",
        "authorids": "/37086051576;/37089661460;/37840048000;/37273829100;/37086051576;/37089661460;/37840048000;/37273829100",
        "aff": "National Institute of Advanced Industrial Science and Technology, Japan; National Institute of Advanced Industrial Science and Technology, Japan; National Institute of Advanced Industrial Science and Technology, Japan; National Institute of Advanced Industrial Science and Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982091/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3413144214040697643&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981229",
        "title": "Using Simulation Optimization to Improve Zero-shot Policy Transfer of Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a data-driven approach to optimize the parameters of a simulation such that control policies can be directly transferred from simulation to a real-world quadrotor. Our neural network-based policies take only onboard sensor data as input and run entirely on the embed-ded hardware. In real-world experiments, we compare low-level Pulse-Width Modulated control with higher-level control structures such as Attitude Rate and Attitude, which utilize Proportional-Integral-Derivative controllers to output motor commands. Our experiments show that low-level controllers trained with Reinforcement Learning require a more accurate simulation than higher-level control policies at the expense of being less robust towards parameter uncertainties.",
        "primary_area": "",
        "author": "Sven Gronauer;Matthias Kissel;Luca Sacchetto;Mathias Korte;Klaus Diepold;Sven Gronauer;Matthias Kissel;Luca Sacchetto;Mathias Korte;Klaus Diepold",
        "authorids": "/37089659677;/37089022221;/37089662250;/37089658930;/37295012700;/37089659677;/37089022221;/37089662250;/37089658930;/37295012700",
        "aff": "Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981229/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12408578080053987673&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981706",
        "title": "Using human gaze in few-shot imitation learning for robot manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning has attracted attention as a method for realizing complex robot control without programmed robot behavior. Meta-imitation learning has been proposed to solve the high cost of data collection and low generalizability to new tasks that imitation learning suffers from. Meta-imitation can learn new tasks involving unknown objects from a small amount of data by learning multiple tasks during training. However, meta-imitation learning, especially using images, is still vulnerable to changes in the background, which occupies a large portion of the input image. This study introduces a human gaze into meta-imitation learning-based robot control. We created a model with model-agnostic meta-learning to predict the gaze position from the image by measuring the gaze with an eye tracker in the head-mounted display. Using images around the predicted gaze position as an input makes the model robust to changes in visual information. We experimentally verified the performance of the proposed method through picking tasks using a simulated robot. The results indicate that our proposed method has a greater ability than the conventional method to learn a new task from only 9 demonstrations even if the object's color or the background pattern changes between the training and test.",
        "primary_area": "",
        "author": "Shogo Hamano;Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi;Shogo Hamano;Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi",
        "authorids": "/37089660166;/37088419106;/37581602900;/37299294900;/37089660166;/37088419106;/37581602900;/37299294900",
        "aff": "Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981706/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11829504621599990339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9982078",
        "title": "VAST: Visual and Spectral Terrain Classification in Unstructured Multi-Class Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Terrain classification is a challenging task for robots operating in unstructured environments. Existing classification methods make simplifying assumptions, such as a reduced number of classes, clearly segmentable roads, or good lighting conditions, and focus primarily on one sensor type. These assumptions do not translate well to off-road vehicles, which operate in varying terrain conditions. To provide mobile robots with the capability to identify the terrain being traversed and avoid undesirable surface types, we propose a multimodal sensor suite capable of classifying different terrains. We capture high resolution macro images of surface texture, spectral reflectance curves, and localization data from a 9 degrees of freedom (DOF) inertial measurement unit (IMU) on 11 different terrains at different times of day. Using this dataset, we train individual neural networks on each of the modalities, and then combine their outputs in a fusion network. The fused network achieved an accuracy of 99.98% percent on the test set, exceeding the results of the best individual network component by 0.98%. We conclude that a combination of visual, spectral, and IMU data provides meaningful improvement over state of the art in terrain classification approaches. The data created for this research is available at https://github.com/RIVeR-Lab/vast_data.",
        "primary_area": "",
        "author": "Nathaniel Hanson;Michael Shaham;Deniz Erdo\u011fmu\u015f;Ta\u015fkin Padir;Nathaniel Hanson;Michael Shaham;Deniz Erdo\u011fmu\u015f;Ta\u015fkin Padir",
        "authorids": "/37089372587;/37089661749;/37285051800;/38496444600;/37089372587;/37089661749;/37285051800;/38496444600",
        "aff": "Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982078/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10502959364757625311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Institute for Experiential Robotics",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981925",
        "title": "VGPN: 6-DoF Grasp Pose Detection Network Based on Hough Voting",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel Voting based Grasp Pose Network (VGPN) to detect 6-DoF grasps in cluttered scenes. The motivation of this paper is that local object geometry can provide useful clues about where the object can be grasped. Generated by the sampled seed points from raw point cloud, the votes allow seed points in different object regions to contribute to locations where the object can be grasped. Geometric features from various local regions are aggregated to generate grasps in a more confident and dense space, which enables grasp prediction utilizing more global context features. The search space of grasp pose detection is also greatly reduced. Experimental results on both simulation and real-world environments show that our proposed method outperforms state-of-the-art approaches in terms of both success rate and coverage of the ground truth grasps. The objects can be grasped with fewer attempts which is critical in real-world applications.",
        "primary_area": "",
        "author": "Liming Zheng;Yinghao Cai;Tao Lu;Shuo Wang;Liming Zheng;Yinghao Cai;Tao Lu;Shuo Wang",
        "authorids": "/37089662986;/37654083400;/37855750400;/37280458600;/37089662986;/37654083400;/37855750400;/37280458600",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Centre for Artificial Intelligence and Robotics (CAIR), Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences (HKISI-CAS); State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981925/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7766064538883841523&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Centre for Artificial Intelligence and Robotics (CAIR)",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Beijing;Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982060",
        "title": "VI-IKD: High-Speed Accurate Off-Road Navigation using Learned Visual-Inertial Inverse Kinodynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the key challenges in high-speed off-road navigation on ground vehicles is that the kinodynamics of the vehicle-terrain interaction can differ dramatically depending on the terrain. Previous approaches to addressing this challenge have considered learning an inverse kinodynamics (IKD) model, conditioned on inertial information of the vehicle to sense the kinodynamic interactions. In this paper, we hypothesize that to enable accurate high-speed off-road navigation using a learned IKD model, in addition to inertial information from the past, one must also anticipate the kinodynamic interactions of the vehicle with the terrain in the future. To this end, we introduce Visual-Inertial Inverse Kinodynamics (VI-IKD), a novel learning based IKD model that is conditioned on visual information from a terrain patch ahead of the robot in addition to past inertial information, enabling it to anticipate kinodynamic interactions in the future. We validate the effectiveness of VI-IKD in accurate high-speed off-road navigation experimentally on a scale 1/5 UT-AlphaTruck off-road autonomous vehicle in both indoor and outdoor environments and show that compared to other state-of-the-art approaches, VI-IKD enables more accurate and robust off-road navigation on a variety of different terrains at speeds of up to 3.5m/s.",
        "primary_area": "",
        "author": "Haresh Karnan;Kavan Singh Sikand;Pranav Atreya;Sadegh Rabiee;Xuesu Xiao;Garrett Warnell;Peter Stone;Joydeep Biswas;Haresh Karnan;Kavan Singh Sikand;Pranav Atreya;Sadegh Rabiee;Xuesu Xiao;Garrett Warnell;Peter Stone;Joydeep Biswas",
        "authorids": "/37086310655;/37089193943;/37089661923;/37086933532;/37086258082;/37079072000;/37269574900;/37538259200;/37086310655;/37089193943;/37089661923;/37086933532;/37086258082;/37079072000;/37269574900;/37538259200",
        "aff": "Department of Mechanical Engineering, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Computational and Information Sciences Directorate, Army Research Laboratory; Sony, AI; Department of Computer Science, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982060/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13829711346372035368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Texas at Austin;Army Research Laboratory;Sony",
        "aff_unique_dep": "Department of Mechanical Engineering;Computational and Information Sciences Directorate;AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.arl.army.mil;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;ARL;Sony",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9981776",
        "title": "VMVG-Loc: Visual Localization for Autonomous Driving using Vector Map and Voxel Grid Map",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a visual localization method using a vector map and voxel grid map with a stereo camera. The two maps provide different modality advantages and are integrated using a particle filter. In contrast to other vector map-based methods, our method does not use road markings because creating and maintaining vector maps that include high-accuracy road markings is laborious. Furthermore, it limits the regions where they are available. This method uses only lane center-lines from vector maps, which are easier to create than road markings. The method performs ray casting and computes the reprojection error to evaluate the vehicle position for voxel grid maps. Although this makes the method environmentally sensitive, the constraints by lanes make the estimation stable. Experiments confirmed that the method could perform localization stably and accurately without failure even over long distances. In addition, an ablation study showed the benefits of combining both maps.",
        "primary_area": "",
        "author": "Kento Yabuuchi;Shinpei Kato;Kento Yabuuchi;Shinpei Kato",
        "authorids": "/37089011442;/37537228700;/37089011442;/37537228700",
        "aff": "TIER IV, Inc., Japan; TIER IV, Inc., Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981776/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9115869801908862084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "TIER IV, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tier-iv.com",
        "aff_unique_abbr": "TIER IV",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981892",
        "title": "VR Facial Animation for Immersive Telepresence Avatars",
        "track": "main",
        "status": "Poster",
        "abstract": "VR Facial Animation is necessary in applications requiring clear view of the face, even though a VR headset is worn. In our case, we aim to animate the face of an operator who is controlling our robotic avatar system. We propose a real-time capable pipeline with very fast adaptation for specific operators. In a quick enrollment step, we capture a sequence of source images from the operator without the VR headset which contain all the important operator-specific appearance information. During inference, we then use the operator keypoint information extracted from a mouth camera and two eye cameras to estimate the target expression and head pose, to which we map the appearance of a source still image. In order to enhance the mouth expression accuracy, we dynamically select an auxiliary expression frame from the captured sequence. This selection is done by learning to transform the current mouth keypoints into the source camera space, where the alignment can be determined accurately. We, furthermore, demonstrate an eye tracking pipeline that can be trained in less than a minute, a time efficient way to train the whole pipeline given a dataset that includes only complete faces, show exemplary results generated by our method, and discuss performance at the ANA Avatar XPRIZE semifinals.",
        "primary_area": "",
        "author": "Andre Rochow;Max Schwarz;Michael Schreiber;Sven Behnke;Andre Rochow;Max Schwarz;Michael Schreiber;Sven Behnke",
        "authorids": "/37088600649;/37085593752;/37298914700;/37295987100;/37088600649;/37085593752;/37298914700;/37295987100",
        "aff": "Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981892/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17770872654183578134&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982118",
        "title": "Variable Impedance Control for Safety and Usability in Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, haptic telemanipulation has been introduced to control robots remotely with an input device that generates force feedback. Compliant control strategies are needed to ensure safe interaction between humans and robots. Accurate and precise manipulation requires a stiff setup of the impedance parameters, while safety demands for low stiffness. This paper proposes an impedance-based control approach that combines stiff manipulation with a safety mechanism that adapts compliance when required. We introduce three system modes: operation, safety and recovery mode. If the external forces exceed a defined force threshold, the system switches to the compliant safety mode. A user input triggers the recovery process that increases the stiffness back to its nominal value. This paper suggests an energy tank, which limits the change of stiffness to ensure stability during recovering phase. We validate the functionality of this approach using a real telemanipulation setup and show that the suggested tank enables recovery even from large displacements.",
        "primary_area": "",
        "author": "Stephan Andreas Schwarz;Ulrike Thomas;Stephan Andreas Schwarz;Ulrike Thomas",
        "authorids": "/37089661735;/37281523200;/37089661735;/37281523200",
        "aff": "Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982118/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16600722110440097428&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Lab of Robotics and Human-Machine-Interaction",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982051",
        "title": "Variable Stiffness Object Recognition with Bayesian Convolutional Neural Network on a Soft Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "From a medical standpoint, detecting the size and shape of hard inclusions hidden in soft three-dimensional objects is of great significance for early detection of cancer through palpation. Soft robots, especially soft grippers, substantially broaden robots' palpation capabilities from soft to hard materials without the assistance of a camera. We have recently introduced a CNN-Bayes approach which added a Na\u00efve Bayes classifier to a convolutional neural network (CNN) architecture called SoftTactNet for variable stiffness object recognition on a three-finger FinRay soft gripper. SoftTactNet itself lacks uncertainty estimations though it can reach a certain level of recognition accuracy. In this paper, we further improve the framework by merging Bayes method directly into CNN architectures and build a new Bayes-SoftTactNet for object recognition. The new approach, using a prior distribution instead of point estimation, allows the network to present results with uncertainty estimates. We conduct new experiments using the same soft gripper with tactile sensor arrays to grasp different variable stiffness objects surrounded by non-different soft material and generate tactile images as dataset. The results show that our new algorithm is more efficient than the previous approach and still able to achieve higher recognition accuracy than general deterministic CNNs.",
        "primary_area": "",
        "author": "Jinyue Cao;Jingyi Huang;Andre Rosendo;Jinyue Cao;Jingyi Huang;Andre Rosendo",
        "authorids": "/37089348519;/37089196185;/37845873600;/37089348519;/37089196185;/37845873600",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982051/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6069290705526878422&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "School of Information Science and Technology",
        "aff_unique_url": "https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981685",
        "title": "Vastus and Gastrocnemius improve hopping efficiency and joints synchronicity at different frequencies: a robotic study",
        "track": "main",
        "status": "Poster",
        "abstract": "The lower limb morphology of biological locomotors is abundant in muscle-tendon units. Yet, not much is known about how these actuation units contribute to the output performance and energy economy of movements. In this work, we investigate the functionality of four of the important lower limb muscles - Vastus, Popliteus, Soleus, and Gastrocnemius - in a hopping task at different frequencies (1.5-3.5 Hz). These muscles are implemented as pneumatic artificial muscles (PAMs) on the EPA-Hopper-II robot, which is a human-sized 3-segmented leg co-actuated by electrical motors and PAMs. A bioinspired reflex-based Force Modulated Control (FMC) is also implemented on the robot to achieve hopping at different frequencies. The results show that the Vastus contributes the most to energy-efficient hopping at low to mid frequencies. The biarticular Gastrocnemius also helps increase efficiency at low frequencies. Further, it is found that the Gastrocnemius synchronizes the knee-ankle motion and mitigates lateral knee motion. The outcomes of this work add further evidence to hypotheses regarding human lower-limb actuation and proper recruitment of muscles for building more efficient robots.",
        "primary_area": "",
        "author": "Omid Mohseni;Patrick Schmidt;Andre Seyfarth;Maziar A. Sharbafi;Omid Mohseni;Patrick Schmidt;Andre Seyfarth;Maziar A. Sharbafi",
        "authorids": "/37086191360;/37089660058;/37394272400;/37394631900;/37086191360;/37089660058;/37394272400;/37394631900",
        "aff": "Lauflabor Locomotion Laboratory, Centre for Cognitive Science, TU, Darmstadt, Germany; Lauflabor Locomotion Laboratory, Centre for Cognitive Science, TU, Darmstadt, Germany; Lauflabor Locomotion Laboratory, Centre for Cognitive Science, TU, Darmstadt, Germany; Lauflabor Locomotion Laboratory, Centre for Cognitive Science, TU, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981685/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6353062668863633496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Centre for Cognitive Science",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TU Darmstadt",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981421",
        "title": "Vehicle Type Specific Waypoint Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a generic mechanism for generating vehicle-type specific sequences of waypoints from a probabilistic foundation model of driving behavior. Many foundation behavior models are trained on data that does not include vehicle information, which limits their utility in downstream applications such as planning. Our novel methodology conditionally specializes such a behavior predictive model to a vehicle-type by utilizing byproducts of the reinforcement learning algorithms used to produce vehicle specific controllers. We show how to compose a vehicle specific value function estimate with a generic probabilistic behavior model to generate vehicle-type specific waypoint sequences that are more likely to be physically plausible then their vehicle-agnostic counterparts.",
        "primary_area": "",
        "author": "Yunpeng Liu;Jonathan Wilder Lavington;Adam Scibior;Frank Wood;Yunpeng Liu;Jonathan Wilder Lavington;Adam Scibior;Frank Wood",
        "authorids": "/37089664164;/37089659970;/37089006656;/37089131590;/37089664164;/37089659970;/37089006656;/37089131590",
        "aff": "University of British Columbia; University of British Columbia; University of British Columbia; Mila",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981421/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2870387597672867076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of British Columbia;Mila",
        "aff_unique_dep": ";Quebec Artificial Intelligence Institute",
        "aff_unique_url": "https://www.ubc.ca;https://mila.quebec",
        "aff_unique_abbr": "UBC;Mila",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9982260",
        "title": "Vertical Bend and T-branch Travels of an Articulated Wheeled In-pipe Inspection Robot by Combining Its Joint Angle and Torque Controls",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper reports the performance verification of vertical bend and T-branch travels of an articulated wheeled in-pipe inspection robot. The robot is composed of only a single active compliant middle joint, two passive compliant joints, three drive wheels, and two roll wheels. The passage of the bend pipe is achieved only by the joint torque control, while the T-branch travel is achieved by controlling both joint angle and torque. Instead of using a torque sensor, a polyurethane-based series elastic actuator (SEA) is installed in the middle joint. In this paper, the travel performances of our developed in-pipe robot were tested on bend pipes and 10 types of T-branch with different gravity directions. From the experiments, in all cases, the effectiveness of the bend and T-branch travels performance was confirmed.",
        "primary_area": "",
        "author": "Atsushi Kakogawa;Kenya Murata;Shugen Ma;Atsushi Kakogawa;Kenya Murata;Shugen Ma",
        "authorids": "/37846134700;/37089663979;/37280187400;/37846134700;/37089663979;/37280187400",
        "aff": "Research Organization of Science and Technology, Ritsumeikan University, Kusatsu, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Rit-sumeikan University, Kusatsu, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Rit-sumeikan University, Kusatsu, Shiga, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982260/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7889532292933871139&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ritsumeikan University;Rit-sumeikan University",
        "aff_unique_dep": "Research Organization of Science and Technology;Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp;https://www.rit-sumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan;Rit-sumei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981209",
        "title": "View Planning Using Discrete Optimization for 3D Reconstruction of Row Crops",
        "track": "main",
        "status": "Poster",
        "abstract": "In view planning, the position and orientation of the cameras have been a major contributing factor to the quality of the resulting 3D model. In applications such as precision agriculture, a dense and accurate reconstruction must be obtained quickly while the data is still actionable. Instead of using an arbitrarily large number of images taken from every possible position and orientation in order to cover the desired area of study, a more optimal approach is required. We present an efficient and realistic pipeline, which aims to optimize the positioning of cameras and hence the quality of the 3D reconstruction of a field of row crops. This is achieved with four steps; an initial flight to obtain a sparse point cloud, the fitting of a simple mesh model, the planning of images via a discrete optimization process, and a second flight to obtain the final reconstruction. We demonstrate the effectiveness of our method by comparing it with baseline methods commonly used for agricultural data collection and processing.",
        "primary_area": "",
        "author": "Athanasios Bacharis;Henry J. Nelson;Nikolaos Papanikolopoulos;Athanasios Bacharis;Henry J. Nelson;Nikolaos Papanikolopoulos",
        "authorids": "/37089661881;/37089779778;/37278578300;/37089661881;/37089779778;/37278578300",
        "aff": "Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981209/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5629948562071894815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981920",
        "title": "Virtual Reality Simulator for Fetoscopic Spina Bifida Repair Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Spina Bifida (SB) is a birth defect developed during the early stage of pregnancy in which there is incomplete closing of the spine around the spinal cord. The growing interest in fetoscopic Spina-Bifida repair, which is performed in fetuses who are still in the pregnant uterus, prompts the need for appropriate training. The learning curve for such procedures is steep and requires excellent procedural skills. Computer-based virtual reality (VR) simulation systems offer a safe, cost-effective, and configurable training environment free from ethical and patient safety issues. However, to the best of our knowledge, there are currently no commercial or experimental VR training simulation systems available for fetoscopic SB-repair procedures. In this paper, we propose a novel VR simulator for core manual skills training for SB-repair. An initial simulation realism validation study was carried out by obtaining subjective feedback (face and content validity) from 14 clinicians. The overall simulation realism was on average marked 4.07 on a 5-point Likert scale (1 - \u2018very unrealistic\u2019, 5 - \u2018very realistic\u2019). Its usefulness as a training tool for SB-repair as well as in learning fundamental laparoscopic skills was marked 4.63 and 4.80, respectively. These results indicate that VR simulation of fetoscopic procedures may contribute to surgical training without putting fetuses and their mothers at risk. It could also facilitate wider adaptation of fetoscopic procedures in place of much more invasive open fetal surgeries.",
        "primary_area": "",
        "author": "Przemys\u0142aw Korzeniowski;Szymon P\u0142otka;Robert Brawura-Biskupski-Samaha;Arkadiusz Sitek;Przemys\u0142aw Korzeniowski;Szymon P\u0142otka;Robert Brawura-Biskupski-Samaha;Arkadiusz Sitek",
        "authorids": "/37089661447;/37089663083;/37089659670;/37089661127;/37089661447;/37089663083;/37089659670;/37089661127",
        "aff": "Sano Centre for Computational Medicine, Cracow, Poland; Quantitative Healthcare Analysis (qurAI) group, Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands; II Department of Obstetrics and Gynaecology, The Medical Centre of Postgraduate Education, Warsaw, Poland; Sano Centre for Computational Medicine, Cracow, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981920/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13030801878376743100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Sano Centre for Computational Medicine;University of Amsterdam;Medical Centre of Postgraduate Education",
        "aff_unique_dep": "Centre for Computational Medicine;Informatics Institute;II Department of Obstetrics and Gynaecology",
        "aff_unique_url": ";https://www.uva.nl;",
        "aff_unique_abbr": ";UvA;",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Cracow;Amsterdam;Warsaw",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Poland;Netherlands"
    },
    {
        "id": "9981084",
        "title": "Visibility-Inspired Models of Touch Sensors for Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces mathematical models of touch sensors for mobile robots based on visibility. Serving a purpose similar to the pinhole camera model for computer vision, the introduced models are expected to provide a useful, idealized characterization of task-relevant information that can be inferred from their outputs or observations. Possible tasks include navigation, localization and mapping when a mobile robot is deployed in an unknown environment. These models allow direct comparisons to be made between traditional depth sensors, highlighting cases in which touch sensing may be interchangeable with time of flight or vision sensors, and char-acterizing unique advantages provided by touch sensing. The models include contact detection, compression, load bearing, and deflection. The results could serve as a basic building block for innovative touch sensor designs for mobile robot sensor fusion systems.",
        "primary_area": "",
        "author": "Kshitij Tiwari;Basak Sakcak;Prasanna Routray;M. Manivannan;Steven M. LaValle;Kshitij Tiwari;Basak Sakcak;Prasanna Routray;M. Manivannan;Steven M. LaValle",
        "authorids": "/37086181805;/37086497815;/37088947245;/37395162800;/37280522300;/37086181805;/37086497815;/37088947245;/37395162800;/37280522300",
        "aff": "Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; Touch Lab, Center for Virtual Reality and Haptics, Indian Institute of Technology Madras, Madras, India; Touch Lab, Center for Virtual Reality and Haptics, Indian Institute of Technology Madras, Madras, India; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981084/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9915043274389941035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Oulu;Indian Institute of Technology Madras",
        "aff_unique_dep": "Faculty of Information Technology and Electrical Engineering;Touch Lab, Center for Virtual Reality and Haptics",
        "aff_unique_url": "https://www.oulu.fi;https://www.iitm.ac.in",
        "aff_unique_abbr": "UOulu;IIT Madras",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Oulu;Madras",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Finland;India"
    },
    {
        "id": "9981897",
        "title": "Vision-Assisted Localization and Terrain Reconstruction with Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots, specifically quadruped robots, have good locomotion performance in complex and rugged terrain and are becoming widely used in field exploration and rescue missions. To achieve full autonomy in such scenarios, robots need not only accurate localization but also an accurate understanding of the surrounding terrain, which will be used for robots path planning and foothold planning. However, due to the kinetic characteristic and limitation of size, quadruped robots have the disadvantages of high-frequency jitter and limited field of sensors, which lead to some challenges in environmental perception. In this paper, we propose a vision-assisted rugged terrain environment reconstruction and localization method for quadruped robots. We use a depth camera to assist in the generation of high-precision localization and terrain reconstruction results, which can help achieve the autonomous mobility of quadruped robots in this environment. We test our method on a quadruped robot platform. Our experimental results show less error and lower drift in different stairs terrain types than the commonly used lidar-based localization method.",
        "primary_area": "",
        "author": "Chengyang Zhang;Jiashi Zhang;Jun Wu;Qiuguo Zhu;Chengyang Zhang;Jiashi Zhang;Jun Wu;Qiuguo Zhu",
        "authorids": "/37089660466;/37089662757;/170654254534521;/38238164400;/37089660466;/37089662757;/170654254534521;/38238164400",
        "aff": "Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981897/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1566732445488122876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-System and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981689",
        "title": "Vision-Based Safety System for Barrierless Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Human safety has always been the main priority when working near an industrial robot. With the rise of Human-Robot Collaborative environments, physical barriers to avoiding collisions have been disappearing, increasing the risk of accidents and the need for solutions that ensure a safe Human-Robot Collaboration. This paper proposes a safety system that implements Speed and Separation Monitoring (SSM) type of operation. For this, safety zones are defined in the robot's workspace following current standards for industrial collaborative robots. A deep learning-based computer vision system detects, tracks, and estimates the 3D position of operators close to the robot. The robot control system receives the operator's 3D position and generates 3D representations of them in a simulation environment. Depending on the zone where the closest operator was detected, the robot stops or changes its operating speed. Three different operation modes in which the human and robot interact are presented. Results show that the vision-based system can correctly detect and classify in which safety zone an operator is located and that the different proposed operation modes ensure that the robot's reaction and stop time are within the required time limits to guarantee safety.",
        "primary_area": "",
        "author": "Lina Mar\u00eda Amaya-Mej\u00eda;Nicol\u00e1s Duque-Su\u00e1rez;Daniel Jaramillo-Ram\u00edrez;Carol Martinez;Lina Mar\u00eda Amaya-Mej\u00eda;Nicol\u00e1s Duque-Su\u00e1rez;Daniel Jaramillo-Ram\u00edrez;Carol Martinez",
        "authorids": "/37089658793;/37089662821;/38306882500;/37682080100;/37089658793;/37089662821;/38306882500;/37682080100",
        "aff": "Space Robotics (SpaceR) Research Group, Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Dept. Electronic Engineering, Faculty of Engineering, Pontificia Universidad Javeriana, Bogot\u00e1, Colombia; Dept. Electronic Engineering, Faculty of Engineering, Pontificia Universidad Javeriana, Bogot\u00e1, Colombia; Space Robotics (SpaceR) Research Group, Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981689/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1469128587830130755&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Luxembourg;Pontificia Universidad Javeriana",
        "aff_unique_dep": "Interdisciplinary Centre for Security, Reliability and Trust (SnT);Dept. Electronic Engineering",
        "aff_unique_url": "https://wwwen.unil.lu;https://www.puj.edu.co",
        "aff_unique_abbr": "UniLu;PUJ",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Bogot\u00e1",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Luxembourg;Colombia"
    },
    {
        "id": "9981072",
        "title": "Vision-Guided Quadrupedal Locomotion in the Wild with Multi-Modal Delay Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing robust vision-guided controllers for quadrupedal robots in complex environments with various obstacles, dynamical surroundings and uneven terrains is very challenging. While Reinforcement Learning (RL) provides a promising paradigm for agile locomotion skills with vision inputs in simulation, it is still very challenging to deploy the vision-guided RL policy in the real world. Our key insight is that the asynchronous multi-modal observations, caused by different latencies in different components of the real robot, create a large sim2real gap for a RL policy. In this paper, we propose Multi-Modal Delay Randomization (MMDR) to address this issue when training in simulation. Specifically, we randomize the selections for both the proprioceptive states and the visual observations in time during training, aiming to simulate the asynchronous inputs when deploying to the real robot. With this technique, we are able to train a RL policy for end-to-end locomotion control in simulation, which can be directly deployed on the real A1 quadruped robot running in the wild. We evaluate our method in different outdoor environments with complex terrain and obstacles. We show that the robot can smoothly maneuver at a high speed while avoiding the obstacles, achieving significant improvement over the baselines. Our project page with videos is at https://mehooz.github.io/mmdr-wild/.",
        "primary_area": "",
        "author": "Chieko Sarah Imai;Minghao Zhang;Yuchen Zhang;Marcin Kierebi\u0144ski;Ruihan Yang;Yuzhe Qin;Xiaolong Wang;Chieko Sarah Imai;Minghao Zhang;Yuchen Zhang;Marcin Kierebi\u0144ski;Ruihan Yang;Yuzhe Qin;Xiaolong Wang",
        "authorids": "/37089659968;/37089525839;/37089664135;/37089659277;/37089661706;/37088454355;/37085652454;/37089659968;/37089525839;/37089664135;/37089659277;/37089661706;/37088454355;/37085652454",
        "aff": "University of California, San Diego, CA, USA; Tsinghua University, Beijing, China; University of California, San Diego, CA, USA; University of California, San Diego, CA, USA; University of California, San Diego, CA, USA; University of California, San Diego, CA, USA; University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981072/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8188697346510696895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://ucsd.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UCSD;THU",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "San Diego;Beijing",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9981803",
        "title": "Vision-based Distributed Multi-UAV Collision Avoidance via Deep Reinforcement Learning for Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Online path planning for multiple unmanned aerial vehicle (multi-UAV) systems is considered a challenging task. It needs to ensure collision-free path planning in real-time, especially when the multi-UAV systems can become very crowded on certain occasions. In this paper, we presented a vision-based decentralized collision-avoidance policy learning method for multi-UAV systems. The policy takes depth images and inertial measurements as sensory inputs and outputs UAV's steering commands, and it is trained together with the latent representation of depth images using a policy gradient-based reinforcement learning algorithm and autoencoder in the multi-UAV three-dimensional workspaces. Each UAV follows the same trained policy and acts independently to reach the goal without colliding or communicating with other UAVs. We validate our method in various simulated scenarios. The experimental results show that our learned policy can guarantee fully autonomous collision-free navigation for multi-UAV in three-dimensional workspaces, and its navigation performance will not be greatly affected by the increase in the number of UAVs.",
        "primary_area": "",
        "author": "Huaxing Huang;Guijie Zhu;Zhun Fan;Hao Zhai;Yuwei Cai;Ze Shi;Zhaohui Dong;Zhifeng Hao;Huaxing Huang;Guijie Zhu;Zhun Fan;Hao Zhai;Yuwei Cai;Ze Shi;Zhaohui Dong;Zhifeng Hao",
        "authorids": "/37089567319;/37087710128;/38548520100;/37089658708;/37088993675;/37089570187;/37089565537;/37089659096;/37089567319;/37087710128;/38548520100;/37089658708;/37088993675;/37089570187;/37089565537;/37089659096",
        "aff": "Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University; Key Lab of Digital Signal and Image Processing of Guangdong Province, College of Engineering, Shantou University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981803/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13003197008885018009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Shantou University",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "https://www.stu.edu.cn",
        "aff_unique_abbr": "STU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981115",
        "title": "Vision-based Relative Detection and Tracking for Teams of Micro Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the vision-based detection and tracking problems of multiple aerial vehicles using a single camera and Inertial Measurement Unit (IMU) as well as the corresponding perception consensus problem (i.e., uniqueness and identical IDs across all observing agents). We design several vision-based decentralized Bayesian multi-tracking filtering strategies to resolve the association between the incoming unsorted measurements obtained by a visual detector algorithm and the tracked agents. We compare their accuracy in different operating conditions as well as their scalability according to the number of agents in the team. This analysis provides useful insights about the most appropriate design choice for the given task. We further show that the proposed perception and inference pipeline which includes a Deep Neural Network (DNN) as visual target detector is lightweight and capable of concurrently running control and planning with Size, Weight, and Power (SWaP) constrained robots on-board. Experimental results show the effective tracking of multiple drones in various challenging scenarios such as heavy occlusions.",
        "primary_area": "",
        "author": "Rundong Ge;Moonyoung Lee;Vivek Radhakrishnan;Yang Zhou;Guanrui Li;Giuseppe Loianno;Rundong Ge;Moonyoung Lee;Vivek Radhakrishnan;Yang Zhou;Guanrui Li;Giuseppe Loianno",
        "authorids": "/37088600577;/37089661041;/37089659053;/37088601876;/37086455447;/37085496544;/37088600577;/37089661041;/37089659053;/37088601876;/37086455447;/37085496544",
        "aff": "New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; Technology Innovation Institute, Abu Dhabi, UAE; New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981115/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8210150972018761521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "New York University;Technology Innovation Institute",
        "aff_unique_dep": "Tandon School of Engineering;",
        "aff_unique_url": "https://www.nyu.edu;",
        "aff_unique_abbr": "NYU;",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Brooklyn;Abu Dhabi",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "9981398",
        "title": "Vision-based rotational control of an agile observation satellite",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent Earth observation satellites are now equipped with new instrument that allows image feedback in real-time. Problematic such as ground target tracking, moving or not, can now be addressed by precisely controlling the satellite attitude. In this paper, we propose to consider this problem using a visual servoing approach. While focusing on the target, the control scheme has also to take into account the satellite motion induced by its orbit, Earth rotational velocities, potential target own motion, but also rotational velocities and accelerations constraints of the system. We show the efficiency of our system using both simulation (considering real Earth image) and experiments on a robot that replicates actual high resolution satellite constraints.",
        "primary_area": "",
        "author": "Maxime Robic;Renaud Fraisse;Eric Marchand;Fran\u00e7ois Chaumette;Maxime Robic;Renaud Fraisse;Eric Marchand;Fran\u00e7ois Chaumette",
        "authorids": "/37089660885;/37089498364;/37269970500;/37265186700;/37089660885;/37089498364;/37269970500;/37265186700",
        "aff": "Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Airbus Defense and Space, Toulouse, France; Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981398/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17909232914589438706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "INRIA;Airbus Defense and Space;University of Rennes",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.inria.fr;https://www.airbusdefenceandspace.com;https://www.univ-rennes1.fr",
        "aff_unique_abbr": "Inria;Airbus DS;Univ Rennes",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Rennes;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981585",
        "title": "Visual Confined-Space Navigation Using an Efficient Learned Bilinear Optic Flow Approximation for Insect-scale Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual navigation for insect-scale robots is very challenging because in such a small scale, the size, weight, and power (SWaP) constraints do not appear to permit visual navigation techniques such as SLAM (Simultaneous Localization and Mapping) because they are likely to be too power-hungry. We propose to use a biology-inspired approach, which we term the bilinear optic flow approximation, that is more computationally efficient. We build on previous work that has shown that the bilinear approximation can be used for visual servoing. Here, we show that a bilinear approximator can be learned that is able to stabilize the heading of a robot while performing continuous forward motion in a corridor-shaped environment. This is a necessary capability for confined-space navigation that insect-sized robots are likely to perform. In this work, we describe the underlining methodology of the method and built a 2D visual simulation environment and omnidirectional camera model to validate our results.",
        "primary_area": "",
        "author": "Zhitao Yu;Gioele Zardini;Andrea Censi;Sawyer Fuller;Zhitao Yu;Gioele Zardini;Andrea Censi;Sawyer Fuller",
        "authorids": "/37089663248;/37088597031;/37398994000;/37408404900;/37089663248;/37088597031;/37398994000;/37408404900",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Paul G. Allen School of Computer Science, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981585/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6722153617331424290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Washington;ETH Zurich",
        "aff_unique_dep": "Department of Mechanical Engineering;Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.washington.edu;https://www.ethz.ch",
        "aff_unique_abbr": "UW;ETHZ",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Seattle;Z\u00fcrich",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9981412",
        "title": "Visual Environment perception for obstacle detection and crossing of lower-limb exoskeletons",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower limb exoskeletons offer support for patients suffering from mobility disorders due to injury, stroke, etc. But these devices are not used in day-to-day life and environments due to their limited human-computer interface to perceive and handle different terrains and tasks. In this paper, we introduce a simple vision-based environment perception pipeline for lower- limb exoskeletons for obstacle crossing tasks. The proposed pipeline consists of three stages, namely, ground plane and obstacle detection, estimating obstacle location and dimensions, and obstacle tracking. To reduce noisy artifacts and reliably detect obstacles, we propose a similarity metric based on color, gradient orientation, and 2D surface normal. Depth map of the detected obstacle region is utilized for estimating the obstacle location and dimensions. Also, we consider two obstacle tracking modes for obstacle crossing, visual tracking using a RGB-D camera and positional tracking using a SLAM camera. The proposed vision-based perception pipeline is integrated with an exoskeleton, where we propose a control scheme that can vary step length adaptively to successfully cross detected obstacles. We conduct offline and online experiments to validate the proposed perception pipeline and provide insights on the same. Our experiments show that the proposed pipeline allows exoskeletons to understand their environment and successfully cross obstacles.",
        "primary_area": "",
        "author": "Manoj Ramanathan;Lincong Luo;Jie Kai Er;Ming Jeat Foo;Chye Hsia Chiam;Lei Li;Wei Yun Yau;Wei Tech Ang;Manoj Ramanathan;Lincong Luo;Jie Kai Er;Ming Jeat Foo;Chye Hsia Chiam;Lei Li;Wei Yun Yau;Wei Tech Ang",
        "authorids": "/37085510452;/37086029079;/37086818197;/37087032368;/37089661200;/37089459349;/37270052300;/37299508300;/37085510452;/37086029079;/37086818197;/37087032368;/37089661200;/37089459349;/37270052300;/37299508300",
        "aff": "Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Rehabilitation Research Institute of Singapore, Nanyang Technological University (NTU), Singapore; Institute for Infocomm Research, A *STAR, Singapore; School of Mechanical and Aerospace Engineering, NTU, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981412/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16363391038293295382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Institute for Infocomm Research",
        "aff_unique_dep": "Rehabilitation Research Institute of Singapore;",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "NTU;I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9981077",
        "title": "Visual Manipulation Relationship Detection based on Gated Graph Neural Network for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploring the relationship among objects and giving the correct operation sequence is vital for robotic manipulation. However, most previous algorithms only model the relationship between pairs of objects independently, ignoring the interaction effect between them, which may generate redundant or missing relations in complex scenes, such as multi-object stacking and partial occlusion. To solve this problem, a Gated Graph Neural Network (GGNN) is designed for visual manipulation relationship detection, which can help robots detect targets in complex scenes and obtain the appropriate grasping order. Firstly, the robot extracts feature from the input image and estimate object categories. Then GGNN is used to effectively capture the dependencies between objects in the whole scene, update the relevant features, and output the grasping sequence. In addition, by embedding positional encoding into pair object features, accurate context information is obtained to reduce the adverse effects of complex scenes. Finally, the constructed algorithm is applied to the physical robot for grasping. Experiment results on the Visual Ma-nipulation Relationship Dataset (VMRD) and the large-scale relational grasp dataset named REGRAD show that our method significantly improves the accuracy of relationship detection in complex scenes, and can be well generalized in the real world.",
        "primary_area": "",
        "author": "Mengyuan Ding;Yaxin Liu;Chenjie Yang;Xuguang Lan;Mengyuan Ding;Yaxin Liu;Chenjie Yang;Xuguang Lan",
        "authorids": "/37089659164;/37089662652;/37086800069;/37270865300;/37089659164;/37089662652;/37086800069;/37270865300",
        "aff": "National Engineering Laboratory for Visual Information Applications, College of Artificial Intelligence, Institute of Artificial Intelligence and Robotics, Xi\u00b4an Jiaotong University, Xi'an, China; National Engineering Laboratory for Visual Information Applications, College of Artificial Intelligence, Institute of Artificial Intelligence and Robotics, Xi\u00b4an Jiaotong University, Xi'an, China; National Engineering Laboratory for Visual Information Applications, College of Artificial Intelligence, Institute of Artificial Intelligence and Robotics, Xi\u00b4an Jiaotong University, Xi'an, China; National Engineering Laboratory for Visual Information Applications, College of Artificial Intelligence, Institute of Artificial Intelligence and Robotics, Xi\u00b4an Jiaotong University, Xi'an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981077/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3438962447566608584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "College of Artificial Intelligence",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981538",
        "title": "Visual Odometry in HDR Environments by Using Spatially Varying Exposure Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "The accuracy and robustness of visual odometry (VO) is significantly affected by the high dynamic range (HDR) environments, because traditional cameras have a limited dynamic range and inevitably miss information in both overexposed and underexposed areas. To overcome the above challenge, we use an spatially varying exposure (SVE) camera, which captures four images with different exposure levels simultaneously. Then, we propose a VO pipeline that leverages the advantages of the SVE camera. Specifically, we extract ORB features from four images in parallel firstly instead of fusing four images, then perform merging and filtering to provide more robust features. We demonstrate that the proposed system outperforms comparable state-of-the-art methods in terms of robustness and accuracy. The real-time performance of the proposed system is also guaranteed due to the elaborate design of the parallel algorithm.",
        "primary_area": "",
        "author": "Keyang Ye;Liuzheng Gao;Banglei Guan;Keyang Ye;Liuzheng Gao;Banglei Guan",
        "authorids": "/37089658405;/37089661982;/37086452960;/37089658405;/37089661982;/37086452960",
        "aff": "College of Aerospace Science and Engineering, National University of Defense Technology, China; College of Aerospace Science and Engineering, National University of Defense Technology, China; College of Aerospace Science and Engineering, National University of Defense Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981538/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8942309091755464225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Aerospace Science and Engineering",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9982073",
        "title": "Visual Pressure Estimation and Control for Soft Robotic Grippers",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic grippers facilitate contact-rich manipulation, including robust grasping of varied objects. Yet the beneficial compliance of a soft gripper also results in significant deformation that can make precision manipulation challenging. We present visual pressure estimation & control (VPEC), a method that infers pressure applied by a soft gripper using an RGB image from an external camera. We provide results for visual pressure inference when a pneumatic gripper and a tendon-actuated gripper make contact with a flat surface. We also show that VPEC enables precision manipulation via closed-loop control of inferred pressure images. In our evaluation, a mobile manipulator (Stretch RE1 from Hello Robot) uses visual servoing to make contact at a desired pressure; follow a spatial pressure trajectory; and grasp small low-profile objects, including a microSD card, a penny, and a pill. Overall, our results show that visual estimates of applied pressure can enable a soft gripper to perform precision manipulation.",
        "primary_area": "",
        "author": "Patrick Grady;Jeremy A. Collins;Samarth Brahmbhatt;Christopher D. Twigg;Chengcheng Tang;James Hays;Charles C. Kemp;Patrick Grady;Jeremy A. Collins;Samarth Brahmbhatt;Christopher D. Twigg;Chengcheng Tang;James Hays;Charles C. Kemp",
        "authorids": "/37087231294;/37089282224;/37085458304;/37088232902;/37086498346;/37410626800;/37266709400;/37087231294;/37089282224;/37085458304;/37088232902;/37086498346;/37410626800;/37266709400",
        "aff": "Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT).; Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT).; Samarth Brahmbhatt is with Intel Labs; Meta Reality Labs; Meta Reality Labs; Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT).; Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT).",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982073/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18252456388476160755&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;2;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Intel;Meta",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines;Intel Labs;Meta Reality Labs",
        "aff_unique_url": "https://www.gatech.edu;https://www.intel.com/content/www/us/en/research/labs.html;https://www.meta.com",
        "aff_unique_abbr": "GT;Intel Labs;MRL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981349",
        "title": "Visual Servo Control of COVID-19 Nasopharyngeal Swab Sampling Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we present a visual servo control framework for fully automated nasopharyngeal swab robots. The proposed framework incorporates a deep learning-based nostril detection with a cascade approach to reliably identify the nostrils with high accuracy in real time. In addition, a partitioned visual servoing scheme that combines image-based visual servoing with axial control is formulated for accurately positioning the sampling swabs at the nostril with a multi-DOF robot arm. As the visual servoing is designed to minimize an error between the detected nostril and the swab, it can compensate for potential errors in real operation, such as positioning error by inaccurate camera-robot calibration and kinematic error by unavoidable swab deflection. The performance of the visual servo control was tested on a head phantom model for 30 unused swabs, and then compared with a method referring to only the 3D nostril target for control. Consequently, the swabs reached the nostril target with less than an average error of 1.2\u00b10.5 mm and a maximum error of 2.0 mm via the visual servo control, while the operation without visual feedback yielded an average error of 10.6\u00b12.3 mm and a maximum error of 16.2 mm. The partitioned visual servoing allows the swab to rapidly converge to the nostril target within 1.0 s without control instability. Finally, the swab placement at the nostril among the entire procedure of fully automated NP swab was successfully demonstrated on a human subject via the visual servo control.",
        "primary_area": "",
        "author": "Guebin Hwang;Jongwon Lee;Sungwook Yang;Guebin Hwang;Jongwon Lee;Sungwook Yang",
        "authorids": "/37089662813;/37089183712;/38667581800;/37089662813;/37089183712;/38667581800",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981349/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13446219220892292745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics",
        "aff_unique_url": "https://www.kist.re.kr",
        "aff_unique_abbr": "KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982163",
        "title": "Visual Servoing with Geometrically Interpretable Neural Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "An increasing number of nonspecialist robotic users demand easy-to-use machines. In the context of visual servoing, the removal of explicit image processing is becoming a trend, allowing an easy application of this technique. This work presents a deep learning approach for solving the perception problem within the visual servoing scheme. An artificial neural network is trained using the supervision coming from the knowledge of the controller and the visual features motion model. In this way, it is possible to give a geometrical interpretation to the estimated visual features, which can be used in the analytical law of the visual servoing. The approach keeps perception and control decoupled, conferring flexibility and interpretability on the whole framework. Simulated and real experiments with a robotic manipulator validate our approach.",
        "primary_area": "",
        "author": "Antonio Paolillo;Mirko Nava;Dario Piga;Alessandro Giusti;Antonio Paolillo;Mirko Nava;Dario Piga;Alessandro Giusti",
        "authorids": "/37077525100;/37086691384;/37398458800;/38498058400;/37077525100;/37086691384;/37398458800;/38498058400",
        "aff": "Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982163/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11405216713281766361&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dalle Molle Institute for Artificial Intelligence",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.idsia.ch/",
        "aff_unique_abbr": "IDSIA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lugano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9981795",
        "title": "Visual-Inertial Multi-Instance Dynamic SLAM with Object-level Relocalisation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a tightly-coupled visual-inertial object-level multi-instance dynamic SLAM system. Even in extremely dynamic scenes, it can robustly optimise for the camera pose, velocity, IMU biases and build a dense 3D reconstruction object-level map of the environment. Our system can robustly track and reconstruct the geometries of arbitrary objects, their semantics and motion by incrementally fusing associated colour, depth, semantic, and foreground object probabilities into each object model thanks to its robust sensor and object tracking. In addition, when an object is lost or moved outside the camera field of view, our system can reliably recover its pose upon re-observation. We demonstrate the robustness and accuracy of our method by quantitatively and qualitatively testing it in real-world data sequences.",
        "primary_area": "",
        "author": "Yifei Ren;Binbin Xu;Christopher L. Choi;Stefan Leutenegger;Yifei Ren;Binbin Xu;Christopher L. Choi;Stefan Leutenegger",
        "authorids": "/37089662505;/37086936010;/37089660169;/37698403100;/37089662505;/37086936010;/37089660169;/37698403100",
        "aff": "Department of Computing, Imperial College London, United Kingdom; Department of Computing, Imperial College London, United Kingdom; Department of Computing, Imperial College London, United Kingdom; Smart Robotics Lab, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981795/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=178979999936021824&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Imperial College London;Technical University of Munich",
        "aff_unique_dep": "Department of Computing;Smart Robotics Lab",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.tum.de",
        "aff_unique_abbr": "Imperial;TUM",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "London;Munich",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9981134",
        "title": "Visual-Inertial SLAM with Tightly-Coupled Dropout-Tolerant GPS Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic applications are continuously striving towards higher levels of autonomy. To achieve that goal, a highly robust and accurate state estimation is indispensable. Combining visual and inertial sensor modalities has proven to yield accurate and locally consistent results in short-term applications. Unfortunately, visual-inertial state estimators suffer from the accumulation of drift for long-term trajectories. To eliminate this drift, global measurements can be fused into the state estimation pipeline. The most known and widely available source of global measurements is the Global Positioning System (GPS). In this paper, we propose a novel approach that fully combines stereo Visual-Inertial Simultaneous Localisation and Mapping (SLAM), including visual loop closures, with the fusion of global sensor modalities in a tightly-coupled and optimisation-based framework. Incorporating measurement uncertainties, we provide a robust criterion to solve the global reference frame initialisation problem. Furthermore, we propose a loop-closure-like optimisation scheme to compensate drift accumulated during outages in receiving GPS signals. Experimental validation on datasets and in a real-world experiment demonstrates the robustness of our approach to GPS dropouts as well as its capability to estimate highly accurate and globally consistent trajectories compared to existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Simon Boche;Xingxing Zuo;Simon Schaefer;Stefan Leutenegger;Simon Boche;Xingxing Zuo;Simon Schaefer;Stefan Leutenegger",
        "authorids": "/37089661836;/37086314032;/37089918470;/37698403100;/37089661836;/37086314032;/37089918470;/37698403100",
        "aff": "Department of Informatics, Smart Robotics Lab, University of Munich, Germany; Department of Comnuting, Imperial College, London, UK; Department of Informatics, Smart Robotics Lab, University of Munich, Germany; Department of Comnuting, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981134/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17131057225059130224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Munich;Imperial College London",
        "aff_unique_dep": "Department of Informatics;Department of Computing",
        "aff_unique_url": "https://www.lmu.de;https://www.imperial.ac.uk",
        "aff_unique_abbr": "LMU;ICL",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Munich;London",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9982263",
        "title": "Visual-Inertial-Aided Online MAV System Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "System modeling and parameter identification of micro aerial vehicles (MAV) are crucial for robust autonomy, especially under highly dynamic motions. Visual-inertial-aided online parameter identification has recently seen research attention due to the demanding of adaptation to platform configuration changes with minimal onboard sensor requirements. To this end, we design an online MAV system identification algorithm to tightly fuse visual, inertial and MAV aerodynamic information within a lightweight multi-state constraint Kalman filter (MSCKF) framework. In particular, while one could blindly fuse the MAV dynamic-induced relative motion constraints in EKF, we numerically show that due to the (quadrotor) MAV system modeling inaccuracy, they often become overconfident and negatively impact the state estimates. As such, we leverage the Schmidt-Kalman filter (SKF) for MAV system parameter identification to prevent corruption of state estimates. Through extensive simulations and real-world experiments, we validate the proposed SKF-based scheme and demonstrate its ability to perform robust system identification even in the presence of an inconsistent MAV dynamic model under different motions.",
        "primary_area": "",
        "author": "Chuchu Chen;Yulin Yang;Patrick Geneva;Woosik Lee;Guoquan Huang;Chuchu Chen;Yulin Yang;Patrick Geneva;Woosik Lee;Guoquan Huang",
        "authorids": "/37088486425;/37085990232;/37086125563;/37087323297;/37077670600;/37088486425;/37085990232;/37086125563;/37087323297;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982263/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4560769031281449168&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982218",
        "title": "Visual-Tactile Multimodality for Following Deformable Linear Objects Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation of deformable objects is a challenging task for a robot. It would be problematic to use a single sensory input to track the behaviour of such objects: vision can be subjected to occlusions, whereas tactile inputs cannot capture the global information that is useful for the task. In this paper, we study the problem of using vision and tactile inputs together to complete the task of following deformable linear objects, for the first time. We create a Reinforcement Learning agent using different sensing modalities and investigate how its behaviour can be boosted using visual-tactile fusion, compared to using a single sensing modality. To this end, we developed a benchmark in simulation for manipulating the deformable linear objects using multimodal sensing inputs. The policy of the agent uses distilled information, e.g., the pose of the object in both visual and tactile perspectives, instead of the raw sensing signals, so that it can be directly transferred to real environments. In this way, we disentangle the perception system and the learned control policy. Our extensive experiments show that the use of both vision and tactile inputs, together with proprioception, allows the agent to complete the task in up to 92% of cases, compared to 77% when only one of the signals is given. Our results can provide valuable insights for the future design of tactile sensors and for deformable objects manipulation. Code and videos can be found at: https://github.com/lpecyna/SoftSlidingGym.",
        "primary_area": "",
        "author": "Leszek Pecyna;Siyuan Dong;Shan Luo;Leszek Pecyna;Siyuan Dong;Shan Luo",
        "authorids": "/37086609409;/37086249096;/37085478830;/37086609409;/37086249096;/37085478830",
        "aff": "Department of Engineering, King's College London, London, UK; School of Computer Science & Engineering, University of Washington, Seattle, WA, USA; Department of Engineering, King's College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982218/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17497912625410809338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "King's College London;University of Washington",
        "aff_unique_dep": "Department of Engineering;School of Computer Science & Engineering",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.washington.edu",
        "aff_unique_abbr": "KCL;UW",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "London;Seattle",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9981153",
        "title": "Visual-tactile Sensing for Real-time Liquid Volume Estimation in Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a deep visuo-tactile model for real-time estimation of the liquid inside a deformable container in a proprioceptive way. We fuse two sensory modalities, i.e., the raw visual inputs from the RGB camera and the tactile cues from our specific tactile sensor without any extra sensor calibrations. The robotic system is well controlled and adjusted based on the estimation model in real time. The main contributions and novelties of our work are listed as follows: 1) Explore a proprioceptive way for liquid volume estimation by developing an end-to-end predictive model with multi-modal convolutional networks, which achieve a high precision with an error of ~ 2 ml in the experimental validation. 2) Propose a multi-task learning architecture which comprehensively considers the losses from both classification and regression tasks, and comparatively evaluate the performance of each variant on the collected data and actual robotic platform. 3) Utilize the proprioceptive robotic system to accurately serve and control the requested volume of liquid, which is continuously flowing into a deformable container in real time. 4) Adaptively adjust the grasping plan to achieve more stable grasping and manipulation according to the real-time liquid volume prediction.",
        "primary_area": "",
        "author": "Fan Zhu;Ruixing Jia;Lei Yang;Youcan Yan;Zheng Wang;Jia Pan;Wenping Wang;Fan Zhu;Ruixing Jia;Lei Yang;Youcan Yan;Zheng Wang;Jia Pan;Wenping Wang",
        "authorids": "/37089661762;/37089316332;/37089920726;/37088772491;/37085463419;/37535628800;/37280469500;/37089661762;/37089316332;/37089920726;/37088772491;/37085463419;/37535628800;/37280469500",
        "aff": "Department of Computer Science, The University of Hong Kong; Department of Computer Science, The University of Hong Kong; Department of Computer Science, The University of Hong Kong; Department of Biomedical Engineering, City University of Hong Kong; Department of Mechanical and Energy Engineering, Southern University of Science and Technology; Department of Computer Science, The University of Hong Kong; Department of Computer Science, The University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981153/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4709852575909702696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "University of Hong Kong;City University of Hong Kong;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science;Department of Biomedical Engineering;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.hku.hk;https://www.cityu.edu.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "HKU;CityU;SUSTech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981318",
        "title": "Voxfield: Non-Projective Signed Distance Fields for Online Planning and 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Creating accurate maps of complex, unknown environments is of utmost importance for truly autonomous navigation robot. However, building these maps online is far from trivial, especially when dealing with large amounts of raw sensor readings on a computation and energy constrained mobile system, such as a small drone. While numerous approaches tackling this problem have emerged in recent years, the mapping accuracy is often sacrificed as systematic approximation errors are tolerated for efficiency's sake. Motivated by these challenges, we propose Voxfield, a mapping framework that can generate maps online with higher accuracy and lower computational burden than the state of the art. Built upon the novel formulation of non-projective truncated signed distance fields (TSDFs), our approach produces more accurate and complete maps, suitable for surface reconstruction. Additionally, it enables efficient generation of Euclidean signed distance fields (ESDFs), useful e.g., for path planning, that does not suffer from typical approximation errors. Through a series of experiments with public datasets, both real-world and synthetic, we demonstrate that our method beats the state of the art in map coverage, accuracy and computational time. Moreover, we show that Voxfield can be utilized as a back-end in recent multi-resolution mapping frameworks, producing high quality maps even in large-scale experiments. Finally, we validate our method by running it onboard a quadrotor, showing it can generate accurate ESDF maps usable for real-time path planning and obstacle avoidance.",
        "primary_area": "",
        "author": "Yue Pan;Yves Kompis;Luca Bartolomei;Ruben Mascaro;Cyrill Stachniss;Margarita Chli;Yue Pan;Yves Kompis;Luca Bartolomei;Ruben Mascaro;Cyrill Stachniss;Margarita Chli",
        "authorids": "/37088999871;/37088941680;/37087322350;/37086455262;/37329668600;/37546501900;/37088999871;/37088941680;/37087322350;/37086455262;/37329668600;/37546501900",
        "aff": "ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; University of Bonn, Germany; ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981318/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8482427842589566622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Bonn",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ethz.ch;https://www.uni-bonn.de",
        "aff_unique_abbr": "ETHZ;UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9981874",
        "title": "WFA-IRL: Inverse Reinforcement Learning of Autonomous Behaviors Encoded as Weighted Finite Automata",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for learning logical task specifications and cost functions from demonstrations. Constructing specifications by hand is challenging for complex objectives and constraints in autonomous systems. Instead, we consider demonstrated task executions, whose logic structure and transition costs need to be inferred by an autonomous agent. We employ a spectral learning approach to extract a weighted finite automaton (WFA), approximating the unknown task logic. Thereafter, we define a product between the WFA for high-level task guidance and a labeled Markov decision process for low-level control. An inverse reinforcement learning (IRL) problem is considered to learn a cost function by backpropagating the loss between agent and expert behaviors through the planning algorithm. Our proposed model, termed WFA-IRL, is capable of generalizing the execution of the inferred task specification in a suite of MiniGrid environments.",
        "primary_area": "",
        "author": "Tianyu Wang;Nikolay Atanasov;Tianyu Wang;Nikolay Atanasov",
        "authorids": "/37088506397;/37670511000;/37088506397;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981874/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:sMXbkmpDCgIJ:scholar.google.com/&scioq=WFA-IRL:+Inverse+Reinforcement+Learning+of+Autonomous+Behaviors+Encoded+as+Weighted+Finite+Automata&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981729",
        "title": "WFH-VR: Teleoperating a Robot Arm to set a Dining Table across the Globe via Virtual Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an easy-to-deploy, virtual reality-based teleoperation system for controlling a robot arm. The proposed system is based on a consumer-grade virtual reality device (Oculus Quest 2) with a low-cost robot arm (a LoCoBot) to allow easy replication and set up. The proposed Work-from-Home Virtual Reality (WFH-VR) system allows the user to feel an intimate connection with the real remote robot arm. Virtual representations of the robot and objects to be manipulated in the real-world are presented in VR by streaming data pertaining to orientation and poses. The user studies suggest that 1) the proposed telerobotic system is effective under conditions both with and without network latency, whereas a method that simply streams video does not. This design enables the system implemented at an arbitrary distance from the actual work site. 2) The proposed system allows novices to perform manipulation tasks requiring higher dexterity than traditional keyboard controls can support, such as setting tableware. All results, hardware settings, and questionnaire feedback can be obtained at https://arg-nctu.github.io/projects/vr-robot-arm.html.",
        "primary_area": "",
        "author": "Lai Sum Yim;Quang TN Vo;Ching-I Huang;Chi-Ruei Wang;Wren McQueary;Hsueh-Cheng Wang;Haikun Huang;Lap-Fai Yu;Lai Sum Yim;Quang TN Vo;Ching-I Huang;Chi-Ruei Wang;Wren McQueary;Hsueh-Cheng Wang;Haikun Huang;Lap-Fai Yu",
        "authorids": "/37089661916;/37089663568;/37088813108;/37089663174;/37089660895;/37066008300;/37086344517;/37085623338;/37089661916;/37089663568;/37088813108;/37089663174;/37089660895;/37066008300;/37086344517;/37085623338",
        "aff": "Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Computer Science, George Mason University, USA; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Computer Science, George Mason University, USA; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Computer Science, George Mason University, USA; Department of Computer Science, George Mason University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981729/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1539980939298380513&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;0;1;1",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;George Mason University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.gmu.edu",
        "aff_unique_abbr": "NYCU;GMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;1;0;0;1;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9981889",
        "title": "Walking Control Framework on Uneven Terrain Using Variable Stiffness Sole",
        "track": "main",
        "status": "Poster",
        "abstract": "Although many walking control frameworks have been developed to enable biped robots to walk stably on uneven terrain, the foot sole of the robot is also important. Inspired by that study, we have developed a Variable Stiffness Sole (VSS), which is able to adapt to the shape of the obstacles on the ground in Compliant Mode and provide robust support in Stiff Mode. Furthermore, we proposed a walking control framework on uneven terrain for a biped robot equipped with the developed VSS. The proposed walking control framework comprises a posture balance controller to stabilize the zero moment point from disturbances applied to the robot, an ankle torque/foot force controller for walking on uneven terrain, and a VSS controller to change the mode of the VSS. Finally, the proposed framework was verified through walking experiments of RoK-3 equipped with the VSS module on a single obstacle and uneven terrain with various obstacles.",
        "primary_area": "",
        "author": "Yun-Ho Han;Junyeon Namgung;Baek-Kyu Cho;Yun-Ho Han;Junyeon Namgung;Baek-Kyu Cho",
        "authorids": "/37089658554;/37089680237;/37289357400;/37089658554;/37089680237;/37289357400",
        "aff": "Yun-Ho Han; Junyeon Namgung; Baek-Kyu Cho",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981889/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2085138065694209515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9982221",
        "title": "Watch Me Calibrate My Force-Sensing Shoes!",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method for smaller-sized humanoid robots to self-calibrate their foot force sensors. The method consists of two steps: 1. The robot is commanded to move along planned whole-body trajectories in different double support configurations. 2. The sensor parameters are determined by minimizing the error between the measured and modeled center of pressure (CoP) and ground reaction force (GRF) during the robot's movement using optimization. This is the first proposed autonomous calibration method for foot force-sensing devices in smaller humanoid robots. Furthermore, we introduce a high-accuracy manual calibration method to establish CoP ground truth, which is used to validate the measured CoP using self-calibration. The results show that the self-calibration can accurately estimate CoP and GRF without any manual intervention. Our method is demonstrated using a NAO humanoid platform and our previously presented force-sensing shoes.",
        "primary_area": "",
        "author": "Yuanfeng Han;Boren Jiang;Gregory S. Chirikjian;Yuanfeng Han;Boren Jiang;Gregory S. Chirikjian",
        "authorids": "/37088689259;/37089663532;/37283175100;/37088689259;/37089663532;/37283175100",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering National, University of Singapore, Singapore; Department of Mechanical Engineering National, University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982221/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4805016440222001399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Johns Hopkins University;National University of Singapore",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "JHU;NUS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9982186",
        "title": "Watch out! There may be a Human. Addressing Invisible Humans in Social Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Current approaches in human-aware or social robot navigation address the humans that are visible to the robot. However, it is also important to address the possible emergences of humans to avoid shocks or surprises to humans and erratic behavior of the robot planner. In this paper, we propose a novel approach to detect and address these human emergences called \u2018invisible humans\u2019. We determine the places from which a human, currently not visible to the robot, can appear suddenly and then adapt the path and speed of the robot with the anticipation of potential collisions. This is done while still considering and adapting humans present in the robot's field of view. We also show how this detection can be exploited to identify and address the doorways or narrow passages. Finally, the effectiveness of the proposed methodology is shown through several simulated and real-world experiments.",
        "primary_area": "",
        "author": "Phani Teja Singamaneni;Anthony Favier;Rachid Alami;Phani Teja Singamaneni;Anthony Favier;Rachid Alami",
        "authorids": "/37089448169;/37088448627;/37278643600;/37089448169;/37088448627;/37278643600",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982186/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1251279094746049936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9981522",
        "title": "When Geometry is not Enough: Using Reflector Markers in Lidar SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Lidar-based SLAM systems perform well in a wide range of circumstances by relying on the geometry of the environment. However, even mature and reliable approaches struggle when the environment contains structureless areas such as long hallways. To allow the use of lidar-based SLAM in such environments, we propose to add reflector markers in specific locations that would otherwise be difficult. We present an algorithm to reliably detect these markers and two approaches to fuse the detected markers with geometry-based scan matching. The performance of the proposed methods is demonstrated on real-world datasets from several industrial environments.",
        "primary_area": "",
        "author": "Gerhard Kurz;Sebastian A. Scherer;Peter Biber;David Fleer;Gerhard Kurz;Sebastian A. Scherer;Peter Biber;David Fleer",
        "authorids": "/37089696351;/37584159000;/37301850700;/37089662095;/37089696351;/37584159000;/37301850700;/37089662095",
        "aff": "Robert Bosch Corporate Research, Germany; Robert Bosch Corporate Research, Germany; Robert Bosch Corporate Research, Germany; Bosch Rexroth AG, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981522/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13193661213827577755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Robert Bosch Corporate Research;Bosch Rexroth AG",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://research.bosch.com;https://www.boschrexroth.com",
        "aff_unique_abbr": "Bosch Research;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9982122",
        "title": "Whisker-Inspired Tactile Sensing for Contact Localization on Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceiving the environment through touch is important for robots to reach in cluttered environments, but devising a way to sense without disturbing objects is challenging. This work presents the design and modelling of whisker-inspired sensors that attach to the surface of a robot manipulator to sense its surrounding through light contacts. We obtain a sensor model using a calibration process that applies to straight and curved whiskers. We then propose a sensing algorithm using Bayesian filtering to localize contact points. The algorithm combines the accurate proprioceptive sensing of the robot and sensor readings from the deflections of the whiskers. Our results show that our algorithm is able to track contact points with sub-millimeter accuracy, outperforming a baseline method. Finally, we demonstrate our sensor and perception method in a real-world system where a robot moves in between free-standing objects and uses the whisker sensors to track contacts tracing object contours.",
        "primary_area": "",
        "author": "Michael A. Lin;Emilio Reyes;Jeannette Bohg;Mark R. Cutkosky;Michael A. Lin;Emilio Reyes;Jeannette Bohg;Mark R. Cutkosky",
        "authorids": "/37085798138;/37089661343;/37591153900;/37329470000;/37085798138;/37089661343;/37591153900;/37329470000",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982122/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4473396431886133686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981199",
        "title": "Whole-Body Control with Motion/Force Transmissibility for Parallel-Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "For achieving kinematically suitable configurations and highly dynamic task execution, an efficient way is to consider robot performance indices in the whole-body control (WBC) of robots. However, current WBC methods have not considered the intrinsic features of parallel robots, especially motion/force transmissibility (MFT). This paper proposes an MFT-enhanced WBC scheme for parallel-legged robots. Introducing the performance indices of MFT into a WBC is challenging due to the nonlinear relationship between MFT indices and the robot configuration. To overcome this challenge, we establish the MFT preferable space of the robot offline and formulate it as a polyhedron in the joint space at the acceleration level. Then, the WBC employs the polyhedron as a soft constraint. As a result, the robot possesses high-speed and high-acceleration capabilities by satisfying this constraint. The offline preprocessing relieves the online computation burden and helps the WBC achieve a 1kHz servo rate. Finally, we validate the performance and robustness of the proposed method via simulations and experiments on a parallel-legged bipedal robot.",
        "primary_area": "",
        "author": "Jiajun Wang;Gang Han;Xiaozhu Ju;Mingguo Zhao;Jiajun Wang;Gang Han;Xiaozhu Ju;Mingguo Zhao",
        "authorids": "/37089450674;/37089446921;/37089449748;/37336278300;/37089450674;/37089446921;/37089449748;/37336278300",
        "aff": "Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Department of Automation Tsinghua University, and Beijing Innovation Center for Future Chips,Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981199/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15450943491846358325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "UBTECH Robotics;Tsinghua University",
        "aff_unique_dep": "Research Institute;Department of Automation",
        "aff_unique_url": "https://www.ubtech.com.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UBTECH;THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9981790",
        "title": "Whole-body model predictive control with rigid contacts via online switching time optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents a whole-body model predictive control (MPC) of robotic systems with rigid contacts, under a given contact sequence using online switching time optimization (STO). We treat robot dynamics with rigid contacts as a switched system and formulate an optimal control problem of switched systems to implement the MPC. We utilize an efficient solution algorithm for the MPC problem that optimizes the switching times and trajectory simultaneously. The present efficient algorithm, unlike inefficient existing methods, enables online optimization as well as switching times. The proposed MPC with online STO is compared over the conventional MPC with fixed switching times, through numerical simulations of dynamic jumping motions of a quadruped robot. In the simulation comparison, the proposed MPC successfully controls the dynamic jumping motions in twice as many cases as the conventional MPC, which indicates that the proposed method extends the ability of the whole-body MPC. We further conduct hardware experiments on the quadrupedal robot Unitree A1 and prove that the proposed method achieves dynamic motions on the real robot.",
        "primary_area": "",
        "author": "Sotaro Katayama;Toshiyuki Ohtsuka;Sotaro Katayama;Toshiyuki Ohtsuka",
        "authorids": "/37086294817;/37270839500;/37086294817;/37270839500",
        "aff": "Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan; Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981790/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8801490982086884418&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyoto University",
        "aff_unique_dep": "Department of System Science, Graduate School of Informatics",
        "aff_unique_url": "https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Kyoto U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9981298",
        "title": "WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search and Rescue",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor-equipped unoccupied aerial vehicles (UAVs) have the potential to help reduce search times and alleviate safety risks for first responders carrying out Wilderness Search and Rescue (WiSAR) operations, the process of finding and rescuing person(s) lost in wilderness areas. Unfortunately, visual sensors alone do not address the need for robustness across all the possible terrains, weather, and lighting conditions that WiSAR operations can be conducted in. The use of multi-modal sensors, specifically visual-thermal cameras, is critical in enabling WiSAR UAVs to perform in diverse operating conditions. However, due to the unique challenges posed by the wilderness context, existing dataset benchmarks are inadequate for developing vision-based algorithms for autonomous WiSAR UAVs. To this end, we present WiSARD, a dataset with roughly 56,000 labeled visual and thermal images collected from UAV flights in various terrains, seasons, weather, and lighting conditions. To the best of our knowledge, WiSARD is the first large-scale dataset collected with multi-modal sensors for autonomous WiSAR operations. We envision that our dataset will provide researchers with a diverse and challenging benchmark that can test the robustness of their algorithms when applied to real-world (life-saving) applications. Link to dataset: https://sites.google.com/uw.edu/wisard/",
        "primary_area": "",
        "author": "Daniel Broyles;Christopher R. Hayner;Karen Leung;Daniel Broyles;Christopher R. Hayner;Karen Leung",
        "authorids": "/37089663618;/37089662745;/37086453267;/37089663618;/37089662745;/37086453267",
        "aff": "Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981298/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=243342318254374603&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Washington;NVIDIA",
        "aff_unique_dep": "Dept. of Aeronautics and Astronautics;NVIDIA Corporation",
        "aff_unique_url": "https://www.washington.edu;https://www.nvidia.com",
        "aff_unique_abbr": "UW;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9981834",
        "title": "Wirelessly Magnetically Actuated Motor for Tissue Regeneration Robotic Implant",
        "track": "main",
        "status": "Poster",
        "abstract": "In biomedical engineering, robotic implants provide new methods to restore and improve bodily function, and regenerate tissue. A significant challenge with the design of these devices is to safely actuate them for weeks or months, while they are residing in a patient's body. Magnetic, and other force-at-distance actuation methods, allow mechanisms to be controlled remotely and without contact or line of sight to the device. In this paper, we present a novel magnetic field driven wireless motor. The motor drives a robotic implant for the treatment of long gap esophageal atresia and short bowel syndrome. The motor is equipped with two oppositely oriented permanent magnets which experience forces in opposite directions when a magnetic field is applied tangential to the magnets' directions. The implant can produce a force of 2 N. It is demonstrated with an ex vivo porcine esophagus.",
        "primary_area": "",
        "author": "Cameron Duffield;Abigail F Smith;Daniela Rus;Dana Damian;Shuhei Miyashita;Cameron Duffield;Abigail F Smith;Daniela Rus;Dana Damian;Shuhei Miyashita",
        "authorids": "/37089663806;/37088999772;/37279652300;/37587456200;/37672509400;/37089663806;/37088999772;/37279652300;/37587456200;/37672509400",
        "aff": "Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Automatic Control and Systems Engineering Department, University of Sheffield, Sheffield, UK; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Insigneo Institute for in silico Medicine, University of Sheffield, UK; Insigneo Institute for in silico Medicine, University of Sheffield, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981834/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1646268169991764567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Sheffield;Massachusetts Institute of Technology",
        "aff_unique_dep": "Automatic Control and Systems Engineering Department;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.sheffield.ac.uk;https://www.mit.edu",
        "aff_unique_abbr": "Sheffield;MIT",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sheffield;Cambridge;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9981754",
        "title": "You Are In My Way: Non-verbal Social Cues for Legible Robot Navigation Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "People and robots may need to cross each other in narrow spaces when they are sharing environments. It is expected that autonomous robots will behave in these contexts safely but also show social behaviors. Thereby, developing an acceptable behavior for autonomous robots in the area mentioned above is a foreseeable problem for the Human-Robot Interaction (HRI) field. Our current work focuses on integrating legible non-verbal behaviors into the robot's social navigation to make nearby humans aware of its intended trajectory. Results from a within-subjects study involving 33 participants show that deictic gestures as navigational cues for humanoid robots result in fewer navigation conflicts than the use of a simulated gaze. Additionally, an increase in the perceived anthropomorphism is found when the robot uses the deictic gesture as a cue. These findings show the importance of social behaviors for people avoidance and suggest a paradigm of such behaviors in future humanoid robotic applications.",
        "primary_area": "",
        "author": "Georgios Angelopoulos;Alessandra Rossi;Claudia Di Napoli;Silvia Rossi;Georgios Angelopoulos;Alessandra Rossi;Claudia Di Napoli;Silvia Rossi",
        "authorids": "/37089577266;/37085642839;/37087107499;/37604830400;/37089577266;/37085642839;/37087107499;/37604830400",
        "aff": "Georgios Angelopoulos is with the Interdepartmental Center for Advances in Robotic Surgery - ICAROS, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technologies - DIETI, University of Naples Federico II, Naples, Italy; Istituto di Calcolo e Reti ad Alte Prestazioni, CNR, Naples, Italy; Department of Electrical Engineering and Information Technologies - DIETI, University of Naples Federico II, Naples, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981754/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9846128540074822135&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Naples Federico II;Istituto di Calcolo e Reti ad Alte Prestazioni",
        "aff_unique_dep": "Interdepartmental Center for Advances in Robotic Surgery - ICAROS;CNR",
        "aff_unique_url": "https://www.unina.it;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Naples;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9981967",
        "title": "Zero-Shot Retargeting of Learned Quadruped Locomotion Policies Using Hybrid Kinodynamic Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) has witnessed great strides for quadruped locomotion, with continued progress in the reliable sim-to-real transfer of policies. However, it remains a challenge to reuse a policy on another robot, which could save time for retraining. In this work, we present a framework for zero-shot policy retargeting wherein diverse motor skills can be transferred between robots of different shapes and sizes. The new framework centers on a planning-and-control pipeline that systematically integrates RL and Model Predictive Control (MPC). The planning stage employs RL to generate a dynamically plausible trajectory as well as the contact schedule, avoiding the combinatorial complexity of contact sequence optimization. This information is then used to seed the MPC to stabilize and robustify the policy roll-out via a new Hybrid Kinodynamic (HKD) model that implicitly optimizes the foothold locations. Hardware results show an ability to transfer policies from both the A1 and Laikago robots to the MIT Mini Cheetah robot without requiring any policy re-tuning.",
        "primary_area": "",
        "author": "He Li;Wenhao Yu;Tingnan Zhang;Patrick M. Wensing;He Li;Wenhao Yu;Tingnan Zhang;Patrick M. Wensing",
        "authorids": "/37088448396;/37085891022;/37088504200;/37946046300;/37088448396;/37085891022;/37088504200;/37946046300",
        "aff": "University of Notre Dame, Notre Dame, IN, USA; Robotics, Google, Mountain View, CA, USA; Robotics, Google, Mountain View, CA, USA; University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981967/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8075413127823456441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Notre Dame;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.nd.edu;https://www.google.com",
        "aff_unique_abbr": "Notre Dame;Google",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Notre Dame;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9982187",
        "title": "dPMP-Deep Probabilistic Motion Planning: A use case in Strawberry Picking Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel probabilistic approach to deep robot learning from demonstrations (LfD). Deep move-ment primitives (DMPs) are deterministic LfD model that maps visual information directly into a robot trajectory. This paper extends DMPs and presents a deep probabilistic model that maps the visual information into a distribution of effective robot trajectories. The architecture that leads to the highest level of trajectory accuracy is presented and compared with the existing methods. Moreover, this paper introduces a novel training method for learning domain-specific latent features. We show the superiority of the proposed probabilistic approach and novel latent space learning in the real-robot task of strawberry harvesting in the lab. The experimental results demonstrate that latent space learning can significantly improve model prediction performances. The proposed approach allows to sample trajectories from distribution and optimises the robot trajectory to meet a secondary objective, e.g. collision avoidance.",
        "primary_area": "",
        "author": "Alessandra Tafuro;Bappaditya Debnath;Andrea M. Zanchettin;E. Amir Ghalamzan;Alessandra Tafuro;Bappaditya Debnath;Andrea M. Zanchettin;E. Amir Ghalamzan",
        "authorids": "/37085859004;/37086637895;/37546427600;/37088970847;/37085859004;/37086637895;/37546427600;/37088970847",
        "aff": "Politecnico di Milano, Italy; Edge Hill University, UK; Politecnico di Milano, Italy; Lincoln Institute for Agri-food Technology, University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982187/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8122716495456717048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Politecnico di Milano;Edge Hill University;University of Lincoln",
        "aff_unique_dep": ";;Lincoln Institute for Agri-food Technology",
        "aff_unique_url": "https://www.polimi.it;https://www.edgehill.ac.uk;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "Polimi;EHU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9981577",
        "title": "db-A*: Discontinuity-bounded Search for Kinodynamic Mobile Robot Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider time-optimal motion planning for dynamical systems that are translation-invariant, a property that holds for many mobile robots, such as differential-drives, cars, airplanes, and multirotors. Our key insight is that we can extend graph-search algorithms to the continuous case when used symbiotically with optimization. For the graph search, we introduce discontinuity-bounded A* (db-A*), a generalization of the A* algorithm that uses concepts and data structures from sampling-based planners. Db-A* reuses short trajectories, so-called motion primitives, as edges and allows a maximum user-specified discontinuity at the vertices. These trajectories are locally repaired with trajectory optimization, which also provides new improved motion primitives. Our novel kinodynamic motion planner, kMP-db-A*, has almost surely asymptotic optimal behavior and computes near-optimal solutions quickly. For our empirical validation, we provide the first benchmark that compares search-, sampling-, and optimization- based time-optimal motion planning on multiple dynamical systems in different settings. Compared to the baselines, kMP- db-A* consistently solves more problem instances, finds lower- cost initial solutions, and converges more quickly.",
        "primary_area": "",
        "author": "Wolfgang H\u00f6nig;Joaquim Ortiz-Haro;Marc Toussaint;Wolfgang H\u00f6nig;Joaquim Ortiz-Haro;Marc Toussaint",
        "authorids": "/37543456200;/37088998356;/37528418600;/37543456200;/37088998356;/37528418600",
        "aff": "TU, Berlin, Germany; TU, Berlin, Germany; TU, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981577/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14236510601353654876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Berlin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9981451",
        "title": "eCDT: Event Clustering for Simultaneous Feature Detection and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Contrary to other standard cameras, event cam-eras interpret the world in an entirely different manner; as a collection of asynchronous events. Despite event camera's unique data output, many event feature detection and tracking algorithms have shown significant progress by making detours to frame-based data representations. This paper questions the need to do so and proposes a novel event data-friendly method that achieve simultaneous feature detection and tracking, called event Clustering-based Detection and Tracking (eCDT). Our method employs a novel clustering method, named as k-NN Classifier-based Spatial Clustering and Applications with Noise (KCSCAN), to cluster adjacent polarity events to retrieve event trajectories. With the aid of a Head and Tail Descriptor Matching process, event clusters that reappear in a different polarity are continually tracked, elongating the feature tracks. Thanks to our clustering approach in spatio-temporal space, our method automatically solves feature detection and feature tracking simultaneously. Also, eCDT can extract feature tracks at any frequency with an adjustable time window, which does not corrupt the high temporal resolution of the original event data. Our method achieves 30 % better feature tracking ages compared with the state-of-the-art approach while also having a low error approximately equal to it.",
        "primary_area": "",
        "author": "Sumin Hu;Yeeun Kim;Hyungtae Lim;Alex Junho Lee;Hyun Myung;Sumin Hu;Yeeun Kim;Hyungtae Lim;Alex Junho Lee;Hyun Myung",
        "authorids": "/37088446287;/37086349774;/37086920570;/37086278558;/37424926900;/37088446287;/37086349774;/37086920570;/37086278558;/37424926900",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981451/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4913025072824954581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST",
        "aff_unique_dep": "School of Electrical Engineering;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9982181",
        "title": "enpheeph: A Fault Injection Framework for Spiking and Compressed Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Research on Deep Neural Networks (DNNs) has focused on improving performance and accuracy for real-world deployments, leading to new models, such as Spiking Neural Networks (SNNs), and optimization techniques, e.g., quantization and pruning for compressed networks. However, the deployment of these innovative models and optimization techniques introduces possible reliability issues, which is a pillar for DNNs to be widely used in safety-critical applications, e.g., autonomous driving. Moreover, scaling technology nodes have the associated risk of multiple faults happening at the same time, a possibility not addressed in state-of-the-art resiliency analyses. Towards better reliability analysis for DNNs, we present enpheeph, a Fault Injection Framework for Spiking and Compressed DNNs. The enpheeph framework enables optimized execution on specialized hardware devices, e.g., GPUs, while providing complete customizability to investigate different fault models, emulating various reliability constraints and use-cases. Hence, the faults can be executed on SNNs as well as compressed networks with minimal-to-none modifications to the underlying code, a feat that is not achievable by other state-of-the-art tools. To evaluate our enpheeph framework, we analyze the resiliency of different DNN and SNN models, with different compression techniques. By injecting a random and increasing number of faults, we show that DNNs can show a reduction in accuracy with a fault rate as low as 7\\times 10^{-7}7\\times 10^{-7} faults per parameter, with an accuracy drop higher than 40%. Run-time overhead when executing enpheeph is less than 20% of the baseline execution time when executing 100 000 faults concurrently, at least 10\u00d7 lower than state-of-the-art frameworks, making enpheeph future-proof for complex fault injection scenarios. We release the source code of our enpheeph framework under an open-source license at https://github.com/Alexei95/enpheeph.",
        "primary_area": "",
        "author": "Alessio Colucci;Andreas Steininger;Muhammad Shafique;Alessio Colucci;Andreas Steininger;Muhammad Shafique",
        "authorids": "/37088517870;/37284661800;/37408660000;/37088517870;/37284661800;/37408660000",
        "aff": "Institute of Computer Engineering, Technische Universit\u00e4t Wien, Vienna, Austria; Institute of Computer Engineering, Technische Universit\u00e4t Wien, Vienna, Austria; Division of Engineering, eBrain Lab, New York University, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9982181/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11751555953494023744&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technische Universit\u00e4t Wien;New York University",
        "aff_unique_dep": "Institute of Computer Engineering;Division of Engineering",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.nyu.edu",
        "aff_unique_abbr": "TU Wien;NYU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Vienna;Abu Dhabi",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Austria;United Arab Emirates"
    },
    {
        "id": "9981194",
        "title": "\u03a92: Optimal Hierarchical Planner for Object Search in Large Environments via Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hierarchical planning algorithm that efficiently computes an optimal plan for finding a target object in large environments where a robot must simultaneously consider both navigation and manipulation. One key challenge that arises from large domains is the substantial increase in search space complexity that stems from considering mobile manipulation actions and the increase in number of objects. We offer a hierarchical planning solution that effectively handles such large problems by decomposing the problem into a set of low-level intra-container planning problems and a high-level key place planning problem that utilizes the low-level plans. To plan optimally, we propose a novel admissible heuristic function that, unlike previous methods, accounts for both navigation and manipulation costs. We propose two algorithms: one based on standard A* that returns the optimal solution, and the other based on Anytime Repairing A* (ARA*) which can trade-off computation time and solution quality, and prove they are optimal even when we use hierarchy. We show our method outperforms existing algorithms in simulated domains involving up to 6 times more number of objects than previously handled.",
        "primary_area": "",
        "author": "Yoonyoung Cho;Donghoon Shin;Beomjoon Kim;Yoonyoung Cho;Donghoon Shin;Beomjoon Kim",
        "authorids": "/37089659060;/37089660377;/37089661469;/37089659060;/37089660377;/37089661469",
        "aff": "Department of Artifical Intelligence, Intelligent Mobile Manipulation Lab,Korea Advanced Institute of Science and Technology; Dronebot Combat Development Center,Republic of Korea Army Training and Doctrine Command; Department of Artifical Intelligence, Intelligent Mobile Manipulation Lab,Korea Advanced Institute of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981194/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6931561357946844913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Republic of Korea Army Training and Doctrine Command",
        "aff_unique_dep": "Department of Artifical Intelligence;Dronebot Combat Development Center",
        "aff_unique_url": "https://www.kaist.ac.kr;",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9981653",
        "title": "\u201cI'm Confident This Will End Poorly\u201d: Robot Proficiency Self-Assessment in Human-Robot Teaming",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot teams are expected to accomplish complex tasks in high-risk and uncertain environments. In domains such as space exploration or search & rescue, a human operator may not be a robotics expert, but will need to establish a baseline understanding of the robot's capabilities with respect to a given task in order to appropriately utilize and rely on the robot. This willingness to rely, also known as trust, is based partly on the operator's belief in the robot's task proficiency. If trust is too high, the operator may unknowingly push the robot beyond its capabilities. If trust is too low, the operator may not utilize it when they otherwise could have, wasting precious time and resources. In this work, we discuss results from an online human-subjects study investigating how a robot communicated report of its task proficiency with respect to an operator's expectations affects trust and performance in a navigation task. Our results show that communication of a robot self-assessment helped operators understand when reliance on the robot was appropriate given the task and conditions. This led to improvements in task performance, informed choices of autonomy level, and increased trust.",
        "primary_area": "",
        "author": "Nicholas Conlon;Daniel Szafir;Nisar Ahmed;Nicholas Conlon;Daniel Szafir;Nisar Ahmed",
        "authorids": "/37089661462;/37086231248;/37533152500;/37089661462;/37086231248;/37533152500",
        "aff": "Department of Computer Science, University of Colorado at Boulder, Boulder, CO, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Smead Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9981653/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4271290211889037746&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Colorado at Boulder;University of North Carolina at Chapel Hill",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.unc.edu",
        "aff_unique_abbr": "CU Boulder;UNC Chapel Hill",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Boulder;Chapel Hill",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    }
]