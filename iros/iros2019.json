[
    {
        "id": "8967671",
        "title": "2-Entity RANSAC for robust visual localization in changing environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization has attracted considerable attention due to its low-cost and stable sensor, which is desired in many applications, such as autonomous driving, inspection robots and unmanned aerial vehicles. However, current visual localization methods still struggle with environmental changes across weathers and seasons, as there is significant appearance variation between the map and the query image. The crucial challenge in this situation is that the percentage of outliers, i.e. incorrect feature matches, is high. In this paper, we derive minimal closed form solutions for 3D-2D localization with the aid of inertial measurements, using only 2 point matches or 1 point match and 1 line match. These solutions are further utilized in the proposed 2-entity RANSAC, which is more robust to outliers as both line and point features can be used simultaneously and the number of matches required for pose calculation is reduced. Furthermore, we introduce three feature sampling strategies with different advantages, enabling an automatic selection mechanism. With the mechanism, our 2-entity RANSAC can be adaptive to the environments with different distribution of feature types in different segments. Finally, we evaluate the method on both synthetic and real-world datasets, validating its performance and effectiveness in inter-session scenarios.",
        "primary_area": "",
        "author": "Yanmei Jiao;Yue Wang;Bo Fu;Xiaqing Ding;Qimeng Tan;Lei Chen;Rong Xiong;Yanmei Jiao;Yue Wang;Bo Fu;Xiaqing Ding;Qimeng Tan;Lei Chen;Rong Xiong",
        "authorids": "/37086475262;/37072299700;/37087325170;/37086331151;/37086355678;/37087325307;/37271511300;/37086475262;/37072299700;/37087325170;/37086331151;/37086355678;/37087325307;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, P.R. China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967671/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2505702426881496261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "Zhejiang University;Beijing Institute of Spacecraft System Engineering",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology;Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968591",
        "title": "2D Contour Following with an Unmanned Aerial Manipulator: Towards Tactile-Based Aerial Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper a force controller via energy tanks is implemented for novel applications in aerial contour follow. This control approach allows the aerial vehicle to trace out a boundary whilst in continuous contact with a surface by means of an actively compliant manipulator. This represents the first step towards tactile-based aerial navigation, which can be used to complement more traditional mapping approaches such as visual SLAM. Key results show that the energy-based approach can be used to apply a continuous shear force through the manipulator while the vehicle remains in contact with the surface of interest. Results also show the robustness and repeatability of this approach for prolonged aerial interaction, and the potential for future use in more complex, un-modeled environments.",
        "primary_area": "",
        "author": "Salua Hamaza;Ioannis Georgilas;Thomas Richardson;Salua Hamaza;Ioannis Georgilas;Thomas Richardson",
        "authorids": "/37085715218;/37085628698;/37683275600;/37085715218;/37085628698;/37683275600",
        "aff": "Faculty of Engineering, University of Bristol, UK; Department of Mechanical Engineering, University of Bath, UK; Faculty of Engineering, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968591/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9534851537236669548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Bristol;University of Bath",
        "aff_unique_dep": "Faculty of Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.bath.ac.uk",
        "aff_unique_abbr": "UoB;Bath",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968046",
        "title": "3-DOF Gravity Compensation Mechanism for Robot Waists with the Variations of Center of Mass",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a three-degrees-of-freedom (DOF) gravity compensation mechanism for the waists of cooperative robots whose centers of mass change according to the arm poses. It comprises 2-DOF and 1-DOF gravity compensation mechanisms in series, and is capable of natural and agile motions such as bobbing and weaving. The 2-DOF mechanism for the upper part of the waist acts as a universal joint. To compensate for the gravity of this 2-DOF motion, a simple and robust link mechanism with one compressive spring is proposed. Moreover, for the complete gravity compensation regardless of the arm poses, a three-dimensional (3D) parallel link structure that maintains the upper body parallel to the ground is introduced. The 1-DOF gravity compensation mechanism, which provides the motions of the hip and thigh, also has a parallelogram structure to maintain the waist parallel to the ground. The implemented 3-DOF waist mechanism can compensate for up to 23 kg and its own weight. It has an adjusting mechanism that can easily calibrate the amount of compensation in case the weight of the upper body changes. The large workspace enables the upper body to move in any direction in a 3D space without singularity. Therefore, the robot with this waist can touch the ground to pick up objects on the ground as well as reach an object at a height of 2145 mm.",
        "primary_area": "",
        "author": "Seong-Ho Yun;Jiwon Seo;Junsuk Yoon;Hansol Song;Yun-Soo Kim;Yong-Jae Kim;Seong-Ho Yun;Jiwon Seo;Junsuk Yoon;Hansol Song;Yun-Soo Kim;Yong-Jae Kim",
        "authorids": "/37086577512;/37086577158;/37086574669;/37086578091;/37086578700;/37085566845;/37086577512;/37086577158;/37086574669;/37086578091;/37086578700;/37085566845",
        "aff": "University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968046/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17884788342293228590&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Technology and Education",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "Koreatech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cheonan-City",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968170",
        "title": "3D LiDAR and Stereo Fusion using Stereo Matching Network with Conditional Cost Volume Normalization",
        "track": "main",
        "status": "Poster",
        "abstract": "The complementary characteristics of active and passive depth sensing techniques motivate the fusion of the LiDAR sensor and stereo camera for improved depth perception. Instead of directly fusing estimated depths across LiDAR and stereo modalities, we take advantages of the stereo matching network with two enhanced techniques: Input Fusion and Conditional Cost Volume Normalization (CCVNorm) on the LiDAR information. The proposed framework is generic and closely integrated with the cost volume component that is commonly utilized in stereo matching neural networks. We experimentally verify the efficacy and robustness of our method on the KITTI Stereo and Depth Completion datasets, obtaining favorable performance against various fusion strategies. Moreover, we demonstrate that, with a hierarchical extension of CCVNorm, the proposed method brings only slight overhead to the stereo matching network in terms of computation time and model size.",
        "primary_area": "",
        "author": "Tsun-Hsuan Wang;Hou-Ning Hu;Chieh Hubert Lin;Yi-Hsuan Tsai;Wei-Chen Chiu;Min Sun;Tsun-Hsuan Wang;Hou-Ning Hu;Chieh Hubert Lin;Yi-Hsuan Tsai;Wei-Chen Chiu;Min Sun",
        "authorids": "/37086455878;/37087321940;/37089092353;/37085759166;/37086286145;/37085873757;/37086455878;/37087321940;/37089092353;/37085759166;/37086286145;/37085873757",
        "aff": "Tsun-Hsuan Wang; Hou-Ning Hu; Chieh Hubert Lin; Yi-Hsuan Tsai; Wei-Chen Chiu; Min Sun",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968170/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8000333135730771844&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8968300",
        "title": "3D Micromanipulation of Particle Swarm Using a Hexapole Magnetic Tweezer",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Xiao Zhang;Louis William Rogowski;Min Jun Kim;Xiao Zhang;Louis William Rogowski;Min Jun Kim",
        "authorids": "/37086024991;/37086020640;/37536816100;/37086024991;/37086020640;/37536816100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968300/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18421402198034678606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "8967918",
        "title": "3D Move to See: Multi-perspective visual servoing towards the next best view within unstructured and occluded environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a novel approach termed 3D Move to See (3DMTS) which is based on the principle of finding the next best view using a 3D camera array and a robotic manipulator to obtain multiple samples of the scene from different perspectives. Distinct from traditional visual servoing and next best view approaches, the proposed method uses simultaneously-captured multiple views, scene segmentation and an objective function applied to each perspective to estimate a gradient representing the direction of the next best view in a \u201csingle shot\u201d. The method is demonstrated within simulation and on a real robot containing a custom 3D camera array for the challenging scenario of robotic harvesting in a highly occluded and unstructured environment. We show, on a real robotic platform, that by moving the eye-in-hand camera using the gradient of an objective function leads to a locally optimal view of the object of interest, even amongst occlusions. The overall performance of the 3DMTS approach obtains a mean increase in target size of 29.3% compared to a baseline method using a single RGB-D camera, which obtained 9.17%. The results demonstrate qualitatively and quantitatively that the 3DMTS method performed better in most scenarios, and yielded three times the target size compared to the baseline method. Increasing the target size in the image given occlusions can improve robotic systems detecting key object features for further manipulation tasks, such as grasping and harvesting.",
        "primary_area": "",
        "author": "Chris Lehnert;Dorian Tsai;Anders Eriksson;Chris McCool;Chris Lehnert;Dorian Tsai;Anders Eriksson;Chris McCool",
        "authorids": "/37546443200;/37086010623;/37269930500;/38274733400;/37546443200;/37086010623;/37269930500;/38274733400",
        "aff": "Queensland University of Technology (QUT), Brisbane, Australia; Queensland University of Technology (QUT), Brisbane, Australia; Queensland University of Technology (QUT), Brisbane, Australia; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967918/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14443914628098511176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Queensland University of Technology;University of Bonn",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.qut.edu.au;https://www.uni-bonn.de",
        "aff_unique_abbr": "QUT;UBonn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Australia;Germany"
    },
    {
        "id": "8968469",
        "title": "3D Point Cloud Data Acquisition Using a Synchronized In-Air Imaging Sonar Sensor Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Obtaining accurate data about the environment in which a robot is located is a crucial matter when it comes to autonomous navigation and other robotic applications. A popular method of acquiring this information is to use sonar-rings, where a robot is fitted with multiple simple ultrasound transducers pointed in the directions where an object can appear. However, in a time where accurate 3D data is gaining importance, other sensing modalities are becoming more popular because of the ability to measure dense 3D point clouds. In these point clouds not only the horizontal plane is measured, but objects in the elevation planes can also be registered, which can be very interesting and makes applications such as 3D SLAM or object recognition possible. In this paper we present a way to extract complex 3D point cloud data from the entire surrounding sphere using multiple interconnected eRTIS sensors. These advanced imaging sonar sensors offer the flexibility of the popular sonar-ring in combination with the benefits of some of the competing sensing modalities. The setup presented here uses less sonar sensors (and thus less external hardware) while obtaining more information from the complete frontal hemispheres of each individual sensor. This setup is discussed, along with the issues that arise when using complex imaging sonar sensors in a network, and is tested in an indoor and outdoor environment. At the end of this paper is a discussion of the obtained results.",
        "primary_area": "",
        "author": "Robin Kerstens;Dennis Laurijssen;Girmi Schouten;Jan Steckel;Robin Kerstens;Dennis Laurijssen;Girmi Schouten;Jan Steckel",
        "authorids": "/37086191943;/37085490219;/37086253512;/37885021400;/37086191943;/37085490219;/37086253512;/37885021400",
        "aff": "Cosys-Lab, University of Antwerp and the Flanders Make Strategic Research Centre; Cosys-Lab, University of Antwerp and the Flanders Make Strategic Research Centre; Cosys-Lab, University of Antwerp and the Flanders Make Strategic Research Centre; Cosys-Lab, University of Antwerp and the Flanders Make Strategic Research Centre",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968469/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14807865692896151271&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Antwerp",
        "aff_unique_dep": "Cosys-Lab",
        "aff_unique_url": "https://www.uantwerp.be",
        "aff_unique_abbr": "UA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "8967729",
        "title": "3D Printed Single Incision Laparoscopic Manipulator System Adapted to the Required Forces in Laparoscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "3D printing in medical technology is mainly used to produce customized devices for surgical planning or surgical guides and templates. However, for laparoscopic systems, 3D printing is hardly used. A challenge is the transmission of the necessary forces required in laparoscopic surgery.We designed and manufactured a 3D printed customizable manipulator system for Single Incision Laparoscopic Surgery (SILS), fulfilling the force-related requirements in laparoscopic surgery.The Single Incision Laparoscopic Manipulator System can apply forces at its tip up to 5.6 N with acceptable operating forces not exceeding 30 N. We showed the functionality of the manipulator system in a manipulation experiment in comparison to standard SILS instruments.",
        "primary_area": "",
        "author": "Sandra V. Brecht;Matthias Stock;Jens-Uwe Stolzenburg;Tim C. Lueth;Sandra V. Brecht;Matthias Stock;Jens-Uwe Stolzenburg;Tim C. Lueth",
        "authorids": "/37085991401;/37087323935;/37601851400;/37389804500;/37085991401;/37087323935;/37601851400;/37389804500",
        "aff": "Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed) of the Technical University of Munich, Munich, Germany; Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed) of the Technical University of Munich, Munich, Germany; University of Leipzig, Leipzig, Germany; Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed) of the Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967729/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12274598080054274917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;University of Leipzig",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.tum.de;https://www.uni-leipzig.de",
        "aff_unique_abbr": "TUM;Uni Leipzig",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Munich;Leipzig",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967734",
        "title": "3D Reconstruction by Single Camera Omnidirectional Multi-Stereo System",
        "track": "main",
        "status": "Poster",
        "abstract": "Omnidirectional catadioptric systems are popular in robotic applications thanks to their large field of view. For 3D scene reconstruction in a single shot, usually two different catadioptric cameras are needed. More cameras may contribute to better reconstruction while larger mounting space and higher power cost are required. In this paper, a single camera multi-stereo catadioptric system with vertical and horizontal baseline structure is proposed. It features achieving multi-pair of central or non-central omnidirectional stereos in a compact manner. To make the 3D reconstruction process general and adaptive to various types of system configurations, a flexible calibration and reconstruction algorithm pipeline is presented. The algorithm features approximating the system into multiple central sub-cameras and carrying out the stereo matching in a spherical representation. In addition, an effective 3D point cloud fusion algorithm is proposed to optimize the reconstruction results from multiple stereo pairs. The experiment carried out with synthetic and real data verified the feasibility and effectiveness of our system.",
        "primary_area": "",
        "author": "Shuya Chen;Zhiyu Xiang;Nan Zoul;Yiman Chen;Chengyu Qiao;Shuya Chen;Zhiyu Xiang;Nan Zoul;Yiman Chen;Chengyu Qiao",
        "authorids": "/37086953294;/37331922100;/37087324416;/37086954010;/37086950749;/37086953294;/37331922100;/37087324416;/37086954010;/37086950749",
        "aff": "College of Information and Electronic Engineering, Zhejiang University, Hangzhou, China; Key Laboratory of Information Processing, Communication and Networking, Zhejiang University, Hangzhou, China; College of Information and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information and Electronic Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967734/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fk_qLRDHSXEJ:scholar.google.com/&scioq=3D+Reconstruction+by+Single+Camera+Omnidirectional+Multi-Stereo+System&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "College of Information and Electronic Engineering",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967835",
        "title": "6-Axis Hybrid Sensing and Estimation of Tip Forces/Torques on a Hyper-Redundant Robotic Surgical Instrument",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper a hybrid method for estimation of 6 degree-of-freedom (DOF) laparoscopic instrument tip force/torques in robotic-assisted minimally invasive surgery systems is proposed. The method is implemented on an in-house developed hyper-redundant (11-DOF) surgical robotic forceps prototype. This surgical robot is composed of two modules with a 7-DOF Kuka IIWA manipulator for performing 4-DOF Remote Centre of Motion (RCM) about the trocar and an articulated 4-DOF parallel wrist/gripper mechanism attached to the distal end of the Kuka robot for intra-corporeal manipulation. The hybrid sensor-based/sensorless method fuses torque estimates from the parallel wrist mechanism with measurements from a force sensor attached between the wrist base and the Kuka tool frame. With this approach it is possible to obtain force/torque estimates on all Cartesian axes (x, y, z, yaw, pitch, roll) of the forceps tip. The prototype is one of the first systems designed for robotic surgery that can achieve accurate force estimation on all 6 axes of the instrument tip. Experiment validation results with a force sensor verify the efficacy of the proposed method.",
        "primary_area": "",
        "author": "Nural Yilmaz;Merve Bazman;Alaa Alassi;Berke Gur;Ugur Tumerdem;Nural Yilmaz;Merve Bazman;Alaa Alassi;Berke Gur;Ugur Tumerdem",
        "authorids": "/37086385321;/37086386074;/37086448657;/37086031977;/37396306900;/37086385321;/37086386074;/37086448657;/37086031977;/37396306900",
        "aff": "Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, Turkey; Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, Turkey; Department of Mechatronics Engineering, Bahcesehir University, Besiktas, Istanbul, Turkey; Department of Mechatronics Engineering, Bahcesehir University, Besiktas, Istanbul, Turkey; Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967835/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11943772251946681934&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Marmara University;Bahcesehir University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechatronics Engineering",
        "aff_unique_url": "https://www.marmara.edu.tr;https://www.bahcesehir.edu.tr",
        "aff_unique_abbr": ";BAU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Istanbul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "8968526",
        "title": "A 3D Static Modeling Method and Experimental Verification of Continuum Robots Based on Pseudo-Rigid Body Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum robots composed of elastic backbones have a broad application prospect in the narrow and restricted environment because they overcome the disadvantages of traditional articulated robots, such as being bulky and inflexible. Statics plays an important role in the planning and control of the continuum robot composed of the elastic backbone. Pseudo-Rigid Body (PRB) theory has shown great potential in the description of flexible body statics. The PRB 3R model accurately describes the large deformation of the flexible body and has high computational efficiency. However, PRB 3R models mostly focus on the planar static modeling, and there are few applications in three-dimensional (3D) statics. In this paper, a 3D static modeling method of cable-driven continuum robot based on PRB 3R theory is proposed. By introducing the equilibrium constraint equations of resultant force/moment and bending plane normal of the elastic backbone, the state of the continuum robot is determined. The 3D static equations established by the proposed method take into account the comprehensive effects of the elastic force, external force, gravity and friction. A static verification experiment system of the cable-driven continuum robot is designed to verify the proposed method. The accuracy of the proposed method is verified by comparison with experimental data. The maximum position error between simulation and experimental results is 7.6%.",
        "primary_area": "",
        "author": "Shaoping Huang;Deshan Meng;Xueqian Wang;Bin Liang;Weining Lu;Shaoping Huang;Deshan Meng;Xueqian Wang;Bin Liang;Weining Lu",
        "authorids": "/37086543846;/37085515586;/37085383477;/37270783900;/37085495844;/37086543846;/37085515586;/37085383477;/37270783900;/37085495844",
        "aff": "Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968526/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16410798351368028637&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Graduate School",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968233",
        "title": "A Behavior Tree Cognitive Assistant System for Emergency Medical Services",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a cognitive assistant system for emergency medical services (EMS) that can serve as a rescue robot or virtual assistant, helping with improving situational awareness of the first responders through automated collection and analysis of data from the incident scene and providing suggestions to them. The proposed system relies on a Behavior Tree (BT) framework that combines the knowledge of EMS protocol guidelines with speech recognition, natural language processing, and machine learning methods to (i) extract critical information from responders' conversations and verbalized observations, (ii) infer the incident context, and (iii) decide on safe and effective response interventions to perform. We use a data-set of 8302 real EMS call records from an urban, high volume regional ambulance agency in the U.S. to evaluate the responsiveness and cognitive ability of the system and assess the safety of the suggestions provided to the responders. The experimental results show that the developed cognitive assistant achieves an average top-3 accuracy of 89% in selecting the correct EMS protocols and an average F1-score of 71% in suggesting the protocol specific interventions while providing transparency and evidence for the suggestions.",
        "primary_area": "",
        "author": "Sile Shu;Sarah Preum;Haydon M. Pitchford;Ronald D. Williams;John Stankovic;Homa Alemzadeh;Sile Shu;Sarah Preum;Haydon M. Pitchford;Ronald D. Williams;John Stankovic;Homa Alemzadeh",
        "authorids": "/37087322380;/37085525323;/37087323799;/38183327400;/37279446200;/37601630800;/37087322380;/37085525323;/37087323799;/38183327400;/37279446200;/37601630800",
        "aff": "Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, USA; Department of Computer Science, University of Virginia, Charlottesville, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, USA; Department of Computer Science, University of Virginia, Charlottesville, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968233/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14372270685764784942&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968554",
        "title": "A Benchmark for Visual-Inertial Odometry Systems Employing Onboard Illumination",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a dataset for evaluating the performance of visual-inertial odometry (VIO) systems employing an onboard light source. The dataset consists of 39 sequences, recorded in mines, tunnels, and other dark environments, totaling more than 160 minutes of stereo camera video and IMU data. In each sequence, the scene is illuminated by an onboard light of approximately 1300, 4500, or 9000 lumens. We accommodate both direct and indirect visual odometry methods by providing the geometric and photometric camera calibrations (i.e. response, attenuation, and exposure times). In contrast with existing datasets, we also calibrate the light source itself and publish data for inferring more complex light models. Ground-truth position data are available for a subset of sequences, as captured by a Leica total station. All remaining sequences start and end at the same position, permitting the use of total accumulated drift as a metric for evaluation. Using our proposed benchmark, we analyze the performance of several start-of-the-art VO and VIO frame-works. The full dataset, including sensor data, calibration sequences, and evaluation scripts, is publicly available online at http://arpg.colorado.edu/research/oivio.",
        "primary_area": "",
        "author": "Mike Kasper;Steve McGuire;Christoffer Heckman;Mike Kasper;Steve McGuire;Christoffer Heckman",
        "authorids": "/37086032035;/37086340420;/37086032368;/37086032035;/37086340420;/37086032368",
        "aff": "Autonomous Robotics and Perception Group (APRG), University of Colorado. Boulder, Colorado, USA; Autonomous Robotics and Perception Group (APRG), University of Colorado. Boulder, Colorado, USA; Autonomous Robotics and Perception Group (APRG), University of Colorado. Boulder, Colorado, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968554/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6925819444877181396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado",
        "aff_unique_dep": "Autonomous Robotics and Perception Group (APRG)",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967799",
        "title": "A Bi-directional Multiple Timescales LSTM Model for Grounding of Actions and Verbs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a neural architecture to learn a bi-directional mapping between actions and language. We implement a Multiple Timescale Long Short-Term Memory (MT-LSTM) network comprised of 7 layers with different timescale factors, to connect actions to language without explicitly learning an intermediate representation. Instead, the model self-organizes such representations at the level of a slow-varying latent layer, linking action branch and language branch at the center. We train the model in a bi-directional way, learning how to produce a sentence from a certain action sequence input and, simultaneously, how to generate an action sequence given a sentence as input. Furthermore we show this model preserves some of the generalization behaviour of Multiple Timescale Recurrent Neural Networks (MTRNN) in generating sentences and actions that were not explicitly trained. We compare this model with a number of different baseline models, confirming the importance of both the bi-directional training and the multiple timescales architecture. Finally, the network was evaluated on motor actions performed by an iCub robot and their corresponding letter-based description. The results of these experiments are presented at the end of the paper.",
        "primary_area": "",
        "author": "Alexandre Antunes;Alban Laflaquiere;Tetsuya Ogata;Angelo Cangelosi;Alexandre Antunes;Alban Laflaquiere;Tetsuya Ogata;Angelo Cangelosi",
        "authorids": "/37085814867;/38275190200;/37273829100;/37428592400;/37085814867;/38275190200;/37273829100;/37428592400",
        "aff": "School of Computing, Electronics and Mathematics, University of Plymouth, Plymouth, United Kingdom; AI Lab, SoftBank Robotics Europe, Paris, France; Department of Intermedia Art and Science, Waseda University, Tokyo, Japan, and Artificial Intelligence Research Center at AIST, Tokyo, Japan; School of Computing, Electronics and Mathematics, University of Plymouth, Plymouth, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967799/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6828515424617195559&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Plymouth;SoftBank Robotics Europe;Waseda University",
        "aff_unique_dep": "School of Computing, Electronics and Mathematics;AI Lab;Department of Intermedia Art and Science",
        "aff_unique_url": "https://www.plymouth.ac.uk;https://www.softbankrobotics.com;https://www.waseda.jp/top",
        "aff_unique_abbr": ";SBR Europe;Waseda",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Plymouth;Paris;Tokyo",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United Kingdom;France;Japan"
    },
    {
        "id": "8968255",
        "title": "A Compact Laser-Steering End-Effector for Transoral Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Laryngeal cancer treatments, while curative, often lead to voice impairment. Minimally invasive surgical methods that facilitate greater preservation of healthy tissue have recently emerged, but they are still limited in important ways. In this work, we describe a device that combines the advantages of the two primary minimally invasive approaches: the high quality incision and reduced post-operative pain achievable with transoral laser microsurgery and the superior visualization and tissue manipulability afforded by transoral robotic surgery. Our 11 mm diameter scanning system connects to focusing optics and a fiber optic laser source and can direct a laser beam across a 18\u00d710 mm plane with controllable trajectories at speeds up to 7m/s. We describe its design and benchtop validation and present avenues for further development within a clinical environment. While oncological treatment is a natural first application area for this technology, we anticipate that it may also yield important benefits for the minimally invasive treatment of benign laryngeal diseases.",
        "primary_area": "",
        "author": "Simon A. Bothner;Peter A. York;Phillip C. Song;Robert J. Wood;Simon A. Bothner;Peter A. York;Phillip C. Song;Robert J. Wood",
        "authorids": "/37087323337;/37085549245;/37087325200;/37326227400;/37087323337;/37085549245;/37087325200;/37326227400",
        "aff": "Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland; School of Engineering and Applied Sciences, Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA; Division of Laryngology, Mass Eye and Ear, Boston, MA, USA; School of Engineering and Applied Sciences, Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968255/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1581848976790907027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne;Harvard University;Massachusetts Eye and Ear",
        "aff_unique_dep": ";School of Engineering and Applied Sciences;Division of Laryngology",
        "aff_unique_url": "https://www.epfl.ch;https://www.harvard.edu;https://www.masseyeandear.org",
        "aff_unique_abbr": "EPFL;Harvard;",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Lausanne;Cambridge;Boston",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "8968105",
        "title": "A Comparative Analysis on the use of Autoencoders for Robot Security Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "While robots are more and more deployed among people in public spaces, the impact of cyber-security attacks is significantly increasing. Most of consumer and professional robotic systems are affected by multiple vulnerabilities and the research in this field is just started. This paper addresses the problem of automatic detection of anomalous behaviors possibly coming from cyber-security attacks. The proposed solution is based on extracting system logs from a set of internal variables of a robotic system, on transforming such data into images, and on training different Autoencoder architectures to classify robot behaviors to detect anomalies. Experimental results in two different scenarios (autonomous boats and social robots) show effectiveness and general applicability of the proposed method.",
        "primary_area": "",
        "author": "Matteo Olivato;Omar Cotugno;Lorenzo Brigato;Domenico Bloisi;Alessandro Farinelli;Luca Iocchi;Matteo Olivato;Omar Cotugno;Lorenzo Brigato;Domenico Bloisi;Alessandro Farinelli;Luca Iocchi",
        "authorids": "/37087324886;/37087323649;/37086447691;/38111727700;/37266396700;/37281906600;/37087324886;/37087323649;/37086447691;/38111727700;/37266396700;/37281906600",
        "aff": "Dept of Information Engineering, University of Brescia, Italy; Dept of Information Engineering, University of Brescia, Italy; Dept of Information Engineering, University of Brescia, Italy; Dept of Mathematics, University of Basilicata, Italy; Dept of Computer Science, University of Verona, Italy; Dept of Computer, Sapienza University of Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968105/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16328829226485807991&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;3",
        "aff_unique_norm": "University of Brescia;University of Basilicata;University of Verona;Sapienza University of Rome",
        "aff_unique_dep": "Dept of Information Engineering;Dept of Mathematics;Dept of Computer Science;Dept of Computer",
        "aff_unique_url": "https://www.unibs.it;https://www.unibas.it;https://www.univr.it;https://www.uniroma1.it",
        "aff_unique_abbr": ";;;Sapienza",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Rome",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967946",
        "title": "A Comparison of Action Spaces for Learning Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing reinforcement learning (RL) problems that can produce delicate and precise manipulation policies requires careful choice of the reward function, state, and action spaces. Much prior work on applying RL to manipulation tasks has defined the action space in terms of direct joint torques or reference positions for a joint-space proportional derivative (PD) controller. In practice, it is often possible to add additional structure by taking advantage of model-based controllers that support both accurate positioning and control of the dynamic response of the manipulator. In this paper, we evaluate how the choice of action space for dynamic manipulation tasks affects the sample complexity as well as the final quality of learned policies. We compare learning performance across three tasks (peg insertion, hammering, and pushing), four action spaces (torque, joint PD, inverse dynamics, and impedance control), and using two modern reinforcement learning algorithms (Proximal Policy optimization and Soft Actor-Critic). Our results lend support to the hypothesis that learning references for a task-space impedance controller significantly reduces the number of samples needed to achieve good performance across all tasks and algorithms.",
        "primary_area": "",
        "author": "Patrick Varin;Lev Grossman;Scott Kuindersma;Patrick Varin;Lev Grossman;Scott Kuindersma",
        "authorids": "/37087324680;/37087323750;/37990645600;/37087324680;/37087323750;/37990645600",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967946/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17854878489035910651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967710",
        "title": "A Comparison of Visual Servoing from Features Velocity and Acceleration Interaction Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Servoing has been widely investigated in the last decades as it provides a powerful strategy for robot control. Thanks to the direct feed-back from a set of sensors, it allows to reduce the impact of some modeling errors and to perform tasks even in uncertain environments. The commonly exploited approach in this field is to use a model that expresses the rate of change of a set of features as a function of sensor twist. These schemes are commonly used to obtain a velocity command, which needs to be tracked by a low-level controller. Another approach that can be exploited consists in going one step further and to consider an acceleration model for the features. This strategy allows also to obtain a natural and direct link with the dynamic model of the controlled system. This study aims at comparing the use of velocity and acceleration-based models in feed-back linearization for Visual Servoing. We consider the case of a redundant manipulator and discuss what this implies for both control techniques. By means of simulations, we show that controllers based on features acceleration give better results than those based on velocity in presence of noisy feedback signals.",
        "primary_area": "",
        "author": "Franco Fusco;Olivier Kermorgant;Philippe Martinet;Franco Fusco;Olivier Kermorgant;Philippe Martinet",
        "authorids": "/37086573623;/37546399400;/37277258700;/37086573623;/37546399400;/37277258700",
        "aff": "Centrale Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes LS2N, France; Centrale Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes LS2N, France; Centrale Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes LS2N, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967710/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18817750443934069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Centrale Nantes",
        "aff_unique_dep": "Laboratoire des Sciences du Num\u00e9rique de Nantes LS2N",
        "aff_unique_url": "https://www.centrale-nantes.fr",
        "aff_unique_abbr": "CN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968179",
        "title": "A Convex-Combinatorial Model for Planar Caging",
        "track": "main",
        "status": "Poster",
        "abstract": "Caging is a promising tool which allows a robot to manipulate an object without directly reasoning about the contact dynamics involved. Furthermore, caging also provides useful guarantees in terms of robustness to uncertainty, and often serves as a way-point to a grasp. However, caging is traditionally difficult to integrate as part of larger manipulation frameworks, where caging is not the goal but an intermediate condition. In this paper, we develop a convex-combinatorial model to characterize caging from an optimization perspective. More specifically, we derive a set of sufficient constraints to enclose the configuration of the object in a compact-connected component of its free-space. The convex-combinatorial nature of this approach provides guarantees on optimality and convergence, and its optimization nature makes it versatile for further applications on robot manipulation tasks. To the best of our knowledge, this is the first optimization-based approach to formulate the caging condition.",
        "primary_area": "",
        "author": "Bernardo Aceituno-Cabezas;Hongkai Dai;Alberto Rodriguez;Bernardo Aceituno-Cabezas;Hongkai Dai;Alberto Rodriguez",
        "authorids": "/37086279842;/37086280420;/38194796600;/37086279842;/37086280420;/38194796600",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology; Toyota Research Institute; Department of Mechanical Engineering, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968179/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14170252535104419201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://web.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967644",
        "title": "A Convolutional Network for Joint Deraining and Dehazing from A Single Image for Autonomous Driving in Rain",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on a rain removal task from a single image of the urban street scene for autonomous driving in rain. We develop a Convolutional Neural Network which takes a rainy image as input, and directly recovers a clean image in the presence of rain streaks, atmospheric veiling effect (haze, fog, mist) caused by distant rain streak accumulation. We propose a synthetic dataset containing images of urban street scenes with different rain intensities, orientations and haziness levels for training and evaluation. We evaluate our method quantitatively and qualitatively on the synthetic data. Experiments show that our model outperforms state-of-the-art methods. We also test our method qualitatively on the real-world data. Our model is fast and it takes 0.05s for an image of 1024 \u00d7 512. Our model can be seamlessly integrated with existing image-based high-level perception algorithms for autonomous driving in rain. Experiment results show that our deraining method improves semantic segmentation and object detection largely for autonomous driving in rain.",
        "primary_area": "",
        "author": "Hao Sun;Marcelo H. Ang;Daniela Rus;Hao Sun;Marcelo H. Ang;Daniela Rus",
        "authorids": "/37086072464;/37279138700;/37279652300;/37086072464;/37279138700;/37279652300",
        "aff": "Singapore-MIT Alliance for Research and Technology (SMART); Department of Mechanical Engineering, National University of Singapore (NUS); Massachusetts Institute of Technology (MIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967644/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11263768036653643705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Department of Mechanical Engineering;",
        "aff_unique_url": "https://smart.mit.edu/;https://www.nus.edu.sg;https://web.mit.edu",
        "aff_unique_abbr": "SMART;NUS;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8968222",
        "title": "A Convolutional Neural Network Feature Detection Approach to Autonomous Quadrotor Indoor Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection, extended to recognize and localize indoor structural features, is used to enable a quadrotor drone to autonomously navigate through indoor environments. The video stream from a monocular front-facing camera on-board a quadrotor drone is fed to an off-board system that runs a Convolutional Neural Network (CNN) object detection algorithm to identify specific features such as dead-ends, doors, and intersections in hallways. Using pixel-scale dimensions of the bounding boxes around the recognized objects, the distance to intersections, dead-ends and doorways can be estimated accurately using a Support Vector Regression (SVR) model to generate flight control commands for consistent real-time autonomous navigation at flight speeds approaching 2 m/s.",
        "primary_area": "",
        "author": "Adriano Garcia;Sandeep S. Mittal;Edward Kiewra;Kanad Ghose;Adriano Garcia;Sandeep S. Mittal;Edward Kiewra;Kanad Ghose",
        "authorids": "/38238316800;/37086058295;/37086939417;/37274791100;/38238316800;/37086058295;/37086939417;/37274791100",
        "aff": "Department of Computer Science, State University of New York, Binghamton, NY; Department of Computer Science, State University of New York, Binghamton, NY; Department of Computer Science, State University of New York, Binghamton, NY; Department of Computer Science, State University of New York, Binghamton, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968222/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4151200261464600403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "State University of New York at Binghamton",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.binghamton.edu",
        "aff_unique_abbr": "SUNY Binghamton",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Binghamton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968458",
        "title": "A Data-Driven Framework for Learning Dexterous Manipulation of Unknown Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of developing precision, quasi-static control strategies for fingertip manipulation in robot hands. In general, analytically specifying useful object transition maps, or hand-object Jacobians, for scenarios in which there is uncertainty in some key aspect of the hand-object system is difficult or impossible. This could be in scenarios with standard fully-actuated hands where, for instance, there is not an accurate model of the contact conditions, or in scenarios with fewer control inputs than mechanical degrees of freedom (such as underactuated hands or those that are controlled by synergies or impedance controlled frameworks), since the output space is of higher dimension than the input space. In this work, we develop a method for extracting object transition maps by tracking the state of the grasp frame. We begin by modeling a compliant, underactuated hand and its mechanical properties through an energy-based approach. From this energy model, we provide controlled actuation inputs to change the state of the grasp frame. We observe the response from these actions and develop a regression map of the action-reaction pairs, where the map is subject to our intent for grasp frame movement and the regional relationship between the contacts. Once the regression model is developed, we perform within-hand planning of the grasp frame with newly introduced objects. This approach is agnostic to the global geometry of the object and is able to adapt when undesirable contact conditions, such as sliding, occur. The learning-based methodology estimates the non-linearities representative in the properties of the system. We test our framework physically on an adapted Yale Openhand Model O. By transferring the learned model from simulation to the physical hand without adaptation, we show that this energy modeling approach is robust to inaccuracies in parameter estimation. We demonstrate its efficacy in a handwriting task.",
        "primary_area": "",
        "author": "Andrew S. Morgan;Kaiyu Hang;Walter G. Bircher;Aaron M. Dollar;Andrew S. Morgan;Kaiyu Hang;Walter G. Bircher;Aaron M. Dollar",
        "authorids": "/37086455182;/37085393148;/37086000645;/37604732600;/37086455182;/37085393148;/37086000645;/37604732600",
        "aff": "Dept of Mech Eng and Mater Science, Yale University, CT, USA; Dept of Mech Eng and Mater Science, Yale University, CT, USA; Dept of Mech Eng and Mater Science, Yale University, CT, USA; Dept of Mech Eng and Mater Science, Yale University, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968458/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13113804260933219879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering and Material Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New Haven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968443",
        "title": "A Deep Learning Approach for Multi-View Engagement Estimation of Children in a Child-Robot Joint Attention Task",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we tackle the problem of child engagement estimation while children freely interact with a robot in a friendly, room-like environment. We propose a deep learning-based multi-view solution that takes advantage of recent developments in human pose detection. We extract the child's pose from different RGB-D cameras placed regularly in the room, fuse the results and feed them to a deep Neural Network (NN) trained for classifying engagement levels. The deep network contains a recurrent layer, in order to exploit the rich temporal information contained in the pose data. The resulting method outperforms a number of baseline classifiers and provides a promising tool for better automatic understanding of a child's attitude, interest and attention while cooperating with a robot. The goal is to integrate this model in next-generation social robots as an attention monitoring tool during various Child Robot Interaction (CRI) tasks both for Typically Developed (TD) children and children affected by autism (ASD).",
        "primary_area": "",
        "author": "Jack Hadfield;Georgia Chalvatzaki;Petros Koutras;Mehdi Khamassi;Costas S. Tzafestas;Petros Maragos;Jack Hadfield;Georgia Chalvatzaki;Petros Koutras;Mehdi Khamassi;Costas S. Tzafestas;Petros Maragos",
        "authorids": "/37086577450;/37085353493;/37085414629;/37085730247;/37296005200;/37285070800;/37086577450;/37085353493;/37085414629;/37085730247;/37296005200;/37285070800",
        "aff": "Athena Research and Innovation Center, Maroussi, Greece; School of ECE, National Technical Univ. of Athens, Athens, Greece; Athena Research and Innovation Center, Maroussi, Greece; School of ECE, National Technical Univ. of Athens, Athens, Greece; School of ECE, National Technical Univ. of Athens, Athens, Greece; Athena Research and Innovation Center, Maroussi, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968443/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1904498321195944389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "Athena Research and Innovation Center;National Technical University of Athens",
        "aff_unique_dep": ";School of Electrical and Computer Engineering",
        "aff_unique_url": ";https://www.ntua.gr",
        "aff_unique_abbr": ";NTUA",
        "aff_campus_unique_index": "0;1;0;1;1;0",
        "aff_campus_unique": "Maroussi;Athens",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "8967914",
        "title": "A Deep Learning Approach for Robust Corridor Following",
        "track": "main",
        "status": "Poster",
        "abstract": "For an autonomous corridor following task where the environment is continuously changing, several forms of environmental noise prevent an automated feature extraction procedure from performing reliably. Moreover, in cases where pre-defined features are absent from the captured data, a well defined control signal for performing the servoing task fails to get produced. In order to overcome these drawbacks, we present in this work, using a convolutional neural network (CNN) to directly estimate the required control signal from an image, encompassing feature extraction and control law computation into one single end-to-end framework. In particular, we study the task of autonomous corridor following using a CNN and present clear advantages in cases where a traditional method used for performing the same task fails to give a reliable outcome. We evaluate the performance of our method on this task on a Wheelchair Platform developed at our institute for this purpose.",
        "primary_area": "",
        "author": "Vishnu Sashank Dorbala;A.H. Abdul Hafez;C.V. Jawahar;Vishnu Sashank Dorbala;A.H. Abdul Hafez;C.V. Jawahar",
        "authorids": "/37086951195;/37295897200;/37270075200;/37086951195;/37295897200;/37270075200",
        "aff": "International Institute of Information Technology, Hyderabad, India; Hasan Kalyoncu University, Gaziantep, Turkey; International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967914/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4750686213583532184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "International Institute of Information Technology;Hasan Kalyoncu University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.hku.edu.tr",
        "aff_unique_abbr": "IIIT Hyderabad;HKU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Hyderabad;Gaziantep",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "India;T\u00fcrkiye"
    },
    {
        "id": "8967551",
        "title": "A Density Map Estimation Model with DropBlock Regularization for Clustered-Fruit Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern agricultural robots like drones have been studied in automatic yield estimation in recent years. Fruit counting is a fundamental task in the automatic yield estimation, on which significant progress has been achieved by detection-based methods and segmentation-regression-based methods. However, for clustered-fruit counting, the existing methods lack advantages on the localization of small and occluded fruits or discrete number regression. In addition, it is observed that existing deep neural network based counting methods have high variances on fruit density map estimation. Aiming at solving these two problems and decreasing the regression variance, in this paper, we propose a density-map-estimation model with DropBlock regularization. For evaluating the proposed model, we propose a new Clustered-Fruit dataset. Extensive experiments show that the proposed model is effective and outperforms the state-of-the-art counting methods on the Clustered-Fruit dataset. Our dataset is available at Clustered-Fruit.",
        "primary_area": "",
        "author": "Xiaochun Mai;Xiao Jia;Xiaoling Deng;Max Q.-H. Meng;Xiaochun Mai;Xiao Jia;Xiaoling Deng;Max Q.-H. Meng",
        "authorids": "/37086113153;/37085886867;/37626605000;/37274117000;/37086113153;/37085886867;/37626605000;/37274117000",
        "aff": "Robotics, Perception and AI Laboratory, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Robotics, Perception and AI Laboratory, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Department of Electronic Information Engineering, South China Agricultural University, China; Robotics, Perception and AI Laboratory, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967551/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5588958424377745368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;South China Agricultural University",
        "aff_unique_dep": "Robotics, Perception and AI Laboratory;Department of Electronic Information Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.scau.edu.cn",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "N.T.;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968144",
        "title": "A Dynamic Optimization Approach for Sloshing Free Transport of Liquid Filled Containers using an Industrial Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The handling of liquid filled containers is a challenging task in industrial manufacturing processes. Without an appropriate trajectory sloshing of the liquid occurs during point-to-point motion. This paper presents a time optimal trajectory planning approach that is used for feedforward motion control and prevents the liquid filled container from sloshing. For this, a model of the liquid inside the container is included into the formulation of a constrained dynamic optimization problem to achieve rest-to-rest motion while simultaneously avoiding obstacles. The presented approach is validated by simulation and on an experimental setup using an industrial robot handling the container.",
        "primary_area": "",
        "author": "Jan Reinhold;Manuel Amersdorfer;Thomas Meurer;Jan Reinhold;Manuel Amersdorfer;Thomas Meurer",
        "authorids": "/37087324162;/37087323569;/37299134300;/37087324162;/37087323569;/37299134300",
        "aff": "Chair of Automatic Control, Faculty of Engineering, Kiel University Kaiserstra\u00dfe 2, Kiel, Germany; Chair of Automatic Control, Faculty of Engineering, Kiel University Kaiserstra\u00dfe 2, Kiel, Germany; Chair of Automatic Control, Faculty of Engineering, Kiel University Kaiserstra\u00dfe 2, Kiel, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968144/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14148597656422926032&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Kiel University",
        "aff_unique_dep": "Chair of Automatic Control",
        "aff_unique_url": "https://www.uni-kiel.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kiel",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968459",
        "title": "A Framework for Depth Estimation and Relative Localization of Ground Robots using Computer Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "The 3D depth estimation and relative pose estimation problem within a decentralized architecture is a challenging problem that arises in missions that require coordination among multiple vision-controlled robots. The depth estimation problem aims at recovering the 3D information of the environment. The relative localization problem consists of estimating the relative pose between two robots, by sensing each other's pose or sharing information about the perceived environment. Most solutions for these problems use a set of discrete data without taking into account the chronological order of the events. This paper builds on recent results on continuous estimation to propose a framework that estimates the depth and relative pose between two non-holonomic vehicles. The basic idea consists in estimating the depth of the points by explicitly considering the dynamics of the camera mounted on a ground robot, and feeding the estimates of 3D points observed by both cameras in a filter that computes the relative pose between the robots. We evaluate the convergence for a set of simulated scenarios and show experimental results validating the proposed framework.",
        "primary_area": "",
        "author": "R\u00f4mulo T. Rodrigues;Pedro Miraldo;Dimos V. Dimarogonas;A. Pedro Aguiar;R\u00f4mulo T. Rodrigues;Pedro Miraldo;Dimos V. Dimarogonas;A. Pedro Aguiar",
        "authorids": "/37085349500;/38241727500;/37282084700;/37427058500;/37085349500;/38241727500;/37282084700;/37427058500",
        "aff": "Research Center for Systems and Technologies (SYSTEC), Faculty of Engineering, University of Porto, Porto, Portugal; Devision of Decision and Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Devision of Decision and Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Research Center for Systems and Technologies (SYSTEC), Faculty of Engineering, University of Porto, Porto, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968459/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=893933930545827828&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Porto;KTH Royal Institute of Technology",
        "aff_unique_dep": "Faculty of Engineering;Devision of Decision and Control Systems",
        "aff_unique_url": "https://www.fe.up.pt;https://www.kth.se",
        "aff_unique_abbr": "UPorto;KTH",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Porto;Stockholm",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Portugal;Sweden"
    },
    {
        "id": "8967733",
        "title": "A Fully-Integrated Sensing and Control System for High-Accuracy Mobile Robotic Building Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a fully-integrated sensing and control system which enables mobile manipulator robots to execute building tasks with millimeter-scale accuracy on building construction sites. The approach leverages multi-modal sensing capabilities for state estimation, tight integration with digital building models, and integrated trajectory planning and whole-body motion control. A novel method for high-accuracy localization updates relative to the known building structure is proposed. The approach is implemented on a real platform and tested under realistic construction conditions. We show that the system can achieve sub-cm end-effector positioning accuracy during fully autonomous operation using solely onboard sensing.",
        "primary_area": "",
        "author": "Abel Gawel;Hermann Blum;Johannes Pankert;Koen Kr\u00e4mer;Luca Bartolomei;Selen Ercan;Farbod Farshidian;Margarita Chli;Fabio Gramazio;Roland Siegwart;Marco Hutter;Timothy Sandy;Abel Gawel;Hermann Blum;Johannes Pankert;Koen Kr\u00e4mer;Luca Bartolomei;Selen Ercan;Farbod Farshidian;Margarita Chli;Fabio Gramazio;Roland Siegwart;Marco Hutter;Timothy Sandy",
        "authorids": "/37085766697;/37086048087;/37086599761;/37086935674;/37087322350;/38542131400;/37085428006;/37546501900;/38540941300;/37281398300;/37545251000;/37085800060;/37085766697;/37086048087;/37086599761;/37086935674;/37087322350;/38542131400;/37085428006;/37546501900;/38540941300;/37281398300;/37545251000;/37085800060",
        "aff": "Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zunch; Robotic Systems Lab, ETH Zunch; Vision for Robotics Lab, ETH Zunch; Gramazio-Kohler Research, ETH Zunch; Robotic Systems Lab, ETH Zunch; Vision for Robotics Lab, ETH Zunch; Gramazio-Kohler Research, ETH Zunch; Autonomous Systems Lab, ETH Zurich; Robotic Systems Lab, ETH Zunch; Robotic Systems Lab, ETH Zunch",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967733/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18051840100474530532&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "1;1;1;1;1;1;1;1;1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968519",
        "title": "A GPS-aided Omnidirectional Visual-Inertial State Estimator in Ubiquitous Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The visual-inertial navigation system (VINS) has been a practical approach for state estimation in recent years. In this paper, we propose a general GPS-aided omnidirectional visual-inertial state estimator capable of operating in ubiquitous environments and platforms. Our system consists of two parts: 1) the pre-processing of omnidirectional cameras, IMU, and GPS measurements, and 2) the sliding window based nonlinear optimization for accurate state estimation. We test our system in different conditions including an indoor office, campus roads, and challenging open water surface. Experiment results demonstrate the high accuracy of our approach than state-of-the-art VINSs in all scenarios. The proposed odometry achieves drift ratio less than 0.5% in 1200 m length outdoors campus road in overexposure conditions and 0.65% in open water surface, without a loop closure, compared with a centimeter accuracy GPS reference.",
        "primary_area": "",
        "author": "Yang Yu;Wenliang Gao;Chengju Liu;Shaojie Shen;Ming Liu;Yang Yu;Wenliang Gao;Chengju Liu;Shaojie Shen;Ming Liu",
        "authorids": "/37086962478;/37086298106;/37677379800;/37954847200;/37085398677;/37086962478;/37086298106;/37677379800;/37954847200;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; College of Electrical and Information Engineering, Tongji University, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968519/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7513739812449947977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Tongji University",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;College of Electrical and Information Engineering",
        "aff_unique_url": "https://www.ust.hk;http://www.tongji.edu.cn",
        "aff_unique_abbr": "HKUST;Tongji",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967588",
        "title": "A Gear-Driven Prosthetic Hand with Major Grasp Functions for Toddlers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a gear-driven prosthetic hand designed for toddlers with transradial amputation. The hand design considers three main issues: weight, cost, and operability. The prosthetic hand and the cosmetic silicon glove are made based on the dimensions of a real hand. The simple, stable, and reliable gear-driven transmission helps to reduce the weight and the cost. A small actuator is embedded in the palm. During the grasp, the four fingers and the thumb flexes and extends as a unit to provide a wide range of holding area. The kinematics and static analysis in grasping was performed and the simulation results were compared with measured data. The motion performance and practical operability of the proposed hand was verified experimentally by a test system and a transradial subject.",
        "primary_area": "",
        "author": "Xiaobei Jingl;Xu Yongl;Yuankang Shi;Yoshiko Yabiki;Yinlai Jiang;Hiroshi Yokoi;Guanglin Li;Xiaobei Jingl;Xu Yongl;Yuankang Shi;Yoshiko Yabiki;Yinlai Jiang;Hiroshi Yokoi;Guanglin Li",
        "authorids": "/37087322476;/37087322209;/37087324920;/37087323735;/37085406020;/37285419100;/37405541900;/37087322476;/37087322209;/37087324920;/37087323735;/37085406020;/37285419100;/37405541900",
        "aff": "CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, China; CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, China; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967588/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3528872612196648909&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Electro-Communications",
        "aff_unique_dep": "Key Laboratory of Human-Machine Intelligence-Synergy Systems;Department of Mechanical Engineering and Intelligent Systems",
        "aff_unique_url": "http://www.cas.cn;https://www.uec.ac.jp",
        "aff_unique_abbr": "CAS;UEC",
        "aff_campus_unique_index": "0;0;1;1;1;1;0",
        "aff_campus_unique": "Shenzhen;Chofu",
        "aff_country_unique_index": "0;0;1;1;1;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8968146",
        "title": "A Generative Model of Underwater Images for Active Landmark Detection and Docking",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater active landmarks (UALs) are widely used for short-range underwater navigation in underwater robotics tasks. Detection of UALs is challenging due to large variance of underwater illumination, water quality and change of camera viewpoint. Moreover, improvement of detection accuracy relies upon statistical diversity of images used to train detection models. We propose a generative adversarial network, called Tank-to-field GAN (T2FGAN), to learn generative models of underwater images, and use the learned models for data augmentation to improve detection accuracy. To this end, first a T2FGAN is trained using images of UALs captured in a tank. Then, the learned model of the T2FGAN is used to generate images of UALs according to different water quality, illumination, pose and landmark configurations (WIPCs). In experimental analyses, we first explore statistical properties of images of UALs generated by T2FGAN under various WIPCs for active landmark detection. Then, we use the generated images for training detection algorithms. Experimental results show that training detection algorithms using the generated images can improve detection accuracy. In field experiments, underwater docking tasks are successfully performed in a lake by employing detection models trained on datasets generated by T2FGAN.",
        "primary_area": "",
        "author": "Shuang Liu;Mete Ozay;Hongli Xu;Yang Lin;Takayuki Okatani;Shuang Liu;Mete Ozay;Hongli Xu;Yang Lin;Takayuki Okatani",
        "authorids": "/37085756209;/38331422900;/37277777400;/37085678254;/37270695100;/37085756209;/38331422900;/37277777400;/37085678254;/37270695100",
        "aff": "State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Chinese Academy of Sciences, Institutes for Robotics and Intelligent Manufacturing, Shenyang, China; University of Chinese Academy of Sciences, Beijing, China; Graduate School of Information Sciences, Tohoku University, Sendai, Miyagi, Japan; RIKEN Center for Advanced Intelligence Project, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968146/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11830237584131137266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Shenyang Institute of Automation, Chinese Academy of Sciences;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Tohoku University;RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": "State Key Laboratory of Robotics;Institutes for Robotics and Intelligent Manufacturing;;Graduate School of Information Sciences;Center for Advanced Intelligence Project",
        "aff_unique_url": "http://www.sia.cas.cn;http://www.cas.cn;http://www.ucas.ac.cn;https://www.tohoku.ac.jp;https://www.riken.jp/en/c-aip/",
        "aff_unique_abbr": "SIA;CAS;UCAS;Tohoku U;RIKEN C-AIP",
        "aff_campus_unique_index": "0;0;1;2;3",
        "aff_campus_unique": "Shenyang;Beijing;Sendai;Tokyo",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8967774",
        "title": "A Handheld Master Controller for Robot-Assisted Microsurgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate master-slave control is important for Robot-Assisted Microsurgery (RAMS). This paper presents a handheld master controller for the operation and training of RAMS. A 9-axis Inertial Measure Unit (IMU) and a micro camera are utilized to form the sensing system for the handheld controller. A new hybrid marker pattern is designed to achieve reliable visual tracking, which integrated QR codes, Aruco markers, and chessboard vertices. Real-time multi-sensor fusion is implemented to further improve the tracking accuracy. The proposed handheld controller has been verified on an in-house microsurgical robot to assess its usability and robustness. User studies were conducted based on a trajectory following task, which indicated that the proposed handheld controller had comparable performance with the Phantom Omni, demonstrating its potential applications in microsurgical robot control and training.",
        "primary_area": "",
        "author": "Dandan Zhang;Yao Guo;Junhong Chen;Jindong Liu;Guang-Zhong Yang;Dandan Zhang;Yao Guo;Junhong Chen;Jindong Liu;Guang-Zhong Yang",
        "authorids": "/37086595836;/37086919325;/37087325379;/37879388800;/37276270800;/37086595836;/37086919325;/37087325379;/37879388800;/37276270800",
        "aff": "Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967774/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14044919958117025916&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968518",
        "title": "A Magnetically Transduced Whisker for Angular Displacement and Moment Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the design, modeling, and fabrication of a whisker-like sensor capable of measuring the whisker's angular displacement as well as the applied moments at the base of the whisker. The sensor takes advantage of readily accessible and low-cost 3D magnetic sensors to transduce whisker deflections, and a planar serpentine spring structure at the whisker base is used to provide a mechanical suspension for the whisker to rotate. The sensor prototype was characterized, calibrated, and compared with analytical models of the spring system and the magnetic field. The prototype showed a moment sensing range of 1.1N\u00b7mm when deflected up to 19.7\u00b0. The sensitivity of the sensor was 0.38\u00b0/LSB for the angular displacement sensing, and 0.021 Nmm/LSB for the moment sensing. A fully integrated system is demonstrated to display real-time information from the whisker on a graphical interface.",
        "primary_area": "",
        "author": "Suhan Kim;Camilo Velez;Dinesh K. Patel;Sarah Bergbreiter;Suhan Kim;Camilo Velez;Dinesh K. Patel;Sarah Bergbreiter",
        "authorids": "/37087323805;/37085494121;/37087324115;/37542605000;/37087323805;/37085494121;/37087324115;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968518/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15175416043505761612&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968523",
        "title": "A Method for Guiding a Person Combining Robot Movement and Projection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new method to guide a person along with a route when a mobile robot explains an exhibition. In previous work, there were problems that people overtake the robot and go out of the guide route, and that people move to positions that interferes with the movement of the robot. In response to these problems, a conventional solution is to frequently instruct people to move by using voice, displays, etc., and it was not a comfortable for people who are guided. In this paper, we focus on a mobile robot with a projection function and propose a method of controlling human positions without explicit instructions by combining movement and projection of a robot. We introduce three basic guiding behaviors combining projection and movement, each controlling a person and a robot into different positional relationship according to the situation of guiding. Experiments of basic guiding behaviors showed that both the existence of the robot and the position of the projected image are combined to affect the movement of the guided person. The result indicates that by selecting appropriate guide behavior according to the situation of guiding, the robot can guide a person effectively while controlling the position of the person.",
        "primary_area": "",
        "author": "Aki Tamai;Tetsushi Ikeda;Satoshi Iwaki;Aki Tamai;Tetsushi Ikeda;Satoshi Iwaki",
        "authorids": "/37087324387;/37278723300;/37295533000;/37087324387;/37278723300;/37295533000",
        "aff": "Graduate School of Information Sciences, Hiroshima City University, Hiroshima, JAPAN; Graduate School of Information Sciences, Hiroshima City University, Hiroshima, JAPAN; Graduate School of Information Sciences, Hiroshima City University, Hiroshima, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968523/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16220590314929533822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hiroshima City University",
        "aff_unique_dep": "Graduate School of Information Sciences",
        "aff_unique_url": "https://www.hcu-hiroshima.ac.jp",
        "aff_unique_abbr": "HCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hiroshima",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967768",
        "title": "A Mobile Extendable Robot Arm: Singularity Analysis and Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspection and maintenance of equipment inside buildings, such as exit signs, bared pipelines, air vents, and fire alarms often requires a robot to reach high, hidden, or confined areas that are difficult for humans to access. Even though these tasks are easy and repeatable, they are still not automated. The Mobile Extendable Robot Arm (MERA) is a movable robot arm with a novel 2-DOF scissor mechanism for reaching a high place and positioning an end-effector. MERA is composed of a locomotion vehicle with a rotation table and a 4-DOF extender arm, itself made of two layers of the 2-DOF scissor mechanism arranged in series. Placing the end-effector at an arbitrary point in space, the 4-DOF arm possesses two degrees of redundancy, allowing access to a point from various directions and enabling obstacle avoidance. In this paper, we present the design and analysis of the 2-DOF scissor mechanism. The 2-DOF scissor mechanism has two rotary actuators for driving the base links individually; consequently, the mechanism can elongate the entire body and tilt at the center of the base shaft. However, we found that the 2-DOF scissor mechanism had a singularity; after analyzing the singularity, we propose two novel solutions to the problem.",
        "primary_area": "",
        "author": "Seiichi Teshigawara;H. Harry Asada;Seiichi Teshigawara;H. Harry Asada",
        "authorids": "/37089267372;/37085790203;/37089267372;/37085790203",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967768/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3155558195006244991&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968271",
        "title": "A Model for Simulating the Robotic Pushing of Dirt",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a model for simulating the pushing of dirt. This is a complex problem requiring the study of the action space for the robot, a deformable model for movable earth, the interaction between the robot's pushing surface and the environment, and techniques that will allow this model to simulate such a scenario. We present our novel framework for studying this problem including the grid-based model of the environment, a simplified earth pushing robot model, and action strategies to model the pushing of dirt from one area of the environment to another.",
        "primary_area": "",
        "author": "Samuel Rodriguez;Zixiu Su;Jiazhen Yu;Samuel Rodriguez;Zixiu Su;Jiazhen Yu",
        "authorids": "/37277219700;/37087324316;/37087324972;/37277219700;/37087324316;/37087324972",
        "aff": "Department of Computer Science, Texas Wesleyan University, Forth Worth, Texas, USA; Department of Computer Science, Texas Wesleyan University, Forth Worth, Texas, USA; Department of Computer Science, Texas Wesleyan University, Forth Worth, Texas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968271/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:25CYh8HPLDQJ:scholar.google.com/&scioq=A+Model+for+Simulating+the+Robotic+Pushing+of+Dirt&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas Wesleyan University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.texaswesleyan.edu",
        "aff_unique_abbr": "TWU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Forth Worth",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967650",
        "title": "A Model-Based Human Activity Recognition for Human\u2013Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Human activity recognition is a crucial ingredient in safe and efficient human-robot collaboration. In this paper, we present a new model-based human activity recognition system called logical activity recognition system (LCARS). LCARS requires much less training data compared to learning-based works. Compared to other model-based works, LCARS requires minimal domain-specific modeling effort from users. The minimal modeling is for two reasons: i) we provide a systematic and intuitive way to encode domain knowledge for LCARS and ii) LCARS automatically constructs a probabilistic estimation model from the domain knowledge. Requiring minimal training data and modeling effort allows LCARS to be easily applicable to various scenarios. We verify this through simulations and experiments.",
        "primary_area": "",
        "author": "Sang Uk Lee;Andreas Hofmann;Brian Williams;Sang Uk Lee;Andreas Hofmann;Brian Williams",
        "authorids": "/37085778048;/37284500000;/37274902300;/37085778048;/37284500000;/37274902300",
        "aff": "MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967650/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13430043674719254623&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967687",
        "title": "A Multi-Channel Embedded DSP Closed-Loop Control System for Musical Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The continuous automatic calibration of musical robots is an important step toward enabling them to create accurate, reliable, and expressive performances. Several attempts have been made to achieve this using external laptops, single-board computers and off-the-shelf hardware, but these solutions have various drawbacks that preclude their use in many musical robotics contexts. This paper presents a new, custom-built embedded DSP system that is capable of up to 32 channels of high quality audio input and output, created to carry out musical information retrieval tasks on the sonic output of musical robots in real time while they are performing. The results of these analyses are continuously fed to musical robot control hardware in order to inform their performance. The design and construction of the circuit board is described, the Musical Information Retrieval (MIR)-based algorithms carried out by the board are outlined, the system's performance in representative applications are evaluated, and its various implications to the field of musical robotics and beyond are discussed. By integrating this system into new musical robots, the result is instruments that are able to `listen' to the audible results of their own actuations in real time, and continuously calibrate their actions to best represent the intentions of the programmed musical composition or live input.",
        "primary_area": "",
        "author": "Jason Long;Jim Murphy;Dale A. Carnegie;Ajay Kapur;Jason Long;Jim Murphy;Dale A. Carnegie;Ajay Kapur",
        "authorids": "/37085391440;/37085377280;/37265929200;/37566146300;/37085391440;/37085377280;/37265929200;/37566146300",
        "aff": "New Zealand School of Music, Victoria University of Wellington, Wellington, New Zealand; New Zealand School of Music, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967687/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FF8ZRl1EcUYJ:scholar.google.com/&scioq=A+Multi-Channel+Embedded+DSP+Closed-Loop+Control+System+for+Musical+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Victoria University of Wellington",
        "aff_unique_dep": "New Zealand School of Music",
        "aff_unique_url": "https://www.victoria.ac.nz",
        "aff_unique_abbr": "VUW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Wellington",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "8967618",
        "title": "A Multi-DOF Human-Powered Robot Using Regenerative Clutches and Constant-Force Springs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the development of a two-degrees-of-freedom (DOF) human-powered robot using regenerative clutches and constant-force springs is described. A regenerative clutch can control a transmitted torque precisely and it includes a regenerative brake and a differential gear mechanism. The single-clutch human-powered joint-drive mechanism developed in this study is a system that can output forward and reverse torques and, to control the joint angle, performs servo control of the joint with one regenerative clutch by offsetting the torque using a constant-force spring. A crank-speed-sensitive spring-locking system has also been developed to implement a safe emergency stop function when the operator stops supplying power. The two-DOF human-powered robot using our systems realized planar trajectory tracking, suggesting that the position control of the end point of a multi-DOF human-powered robot is possible.",
        "primary_area": "",
        "author": "Yusuke Sugahara;Kohei Tsukamoto;Mitsuru Endo;Jun Okamoto;Daisuke Matsuura;Yukio Takeda;Yusuke Sugahara;Kohei Tsukamoto;Mitsuru Endo;Jun Okamoto;Daisuke Matsuura;Yukio Takeda",
        "authorids": "/37284032000;/37087324861;/37568389000;/37273301800;/37684232700;/37609656800;/37284032000;/37087324861;/37568389000;/37273301800;/37684232700;/37609656800",
        "aff": "School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Mechanical Engineering, Nihon University, Fukushima, Japan; Institute of Advanced Biomedical Engineering and Science, Tokyo Women\u2019s Medical University, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967618/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3558540427797648918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Nihon University;Tokyo Women\u2019s Medical University",
        "aff_unique_dep": "School of Engineering;Department of Mechanical Engineering;Institute of Advanced Biomedical Engineering and Science",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.nihon-u.ac.jp;https://www.twmu.ac.jp",
        "aff_unique_abbr": "Titech;Nihon U;TWMU",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Tokyo;Fukushima",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967977",
        "title": "A Multi-task Convolutional Neural Network for Autonomous Robotic Grasping in Object Stacking Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robotic grasping plays an important role in intelligent robotics. However, how to help the robot grasp specific objects in object stacking scenes is still an open problem, because there are two main challenges for autonomous robots: (1) it is a comprehensive task to know what and how to grasp; (2) it is hard to deal with the situations in which the target is hidden or covered by other objects. In this paper, we propose a multi-task convolutional neural network for autonomous robotic grasping, which can help the robot find the target, make the plan for grasping and finally grasp the target step by step in object stacking scenes. We integrate vision-based robotic grasping detection and visual manipulation relationship reasoning in one single deep network and build the autonomous robotic grasping system. Experimental results demonstrate that with our model, Baxter robot can autonomously grasp the target with a success rate of 90.6%, 71.9% and 59.4% in object cluttered scenes, familiar stacking scenes and complex stacking scenes respectively.",
        "primary_area": "",
        "author": "Hanbo Zhang;Xuguang Lan;Site Bai;Lipeng Wan;Chenjie Yang;Nanning Zheng;Hanbo Zhang;Xuguang Lan;Site Bai;Lipeng Wan;Chenjie Yang;Nanning Zheng",
        "authorids": "/37086441588;/37270865300;/37087324621;/37087323777;/37086800069;/37271536700;/37086441588;/37270865300;/37087324621;/37087323777;/37086800069;/37271536700",
        "aff": "National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi\u2019an, Shaanxi, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967977/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8404277552444914659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "National Engineering Laboratory for Visual Information Processing and Applications",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967868",
        "title": "A Multiclass EEG Signal Classification Model using Spatial Feature Extraction and XGBoost Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Brain-computer interface is a framework which provides a communicating pathway between the human brain and neuroprosthetic devices. In this work, we have performed signal smoothing to fix unregulated electroencephalogram (EEG) fluctuations and to effectively collect hidden patterns in corresponding EEG spectra. To do it, we have applied a Savitzky Golay function because of its ability to preserve spectral properties without distorting it much. For feature selection, we have applied the Filter Bank Common Spatial Pattern (FBCSP) algorithm with the Principle Component Analysis (PCA). FBCSP creates 11352 features from EEG signals and PCA gradually reduces the features to 185 most significant features. These features are utilized in the classification process by the eXtreme Gradient Boosting (XGBoost) algorithm with suitable node split criteria to manage optimal tree height. A five-fold cross-validation approach concludes the superior performance of XGBoost in terms of minimizing execution time (3.7 times faster in the training phase) and providing improved accuracy as compared to existing results. Our approach enhances classification accuracy (88.80%) by approximately 10% over regularized common spatial patterns (78.01% accuracy), 15% over shift variance approximation (73.84% accuracy) and 15% over Riemannian approach (74.77% accuracy). It also concludes that the pre-consideration of the noise level in EEG spectra provides a better approximation.",
        "primary_area": "",
        "author": "Anurag Tiwari;Amrita Chaturvedi;Anurag Tiwari;Amrita Chaturvedi",
        "authorids": "/37085995329;/37085996228;/37085995329;/37085996228",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, India; Department of Computer Science and Engineering, Indian Institute of Technology (BHU), Varanasi, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967868/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16095389164786180804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology (BHU)",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitbhu.ac.in",
        "aff_unique_abbr": "IIT (BHU)",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Varanasi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968505",
        "title": "A Multimodal Human-Robot Interaction Manager for Assistive Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "With rapid advances in social robotics, humanoids and autonomy, robot assistants appear to be within reach. However, robots are still unable to effectively interact with humans in activities of daily living. One of the challenges is in the frequent use of multiple communication modalities when humans engage in collaborative activities. In this paper, we propose a Multimodal Interaction Manager, a framework for an assistive robot that maintains an active multimodal interaction with a human partner while performing physical collaborative tasks. The heart of our framework is a Hierarchical Bipartite Action-Transition Network (HBATN), which allows the robot to infer the state of the task and the dialogue given spoken utterances and observed pointing gestures from a human partner, and to plan its next actions. Finally, we implemented this framework on a robot to provide preliminary evidence that the robot can successfully participate in a task-oriented multimodal interaction.",
        "primary_area": "",
        "author": "Bahareh Abbasi;Natawut Monaikul;Zhanibek Rysbek;Barbara Di Eugenio;Milo\u0161 \u017defran;Bahareh Abbasi;Natawut Monaikul;Zhanibek Rysbek;Barbara Di Eugenio;Milo\u0161 \u017defran",
        "authorids": "/38246213800;/37085625434;/37087322697;/37643389700;/37323968200;/38246213800;/37085625434;/37087322697;/37643389700;/37323968200",
        "aff": "The Robotics Lab, Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; The Natural Language Processing Lab, Computer Science Department, University of Illinois at Chicago, Chicago, IL, USA; The Robotics Lab, Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; The Natural Language Processing Lab, Computer Science Department, University of Illinois at Chicago, Chicago, IL, USA; The Robotics Lab, Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968505/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3957034824070035845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Illinois at Chicago",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.uic.edu",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968297",
        "title": "A Multimodal Soft Crawling-Climbing Robot with the Controllable Horizontal Plane to Slope Transition",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the existing soft locomotive robots are capable of moving on horizontal planes and small-angled slopes, but few of them can accomplish the large-angled slope climbing or wall climbing. We introduce an inchworm inspired soft crawling-climbing robot capable of continuous motion from a horizontal plane to a slope of up to 75 degrees and it can perform multiple locomotion including crawling, climbing, and the transition between them. This soft crawling-climbing robot is powered by three pneumatic actuators connected in series that deforms with two degrees of freedom, negative pressure sucker feet that generate periodical adhesion, and a semi-automatic controlling system synchronizing the body shape and anchoring of the feet. The robot mimics the body deformation and feet anchoring pattern exhibited by inchworms and can be applied in inspection, surveillance, and rescuing.",
        "primary_area": "",
        "author": "Yifan Zhang;Lisen Ge;Jiang Zou;Haipeng Xu;Guoying Gu;Yifan Zhang;Lisen Ge;Jiang Zou;Haipeng Xu;Guoying Gu",
        "authorids": "/37087323389;/37086842577;/37086033647;/37087325156;/37404380300;/37087323389;/37086842577;/37086033647;/37087325156;/37404380300",
        "aff": "Soft Robotics and Bio-design Lab, School of Mechanical Engineering, Robotics Institute; Soft Robotics and Bio-design Lab, School of Mechanical Engineering, Robotics Institute; Soft Robotics and Bio-design Lab, School of Mechanical Engineering, Robotics Institute; Soft Robotics and Bio-design Lab, School of Mechanical Engineering, Robotics Institute; Soft Robotics and Bio-design Lab, School of Mechanical Engineering, Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968297/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17737143349511054577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Robotics Institute",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ri.cmu.edu",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968228",
        "title": "A New Time-Varying Feedback RISE Control of PKMs: Theory and Application",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel time-varying feedback control strategy based on the Robust Integral of the Sign of the Error (RISE). The main motivation is to enhance the tracking performance of RISE controller at high dynamic operating conditions. RISE control law ensures a semi-global asymptotic tracking without introducing severe restrictions on the uncertain and nonlinearly parametrized systems. More nonlinearities are added to the original RISE control law by replacing the static feedback gains with nonlinear ones which depend on the system state variables. The proposed contribution is implemented in real-time experiments on a non-redundant three-degrees-of-freedom parallel manipulator named Delta. Comparing to the standard RISE controller, experimental results show better tracking performances of the proposed time-varying feedback RISE controller.",
        "primary_area": "",
        "author": "Hussein Saied;Ahmed Chemori;Mohamed Bouri;Maher El Rafei;Clovis Francis;Francois Pierrot;Hussein Saied;Ahmed Chemori;Mohamed Bouri;Maher El Rafei;Clovis Francis;Francois Pierrot",
        "authorids": "/37086575618;/37273794600;/37294221500;/37086059043;/37282524600;/37277264300;/37086575618;/37273794600;/37294221500;/37086059043;/37282524600;/37277264300",
        "aff": "LIRMM, University of Montpellier, CNRS, Montpellier, France; LIRMM, University of Montpellier, CNRS, Montpellier, France; EPFL Station 9 Lausanne CH-1015, Switzerland; CRSI, Lebanese University, Beirut, Lebanon; CRSI, Lebanese University, Beirut, Lebanon; LIRMM, University of Montpellier, CNRS, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968228/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1653424254826388314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;2;0",
        "aff_unique_norm": "University of Montpellier;EPFL;Lebanese University",
        "aff_unique_dep": "LIRMM;;CRSI",
        "aff_unique_url": "https://www.univ-montp2.fr;https://www.epfl.ch;",
        "aff_unique_abbr": "UM;EPFL;",
        "aff_campus_unique_index": "0;0;1;2;2;0",
        "aff_campus_unique": "Montpellier;Lausanne;Beirut",
        "aff_country_unique_index": "0;0;1;2;2;0",
        "aff_country_unique": "France;Switzerland;Lebanon"
    },
    {
        "id": "8967851",
        "title": "A Novel 4-DoF Robotic Link Mechanism with E-CoSMo: Kinematics Based Torque Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a novel four degrees of freedom (DoF) robotic link mechanism and its torque analysis based on extended coaxial spherical joint module (E-CoSMo) are introduced. The E-CoSMo is a previously developed 4-DoF point-centered rotational parallel mechanism with coaxial actuators. The use of the E-CoSMo on robotic system is expected to improve dynamic performance since all actuators are mounted on fixed base. Furthermore, output torque is amplified in a specific axial direction, due to a coaxial parallel mechanism. Torque analysis of the mechanism is derived based on kinematics of a virtual 4-DoF serial linkages and the E-CoSMo. A virtual force-based position control simulation is performed for verifying the torque analysis. Due to the valid torque analysis, the norm of position error is less than 0. 7 mm. It is confirmed that the output torque is amplified compare to actuator torques, which is a special feature of the E-CoSMo. Control experiments using prototype are also carried out to validate the feasibility.",
        "primary_area": "",
        "author": "Jaeyong Lee;Jaeho Noh;Sungon Lee;Woosung Yang;Jaeyong Lee;Jaeho Noh;Sungon Lee;Woosung Yang",
        "authorids": "/37086580696;/37086070089;/37085819269;/37556518300;/37086580696;/37086070089;/37085819269;/37556518300",
        "aff": "School of Robotics, Kwangwoon University, Seoul, Republic of Korea; School of Robotics, Kwangwoon University, Seoul, Republic of Korea; School of Robotics, Kwangwoon University, Seoul, Republic of Korea; School of Electrical Engineering, Hanyang University, Ansan, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967851/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14660901026339373861&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Kwangwoon University;Hanyang University",
        "aff_unique_dep": "School of Robotics;School of Electrical Engineering",
        "aff_unique_url": "http://www.kw.ac.kr;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "KWU;HYU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Seoul;Ansan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967653",
        "title": "A Novel Approach for Outlier Detection and Robust Sensory Data Model Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In the past few decades machine learning and data analysis have been having a huge growth and they have been applied in many different problems in the field of robotics. Data are usually the result of sensor measurements and, as such, they might be subjected to noise and outliers. The presence of outliers has a huge impact on modelling the acquired data, resulting in inappropriate models. In this work a novel approach for outlier detection and rejection for input/output mapping in regression problems is presented. The robustness of the method is shown both through simulated data for linear and nonlinear regression, and real sensory data. Despite being validated by using artificial neural networks, the method can be generalized to any other regression method.",
        "primary_area": "",
        "author": "Francesco Cursi;Guang-Zhong Yang;Francesco Cursi;Guang-Zhong Yang",
        "authorids": "/37086145777;/37276270800;/37086145777;/37276270800",
        "aff": "Hamlyn Center, Imperial College London, London, UK; Hamlyn Center, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967653/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11295097227254742292&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Hamlyn Center",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968175",
        "title": "A Novel Capabilities of Quadruped Robot Moving through Vertical Ladder without Handrail Support",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the novel capabilities of a quadruped robot by performing horizontal-vertical-horizontal movement transition through vertical ladder without handrailing supporter. To overcome the proposed problem, we propose a multi-behavior generation model using independent stepping and pose control in the quadruped robot. The model is able to generate appropriate behavior depending on external (3D point clouds) and internal sensors (ground touch sensor, and Inertial Measurement Unit). Posture condition, safe movement area, possible touchpoint, grasping possibility, and target movement are the information that is analyzed from the sensors. There are four options developed in behavior generation, which are, Approaching, Body Placing, Stepping, and Grasping behavior. In order to prove the effectiveness of the proposed algorithm, the model was implemented on the computer simulation and the real application. Before being applied in the real robot, the proposed model is optimized in the computer simulation. Then, the optimized parameter is used for applying in the real robot. As a result, the robot succeeded to move through the ladder without handrail from lower stair to upper stair. From the analysis, the body placing behavior is the most important strategy in the proposed case.",
        "primary_area": "",
        "author": "Azhar Aulia Saputra;Yuichiro Toda;Naoyuki Takesue;Naoyuki Kubota;Azhar Aulia Saputra;Yuichiro Toda;Naoyuki Takesue;Naoyuki Kubota",
        "authorids": "/37085403752;/37720856200;/37295990600;/37275324300;/37085403752;/37720856200;/37295990600;/37275324300",
        "aff": "Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan; Graduate School of Natural Science, Okayama University, Okayama, Japan; Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan; Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968175/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9009094413946111903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tokyo Metropolitan University;Okayama University",
        "aff_unique_dep": "Graduate School of System Design;Graduate School of Natural Science",
        "aff_unique_url": "https://www.tmuc.ac.jp;https://www.okayama-u.ac.jp",
        "aff_unique_abbr": "TMU;Okayama U",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Hino;Okayama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968447",
        "title": "A Novel Robust Approach for Correspondence-Free Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Extrinsic calibration is a necessary step when using heterogeneous sensors for robotics applications. Most existing methods work under the assumption that the prior data correspondence is known. Considering data loss and false measurements, the correspondence may not be accessible in practice. To solve this problem without knowing the correspondence, several probabilistic methods have been proposed. However, an implicit restriction on input data limits their application. Therefore, in this paper, we propose a more stable correspondence-free method with two improvements that can relax the restrictions on inputs and improve the calibration accuracy. The first improvement finds consistent sets from raw inputs using screw invariants, which significantly improve the robustness in case of outliers and data loss. A new optimization method on matrix Lie group is proposed as the second improvement, which demonstrates better accuracy. The experimental results on both numerical and real data show the superiority and robustness of the proposed method.",
        "primary_area": "",
        "author": "Xiao Hu;Daniel Olesen;Knudsen Per;Xiao Hu;Daniel Olesen;Knudsen Per",
        "authorids": "/37086515998;/37073196900;/37086513887;/37086515998;/37073196900;/37086513887",
        "aff": "National Space Institute, Technical University of Denmark, Elektrovej, Lyngby, Denmark; National Space Institute, Technical University of Denmark, Elektrovej, Lyngby, Denmark; National Space Institute, Technical University of Denmark, Elektrovej, Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968447/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4312918235217918717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "National Space Institute",
        "aff_unique_url": "https://www.space.dtu.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lyngby",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8967751",
        "title": "A Novel Semi-Autonomous Control Framework for Retina Confocal Endomicroscopy Scanning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel semi-autonomous control framework is presented for enabling probe-based confocal laser endomicroscopy (pCLE) scan of the retinal tissue. With pCLE, retinal layers such as nerve fiber layer (NFL) and retinal ganglion cell (RGC) can be scanned and characterized in real-time for an improved diagnosis and surgical outcome prediction. However, the limited field of view of the pCLE system and the micron-scale optimal focus distance of the probe, which are in the order of physiological hand tremor, act as barriers to successful manual scan of retinal tissue.Therefore, a novel sensorless framework is proposed for real-time semi-autonomous endomicroscopy scanning during retinal surgery. The framework consists of the Steady-Hand Eye Robot (SHER) integrated with a pCLE system, where the motion of the probe is controlled semi-autonomously. Through a hybrid motion control strategy, the system autonomously controls the confocal probe to optimize the sharpness and quality of the pCLE images, while providing the surgeon with the ability to scan the tissue in a tremor-free manner. Effectiveness of the proposed architecture is validated through experimental evaluations as well as a user study involving 9 participants. It is shown through statistical analyses that the proposed framework can reduce the work load experienced by the users in a statistically-significant manner, while also enhancing their performance in retaining pCLE images with optimized quality.",
        "primary_area": "",
        "author": "Zhaoshuo Li;Mahya Shahbazi;Niravkumar Patel;Eimear O\u2019 Sullivan;Haojie Zhang;Khushi Vyas;Preetham Chalasani;Peter L. Gehlbach;Iulian Iordachita;Guang-Zhong Yang;Russell H. Taylor;Zhaoshuo Li;Mahya Shahbazi;Niravkumar Patel;Eimear O\u2019 Sullivan;Haojie Zhang;Khushi Vyas;Preetham Chalasani;Peter L. Gehlbach;Iulian Iordachita;Guang-Zhong Yang;Russell H. Taylor",
        "authorids": "/37087325398;/37854437900;/37086366528;/37088737971;/37087322440;/37086696019;/37085511221;/37547001700;/37330620500;/37276270800;/37277162900;/37087325398;/37854437900;/37086366528;/37088737971;/37087322440;/37086696019;/37085511221;/37547001700;/37330620500;/37276270800;/37277162900",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA; Johns Hopkins Hospital, Johns Hopkins Wilmer Eye Institute, 600 N. Wolfe Street, Maryland, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Maryland, Baltimore, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967751/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4843506841321157875&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;1;1;1;0;2;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Imperial College London;Johns Hopkins Hospital",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Hamlyn Centre for Robotic Surgery;Johns Hopkins Wilmer Eye Institute",
        "aff_unique_url": "https://www.jhu.edu;https://www.imperial.ac.uk;https://www.hopkinsmedicine.org/hospital/",
        "aff_unique_abbr": "JHU;ICL;JHH",
        "aff_campus_unique_index": "0;0;0;1;1;1;0;0;1;0",
        "aff_campus_unique": "Baltimore;London;",
        "aff_country_unique_index": "0;0;0;1;1;1;0;0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "8968304",
        "title": "A Novel Small-scale Turtle-inspired Amphibious Spherical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a novel small-scale turtle-inspired Amphibious Spherical Robot (ASRobot) to accomplish exploration tasks in the restricted environment, such as amphibious areas and narrow underwater cave. A Legged, Multi-Vectored Water-Jet Composite Propulsion Mechanism (LMVWCPM) is designed with four legs, one of which contains three connecting rod parts, one water-jet thruster and three joints driven by digital servos. Using this mechanism, the robot is able to walk like amphibious turtles on various terrains and swim flexibly in submarine environment. A simplified kinematic model is established to analyze crawling gaits. With simulation of the crawling gait, the driving torques of different joints contributed to the choice of servos and the size of links of legs. Then we also modeled the robot in water and proposed several underwater locomotion. In order to assess the performance of the proposed robot, a series of experiments were carried out in the lab pool and on flat ground using the prototype robot. Experiments results verified the effectiveness of LMVWCPM and the amphibious control approaches.",
        "primary_area": "",
        "author": "Huiming Xing;Shuxiang Guo;Liwei Shi;Xihuan Hou;Yu Liu;Huikang Liu;Yao Hu;Debin Xia;Zan Li;Huiming Xing;Shuxiang Guo;Liwei Shi;Xihuan Hou;Yu Liu;Huikang Liu;Yao Hu;Debin Xia;Zan Li",
        "authorids": "/37086023387;/37274155200;/37531265800;/37086474971;/37086476832;/37086474993;/37086957966;/37086955396;/37086958443;/37086023387;/37274155200;/37531265800;/37086474971;/37086476832;/37086474993;/37086957966;/37086955396;/37086958443",
        "aff": "Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968304/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11668462998993140018&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "Key Laboratory of Convergence Medical Engineering System and Healthcare Technology",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967971",
        "title": "A Parallel Gripper with a Universal Fingertip Device Using Optical Sensing and Jamming Transition for Maintaining Stable Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "For a robotic gripper to perform as well as the human hand, the performance of the tactile sensing and grasping of the gripper must be improved. In this study, a parallel gripper with a universal fingertip device that combines both object holding using jamming transition and optical sensing is proposed. By using a transparent material along with the jamming transition, both a tactile sense is achieved via optical sensing and the holding stability is improved by tightly restraining the object. Because the hardness of the contact region of the membrane can be adjusted, the gripper can grasp heavy objects as well as light objects. In this paper, the structure of the developed gripper and its grasping characteristics are described, and the experimental results from grasping and sensing are presented. It is experimentally shown that the proposed gripper is capable of both grasping fragile objects (such as an egg and tofu) by using tactile sensing and grasping dumbbells (with weights between 1-3 kg) by using jamming transition. Additionally, grasping a plastic cup, the proposed gripper demonstrated the potential of combining tactile sensing and more-constrained grasping.",
        "primary_area": "",
        "author": "Tatsuya Sakuma;Elaine Phillips;Gustavo Alfonso Garcia Ricardez;Ming Ding;Jun Takamatsu;Tsukasa Ogasawara;Tatsuya Sakuma;Elaine Phillips;Gustavo Alfonso Garcia Ricardez;Ming Ding;Jun Takamatsu;Tsukasa Ogasawara",
        "authorids": "/37086581398;/37087324160;/37061031300;/37690261000;/37324010500;/37269488400;/37086581398;/37087324160;/37061031300;/37690261000;/37324010500;/37269488400",
        "aff": "Graduate School of Information Science, Nara Institute of Science and Technology; Mechanical Engineering Department, Massachusetts Institute of Technology; Graduate School of Information Science, Nara Institute of Science and Technology; Graduate School of Information Science, Nara Institute of Science and Technology; Graduate School of Information Science, Nara Institute of Science and Technology; Graduate School of Information Science, Nara Institute of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967971/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7586900869101896661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology;Massachusetts Institute of Technology",
        "aff_unique_dep": "Graduate School of Information Science;Mechanical Engineering Department",
        "aff_unique_url": "https://www.nist.go.jp;https://web.mit.edu",
        "aff_unique_abbr": "NIST;MIT",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Nara;Cambridge",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "8968076",
        "title": "A Passive Closing, Tendon Driven, Adaptive Robot Hand for Ultra-Fast, Aerial Grasping and Perching",
        "track": "main",
        "status": "Poster",
        "abstract": "Current grasping methods for aerial vehicles are slow, inaccurate and they cannot adapt to any target object. Thus, they do not allow for on-the-fly, ultra-fast grasping. In this paper, we present a passive closing, adaptive robot hand design that offers ultra-fast, aerial grasping for a wide range of everyday objects. We investigate alternative uses of structural compliance for the development of simple, adaptive robot grippers and hands and we propose an appropriate quick release mechanism that facilitates an instantaneous grasping execution. The quick release mechanism is triggered by a simple distance sensor. The proposed hand utilizes only two actuators to control multiple degrees of freedom over three fingers and it retains the superior grasping capabilities of adaptive grasping mechanisms, even under significant object pose or other environmental uncertainties. The hand achieves a grasping time of 96 ms, a maximum grasping force of 56 N and it is able to secure objects of various shapes at high speeds. The proposed hand can serve as the end-effector of grasping capable Unmanned Aerial Vehicle (UAV) platforms and it can offer perching capabilities, facilitating autonomous docking.",
        "primary_area": "",
        "author": "Andrew McLaren;Zak Fitzgerald;Geng Gao;Minas Liarokapis;Andrew McLaren;Zak Fitzgerald;Geng Gao;Minas Liarokapis",
        "authorids": "/37087321900;/37087324773;/37087027460;/38558084100;/37087321900;/37087324773;/37087027460;/38558084100",
        "aff": "New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968076/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6909348009174263318&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "New Dexterity research group",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "8967563",
        "title": "A Penetration Metric for Deforming Tetrahedra using Object Norm",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel penetration metric, called deformable penetration depth PDd, to define a measure of inter-penetration between two linearly deforming tetrahedra using the object norm [1]. First of all, we show that a distance metric for a tetrahedron deforming between two configurations can be found in closed form based on object norm. Then, we show that the PDd between an intersecting pair of static and deforming tetrahedra can be found by solving a quadratic programming (QP) problem in terms of the distance metric with non-penetration constraints. We also show that the PDd between two, intersected, deforming tetrahedra can be found by solving a similar QP problem under some assumption on penetrating directions, and it can be also accelerated by an order of magnitude using pre-calculated penetration direction. We have implemented our algorithm on a standard PC platform using an off-the-shelf QP optimizer, and experimentally show that both the static/deformable and deformable/deformable tetrahedra cases can be solvable in from a few to tens of milliseconds. Finally, we demonstrate that our penetration metric is three-times smaller (or tighter) than the classical, rigid penetration depth metric in our experiments.",
        "primary_area": "",
        "author": "Jisu Kim;Young J. Kim;Jisu Kim;Young J. Kim",
        "authorids": "/37068760500;/38185529300;/37068760500;/38185529300",
        "aff": "Department of Computer Science and Engineering, Ewha Womans University, Korea; Department of Computer Science and Engineering, Ewha Womans University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967563/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4zH5-jSbcLEJ:scholar.google.com/&scioq=A+Penetration+Metric+for+Deforming+Tetrahedra+using+Object+Norm&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ewha Womans University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "http://www.ewha.ac.kr",
        "aff_unique_abbr": "Ewha",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968051",
        "title": "A Probabilistic Approach to Human-Robot Communication",
        "track": "main",
        "status": "Poster",
        "abstract": "Since robots are increasingly expected to work in concert with humans in dynamic, unstructured environments, they will need to express information about their state and actions. We propose a formalism for planning robot communication that employs a probabilistic representation of the robots world. This representation takes on the form of a Markov Decision Process (MDP) and captures the uncertainty of interacting with humans. The key insight of this work is that humans preferences and time need to be carefully balanced against the robots in order to minimize human annoyance. The communication-MDP enables the robot to reason about the effects of its actions on a human interactor. We validated the model through a human subjects experiment (n=44) by learning communication policies for a loosely collaborative task. The results show that the communication-MDP improves participants' perceptions of the robot's thoughtfulness as an interactor.",
        "primary_area": "",
        "author": "Elizabeth Cha;Emily Meschke;Terrence Fong;Maja J Matari\u0107;Elizabeth Cha;Emily Meschke;Terrence Fong;Maja J Matari\u0107",
        "authorids": "/38570332000;/37087323157;/37338020300;/38300930600;/38570332000;/37087323157;/37338020300;/38300930600",
        "aff": "Interaction Lab, University of Southern California, Los Angeles, CA, USA; Interaction Lab, University of Southern California, Los Angeles, CA, USA; Intelligent Robotics Group, NASA Ames Research Center, Mountain View, CA, USA; Interaction Lab, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968051/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11086200754162836638&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Southern California;NASA Ames Research Center",
        "aff_unique_dep": "Interaction Lab;Intelligent Robotics Group",
        "aff_unique_url": "https://www.usc.edu;https://ames.nasa.gov",
        "aff_unique_abbr": "USC;NASA Ames",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Los Angeles;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968283",
        "title": "A RUGD Dataset for Autonomous Navigation and Visual Perception in Unstructured Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in autonomous driving has benefited from a number of visual datasets collected from mobile platforms, leading to improved visual perception, greater scene understanding, and ultimately higher intelligence. However, this set of existing data collectively represents only highly structured, urban environments. Operation in unstructured environments, e.g., humanitarian assistance and disaster relief or off-road navigation, bears little resemblance to these existing data. To address this gap, we introduce the Robot Unstructured Ground Driving (RUGD) dataset with video sequences captured from a small, unmanned mobile robot traversing in unstructured environments. Most notably, this data differs from existing autonomous driving benchmark data in that it contains significantly more terrain types, irregular class boundaries, minimal structured markings, and presents challenging visual properties often experienced in off road navigation, e.g., blurred frames. Over 7, 000 frames of pixel-wise annotation are included with this dataset, and we perform an initial benchmark using state-of-the-art semantic segmentation architectures to demonstrate the unique challenges this data introduces as it relates to navigation tasks.",
        "primary_area": "",
        "author": "Maggie Wigness;Sungmin Eum;John G. Rogers;David Han;Heesung Kwon;Maggie Wigness;Sungmin Eum;John G. Rogers;David Han;Heesung Kwon",
        "authorids": "/37085661502;/37086341551;/37533731800;/37588964400;/37346486000;/37085661502;/37086341551;/37533731800;/37588964400;/37346486000",
        "aff": "CCDC Army Research Laboratory (ARL), Adelphi, MD, USA; CCDC Army Research Laboratory (ARL), Adelphi, MD, USA; CCDC Army Research Laboratory (ARL), Adelphi, MD, USA; CCDC Army Research Laboratory (ARL), Adelphi, MD, USA; CCDC Army Research Laboratory (ARL), Adelphi, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968283/",
        "gs_citation": 208,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5757445607403905754&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "CCDC Army Research Laboratory",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.arl.army.mil",
        "aff_unique_abbr": "ARL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Adelphi",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968568",
        "title": "A Real-Time Dynamic Simulator and an Associated Front-End Representation Format for Simulating Complex Robots and Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot Dynamic Simulators offer convenient implementation and testing of physical robots, thus accelerating research and development. While existing simulators support most real-world robots with serially linked kinematic and dynamic chains, they offer limited or conditional support for complex closed-loop robots. On the other hand, many of the underlying physics computation libraries that these simulators employ support closed-loop kinematic chains and redundant mechanisms. Such mechanisms are often utilized in surgical robots to achieve constrained motions (e.g., the remote center of motion (RCM)). To deal with such robots, we propose a new simulation framework based on a front-end description format and a robust real-time dynamic simulator. Although this study focuses on surgical robots, the proposed format and simulator are applicable to any type of robot. In this manuscript, we describe the philosophy and implementation of the front-end description format and demonstrate its performance and the simulator\u2019s capabilities using simulated models of real-world surgical robots.",
        "primary_area": "",
        "author": "Adnan Munawar;Yan Wang;Radian Gondokaryono;Gregory S. Fischer;Adnan Munawar;Yan Wang;Radian Gondokaryono;Gregory S. Fischer",
        "authorids": "/37086207599;/37086932714;/37086268694;/37398771000;/37086207599;/37086932714;/37086268694;/37398771000",
        "aff": "Robotic Engineering Department, Worcester Polytechnic Institute, WPI, 100 Institute Road, MA, USA; Robotic Engineering Department, Worcester Polytechnic Institute, WPI, 100 Institute Road, MA, USA; Robotic Engineering Department, Worcester Polytechnic Institute, WPI, 100 Institute Road, MA, USA; Robotic Engineering Department, Worcester Polytechnic Institute, WPI, 100 Institute Road, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968568/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2568765059664408899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotic Engineering Department",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "WPI",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967801",
        "title": "A Ring Network Protocol for Articulated Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Articulated robots such as the humanoid robot often have multiple joints implemented in its limbs. It is common for sensor and controller cables to be routed inside of the limb, impacting mobility. A network protocol with high efficiency, low latency, fault tolerance is needed to facilitate communication of sensor and controller data over a more compact communications channel. In this paper, we propose a ring network protocol with fault tolerance in low latency, high efficiency communication over a compact channel. The performance of the proposed network protocol was verified in simulation and experiment, showing that low latency, high efficiency, and fault tolerance can be achieved over a single communications channel.",
        "primary_area": "",
        "author": "Ryusuke Ishizaki;Takeshi Misumi;Takahide Yoshiike;Ryusuke Ishizaki;Takeshi Misumi;Takahide Yoshiike",
        "authorids": "/37087324975;/37087325154;/37682554700;/37087324975;/37087325154;/37682554700",
        "aff": "FORESTHILLS EASTWING 1F, 4-18-11, Minami-aoyama, Minato-ku, Honda Research Institute Japan Co., Ltd, Tokyo, Japan; Honda R&D Co., Ltd 8-1 Honcho, Wako, Saitama, Japan; FORESTHILLS EASTWING 1F, 4-18-11, Minami-aoyama, Minato-ku, Honda Research Institute Japan Co., Ltd, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967801/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3809312373209524086&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Honda Research Institute Japan Co., Ltd;Honda R&D Co., Ltd",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.honda-ri.jp/english/;https://www.honda.com",
        "aff_unique_abbr": "HRI-JP;Honda R&D",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968588",
        "title": "A Robotic Surgery Approach to Mitochondrial Transfer Amongst Single Cells",
        "track": "main",
        "status": "Poster",
        "abstract": "Introducing alterations in the mtDNA sequence is challenging but needed for potential therapies and basic studies. Direct microinjection of mitochondria into small cells has been considered inefficient and impractical. To address this issue, we present a highly efficient and precise robotic approach for automatically transferring mitochondria from one single cell to another. A microfluidic cell positioning device is used to pattern two different types of cells in one dimensional array, and an image processing algorithm is applied to identify the location of the mitochondria and cell. A visual feedback control mechanism is developed to enhance the mitochondrial extraction efficiency. A robust adaptive sliding control algorithm is developed to precisely control an X-Y stage to accomplish the extraction of mitochondria from A type cell followed by injection of the mitochondria into B type cell automatically. The system can transfer mitochondria from one cell to another with an average duration of 15 s/mitochondria. Experiments of mitochondrial transfer from THPI and NB4 cells to THPI cells and fibroblasts are conducted to show the effectiveness of the developed approach.",
        "primary_area": "",
        "author": "Adnan Shakoor;Mingyang Xie;Fei Pan;Wendi Gao;Jiayu Sun;Dong Sun;Adnan Shakoor;Mingyang Xie;Fei Pan;Wendi Gao;Jiayu Sun;Dong Sun",
        "authorids": "/37085432267;/37085433577;/37087323901;/37086014744;/37087321981;/37277362800;/37085432267;/37085433577;/37087323901;/37086014744;/37087321981;/37277362800",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; College of Automation Engineering, Nanjing University of Aeronautics & Astronautics, Nanjing, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, Kowloon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968588/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11529848418417218647&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "City University of Hong Kong;Nanjing University of Aeronautics & Astronautics",
        "aff_unique_dep": "Department of Biomedical Engineering;College of Automation Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk;http://www.nuaa.edu.cn",
        "aff_unique_abbr": "CityU;NUAA",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;Nanjing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967778",
        "title": "A Robust Biped Locomotion Based on Linear-Quadratic-Gaussian Controller and Divergent Component of Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating robust locomotion for a humanoid robot in the presence of disturbances is difficult because of its high number of degrees of freedom and its unstable nature. In this paper, we used the concept of Divergent Component of Motion (DCM) and propose an optimal closed-loop controller based on Linear-Quadratic-Gaussian to generate a robust and stable walking for humanoid robots. The biped robot dynamics has been approximated using the Linear Inverted Pendulum Model (LIPM). Moreover, we propose a controller to adjust the landing location of the swing leg to increase the withstanding level of the robot against a severe external push. The performance and also the robustness of the proposed controller is analyzed and verified by performing a set of simulations using MATLAB. The simulation results showed that the proposed controller is capable of providing a robust walking even in the presence of disturbances and in challenging situations.",
        "primary_area": "",
        "author": "Mohammadreza Kasaei;Nuno Lau;Artur Pereira;Mohammadreza Kasaei;Nuno Lau;Artur Pereira",
        "authorids": "/37086391027;/37296118200;/37085580615;/37086391027;/37296118200;/37085580615",
        "aff": "IEETA/DETI University of Aveiro, Aveiro, Portugal; IEETA/DETI University of Aveiro, Aveiro, Portugal; IEETA/DETI University of Aveiro, Aveiro, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967778/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14490433139860631973&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Aveiro",
        "aff_unique_dep": "IEETA/DETI",
        "aff_unique_url": "https://www.ua.pt",
        "aff_unique_abbr": "UA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aveiro",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "8968244",
        "title": "A Robust Extrinsic Calibration Framework for Vehicles with Unscaled Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate extrinsic sensor calibration is essential for both autonomous vehicles and robots. Traditionally this is an involved process requiring calibration targets, known fiducial markers and is generally performed in a lab. Moreover, even a small change in the sensor layout requires recalibration. With the anticipated arrival of consumer autonomous vehicles, there is demand for a system which can do this automatically, after deployment and without specialist human expertise. To solve these limitations, we propose a flexible framework which can estimate extrinsic parameters without an explicit calibration stage, even for sensors with unknown scale. Our first contribution builds upon standard hand-eye calibration by jointly recovering scale. Our second contribution is that our system is made robust to imperfect and degenerate sensor data, by collecting independent sets of poses and automatically selecting those which are most ideal. We show that our approach's robustness is essential for the target scenario. Unlike previous approaches, ours runs in real time and constantly estimates the extrinsic transform. For both an ideal experimental setup and a real use case, comparison against these approaches shows that we outperform the state-of-the-art. Furthermore, we demonstrate that the recovered scale may be applied to the full trajectory, circumventing the need for scale estimation via sensor fusion.",
        "primary_area": "",
        "author": "Celyn Walters;Oscar Mendez;Simon Hadfield;Richard Bowden;Celyn Walters;Oscar Mendez;Simon Hadfield;Richard Bowden",
        "authorids": "/37087323095;/37710939600;/38232557500;/37268872100;/37087323095;/37710939600;/38232557500;/37268872100",
        "aff": "CVSSP, University of Surrey, UK; CVSSP, University of Surrey, UK; CVSSP, University of Surrey, UK; CVSSP, University of Surrey, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968244/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12610835776169049293&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Vision, Speech and Signal Processing",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967880",
        "title": "A Robust Laser-Inertial Odometry and Mapping Method for Large-Scale Highway Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel laser-inertial odometry and mapping method to achieve real-time, low-drift and robust pose estimation in large-scale highway environments. The proposed method is mainly composed of four sequential modules, namely scan pre-processing module, dynamic object detection module, laser-inertial odometry module and laser mapping module. Scan pre-processing module uses inertial measurements to compensate the motion distortion of each laser scan. Then, the dynamic object detection module is used to detect and remove dynamic objects from each laser scan by applying CNN segmentation network. After obtaining the undistorted point cloud without moving objects, the laser-inertial odometry module uses an Error State Kalman Filter to fuse the data of laser and IMU and output the coarse pose estimation at high frequency. Finally, the laser mapping module performs a fine processing step and the \u201cFrame-to-Model'' scan matching strategy is used to create a static global map. We compare the performance of our method with two state-of-the-art methods, LOAM and SuMa, using KITTI dataset and real highway scene dataset. Experiment results show that our method performs better than the state-of-the-art methods in real highway environments and achieves competitive accuracy on the KITTI dataset.",
        "primary_area": "",
        "author": "Shibo Zhao;Zheng Fang;HaoLai Li;Sebastian Scherer;Shibo Zhao;Zheng Fang;HaoLai Li;Sebastian Scherer",
        "authorids": "/37086444189;/37401391100;/37085828272;/37584159000;/37086444189;/37401391100;/37085828272;/37584159000",
        "aff": "Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967880/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17376451543122660555&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Northeastern University;Carnegie Mellon University",
        "aff_unique_dep": "Faculty of Robot Science and Engineering;Robotics Institute",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.cmu.edu",
        "aff_unique_abbr": "NEU;CMU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Shenyang;Pittsburgh",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8967887",
        "title": "A Robust Position and Posture Measurement System Using Visual Markers and an Inertia Measurement Unit",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic control of mobile robots and robot arms requires techniques for estimating the position and orientation of objects with high accuracy and robustness. Although methods using markers or machine learning have been developed, general-purpose and highly accurate estimations have not been realized. Our team developed a high-accuracy visual marker \u201cLentiMark\u201d for high-accuracy estimations of position and posture, but data are lost when the camera cannot obtain marker images. We therefore developed the Marker-IMU system for integrating visual markers with an inertia measurement unit (IMU). When cameras cannot acquire the image of a visual marker, any missing data are restored from IMU data. However, when calculating positions from acceleration sensor values, sensor error increases estimation error. Therefore, we developed a method for error correction using measurements from before and after the missing data. Evaluation experiments confirm that missing data can be estimated using the proposed method.",
        "primary_area": "",
        "author": "Kunihiro Ogata;Hideyuki Tanaka;Yoshio Matsumoto;Kunihiro Ogata;Hideyuki Tanaka;Yoshio Matsumoto",
        "authorids": "/37647366000;/37676195700;/37272999900;/37647366000;/37676195700;/37272999900",
        "aff": "Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Kashiwa-shi, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Kashiwa-shi, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Kashiwa-shi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967887/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1206533553109749622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Human Augmentation Research Center",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kashiwa-shi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968008",
        "title": "A Robust Stereo Semi-direct SLAM System Based on Hybrid Pyramid",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hybrid pyramid based approach to fuse the direct and indirect methods in visual SLAM, to allow robust localization under various situations including large-baseline motion, low-texture environment, and various illumination changes. In our approach, we first calculate coarse inter-frame pose estimation by matching the feature points. Subsequently, we use both direct image alignment and a multiscale pyramid method, for refining the previous estimation to attain better precision. Furthermore, we perform online photometric calibration along with pose estimation, to reduce un-modelled errors. To evaluate our approach, we conducted various real-world experiments on both public datasets and self-collected ones, by implementing a full SLAM system with the proposed methods. The results show that our system improves both localization accuracy and robustness by a wide margin.",
        "primary_area": "",
        "author": "Xiangrui Zhao;Renjie Zheng;Wenlong Ye;Yong Liu;Xiangrui Zhao;Renjie Zheng;Wenlong Ye;Yong Liu",
        "authorids": "/37087122595;/37087323824;/37086914589;/37066946100;/37087122595;/37087323824;/37086914589;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968008/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7666174352902459756&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zhejiang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967844",
        "title": "A Simple Approach on Global Control of a Class of Underactuated Mechanical Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an approach to show global controllability of a class of underactuated mechanical systems. This class of systems include gymnastic robots and the classic cart-pole system. For this class of systems, we can define a connection point, and design a damping controller u(t) with the Lyapunov method to drive all states to the connection point. Further by exploiting the time reversal symmetry of the system and spline interpolation, a controller u(-t) can be obtained to drive the system from the connection point to any other state. The system is thus shown completely controllable, i.e., there exists an admissible trajectory from any given state to any given final state. Swing-up control designs for a pendubot, cart-pole system and triple pendulum are given as illustrative examples.",
        "primary_area": "",
        "author": "Tan Chen;Bill Goodwine;Tan Chen;Bill Goodwine",
        "authorids": "/37086128468;/37324652900;/37086128468;/37324652900",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967844/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11047469894097472946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967757",
        "title": "A Spring-Aided Two-Dimensional Electromechanical Spine Architecture for Bio-Inspired Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a distributed six-link two-dimensional electromechanical actuator that emulates a biological spine. The gearless actuator is made by stacking modules of E-shaped cores along with integrated springs. A coil excitation induces magnetic flux in the core, which produces electromechanical force in the air gap between two adjacent cores. The proposed actuator is driven by dc-dc converters with current control. Electromechanical force analysis for the proposed spine architecture with different air-gap distances and spring analysis that improve the actuator's performance are discussed. Experimental results show different biological motions with a prototype design. The prototype can produce a maximum torque of 1.4 N-m.",
        "primary_area": "",
        "author": "Bonhyun Ku;Sunyu Wang;Arijit Banerjee;Bonhyun Ku;Sunyu Wang;Arijit Banerjee",
        "authorids": "/37086932307;/37086931682;/38496446600;/37086932307;/37086931682;/38496446600",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967757/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5787733220087299419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968490",
        "title": "A Study of a Class of Vibration-Driven Robots: Modeling, Analysis, Control and Design of the Brushbot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a study of a specific class of vibration-driven robots: the brushbots. In a bottom-up fashion, we start by deriving dynamic models of the brushes and we discuss the conditions under which these models can be employed to describe the motion of brushbots. Then, we present two designs of brushbots: a fully-actuated platform and a differential-drive-like one. The former is employed to experimentally validate both the developed theoretical models and the devised motion control algorithms. Finally, a coordinated-control algorithm is implemented on a swarm of differential-drive-like brushbots in order to demonstrate the design simplicity and robustness that can be achieved by employing a vibration-based locomotion strategy.",
        "primary_area": "",
        "author": "Gennaro Notomista;Siddharth Mayya;Anirban Mazumdar;Seth Hutchinson;Magnus Egerstedt;Gennaro Notomista;Siddharth Mayya;Anirban Mazumdar;Seth Hutchinson;Magnus Egerstedt",
        "authorids": "/37085607644;/37085621013;/37534392200;/37282386200;/37269707500;/37085607644;/37085621013;/37534392200;/37282386200;/37269707500",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968490/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18178121852337767637&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968184",
        "title": "A Sweeping and Grinding Methods Combined Hybrid Sampler for Asteroid Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Successful sampling on the surface of asteroids is difficult because of their weightless environment and unknown material mechanical property. This work presents an asteroid sampler based on sweeping and grinding methods to improve the success rate of sampling. The sampler uses two brushes rotating clockwise and counter-clockwise to collect sample particles on the surface of asteroids. When encountering the hard rock or sample particles with large cohesion, the sampler adopts a drill bit to grind them to loose samples suitable for collecting by the brushes. The interaction between the brushes and the regolith is modeled and the sweeping mechanism is designed. A simple grinding mechanism is also designed. Numerical simulation and prototype experiments, at different parameters including blades number, rotational speed, and feeding speed of the brushes, mechanical property of the sample, and gravity, were conducted for validating the proposed methods. The 280g sampler prototype with 8 blades of brushes could collect about 19g regolith simulant in 25s in earth environment. The drill bits could work together with the brushes to improve the sampling efficiency through DEM simulation in case of large cohesion among sample particles. The sampler will be a good choice for installing into an asteroid rover in exploration.",
        "primary_area": "",
        "author": "Chengcheng Dong;Jun Zhang;Chaojun Jiang;Fanzhang Huang;Xi Lu;Fan Huang;Aiguo Song;Chengcheng Dong;Jun Zhang;Chaojun Jiang;Fanzhang Huang;Xi Lu;Fan Huang;Aiguo Song",
        "authorids": "/37086355229;/37087323126;/37087322320;/37087321881;/37087323822;/37087321875;/37276033000;/37086355229;/37087323126;/37087322320;/37087321881;/37087323822;/37087321875;/37276033000",
        "aff": "State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Shanghai Institute of Satellite Engineering, Shanghai, China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968184/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10734387766092887768&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "Southeast University;Shanghai Institute of Satellite Engineering",
        "aff_unique_dep": "School of Instrument Science and Engineering;",
        "aff_unique_url": "https://www.seu.edu.cn/;",
        "aff_unique_abbr": "SEU;",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Nanjing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967846",
        "title": "A Systematic Comparison of Affective Robot Expression Modalities",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper provides a survey of the different means of expression employed by robots conveying affective states to human recipients. The paper introduces a model of affective expression modalities (MOAM) that describes and compares the emphasis on specific means of expression and applies it to the surveyed robots. Using the model entails viewing the effect of applied expression modalities in light of how well the robot responds to external stimuli and with attention to how aligned the robot's means of affective expressions are with the intended working scenario. The model-based survey shows that a majority (85%) of the surveyed robots contain a category with room for additional affective means of expression, and a quarter (25.6%) of the robots use a single or two affective expression modalities to convey affective states. The result of the survey indicates there is an under-researched opportunity in exploring synergies between the different expression modalities to amplify the overall affective impact of a robot.",
        "primary_area": "",
        "author": "Morten Roed Frederiksen;Kasper Stoy;Morten Roed Frederiksen;Kasper Stoy",
        "authorids": "/37087119873;/37333021600;/37087119873;/37333021600",
        "aff": "Computer science department of, The IT-University of Copenhagen, Rued Langgaards vej 7, 2300 Copenhagen S, Denmark; Computer science department of, The IT-University of Copenhagen, Rued Langgaards vej 7, 2300 Copenhagen S, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967846/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=527439872696687479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "IT-University of Copenhagen",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://itu.dk",
        "aff_unique_abbr": "ITU Copenhagen",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Copenhagen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8967974",
        "title": "A Taxonomy for Characterizing Modes of Interactions in Goal-driven, Human-robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots and other autonomous agents are increasingly incorporated into complex domains, characterizing interaction within heterogeneous teams that include both humans and machines becomes more necessary. Previous literature has addressed the task of characterizing human-robot interaction from different perspectives and in multiple contexts. However, the numerous factors behind interaction work in conjunction, and the insights gained from one perspective can inadvertently affect another, creating a need for unification of these taxonomies and frameworks within an overarching taxonomy that systematically defines these relationships. In this paper we review existing taxonomies related to human-robot interaction, the behavioral sciences, and social and algorithmic taxonomies, and propose an overarching ontology for the factors from these works. We identify three main components characterizing the structure of an interaction (environment, task, and team), and structure them over two levels: contextual factors and factors driven by local dynamics. Finally, we present an analysis of how these factors affect decisions about levels of robot automation and level of information abstraction in an interaction, and discuss curent gaps in the literature that can motivate future research.",
        "primary_area": "",
        "author": "Priyam Parashar;Lindsay M. Sanneman;Julie A. Shah;Henrik I. Christensen;Priyam Parashar;Lindsay M. Sanneman;Julie A. Shah;Henrik I. Christensen",
        "authorids": "/37085725224;/37085557517;/38252774900;/37281307400;/37085725224;/37085557517;/38252774900;/37281307400",
        "aff": "Contextual Robotics Institute, University of California, San Diego; Interactive Robotics Group, MIT, Cambridge; Interactive Robotics Group, MIT, Cambridge; Contextual Robotics Institute, University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967974/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11668435080011379729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of California, San Diego;Massachusetts Institute of Technology",
        "aff_unique_dep": "Contextual Robotics Institute;Interactive Robotics Group",
        "aff_unique_url": "https://ucsd.edu;https://web.mit.edu/",
        "aff_unique_abbr": "UCSD;MIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "San Diego;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967952",
        "title": "A Two-DOF Bipedal Robot Utilizing the Reuleaux Triangle Drive Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design, modeling, analysis, and experimental results of a bipedal robotic system that utilizes two interconnected single degree-of-freedom leg mechanisms to produce stable forward locomotion and steering. The legs are composed of double four-bar mechanism connected in series that maintain a parallel orientation of a flat foot, relative to the biped body, that is actuated via a Reuleaux triangle cam-follower system to produce a desirable foot trajectory. The mechanical design of the leg mechanism is presented followed by kinematic analysis of the cam-follower system to select the optimal foot trajectory and synthesize the mechanism dimensions and produce a desired step height and step length. The concept of leg sequencing is then presented to maintain a constant body height above the ground and a constant forward walking velocity. Experimental results using an integrated prototype indicate that the proposed biped robot is capable of maintaining quasi-static stability during locomotion, maintaining a constant robot body height, maintaining a constant body orientation, move forward with a constant maximum velocity of 27.4 cm/s, and steer.",
        "primary_area": "",
        "author": "Jiteng Yang;Wael Saab;Pinhas Ben-Tzvi;Jiteng Yang;Wael Saab;Pinhas Ben-Tzvi",
        "authorids": "/37086579440;/37086319273;/38277770000;/37086579440;/37086319273;/38277770000",
        "aff": "Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, VA, USA; Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, VA, USA; Robotics and Mechatronics Lab, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967952/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17854797330799368114&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Robotics and Mechatronics Lab",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968055",
        "title": "A Unified Active Assistance Control Framework of Hip Exoskeleton for Walking and Balance Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "To actively assist human walking and balance recovery, a unified active assistance control framework of the hip exoskeleton is proposed in this paper. At the beginning of this paper, the condition of active assistance is analyzed. And then, a novel virtual stiffness model is proposed based on the analysis of human hip joint torque during walking and balance recovery. The virtual stiffness model is utilized to generate the desired active assistance torque profile for active walking and balance assistance. Next, the unified active assistance control framework is established based on the virtual stiffness model. Finally, the effectiveness of the proposed control framework is demonstrated by walking experiments. The results of the forward walking experiment show that the muscle effort of iliopsoas is reduced and the amplitude of hip joint motion is enlarged with the assistance of hip exoskeleton. The walking forward pull experiments and the walking backward pull experiments show that when the human suffers from a forward or backward disturbance force during forward walking, exoskeleton can help human regain balance faster and can enlarge the margin of stability (MoS) of the human.",
        "primary_area": "",
        "author": "Shiyin Qiu;Wei Guo;Pengfei Wang;Fei Chen;Fusheng Zha;Xin Wang;Jing Deng;Shiyin Qiu;Wei Guo;Pengfei Wang;Fei Chen;Fusheng Zha;Xin Wang;Jing Deng",
        "authorids": "/37086225094;/37291945900;/37406354200;/37085388569;/37085373305;/37281382000;/37086219658;/37086225094;/37291945900;/37406354200;/37085388569;/37085373305;/37281382000;/37086219658",
        "aff": "State Key Laboratory of Robotics and System, School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; Department of Advanced Robotics, Istituto Italiano di Tecnologia, 30, Genova, Italy; State Key Laboratory of Robotics and System, School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; Shenzhen Academy of Aerospace Technology, Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968055/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3569962187416558078&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;0",
        "aff_unique_norm": "Harbin Institute of Technology;Istituto Italiano di Tecnologia;Shenzhen Academy of Aerospace Technology",
        "aff_unique_dep": "School of Mechatronics Engineering;Department of Advanced Robotics;",
        "aff_unique_url": "http://www.hit.edu.cn;https://www.iit.it;",
        "aff_unique_abbr": "HIT;IIT;",
        "aff_campus_unique_index": "0;0;0;1;0;2;0",
        "aff_campus_unique": "Harbin;Genova;Shenzhen",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "8968440",
        "title": "A Unified Formulation for Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular Odometry systems can be broadly categorized as being either Direct, Indirect, or a hybrid of both. While Indirect systems process an alternative image representation to compute geometric residuals, Direct methods process the image pixels directly to generate photometric residuals. Both paradigms have distinct but often complementary properties. This paper presents a Unified Formulation for Visual Odometry, referred to as UFVO, with the following key contributions: (1) a tight coupling of photometric (Direct) and geometric (Indirect) measurements using a joint multi-objective optimization, (2) the use of a utility function as a decision maker that incorporates prior knowledge on both paradigms, (3) descriptor sharing, where a feature can have more than one type of descriptor and its different descriptors are used for tracking and mapping, (4) the depth estimation of both corner features and pixel features within the same map using an inverse depth parametrization, and (5) a corner and pixel selection strategy that extracts both types of information, while promoting a uniform distribution over the image domain. Experiments show that our proposed system can handle large inter-frame motions, inherits the sub-pixel accuracy of direct methods, can run efficiently in real-time, can generate an Indirect map representation at a marginal computational cost when compared to traditional Indirect systems, all while outperforming state of the art in Direct, Indirect and hybrid systems.",
        "primary_area": "",
        "author": "Georges Younes;Daniel Asmar;John Zelek;Georges Younes;Daniel Asmar;John Zelek",
        "authorids": "/37087137691;/37424435700;/37268935100;/37087137691;/37424435700;/37268935100",
        "aff": "Systems Design Engineenng Department, University of Waterloo, Canada; Department of Mechanical Engineering, Amencan University of Beirut, Beirut, Lebanon; Systems Design Engineenng Department, University of Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968440/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1860991625951017776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Waterloo;American University of Beirut",
        "aff_unique_dep": "Systems Design Engineering Department;Department of Mechanical Engineering",
        "aff_unique_url": "https://uwaterloo.ca;https://www.aub.edu.lb",
        "aff_unique_abbr": "UW;AUB",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beirut",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;Lebanon"
    },
    {
        "id": "8968598",
        "title": "A VR System for Immersive Teleoperation and Live Exploration with a Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Applications like disaster management and industrial inspection often require experts to enter contaminated places. To circumvent the need for physical presence, it is desirable to generate a fully immersive individual live teleoperation experience. However, standard video-based approaches suffer from a limited degree of immersion and situation awareness due to the restriction to the camera view, which impacts the navigation. In this paper, we present a novel VR-based practical system for immersive robot teleoperation and scene exploration. While being operated through the scene, a robot captures RGB-D data that is streamed to a SLAM-based live multiclient telepresence system. Here, a global 3D model of the already captured scene parts is reconstructed and streamed to the individual remote user clients where the rendering for e.g. head-mounted display devices (HMDs) is performed. We introduce a novel lightweight robot client component which transmits robot-specific data and enables a quick integration into existing robotic systems. This way, in contrast to first- person exploration systems, the operators can explore and navigate in the remote site completely independent of the current position and view of the capturing robot, complementing traditional input devices for teleoperation. We provide a proof-of-concept implementation and demonstrate the capabilities as well as the performance of our system regarding interactive object measurements and bandwidth-efficient data streaming and visualization. Furthermore, we show its benefits over purely video-based teleoperation in a user study revealing a higher degree of situation awareness and a more precise navigation in challenging environments.",
        "primary_area": "",
        "author": "Patrick Stotko;Stefan Krumpen;Max Schwarz;Christian Lenz;Sven Behnke;Reinhard Klein;Michael Weinmann;Patrick Stotko;Stefan Krumpen;Max Schwarz;Christian Lenz;Sven Behnke;Reinhard Klein;Michael Weinmann",
        "authorids": "/37086806788;/37086806911;/37085593752;/38468570500;/37295987100;/37271619700;/37303795300;/37086806788;/37086806911;/37085593752;/38468570500;/37295987100;/37271619700;/37303795300",
        "aff": "Institute of Computer Science II \u2013 Computer Graphics, University of Bonn, Germany; Institute of Computer Science II \u2013 Computer Graphics, University of Bonn, Germany; Institute of Computer Science VI \u2013 Autonomous Intelligent Systems, University of Bonn, Germany; Institute of Computer Science VI \u2013 Autonomous Intelligent Systems, University of Bonn, Germany; Institute of Computer Science VI \u2013 Autonomous Intelligent Systems, University of Bonn, Germany; Institute of Computer Science II \u2013 Computer Graphics, University of Bonn, Germany; Institute of Computer Science II \u2013 Computer Graphics, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968598/",
        "gs_citation": 135,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15895089006719837953&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Institute of Computer Science II \u2013 Computer Graphics",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bonn;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8970475",
        "title": "A Variable Stiffness Elbow Joint for Upper Limb Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main research trends toward next-generation prostheses and bionic aids is to better replicate human motor behaviours and to improve the interconnection with the human sensory-motor architecture. One of the natural characteristics of the human arm of utmost importance in our interaction with the environment is our ability to vary the mechanical impedance of our joints by commanding the co-contraction of antagonist muscles. Integration in prostheses of such features is currently under studies. The introduction of physical variable impedance in the mechatronic structure of the devices could at the same time improve interaction and robustness and allow for more sophisticated controls with the goal of naturalness of motion. The system proposed in this paper is a variable stiffness elbow joint for upper limb prostheses that reproduces mechanical abilities of the human joint, in terms of performance, inherent compliance and natural behaviour. This variable stiffness mechanism can be actively controlled by the user, and by using an agonist-antagonistic configuration of proper elastic elements, its output functions are similar to the models of the human muscle. The design and mechanical implementation of the device are detailed in this document together with its experimental validation and characterisation.",
        "primary_area": "",
        "author": "Simon Lemerle;Giorgio Grioli;Antonio Bicchi;Manuel G. Catalano;Simon Lemerle;Giorgio Grioli;Antonio Bicchi;Manuel G. Catalano",
        "authorids": "/37086022511;/37590311700;/37278626700;/37544547800;/37086022511;/37590311700;/37278626700;/37544547800",
        "aff": "Research Center \u201dE. Piaggio\u201c, University of Pisa, Largo Lucio Lazzarino 1,, Pisa, Italy; Istituto Italiano di Tecnologia (IIT), via Morego 30,, Genoa, Italy; Research Center \u201dE. Piaggio\u201c, University of Pisa, Largo Lucio Lazzarino 1,, Pisa, Italy; Istituto Italiano di Tecnologia (IIT), via Morego 30,, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8970475/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10834020865587977170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Pisa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Research Center \"E. Piaggio\";",
        "aff_unique_url": "https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": "UNIP;IIT",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Pisa;Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967715",
        "title": "A behavior driven approach for sampling rare event situations for autonomous vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Performance evaluation of urban autonomous vehicles (AVs) requires a realistic model of the behavior of other road users in the environment. Learning such models from data involves collecting naturalistic data of real-world human behavior. In many cases, acquisition of this data can be prohibitively expensive or intrusive. Additionally, the available data often contain only typical behaviors and exclude behaviors that are classified as rare events. To evaluate the performance of AVs in such situations, we develop a model of traffic behavior based on the theory of bounded rationality. Based on the experiments performed on a large naturalistic driving data, we show that the developed model can be applied to estimate probability of rare events, as well as to generate new traffic situations for testing.",
        "primary_area": "",
        "author": "Atrisha Sarkar;Krzysztof Czamecki;Atrisha Sarkar;Krzysztof Czamecki",
        "authorids": "/37085763412;/37087323176;/37085763412;/37087323176",
        "aff": "University of Waterloo; University of Waterloo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967715/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5022746857846177148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8967771",
        "title": "A multi-trainee architecture for haptic hands-on training",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic simulators are used in many education domains to improve hands-on training performance. Many of these simulators are used in the medical domain, where it is particularly important to be trained, guided by an expert. However, the majority of haptic hands-on training devices are usable by only one user at the same time, either the trainer or the trainee. Dual-user approaches have enhanced this situation by allowing both trainer and trainee to use the same simulator to introduce guided training into the simulation. In this paper, we introduce a multi-trainee architecture that expands further a former dual-user hands-on haptic training solution designed according to an energetic approach. This system will permit several trainees to be involved in the same simulation at the same time, guided by a single trainer. It paves the way to the multi-trainee hands-on training on haptic simulators.",
        "primary_area": "",
        "author": "A.R. Licona;A. Lelevel;M.T. Pham;D. Eberard;A.R. Licona;A. Lelevel;M.T. Pham;D. Eberard",
        "authorids": "/37087322102;/37087324137;/37447734900;/38667623700;/37087322102;/37087324137;/37447734900;/38667623700",
        "aff": "Amp\u00e8re Laboratory, INSA, universit\u00e8 de Lyon, Villeurbanne, France; Amp\u00e8re Laboratory, INSA, universit\u00e8 de Lyon, Villeurbanne, France; Amp\u00e8re Laboratory, INSA, universit\u00e8 de Lyon, Villeurbanne, France; Amp\u00e8re Laboratory, INSA, universit\u00e8 de Lyon, Villeurbanne, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967771/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13978932114639787297&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "INSA Lyon",
        "aff_unique_dep": "Amp\u00e8re Laboratory",
        "aff_unique_url": "https://www.insa-lyon.fr",
        "aff_unique_abbr": "INSA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Villeurbanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968548",
        "title": "A pressure field model for fast, robust approximation of net contact force and moment between nominally rigid objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Pressure Field Contact (PFC), an approximate model for predicting the contact surface, pressure distribution, and net contact wrench between nominally rigid objects. PFC combines and generalizes two ideas: a bed of springs (an `elastic foundation') and hydrostatic pressure. Continuous pressure fields are computed offline for the interior of each nominally rigid object. Unlike hydrostatics or elastic foundations, the pressure fields need not satisfy mechanical equilibrium conditions. When two objects nominally overlap, a contact surface is defined where the two pressure fields are equal. This static pressure is supplemented with a dissipative rate-dependent pressure and friction to determine tractions on the contact surface. The contact wrench between pairs of objects is an integral of traction contributions over this surface. PFC evaluates much faster than elasticity-theory models, while showing the essential trends of force, moment, and stiffness increase with contact load. It yields continuous wrenches even for non-convex objects and coarse meshes. The method shows promise as sufficiently fast, accurate, physical, and robust for robotics applications including motion and tactile sensor simulation, controller learning and synthesis, state estimation, and design-in-simulation.",
        "primary_area": "",
        "author": "Ryan Elandt;Evan Drumwright;Michael Sherman;Andy Ruina;Ryan Elandt;Evan Drumwright;Michael Sherman;Andy Ruina",
        "authorids": "/37087323849;/37329503400;/37087321849;/37564257100;/37087323849;/37329503400;/37087321849;/37564257100",
        "aff": "Toyota Research Institute, Los Altos, CA; Toyota Research Institute, Los Altos, CA; Toyota Research Institute, Los Altos, CA; Cornell University, Mechanical Engineering, Ithaca, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968548/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10621489937105976786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Toyota Research Institute;Cornell University",
        "aff_unique_dep": ";Mechanical Engineering",
        "aff_unique_url": "https://www.tri.global;https://www.cornell.edu",
        "aff_unique_abbr": "TRI;Cornell",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Los Altos;Ithaca",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967737",
        "title": "A-EXP4: Online Social Policy Learning for Adaptive Robot-Pedestrian Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "We study self-supervised adaptation of a robot's policy for social interaction, i.e., a policy for active communication with surrounding pedestrians through audio or visual signals. Inspired by the observation that humans continually adapt their behavior when interacting under varying social context, we propose Adaptive EXP4 (A-EXP4), a novel online learning algorithm for adapting the robot-pedestrian interaction policy. To address limitations of bandit algorithms in adaptation to unseen and highly dynamic scenarios, we employ a mixture model over the policy parameter space. Specifically, a Dirichlet Process Gaussian Mixture Model (DPMM) is used to cluster the parameters of sampled policies and maintain a mixture model over the clusters, hence effectively discovering policies that are suitable to the current environmental context in an unsupervised manner. Our simulated and real-world experiments demonstrate the feasibility of A-EXP4 in accommodating interaction with different types of pedestrians while jointly minimizing social disruption through the adaptation process. While the A-EXP4 formulation is kept general for application in a variety of domains requiring continual adaptation of a robot's policy, we specifically evaluate the performance of our algorithm using a suitcase-inspired assistive robotic platform. In this concrete assistive scenario, the algorithm observes how audio signals produced by the navigational system affect the behavior of pedestrians and adapts accordingly. Consequently, we find A-EXP4 to effectively adapt the interaction policy for gently clearing a navigation path in crowded settings, resulting in significant reduction in empirical regret compared to the EXP4 baseline.",
        "primary_area": "",
        "author": "Pengju Jin;Eshed Ohn-Bar;Kris Kitani;Chieko Asakawa;Pengju Jin;Eshed Ohn-Bar;Kris Kitani;Chieko Asakawa",
        "authorids": "/37087322948;/37073869900;/37294510900;/37352958000;/37087322948;/37073869900;/37294510900;/37352958000",
        "aff": "Authors are affiliated with the Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Max Planck Institute for Intelligent Systems.; Authors are affiliated with the Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Authors are affiliated with the Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967737/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8992835498707909777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "CMU;MPI-IS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "8967947",
        "title": "A2-piece six-axis force/torque sensor capable of measuring loads applied to tools of complex shapes",
        "track": "main",
        "status": "Poster",
        "abstract": "Measuring forces and torques applied to tools of unconventional shapes can be challenging due to difficulties in connecting commercially available force/torque sensors. We propose an innovative, customizable six-axis force/torque sensor which can be clamped around a tool or end-effector to minimize the proximity between tool tip and sensor structure. The sensor is fabricated using 3d printing technology and consists of two pieces which together form an 8-legged Stewart platform. Each leg is designed as a cantilever beam to allow for a measurable displacement under an external load. The displacements of the legs are measured with 8 light intensity-based optoelectronic sensors, which exhibit high sensitivities and low noise levels without the need for external amplification circuitry. A customized printed circuit board and peripheral hardware are proposed to allow for efficient analog-to-digital conversion of the force/torque measurement. A calibration process is proposed which makes use ofa commercial ATI Mini40 sensor and custom hardware to allow for fast calibration routines. Finally, the calibrated sensor design is compared to the ATI Mini40 sensor by measuring sequences of forces and torques, and the maximum errors of force/torque components (Fx, Fy, Fz, Mx, My, Mz) are 16.3%, 20.0%, 27.5%, 20.5%, 21.6%, 14.9% respectively.",
        "primary_area": "",
        "author": "Yohan Noh;Lukas Lindenroth;Shuangyi Wang;Richard James Housden;Anne-Sophie van Wingerden;Wanlin Li;Kawal Rhode;Yohan Noh;Lukas Lindenroth;Shuangyi Wang;Richard James Housden;Anne-Sophie van Wingerden;Wanlin Li;Kawal Rhode",
        "authorids": "/37085437433;/37085842056;/37086183002;/38559299300;/37087323339;/37087031325;/37294454000;/37085437433;/37085842056;/37086183002;/38559299300;/37087323339;/37087031325;/37294454000",
        "aff": "Department of Biomedical Eng., King\u2019s College, London, UK.; School of Natural and Mathematical Science, King\u2019s College London, UK; Department of Biomedical Eng., King\u2019s College, London, UK.; Department of Biomedical Eng., King\u2019s College, London, UK.; Department of Chemistry, Williams College, Williamstown, USA; Department of Electrical Eng., Queen Maiy University of London, UK; Department of Biomedical Eng., King\u2019s College, London, UK.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967947/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2778301799315904772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "King\u2019s College London;Williams College;Queen Mary University of London",
        "aff_unique_dep": "Department of Biomedical Engineering;Department of Chemistry;Department of Electrical Engineering",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.williams.edu;https://www.qmul.ac.uk",
        "aff_unique_abbr": "KCL;Williams;QMUL",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "London;;Williamstown",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8967788",
        "title": "ALTRO: A Fast Solver for Constrained Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization is a widely used tool for robot motion planning and control. Existing solvers for these problems either rely on off-the-shelf nonlinear programming solvers that are numerically robust and capable of handling arbitrary constraints, but tend to be slow because they are general purpose; or they use custom numerical methods that take advantage of the problem structure to be fast, but often lack robustness and have limited or no ability to reason about constraints. This paper presents ALTRO (Augmented Lagrangian TRajectory optimizer), a solver for constrained trajectory optimization problems that handles general nonlinear state and input constraints and offers fast convergence and numerical robustness thanks to careful exploitation of problem structure. We demonstrate its performance on a set of benchmark motion-planning problems and offer comparisons to the standard direct collocation method with large-scale sequential quadratic programming and interior-point solvers.",
        "primary_area": "",
        "author": "Taylor A. Howell;Brian E. Jackson;Zachary Manchester;Taylor A. Howell;Brian E. Jackson;Zachary Manchester",
        "authorids": "/37087324047;/37087323361;/37086011525;/37087324047;/37087323361;/37086011525",
        "aff": "Department of Mechanical Engineering, Stanford University, USA; Department of Mechanical Engineering, Stanford University, USA; Department of Aeronautics and Astronautics, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967788/",
        "gs_citation": 264,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13805282096371168585&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967907",
        "title": "ARMCL: ARM Contact point Localization via Monte Carlo Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting and localizing contacts acting on a manipulator is a relevant problem for manipulation tasks like grasping, since contact information can be helpful for recovering from collisions or for improving the grasping performance itself. In this work, we present a solution for contact point localization, which is based on Monte Carlo Localization. Usually, an Articulated Robotic Manipulator (ARM) is not equipped with tactile skin, but with proprioceptive sensors, which we assume as an input for our method. In our experiments, we compare our method with a direct optimization method, machine learning approaches and another particle filter method, both on simulated and real world data from a Kinova Jaco2. While our proposed method clearly outperforms the other optimization approaches, it performs about equally well as Random Forest (RF) classifiers, although both methods have their strengths on different parts of the manipulator, and even achieves better results than multi-layer perceptions (MLPs) on the links farthest from the manipulator base.",
        "primary_area": "",
        "author": "Adrian Zwiener;Richard Hanten;Cornelia Schulz;Andreas Zell;Adrian Zwiener;Richard Hanten;Cornelia Schulz;Andreas Zell",
        "authorids": "/37086455280;/37085619648;/37086579417;/37276583400;/37086455280;/37085619648;/37086579417;/37276583400",
        "aff": "Cognitive Systems Group, University of T\u00fcbingen, Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group, University of T\u00fcbingen, Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group, University of T\u00fcbingen, Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group, University of T\u00fcbingen, Sand 1, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967907/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12854616690531941995&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Cognitive Systems Group",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968124",
        "title": "Absolute Localization Through Orbital Maps and Surface Perspective Imagery: A Synthetic Lunar Dataset and Neural Network Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a neural network approach and publicly available dataset for developing and benchmarking algorithms for localization on the Moon. Accurate localization is essential for navigation, path planning, and science objectives. On Earth, localization can be achieved using a satellite navigation system; such a system is, however, unavailable for other planetary bodies. Current absolute and relative localization methods for rovers on planetary surfaces are laborious manual tasks or accumulate significant location errors over time resulting in incorrect location estimates, respectively. Recently, Earth-based approaches have explored localization by matching surface-perspective imagery to satellite imagery using computer vision and machine learning. Those focusing on natural environments have shown such image matching to be feasible for localization, though it remains challenging. The purpose of this project was to produce a working proof-of-concept model to match surface-perspective imagery to satellite images for planetary roving applications. This would improve absolute localization accuracy (relative to current methods) by utilizing machine learning algorithms to offer greater automation and faster calculations, and produce a benchmark dataset for future studies. To achieve these, the following objectives were met: (1) configuration and modification of an existing synthetic planetary environment using Unreal Engine 4 to generate surface and satellite perspective images, (2) reprojection of 2.4 + million surface perspective images to 600,000 + satellite perspective images, and (3) matching of said reprojected images to satellite images via a Siamese convolutional neural network, designed and trained for this task.",
        "primary_area": "",
        "author": "Benjamin Wu;Potter Ross W. K.;Philippe Ludivig;Andrew S. Chung;Timothy Seabrook;Benjamin Wu;Potter Ross W. K.;Philippe Ludivig;Andrew S. Chung;Timothy Seabrook",
        "authorids": "/37087323199;/37087323753;/37087324799;/37087323373;/37086811907;/37087323199;/37087323753;/37087324799;/37087323373;/37086811907",
        "aff": "National Astronomical Observatory of Japan, Mitaka, Japan; Department of Earth, Environmental and Planetary Sciences, Brown University, Providence, RI; ispace Europe, Luxembourg City, Luxembourg; tensorlicious, Germany; Department of Computer Science, University of Oxford, Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968124/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9111972723516343638&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "National Astronomical Observatory of Japan;Brown University;ispace Europe;tensorlicious;University of Oxford",
        "aff_unique_dep": ";Department of Earth, Environmental and Planetary Sciences;;;Department of Computer Science",
        "aff_unique_url": "https://naoj.org/;https://www.brown.edu;;;https://www.ox.ac.uk",
        "aff_unique_abbr": "NAOJ;Brown;;;Oxford",
        "aff_campus_unique_index": "0;1;3",
        "aff_campus_unique": "Mitaka;Providence;;Oxford",
        "aff_country_unique_index": "0;1;2;3;4",
        "aff_country_unique": "Japan;United States;Luxembourg;Germany;United Kingdom"
    },
    {
        "id": "8968285",
        "title": "Accelerated Visual Inertial Navigation via Fragmented Structure Updates",
        "track": "main",
        "status": "Poster",
        "abstract": "Tightly coupled Visual-Inertial Navigation System (VINS) implementations have proven their superiority due to their ability to jointly optimize all state variables. However, this joint optimization is considered as a computational bottleneck within the system, and thus many traditional VINS can only be implemented on platforms containing powerful processors. In this work, we show a significant reduction in the computational burden of optimization can be achieved through the use of fragments; a set of co-visible feature points from across several different cameras efficiently split, categorized into groups, and then analyzed using a machine-learning inspired frequent-pattern growth algorithm. Furthermore, we use a reduced continuous representation during preintegration for better accuracy while requiring less computational resources. We validate our algorithm in datasets, showing that the derivation is not only more accurate, but requires significantly less computational resources. When tested on a Raspberry Pi, our implementation was able to track the system's state in nearly 20 frames per second using only a single CPU core. Testing on another low power module shows a power draw of around 800 mW. Due to run-time considerations the Raspberry Pi was only competitive in regards to other optimization methodologies, but our algorithm displays remarkable accuracy on a more powerful platform.",
        "primary_area": "",
        "author": "Yehonathan Litman;Ya Wang;Ji Liu;Yehonathan Litman;Ya Wang;Ji Liu",
        "authorids": "/37087322119;/37086411368;/37087322330;/37087322119;/37086411368;/37087322330",
        "aff": "Department of Computer Science, Texas A&M University; Department of Mechanical Engineering, Texas A&M University; Department of Electrical and Computer Engineering, Texas A&M University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968285/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18084699654843723976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "College Station;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968258",
        "title": "Accelerating the Construction of Boundaries of Feasibility in Three Classes of Robot Design Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to improve the practical scalability of automated tools to assist in designing robots. Such problems rapidly become intractable because the underlying design space is immense. We consider a specific type of design tool addressed in prior work, which constructs a representation of the destructiveness boundary in the space of robot designs. This prior work showed that a legible representation, specifically a decision tree, of this boundary can illuminate which elements of a sensing or actuation system are most important for enabling the robot to complete its task. In that context, the robot's interaction with the world is represented as procrustean graph, and the space of robot designs is represented by the space of label maps that rewrite the labels on that graph. In this paper, we expand upon those results by showing how domain knowledge can enable such tools to find solutions to more complex problems within a reasonable time frame. Specifically, we propose three different scenarios, expressed as constraints on the p-graph and on the label maps, under which the learning algorithm to identify the destructiveness boundary can converge quickly to high accuracy results for problems at larger scales than the prior, general-purpose algorithm. The conditions for each of these scenarios are easily verifiable and the set of problems that fall under each is rich enough to encompass several interesting problems. Experimental results demonstrate the effectiveness of the proposed methods.",
        "primary_area": "",
        "author": "Shervin Ghasemlou;Jason M. O\u2019Kane;Shervin Ghasemlou;Jason M. O\u2019Kane",
        "authorids": "/37086169381;/37279835400;/37086169381;/37279835400",
        "aff": "Department of Computer Science & Engineering, University of South Carolina, South Carolina, United States; Department of Computer Science & Engineering, University of South Carolina, South Carolina, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968258/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14339427178666922587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967802",
        "title": "Accurate Pouring using Model Predictive Control Enabled by Recurrent Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans perform the task of pouring often and in which exhibit consistent accuracy regardless of the complicated dynamics of the liquid. Model predictive control (MPC) appears to be a natural candidate solution for the task of accurate pouring considering its wide use in industrial applications. However, MPC requires the model of the system in question. Since an accurate model of the liquid dynamics is difficult to obtain, the usefulness of MPC for the pouring task is uncertain. In this work, we model the dynamics of water using a recurrent neural network (RNN), which enables the use of MPC for pouring control. We evaluated our RNN-enabled MPC controller using a physical system we made ourselves and averaged a pouring error of 16.4 mL over 5 different source containers. We also compared our controller with a baseline switch controller and showed that our controller achieved a much higher accuracy than the baseline controller.",
        "primary_area": "",
        "author": "Tianze Chen;Yongqiang Huang;Yu Sun;Tianze Chen;Yongqiang Huang;Yu Sun",
        "authorids": "/37087323523;/37085721329;/37291603500;/37087323523;/37085721329;/37291603500",
        "aff": "Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967802/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10273423032210798787&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967672",
        "title": "Achievement of Online Agile Manipulation Task for Aerial Transformable Multilink Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformable aerial robots are favorable in aerial manipulation tasks for their flexible ability to change configuration during the flight. By assuming robot keeping in the mild motion, the previous researches sacrifice aerial agility to simplify the complex non-linear system into a single rigid body with a linear controller. In this paper, we present a framework towards agile swing motion for the transformable multi-links aerial robot. We introduce a computational-efficient non-linear model predictive controller and joints motion primitive frame-work to achieve agile transforming motions and validate with a novel robot named HYRURS-X. Finally, we implement our framework under a table tennis task to validate the online and agile performance.Supplementary MaterialThis paper is accompanied by a experiment video: http://www.jsk.t.u-tokyo.ac.jp/%7eshifan/paper/iros19/video.mp4.",
        "primary_area": "",
        "author": "Fan Shi;Moju Zhao;Tomoki Anzai;Keita Ito;Xiangyu Chen;Kei Okada;Masayuki Inaba;Fan Shi;Moju Zhao;Tomoki Anzai;Keita Ito;Xiangyu Chen;Kei Okada;Masayuki Inaba",
        "authorids": "/37086162286;/37085684946;/37086287194;/37087322262;/37085704184;/37280639000;/37286658200;/37086162286;/37085684946;/37086287194;/37087322262;/37085704184;/37280639000;/37286658200",
        "aff": "Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967672/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1306663625473031727&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Creative-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967570",
        "title": "Action Recognition Based on 3D Skeleton and RGB Frame Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Action recognition has wide applications in assisted living, health monitoring, surveillance, and human-computer interaction. In traditional action recognition methods, RGB video-based ones are effective but computationally inefficient, while skeleton-based ones are computationally efficient but do not make use of low-level detail information. This work considers action recognition based on a multimodal fusion between the 3D skeleton and the RGB image. We design a neural network that uses a 3D skeleton sequence and a single middle frame from an RGB video as input. Specifically, our method picks up one frame in a video and extracts spatial features from it using two attention modules, a self-attention module and a skeleton-attention module. Further, temporal features are extracted from the skeleton sequence via a BI-LSTM sub-network. Finally, the spatial features and the temporal features are combined via a feature fusion network for action classification. A distinct feature of our method is that it uses only a single RGB frame rather than an RGB video. Accordingly, it has a light-weighted architecture and is more efficient than RGB video-based methods. Comparative evaluation on two public datasets, NTU-RGBD and SYSU, demonstrates that, our method can achieve competitive performance compared with state-of-the-art methods.",
        "primary_area": "",
        "author": "Guiyu Liu;Jiuchao Qian;Fei Wen;Xiaoguang Zhu;Rendong Ying;Peilin Liu;Guiyu Liu;Jiuchao Qian;Fei Wen;Xiaoguang Zhu;Rendong Ying;Peilin Liu",
        "authorids": "/37087324418;/37086497523;/37085786582;/37086884101;/37265730700;/37402099000;/37087324418;/37086497523;/37085786582;/37086884101;/37265730700;/37402099000",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967570/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13631411259982188472&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Electronic Information and Electrical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967837",
        "title": "Active Incremental Learning of a Contextual Skill Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Contextual skill models are learned to provide skills over a range of task parameters, often using regression across optimal task-specific policies. However, the sequential nature of the learning process is usually neglected. In this paper, we propose to use active incremental learning by selecting a task which maximizes performance improvement over entire task set. The proposed framework exploits knowledge of individual tasks accumulated in a database and shares it among the tasks using a contextual skill model. The framework is agnostic to the type of policy representation, skill model, and policy search. We evaluated the skill improvement rate in two tasks, ball-in-a-cup and basketball. In both, active selection of tasks lead to a consistent improvement in skill performance over a baseline.",
        "primary_area": "",
        "author": "Murtaza Hazara;Xiaopu Li;Ville Kyrki;Murtaza Hazara;Xiaopu Li;Ville Kyrki",
        "authorids": "/37086059143;/37087324765;/37274001900;/37086059143;/37087324765;/37274001900",
        "aff": "Department of Electrical Engineering and Automation, Aalto University, Finland; Department of Electrical Engineering and Automation, Aalto University, Finland; Department of Electrical Engineering and Automation, Aalto University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967837/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5968066578385642075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "Department of Electrical Engineering and Automation",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "8967660",
        "title": "Active Infrared Coded Target Design and Pose Estimation for Multiple Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Relative pose estimation is critical for collaborative multi-agent systems. To achieve accurate and low-cost localization in cluttered and GPS-denied environments, we propose a novel relative pose estimation system based on a designed active infrared coded target. Specifically, each agent is equipped with a forward-looking monocular camera and a unique infrared coded target. The target with the unique lighted LED arrangement is detected by the camera and processed with an efficient decoding algorithm. The relative pose between the agent and the camera is estimated by combining a PnP algorithm and a Kalman filter. Various experiments are performed to show that the proposed pose estimation system is accurate, robust and efficient in cluttered and GPS-denied environments.",
        "primary_area": "",
        "author": "Xudong Yan;Heng Deng;Quan Quan;Xudong Yan;Heng Deng;Quan Quan",
        "authorids": "/37087323931;/37086417192;/37406014700;/37087323931;/37086417192;/37406014700",
        "aff": "The School of Automation Science and Electrical Engineering, Beihang University, Beijing, P. R. China; The School of Automation Science and Electrical Engineering, Beihang University, Beijing, P. R. China; The School of Automation Science and Electrical Engineering, Beihang University, Beijing, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967660/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8945035432044616333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967858",
        "title": "Active Inverse Model Learning with Error and Reachable Set Estimates",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a framework to learn an inverse model of redundant systems. We address three problems. By formalizing what it actually means to learn an inverse model, we derive a method where the inverse model, represented as a neural network, is learned by minimizing an upper bound on the real performance error, which is provided by a forward model (kernel regression or Gaussian process) learned on the currently available data. Most machine learning methods focus on learning the mapping of the function. For inverse models, it is, however, crucial to know the reachable set of the true forward model, since this becomes the domain of the inverse. Therefore, we secondly propose a method to estimate the reachable set of the system. Finally, we develop an active exploration strategy that is based on maximizing a lower bound on the true fill-distance to efficiently generate the data in the high dimensional input space. A key feature of our method is that the resulting learned inverse model provides error bounds on its performance.From an application point of view, this work is motivated by learning to control musculoskeletal systems. In the experiments, we show for both a simulated model of a human arm with six muscles and a real muscle-driven robot that the proposed method is able to learn the reachable set of these systems as well as a policy that enables to accurately control the position.",
        "primary_area": "",
        "author": "Danny Driess;Syn Schmitt;Marc Toussaint;Danny Driess;Syn Schmitt;Marc Toussaint",
        "authorids": "/37085994159;/37949425500;/37528418600;/37085994159;/37949425500;/37528418600",
        "aff": "Machine Learning and Robotics Lab, University of Stuttgart, Germany; Biomechanics and Biorobotics Group, University of Stuttgart, Germany; Machine Learning and Robotics Lab, University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967858/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=129832329930986422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Stuttgart",
        "aff_unique_dep": "Machine Learning and Robotics Lab",
        "aff_unique_url": "https://www.ira.uka.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968522",
        "title": "Active Learning of Reward Dynamics from Hierarchical Queries",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling robots to act according to human preferences across diverse environments is a crucial task, extensively studied by both roboticists and machine learning researchers. To achieve it, human preferences are often encoded by a reward function which the robot optimizes for. This reward function is generally static in the sense that it does not vary with time or the interactions. Unfortunately, such static reward functions do not always adequately capture human preferences, especially, in non-stationary environments: Human preferences change in response to the emergent behaviors of the other agents in the environment. In this work, we propose learning reward dynamics that can adapt in non-stationary environments with several interacting agents. We define reward dynamics as a tuple of reward functions, one for each mode of interaction, and mode-utility functions governing transitions between the modes. Reward dynamics thereby encodes not only different human preferences but also how the preferences change. Our contribution is in the way we adapt preference-based learning into a hierarchical approach that aims at learning not only reward functions but also how they evolve based on interactions. We derive a probabilistic observation model of how people will respond to the hierarchical queries. Our algorithm leverages this model to actively select hierarchical queries that will maximize the volume removed from a continuous hypothesis space of reward dynamics. We empirically demonstrate reward dynamics can match human preferences accurately.",
        "primary_area": "",
        "author": "Chandrayee Basu;Erdem B\u0131y\u0131k;Zhixun He;Mukesh Singhal;Dorsa Sadigh;Chandrayee Basu;Erdem B\u0131y\u0131k;Zhixun He;Mukesh Singhal;Dorsa Sadigh",
        "authorids": "/37085357754;/37086082220;/37088945239;/37271719500;/38234464200;/37085357754;/37086082220;/37088945239;/37271719500;/38234464200",
        "aff": "School of Engineering, Electrical Engineering and Computer Science, UC Merced, 5200 North Lake Road Merced, CA; School of Engineering, Electrical Engineering, Stanford University, 350 Serra Mall, Stanford, CA; School of Engineering, Electrical Engineering and Computer Science, UC Merced, 5200 North Lake Road Merced, CA; School of Engineering, Electrical Engineering and Computer Science, UC Merced, 5200 North Lake Road Merced, CA; School of Engineering, Electrical Engineering, Stanford University, 350 Serra Mall, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968522/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2160421071687727703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "University of California, Merced;Stanford University",
        "aff_unique_dep": "School of Engineering, Electrical Engineering and Computer Science;School of Engineering, Electrical Engineering",
        "aff_unique_url": "https://www.ucmerced.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UC Merced;Stanford",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Merced;Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968613",
        "title": "Active SLAM using Connectivity Graphs as Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots can be considered completely autonomous if they embed active algorithms for Simultaneous Localization And Mapping (SLAM). This means that the robot is able to autonomously, or actively, explore and create a reliable map of the environment, while simultaneously estimating its pose. In this paper, we propose a novel framework to robustly solve the active SLAM problem, in scenarios in which some prior information about the environment is available in the form of a topo-metric graph. This information is typically available or can be easily developed in industrial environments, but it is usually affected by uncertainties. In particular, the distinguishing features of our approach are: the inclusion of prior information for solving the active SLAM problem; the exploitation of this information to pursue active loop closure; the on-line correction of the inconsistencies in the provided data. We present some experiments, that are performed in different simulated environments: the results suggest that our method improves on state-of-the-art approaches, as it is able to deal with a wide variety of possibly large uncertainties.",
        "primary_area": "",
        "author": "Alberto Soragna;Marco Baldini;Dominik Joho;Rainer K\u00fcmmerle;Giorgio Grisetti;Alberto Soragna;Marco Baldini;Dominik Joho;Rainer K\u00fcmmerle;Giorgio Grisetti",
        "authorids": "/37087324952;/37087323084;/37546390100;/37572076600;/37324134600;/37087324952;/37087323084;/37546390100;/37572076600;/37324134600",
        "aff": "Department of Computer Science, La Sapienza University of Rome; KUKA Deutschland GmbH, Augsburg; KUKA Deutschland GmbH, Augsburg; KUKA Deutschland GmbH, Augsburg; Department of Computer Science, La Sapienza University of Rome",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968613/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3878466872925196162&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "La Sapienza University of Rome;KUKA Deutschland GmbH",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.sapienza.uniroma.it;https://www.kuka.com",
        "aff_unique_abbr": "Sapienza;KUKA",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Rome;Augsburg",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "8968517",
        "title": "Active Whisker Placement and Exploration For Rapid Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying objects using sparse tactile sensor arrays requires movement across the surface and the integration of sensory information to support hypotheses. In this study we demonstrate a surface placement control strategy to orient and position a biomimetic tactile whisker array relative to the object surface. This reduces the variance in tactile view, or representation, of each region of the object surface thus relaxing the prior pose dependence for object recall. In addition we evaluate two regional search strategies in an attempt to further improve the robustness and speed of object classification.",
        "primary_area": "",
        "author": "Martin J. Pearson;Mohammed Salman;Martin J. Pearson;Mohammed Salman",
        "authorids": "/38537899700;/37086175427;/38537899700;/37086175427",
        "aff": "Bristol Robotics Laboratory, University of the West of England, Bristol, UK; Bristol Robotics Laboratory, University of Bristol",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968517/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10504927404937197072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of the West of England;University of Bristol",
        "aff_unique_dep": "Bristol Robotics Laboratory;Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.uwe.ac.uk;https://www.bristol.ac.uk",
        "aff_unique_abbr": "UWE;UoB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967764",
        "title": "Actuation and stiffening in fluid-driven soft robots using low-melting-point material",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft material robots offer a number of advantages over traditional rigid robots in applications including human-robot interaction, rehabilitation and surgery. These robots can navigate around obstacles, elongate, squeeze through narrow openings or be squeezed - and they are considered to be inherently safe. The ability to stiffen compliant soft actuators has been achieved by embedding various mechanisms that are generally decoupled from the actuation principle. Miniaturisation becomes challenging due to space limitations which can in turn result in diminution of stiffening effects. Here, we propose to hydraulically actuate soft manipulators with low-melting-point material and, at the same time, be able to switch between a soft and stiff state. Instead of allocating an additional stiffening chamber within the soft robot, one chamber only is used for actuation and stiffening. Low Melting Point Alloy is integrated into the actuation chamber of a single-compartment soft robotic manipulator and the interfaced robotic syringe pump. Temperature change is enabled through embedded nichrome wires. Our experimental results show higher stiffness factors, from 9-12 opposing the motion of curvature, than those previously found for jamming mechanisms incorporated in separate additional chambers, in the range of 2-8 for the same motion.",
        "primary_area": "",
        "author": "Jan Peters;Erin Nolan;Mats Wiese;Mark Miodownik;Sarah Spurgeon;Alberto Arezzo;Annika Raatz;Helge A. Wurdemann;Jan Peters;Erin Nolan;Mats Wiese;Mark Miodownik;Sarah Spurgeon;Alberto Arezzo;Annika Raatz;Helge A. Wurdemann",
        "authorids": "/37086356454;/37087323043;/37086148951;/38185142300;/37270909200;/38233742700;/37394383100;/37991827000;/37086356454;/37087323043;/37086148951;/38185142300;/37270909200;/38233742700;/37394383100;/37991827000",
        "aff": "Institute of Assembly Technology, Leibniz University Hannover, Germany; Department of Mechanical Engineering, University College London, UK; Institute of Assembly Technology, Leibniz University Hannover, Germany; Department of Mechanical Engineering, University College London, UK; Department of Electronic Electrical Engineering, University College London, UK; Department of Surgical Sciences, University of Torino, Italy; Institute of Assembly Technology, Leibniz University Hannover, Germany; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967764/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10914295360671765815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;1;2;0;1",
        "aff_unique_norm": "Leibniz University Hannover;University College London;University of Torino",
        "aff_unique_dep": "Institute of Assembly Technology;Department of Mechanical Engineering;Department of Surgical Sciences",
        "aff_unique_url": "https://www.uni-hannover.de;https://www.ucl.ac.uk;https://www.unito.it",
        "aff_unique_abbr": "LUH;UCL;Unito",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Hannover;;London",
        "aff_country_unique_index": "0;1;0;1;1;2;0;1",
        "aff_country_unique": "Germany;United Kingdom;Italy"
    },
    {
        "id": "8968267",
        "title": "Adaptive Adversarial Videos on Roadside Billboards: Dynamically Modifying Trajectories of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks (DNNs) are being incorporated into various autonomous systems like self-driving cars and robots. However, there is a rising concern about the robustness of these systems because of their susceptibility to adversarial attacks on DNNs. Past research has established that DNNs used for classification and object detection are prone to attacks causing targeted misclassification. In this paper, we show the effectiveness of an adversarial dynamic attack on an end-to-end trained DNN controlling an autonomous vehicle. We launch the attack by installing a billboard on the roadside and displaying videos to approaching vehicles to cause the DNN controller in the vehicle to generate steering commands that cause, for example, unintended lane changes or motion off the road causing accidents. The billboard has an integrated camera estimating the pose of the on-coming vehicle. The approach enables dynamic adversarial perturbation that adapts to the relative pose of the vehicle and uses the dynamics of the vehicle to steer it along adversary-chosen trajectories while being robust to variations in view, lighting, and weather. We demonstrate the effectiveness of the attack on a recently published off-the-shelf end-to-end learning-based autonomous navigation system in a high-fidelity simulator, CARLA (CAR Learning to Act). The proposed approach may also be applied to other systems driven by an end-to-end trained network.",
        "primary_area": "",
        "author": "Naman Patel;Prashanth Krishnamurthy;Siddharth Garg;Farshad Khorrami;Naman Patel;Prashanth Krishnamurthy;Siddharth Garg;Farshad Khorrami",
        "authorids": "/37086214889;/37266317400;/37289176300;/37283001400;/37086214889;/37266317400;/37289176300;/37283001400",
        "aff": "Controls/Robotics Research Laboratory (CRRL), NYU Tandon School of Engineering, 6 MetroTech Center, Brooklyn, NY, USA; Controls/Robotics Research Laboratory (CRRL), NYU Tandon School of Engineering, 6 MetroTech Center, Brooklyn, NY, USA; Center for Cyber-security (CCS), NYU Tandon School of Engineering, 370 Jay St., Brooklyn, NY, USA; Controls/Robotics Research Laboratory (CRRL), NYU Tandon School of Engineering, 6 MetroTech Center, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968267/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5908117980843654969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NYU Tandon School of Engineering",
        "aff_unique_dep": "Controls/Robotics Research Laboratory (CRRL)",
        "aff_unique_url": "https://engineering.nyu.edu",
        "aff_unique_abbr": "NYU Tandon",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968464",
        "title": "Adaptive Assist-as-needed Control Based on Actor-Critic Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In robot-assisted rehabilitation, assist-as-needed (AAN) controllers have been proposed to promote subjects\u2019 active participation, which is thought to lead to better training outcomes. Most of these AAN controllers require a patient-specific manual tuning of the parameters defining the underlying force-field, which typically results in a tedious and time-consuming process. In this paper, we propose a reinforcement-learning-based impedance controller that actively reshapes the stiffness of the force-field to the subject\u2019s performance, while providing assistance only when needed. This adaptability is made possible by correlating the subject\u2019s most recent performance to the ultimate control objective in real-time. In addition, the proposed controller is built upon action dependent heuristic dynamic programming using the actor-critic structure, and therefore does not require prior knowledge of the system model. The controller is experimentally validated with healthy subjects through a simulated ankle mobilization training session using a powered ankle-foot orthosis.",
        "primary_area": "",
        "author": "Yufeng Zhang;Shuai Li;Karen J. Nolan;Damiano Zanotto;Yufeng Zhang;Shuai Li;Karen J. Nolan;Damiano Zanotto",
        "authorids": "/37086481528;/37086085139;/37085501856;/37887906100;/37086481528;/37086085139;/37085501856;/37887906100",
        "aff": "Wearable Robotics Systems (WRS) Lab., Stevens Institute of Technology, Hoboken, NJ, USA; Wearable Robotics Systems (WRS) Lab., Stevens Institute of Technology, Hoboken, NJ, USA; Human Performance and Engineering Research, Kessler Foundation, West Orange, NJ, USA; Wearable Robotics Systems (WRS) Lab., Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968464/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7808785229828959954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stevens Institute of Technology;Kessler Foundation",
        "aff_unique_dep": "Wearable Robotics Systems (WRS) Lab.;Human Performance and Engineering Research",
        "aff_unique_url": "https://www.stevens.edu;https://www.kesslerfoundation.org",
        "aff_unique_abbr": "SIT;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hoboken;West Orange",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967793",
        "title": "Adaptive Deep Path: Efficient Coverage of a Known Environment under Various Configurations",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage path planning of a known environment sees a variety of applications, including cleaning, surveillance, agriculture and 3D printing. Most approaches employ hard-coded heuristics or other application-specific requirements, making them hard to extend to other problem scenarios or \u201cconfigurations,\u201d such as different motion strategies or robot size. This work presents a unifying, general, and adaptive framework, called adaptive deep path (AD Path), for coverage path planning problems under a variety of configurations. It can improve path efficiency with respect to both path length and number of turns, and can flexibly accommodate different problem configuration options. We evaluate AD Path against a state-of-the-art baseline in four complex environments with different configurations. We show that our approach can produce efficient paths; our experimental results show that AD Path can reduce the path length by 21.8% and the number turns by 38.6% on average compared with the baseline.",
        "primary_area": "",
        "author": "Xin Chen;Thomas M. Tucker;Thomas R. Kurfess;Richard Vuduc;Xin Chen;Thomas M. Tucker;Thomas R. Kurfess;Richard Vuduc",
        "authorids": "/37086044255;/37085859326;/37344313200;/37281842800;/37086044255;/37085859326;/37344313200;/37281842800",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Tucker Innovations Inc., Waxhaw, NC, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967793/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16522510900092139607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Tucker Innovations Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;",
        "aff_unique_abbr": "Georgia Tech;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967561",
        "title": "Adaptive Leader-Follower Formation Control and Obstacle Avoidance via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a deep reinforcement learning (DRL) methodology for the tracking, obstacle avoidance, and formation control of nonholonomic robots. By separating vision-based control into a perception module and a controller module, we can train a DRL agent without sophisticated physics or 3D modeling. In addition, the modular framework averts daunting retrains of an image-to-action end-to-end neural network, and provides flexibility in transferring the controller to different robots. First, we train a convolutional neural network (CNN) to accurately localize in an indoor setting with dynamic foreground/background. Then, we design a new DRL algorithm named Momentum Policy Gradient (MPG) for continuous control tasks and prove its convergence. We also show that MPG is robust at tracking varying leader movements and can naturally be extended to problems of formation control. Leveraging reward shaping, features such as collision and obstacle avoidance can be easily integrated into a DRL controller.",
        "primary_area": "",
        "author": "Yanlin Zhou;Fan Lu;George Pu;Xiyao Ma;Runhan Sun;Hsi-Yuan Chen;Xiaolin Li;Yanlin Zhou;Fan Lu;George Pu;Xiyao Ma;Runhan Sun;Hsi-Yuan Chen;Xiaolin Li",
        "authorids": "/37087324040;/37087324304;/37087322614;/37089468865;/37087325292;/37085657928;/37065193400;/37087324040;/37087324304;/37087322614;/37089468865;/37087325292;/37085657928;/37065193400",
        "aff": "National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory, University of Florida, Gainesville, Florida, USA; National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory, University of Florida, Gainesville, Florida, USA; National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory, University of Florida, Gainesville, Florida, USA; National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory, University of Florida, Gainesville, Florida, USA; Department of Mechanical and Aerospace Engineering, University of Florida, Gainesville, FL, USA; Department of Mechanical and Aerospace Engineering, University of Florida, Gainesville, FL, USA; National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory, University of Florida, Gainesville, Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967561/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9526901141256344279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "National Science Foundation Center for Big Learning, Large-scale Intelligent Systems Laboratory",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Gainesville",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968614",
        "title": "Adaptive Loss Balancing for Multitask Learning of Object Instance Recognition and 3D Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Object instance recognition and 3D pose estimation are important elements in robot vision technology. State-of-the-art methods improve the accuracy of both instance recognition and pose estimation using multitask learning. These methods use unified balancing parameters to integrate the loss of each task, which means task difficulties are the same for all objects. However, the method we propose can adjust the balancing parameters for each object. This idea is based on the assumption that task difficulties are different for each object, since the distinctiveness of object instances and poses depends on their appearance and shape. Our method sequentially estimates task difficulties for CNN based on the amount of loss change and calculates balancing parameters for each object. Our experiments show that our method improves the accuracy of both object instance recognition and pose estimation compared with state-of-the-art methods using the common LineMOD dataset.",
        "primary_area": "",
        "author": "Takashi Hosono;Yuuna Hoshi;Jun Shimamura;Atsushi Sagata;Takashi Hosono;Yuuna Hoshi;Jun Shimamura;Atsushi Sagata",
        "authorids": "/37089466199;/37086280519;/37331263600;/37352492500;/37089466199;/37086280519;/37331263600;/37352492500",
        "aff": "NTT Media Intelligence Laboratories, NTT Corporation, Kanagawa, Japan; College of Computing, Georgia Institute of Technology, Atlanta, USA; NTT Media Intelligence Laboratories, NTT Corporation, Kanagawa, Japan; NTT Media Intelligence Laboratories, NTT Corporation, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968614/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12734752538858304503&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "NTT Corporation;Georgia Institute of Technology",
        "aff_unique_dep": "Media Intelligence Laboratories;College of Computing",
        "aff_unique_url": "https://www.ntt.co.jp;https://www.gatech.edu",
        "aff_unique_abbr": "NTT;Georgia Tech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "8967888",
        "title": "Adaptive Navigation Scheme for Optimal Deep-Sea Localization Using Multimodal Perception Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater robot interventions require a high level of safety and reliability. A major challenge to address is a robust and accurate acquisition of localization estimates, as it is a prerequisite to enable more complex tasks, e.g. floating manipulation and mapping. State-of-the-art navigation in commercial operations, such as oil& gas production (OGP), rely on costly instrumentation. These can be partially replaced or assisted by visual navigation methods, especially in deep-sea scenarios where equipment deployment has high costs and risks. Our work presents a multimodal approach that adapts state-of-the-art methods from on-land robotics, i.e., dense point cloud generation in combination with plane representation and registration, to boost underwater localization performance. A (a) two-stage navigation scheme is proposed that initially generates a coarse probabilistic map of the workspace, which is used to filter noise from computed point clouds and planes in the second stage. Furthermore, an adaptive decision-making approach is introduced that determines which perception cues to incorporate into the localization filter to optimize accuracy and computation performance. Our approach is investigated first in simulation and then validated with data from field trials in OGP monitoring and maintenance scenarios.",
        "primary_area": "",
        "author": "Arturo Gomez Chavez;Qingwen Xu;Christian A. Mueller;S\u00f6ren Schwertfeger;Andreas Birk;Arturo Gomez Chavez;Qingwen Xu;Christian A. Mueller;S\u00f6ren Schwertfeger;Andreas Birk",
        "authorids": "/37085698090;/37087243310;/37085440944;/37391715800;/37283236400;/37085698090;/37087243310;/37085440944;/37391715800;/37283236400",
        "aff": "Robotics Group, Computer Science & Electrical Engineering, Jacobs University, Bremen, Germany; School of Information Science Technology of ShanghaiTech University; Robotics Group, Computer Science & Electrical Engineering, Jacobs University, Bremen, Germany; School of Information Science Technology of ShanghaiTech University; Robotics Group, Computer Science & Electrical Engineering, Jacobs University, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967888/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14131149621590840510&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Jacobs University;ShanghaiTech University",
        "aff_unique_dep": "Computer Science & Electrical Engineering;School of Information Science Technology",
        "aff_unique_url": "https://www.jacobs-university.de;https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "Jacobs U;ShanghaiTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bremen;",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "8967720",
        "title": "Adaptive Neural Admittance Control for Collision Avoidance in Human-Robot Collaborative Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposed an adaptive neural admittance control strategy for collision avoidance in human-robot collaborative tasks. In order to ensure that the robot end-effector can avoid collisions with surroundings, robot should be operated compliantly by human within a constrained task space. An impedance model and a soft saturation function are employed to generate a differentiable reference trajectory. Then, adaptive neural network control with position constraint, based on integral barrier Lyapunov function (IBLF), is designed to achieve precise tracking while guaranteeing constrained satisfaction. Utilizing Lyapunov stability principles, we prove that semi-globally uniformly bounded stability is guaranteed for all states of the closed-loop system. At last, the effectiveness of the proposed algorithm is verified on a Baxter robot experimental platform. Collisions with surroundings can be avoided in human-robot collaborative tasks.",
        "primary_area": "",
        "author": "Xinbo Yu;Wei He;Chengqian Xue;Bin Li;Long Cheng;Chenguang Yang;Xinbo Yu;Wei He;Chengqian Xue;Bin Li;Long Cheng;Chenguang Yang",
        "authorids": "/37086326687;/37532768100;/37086416648;/37089266127;/37292880600;/37404783000;/37086326687;/37532768100;/37086416648;/37089266127;/37292880600;/37404783000",
        "aff": "School of Automation and Electrical Engineering, Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, China; School of Automation and Electrical Engineering, Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, China; School of Automation and Electrical Engineering, Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, China; School of Automation and Electrical Engineering, Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Bristol Robotics Laboratory, University of the West of England, Bristol, U.K",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967720/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8643085719215488555&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "University of Science and Technology Beijing;Chinese Academy of Sciences;University of the West of England",
        "aff_unique_dep": "School of Automation and Electrical Engineering;Institute of Automation;Bristol Robotics Laboratory",
        "aff_unique_url": "http://www.ustb.edu.cn;http://www.ia.cas.cn;https://www.uwe.ac.uk",
        "aff_unique_abbr": "USTB;CAS;UWE",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Bristol",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "8967713",
        "title": "Adaptive Outcome Selection for Planning with Reduced Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Reduced models allow autonomous robots to cope with the complexity of planning in stochastic environments by simplifying the model and reducing its accuracy. The solution quality of a reduced model depends on its fidelity. We present 0/1 reduced model that selectively improves model fidelity in certain states by switching between using a simplified deterministic model and the full model, without significantly compromising the run time gains. We measure the reduction impact for a reduced model based on the values of the ignored outcomes and use this as a heuristic for outcome selection. Finally, we present empirical results of our approach on three different domains, including an electric vehicle charging problem using real-world data from a university campus.",
        "primary_area": "",
        "author": "Sandhya Saisubramanian;Shlomo Zilbertsein;Sandhya Saisubramanian;Shlomo Zilbertsein",
        "authorids": "/37087104876;/37087325339;/37087104876;/37087325339",
        "aff": "College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967713/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9107448184740256436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967679",
        "title": "Adaptive Trajectory Planning and optimization at Limits of Handling",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we tackle the problem of trajectory planning and control of a vehicle under locally varying traction limitations, in the presence of suddenly appearing obstacles. We employ concepts from adaptive model predictive control for run-time adaptation of tire force constraints that are imposed by local traction conditions. To solve the resulting optimization problem for real-time control synthesis with such time varying constraints, we propose a novel numerical scheme based on Real Time Iteration Sequential Quadratic Programming (RTI-SQP), which we call Sampling Augmented Adaptive RTI (SAA-RTI). Sampling augmentation of conventional RTI-SQP provides additional feasible candidate trajectories for warm-starting the optimization procedure. Thus, the proposed SAA-RTI algorithm enables real time constraint adaptation and reduces sensitivity to local minima. Through extensive numerical simulations we demonstrate that our method increases the vehicle's capacity to avoid accidents in scenarios with unanticipated obstacles and locally varying traction, compared to equivalent non-adaptive control schemes and traditional planning and tracking approaches.",
        "primary_area": "",
        "author": "Lars Svensson;Monimoy Bujarbaruah;Nitin R. Kapania;Martin T\u00f6rngren;Lars Svensson;Monimoy Bujarbaruah;Nitin R. Kapania;Martin T\u00f6rngren",
        "authorids": "/37086168669;/37086351739;/37085444708;/37266910300;/37086168669;/37086351739;/37085444708;/37266910300",
        "aff": "Mechatronics and Embedded Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Model Predictive Control Laboratory, University of California, Berkeley, USA; Dynamic Design Laboratory, Stanford University, USA; Mechatronics and Embedded Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967679/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3723450836737432395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;University of California, Berkeley;Stanford University",
        "aff_unique_dep": "Mechatronics and Embedded Control Systems;Model Predictive Control Laboratory;Dynamic Design Laboratory",
        "aff_unique_url": "https://www.kth.se;https://www.berkeley.edu;https://www.stanford.edu",
        "aff_unique_abbr": "KTH;UC Berkeley;Stanford",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Stockholm;Berkeley;Stanford",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "8970476",
        "title": "Adaptive Unscented Kalman Filter-based Disturbance Rejection With Application to High Precision Hydraulic Robotic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel nonlinear disturbance rejection approach for high precision model-based control of hydraulic robots. While most disturbance rejection approaches make use of observers, we propose a novel adaptive Unscented Kalman Filter to estimate the disturbances in an unbiased minimum-variance sense. The filter is made adaptive such that there is no need to tune the covariance matrix for the disturbance estimation. Furthermore, whereas most model-based control approaches require the linearization of the system dynamics, our method is nonlinear which means that no linearization is required. Through extensive simulations as well as real hardware experiments, we demonstrate that our proposed approach can achieve high precision tracking and can be readily applied to most robotic systems even in the presence of uncertainties and external disturbances. The proposed approach is also compared to existing approaches which demonstrates its superior tracking performance.",
        "primary_area": "",
        "author": "Peng Lu;Timothy Sandy;Jonas Buchli;Peng Lu;Timothy Sandy;Jonas Buchli",
        "authorids": "/37087243038;/37085800060;/37542866900;/37087243038;/37085800060;/37542866900",
        "aff": "Interdisciplinary Division of Aeronautical and Aviation Engineering, Hong Kong Polytechnic University, HKSAR, China; Agile & Dexterous Robotics Lab, Institute of Robotics and Intelligent Systems, ETH Z\u00fcrich, Switzerland; Agile & Dexterous Robotics Lab, Institute of Robotics and Intelligent Systems, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8970476/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8937217871278291787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Hong Kong Polytechnic University;ETH Zurich",
        "aff_unique_dep": "Interdisciplinary Division of Aeronautical and Aviation Engineering;Institute of Robotics and Intelligent Systems",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.ethz.ch",
        "aff_unique_abbr": "PolyU;ETH",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Z\u00fcrich",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;Switzerland"
    },
    {
        "id": "8967976",
        "title": "Adaptive Vision-Based Control for Rope-Climbing Robot Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "While the mechanism of Rope-Climbing provides much flexibility, it opens up challenges to the development of the controller for Robotic Manipulator installed on Rope-Climbing robot(RCR), which is called Rope-Climbing Robot Manipulator(RCRM) here. In particular, the deformable nature of the rope results in the vibration to the manipulator and hence affects the positioning of the end effector. In this paper, a new adaptive vision-based controller is proposed for RCRM, which enables the robot to carry out the high-accuracy task under the unknown vibration from the rope. The proposed controller guarantees the performance of the robot in twofold. First, the control problem is directly formulated in the image space such that the exact spatial relationship between the moving base of the manipulator (due to the vibrating rope) and the target (e.g. the wall) is not required. Second, novel adaptation laws are developed to estimate the vibration from the rope online and are cancelled out in the robot control input to stabilize the end effector. The stability of the closed-loop system is rigorously proved with Lyapunov methods, and experimental results are presented to illustrate the performance of the proposed controller.",
        "primary_area": "",
        "author": "Guangli Sun;Xiang Li;Peng Li;Linzhu Yue;Zhen Yu;Yang Zhou;Yun-Hui Liu;Guangli Sun;Xiang Li;Peng Li;Linzhu Yue;Zhen Yu;Yang Zhou;Yun-Hui Liu",
        "authorids": "/37086356287;/37280877200;/132178398280570;/37087053034;/37087244276;/37086348797;/37279412600;/37086356287;/37280877200;/132178398280570;/37087053034;/37087244276;/37086348797;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Automation, Tsinghua University; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen); Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967976/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11122806769016428652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Tsinghua University;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Automation;School of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.tsinghua.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "CUHK;THU;HIT",
        "aff_campus_unique_index": "0;2;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967807",
        "title": "Adaptive swept volumes generation for human-robot coexistence using Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Letting humans and robots share a common space for collaboration is considered a consolidated practice. The trajectories followed by the robot must be safe for the human mate, especially when the robot holds dangerous tools or parts. At the same time, the productivity must be preserved, without imposing too restrictive limitations on the robot's movements. This article proposes the use of Gaussian Processes to predict the motion of an operator in a robotic cell, with the aim of controlling the robot speed and avoid collisions. An adaptive approach is proposed and the model for the human motion is persistently re-updated. The resulting approach will be demonstrated to be less conservative than previous ones, while at the same time to preserve the safety of the operator. Real experiments have been conducted on the 7 d.o.f. ABB YuMi robot.",
        "primary_area": "",
        "author": "Andrea Casalino;Alberto Brameri;Andrea Maria Zanchettin;Paolo Rocco;Andrea Casalino;Alberto Brameri;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086208346;/37087322604;/37546427600;/37274178600;/37086208346;/37087322604;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967807/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10904869332133805072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967581",
        "title": "Adjusting Weight of Action Decision in Exploration for Logistics Warehouse Picking Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this study is for a robot to learn picking motions in a logistics warehouse environment. The picking operation performed by a robot often fails owing to the inclination of items placed on a shelf, as well as the minimum clearance between the products and their vinyl packaging. Therefore, we considered acquiring a specific motion trajectory by reinforcement learning. However, because numerous types of items are handled in logistics warehouses, efficient learning is required. Therefore, in this research, we propose a method to efficiently exploration for learning picking an object by determining a focus exploration area for learning based on previous results of different objects.",
        "primary_area": "",
        "author": "Kato Yusuke;Nakamura Tomoaki;Nagai Takayuki;Yamanobe Natsuki;Nagata Kazuyuki;Ozawa Jun;Kato Yusuke;Nakamura Tomoaki;Nagai Takayuki;Yamanobe Natsuki;Nagata Kazuyuki;Ozawa Jun",
        "authorids": "/37087324999;/37087325197;/37087321898;/37087324500;/37087322712;/37087323885;/37087324999;/37087325197;/37087321898;/37087324500;/37087322712;/37087323885",
        "aff": "Panasonic Corp., Tokyo, Japan; University of Electro-Communications, Tokyo, Japan; University of Electro-Communications, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967581/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:JvgrbFKkiZUJ:scholar.google.com/&scioq=Adjusting+Weight+of+Action+Decision+in+Exploration+for+Logistics+Warehouse+Picking+Learning&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;2",
        "aff_unique_norm": "Panasonic Corporation;University of Electro-Communications;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.panasonic.com;https://www.uec.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Panasonic;UEC;AIST",
        "aff_campus_unique_index": "0;0;0;1;1;1",
        "aff_campus_unique": "Tokyo;Ibaraki",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967595",
        "title": "Advanced Autonomy on a Low-Cost Educational Drone Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "PiDrone is a quadrotor platform created to accompany an introductory robotics course. Students build an autonomous flying robot from scratch and learn to program it through assignments and projects. Existing educational robots do not have significant autonomous capabilities, such as high-level planning and mapping. We present a hardware and software framework for an autonomous aerial robot, in which all software for autonomy can run onboard the drone, implemented in Python. We present an Unscented Kalman Filter (UKF) for accurate state estimation. Next, we present an implementation of Monte Carlo (MC) Localization and FastSLAM for Simultaneous Localization and Mapping (SLAM). The performance of UKF, localization, and SLAM is tested and compared to ground truth, provided by a motion-capture system. Our evaluation demonstrates that our autonomous educational framework runs quickly and accurately on a Raspberry Pi in Python, making it ideal for use in educational settings.",
        "primary_area": "",
        "author": "Luke Eller;Th\u00e9o Gu\u00e9rin;Baichuan Huang;Garrett Warren;Sophie Yang;Josh Roy;Stefanie Tellex;Luke Eller;Th\u00e9o Gu\u00e9rin;Baichuan Huang;Garrett Warren;Sophie Yang;Josh Roy;Stefanie Tellex",
        "authorids": "/37087322698;/37087324555;/37086937298;/37087323864;/37087322412;/37086582122;/37402794800;/37087322698;/37087324555;/37086937298;/37087323864;/37087322412;/37086582122;/37402794800",
        "aff": "Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967595/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17170552199364022911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968555",
        "title": "Aerial Animal Biometrics: Individual Friesian Cattle Recovery and Visual Identification via an Autonomous UAV with Onboard Deep Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a computationally-enhanced M100 UAV platform with an onboard deep learning inference system for integrated computer vision and navigation. The system is able to autonomously find and visually identify by coat pattern individual Holstein Friesian cattle in freely moving herds. We propose an approach that utilises three deep convolutional neural network architectures running live onboard the aircraft: (1) a YOLOv2-based species detector, (2) a dual-stream deep network delivering exploratory agency, and (3) an InceptionV3-based biometric long-term recurrent convolutional network for individual animal identification. We evaluate the performance of each of the components offline, and also online via real-world field tests comprising 147 minutes of autonomous low altitude flight in a farm environment over a dispersed herd of 17 heifer dairy cows. We report error-free identification performance on this online experiment. The presented proof-of-concept system is the first of its kind. It represents a practical step towards autonomous biometric identification of individual animals from the air in open pasture environments for tag-less AI support in farming and ecology.",
        "primary_area": "",
        "author": "William Andrew;Colin Greatwood;Tilo Burghardt;William Andrew;Colin Greatwood;Tilo Burghardt",
        "authorids": "/37086299844;/37086279678;/38229802700;/37086299844;/37086279678;/38229802700",
        "aff": "Department of Computer Science, University of Bristol, United Kingdom (UK); Department of Airspace Engineering, University of Bristol, United Kingdom (UK); Department of Computer Science, University of Bristol, United Kingdom (UK)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968555/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3516557264372794250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "Bristol",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967611",
        "title": "Aerial Robot Control in Close Proximity to Ceiling: A Force Estimation-based Nonlinear MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "Being motivated by ceiling inspection applications via unmanned aerial vehicles (UAVs) which require close proximity flight to surfaces, a systematic control approach enabling safe and accurate close proximity flight is proposed in this work. There are two main challenges for close proximity flights: (i) the trust characteristics varies drastically for the different distance from the ceiling which results in a complex nonlinear dynamics; (ii) the system needs to consider physical and environmental constraints to safely fly in close proximity. To address these challenges, a novel framework consisting of a constrained optimization-based force estimation and an optimization-based nonlinear controller is proposed. Experimental results illustrate that the performance of the proposed control approach can stabilize UAV down to 1 cm distance to the ceiling. Furthermore, we report that the UAV consumes up to 12.5% less power when it is operated 1 cm distance to ceiling, which is promising potential for more battery-efficient inspection flights.",
        "primary_area": "",
        "author": "Basaran Bahadir Kocer;Mehmet Efe Tiryaki;Mahardhika Pratama;Tegoeh Tjahjowidodo;Gerald Gim Lee Seet;Basaran Bahadir Kocer;Mehmet Efe Tiryaki;Mahardhika Pratama;Tegoeh Tjahjowidodo;Gerald Gim Lee Seet",
        "authorids": "/37072753900;/37087324110;/38233985400;/37568813000;/37325857600;/37072753900;/37087324110;/38233985400;/37568813000;/37325857600",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; School of Computer Science and Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967611/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17841119644777241041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Nanyang Technological University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;Physical Intelligence Department",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "NTU;MPI-IS",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Singapore;Stuttgart",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Singapore;Germany"
    },
    {
        "id": "8968596",
        "title": "Affordance Learning for End-to-End Visuomotor Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Training end-to-end deep robot policies requires a lot of domain-, task-, and hardware-specific data, which is often costly to provide. In this work, we propose to tackle this issue by employing a deep neural network with a modular architecture, consisting of separate perception, policy, and trajectory parts. Each part of the system is trained fully on synthetic data or in simulation. The data is exchanged between parts of the system as low-dimensional latent representations of affordances and trajectories. The performance is then evaluated in a zero-shot transfer scenario using Franka Panda robot arm. Results demonstrate that a low-dimensional representation of scene affordances extracted from an RGB image is sufficient to successfully train manipulator policies. We also introduce a method for affordance dataset generation, which is easily generalizable to new tasks, objects and environments, and requires no manual pixel labeling.",
        "primary_area": "",
        "author": "Aleksi H\u00e4m\u00e4l\u00e4inen;Karol Arndt;Ali Ghadirzadeh;Ville Kyrki;Aleksi H\u00e4m\u00e4l\u00e4inen;Karol Arndt;Ali Ghadirzadeh;Ville Kyrki",
        "authorids": "/37087323562;/37087322085;/37085340524;/37274001900;/37087323562;/37087322085;/37085340524;/37274001900",
        "aff": "Aalto University, Espoo, Finland; Aalto University, Espoo, Finland; Aalto University, Espoo, Finland; Aalto University, Espoo, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968596/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7670289181984295731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Espoo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "8967743",
        "title": "Agent Prioritization for Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous navigation, a planning system reasons about other agents to plan a safe and plausible trajectory. Before planning starts, agents are typically processed with computationally intensive models for recognition, tracking, motion estimation and prediction. With limited computational resources and a large number of agents to process in real time, it becomes important to efficiently rank agents according to their impact on the decision making process. This allows spending more time processing the most important agents. We propose a system to rank agents around an autonomous vehicle (AV) in real time. We automatically generate a ranking data set by running the planner in simulation on real-world logged data, where we can afford to run more accurate and expensive models on all the agents. The causes of various planner actions are logged and used for assigning ground truth importance scores. The generated data set can be used to learn ranking models. In particular, we show the utility of combining learned features, via a convolutional neural network, with engineered features designed to capture domain knowledge. We show the benefits of various design choices experimentally. When tested on real AVs, our system demonstrates the capability of understanding complex driving situations.",
        "primary_area": "",
        "author": "Khaled S. Refaat;Kai Ding;Natalia Ponomareva;St\u00e9phane Ross;Khaled S. Refaat;Kai Ding;Natalia Ponomareva;St\u00e9phane Ross",
        "authorids": "/37540952100;/37087322424;/37870711500;/37089038098;/37540952100;/37087322424;/37870711500;/37089038098",
        "aff": "Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA; Google Research, Mountain View, CA, USA; Waymo, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967743/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15478616192587171947&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Waymo;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://waymo.com;https://research.google",
        "aff_unique_abbr": "Waymo;Google",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968006",
        "title": "Agile Standing-up Control of Humanoids: Energy-based Reactive Contact Wrench Optimization with Strict Dynamic Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a dynamic whole-body control method for humanoids to render agile and stable standing-up motion based on energy concepts. First, to cope with the standing-up problem with multiple contacts in hierarchical tasks, an enhanced operational-space based whole-body control (WBC) framework is proposed, which offers optimal torque resolutions guaranteeing strict dynamic consistency with inequality constraints formulated by quadratic programming. Second, agile standing-up control strategy with dynamic push and rise actions is newly developed based on the notion of the total energy. The optimal pushing wrenches at contacts are computed to obtain sufficient energy to accelerate the center-of-mass (CoM) of the robot as quick as possible, and the total energy is then controlled to attain rapid rise-up motion and to stabilize the body of the robot. Consequently, the robot can effectively and actively stand up to recover from a certain pose in which cannot be accomplished by any quasi-static motion. The proposed method is numerically experimented and validated with dynamic parameters from the real humanoid COMAN+, fulfilling different types of standing-up actions.",
        "primary_area": "",
        "author": "Yisoo Lee;Nikos Tsagarakis;Jinoh Lee;Yisoo Lee;Nikos Tsagarakis;Jinoh Lee",
        "authorids": "/38240852700;/37295830800;/37085391573;/38240852700;/37295830800;/37085391573",
        "aff": "Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968006/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18271978997322544165&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Advanced Robotics",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967963",
        "title": "Air To Ground Collaboration For Energy-efficient Path Planning For Ground Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a fundamental motion planning problem of navigating a ground robot to a goal position with minimum energy consumption. Most existing solutions for this problem require an energy consumption model as a function of the environment and the robot motion. Obtaining such models is difficult which prevents the practical applicability of path planning algorithms for energy optimization. To address this issue, we present a new approach based on the assumption that the energy consumption for the ground robot is correlated with ground appearance. The first main contribution of this paper is the validation of the ground appearance assumption by experiments using actual energy consumption data obtained by ground robots. We then show how aerial images collected by an unmanned aerial vehicle can be used to generate the energy cost map of a given environment, which can further be used for planning energy-efficient paths for ground robots.",
        "primary_area": "",
        "author": "Minghan Wei;Volkan Isler;Minghan Wei;Volkan Isler",
        "authorids": "/37086455365;/37298487800;/37086455365;/37298487800",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, United States; Department of Computer Science and Engineering, University of Minnesota, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967963/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13344738391227438253&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968156",
        "title": "An Adaptive Velocity Obstacle Avoidance Algorithm for Autonomous Surface Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new algorithm for a real-time obstacle avoidance for autonomous surface vehicles (ASV) that is capable of undertaking preemptive actions in complex and challenging scenarios. The algorithm is called adaptive velocity obstacle avoidance (AVOA) and takes into consideration the kinematic and dynamic constraints of autonomous vessels along with a protective zone concept to determine the safe crossing distance to obstacles. A configuration space that includes both the position and velocity of static or dynamic elements within the field-of-view of the ASV is supporting a particle swarm optimization procedure that minimizes the risk of harm and the deviation towards a predefined course while generating a navigation path with capabilities to prevent potential collisions. Extensive experiments demonstrate the ability of AVOA to select a velocity estimative for ASVs that originates a smoother, safer and, at least, two times more effective collision-free path when compared to existing techniques.",
        "primary_area": "",
        "author": "Daniel Filipe Campos;An\u00edbal Matos;Andry Maykol Pinto;Daniel Filipe Campos;An\u00edbal Matos;Andry Maykol Pinto",
        "authorids": "/38297126100;/37355049200;/37076195300;/38297126100;/37355049200;/37076195300",
        "aff": "Center for Robotics and Autonomous Systems, INESC TEC and Faculty of Engineering of University of Porto, Rua Dr. Roberto Frias, Portugal; Center for Robotics and Autonomous Systems, INESC TEC and Faculty of Engineering of University of Porto, Rua Dr. Roberto Frias, Portugal; Center for Robotics and Autonomous Systems, INESC TEC and Faculty of Engineering of University of Porto, Rua Dr. Roberto Frias, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968156/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2354614526167848581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INESC TEC",
        "aff_unique_dep": "Center for Robotics and Autonomous Systems",
        "aff_unique_url": "https://www.inesctec.pt",
        "aff_unique_abbr": "INESC TEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "8967949",
        "title": "An Approach of Facilitated Investigation of Active Self-healing Tension Transmission System Oriented for Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-healing robotics has been of considerable interest. We believe the function will have a major role in legged robots as a typical high-load application of robotics. Some pioneering works have been ongoing on self-healing soft robots. However, the development of large load self-healing component and its system integration with a life-sized legged robot is a challenging task. This study is to try the problem by a constructing self-healing component oriented for facilitated investigation. Proposed part enhances visibility and manufacturing by specializing tension transmission system. The developed module was evaluated by several experiments. First, healing visualization experiment was conducted to evaluate healing progress. In addition, the module's strength was tested using a motor-driven tendon module previously developed in our laboratory. Results of these experiments suggested that the stirring process have a major role in performing self-healing behaviour. Finally, we conducted a preliminary experiment on a tendon-driven legged robot. The experiment demonstrated that the module functioned in a real robot once.",
        "primary_area": "",
        "author": "Shinsuke Nakashima;Takuma Shirai;Kento Kawaharazuka;Yuki Asano;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Shinsuke Nakashima;Takuma Shirai;Kento Kawaharazuka;Yuki Asano;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086104250;/38237530400;/37086101930;/38238750500;/38242437800;/37280639000;/37286658200;/37086104250;/38237530400;/37086101930;/38238750500;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967949/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11585245830681307168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967666",
        "title": "An Approximation-Free Simple Control Scheme for Uncertain Quadrotor Systems: Theory and Validations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a simple tracking control scheme is proposed for quadrotor systems with uncertain dynamics. It precludes the necessity for prohibitive analytic computation of the derivatives of the desired (virtual) attitude that is typically employed in controlling quadrotor systems. Moreover, this control scheme is approximation-free in the sense that it does not incorporate any adaptive laws, observers, or command filters to compensate for unknown parameters in the dynamics and the absence of the analytic differentiation, thus exhibiting remarkably low complexity levels and making its implementation straightforward. The thrust saturation is approached in the position control design which also enables the singularity in desired attitude extraction to be avoided entirely. It is demonstrated that based on the proposed scheme, the tracking errors can be made arbitrarily small by appropriately selecting design parameters. Extensive simulations and experiments are performed to verify the effectiveness of our scheme.",
        "primary_area": "",
        "author": "Gang Wang;Weixin Yang;Na Zhao;Peng Li;Yantao Shen;Chaoli Wang;Gang Wang;Weixin Yang;Na Zhao;Peng Li;Yantao Shen;Chaoli Wang",
        "authorids": "/37085379673;/37086437281;/37086001139;/132178398280570;/37274462800;/37405889100;/37085379673;/37086437281;/37086001139;/132178398280570;/37274462800;/37405889100",
        "aff": "Institute of Machine Intelligence, University of Shanghai for Science and Technology, Shanghai, China; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; HIT, Shenzhen, China; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Control Science and Engineering, University of Shanghai for Science and Technology, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967666/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13648398468688067478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "University of Shanghai for Science and Technology;University of Nevada, Reno;Harbin Institute of Technology",
        "aff_unique_dep": "Institute of Machine Intelligence;Department of Electrical & Biomedical Engineering;",
        "aff_unique_url": "https://www.usst.edu.cn;https://www.unr.edu;http://www.hit.edu.cn/",
        "aff_unique_abbr": "USST;UNR;HIT",
        "aff_campus_unique_index": "0;1;1;2;1;0",
        "aff_campus_unique": "Shanghai;Reno;Shenzhen",
        "aff_country_unique_index": "0;1;1;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968594",
        "title": "An Asynchronous Multi-Body Simulation Framework for Real-Time Dynamics, Haptics and Learning with Application to Surgical Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical robots for laparoscopy consist of several patient side slave manipulators that are controlled via surgeon operated master telemanipulators. Commercial surgical robots do not perform any sub-tasks - even of repetitive or noninvasive nature - autonomously or provide intelligent assistance. While this is primarily due to safety and regulatory reasons, the state of such automation intelligence also lacks the reliability and robustness for use in high-risk applications. Recent developments in continuous control using Artificial Intelligence and Reinforcement Learning have prompted growing research interest in automating mundane sub-tasks. To build on this, we present an inspired Asynchronous Framework which incorporates realtime dynamic simulation - manipulable with the masters of a surgical robot and various other input devices - and interfaces with learning agents to train and potentially allow for the execution of shared sub-tasks. The scope of this framework is generic to cater to various surgical (as well as non-surgical) training and control applications. This scope is demonstrated by examples of multi-user and multi-manual applications which allow for realistic interactions by incorporating distributed control, shared task allocation and a well-defined communication pipe-line for learning agents. These examples are discussed in conjunction with the design philosophy, specifications, system-architecture and metrics of the Asynchronous Framework and the accompanying Simulator. We show the stability of Simulator while achieving real-time dynamic simulation and interfacing with several haptic input devices and a training agent at the same time.",
        "primary_area": "",
        "author": "Adnan Munawar;Gregory S. Fischer;Adnan Munawar;Gregory S. Fischer",
        "authorids": "/37086207599;/37398771000;/37086207599;/37398771000",
        "aff": "Department of Robotics Engineering, Worcester Polytechnic Institute, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968594/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=936591892996859312&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967973",
        "title": "An Augmented Reality Interface for Human-Robot Interaction in Unconstrained Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots start to become ubiquitous in the personal workspace, it is necessary to have simple and intuitive interfaces to interact with them. In this paper, we propose an augmented reality (AR) interface for human-robot interaction (HRI) in a shared working environment. By fusing marker-based and markerless AR technologies, a mobile AR interface is created that enables a smartphone to detect planar surfaces and localize a manipulator robot in its working environment while obviating the need for a controlled or constrained environment. The AR interface and robot manipulator are integrated to render a system that enables users to perform pick-and-place task effortlessly. Specifically, a smartphone-based AR application is developed that allows a user to select any location within the robot's workspace by merely touching on the smartphone screen. Virtual objects, rendered at user-selected locations, are used to determine the pick and place locations of objects in the real world. The virtual object's start and end points, originally specified in the smartphone camera coordinate frame, are transformed into the robot coordinate frame for the robot manipulator to autonomously perform the assigned task. A user study is conducted with participants to evaluate the system performance and user experience. The results show that the proposed AR interface is user-friendly and intuitive to operate the robot, and it allows users to communicate their intentions through the virtual object easily.",
        "primary_area": "",
        "author": "Sonia Mary Chacko;Vikram Kapila;Sonia Mary Chacko;Vikram Kapila",
        "authorids": "/37087236102;/37267175100;/37087236102;/37267175100",
        "aff": "Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA; Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967973/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10157861569036940262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "NYU Tandon School of Engineering",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://engineering.nyu.edu",
        "aff_unique_abbr": "NYU Tandon",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968102",
        "title": "An Automated Learning-Based Procedure for Large-scale Vehicle Dynamics Modeling on Baidu Apollo Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "In the autonomous driving industry, vehicle dynamic models are important to control-in-the-loop simulations. For current commercial self-driving simulators, vehicle dynamic models are expressed explicitly by sophisticated analytical equations, which are accurate but difficult to build and expensive to scale to fleets of vehicles of different brands. In this paper, we introduce a highly automated learning-based vehicle dynamic modeling procedure, which has been deployed on Baidu Apollo self-driving platform, to support cross-vehicle data-driven applications on a large scale. Compared with our previous analytical models, the end-to-end learning-based dynamic models can achieve high accuracy with significantly reduced re-development effort.",
        "primary_area": "",
        "author": "Jiaxuan Xu;Qi Luo;Kecheng Xu;Xiangquan Xiao;Siyang Yu;Jiangtao Hu;Jinghao Miao;Jingao Wang;Jiaxuan Xu;Qi Luo;Kecheng Xu;Xiangquan Xiao;Siyang Yu;Jiangtao Hu;Jinghao Miao;Jingao Wang",
        "authorids": "/37087324378;/37087321741;/37087323360;/37087325091;/37087321742;/37087107420;/37088643032;/37087324542;/37087324378;/37087321741;/37087323360;/37087325091;/37087321742;/37087107420;/37088643032;/37087324542",
        "aff": "Authors contributed equally to this paper; Authors contributed equally to this paper; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA; Baidu USA LLC, 250 E Caribbean Drive, Sunnyvale, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968102/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7537243547923521324&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "1;1;1;1;1;1",
        "aff_unique_norm": ";Baidu",
        "aff_unique_dep": ";Baidu USA LLC",
        "aff_unique_url": ";https://www.baidu.com",
        "aff_unique_abbr": ";Baidu USA",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Sunnyvale",
        "aff_country_unique_index": "1;1;1;1;1;1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "8968127",
        "title": "An Autonomous Quadrotor System for Robust High-Speed Flight Through Cluttered Environments Without GPS",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust autonomous flight without GPS is key to many emerging drone applications, such as delivery, search and rescue, and warehouse inspection. These and other applications require accurate trajectory tracking through cluttered static environments, where GPS can be unreliable, while high-speed, agile, flight can increase efficiency. We describe the hardware and software of a quadrotor system that meets these requirements with onboard processing: a custom 300 mm wide quadrotor that uses two wide-field-of-view cameras for visual-inertial motion tracking and relocalization to a prior map. Collision-free trajectories are planned offline and tracked online with a custom tracking controller. This controller includes compensation for drag and variability in propeller performance, enabling accurate trajectory tracking, even at high speeds where aerodynamic effects are significant. We describe a system identification approach that identifies quadrotor-specific parameters via maximum likelihood estimation from flight data. Results from flight experiments are presented, which 1) validate the system identification method, 2) show that our controller with aerodynamic compensation reduces tracking error by more than 50% in both horizontal flights at up to 8.5 m/s and vertical flights at up to 3.1 m/s compared to the state-of-the-art, and 3) demonstrate our system tracking complex, aggressive, trajectories.",
        "primary_area": "",
        "author": "Marc Rigter;Benjamin Morrell;Robert G. Reid;Gene B. Merewether;Theodore Tzanetos;Vinay Rajur;KC Wong;Larry H. Matthies;Marc Rigter;Benjamin Morrell;Robert G. Reid;Gene B. Merewether;Theodore Tzanetos;Vinay Rajur;KC Wong;Larry H. Matthies",
        "authorids": "/37086455736;/37086454259;/38226801400;/37086408197;/37086454635;/37086453521;/37404428900;/37270488400;/37086455736;/37086454259;/38226801400;/37086408197;/37086454635;/37086453521;/37404428900;/37270488400",
        "aff": "School of Aerospace, Mechanical and Mechatronics Engineering at The University of Sydney, Australia; School of Aerospace, Mechanical and Mechatronics Engineering at The University of Sydney, Australia; California Institute of Technology, USA; California Institute of Technology, USA; California Institute of Technology, USA; Georgia Institute of Technology, USA; School of Aerospace, Mechanical and Mechatronics Engineering at The University of Sydney, Australia; California Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968127/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5746682084165694587&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;1;2;0;1",
        "aff_unique_norm": "University of Sydney;California Institute of Technology;Georgia Institute of Technology",
        "aff_unique_dep": "School of Aerospace, Mechanical and Mechatronics Engineering;;",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.caltech.edu;https://www.gatech.edu",
        "aff_unique_abbr": "USYD;Caltech;Georgia Tech",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;0;1;1;1;1;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "8968482",
        "title": "An Efficient and Accurate Algorithm for the Perspecitve-n-Point Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of pose estimation from N 2D/3D point correspondences, known as the Perspective-n-Point (PnP) problem. Although many solutions have been proposed, it is hard to optimize both computational complexity and accuracy at the same time. In this paper, we propose an accurate and simultaneously efficient solution to the PnP problem. Previous PnP algorithms generally involve two sets of unknowns including the depth of each pixel and the pose of the camera. Our formulation does not involve the depth of each pixel. By introducing some intermediate variables, this formulation leads to a fourth degree polynomial cost function with 3 unknowns that only involves the rotation. In contrast to previous works, we do not address this minimization problem by solving the first-order optimality conditions using the off-the-shelf Gr\u00f6bner basis method, as the Gr\u00f6bner basis method may encounter numeric problems. Instead, we present a method based on linear system null space analysis to provide a robust initial estimation for a Newton iteration. Experimental results demonstrate that our algorithm is comparable to the start-of-the-art algorithms in terms of accuracy, and the speed of our algorithm is among the fastest algorithms.",
        "primary_area": "",
        "author": "Lipu Zhou;Michael Kaess;Lipu Zhou;Michael Kaess",
        "authorids": "/37088198282;/37324200400;/37088198282;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968482/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8524327938540702572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967882",
        "title": "An Evaluation of Robot-to-Human Handover Configurations for Commercial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The handover of objects is a fundamental task in robot-human interaction. The nature of the handover can be varied by adjusting various parameters in order to achieve a human-like interaction. In this paper the final handover configuration is examined and analyzed. For this purpose, we conducted an experiment in which subjects taught a robot proper and improper end poses for different objects in different situations. We analyze the learned poses to determine what factors proper poses depend on. In addition to the poses, the configurations of the individual joints of the commercial robot are evaluated. Our results demonstrate that proper poses can be grouped into three clusters. These differ mainly in the rotation of the forearm. The height of a proper handover is also determined based on external factors.",
        "primary_area": "",
        "author": "Robin Rasch;Sven Wachsmuth;Matthias K\u00f6nig;Robin Rasch;Sven Wachsmuth;Matthias K\u00f6nig",
        "authorids": "/37086307775;/37329499300;/37086328819;/37086307775;/37329499300;/37086328819",
        "aff": "Faculty Campus Minden, Bielefeld University of Applied Sciences, Minden, Germany; Central Lab Facilities, Cognitive Interaction Technology Excellence Cluster, Bielefeld University, Germany; Faculty Campus Minden, Bielefeld University of Applied Sciences, Minden, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967882/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16163645920922489240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Bielefeld University of Applied Sciences;Bielefeld University",
        "aff_unique_dep": "Faculty Campus Minden;Cognitive Interaction Technology Excellence Cluster",
        "aff_unique_url": "https://www.fh-bielefeld.de;https://www.uni-bielefeld.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minden;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968221",
        "title": "An In-pipe Inspection Module with an Omnidirectional Bent-pipe Self-adaptation Mechanism using a Joint Torque Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents an in-pipe inspection robot module, called AIRo-2.3s. This robot module can control its joint angle and torque and adapt to any directed bent pipe regardless of its orientation. Stretching the drive wheels against the inner wall of pipes is essential for adapting robots to be used in vertical pipes and slippery inner surfaces. To achieve this, a series elastic actuator (SEA) with a high reduction system and a polyurethane rubber is installed to sense the joint torque. More than 100 N constant traction force and a wide range of adaptive inner diameters (4 to 6 in.) are achieved despite the short body length, a minimum number of the drive wheels, and a simple joint of 1 degree of freedom. Experiments to verify the performance in bent pipes are conducted after the robot module configuration is described.",
        "primary_area": "",
        "author": "Atsushi Kakogawa;Shugen Ma;Atsushi Kakogawa;Shugen Ma",
        "authorids": "/37846134700;/37280187400;/37846134700;/37280187400",
        "aff": "Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968221/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2106736324482303450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967587",
        "title": "An Interactive Indoor Drone Assistant",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid advance of sophisticated control algorithms, the capabilities of drones to stabilise, fly and manoeuvre autonomously have dramatically improved, enabling us to pay greater attention to entire missions and the interaction of a drone with humans and with its environment during the course of such a mission. In this paper, we present an indoor office drone assistant that is tasked to run errands and carry out simple tasks at our laboratory, while given instructions from and interacting with humans in the space. To accomplish its mission, the system has to be able to understand verbal instructions from humans, and perform subject to constraints from control and hardware limitations, uncertain localisation information, unpredictable and uncertain obstacles and environmental factors. We combine and evaluate the dialogue, navigation, flight control, depth perception and collision avoidance components. We discuss performance and limitations of our assistant at the component as well as the mission level. A 78% mission success rate was obtained over the course of 27 missions.",
        "primary_area": "",
        "author": "Tino Fuhrman;David Schneider;Felix Altenberg;Tung Nguyen;Simon Blasen;Stefan Constantin;Alex Waibe;Tino Fuhrman;David Schneider;Felix Altenberg;Tung Nguyen;Simon Blasen;Stefan Constantin;Alex Waibe",
        "authorids": "/37087322420;/37089732235;/37087322922;/37087324272;/37087325081;/37087323489;/37087323628;/37087322420;/37089732235;/37087322922;/37087324272;/37087325081;/37087323489;/37087323628",
        "aff": "Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany; Interactive Systems Lab, Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967587/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17242915403183800457&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967526",
        "title": "An Interactive Physically-based Model for Active Suction Phenomenon Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "While suction cups are widely used in Robotics, the literature is underdeveloped when it comes to the modelling and simulation of the suction phenomenon. In this paper, we present a novel physically-based approach to simulate the behavior of active suction cups. Our model relies on a novel formulation which assumes the pressure exerted on a suction cup during active control is based on constraint resolution. Our algorithmic implementation uses a classification process to handle the contacts during the suction phenomenon of the suction cup on a surface. Then, we formulate a convenient way for coupling the pressure constraint with the multiple contact constraints. We propose an evaluation of our approach through a comparison with real data, showing the ability of our model to reproduce the behavior of suction cups. Our approach paves the way for improving the design as well as the control of robotic actuators based on suction cups such as vaccum grippers.",
        "primary_area": "",
        "author": "Antonin Bernardin;Christian Duriez;Maud Marchal;Antonin Bernardin;Christian Duriez;Maud Marchal",
        "authorids": "/37086232760;/37428704500;/38325252000;/37086232760;/37428704500;/38325252000",
        "aff": "Univ. Rennes, INSA, IRISA, Inria, France; Univ. Lille, Inria, France; Univ. Rennes, INSA, IRISA, Inria, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967526/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6252008842593899537&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Rennes;University of Lille",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.univ-rennes1.fr;https://www.univ-lille.fr",
        "aff_unique_abbr": "Univ. Rennes;Univ. Lille",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967782",
        "title": "An Intuitive, Affordances Oriented Telemanipulation Framework for a Dual Robot Arm Hand System: On the Execution of Bimanual Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The concept of teleoperation has been studied since the advent of robotics and has found use in a wide range of applications, including exploration of remote or dangerous environments (e.g., space missions, disaster management), telepresence based time optimisation (e.g., remote surgery) and robot learning. While a significant amount of research has been invested into the field, intricate manipulation tasks still remain challenging from the user perspective due to control complexity. In this paper, we propose an intuitive, affordances oriented telemanipulation framework for a dual robot arm hand system. An object recognition module is utilised to extract scene information and provide grasping and manipulation assistance to the user, simplifying the control of adaptive, multi-fingered hands through a commercial Virtual Reality (VR) interface. The system's performance was experimentally validated in a remote operation setting, where the user successfully performed a set of bimanual manipulation tasks.",
        "primary_area": "",
        "author": "Gal Gorjup;Anany Dwivedi;Nathan Elangovan;Minas Liarokapis;Gal Gorjup;Anany Dwivedi;Nathan Elangovan;Minas Liarokapis",
        "authorids": "/37087237844;/37086133073;/37087236413;/38558084100;/37087237844;/37086133073;/37087236413;/38558084100",
        "aff": "New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967782/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15159643340311703302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "New Dexterity research group",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "8967621",
        "title": "An Object Attribute Guided Framework for Robot Learning Manipulations from Human Demonstration Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning manipulations from videos is an inspiriting way for robots to acquire new skills. In this paper, we propose a framework that can generate robotic manipulation plans by observing human demonstration videos without special marks or unnatural demonstrated behaviors. More specifically, the framework contains a video parsing module and a robot execution module. The first module recognizes the demonstrator's actions using two-stream convolution neural networks, and classifies the operated objects by adopting a Mask R-CNN. After that, two XGBoost classifiers are applied to further classify the objects into subject object and patient object respectively, according to the demonstrator's actions. In the second module, a grammar-based parser is used to summarize the videos and generate the common instructions for robot execution. Extensive experiments are conducted on a publicly available video datasets consisting of 273 videos and manifest that our approach is able to learn manipulation plans from demonstration videos with high accuracy (73.36%). Furthermore, we integrate our framework with a humanoid robot Baxter to perform the manipulation learning from demonstration videos, which effectively verifies the performance of our framework.",
        "primary_area": "",
        "author": "Qixiang Zhang;Junhong Chen;Dayong Liang;Huaping Liu;Xiaojing Zhou;Zihan Ye;Wenyin Liu;Qixiang Zhang;Junhong Chen;Dayong Liang;Huaping Liu;Xiaojing Zhou;Zihan Ye;Wenyin Liu",
        "authorids": "/37087322413;/37087325291;/37087325333;/37310126400;/37087323333;/37086925250;/37086155310;/37087322413;/37087325291;/37087325333;/37310126400;/37087323333;/37086925250;/37086155310",
        "aff": "Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Cobot Vision Lab at the School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967621/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2192755050805311230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Guangdong University of Technology;Tsinghua University",
        "aff_unique_dep": "School of Computer Science and Technology;Department of Computer Science and Technology",
        "aff_unique_url": "http://www.gdut.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "GDUT;THU",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Guangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968552",
        "title": "An Open-Source 7-Axis, Robotic Platform to Enable Dexterous Procedures within CT Scanners",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the design, manufacture, and performance of a highly dexterous, low-profile, 7 Degree-of-Freedom (DoF) robotic arm for CT-guided percutaneous needle biopsy. Direct CT guidance allows physicians to localize tumours quickly; however, needle insertion is still performed by hand. This system is mounted to a fully active motion stage superior to the patient's head and teleoperated by a radiologist. Unlike other similar robots, this robot's fully serial-link approach uses a unique combination of belt and cable drives for high-transparency and minimal-backlash, allowing for an expansive working area and numerous approach angles to targets, all while maintaining a small in-bore cross-section of less than 16cm2. Simulations verified the system's expansive collision free work-space and ability to hit targets across the entire chest, as required for lung cancer biopsy. Targeting error was on average <; 1mm on a teleoperated accuracy task, illustrating the system's sufficient accuracy to perform biopsy procedures. While this system was developed for lung biopsies, it can be easily modified for other CT-guided needle based procedures. Additionally, this system is open-hardware.",
        "primary_area": "",
        "author": "Dimitri A. Schreiber;Daniel B. Shak;Alexander M. Norbash;Michael C. Yip;Dimitri A. Schreiber;Daniel B. Shak;Alexander M. Norbash;Michael C. Yip",
        "authorids": "/37087322737;/37087323561;/37990574500;/37085382768;/37087322737;/37087323561;/37990574500;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Radiology, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968552/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=903094432145227718&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968096",
        "title": "An Optimal Algorithm to Solve the Combined Task Allocation and Path Finding Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider multi-agent transport task problems where, e.g. in a factory setting, items have to be delivered from a given start to a goal pose while the delivering robots need to avoid collisions with each other on the floor.We introduce a Task Conflict-Based Search (TCBS) Algorithm to solve the combined delivery task allocation and multiagent path planning problem optimally. The problem is known to be NP-hard and the optimal solver cannot scale. However, we introduce it as a baseline to evaluate the sub-optimality of other approaches. We show experimental results that compare our solver with different sub-optimal ones in terms of regret.",
        "primary_area": "",
        "author": "Christian Henkel;Jannik Abbenseth;Marc Toussaint;Christian Henkel;Jannik Abbenseth;Marc Toussaint",
        "authorids": "/37086226562;/37086227812;/37528418600;/37086226562;/37086227812;/37528418600",
        "aff": "Machine Learning and Robotics Lab, University of Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Machine Learning and Robotics Lab, University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968096/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16206842640222031226&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Stuttgart;Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "Machine Learning and Robotics Lab;",
        "aff_unique_url": "https://www.ira.uka.de;https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": ";Fraunhofer IPA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stuttgart",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968454",
        "title": "An assisted telemanipulation approach: combining autonomous grasp planning with haptic cues",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an assisted telemanipulation approach with integrated grasp planning. It also studies how the human teleoperation performance benefits from the incorporated visual and haptic cues while manipulating objects in cluttered environments. The developed system combines the widely used master-slave teleoperation with our previous model-free and learning-free grasping algorithm by means of a dynamic grasp re-ranking strategy and a semi-autonomous reach-to-grasptrajectory guidance. The proposed re-ranking metric helps in dynamically updating the stable grasps based on the current state of the slave device. The trajectory guidance system assists in maintaining smooth trajectory by controlling the haptic forces. A virtual pose controller has been integrated with the guidance scheme to automatically correct the end-effector orientation while reaching towards the grasp. Various experiments are conducted evaluating the proposed method using a six degrees of freedom (dof) haptic master and a seven dof slave robot. Results obtained with these tests along with the results gathered from the performed human-factor trials demonstrate the efficiency of our method in terms of objective metrics of task completion, and also subjective metrics of user experience.",
        "primary_area": "",
        "author": "Maxime Adjigble;Naresh Marturi;Valerio Ortenzi;Rustam Stolkin;Maxime Adjigble;Naresh Marturi;Valerio Ortenzi;Rustam Stolkin",
        "authorids": "/37085407107;/37085558507;/37085426095;/37424300500;/37085407107;/37085558507;/37085426095;/37424300500",
        "aff": "Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968454/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18052070106871076030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Birmingham",
        "aff_unique_dep": "Extreme Robotics Laboratory",
        "aff_unique_url": "https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edgbaston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967647",
        "title": "An assistive low-vision platform that augments spatial cognition through proprioceptive guidance: Point-to-Tell-and-Touch",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatial cognition, as gained through the sense of vision, is one of the most important capabilities of human beings. However, for the visually impaired (VI), lack of this perceptual capability poses great challenges in their life. Therefore, we have designed Point-to-Tell-and-Touch, a wearable system with an ergonomic human-machine interface, for assisting the VI with active environmental exploration, with a particular focus on spatial intelligence and navigation to objects of interest in an alien environment. Our key idea is to link visual signals, as decoded synthetically, to the VI\u2019s proprioception for more intelligible guidance, in addition to vision-to-audio assistance, i.e., finger pose, as indicated by pointing, is used as \u201cproprioceptive laser pointer\u201d to target an object in that line of sight. The whole system consists of two features, Point-to-Tell and Point-to-Touch, both of which can work independently or cooperatively. The Point-to-Tell feature contains a camera with a novel one-stage neural network tailored for blind-centered object detection and recognition, and a headphone telling the VI the semantic label and distance from the pointed object. the Point-to-Touch, the second feature, leverages a vibrating wrist band to create a haptic feedback tool that supplements the initial vectorial guidance provided by the first stage (hand pose being direction and the distance being the extent, offered through audio cues). Both platform features utilize proprioception or joint position sense. Through hand pose, the VI end user knows where he or she is pointing relative to their egocentric coordinate system and we are able to use this foundation to build spatial intelligence. Our successful indoor experiments demonstrate the proposed system to be effective and reliable in helping the VI gain spatial cognition and explore the world in a more intuitive way.",
        "primary_area": "",
        "author": "Wenjun Gui;Bingyu Li;Shuaihang Yuan;John-Ross Rizzo;Lakshay Sharma;Chen Feng;Anthony Tzes;Yi Fang;Wenjun Gui;Bingyu Li;Shuaihang Yuan;John-Ross Rizzo;Lakshay Sharma;Chen Feng;Anthony Tzes;Yi Fang",
        "authorids": "/37087321836;/37087324473;/37087324510;/37086000958;/37089853647;/37089732330;/37283528800;/37085619965;/37087321836;/37087324473;/37087324510;/37086000958;/37089853647;/37089732330;/37283528800;/37085619965",
        "aff": "NYU Multimedia and Visual Computing Lab, NYU, Tandon; NYU Multimedia and Visual Computing Lab, NYU, Tandon; NYU Multimedia and Visual Computing Lab, NYU, Tandon; Langone Medical Center, NYU; NYU Multimedia and Visual Computing Lab, NYU, Tandon; Langone Medical Center, NYU; NYU, Abu Dhabi; NYU, Tandon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967647/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8902654780542529786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Multimedia and Visual Computing Lab",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0;1;0;1;2;0",
        "aff_campus_unique": "Tandon;New York;Abu Dhabi",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "8967940",
        "title": "An autonomous exploration algorithm using environment-robot interacted traversability analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Auto-exploration is a task for self-driving robots to explore unknown environments, which becomes much complicated when they move on irregular outdoor terrains. To improve the situation, a new frontier-based exploration algorithm is presented in this paper. It starts from original 3D cloud points of the environment to analyze the traversability of the scanned area, and further provides a reachability map to mark all map grid cells as reachable, dangerous or unknown. Frontier candidates are obtained from the reachable map, then clustered and reduced using an improved K-means. Finally, the target of next exploration step is selected from the frontiers left by evaluating their travel cost. The algorithm is validated on an irregular outdoor terrain and shows the capability for a field robot to explore on an irregular terrain.",
        "primary_area": "",
        "author": "Yujie Tang;Jun Cai;Meng Chen;Xuejiao Yan;Yangmin Xie;Yujie Tang;Jun Cai;Meng Chen;Xuejiao Yan;Yangmin Xie",
        "authorids": "/37087323728;/37087323051;/37085654172;/37087323940;/37086108182;/37087323728;/37087323051;/37085654172;/37087323940;/37086108182",
        "aff": "School of Mechatronics Engineering and Automation, Shanghai University, Shanghai, PR China; School of Mechatronics Engineering and Automation, Shanghai University, Shanghai, PR China; School of Mechatronics Engineering and Automation, Shanghai University, Shanghai, PR China; School of Mechatronics Engineering and Automation, Shanghai University, Shanghai, PR China; Institute of Aerospace System Engineering Shanghai, No. 3805 Jindu Rd., Shanghai, PR China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967940/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4446015699935906845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Shanghai University;Institute of Aerospace System Engineering",
        "aff_unique_dep": "School of Mechatronics Engineering and Automation;",
        "aff_unique_url": "https://www.shu.edu.cn;",
        "aff_unique_abbr": "SHU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968015",
        "title": "An experimental study of parameters influencing physical Human-Robot negotiation in comanipulative tracking task",
        "track": "main",
        "status": "Poster",
        "abstract": "The present paper investigates the relationship between human and virtual partners\u2019 behaviors during a comanipulative task requiring negotiation. More precisely, the study is focused on the influence of the Virtual Partner\u2019s (which was designed in a previous study) propensity to take the lead during conflicts over its human partner behavior. The experimental design includes both Human-Human and Human-Robot trials. The Human-Human trials serve as a baseline condition and help assessing the importance of the partner\u2019s nature (human vs robot) knowledge in the subjects behavior. The Human-Robot trials are used to observe the effect of different tuning of the Virtual Partner on the dominance relationship within Human-Robot dyads. The results of the study show that Human behavior is consistent across Human-Human trials, and is not influenced by the knowledge of their partner\u2019s nature. Moreover, a simple tuning of the negotiation thresholds of the Virtual Partner allows to significantly modify the dominance of the human partner, although this modification has no lasting effects.",
        "primary_area": "",
        "author": "Lucas Roche;Anish Monachan;Ludovic Saint-Bauzel;Lucas Roche;Anish Monachan;Ludovic Saint-Bauzel",
        "authorids": "/37086204920;/37087322972;/38272835100;/37086204920;/37087322972;/38272835100",
        "aff": "75005, Institut des Systemes Intelligents et de Robotique, Sorbonne Universite, Paris, France; 75005, Institut des Systemes Intelligents et de Robotique, Sorbonne Universite, Paris, France; 75005, Institut des Systemes Intelligents et de Robotique, Sorbonne Universite, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968015/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1771841565123879441&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universite",
        "aff_unique_dep": "Institut des Systemes Intelligents et de Robotique",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967623",
        "title": "An optimization framework for simulation and kinematic control of Constrained Collaborative Mobile Agents (CCMA) system",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a concept of constrained collaborative mobile agents (CCMA) system, which consists of multiple wheeled mobile agents constrained by a passive kinematic chain. This mobile robotic system is modular in nature, the passive kinematic chain can be easily replaced with different designs and morphologies for different functions and task adaptability. Depending solely on the actuation of the mobile agents, this mobile robotic system can manipulate or position an end-effector. However, the complexity of the system due to presence of several mobile agents, passivity of the kinematic chain and the nature of the constrained collaborative manipulation requires development of an optimization framework. We therefore present an optimization framework for forward simulation and kinematic control of this system. With this optimization framework, the number of deployed mobile agents, actuation schemes, the design and morphology of the passive kinematic chain can be easily changed, which reinforces the modularity and collaborative aspects of the mobile robotic system. We present results, in simulation, for spatial 4-DOF to 6-DOF CCMA system examples. Finally, we present experimental quantitative results for two different fabricated 4-DOF prototypes, which demonstrate different actuation schemes, control and collaborative manipulation of an end-effector.",
        "primary_area": "",
        "author": "Nitish Kumar;Stelian Coros;Nitish Kumar;Stelian Coros",
        "authorids": "/37086192720;/37077396200;/37086192720;/37077396200",
        "aff": "Computational Robotics Lab at the, Institute for Pervasive Computing, ETH Zurich, Switzerland; Computational Robotics Lab at the, Institute for Pervasive Computing, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967623/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17682730473833970620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Pervasive Computing",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967812",
        "title": "Analysis and Exploitation of Synchronized Parallel Executions in Behavior Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior Trees (BTs) are becoming a popular tool to model the behaviors of autonomous agents in the computer game and the robotics industry. One of the key advantages of BTs lies in their composability, where complex behaviors can be built by composing simpler ones. The parallel composition is the one with the highest potential since the complexity of composing pre-existing behaviors in parallel is much lower than the one needed using classical control architectures as finite state machines. However, the parallel composition is rarely used due to the underlying concurrency problems that are similar to the ones faced in concurrent programming. In this paper, we define two synchronization techniques to tackle the concurrency problems in BTs compositions and we show how to exploit them to improve behavior predictability. Also, we introduce measures to assess execution performance and we show how design choices can affect them. To illustrate the proposed framework, we provide a set of experiments using the R1 robot and we gather statistically-significant data.",
        "primary_area": "",
        "author": "Michele Colledanchise;Lorenzo Natale;Michele Colledanchise;Lorenzo Natale",
        "authorids": "/37085361393;/37542770000;/37085361393;/37542770000",
        "aff": "iCub Facility, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Facility, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967812/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11955330904054406173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "iCub Facility",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968118",
        "title": "Analyzing Liquid Pouring Sequences via Audio-Visual Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing work to estimate the weight of a liquid poured into a target container often require predefined source weights or visual data. We present novel audio-based and audio-augmented techniques, in the form of multimodal convolutional neural networks (CNNs), to estimate poured weight, perform overflow detection, and classify liquid and target container. Our audio-based neural network uses the sound from a pouring sequence-a liquid being poured into a target container. Audio inputs consist of converting raw audio into mel-scaled spectrograms. Our audio-augmented network fuses this audio with its corresponding visual data based on video images. Only a microphone and camera are required, which can be found in any modern smartphone or Microsoft Kinect. Our approach improves classification accuracy for different environments, containers, and contents of the robot pouring task. Our Pouring Sequence Neural Networks (PSNN) are trained and tested using the Rethink Robotics Baxter Research Robot. To the best of our knowledge, this is the first use of audio-visual neural networks to analyze liquid pouring sequences by classifying their weight, liquid, and receiving container.",
        "primary_area": "",
        "author": "Justin Wilson;Auston Sterling;Ming C. Lin;Justin Wilson;Auston Sterling;Ming C. Lin",
        "authorids": "/37087322840;/37086806073;/37278387400;/37087322840;/37086806073;/37278387400",
        "aff": "Department of Computer Science, UNC Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, UNC Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, UNC Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968118/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2915621490560408840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unc.edu",
        "aff_unique_abbr": "UNC Chapel Hill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chapel Hill",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967562",
        "title": "Angle of Arrival Estimation based on Channel Impulse Response Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, ultra-wideband radio technology has become increasingly popular as a space-and cost-effective solution to the problem of indoor localization. This paper demonstrates how measurements of the channel impulse response can be used to estimate a signal's angle of arrival at a receiving antenna. This novel method requires no additional hardware, uses only a single antenna, and works with unsynchronized clocks and one-way communication. We evaluate our method on a real-dataset, and experimentally demonstrate how a mobile robot can localize itself by measuring angles to multiple ultra-wideband anchors.",
        "primary_area": "",
        "author": "Anton Ledergerber;Michael Hamer;Raffaello D\u2019Andrea;Anton Ledergerber;Michael Hamer;Raffaello D\u2019Andrea",
        "authorids": "/37085716054;/38359407100;/38525077800;/37085716054;/38359407100;/38525077800",
        "aff": "Dynamic Systems and Control, ETH Zurich, Switzerland; Dynamic Systems and Control, ETH Zurich, Switzerland; Dynamic Systems and Control, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967562/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=771112242903795131&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968606",
        "title": "Ankle Torque During Mid-Stance Does Not Lower Energy Requirements of Steady Gaits",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate whether applying ankle torques during mid-stance can be a more effective way to reduce energetic cost of locomotion than actuating leg length alone. Ankles are useful in human gaits for many reasons including static balancing. In this work, we specifically avoid the heel-strike and toe-off benefits to investigate whether the progression of the center of pressure from heel-to-toe during mid-stance, or some other approach, is beneficial in and of itself. We use an Ankle Actuated Spring Loaded Inverted Pendulum model to simulate the shifting center of pressure dynamics, and trajectory optimization is applied to find limit cycles that minimize cost of transport. The results show that, for the vast majority of gaits, ankle torques do not affect cost of transport. Ankles reduce the cost of transport during a narrow band of gaits at the transition from grounded running to aerial running. This suggests that applying ankle torque during mid-stance of a steady gait is not a directly beneficial strategy, but is most likely a path between beneficial heel-strikes and toe-offs.",
        "primary_area": "",
        "author": "Mike Hector;Kevin Green;Burak Sencer;Jonathan Hurst;Mike Hector;Kevin Green;Burak Sencer;Jonathan Hurst",
        "authorids": "/37087323318;/37087323965;/37072737700;/37267365600;/37087323318;/37087323965;/37072737700;/37267365600",
        "aff": "School of Mechanical, Industrial, & Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; School of Mechanical, Industrial, & Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; School of Mechanical, Industrial, & Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; School of Mechanical, Industrial, & Manufacturing Engineering, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968606/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7673169527547233721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "School of Mechanical, Industrial, & Manufacturing Engineering",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968178",
        "title": "Application of Digging Control based on the Center-of-Mass Velocity of the Attachment of a Hydraulic Excavator",
        "track": "main",
        "status": "Poster",
        "abstract": "Superior operation skills for hydraulic excavators are learned over time. Therefore, it is difficult to improve the skills of non-expert operators quickly, and their work needs to be supported. This paper presents a control system, which realizes smooth digging (similar to that performed by expert operators), based on the Center of Mass velocity of the attachment as an index. In addition, corresponding to the system switching caused by the digging reaction force, a controller gain tuning method that uses the Fictitious Exogenous Signal is proposed. The proposed method is applied to a hydraulic excavator, and its effect is verified.",
        "primary_area": "",
        "author": "Masatoshi Kozui;Toru Yamamoto;Kazushige Koiwai;Koji Yamashita;Yoichiro Yamazaki;Masatoshi Kozui;Toru Yamamoto;Kazushige Koiwai;Koji Yamashita;Yoichiro Yamazaki",
        "authorids": "/37087323911;/37280377100;/37644316700;/37086228727;/37085827124;/37087323911;/37280377100;/37644316700;/37086228727;/37085827124",
        "aff": "Graduate School of Engineering, Hiroshima University, 1-4-1 Kagamiyama, Higashi-Hiroshima, Hiroshima, Japan; Graduate School of Engineering, Hiroshima University, 1-4-1 Kagamiyama, Higashi-Hiroshima, Hiroshima, Japan; KOBELCO Construction Machinery Co., Ltd., 2-2-1, Itsukaichikou, Saeki-ku, Hiroshima, Japan; KOBELCO Construction Machinery Co., Ltd., 2-2-1, Itsukaichikou, Saeki-ku, Hiroshima, Japan; KOBELCO Construction Machinery Co., Ltd., 2-2-1, Itsukaichikou, Saeki-ku, Hiroshima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968178/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18025822184300818220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Hiroshima University;KOBELCO Construction Machinery Co., Ltd.",
        "aff_unique_dep": "Graduate School of Engineering;",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp;",
        "aff_unique_abbr": "Hiroshima U;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Higashi-Hiroshima;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968260",
        "title": "Applying the Interaction of Walking-Emotion to an Assistive Device for Rehabilitation and Exercise",
        "track": "main",
        "status": "Poster",
        "abstract": "To maintain a high level of motivation is a vital issue during rehabilitation because rehabilitation involves much pain, depression, and discomfort. To study the mental state of patients is necessary. A new assistive approach using emotion evaluation combined with an assistive walking device to maintain motivation during the rehabilitation is proposed. To realize it, the walking-emotion relationship within personal walking limitation (PWL) was explored at first. The results showed that when people walked by following the personal preferred walking ratio (PPWR), they were evoked the arousal emotion and kept the current valence emotion simultaneously; however, when people were not following PPWR to walk, the negative emotion was elicited. After that, subject was required to wear the assistive walking device to conduct the test, which aims to observe the emotion variation when subject walked at specific walking gait with an assistive device. We then are according to current emotion state to tune device. The findings show if people mistakenly use the device, unpleasant feeling would be elicited. When we properly tuning assistive device conforms to current gait, it can validly alleviate the negative emotion further becoming the positive emotion. From these results, we conclude that emotion can be affected by walking. By using walking-emotion evaluation to an assistive device, we can be according to users' emotion to control device; also, we can use an assistive device to inspire users' emotion to further maintain motivation. Finally, this assistive approach provides a useful treatment way for serving rehabilitation.",
        "primary_area": "",
        "author": "Jyun Rong Zhuang;Guan Yu Wu;Hee Hyol Lee;Eiichiro Tanaka;Jyun Rong Zhuang;Guan Yu Wu;Hee Hyol Lee;Eiichiro Tanaka",
        "authorids": "/37086448100;/37087031860;/37086053751;/37870907700;/37086448100;/37087031860;/37086053751;/37870907700",
        "aff": "Graduate School of Information, Production and Systems, Waseda University, 2-7 Hibikino, Wakamatsu-ku, Kita-Kyushu, Fukuoka, Japan; Graduate School of Information, Production and Systems, Waseda University, 2-7 Hibikino, Wakamatsu-ku, Kita-Kyushu, Fukuoka, Japan; Graduate School of Information, Production and Systems, Waseda University, 2-7 Hibikino, Wakamatsu-ku, Kita-Kyushu, Fukuoka, Japan; Graduate School of Information, Production and Systems, Waseda University, 2-7 Hibikino, Wakamatsu-ku, Kita-Kyushu, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968260/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1890532079199466354&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Graduate School of Information, Production and Systems",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kita-Kyushu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968148",
        "title": "Approximating Cfree Space Topology by Constructing Vietoris-Rips Complex",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new way of constructing sparse roadmaps using point clouds that approximates and measures the underlying topology of the Cfree space. The main advantage of the constructed roadmap is its homotopy equivalence to the \u03b7-offset of the Cfree space. Though only used to plan paths as a regular roadmap in this work, because the roadmap preserves the topology of the underlying sampled space, the information can be used to plan paths beyond the simple connection of graph vertices. To construct the roadmap, we first sample the configuration space so that the resulting graph is a n-skeleton graph that constructs a Vietoris-Rips (VR) complex. Then, we perform a series of topological collapses to remove vertices from the graph while still preserving its topological properties. The resulting roadmaps are used to plan paths for different robots and the experimental results show that the proposed topological approach is faster and more feasible in complex high-dimensional spaces.",
        "primary_area": "",
        "author": "Aakriti Upadhyay;Weifu Wang;Chinwe Ekenna;Aakriti Upadhyay;Weifu Wang;Chinwe Ekenna",
        "authorids": "/37086395279;/37086596204;/37085676589;/37086395279;/37086596204;/37085676589",
        "aff": "Department of Computer Science, University at Albany; Department of Electrical and Computer Engineering, University at Albany; Department of Computer Science, University at Albany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968148/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1183535835125543818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University at Albany",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.albany.edu",
        "aff_unique_abbr": "UAlbany",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Albany",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968511",
        "title": "Are You With Me? Determining the Association of Individuals and the Collective Social Space",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing use of autonomous mobile robots in different parts of society, and not restricted only to industrial environments, makes it important to propose techniques that will allow them to behave in the most socially acceptable way as possible. In most real-world scenarios, individuals in the environment are interacting with each other and are arranged into groups. Therefore, it is paramount the proposition of techniques to efficiently and correctly identify and represent such groups. This information can be useful in different tasks such as approaching and initiating an interaction, escorting, and the navigation itself. In this work, we propose a novel graph-based approach to evaluate the possible association of individuals in the environment based on their position and body orientation. Next, based on this association, we propose a representation of the combined social space of individuals in the same group. The methodology was evaluated using synthetic and real-world datasets, showing that it achieves results comparable to or better than the state-of-the-art.",
        "primary_area": "",
        "author": "Alan D. G. Silva;Douglas G. Macharet;Alan D. G. Silva;Douglas G. Macharet",
        "authorids": "/37088225365;/37590114800;/37088225365;/37590114800",
        "aff": "Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil; Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968511/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2971704985569662518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Computer Vision and Robotics Laboratory (VeRLab)",
        "aff_unique_url": "http://www.ufmg.br",
        "aff_unique_abbr": "UFMG",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "MG",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "8967930",
        "title": "Are you hearing or listening? The effect of task performance in verbal behavior with smart speaker",
        "track": "main",
        "status": "Poster",
        "abstract": "Human has an ability to adjust utterance depending on the state of interlocutor. In this study, we explore the verbal behaviors of human through interaction with two smart speakers that have different level of task competence. We analyzed (1) linguistic behaviors appeared in user\u2019s utterance, (2) length of the uttered speech, and (3) required pragmatics skills to understand the user\u2019s intent. As a result, there were no significant difference in linguistic behaviors and length of the speech while user interacts with speakers with different task competence. In addition, various pragmatics elements were equally utilized and especially, implied intentions were frequently observed in user\u2019s short utterance even under simple interaction scenarios.",
        "primary_area": "",
        "author": "Chaewon Park;Jongsuk Choi;Jee Eun Sung;Yoonseob Lim;Chaewon Park;Jongsuk Choi;Jee Eun Sung;Yoonseob Lim",
        "authorids": "/37087321818;/37292544300;/37087324239;/37695437400;/37087321818;/37292544300;/37087324239;/37695437400",
        "aff": "Center for Intelligent and Interactive Robotics, Korea, Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea, Institute of Science and Technology, Seoul, Korea; Department of Communication Disorders, EWHA, Womans University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea, Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967930/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:OY4rIz7RfG0J:scholar.google.com/&scioq=Are+you+hearing+or+listening%3F+The+effect+of+task+performance+in+verbal+behavior+with+smart+speaker&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;Ewha Womans University",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Department of Communication Disorders",
        "aff_unique_url": "https://www.kist.re.kr;http://www.ewha.ac.kr",
        "aff_unique_abbr": "KIST;EWHA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967670",
        "title": "Arguing Security of Autonomous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots are already being used, for example, as tour guides, receptionists, or office-assistants. The proximity to humans and the possibility to physically interact with them highlights the importance of developing secure robot applications. It is crucial to consider security implications to be an important part of the robot application's development process. Adding security later in the application's life-cycle usually leads to high costs, or is not possible due to earlier design decisions. In this work, we present the Robot Application Security Process (RASP) as a lightweight process that enables the development of secure robot applications. Together with RASP we introduce the role of a Security Engineer (SecEng) as an important stakeholder in any robot application development process. RASP enables the SecEng to verify the completeness of his work and allows him to argue about the application's security with other stakeholders. Furthermore, we demonstrate how the RASP supports the SecEng and also other developers in their daily work.",
        "primary_area": "",
        "author": "Nico Hochgeschwender;Gary Cornelius;Holger Voos;Nico Hochgeschwender;Gary Cornelius;Holger Voos",
        "authorids": "/38228828900;/37087324111;/37449354600;/38228828900;/37087324111;/37449354600",
        "aff": "German Aerospace Center (DLR) and the Bonn-Rhein-Sieg University, Germany; German Aerospace Center (DLR) and the Bonn-Rhein-Sieg University, Germany; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967670/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=817663913350211090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "German Aerospace Center (DLR);University of Luxembourg",
        "aff_unique_dep": ";Interdisciplinary Centre for Security, Reliability and Trust",
        "aff_unique_url": "https://www.dlr.de;https://wwwen.unil.lu",
        "aff_unique_abbr": "DLR;UniLu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;Luxembourg"
    },
    {
        "id": "8968604",
        "title": "Articulated Multi-Perspective Cameras and Their Application to Truck Motion Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "While monocular and stereo camera based motion estimation has reached a level of maturity that enables industrial use, the community keeps exploring novel multi-sensor solutions to meet the high robustness and accuracy requirements of certain applications such as autonomous vehicles. The present paper focuses on motion estimation with multi-perspective camera systems. In particular, we look into the intricate case in which the cameras are distributed over an articulated body, a scenario that occurs in truck motion estimation where additional cameras are installed on the trailer. The resulting articulated multi-perspective camera is analyzed in theory and practice, and we show that- by taking the non-holonomic constraints of the vehicle into account- a single point correspondence measured from the trailer is sufficient to render the additional unknown parameters given by the internal joint configuration before and after a relative displacement fully observable. optimizing over all parameters enhances the accuracy of the motion estimation of the entire system with respect to using the cameras on each rigid part alone. Results are confirmed on both simulated and real data.",
        "primary_area": "",
        "author": "Xin Peng;Jiadi Cui;Laurent Kneip;Xin Peng;Jiadi Cui;Laurent Kneip",
        "authorids": "/37087323642;/37087323375;/37569040300;/37087323642;/37087323375;/37569040300",
        "aff": "Mobile Perception Lab, ShanghaiTech University; Mobile Perception Lab, ShanghaiTech University; Mobile Perception Lab, ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968604/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8986613800788959588&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "Mobile Perception Lab",
        "aff_unique_url": "http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967597",
        "title": "Artificial lateral line based longitudinal separation sensing for two swimming robotic fish with leader-follower formation",
        "track": "main",
        "status": "Poster",
        "abstract": "Lateral line system (LLS) is a sensory organ system which serves functions in varieties of flow-relative fish behaviors. Inspired by excellent performances of LLS in fish behaviors, multiple artificial lateral line systems (ALLSs) have been designed and applied to promote underwater robot technology. In this article, we focus on using ALLS for longitudinal separation sensing between two adjacent swimming robotic fish whose tails oscillate, and meanwhile the two fish are towed with a precisely controlled speed which equals to the rectilinear speed of freely-swimming robotic fish with the same oscillating parameters. Flow visualizations based on dye injection technique, hydrogen bubble technique, and computational fluid dynamics simulation are conducted to study the distribution characteristics of the vortices caused by the robotic fish. In addition, towing tank experiments are conducted for investigating the qualitative relationships between the longitudinal separations and the ALLS-measured HPVs of the two robotic fish. This work provide a guidance for the application of ALLS in relative states sensing of underwater robot group composed of two or more individuals, which has been rarely explored.",
        "primary_area": "",
        "author": "Xingwen Zheng;Manyi Wang;Junzheng Zheng;Runyu Tian;Minglei Xiong;Guangming Xie;Xingwen Zheng;Manyi Wang;Junzheng Zheng;Runyu Tian;Minglei Xiong;Guangming Xie",
        "authorids": "/37085823629;/37087323183;/37089280073;/37087324232;/37087106139;/37270592800;/37085823629;/37087323183;/37089280073;/37087324232;/37087106139;/37270592800",
        "aff": "The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory for Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967597/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=375898828242799127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967928",
        "title": "Asynchronous Behavior Trees with Memory aimed at Aerial Vehicles with Redundancy in Flight Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex aircraft systems are becoming a target for automation. For successful operation, they require both efficient and readable mission execution system (MES). Flight control computer (FCC) units, as well as all important subsystems, are often duplicated. Discrete nature of MES does not allow small differences in data flow among redundant FCCs which are acceptable for continuous control algorithms. Therefore, mission state consistency has to be specifically maintained. We present a novel MES which includes FCC state synchronization. To achieve this result we developed the new concept of Asynchronous Behavior Tree with Memory (ABTM) and proposed a state synchronization algorithm. The implemented system was tested and proven to work in a real-time simulation of High Altitude Pseudo Satellite (HAPS) mission.",
        "primary_area": "",
        "author": "Evgenii Safronov;Michael Vilzmann;Dzmitry Tsetserukou;Konstantin Kondak;Evgenii Safronov;Michael Vilzmann;Dzmitry Tsetserukou;Konstantin Kondak",
        "authorids": "/37086870741;/37087322407;/37548023000;/37427143400;/37086870741;/37087322407;/37548023000;/37427143400",
        "aff": "Space CREI, Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russia; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Space CREI, Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russia; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967928/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16964304501276599688&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;German Aerospace Center (DLR)",
        "aff_unique_dep": "Space CREI;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.skoltech.ru;https://www.dlr.de",
        "aff_unique_abbr": "Skoltech;DLR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Moscow;",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Russian Federation;Germany"
    },
    {
        "id": "8968567",
        "title": "Atomic force microscope tip localization and tracking through deep learning based vision inside an electron microscope",
        "track": "main",
        "status": "Poster",
        "abstract": "Scanning Electron Microscopy (SEM) is an ideal observation tool for small scales robotics. It has the potential to achieve automated nano-robotic tasks such as nano-handling and nano-assembly. Path following control of nano-robot end effectors using SEM vision feedback is a key for an intuitive programming of elementary robotic tasks sequences. It requires the ability to track end effectors under various SEM scan speeds. SEM suffers however from tricky issues that limits robotic tracking capabilities. This paper focuses on one specific issue related to the compromise between the scan speed and the image quality. This restriction seriously limits the performance of conventional vision tracking algorithms when used with electron images. At high scan speed, the image quality is very noisy making very difficult to differentiate the robot end effector from the background, hence limiting the tracking capabilities. The work related in this paper explores for the first time the potential value of Convolutional Neural Networks (ConvNet) in the context of nano-robotic vision tracking inside SEM. The aim is to localize an end-effector, AFM cantilever in the case of the study, from SEM images for any scan speed configuration and despite of low images quality. For that purpose, a data set of AFM tip images is build up from SEM images for the learning algorithm. Network performances are estimated under different SEM scan speeds. Thanks to the learning algorithm, experimental results show robust AFM tip tracking capabilities inside the SEM under various scan speed conditions.",
        "primary_area": "",
        "author": "Shuai Liang;Mokrane Boudaoud;Catherine Achard;Weibin Rong;St\u00e9phane R\u00e9gnier;Shuai Liang;Mokrane Boudaoud;Catherine Achard;Weibin Rong;St\u00e9phane R\u00e9gnier",
        "authorids": "/37086086041;/37594372000;/37269937300;/38337550500;/37283234800;/37086086041;/37594372000;/37269937300;/38337550500;/37283234800",
        "aff": "St\u00e9phane R\u00e9gnier are with the Sorbonne Universit\u00e9, campus Pierre et Marie Curie/ ISIR CNRS UMR 72224 Place Jussieu, CC 173, Pyramide - T55/65, Paris; St\u00e9phane R\u00e9gnier are with the Sorbonne Universit\u00e9, campus Pierre et Marie Curie/ ISIR CNRS UMR 72224 Place Jussieu, CC 173, Pyramide - T55/65, Paris; St\u00e9phane R\u00e9gnier are with the Sorbonne Universit\u00e9, campus Pierre et Marie Curie/ ISIR CNRS UMR 72224 Place Jussieu, CC 173, Pyramide - T55/65, Paris; State Key Lab. of Robotics and System, Harbin Institute of Technology, 92 West Dazhi Street, Nan Gang District, Harbin, China; St\u00e9phane R\u00e9gnier are with the Sorbonne Universit\u00e9, campus Pierre et Marie Curie/ ISIR CNRS UMR 72224 Place Jussieu, CC 173, Pyramide - T55/65, Paris",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968567/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10066556603994647619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9;Harbin Institute of Technology",
        "aff_unique_dep": "ISIR CNRS UMR 72224;State Key Lab. of Robotics and System",
        "aff_unique_url": "https://www.sorbonne-universite.fr;http://www.hit.edu.cn/",
        "aff_unique_abbr": "Sorbonne U;HIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Pierre et Marie Curie;Harbin",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "France;China"
    },
    {
        "id": "8968565",
        "title": "Attention-based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing safe and efficient lane changes is a crucial feature for creating fully autonomous vehicles. Recent advances have demonstrated successful lane following behavior using deep reinforcement learning, yet the interactions with other vehicles on-road for lane changes are rarely considered. In this paper, we design a hierarchical Deep Reinforcement Learning (DRL) algorithm to learn lane change behaviors in dense traffic. By breaking down overall behavior to sub-policies, faster and safer lane change actions can be learned. We also apply temporal and spatial attention to the DRL architecture, which helps the vehicle focus more on surrounding vehicles and leads to smoother lane change behavior. We conduct our experiments in the TORCS simulator and the results outperform the state-of-the-art deep reinforcement learning algorithm in various lane change scenarios.",
        "primary_area": "",
        "author": "Yilun Chen;Chiyu Dong;Praveen Palanisamy;Priyantha Mudalige;Katharina Muelling;John M. Dolan;Yilun Chen;Chiyu Dong;Praveen Palanisamy;Priyantha Mudalige;Katharina Muelling;John M. Dolan",
        "authorids": "/37086702883;/37086089544;/37086488161;/37299435400;/37992473400;/37283756800;/37086702883;/37086089544;/37086488161;/37299435400;/37992473400;/37283756800",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Department of Eletrical and Computing Engineering, Carnegie Mellon University, Pittsburgh, USA; General Motor Global R&D Center, Warren, USA; General Motor Global R&D Center, Warren, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968565/",
        "gs_citation": 139,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16999000025721848472&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;General Motors",
        "aff_unique_dep": "The Robotics Institute;Global R&D Center",
        "aff_unique_url": "https://www.cmu.edu;https://www.gm.com",
        "aff_unique_abbr": "CMU;GM",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Pittsburgh;Warren",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968183",
        "title": "Audio-visual sensing from a quadcopter: dataset and baselines for source localization and sound enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an audio-visual dataset recorded outdoors from a quadcopter and discuss baseline results for multiple applications. The dataset includes a scenario for source localization and sound enhancement with up to two static sources, and a scenario for source localization and tracking with a moving sound source. These sensing tasks are made challenging by the strong and time-varying ego-noise generated by the rotating motors and propellers. The dataset was collected using a small circular array with 8 microphones and a camera mounted on the quadcopter. The camera view was used to facilitate the annotation of the sound-source positions and can also be used for multi-modal sensing tasks. We discuss the audio-visual calibration procedure that is needed to generate the annotation for the dataset, which we make available to the research community.",
        "primary_area": "",
        "author": "Lin Wang;Ricardo Sanchez-Matilla;Andrea Cavallaro;Lin Wang;Ricardo Sanchez-Matilla;Andrea Cavallaro",
        "authorids": "/37539337200;/37086527651;/37273747900;/37539337200;/37086527651;/37273747900",
        "aff": "Centre for Intelligent Sensing, Queen Mary University of London, U.K.; Centre for Intelligent Sensing, Queen Mary University of London, U.K.; Centre for Intelligent Sensing, Queen Mary University of London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968183/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17153980421927247446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Centre for Intelligent Sensing",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968290",
        "title": "Augmented Reality Controlled Smart Wheelchair Using Dynamic Signifiers for Affordance Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of augmented reality interfaces for people with mobility impairments is a novel area with great potential, as well as multiple outstanding research challenges. In this paper we present an augmented reality user interface for controlling a smart wheelchair with a head-mounted display to provide assistance for mobility restricted people. Our motivation is to reduce the cognitive requirements needed to control a smart wheelchair. A key element of our platform is the ability to control the smart wheelchair using the concepts of affordances and signifiers. In addition to the technical details of our platform, we present a baseline study by evaluating our platform through user-trials of able-bodied individuals and two different affordances: 1) Door Go Through and 2) People Approach. To present these affordances to the user, we evaluated fixed symbol based signifiers versus our novel dynamic signifiers in terms of ease to understand the suggested actions and its relation with the objects. Our results show a clear preference for dynamic signifiers. In addition, we show that the task load reported by participants is lower when controlling the smart wheelchair with our augmented reality user interface compared to using the joystick, which is consistent with their qualitative answers.",
        "primary_area": "",
        "author": "Rodrigo Chac\u00f3n-Quesada;Yiannis Demiris;Rodrigo Chac\u00f3n-Quesada;Yiannis Demiris",
        "authorids": "/37086064938;/37296338900;/37086064938;/37296338900",
        "aff": "Personal Robotics Laboratory, Imperial College London, UK; Personal Robotics Laboratory, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968290/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9855107014187302525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Personal Robotics Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968269",
        "title": "Augmenting Knowledge through Statistical, Goal-oriented Human-Robot Dialog",
        "track": "main",
        "status": "Poster",
        "abstract": "Some robots can interact with humans using natural language, and identify service requests through human-robot dialog. However, few robots are able to improve their language capabilities from this experience. In this paper, we develop a dialog agent for robots that is able to interpret user commands using a semantic parser, while asking clarification questions using a probabilistic dialog manager. This dialog agent is able to augment its knowledge base and improve its language capabilities by learning from dialog experiences, e.g., adding new entities and learning new ways of referring to existing entities. We have extensively evaluated our dialog system in simulation as well as with human participants through MTurk and real-robot platforms. We demonstrate that our dialog agent performs better in efficiency and accuracy in comparison to baseline learning agents. Demo video can be found at https://youtu.be/DFB3jbHBqYE.",
        "primary_area": "",
        "author": "Saeid Amiri;Sujay Bajracharya;Cihangir Goktolgal;Jesse Thomason;Shiqi Zhang;Saeid Amiri;Sujay Bajracharya;Cihangir Goktolgal;Jesse Thomason;Shiqi Zhang",
        "authorids": "/37087322559;/37087323913;/37087322316;/37086936057;/37086294744;/37087322559;/37087323913;/37087322316;/37086936057;/37086294744",
        "aff": "SUNY Binghamton; Cleveland State University; SUNY Binghamton; University of Washington; SUNY Binghamton",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968269/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2954287523135334049&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "State University of New York at Binghamton;Cleveland State University;University of Washington",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.binghamton.edu;https://www.csuohio.edu;https://www.washington.edu",
        "aff_unique_abbr": "SUNY Binghamton;CSU;UW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Binghamton;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968446",
        "title": "Automated Boxwood Topiary Trimming with a Robotic Arm and Integrated Stereo Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an integrated hardware-software solution to perform fully automated robotic bush trimming to user-specified shapes. In contrast to specialized solutions that can trim only bushes of a certain shape, the approach ensures flexibility via a vision-based shape fitting module that allows fitting an arbitrary mesh into a bush at hand. A trimming planning method considers the available degrees of freedom of the robot arm to achieve effective cutting motions. The performance of the mesh fitting module is assessed in multiple experiments involving both artificial and real plants with a variety of shapes. The trimming accuracy of the overall approach is quantitatively evaluated by inspecting the bush pointcloud before and after robotic trimming, and measuring the change in the deviation from the originally computed target mesh.",
        "primary_area": "",
        "author": "Dejan Kaljaca;Nikolaus Mayer;Bastiaan Vroegindeweij;Angelo Mencarelli;Eldert van Henten;Thomas Brox;Dejan Kaljaca;Nikolaus Mayer;Bastiaan Vroegindeweij;Angelo Mencarelli;Eldert van Henten;Thomas Brox",
        "authorids": "/37087324980;/37086107404;/37087323571;/37087323920;/37087323279;/37541664500;/37087324980;/37086107404;/37087323571;/37087323920;/37087323279;/37541664500",
        "aff": "Farm Technology Group of Wageningen University; Department of Computer Science, University of Freiburg, Germany; Farm Technology Group of Wageningen University; Wageningen Plant Research; Farm Technology Group of Wageningen University; Department of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968446/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18333090700541312243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;1",
        "aff_unique_norm": "Wageningen University;University of Freiburg;Wageningen University & Research",
        "aff_unique_dep": "Farm Technology Group;Department of Computer Science;Plant Research",
        "aff_unique_url": "https://www.wageningen.edu;https://www.uni-freiburg.de;https://www.wur.nl",
        "aff_unique_abbr": "WU;;WUR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;1",
        "aff_country_unique": "Netherlands;Germany"
    },
    {
        "id": "8968487",
        "title": "Automated Macro-Micro Manipulation for Robotic Microinjection with Computer Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Extensive research efforts have been made toward automating the microinjection of biological cells by leveraging micro-robotic technologies. However, to best knowledge of the authors, there is no report on the automation of the time-consuming process: moving the injection tools (a micropipette, a grippers, etc.) and cells into the field of view (FOV) of microscope from the macro FOV(outside the microscopic FOV). This paper presents a novel macro-micro conversion strategy, and a grid detection and positioning algorithm to automate the time-consuming step of moving the injection tools and cells to the microscopic FOV. The proposed solution can free the technician from the laborious hand-eye coordination operations for moving the injection tools and cells to the target position within the microscopic FOV. Furthermore, this paper proposes an auto-focusing algorithm to automate the operation step: moving down the gripper from the air outside the culture media and then precisely clamping a cell in the liquid environment for injection. In the proposed solution, the active window-based auto-focusing algorithm is developed to solve the challenging problem: the image information is lost due to the \u201cviscous effect\u201d taking place when the gripper jaw touches the water surface. The proposed solutions are tested and validated by the microinjection experiments of zebrafish embryos using the in-house develop micro-robotic system. The technologies and strategies proposed in this paper significantly improve the automation level of the cell microinjections, and can be easily extended to any other micromanipulation of biological cells.",
        "primary_area": "",
        "author": "Huipeng Zhang;Liying Su;Hongmiao Wei;Yueqing Yu;Xuping Zhang;Huipeng Zhang;Liying Su;Hongmiao Wei;Yueqing Yu;Xuping Zhang",
        "authorids": "/37086963665;/37267887600;/37086958698;/37279649800;/37085664403;/37086963665;/37267887600;/37086958698;/37279649800;/37085664403",
        "aff": "College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, Beijing, China; College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, Beijing, China; College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, Beijing, China; College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, Beijing, China; Department of Engineering, Aarhus University Aarhus, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968487/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14325593393284242791&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Beijing University of Technology;Aarhus University",
        "aff_unique_dep": "College of Mechanical Engineering and Applied Electronics Technology;Department of Engineering",
        "aff_unique_url": "http://www.bjut.edu.cn;https://www.au.dk",
        "aff_unique_abbr": "BJUT;AU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Beijing;Aarhus",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;Denmark"
    },
    {
        "id": "8968207",
        "title": "Automated Sorting of Rare Cells Based on Autofocusing Visual Feedback in Fluorescence Microscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "The research on rare cells makes a significant contribution to biology research and medical treatment for the application of diagnostic operation as well as prognoses treatment. Therefore, sorting them from heterogeneous mixtures is crucial and valuable. Traditional cell sorting methods featured with poor purity and recovery rate as well as limited flexibility, which are not ideal approaches for rare type. In this paper, we proposed a cell screening method based on automated microrobotic aspiration-and-placement strategy under fluorescence microscope. An innovative autofocusing visual feedback (AVF) method is proposed for precise three-dimensional (3D) locating of target cells. For depth detection, multiple depth from defocus (MDFD) method is adopted to solve symmetry problem and attain an average accuracy of 97.07%. For planar locating, Markov random field (MRF) based locating method is utilized to separate and locate the overlapped cells. The end actuator locating and real-time tracking are performed relying on normalized cross-correlation (NCC) method. Experiential results show that our system collects rare cells (100 cells ml-1) at a speed of 5 cells min-1 with 90% purity and 75% recovery rate, which is valuable for biological and medical application.",
        "primary_area": "",
        "author": "Kailun Bai;Huaping Wang;Qing Shi;Zhiqiang Zheng;Juan Cui;Tao Sun;Qiang Huang;Paolo Dario;Toshio Fukuda;Kailun Bai;Huaping Wang;Qing Shi;Zhiqiang Zheng;Juan Cui;Tao Sun;Qiang Huang;Paolo Dario;Toshio Fukuda",
        "authorids": "/37087325013;/37964523300;/37593189500;/37086355207;/37086355009;/38022518100;/37279982900;/37280269300;/37279174500;/37087325013;/37964523300;/37593189500;/37086355207;/37086355009;/38022518100;/37279982900;/37280269300;/37279174500",
        "aff": "Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, CHINA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968207/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17328163035641981829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Mechatronical Engineering",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968230",
        "title": "Automatic Annotation for Semantic Segmentation in Indoor Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Domestic robots could eventually transform our lives, but safely operating in home environments requires a rich understanding of indoor scenes. Learning-based techniques for scene segmentation require large-scale, pixel-level annotations, which are laborious and expensive to collect. We propose an automatic method for pixel-wise semantic annotation of video sequences, that gathers cues from object detectors and indoor 3D room-layout estimation and then annotates all the image pixels in an energy minimization framework. Extensive experiments on a publicly available video dataset (SUN3D) evaluate the approach and demonstrate its effectiveness.",
        "primary_area": "",
        "author": "Md Alimoor Reza;Akshay U. Naik;Kai Chen;David J. Crandall;Md Alimoor Reza;Akshay U. Naik;Kai Chen;David J. Crandall",
        "authorids": "/37086063470;/37087323430;/37087323271;/37282605100;/37086063470;/37087323430;/37087323271;/37282605100",
        "aff": "School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; School of Computer Science, Fudan University, Shanghai, China; School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968230/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13348307243302194776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Indiana University;Fudan University",
        "aff_unique_dep": "School of Informatics, Computing, and Engineering;School of Computer Science",
        "aff_unique_url": "https://www.indiana.edu;https://www.fudan.edu.cn",
        "aff_unique_abbr": "IU;Fudan",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Bloomington;Shanghai",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967797",
        "title": "Automatic Calibration of Multiple 3D LiDARs in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiple LiDARs have progressively emerged on autonomous vehicles for rendering a rich view and dense measurements. However, the lack of precise calibration negatively affects their potential applications. In this paper, we propose a novel system that enables automatic multi-LiDAR calibration method without any calibration target, prior environment information, and manual initialization. Our approach starts with a hand-eye calibration by aligning the motion of each sensor. The initial results are then refined by an appearance-based method by minimizing a cost function constructed by point-plane distance. Experimental results on simulated and real-world data demonstrate the reliability and accuracy of our calibration approach. The proposed approach can calibrate a multi-LiDAR system with the rotation and translation errors less than 0. 04rad and 0. 1m respectively for a mobile platform.",
        "primary_area": "",
        "author": "Jianhao Jiao;Yang Yu;Qinghai Liao;Haoyang Ye;Rui Fan;Ming Liu;Jianhao Jiao;Yang Yu;Qinghai Liao;Haoyang Ye;Rui Fan;Ming Liu",
        "authorids": "/37086552343;/37086962478;/37086189742;/37086022108;/37085892666;/37085398677;/37086552343;/37086962478;/37086189742;/37086022108;/37085892666;/37085398677",
        "aff": "RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China; RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China; RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China; RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China; RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China; RAM-LAB, The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967797/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5747178586055236579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "RAM-LAB",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967740",
        "title": "Automatic Cell Assembly by Two-fingered Microhand",
        "track": "main",
        "status": "Poster",
        "abstract": "We have successfully achieved manipulation and assembly of microbeads having the size of 100\u03bcm diameter by hemispherical end-effectors with high stability and accuracy. The motivation of achieving assembly of actual cells lies in the great significance of it in tissue regeneration and cell analysis. Firstly, the most difficult problem we need to solve is the releasing problem caused by adhesion force. The viscosity on cell surface is much larger than the microbeads which makes cell releasing challenging. Secondly, the cell can generate its deformation, then contact area with end-effector will change during grasping process. This may influence the adhesion force and also bring problem to releasing. Thirdly, cell is much smaller, around 15\u03bcm in diameter, so we need to fabricate smaller end-effector to achieve successful manipulation and ensure the stability in the meantime. In this paper, we realize the manipulation by decreasing the adhesion forces and apply vibration to release a cell stably. We found the appropriate scale size for the end-effector is around 10\u03bcm diameter. It can not only grasp a 15\u03bcm cell but also bring little interference to the environment. As a demonstration of the proposed manipulation method, the repeated experiments were conducted to explore the dependence of adhesion force on the grasping distance, which can be helpful in the improvement of successful rate. Finally, we achieved automatic cell assembly using Hela cells.",
        "primary_area": "",
        "author": "Junnan Chen;Xiaoming Liu;Shengnan Dong;Pengyun Li;Xiaoqing Tang;Dan Liu;Masaru Kojima;Qiang Huang;Tatsuo Arai;Junnan Chen;Xiaoming Liu;Shengnan Dong;Pengyun Li;Xiaoqing Tang;Dan Liu;Masaru Kojima;Qiang Huang;Tatsuo Arai",
        "authorids": "/37086476841;/37085366355;/37086476320;/37086476112;/37086473572;/37086960115;/37528394100;/37279982900;/37281360800;/37086476841;/37085366355;/37086476320;/37086476112;/37086473572;/37086960115;/37528394100;/37279982900;/37281360800",
        "aff": "Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Department of Systems Innovation, Graduate school of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Intelligent Robotics Institute School of Mechatronical Engineering Key Laboratory of Biomimetic Robots and Systems Ministry of Education Key Laboratory of Intelligent Control and Decision of Complex System Beijing Institute of Technology, Beijing, CHINA; Global Alliance Lab, The University of Electro-Communications, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967740/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:T1Mrdrh69qEJ:scholar.google.com/&scioq=Automatic+Cell+Assembly+by+Two-fingered+Microhand&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;0;2",
        "aff_unique_norm": "Beijing Institute of Technology;Osaka University;University of Electro-Communications",
        "aff_unique_dep": "School of Mechatronical Engineering;Department of Systems Innovation;Global Alliance Lab",
        "aff_unique_url": "http://www.bit.edu.cn/;https://www.osaka-u.ac.jp;https://www.uec.ac.jp",
        "aff_unique_abbr": "BIT;Osaka U;UEC",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0;2",
        "aff_campus_unique": "Beijing;Toyonaka;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8968286",
        "title": "Automatic Spatial Template Generation for Realistic 3D Modeling of Large-Scale Indoor Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a realistic indoor modeling framework for large-scale indoor spaces. The proposed framework reduces the geometric complexity of an indoor model to efficiently represent large-scale environments for image-based rendering (IBR) approaches. For this purpose, the proposed framework removes geometrically excluded objects (GEOs) in point cloud and images, which represent the primary factors in high geometric complexity. In particular, GEOs are coherently removed from all images using a global geometry model. Then, the remaining holes are inpainted using globally consistent guidelines, to achieve accurate image blending in IBR approaches. The experimental results verify that the proposed GEO removal framework provides efficient point clouds and images for realistic indoor modeling in large-scale indoor spaces.",
        "primary_area": "",
        "author": "Janghun Hyeon;Hyunga Choi;JooHyung Kim;Bumchul Jang;Jaehyeon Kang;Nakju Doh;Janghun Hyeon;Hyunga Choi;JooHyung Kim;Bumchul Jang;Jaehyeon Kang;Nakju Doh",
        "authorids": "/37086619216;/37085525873;/37068770800;/37087324697;/37085528615;/37424560400;/37086619216;/37085525873;/37068770800;/37087324697;/37085528615;/37424560400",
        "aff": "School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968286/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15238894574913704250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Korea University",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "http://www.korea.ac.kr",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968276",
        "title": "Autonomous Hybrid Ground/Aerial Mobility in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Hybrid ground and aerial vehicles can possess distinct advantages over ground-only or flight-only designs in terms of energy savings and increased mobility. In this work we outline our unified framework for controls, planning, and autonomy of hybrid ground/air vehicles. Our contribution is three-fold: 1) We develop a control scheme for the control of passive two-wheeled hybrid ground/aerial vehicles. 2) We present a unified planner for both rolling and flying by leveraging differential flatness mappings. 3) We conduct experiments leveraging mapping and global planning for hybrid mobility in unknown environments, showing that hybrid mobility uses up to five times less energy than flying only1.1Video at https://youtu.be/nlGfYehTLpg.",
        "primary_area": "",
        "author": "David D. Fan;Rohan Thakker;Tara Bartlett;Meriem Ben Miled;Leon Kim;Evangelos Theodorou;Ali-akbar Agha-mohammadi;David D. Fan;Rohan Thakker;Tara Bartlett;Meriem Ben Miled;Leon Kim;Evangelos Theodorou;Ali-akbar Agha-mohammadi",
        "authorids": "/37086010932;/37085356248;/37087323491;/37087324790;/37087321913;/37546007800;/38274170800;/37086010932;/37085356248;/37087323491;/37087324790;/37087321913;/37546007800;/38274170800",
        "aff": "NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968276/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6672014159281532974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "California Institute of Technology;Georgia Institute of Technology",
        "aff_unique_dep": "NASA Jet Propulsion Laboratory;Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.caltech.edu;https://www.gatech.edu",
        "aff_unique_abbr": "Caltech;Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Pasadena;Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968196",
        "title": "Autonomous Safe Locomotion System for Bipedal Robot Applying Vision and Sole Reaction Force to Footstep Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Humanoid robots are expected to conduct tasks on behalf of humans in places such as a disaster scattered environment. Although humanoid robots have potentials to walk on uneven ground unlike wheeled robots, it is difficult to reach a given destination without falling down based on only visual information. In this paper, to reach the destination safely, we propose the autonomous safe locomotion system applying vision and sole reaction force to the footstep planning. Considering force information in addition to visual information, the robot can plan a path avoiding unstable footholds. The planned path is safer than a path which is planned based on only visual information. In our system, the robot checks if the foothold is safe or not by the foothold ascertainment motion. In addition to that, the robot saves the results of the motion to the database with the foothold label given by the visual classifier. To judge foothold safety, stiffness of the foothold is estimated from the reaction force and stepping amount. We propose the system considering these requirements for safe locomotion for bipedal robots and show experimental results using a real bipedal robot CHIDORI.",
        "primary_area": "",
        "author": "Yuki Omori;Yuta Kojio;Tatsuya Ishikawa;Kunio Kojima;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Yuki Omori;Yuta Kojio;Tatsuya Ishikawa;Kunio Kojima;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086458612;/37086211574;/38148331500;/37085360901;/37085651948;/38242437800;/37280639000;/37286658200;/37086458612;/37086211574;/38148331500;/37085360901;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "Yuki Omori; Yuta Kojio; Tatsuya Ishikawa; Kunio Kojima; Fumihito Sugai; Yohei Kakiuchi; Kei Okada; Masayuki Inaba",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968196/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12842229503948320771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8967593",
        "title": "Autonomous Steering of Concentric Tube Robots for Enhanced Force/Velocity Manipulability",
        "track": "main",
        "status": "Poster",
        "abstract": "Concentric tube robots (CTR) can traverse tightly curved paths and offer dexterity in constrained environments, making them advantageous for minimally invasive surgical scenarios that experience strict anatomical and surgical constraints. Their shape is controlled via rotation and translation of several concentrically arranged super-elastic precurved tubes that form the robot backbone. As the elastic energy accumulated in the backbone due to bending and twist of the tubes increases, robots can exhibit sudden snapping motions, which can damage the surrounding tissues. In this paper, we proposed an approach for closed-loop steering of a redundant CTR that allows for snap-free motion and enhances its force/velocity manipulability, increasing the capacity of the robot to move and/or exercise forces along any direction. First, a controller stabilizes the CTR end-effector on a desired time-variant trajectory. Next, an online optimizer uses the robot's redundant Degrees of Freedom (DoF) to reshape its manipulability in real-time and steer it away from potentially snapping configurations or increase its capacity in delivering force payloads. Simulations and experiments demonstrate the performance of the proposed control strategy. The controller can steer a generally unstable CTR along trajectories while avoiding instabilities with a mean error of 850 \u03bcm, corresponding to 0.6% of arclength, and improves robot ability to exercise forces by 55%.",
        "primary_area": "",
        "author": "Mohsen Khadem;John O\u2019Neill;Zisos Mitros;Lyndon da Cruz;Christos Bergeles;Mohsen Khadem;John O\u2019Neill;Zisos Mitros;Lyndon da Cruz;Christos Bergeles",
        "authorids": "/37085447737;/37085456410;/37085871075;/37087322775;/37399073100;/37085447737;/37085456410;/37085871075;/37087322775;/37399073100",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Biomedical Engineering and Imaging Sciences, King\u2019s College London, London, UK; School of Biomedical Engineering and Imaging Sciences, King\u2019s College London, London, UK; UCL Wellcome/EPSRC Centre for Interventional and Surgical Engineering Sciences, UCL; School of Biomedical Engineering and Imaging Sciences, King\u2019s College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967593/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5161449265531453967&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "University of Edinburgh;King\u2019s College London;University College London",
        "aff_unique_dep": "School of Informatics;School of Biomedical Engineering and Imaging Sciences;UCL Wellcome/EPSRC Centre for Interventional and Surgical Engineering Sciences",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.kcl.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Edinburgh;KCL;UCL",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Edinburgh;London;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967850",
        "title": "Autonomous landing on pipes using soft gripper for inspection and maintenance in outdoor environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of unmanned aerial systems for industrial applications has evolved considerably in recent years. This paper presents an aerial system capable of perching autonomously on pipes for inspection and maintenance in industrial environments. The target pipe to perch on is detected using a visual algorithm based on a semantic convolutional neuronal network. The information from a color camera is used to segment the image. Then, the segmentation information is fused with a depth image to estimate the pipe's pose, so that the pose of the robot can be controlled relative to it. The aerial robot is equipped with a soft landing system that robustly attaches it to the pipe. The article presents the complete development of the system. Experimental results performed in outdoor environments are shown.",
        "primary_area": "",
        "author": "P. Ramon-Soria;A.E. Gomez-Tamm;F.J. Garcia-Rubiales;B.C. Arrue;A. Ollero;P. Ramon-Soria;A.E. Gomez-Tamm;F.J. Garcia-Rubiales;B.C. Arrue;A. Ollero",
        "authorids": "/37086942931;/37087322181;/37087324945;/37444998200;/37265412000;/37086942931;/37087322181;/37087324945;/37444998200;/37265412000",
        "aff": "Group of Robotics, Vision and Contol, University of Seville. Camino de los descubrimientos S/N 41092; Group of Robotics, Vision and Contol, University of Seville. Camino de los descubrimientos S/N 41092; Group of Robotics, Vision and Contol, University of Seville. Camino de los descubrimientos S/N 41092; Group of Robotics, Vision and Contol, University of Seville. Camino de los descubrimientos S/N 41092; Group of Robotics, Vision and Contol, University of Seville. Camino de los descubrimientos S/N 41092",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967850/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18180653277154652737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "Group of Robotics, Vision and Control",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "US",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968009",
        "title": "Avoiding Obstacles during Push Recovery Using Real-Time Vision Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an obstacle-avoiding algorithm for bipedal robots, especially in push recovery situations. Typically, There are many algorithms that plan footstep to avoid obstacles based on vision recognition data. However, if the robot is pushed, the planned footprint will change, and thus, there is no guarantee that it will avoid obstacles. Although modified stepping positions can be limited, the robot's stability is not assured. Our proposed algorithm focuses on avoiding obstacles through vision recognition in push recovery situations and generating compensation actions for instability by restricting modified footsteps. We fuse vision feedback with our previous push recovery algorithm, which optimizes the ankle, hip, and stepping strategies. We build simple grid data using vision recognition and apply it to the inequality constraint of the stepping position. We validate the effectiveness of our algorithm using the bipedal platform GAZELLE with the Kinect V2 RGBD sensor.",
        "primary_area": "",
        "author": "Hyobin Jeong;Joon-Ha Kim;Okkee Sim;Jun-Ho Oh;Hyobin Jeong;Joon-Ha Kim;Okkee Sim;Jun-Ho Oh",
        "authorids": "/37085760405;/37087322590;/37085750907;/37292052500;/37085760405;/37087322590;/37085750907;/37292052500",
        "aff": "Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968009/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11938620548698796014&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Mechanical, Aerospace & Systems Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968298",
        "title": "BP Neural Network Based On-board Training for Real-time Locomotion Mode Recognition in Robotic Transtibial Prostheses",
        "track": "main",
        "status": "Poster",
        "abstract": "Locomotion mode recognition based on the off-line trained model brings difficulties in integration and application to wearable robots. In this paper, we put forward an on-board training based on back propagation (BP) neural network and developed the real-time locomotion mode recognition research in robotic transtibial prosthesis. Three transtibial amputees participated in the study to finish the designed six experimental tasks (standing, level ground walking, stair ascending and descending, ramp ascending and descending) with robotic transtibial prostheses. Data of six locomotion modes were collected under normal speed condition as training data set to train model on board. Based on the on-board trained models, real-time recognition experiments were developed under three different speeds conditions. The total recognition accuracies were 91.54%, 96.72% and 95.35% corresponding to slow, normal and fast speeds, respectively. The results showed some adaptation of recognition for the six locomotion modes at different speeds. The on-board training strategy was feasible and effective with satisfactory performance.",
        "primary_area": "",
        "author": "Dongfang Xu;Qining Wang;Dongfang Xu;Qining Wang",
        "authorids": "/37086270322;/37577407400;/37086270322;/37577407400",
        "aff": "Robotics Research Group, College of Engineering, Peking University, Beijing, China; Beijing Innovation Center for Engineering Science and Advanced Technology (BIC-ESAT), Peking University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968298/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=269828798837266194&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968507",
        "title": "Basic Performance of Planar Omnidirectional Crawler during Direction Switching using Disturbance Degree of Ground Evaluation Method",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduced the disturbance degree of ground and proposed an evaluation method to measure the mobile performance of a crawler on soft ground during direction switching. First, we developed a planar omnidirectional crawler, which had a configuration with two left and right unit crawlers for performing turning motion, as the target for evaluation. Second, by utilizing the proposed disturbance degree of ground evaluation method, we investigated how the turning and translational motions of the crawler mechanism affected soft ground by measuring the flow of sand on a horizontal surface. It was quantitatively shown that translational motion switched the travel direction with lesser disturbance to the road surface compared to turning motion. We confirmed that ground disturbance could be evaluated during direction switching using the proposed method.",
        "primary_area": "",
        "author": "Eri Takane;Kenjiro Tadakuma;Tori Shimizu;Sosuke Hayashi;Masahiro Watanabe;Shingo Kagami;Keiji Nagatani;Masashi Konyo;Satoshi Tadokoro;Eri Takane;Kenjiro Tadakuma;Tori Shimizu;Sosuke Hayashi;Masahiro Watanabe;Shingo Kagami;Keiji Nagatani;Masashi Konyo;Satoshi Tadokoro",
        "authorids": "/37086003949;/38534909200;/37087013645;/37087013774;/37403419100;/37273845900;/37283174900;/37296053600;/37296054300;/37086003949;/38534909200;/37087013645;/37087013774;/37403419100;/37273845900;/37283174900;/37296053600;/37296054300",
        "aff": "Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968507/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6879155410252696896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Graduate School of Information Sciences",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967736",
        "title": "Bayesian Optimization for Policy Search in High-Dimensional Systems via Automatic Domain Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Bayesian Optimization (BO) is an effective method for optimizing expensive-to-evaluate black-box functions with a wide range of applications for example in robotics, system design and parameter optimization. However, scaling BO to problems with large input dimensions (>10) remains an open challenge. In this paper, we propose to leverage results from optimal control to scale BO to higher dimensional control tasks and to reduce the need for manually selecting the optimization domain. The contributions of this paper are twofold: 1) We show how we can make use of a learned dynamics model in combination with a model-based controller to simplify the BO problem by focusing onto the most relevant regions of the optimization domain. 2) Based on (1) we present a method to find an embedding in parameter space that reduces the effective dimensionality of the optimization problem. To evaluate the effectiveness of the proposed approach, we present an experimental evaluation on real hardware, as well as simulated tasks including a 48-dimensional policy for a quadcopter.",
        "primary_area": "",
        "author": "Lukas P. Fr\u00f6hlich;Edgar D. Klenske;Christian G. Daniel;Melanie N. Zeilinger;Lukas P. Fr\u00f6hlich;Edgar D. Klenske;Christian G. Daniel;Melanie N. Zeilinger",
        "authorids": "/37087322364;/37085760627;/38194685500;/37398798800;/37087322364;/37085760627;/38194685500;/37398798800",
        "aff": "Robert Bosch GmbH, Bosch Center for Artificial Intelligence, Renningen, Germany; Robert Bosch GmbH, Bosch Center for Artificial Intelligence, Renningen, Germany; Robert Bosch GmbH, Bosch Center for Artificial Intelligence, Renningen, Germany; ETH Zurich, Institute for Dynamic Systems and Control, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967736/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8405342405492467351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Robert Bosch GmbH;ETH Zurich",
        "aff_unique_dep": "Bosch Center for Artificial Intelligence;Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.bosch.com;https://www.ethz.ch",
        "aff_unique_abbr": "Bosch;ETHZ",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Renningen;Zurich",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "8967564",
        "title": "BeBOT: Bernstein Polynomial Toolkit for Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method and an open-source implementation (BeBOT) for the generation of trajectories for autonomous system operations using Bernstein polynomials. Bernstein polynomials possess convenient geometric properties that enable the trajectory planner to efficiently evaluate and impose constraints along the vehicles' trajectories, such as maximum speed and angular rates, minimum distance between trajectories and between the vehicles and obstacles. Thus, the proposed method is particularly suitable for generating trajectories in real-time for safe operations in complex environments and multiple vehicle missions.",
        "primary_area": "",
        "author": "Calvin Kielas-Jensen;Venanzio Cichella;Calvin Kielas-Jensen;Venanzio Cichella",
        "authorids": "/37087322566;/38232810000;/37087322566;/38232810000",
        "aff": "Mechanical Engineering department, University of Iowa, Iowa City, IA, USA; Mechanical Engineering department, University of Iowa, Iowa City, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967564/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1140951713034373902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Iowa",
        "aff_unique_dep": "Mechanical Engineering department",
        "aff_unique_url": "https://www.uiowa.edu",
        "aff_unique_abbr": "UIowa",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Iowa City",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967676",
        "title": "Belief Space Metareasoning for Exception Recovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the complexity of the real world, autonomous systems use decision-making models that rely on simplifying assumptions to make them computationally tractable and feasible to design. However, since these limited representations cannot fully capture the domain of operation, an autonomous system may encounter unanticipated scenarios that cannot be resolved effectively. We first formally introduce an introspective autonomous system that uses belief space metareasoning to recover from exceptions by interleaving a main decision process with a set of exception handlers. We then apply introspective autonomy to autonomous driving. Finally, we demonstrate that an introspective autonomous vehicle is effective in simulation and on a fully operational prototype.",
        "primary_area": "",
        "author": "Justin Svegliato;Kyle Hollins Wray;Stefan J. Witwicki;Joydeep Biswas;Shlomo Zilberstein;Justin Svegliato;Kyle Hollins Wray;Stefan J. Witwicki;Joydeep Biswas;Shlomo Zilberstein",
        "authorids": "/37072711700;/37086208879;/37085709708;/37538259200;/37285091900;/37072711700;/37086208879;/37085709708;/37538259200;/37285091900",
        "aff": "College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; Alliance Innovation Lab Silicon Valley, Santa Clara, CA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967676/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=965433808425198976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst;Alliance Innovation Lab",
        "aff_unique_dep": "College of Information and Computer Sciences;",
        "aff_unique_url": "https://www.umass.edu;",
        "aff_unique_abbr": "UMass Amherst;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Amherst;Silicon Valley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968119",
        "title": "Belief-Driven Control Policy of a Drone with Microphones for Multiple Sound Source Search",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a belief-driven control policy of a drone with microphones for multiple sound source search. As the sound source localization by drones is uncertain because of the observation significantly distorted by noise such as rotor noise, the belief on the estimated targets may consist of multiple peaks that are spread over the bounded search area. The proposed control policy is formulated with a robust cost function so that the function encodes the search mission properly. A peak management mechanism is additionally introduced to keep tracking all targets by masking sufficiently observed and well estimated targets whose peaks normally become steep and high. The proposed control policy was evaluated by numerical simulations, and experiments, and those results have validated the efficacy of the proposed control policy.",
        "primary_area": "",
        "author": "Kenshiro Yamada;Makoto Kumon;Tomonari Furukawa;Kenshiro Yamada;Makoto Kumon;Tomonari Furukawa",
        "authorids": "/37087322706;/37296098600;/37280186200;/37087322706;/37296098600;/37280186200",
        "aff": "Graduate School of Science and Technology, Kumamoto University 2-39-1, Kurokami, Chuoku, Kumamoto, Japan; Faculty of Advanced Science and Technology, and International Research Organization of Advanced Science and Technology, Kumamoto University, 2-39-1, Kurokami, Chuoku, Kumamoto, Japan; Deparment of Mechanical Engineering, Virginia Polytechnic Institute and State University, 635 Prices Fork Road - MC 0238 Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968119/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18113719539499823746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Kumamoto University;Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Graduate School of Science and Technology;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kumamoto-u.ac.jp;https://www.vt.edu",
        "aff_unique_abbr": "Kumamoto U;VT",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Kumamoto;Blacksburg",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "8967694",
        "title": "Benchmarking and Workload Analysis of Robot Dynamics Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Rigid body dynamics calculations are needed for many tasks in robotics, including online control. While there currently exist several competing software implementations that are sufficient for use in traditional control approaches, emerging sophisticated motion control techniques such as nonlinear model predictive control demand orders of magnitude more frequent dynamics calculations. Current software solutions are not fast enough to meet that demand for complex robots. The goal of this work is to examine the performance of current dynamics software libraries in detail. In this paper, we (i) survey current state-of-the-art software implementations of the key rigid body dynamics algorithms (RBDL, Pinocchio, Rigid-BodyDynamics.jl, and RobCoGen), (ii) establish a methodology for benchmarking these algorithms, and (iii) characterize their performance through real measurements taken on a modern hardware platform. With this analysis, we aim to provide direction for future improvements that will need to be made to enable emerging techniques for real-time robot motion control. To this end, we are also releasing our suite of benchmarks to enable others to help contribute to this important task.",
        "primary_area": "",
        "author": "Sabrina M. Neuman;Twan Koolen;Jules Drean;Jason E. Miller;Srinivas Devadas;Sabrina M. Neuman;Twan Koolen;Jules Drean;Jason E. Miller;Srinivas Devadas",
        "authorids": "/37062893900;/37681802300;/37086836404;/37275462900;/37283553100;/37062893900;/37681802300;/37086836404;/37275462900;/37283553100",
        "aff": "MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967694/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7138515837645634189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968182",
        "title": "Better Lost in Transition Than Lost in Space: SLAM State Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "A Simultaneous Localization and Mapping (SLAM) system is a complex program consisting of several interconnected components with different functionalities such as optimization, tracking or loop detection. Whereas the literature addresses in detail how enhancing the algorithmic aspects of the individual components improves SLAM performance, the modal aspects, such as when to localize, relocalize or close a loop, are usually left aside. In this paper, we address the modal aspects of a SLAM system and show that the design of the modal controller has a strong impact on SLAM performance in particular in terms of robustness against unforeseen events such as sensor failures, perceptual aliasing or kidnapping. We preset a novel taxonomy for the components of a modern SLAM system, investigate their interplay and propose a highly modular architecture of a generic SLAM system using the Unified Modeling LanguageTM (UML) state machine formalism. The result, called SLAM state machine, is compared to the modal controller of several state-of-the-art SLAM systems and evaluated in two experiments. We demonstrate that our state machine handles unforeseen events much more robustly than the state-of-the-art systems.",
        "primary_area": "",
        "author": "Mirco Colosi;Sebastian Haug;Peter Biber;Kai O. Arras;Giorgio Grisetti;Mirco Colosi;Sebastian Haug;Peter Biber;Kai O. Arras;Giorgio Grisetti",
        "authorids": "/37086455775;/37722490500;/37301850700;/37276687700;/37324134600;/37086455775;/37722490500;/37301850700;/37276687700;/37324134600",
        "aff": "University La Sapienza of Rome, Italy; University La Sapienza of Rome, Italy; University La Sapienza of Rome, Italy; Robert Bosch Corporate Research, Stuttgart, Germany; University La Sapienza of Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968182/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11422818835258520819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Sapienza University of Rome;Robert Bosch Corporate Research",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uniroma1.it;https://research.bosch.com",
        "aff_unique_abbr": "Sapienza;Bosch Research",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Rome;Stuttgart",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "8967878",
        "title": "Bi-Modal Hemispherical Sensor: A Unifying Solution for Three Axis Force and Contact Angle Measurement",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic tasks that require physical interactions such as manipulation and legged locomotion, it is important to simultaneously measure contact forces and contact angles. This paper presents a unified solution for simultaneously measuring three axis contact forces and contact angles for legged locomotion or manipulation. Unlike most tactile sensors, the presented design utilizes the stress field method by sampling pressures over multiple locations within an elastomer, enabling inherently robust operation against impact and abrasive interactions. The presented sensor is designed for point-feet quadrupedal robots and can be easily scaled down for other applications such as grasping. The sampled stress distribution is mapped to output forces fx, fy, and fz and two contact angles, \u03b8 and \u03c8 on the hemispherical sensor surface via Gaussian process regression. The prototype sensor is able track normal and shear forces accurately, achieving a normalized root mean (RMS) squared error of only 1.00% - 1.36% for fz across multiple tests with up to 180N normal force, and a normalized RMS error of 1.71% - 4.67% and 1.82% - 6.68% for fx and fy, respectively, with up to 80N shear force. Additionally, the footpad is able to estimate the contact location coordinates \u03b8 and \u03c8 with a normalized RMS error of 2.69% -7.51% over a range of 0-40\u00b0 and 2.79% - 9.62% over a range of 0-30\u00b0, respectively. The footpad can estimate contact location over a maximum range of \u03b8 = \u00b145\u00b0 and \u03c8 = \u00b145\u00b0, and can withstand over 450N of normal force at location \u03b8 = \u03c8 = 0\u00b0 without reaching saturation. This prototype demonstrates the ability to simultaneously measure force in three axes and contact angles using Gaussian process regression, with the potential to explore other regression methods for embedded computing and miniaturization of the design for finger tip scale sensors.",
        "primary_area": "",
        "author": "Meng Yee Michael Chuah;Lindsay Epstein;Donghyun Kim;Juan Romero;Sangbae Kim;Meng Yee Michael Chuah;Lindsay Epstein;Donghyun Kim;Juan Romero;Sangbae Kim",
        "authorids": "/38541406400;/37087323559;/37085554176;/37087324997;/37537397200;/38541406400;/37087323559;/37085554176;/37087324997;/37537397200",
        "aff": "Robotics and Autonomous Systems (RAS) department, Institute for Infocomm Research (I2R), Singapore; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967878/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12126537181398445873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Institute for Infocomm Research;Massachusetts Institute of Technology",
        "aff_unique_dep": "Robotics and Autonomous Systems;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg;https://web.mit.edu",
        "aff_unique_abbr": "I2R;MIT",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8967796",
        "title": "Bidirectional Heuristic Search for Motion Planning with an Extend Operator",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based approaches are often favored in robotics for high-dimensional motion planning for their fast exploration of the search space. However, at best they offer asymptotic guarantees on solution quality due to their inherent stochasticity. While planning, the majority of effort is often spent near the start and goal configurations with a large amount of free space in between. Bidirectional approaches such as RRT-Connect exploit this fact by greedily extending and connecting search frontiers that simultaneously propagate from the start and goal configurations of a planning problem. In this work, we use such an extend operator for bidirectional heuristic search-based planners, which typically struggle with high-dimensionality. In doing so, we address the difficulty that these bidirectional planners face with connecting frontiers of both search efforts while providing suboptimality bounds on solution quality. We validate our simple approach on high-dimensional manipulation tasks, demonstrating significantly reduced search effort when compared against other popular bidirectional algorithms, both search-based and sampling. Our algorithm maintains theoretical guarantees on suboptimality and completeness for a given resolution. In addition, the solutions found by our planner are of higher quality compared to those found by the other baseline algorithms.",
        "primary_area": "",
        "author": "Allen Cheng;Dhruv Mauria Saxena;Maxim Likhachev;Allen Cheng;Dhruv Mauria Saxena;Maxim Likhachev",
        "authorids": "/37087322268;/37086188218;/37309318800;/37087322268;/37086188218;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967796/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2908392127276284816&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968291",
        "title": "Biped Robot Pelvis Kinematics Estimation based on the Touch-Point Updating Method",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a biped-robot pelvis-kinematics estimator based on the touch-point updating method. Because the pelvis frame is used as the base coordinate for the control, the kinematics of it with respect to the global frame should be precisely estimated. To this end, it was necessary to know where the robot made contact with the ground. The touch-point concept was introduced as the temporal contact-point, which was instantly the robot's rotation center. By updating this point, the biped's global pelvis-kinematics could be estimated. The proposed estimator was implemented into the actual robot, and its superiority was verified through ground-truth data.",
        "primary_area": "",
        "author": "Hyoin Bae;Jaesung Oh;Hyun-Min Joe;Jun-Ho Oh;Hyoin Bae;Jaesung Oh;Hyun-Min Joe;Jun-Ho Oh",
        "authorids": "/37085873378;/37085762789;/37085748137;/37292052500;/37085873378;/37085762789;/37085748137;/37292052500",
        "aff": "Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968291/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2326832838561948206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Mechanical, Aerospace & Systems Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967674",
        "title": "Boundary Effect-Aware Visual Tracking for UAV with Online Enhanced Background Learning and Multi-Frame Consensus Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to implicitly introduced periodic shifting of limited searching area, visual object tracking using correlation filters often has to confront undesired boundary effect. As boundary effect severely degrade the quality of object model, it has made it a challenging task for unmanned aerial vehicles (UAV) to perform robust and accurate object following. Traditional hand-crafted features are also not precise and robust enough to describe the object in the viewing point of UAV. In this work, a novel tracker with online enhanced background learning is specifically proposed to tackle boundary effects. Real background samples are densely extracted to learn as well as update correlation filters. Spatial penalization is introduced to offset the noise introduced by exceedingly more background information so that a more accurate appearance model can be established. Meanwhile, convolutional features are extracted to provide a more comprehensive representation of the object. In order to mitigate changes of objects' appearances, multi-frame technique is applied to learn an ideal response map and verify the generated one in each frame. Exhaustive experiments were conducted on 100 challenging UAV image sequences and the proposed tracker has achieved state-of-the-art performance.",
        "primary_area": "",
        "author": "Changhong Fu;Ziyuan Huang;Yiming Li;Ran Duan;Peng Lu;Changhong Fu;Ziyuan Huang;Yiming Li;Ran Duan;Peng Lu",
        "authorids": "/37086797986;/37086868757;/37087323806;/37086798983;/37087243038;/37086797986;/37086868757;/37087323806;/37086798983;/37087243038",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Adaptive Robotic Controls Lab (ArcLab), Hong Kong Polytechnic University (PolyU), Hong Kong; Adaptive Robotic Controls Lab (ArcLab), Hong Kong Polytechnic University (PolyU), Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967674/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9265079742484664913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Tongji University;Hong Kong Polytechnic University",
        "aff_unique_dep": "School of Mechanical Engineering;Adaptive Robotic Controls Lab (ArcLab)",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.polyu.edu.hk",
        "aff_unique_abbr": "Tongji;PolyU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Shanghai;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967750",
        "title": "Bounded-Error LQR-Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a feedback motion planning algorithm, Bounded-Error LQR-Trees, that leverages reinforcement learning theory to find a policy with a bounded amount of error. The algorithm composes locally valid linear-quadratic regulators (LQR) into a nonlinear controller, similar to how LQR-Trees constructs its policy, but minimizes the cost of the constructed policy by minimizing the Bellman Residual, which is estimated in the overlapping regions of LQR controllers. We prove a sample-based upper bound on the true Bellman Residual, and demonstrate a five-fold reduction in cost over previous methods on a simple underactuated nonlinear system.",
        "primary_area": "",
        "author": "Barrett Ames;George Konidaris;Barrett Ames;George Konidaris",
        "authorids": "/37085709574;/38318614200;/37085709574;/38318614200",
        "aff": "Duke University Computer Science; Brown University Computer Science",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967750/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9931826050888359282&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Duke University;Brown University",
        "aff_unique_dep": "Computer Science;Computer Science",
        "aff_unique_url": "https://www.duke.edu;https://www.brown.edu",
        "aff_unique_abbr": "Duke;Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967566",
        "title": "Buckling-induced Shape Morphing using Dielectric Elastomer Actuators Patterned with Spatially-varying Electrodes",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape morphing is at the core of future research, which shows promise for wide applications ranging from reconfigurable electronics to soft material robots. In this paper, we present a novel buckling-induced mechanism for shape morphing using dielectric elastomer actuators (DEAs), by bonding the planar precursor structure's \u201cfeet\u201d with the DEA. With spatially-varying electric fields applied, the inplane deformation of the DEA generates compressive loads to trigger buckling of planar precursors into desired three-dimensional configurations. To enlarge the achievable motion range at the \u201cfeet\u201d, we develop a design optimization approach to the electrode arrangement which is concisely described by cosine functions. By numerically optimizing the cosine function coefficients, we obtain the optimal spatially-varying electrodes for various precursors with different patterns of bonding sites. The experimental results demonstrate the remarkable shape-morphing from two dimensions to three dimensional configurations. Our work paves the way to novel actuation mechanisms for shape-morphing structures, with advantages of rapid response and reversible controllability.",
        "primary_area": "",
        "author": "Feifei Chen;Kun Liu;Xiangyang Zhu;Feifei Chen;Kun Liu;Xiangyang Zhu",
        "authorids": "/37085818046;/37087029422;/37278847400;/37085818046;/37087029422;/37278847400",
        "aff": "State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, and Robotics Institute, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, and Robotics Institute, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, and Robotics Institute, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967566/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14809228639814811818&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968159",
        "title": "CALC2.0: Combining Appearance, Semantic and Geometric Information for Robust and Efficient Visual Loop Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional attempts for loop closure detection typically use hand-crafted features, relying on geometric and visual information only, whereas more modern approaches tend to use semantic, appearance or geometric features extracted from deep convolutional neural networks (CNNs). While these approaches are successful in many applications, they do not utilize all of the information that a monocular image provides, and many of them, particularly the deep-learning based methods, require user-chosen thresholding to actually close loops - which may impact generality in practical applications. In this work, we address these issues by extracting all three modes of information from a custom deep CNN trained specifically for the task of place recognition. Our network is built upon a combination of a semantic segmentator, Variational Autoencoder (VAE) and triplet embedding network. The network is trained to construct a global feature space to describe both the visual appearance and semantic layout of an image. Then local keypoints are extracted from maximally-activated regions of low-level convolutional feature maps, and keypoint descriptors are extracted from these feature maps in a novel way that incorporates ideas from successful hand-crafted features. These keypoints are matched globally for loop closure candidates, and then used as a final geometric check to refute false positives. As a result, the proposed loop closure detection system requires no touchy thresholding, and is highly robust to false positives - achieving better precision-recall curves than the state-of-the-art NetVLAD, and with real-time speeds.",
        "primary_area": "",
        "author": "Nathaniel Merrill;Guoquan Huang;Nathaniel Merrill;Guoquan Huang",
        "authorids": "/37087322112;/37077670600;/37087322112;/37077670600",
        "aff": "Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware, Newark, DE; Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware, Newark, DE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968159/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3319863527620361956&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Dept. of Computer and Information Sciences",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968480",
        "title": "COBRA: COllaborative Bot with multi-Rotor Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Wheeled robots operating in the field are faced with mobility challenges such as drop-offs, slippery slopes, and cluttered environments. In these situations, it is desirable to have agile and highly mobile platforms. This paper explores the utilization of multiple rotors to enhance the mobility of ground vehicles. A strategy based on downward thrust generation is developed to increase traction and surmount otherwise non-traversable slippery inclines. Both simulation and experimental results are presented to show the efficacy of the proposed solution.",
        "primary_area": "",
        "author": "Camilo Ordonez;Oscar Chuy;Tomas Fajardo;Camilo Ordonez;Oscar Chuy;Tomas Fajardo",
        "authorids": "/37571185000;/37395949700;/37087322514;/37571185000;/37395949700;/37087322514",
        "aff": "Department of Mechanical Engineering, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Electrical Engineering, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Tallahassee, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968480/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2241430164719527862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "FAMU-FSU College of Engineering",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.famu-fsu.edu/engineering",
        "aff_unique_abbr": "FAMU-FSU Eng",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967716",
        "title": "Cable-Driven 4-DOF Upper Limb Rehabilitation Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper developed a 4-degree-of-freedom cable-driven upper limb rehabilitation robot and proposed a control algorithm of the passive training for this robot. Comparing with the conventional cable-driven rehabilitation robot, the workspace of this robot is increased by optimizing the distribution of the cable attachment points and by improving the mechanical design. The rotation structure of the upper arm module can change the distribution of the attachment points as needed, by which the cable tension planner can be satisfied in almost all cases. At the meantime, the internal/external rotation of shoulder joint can be achieved without the change of the cables configuration, which is also important for increasing the workspace and comfortability of utilization. The activities of daily living (ADLs) training can be achieved well without any manual adjustment. The related controller for passive training is designed, which includes a higher controller for trajectory tracking and a lower controller for keeping cable tension as the output of the tension planner in real-time. The passive training experiments are conducted on five healthy subjects of different body size. The results demonstrated that the passive training can be achieved well on different subjects and the cable tension controller is also working effectively.",
        "primary_area": "",
        "author": "Ke Shi;Aiguo Song;Ye Li;Dapeng Chen;Huijun Li;Ke Shi;Aiguo Song;Ye Li;Dapeng Chen;Huijun Li",
        "authorids": "/37086500721;/37276033000;/37089613376;/37085655578;/38240952000;/37086500721;/37276033000;/37089613376;/37085655578;/38240952000",
        "aff": "School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967716/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7649350862735789629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968590",
        "title": "Camera Exposure Control for Robust Robot Vision with Noise-Aware Image Quality Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a noise-aware exposure control algorithm for robust robot vision. Our method aims to capture best-exposed images, which can boost the performance of various computer vision and robotics tasks. For this purpose, we carefully design an image quality metric that captures complementary quality attributes and ensures light-weight computation. Specifically, our metric consists of a combination of image gradient, entropy, and noise metrics. The synergy of these measures allows the preservation of sharp edges and rich texture in the image while maintaining a low noise level. Using this novel metric, we propose a real-time and fully automatic exposure and gain control technique based on the Nelder-Mead method. To illustrate the effectiveness of our technique, a large set of experimental results demonstrates the higher qualitative and quantitative performance compared with conventional approaches.",
        "primary_area": "",
        "author": "Ukcheol Shin;Jinsun Park;Gyumin Shim;Francois Rameau;In So Kweon;Ukcheol Shin;Jinsun Park;Gyumin Shim;Francois Rameau;In So Kweon",
        "authorids": "/37087323766;/37085711113;/37087324667;/37892103100;/37270474800;/37087323766;/37085711113;/37087324667;/37892103100;/37270474800",
        "aff": "Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968590/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14945805358183267627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968180",
        "title": "Camera Pose Estimation with Semantic 3D Model",
        "track": "main",
        "status": "Poster",
        "abstract": "In computer vision, estimating camera pose from correspondences between 3D geometric entities and their projections into the image is a widely investigated problem. Although most state-of-the-art methods exploit simple primitives such as points or lines, and thus require dense scene models, the emergence of very effective CNN-based object detectors in the recent years have paved the way to the use of much lighter 3D models composed solely of a few semantically relevant features. In that context, we propose a novel model-based camera pose estimation method in which the scene is modeled by a set of virtual ellipsoids. We show that 6-DoF camera pose can be determined by optimizing only the three orientation parameters, and that at least two correspondences between 3D ellipsoids and their 2D projections are necessary in practice. We validate the approach on both simulated and real environments.",
        "primary_area": "",
        "author": "Vincent Gaudilli\u00e8re;Gilles Simon;Marie-Odile Berger;Vincent Gaudilli\u00e8re;Gilles Simon;Marie-Odile Berger",
        "authorids": "/37086527946;/37268825900;/37266139100;/37086527946;/37268825900;/37266139100",
        "aff": "CNRS, Inria, LORIA, Universit\u00e9 de Lorraine, Nancy, France; CNRS, Inria, LORIA, Universit\u00e9 de Lorraine, Nancy, France; CNRS, Inria, LORIA, Universit\u00e9 de Lorraine, Nancy, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968180/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8510395610793857086&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967936",
        "title": "Can User-Centered Reinforcement Learning Allow a Robot to Attract Passersby without Causing Discomfort?",
        "track": "main",
        "status": "Poster",
        "abstract": "The aim of our study is to develop a method by which a social robot can greet passersby and get their attention without causing them to suffer discomfort. Social robots now function in a number of customer service roles, such as receptionists, guides, and exhibitors. However, sudden greetings from a robot can startle passersby. Therefore, we developed a method that allows social robots to adapt their mannerisms situationally based the results of related work. Our proposed method, user-centered reinforcement learning, enables robots to greet passersby without causing them discomfort (p<0.01). Our field experiment in an office entrance demonstrated that our method meets this requirement.",
        "primary_area": "",
        "author": "Yasunori Ozaki;Tatsuya Ishihara;Narimune Matsumura;Tadashi Nunobiki;Yasunori Ozaki;Tatsuya Ishihara;Narimune Matsumura;Tadashi Nunobiki",
        "authorids": "/37085890570;/37085717092;/37086512178;/37086512925;/37085890570;/37085717092;/37086512178;/37086512925",
        "aff": "Service Evolution Lab., NTT Corporation, Yokosuka, Japan; R & D Center, NTT West Corporation, Osaka, Japan; Service Evolution Lab., NTT Corporation, Yokosuka, Japan; Service Evolution Lab., NTT Corporation, Yokosuka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967936/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3986195556251523430&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "NTT Corporation;NTT West Corporation",
        "aff_unique_dep": "Service Evolution Lab.;R & D Center",
        "aff_unique_url": "https://www.ntt.co.jp;https://www.ntt-west.co.jp",
        "aff_unique_abbr": "NTT;NTT West",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Yokosuka;Osaka",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967592",
        "title": "Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",
        "primary_area": "",
        "author": "Mirko Gschwindt;Efe Camci;Rogerio Bonatti;Wenshan Wang;Erdal Kayacan;Sebastian Scherer;Mirko Gschwindt;Efe Camci;Rogerio Bonatti;Wenshan Wang;Erdal Kayacan;Sebastian Scherer",
        "authorids": "/37087321777;/37085899628;/37086934741;/37087322184;/37595300900;/37584159000;/37087321777;/37085899628;/37086934741;/37087322184;/37595300900;/37584159000",
        "aff": "Department of Computer Science, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany; School of Mechanical and Aerospace Engineering (MAE), Nanyang Technological University (NTU), 50 Nanyang Avenue, Singapore; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Department of Engineering, Aarhus University, Aarhus C, Denmark; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967592/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12505550470538653865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;3;2",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Nanyang Technological University;Carnegie Mellon University;Aarhus University",
        "aff_unique_dep": "Department of Computer Science;School of Mechanical and Aerospace Engineering;School of Computer Science;Department of Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.ntu.edu.sg;https://www.cmu.edu;https://www.au.dk",
        "aff_unique_abbr": "TUM;NTU;CMU;AU",
        "aff_campus_unique_index": "0;1;2;2;3;2",
        "aff_campus_unique": "Munich;Singapore;Pittsburgh;Aarhus",
        "aff_country_unique_index": "0;1;2;2;3;2",
        "aff_country_unique": "Germany;Singapore;United States;Denmark"
    },
    {
        "id": "8968612",
        "title": "Can a Robot Hear the Shape and Dimensions of a Room?",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowing the geometry of a space is desirable for many applications, e.g. sound source localization, sound field reproduction or auralization. In circumstances where only acoustic signals can be obtained, estimating the geometry of a room is a challenging proposition. Existing methods have been proposed to reconstruct a room from the room impulse responses (RIRs). However, the sound source and microphones must be deployed in a feasible region of the room for it to work, which is impractical when the room is unknown. This work propose to employ a robot equipped with a sound source and four acoustic sensors, to follow a proposed path planning strategy to moves around the room to collect first image sources for room geometry estimation. The strategy can effectively drives the robot from a random initial location through the room so that the room geometry is guaranteed to be revealed. Effectiveness of the proposed approach is extensively validated in a synthetic environment, where the results obtained are highly promising.",
        "primary_area": "",
        "author": "Linh Nguyen;Jaime Valls Miro;Xiaojun Qiu;Linh Nguyen;Jaime Valls Miro;Xiaojun Qiu",
        "authorids": "/37085341217;/37411105600;/37533938200;/37085341217;/37411105600;/37533938200",
        "aff": "Centre for Autonomous Systems, University of Technology Sydney, Ultimo, New South Wales, Australia; Centre for Autonomous Systems, University of Technology Sydney, Ultimo, New South Wales, Australia; Centre for Audio Acoustics and Vibration, University of Technology Sydney, Ultimo, New South Wales, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968612/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2233447886484297172&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967825",
        "title": "Can a Social Robot Encourage Children\u2019s Self-Study?",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a robot behavioral model designed to support children during self-study. In particular, we want to investigate how a robot could increase the time children keep concentration. The behavioral model was developed by observing children during self-study and by collecting information from experienced tutors through interviews. After observing the children, we decided to consider three states corresponding to different levels of concentration. The child can be smoothly performing the task (\u201clearning\u201d state), encountering some difficulties (\u201cstuck\u201d state) or distracted (\u201cdistracted\u201d state). The behavioral model was designed to increase the time spent concentrating on the task by implementing adequate behaviors for each of these three states. These behaviors were designed using the advices collected during the interview survey of the experienced tutors. A self-study system based on the proposed behavior model was implemented. In this system, a small robot sits on the table and encourages the child during self-study. An operator is in charge of determining the state of the child (Wizard of Oz) and the behavioral model triggers the appropriate behaviors for the different states. To demonstrate the effectiveness of the proposed behavioral model, a user study was conducted: 22 children were asked to solve problems alone and to solve problems with the robot. The children spent significantly (p = 0.024) more time in the \u201clearning\u201d state when studying with the robot.",
        "primary_area": "",
        "author": "Risa Maeda;Jani Even;Takayuki Kanda;Risa Maeda;Jani Even;Takayuki Kanda",
        "authorids": "/37087323747;/37294742400;/38599608900;/37087323747;/37294742400;/38599608900",
        "aff": "Human Robot Interaction Laboratory, University of Kyoto, Japan; Human Robot Interaction Laboratory, University of Kyoto, Japan; Human Robot Interaction Laboratory, University of Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967825/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12246575936327628917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Kyoto",
        "aff_unique_dep": "Human Robot Interaction Laboratory",
        "aff_unique_url": "https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Kyoto U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967809",
        "title": "Cannot avoid penalty for fluctuating order arrival rate? Let's minimize",
        "track": "main",
        "status": "Poster",
        "abstract": "Warehouse management system assigns a preferred completion time for every order based on the customer profile and the good(s) that is/are ordered. Even though employing multi-robot systems to manage goods movement bring operational efficiency in a warehouse, it is difficult to meet these soft deadlines of tasks in the peak hours/seasons. This can impact the respective businesses significantly as the lateness of task completion incurs a direct/indirect penalty. In this work, we develop an online task scheduling algorithm for such a multi-robot system, called Online Minimum Penalty Scheduling (OMPS). Though there exists a large number of multi-robot task scheduling algorithms, they are not suitable (or less efficient) for a system where each task has a soft deadline and accumulates penalty if it is executed beyond its deadline. Moreover, the lack of knowledge of future tasks (online scheduling) makes task allocation a much more difficult job. OMPS provides a robust, scalable, and near-optimal online task schedule. By comparing with the state-of-the-art algorithm, we show that OMPS attracts up to 78% less penalty when a significant number of tasks are bound to miss the deadline. Additionally, it achieves a competitive ratio of up to 1 when compared with a state-of-the-art offline task scheduling algorithm.",
        "primary_area": "",
        "author": "Marichi Agarwal;Chayan Sarkar;Marichi Agarwal;Chayan Sarkar",
        "authorids": "/37086274385;/37085392494;/37086274385;/37085392494",
        "aff": "Embedded Systems & Robotics division of TCS Research & Innovation, India; Embedded Systems & Robotics division of TCS Research & Innovation, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967809/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4562891673987971759&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Embedded Systems & Robotics division",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968305",
        "title": "Carpie: A soft, mechanically-reconfigurable worm robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are a burgeoning archetype in robotics due to their ability to perform intricate movements easily and seamlessly. They serve as an ideal concept for realistically emulating animal movements. However, the majority of soft robots today are unable to vary their motions due to the coupled interaction of the nature of their kinematics and structural composition. We therefore created Carpie, a robotic caterpillar adapted from a modular, pneumatic actuator. Carpie is designed to perform a variety of caterpillar movements by tuning its mechanical structure through physical reconfiguration. The robot has a completely soft body that enables a variety of movements and contortions into different shapes, making Carpie is perhaps the perfect example to showcase a soft robot's aptness for animal mimicry. We analyzed the robot's control aspect. Its capabilities were measured by performing gait velocity studies on three different configurations. Each configuration was executed by applying various modules on Carpie's structure without fully refabricating the entire assembly. We also analyzed the accompanying change in the robot's maximum height during gait. Finally, we demonstrate how physical reconfiguration was able to radically alter Carpie's movement, allowing it to perform a turning motion.",
        "primary_area": "",
        "author": "Pouya Ahmadian;Rainier F. Natividad;Chen-Hua Yeow;Pouya Ahmadian;Rainier F. Natividad;Chen-Hua Yeow",
        "authorids": "/37070646300;/37085845188;/37085560996;/37070646300;/37085845188;/37085560996",
        "aff": "Department of Mechanical and Industrial Engineering, University of Toronto (UofT), Canada; Department of Biomedical Engineering, National University of Singapore (NUS), Singapore; Advanced Robotics Center, NUS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968305/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:tvYk1xSp0zkJ:scholar.google.com/&scioq=Carpie:+A+soft,+mechanically-reconfigurable+worm+robot&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Toronto;National University of Singapore",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.utoronto.ca;https://www.nus.edu.sg",
        "aff_unique_abbr": "UofT;NUS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Canada;Singapore"
    },
    {
        "id": "8968107",
        "title": "Cascaded Gaussian Processes for Data-efficient Robot Dynamics Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the recursive Newton-Euler formulation, we propose a novel cascaded Gaussian process learning framework for the inverse dynamics of robot manipulators. This approach leads to a significant dimensionality reduction which in turn results in better learning and data efficiency. We explore two formulations for the cascading: the inward and outward, both along the manipulator chain topology. The learned modeling is tested in conjunction with the classical inverse dynamics model (semi-parametric) and on its own (non-parametric) in the context of feed-forward control of the arm. Experimental results are obtained with Jaco 2 six-DOF and SARCOS seven-DOF manipulators for randomly defined sinusoidal motions of the joints in order to evaluate the performance of cascading against the standard GP learning. In addition, experiments are conducted using Jaco 2 on a task emulating a pouring maneuver. Results indicate a consistent improvement in learning speed with the inward cascaded GP model and an overall improvement in data efficiency and generalization.",
        "primary_area": "",
        "author": "Sahand Rezaei-Shoshtari;David Meger;Inna Sharf;Sahand Rezaei-Shoshtari;David Meger;Inna Sharf",
        "authorids": "/37087323637;/37542891800;/37283633500;/37087323637;/37542891800;/37283633500",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, Canada; Department of Computer Science, McGill University, Montreal, Canada; Department of Mechanical Engineering, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968107/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11994934863074669122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968499",
        "title": "Centralized Control Architecture for Cooperative Object Transportation using Multiple Omnidirectional AGVs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of cooperative transportation using multiple omnidirectional Automated Guided Vehicles (AGVs). To enhance flexibility and application potentials, mecanum-wheeled platform is considered for the proposed multi-AGV system while the cooperative transportation is executed without physical link/gripper to fix the object on the AGVs. Therefore, the position and number of AGV is adjustable depending on the size and weight of the transported object. Analysis of force distribution to each AGV during cooperative transportation is presented. Furthermore, the gradient projection method is exploited to regulate internal force according to the operational capability of each AGV. Moreover, an adaptive sliding mode controller is designed for AGV to cope with dynamic uncertainty during cooperative transportation. Stability of the proposed controller is proven by using Lyapunov Theorem. Finally, numerical simulation is presented to demonstrate the performance of the proposed control system.",
        "primary_area": "",
        "author": "Firhan Huzaefa;Yen-Chen Liu;Firhan Huzaefa;Yen-Chen Liu",
        "authorids": "/37087322992;/37537605900;/37087322992;/37537605900",
        "aff": "Department of Mechanical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Mechanical Engineering, National Cheng Kung University, Tainan, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968499/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8896788686459092427&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Cheng Kung University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ncku.edu.tw",
        "aff_unique_abbr": "NCKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967794",
        "title": "Chance-Constrained Trajectory Optimization for Non-linear Systems with Unknown Stochastic Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Iterative trajectory optimization techniques for non-linear dynamical systems are among the most powerful and sample-efficient methods of model-based reinforcement learning and approximate optimal control. By leveraging time-variant local linear-quadratic approximations of system dynamics and reward, such methods can find both a target-optimal trajectory and time-variant optimal feedback controllers. However, the local linear-quadratic assumptions are a major source of optimization bias that leads to catastrophic greedy updates, raising the issue of proper regularization. Moreover, the approximate models' disregard for any physical state-action limits of the system causes further aggravation of the problem, as the optimization moves towards unreachable areas of the state-action space. In this paper, we address the issue of constrained systems in the scenario of online-fitted stochastic linear dynamics. We propose modeling state and action physical limits as probabilistic chance constraints linear in both state and action and introduce a new trajectory optimization technique that integrates these probabilistic constraints by optimizing a relaxed quadratic program. Our empirical evaluations show a significant improvement in learning robustness, which enables our approach to perform more effective updates and avoid premature convergence observed in state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Onur Celik;Hany Abdulsamad;Jan Peters;Onur Celik;Hany Abdulsamad;Jan Peters",
        "authorids": "/37087322525;/37085685682;/37533077600;/37087322525;/37085685682;/37533077600",
        "aff": "Department of Computer Science, Universtit\u00e4t T\u00fcbingen.; Department of Computer Science, Intelligent Autonomous Systems; Department of Computer Science, Intelligent Autonomous Systems",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967794/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14170725891468301363&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of T\u00fcbingen;Intelligent Autonomous Systems",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.uni-tuebingen.de/;",
        "aff_unique_abbr": "Uni T\u00fcbingen;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "T\u00fcbingen;",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany;"
    },
    {
        "id": "8968137",
        "title": "Characterizing Environmental Interactions for Soft Growing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft, tip-extending devices, or \u201cvine robots,\u201d are a promising new paradigm for navigating cluttered and confined environments. Because they lengthen from their tips, there is little relative movement of the body with the environment, and the compressible nature of the device allows it to pass through orifices smaller than its diameter. However, the interaction between these devices and the environment is not well characterized. Here we present a comprehensive mathematical model that describes vine robot behavior during environmental interaction that provides a basis from which informed designs can be generated in future works. The model incorporates transverse and axial buckling modes that result from growing into obstacles with varying surface normals, as well as internal path-dependent and independent resistances to growth. Accordingly, the model is able to predict the pressure required to grow through a given environment due to the interaction forces it experiences. We experimentally validate both the individual components and the full model. Finally, we present three design insights from the model and demonstrate how they each improve performance in confined space navigation. Our work helps advance the understanding of tip-extending, vine robots through quantifying their interactions with the environment, opening the door for new designs and impactful applications in the realms of healthcare, research, search and rescue, and space exploration.",
        "primary_area": "",
        "author": "David A. Haggerty;Nicholas D. Naclerio;Elliot W. Hawkes;David A. Haggerty;Nicholas D. Naclerio;Elliot W. Hawkes",
        "authorids": "/37086617932;/37086581043;/37681388800;/37086617932;/37086581043;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California, Santa Barbara, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968137/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7422949376841988114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967790",
        "title": "Cheating with robots: how at ease do they make us feel?",
        "track": "main",
        "status": "Poster",
        "abstract": "People are not perfect, and if given the chance, some will be dishonest with no regrets. Some people will cheat just a little to gain some advantage, and others will not do it at all. With the prospect of more human-robot interactions in the future, it will become very important to understand which kind of roles a robot can have in the regulation of cheating behavior. We investigated whether people will cheat while in the presence of a robot and to what extent this depends on the role the robot plays. We ran a study to test cheating behavior with a die task, and allocated people to one of the following conditions: 1) participants were alone in the room while doing the task; 2) with a robot with a vigilant role or 3) with a robot that had a supporting role in the task, accompanying and giving instructions. Our results showed that participants cheated significantly more than chance when they were alone or with the robot giving instructions. In contrast, cheating could not be proven when the robot presented a vigilant role. This study has implications for human-robot interaction and for the deployment of autonomous robots in sensitive roles in which people may be prone to dishonest behavior.",
        "primary_area": "",
        "author": "Sofia Petisca;Francisco Esteves;Ana Paiva;Sofia Petisca;Francisco Esteves;Ana Paiva",
        "authorids": "/37085777248;/38469492100;/37267245800;/37085777248;/38469492100;/37267245800",
        "aff": "INESC-ID and Instituto Universit\u00e1rio de Lisboa (ISCTE-IUL), CIS, Portugal; Mid Sweden University, Sweden and Instituto Universit\u00e1rio de Lisboa (ISCTE-IUL); INESC-ID,Instituto Superior Tecnico, University of Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967790/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8592627177596606533&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "INESC-ID;Mid Sweden University;University of Lisbon",
        "aff_unique_dep": "CIS;;INESC-ID, Instituto Superior Tecnico",
        "aff_unique_url": ";https://www.midSwedenuniversity.se;https://www IST Lisbon",
        "aff_unique_abbr": ";Mid Sweden Uni;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Portugal;Sweden"
    },
    {
        "id": "8967824",
        "title": "Clone Swarms: Learning to Predict and Control Multi-Robot Systems by Imitation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose SwarmNet \u2013 a neural network architecture that can learn to predict and imitate the behavior of an observed swarm of agents in a centralized manner. Tested on artificially generated swarm motion data, the network achieves high levels of prediction accuracy and imitation authenticity. We compare our model to previous approaches for modelling interaction systems and show how modifying components of other models gradually approaches the performance of ours. Finally, we also discuss an extension of SwarmNet that can deal with nondeterministic, noisy, and uncertain environments, as often found in robotics applications.",
        "primary_area": "",
        "author": "Siyu Zhou;Mariano J. Phielipp;Jorge A. Sefair;Sara I. Walker;Heni Ben Amor;Siyu Zhou;Mariano J. Phielipp;Jorge A. Sefair;Sara I. Walker;Heni Ben Amor",
        "authorids": "/665158615802505;/37087324977;/37947317100;/37086284234;/37293927700;/665158615802505;/37087324977;/37947317100;/37086284234;/37293927700",
        "aff": "Department of Physics, Arizona State University; Intel Corporation; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University; School of Earch and Space Exploration, Arizona State University; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967824/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14641617821192477749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Arizona State University;Intel",
        "aff_unique_dep": "Department of Physics;Intel Corporation",
        "aff_unique_url": "https://www.asu.edu;https://www.intel.com",
        "aff_unique_abbr": "ASU;Intel",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tempe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968477",
        "title": "Closed-Form Equations and Experimental Verification for Soft Robot Arm Based on Cosserat Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared with conventional robots, soft structures such as living octopus arms and various soft-robot arms have more degrees of freedom (DOFs) and greater flexibility. Soft robot arms have a considerable range of applications. However, it is arduous to establish a mechanical model for them, because of the hyper-redundant DOFs, and the hyperelasticity and nonlinearity of the soft material. In this study, to investigate the deformation of soft octopus robot arms, the simplified closed-form analytical equations for the curvature and torsion were derived according to the Cosserat theory. A closed-form model for axial constriction was developed. The analytical equations were experimentally validated, and a dynamical simulation of the multi-flexible bodies was performed for a cable-driven soft-robot arm inspired by the octopus. The results show satisfactory accuracy.",
        "primary_area": "",
        "author": "Lizhou Niu;Liang Ding;Haibo Gao;Yang Su;Zongquan Deng;Zhen Liu;Lizhou Niu;Liang Ding;Haibo Gao;Yang Su;Zongquan Deng;Zhen Liu",
        "authorids": "/37087322846;/37529158200;/37535800300;/37087324015;/37271509900;/37592993900;/37087322846;/37529158200;/37535800300;/37087324015;/37271509900;/37592993900",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968477/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15066307416496933964&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968226",
        "title": "Closed-loop Force Control of a Pneumatic Gripper Actuated by Two Pressure Regulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic arms can perform grasping actions thanks to their \u201cdexteorus\u201d part, i.e. the gripper. Among the various categories, nowadays pneumatic grippers became the most employed in industry, as they have low cost and little bulkiness. Despite their simplicity, controlling the force applied by these grippers is not straightforward due to the dependence of such a force on the air pressure in the gripper chambers. As a result, it is still tricky to implement closed-loop force control for pneumatic grippers. This paper intends to deliver a control scheme relying on the force measurement to control pneumatic grippers. The force might be measured through a commercial sensor (e.g. a load cell) and fed back to close the control loop. This includes a calibration which maps the force-pressure relation taking into account both desired force and length of the gripper fingers. The control scheme exploits two different pressure regulators to precisely adjust the air pressure inside the gripper chambers (i.e. opening and closing chambers). To this aim, a quadratic programming algorithm is employed. The control scheme performance revealed to be good: results will be shown in terms of gripper response to sinusoidal and step inputs, along with the pressure-force characterization.",
        "primary_area": "",
        "author": "Rocco A. Romeo;Luca Fiorio;Edwin J. Avila-Mireles;Ferdinando Cannella;Giorgio Metta;Daniele Pucci;Rocco A. Romeo;Luca Fiorio;Edwin J. Avila-Mireles;Ferdinando Cannella;Giorgio Metta;Daniele Pucci",
        "authorids": "/37085705883;/37085446877;/37085607569;/37681701900;/37295477800;/37706167200;/37085705883;/37085446877;/37085607569;/37681701900;/37295477800;/37706167200",
        "aff": "iCub Facility Department, Istituto Italiano di Tecnologi, Via Morego 30, Genoa, Italy; iCub Facility Department, Istituto Italiano di Tecnologi, Via Morego 30, Genoa, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia, Via Morego 30, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia, Via Morego 30, Italy; iCub Facility Department, Istituto Italiano di Tecnologi, Via Morego 30, Genoa, Italy; iCub Facility Department, Istituto Italiano di Tecnologi, Via Morego 30, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968226/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=655327128202907348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologi;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "iCub Facility Department;Advanced Robotics Department",
        "aff_unique_url": "https://www.iit.it;https://www.iit.it",
        "aff_unique_abbr": "IIT;IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967667",
        "title": "Cognitive Robotic Architecture for Semi-Autonomous Execution of Manipulation Tasks in a Surgical Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of robotic systems with a certain level of autonomy to be used in critical scenarios, such as an operating room, necessarily requires a seamless integration of multiple state-of-the-art technologies. In this paper we propose a cognitive robotic architecture that is able to help an operator accomplish a specific task. The architecture integrates an action recognition module to understand the scene, a supervisory control to make decisions, and a model predictive control to plan collision-free trajectory for the robotic arm taking into account obstacles and model uncertainty. The proposed approach has been validated on a simplified scenario involving only a da VinciO surgical robot and a novel manipulator holding standard laparoscopic tools.",
        "primary_area": "",
        "author": "Giacomo De Rossi;Marco Minelli;Alessio Sozzi;Nicola Piccinelli;Federica Ferraguti;Francesco Setti;Marcello Bonf\u00e9;Cristian Secchi;Riccardo Muradore;Giacomo De Rossi;Marco Minelli;Alessio Sozzi;Nicola Piccinelli;Federica Ferraguti;Francesco Setti;Marcello Bonf\u00e9;Cristian Secchi;Riccardo Muradore",
        "authorids": "/37085759529;/37086036138;/37087322421;/37086529418;/37075262200;/37887481900;/37300903100;/37300905500;/37299825000;/37085759529;/37086036138;/37087322421;/37086529418;/37075262200;/37887481900;/37300903100;/37300905500;/37299825000",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Engineering Sciences and Methods, University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Engineering, University of Ferrara, Ferrara, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Engineering Sciences and Methods, University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Engineering, University of Ferrara, Ferrara, Italy; Department of Engineering Sciences and Methods, University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967667/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13563817896205772778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;1;0;2;1;0",
        "aff_unique_norm": "University of Verona;University of Modena and Reggio Emilia;University of Ferrara",
        "aff_unique_dep": "Department of Computer Science;Department of Engineering Sciences and Methods;Department of Engineering",
        "aff_unique_url": "https://www.univr.it;https://www.unimore.it;https://www.unife.it",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "0;1;2;0;1;0;2;1;0",
        "aff_campus_unique": "Verona;Reggio Emilia;Ferrara",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968027",
        "title": "Collaborative Human Augmented SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we are proposing a collaborative SLAM system between a team of three heterogeneous agents: a robot, a human operator, and an augmented reality head mounted display (ARHMD). The system allows for online editing of a map produced by a robot running SLAM. Through hand gestures, the user can edit, in real time, the robot map that is augmented on top of the physical environment. Moreover, the proposed system leverages the built-in SLAM capabilities of the AR-HMD to correct the robot's map and map areas that are not yet discovered by the robot. Our method aims to combine the unique and complementary capabilities of each of the three different agents to produce the maximum possible mapping accuracy in the minimum amount of time. The proposed system is implemented on ROS and Unity. Experiments performed demonstrate the considerably superior SLAM outputs in terms of reducing mapping time, eliminating maps post-processing, and increasing mapping accuracy.",
        "primary_area": "",
        "author": "Abbas Sidaoui;Imad H. Elhajj;Daniel Asmar;Abbas Sidaoui;Imad H. Elhajj;Daniel Asmar",
        "authorids": "/37086576742;/37281934400;/37424435700;/37086576742;/37281934400;/37424435700",
        "aff": "Maroun Semaan Faculty of Engineering and Architecture, American University of Beirut, Beirut, Lebanon; Maroun Semaan Faculty of Engineering and Architecture, American University of Beirut, Beirut, Lebanon; Maroun Semaan Faculty of Engineering and Architecture, American University of Beirut, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968027/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11139978704327913065&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "American University of Beirut",
        "aff_unique_dep": "Maroun Semaan Faculty of Engineering and Architecture",
        "aff_unique_url": "https://www.aub.edu.lb",
        "aff_unique_abbr": "AUB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beirut",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Lebanon"
    },
    {
        "id": "8968035",
        "title": "Collaborative Mapping with Pose Uncertainties using different Radio Frequencies and Communication Modules",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotic applications, especially exploration scenarios, benefit from deploying multiple collaborating robots with the aim of parallelizing and therefore accelerating the involved task. One critical part of a multi-robot system is its communication system. Depending on the application scenario, high-bandwidth wireless connections, such as WiFi, may not always be available and suffer from a limited communication range. On the other hand, low-bandwith systems require the application itself to deal with limited information exchange. In this work, we present a novel approach for collaborative mapping using mixtures of occupancy and NDT maps (called ONDT), which provide detailed information at low resolutions and in which the pose uncertainty can be encoded efficiently. Further, we compare the applicability of three different radio frequency modules operating at different frequencies in real world experiments with five robots at large distances.",
        "primary_area": "",
        "author": "Cornelia Schulz;Richard Hanten;Matthias Reisenauer;Andreas Zell;Cornelia Schulz;Richard Hanten;Matthias Reisenauer;Andreas Zell",
        "authorids": "/37086579417;/37085619648;/37086806154;/37276583400;/37086579417;/37085619648;/37086806154;/37276583400",
        "aff": "Cognitive Systems Group at the Computer Science Department, University of T\u00fcbingen Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group at the Computer Science Department, University of T\u00fcbingen Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group at the Computer Science Department, University of T\u00fcbingen Sand 1, T\u00fcbingen, Germany; Cognitive Systems Group at the Computer Science Department, University of T\u00fcbingen Sand 1, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968035/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4838057143751485978&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "Uni T\u00fcbingen",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968154",
        "title": "Collaborative Robot Assistant for the Ergonomic Manipulation of Cumbersome Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robotics refers to the cooperation between humans and machines and aims at improving productivity and at facilitating the worker in demanding tasks. The advantage of collaboration is to combine the superior cognitive and motor skills of the operator with the physical capabilities of the robots. This work presents a control strategy for the robotic manipulator to minimise the muscular fatigue of the human operator during the manipulation of bulky objects. The robot moves the workpiece so that the human is always operating close to his/her most natural and ergonomic posture. This way the risk of developing postures and movements inducing musculoskeletal disorders is minimised. A substantial reduction of the amplitude of the operator movements, without degrading the precision in fulfilling the task, has been registered in the experimental campaign.",
        "primary_area": "",
        "author": "Andrea Maria Zanchettin;Elio Lotano;Paolo Rocco;Andrea Maria Zanchettin;Elio Lotano;Paolo Rocco",
        "authorids": "/37546427600;/37087322335;/37274178600;/37546427600;/37087322335;/37274178600",
        "aff": "Politecnico di Milano, Informazione e Bioingegneria Piazza L. Da Vinci 32, Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria Piazza L. Da Vinci 32, Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria Piazza L. Da Vinci 32, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968154/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6297114095170276586&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967998",
        "title": "Collision Detection and Isolation on a Robot using Joint Torque Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "As robotic systems become more flexible and intelligent, they must be able to move into environments with a high degree of uncertainty or clutter, such as our homes, workplaces, and the outdoors. In these unstructured scenarios, it is possible that the body of the robot collides with its surroundings. As such, it would be desirable to characterise these contacts in terms of their location and interaction forces. This paper addresses the problem of detecting and isolating collisions between a robotic manipulator and its environment, using only on-board joint torque and position sensing. The algorithm is based on a particle filter and, under some assumptions, is able to identify the contact location anywhere on the robot body. It requires the robot to perform small exploratory movements, progressively integrating the new sensing information through a Bayesian framework. The approach was tested and benchmarked in simulation, with respect to its accuracy and robustness. Validation using a robot with joint torque sensing in a real environment demonstrated the applicability of the method to real-world scenarios.",
        "primary_area": "",
        "author": "Joao Bimbo;Claudio Pacchierotti;Nikos G. Tsagarakis;Domenico Prattichizzo;Joao Bimbo;Claudio Pacchierotti;Nikos G. Tsagarakis;Domenico Prattichizzo",
        "authorids": "/38502461400;/38513576600;/37295830800;/37276309600;/38502461400;/38513576600;/37295830800;/37276309600",
        "aff": "Istituto Italiano di Tecnologia, Italy; CNRS, Univ Rennes, Inria, IRISA, France; Istituto Italiano di Tecnologia, Italy; Istituto Italiano di Tecnologia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967998/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iit.it;https://www.cnrs.fr",
        "aff_unique_abbr": "IIT;CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Italy;France"
    },
    {
        "id": "8968081",
        "title": "Combined Optimization of Gripper Finger Design and Pose Estimation Processes for Advanced Industrial Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision systems are often used jointly with robotic manipulators to perform automated tasks in industrial applications. Still, the correct set up of such workcells is difficult and requires significant resources. One of the main challenges, when implementing such systems in industrial use cases, is the pose uncertainties presented by the vision system which have to be handled by grasping. In this paper, we present a framework for the design and analysis of optimal gripper finger designs and vision parameters. The proposed framework consists of two parallel methods which rely on vision and grasping simulation to provide an initial estimation of the uncertainty compensation capabilities of the designs. In case the compensation is not feasible with the initial design, an optimization process is introduced, to select the optimal pose estimation parameters and finger designs for the presented task. The proposed framework was evaluated in dynamic simulation and implemented in a real industrial use case.",
        "primary_area": "",
        "author": "Frederik Hagelskj\u00e6r;Alja\u017e Kramberger;Adam Wolniakowski;Thiusius Rajeeth Savarimuthu;Norbert Kr\u00fcger;Frederik Hagelskj\u00e6r;Alja\u017e Kramberger;Adam Wolniakowski;Thiusius Rajeeth Savarimuthu;Norbert Kr\u00fcger",
        "authorids": "/37087009683;/37085387168;/37085671509;/37946053800;/37546662200;/37087009683;/37085387168;/37085671509;/37946053800;/37546662200",
        "aff": "Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968081/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14097184810501218373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Odense",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8968091",
        "title": "Combined Task and Action Learning from Human Demonstrations for Mobile Manipulation Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstrations is a promising paradigm for transferring knowledge to robots. However, learning mobile manipulation tasks directly from a human teacher is a complex problem as it requires learning models of both the overall task goal and of the underlying actions. Additionally, learning from a small number of demonstrations often introduces ambiguity with respect to the intention of the teacher, making it challenging to commit to one model for generalizing the task to new settings. In this paper, we present an approach to learning flexible mobile manipulation action models and task goal representations from teacher demonstrations. Our action models enable the robot to consider different likely outcomes of each action and to generate feasible trajectories for achieving them. Accordingly, we leverage a probabilistic framework based on Monte Carlo tree search to compute sequences of feasible actions imitating the teacher intention in new settings without requiring the teacher to specify an explicit goal state. We demonstrate the effectiveness of our approach in complex tasks carried out in real-world settings.",
        "primary_area": "",
        "author": "Tim Welschehold;Nichola Abdo;Christian Dornhege;Wolfram Burgard;Tim Welschehold;Nichola Abdo;Christian Dornhege;Wolfram Burgard",
        "authorids": "/37085678776;/38230536100;/37391714500;/37270485300;/37085678776;/38230536100;/37391714500;/37270485300",
        "aff": "Institute of Computer Science, University of Freiburg, Germany; Institute of Computer Science, University of Freiburg, Germany; Institute of Computer Science, University of Freiburg, Germany; Institute of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968091/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=787108802851551231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "Institute of Computer Science",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "Uni Freiburg",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Freiburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968512",
        "title": "Combining Stochastic Optimization and Frontiers for Aerial Multi-Robot Exploration of 3D Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of exploring unknown terrains with a fleet of cooperating aerial vehicles. We present a novel decentralized approach which alternates gradient-free stochastic optimization and a frontier-based approach. Our method allows each robot to generate its trajectory based on the collected data and the local map built integrating the information shared by its teammates. Whenever a local optimum is reached, which corresponds to a location surrounded by already explored areas, the algorithm identifies the closest frontier to get over it and restarts the local optimization. Its low computational cost, the capability to deal with constraints and the decentralized decision-making make it particularly suitable for multi-robot applications in complex 3D environments. Simulation results show that our approach generates feasible trajectories which drive multiple robots to completely explore realistic environments. Furthermore, in terms of exploration time, our algorithm significantly outperforms a standard solution based on closest frontier points while providing similar performances compared to a computationally more expensive centralized greedy solution.",
        "primary_area": "",
        "author": "Alessandro Renzaglia;Jilles Dibangoye;Vincent Le Doze;Olivier Simonin;Alessandro Renzaglia;Jilles Dibangoye;Vincent Le Doze;Olivier Simonin",
        "authorids": "/37590277500;/37086163536;/37087324447;/37329541300;/37590277500;/37086163536;/37087324447;/37329541300",
        "aff": "Univ. Grenoble Alpes, Inria, Grenoble, France; INSA Lyon, CITI Lab, Inria, Chroma, Lyon, France; INSA Lyon, CITI Lab, Inria, Chroma, Lyon, France; INSA Lyon, CITI Lab, Inria, Chroma, Lyon, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968512/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4788696392355696029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Universite Grenoble Alpes;INSA Lyon",
        "aff_unique_dep": ";CITI Lab",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.insa-lyon.fr",
        "aff_unique_abbr": "UGA;INSA Lyon",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Grenoble;Lyon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968128",
        "title": "Combining spiking motor primitives with a behaviour-based architecture to model locomotion for six-legged robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Bio-inspired robots take advantage of millions of years of evolution to provide interesting and flexible solutions for issues related to motion and perception. Often, they have challenging kinematics classical robotics control mechanisms are not always able to take advantage of them. A concrete example of this is LAURON V, a six-legged robot for space exploration inspired by the stick insects. The main goals of this work is to combine classical behaviour-based control with motor primitives implemented with SNN for motion representation. We extend a previously presented bio-inspired approach to represent hand and arm motion using motor primitives, and combine it with a behaviour-based architecture to model different locomotion behaviours for a multi-legged robot. There are four main components. First, to model the individual leg motions we use two motor primitives implemented with spiking neural networks for the swing and stance phases. Second, to control the motor primitives of each leg there are local behaviours corresponding to each phase, and corresponding to each activation pattern. Third, the activation patterns are used to facilitate multi-leg coordination and generate different walking behaviours. Fourth, a high-level control interface integrates control signals from other sources and activates the patterns. We conducted five different experiments to evaluate our approach in a simulated environment using the Neurorobotics Platform (NRP). The results show that our modelling approach with motor primitives is flexible enough to represent different types of motions, and also highlight the value of the NRP for robotics development.",
        "primary_area": "",
        "author": "J. Camilo Vasquez Tieck;Jacqueline Rutschke;Jacques Kaiser;Martin Schulze;Timothee Buettner;Daniel Reichard;Arne Roennau;R\u00fcdiger Dillmann;J. Camilo Vasquez Tieck;Jacqueline Rutschke;Jacques Kaiser;Martin Schulze;Timothee Buettner;Daniel Reichard;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37086473149;/37085672168;/37086472819;/37086883652;/37086158340;/37087010313;/37590849800;/37280242100;/37086473149;/37085672168;/37086472819;/37086883652;/37086158340;/37087010313;/37590849800;/37280242100",
        "aff": "FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968128/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18017373706880015683&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "FZI Research Center for Information Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.fzi.de",
        "aff_unique_abbr": "FZI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968605",
        "title": "Common Dimensional Autoencoder for Learning Redundant Muscle-Posture Mappings of Complex Musculoskeletal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "It has been widely considered that a distinctive feature of musculoskeletal structures is that both the joint angle and stiffness can be changed by exploiting the agonistantagonist driving of the joint. However, musculoskeletal systems in animals and humans are typically highly complex, and the simple agonist-antagonist driving is rarely found. Therefore, in accordance with the increasing complexity of musculoskeletal robots, the feature that causes the robot to assume a posture with different stiffness values becomes difficult to achieve, owing to the difficulty in modeling the kinematics. Although datadriven approaches such as the neural network are regarded as suitable for modeling complex relationships, the training data are difficult to obtain because measuring joint stiffness is typically extremely difficult in contrast to measuring an actuator's state and posture. Hence, we herein propose the common dimensional autoencoder where the encoded feature exhibits identical dimensions to the original input vector. In the proposed network, in parallel with the original unsupervised training using the data of the actuators' states, supervised training at part of the encoded features is performed using posture data. Consequently, features expressing the redundancy of inverse kinematics appear at the remaining part of the encoded features without using data such as joint stiffness. The validity of the proposed method was confirmed successfully through an experiment using a 10 degrees-of-freedom complex musculoskeletal robot arm driven by pneumatic artificial muscles.",
        "primary_area": "",
        "author": "Hiroaki Masuda;Ame Hitzmann;Koh Hosoda;Shuhei Ikemoto;Hiroaki Masuda;Ame Hitzmann;Koh Hosoda;Shuhei Ikemoto",
        "authorids": "/37087322236;/37087100760;/37270101900;/37659393100;/37087322236;/37087100760;/37270101900;/37659393100",
        "aff": "School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu-ku, Kitakyushu, Japan; School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu-ku, Kitakyushu, Japan; School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu-ku, Kitakyushu, Japan; School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu-ku, Kitakyushu, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968605/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17023528302428758120&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Kyushu Institute of Technology",
        "aff_unique_dep": "School of Life Science and Systems Engineering",
        "aff_unique_url": "https://www.kyutech.ac.jp",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kitakyushu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968550",
        "title": "Communication constrained cloud-based long-term visual localization in real time",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization is one of the primary capabilities for mobile robots. Long-term visual localization in real time is particularly challenging, in which the robot is required to efficiently localize itself using visual data where appearance may change significantly over time. In this paper, we propose a cloud-based visual localization system targeting at long-term localization in real time. On the robot, we employ two estimators to achieve accurate and real-time performance. One is a sliding-window based visual inertial odometry, which integrates constraints from consecutive observations and self-motion measurements, as well as the constraints induced by localization results from the cloud. This estimator builds a local visual submap as the virtual observation which is then sent to the cloud as new localization constraints. The other one is a delayed state Extended Kalman Filter to fuse the pose of the robot localized from the cloud, the local odometry and the high-frequency inertial measurements. On the cloud, we propose a longer sliding-window based localization method to aggregate the virtual observations for larger field of view, leading to more robust alignment between virtual observations and the map. Under this architecture, the robot can achieve drift-free and real-time localization using onboard resources even in a network with limited bandwidth, high latency and existence of package loss, which enables the autonomous navigation in real-world environment. We evaluate the effectiveness of our system on a dataset with challenging seasonal and illuminative variations. We further validate the robustness of the system under challenging network conditions.",
        "primary_area": "",
        "author": "Xiaqing Ding;Yue Wang;Li Tang;Huan Yin;Rong Xiong;Xiaqing Ding;Yue Wang;Li Tang;Huan Yin;Rong Xiong",
        "authorids": "/37086331151;/37072299700;/37086334310;/37086355830;/37271511300;/37086331151;/37072299700;/37086334310;/37086355830;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968550/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15475251795829007739&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968050",
        "title": "Compact Reachability Map for Excavator Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel compact reachability map representation for excavator motion planning. The constructed reachability map can concisely encode the bucket\u2019s reachable pose and the translation capability limited by excavator\u2019s kinematic structure. By explicitly exploiting the property that the basic excavation motion lies on the excavation plane determined by excavator links, we further reduce the construction of the map from 3D Euclidean space to 2D excavation plane. We show the pre-computed reachability map can be used to develop new excavator motion planning approach. By indexing on the pre-computed reachability map, we can efficiently compute the feasible full-bucket trajectory for single step excavation operation. We highlight the results of the reachability map construction and demonstrate the simulation results of motion planning using a commercial dynamic simulator.",
        "primary_area": "",
        "author": "Yajue Yang;Liangjun Zhang;Xinjing Cheng;Jia Pan;Ruigang Yang;Yajue Yang;Liangjun Zhang;Xinjing Cheng;Jia Pan;Ruigang Yang",
        "authorids": "/37086089790;/37088642847;/37089111869;/37535628800;/37087323066;/37086089790;/37088642847;/37089111869;/37535628800;/37087323066",
        "aff": "City University of Hong Kong; Robotics and Auto-Driving Lab, Baidu Research; Robotics and Auto-Driving Lab, Baidu Research; University of Hong Kong; Robotics and Auto-Driving Lab, Baidu Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968050/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18166616879967040511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "City University of Hong Kong;Baidu;University of Hong Kong",
        "aff_unique_dep": ";Robotics and Auto-Driving Lab;",
        "aff_unique_url": "https://www.cityu.edu.hk;https://baidu.com;https://www.hku.hk",
        "aff_unique_abbr": "CityU;Baidu;HKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968485",
        "title": "Comparing swimming performances of flexible and helical magnetic swimmers",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible and helical magnetic microswimmers have been well reviewed in the literature because they could be exploited for envisaged applications such as targeted drug delivery, material removal, and micromanipulation. In this article, scaled-up versions of those robots are introduced to study in detail their maneuverability and dexterity while swimming. The robots were immersed in pure glycerol, thus, reproducing a low Reynolds scenario. The proposed robots were previously optimized, achieving their best performances. The experiments assess the performances of these two kinds of robots in terms of rapidity, and steering error following 3D trajectories in environments with high viscous variations.",
        "primary_area": "",
        "author": "Ali Oulmas;Johan E. Quispe;Nicolas Andreff;St\u00e9phane R\u00e9gnier;Ali Oulmas;Johan E. Quispe;Nicolas Andreff;St\u00e9phane R\u00e9gnier",
        "authorids": "/37085799757;/37085849583;/37277288700;/37283234800;/37085799757;/37085849583;/37277288700;/37283234800",
        "aff": "Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Univ. Bourgogne FrancheComt/ CNRS, FEMTO-ST Institute, Besan\u00e7on, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968485/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4567729034331331885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9;University Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "Institut des Syst\u00e9mes Intelligents et de Robotique;FEMTO-ST Institute",
        "aff_unique_url": "https://www.sorbonne-universite.fr;https://www.ubfc.fr",
        "aff_unique_abbr": "Sorbonne U;UBFC",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Paris;Besan\u00e7on",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967945",
        "title": "Comparison of Deep Reinforcement Learning Policies to Formal Methods for Moving Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Reinforcement Learning (RL) has recently emerged as a solution for moving obstacle avoidance. Deep RL learns to simultaneously predict obstacle motions and corresponding avoidance actions directly from robot sensors, even for obstacles with different dynamics models. However, deep RL methods typically cannot guarantee policy convergences, i.e., cannot provide probabilistic collision avoidance guarantees. In contrast, stochastic reachability (SR), a computationally expensive formal method that employs a known obstacle dynamics model, identifies the optimal avoidance policy and provides strict convergence guarantees. The availability of the optimal solution for versions of the moving obstacle problem provides a baseline to compare trained deep RL policies. In this paper, we compare the expected cumulative reward and actions of these policies to SR, and find the following. 1) The state-value function approximates the optimal collision probability well, thus explaining the high empirical performance. 2) RL policies deviate from the optimal significantly thus negatively impacting collision avoidance in some cases. 3) Evidence suggests that the deviation is caused, at least partially, by the actor net failing to approximate the action corresponding to the highest state-action value.",
        "primary_area": "",
        "author": "Arpit Garg;Hao-Tien Lewis Chiang;Satomi Sugaya;Aleksandra Faust;Lydia Tapia;Arpit Garg;Hao-Tien Lewis Chiang;Satomi Sugaya;Aleksandra Faust;Lydia Tapia",
        "authorids": "/37087324459;/37085457881;/37087323775;/37077144300;/37564283100;/37087324459;/37085457881;/37087323775;/37077144300;/37564283100",
        "aff": "Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Google AI, Mountain View, CA, USA; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967945/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5549612938530457614&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of New Mexico;Google",
        "aff_unique_dep": "Department of Computer Science;Google AI",
        "aff_unique_url": "https://www.unm.edu;https://ai.google",
        "aff_unique_abbr": "UNM;Google AI",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Albuquerque;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968005",
        "title": "Complex Stiffness Model of Physical Human-Robot Interaction: Implications for Control of Performance Augmentation Exoskeletons",
        "track": "main",
        "status": "Poster",
        "abstract": "Human joint dynamic stiffness plays an important role in the stability of performance augmentation exoskeletons. In this paper, we consider a new frequency domain model of the human joint dynamics which features a complex value stiffness. This complex stiffness consists of a real stiffness and a hysteretic damping. We use it to explain the dynamic behaviors of the human connected to the exoskeleton, in particular the observed non-zero low frequency phase shift and the near constant damping ratio of the resonance as stiffness and inertia vary. We validate this concept with an elbow-joint exoskeleton testbed (attached to a subject) by experimentally varying joint stiffness behavior, exoskeleton inertia, and the strength augmentation gain. We compare three different models of elbow-joint dynamic stiffness: a model with real stiffness, viscous damping and inertia; a model with complex stiffness and inertia; and a model combining the previous two models. Our results show that the hysteretic damping term improves modeling accuracy (via a statistical F-test). Moreover, this term contributes more to model accuracy than the viscous damping term. In addition, we experimentally observe a linear relationship between the hysteretic damping and the real part of the stiffness which allows us to simplify the complex stiffness model down to a 1-parameter system. Ultimately, we design a fractional order controller to demonstrate how human hysteretic damping behavior can be exploited to improve strength amplification performance while maintaining stability.",
        "primary_area": "",
        "author": "Binghan He;Huang Huang;Gray C. Thomas;Luis Sentis;Binghan He;Huang Huang;Gray C. Thomas;Luis Sentis",
        "authorids": "/37086429909;/37087325020;/37085525465;/37426747500;/37086429909;/37087325020;/37085525465;/37426747500",
        "aff": "The Departments of Mechanical Engineering (B.H., H.H., G.C.T.) and Aerospace Engineering (L.S.), University of Texas at Austin, Austin, TX; The Departments of Mechanical Engineering (B.H., H.H., G.C.T.) and Aerospace Engineering (L.S.), University of Texas at Austin, Austin, TX; The Departments of Mechanical Engineering (B.H., H.H., G.C.T.) and Aerospace Engineering (L.S.), University of Texas at Austin, Austin, TX; The Departments of Mechanical Engineering (B.H., H.H., G.C.T.) and Aerospace Engineering (L.S.), University of Texas at Austin, Austin, TX",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968005/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=335790026632686113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968068",
        "title": "Component Modularized Design of Musculoskeletal Humanoid Platform Musashi to Investigate Learning Control Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "To develop Musashi as a musculoskeletal humanoid platform to investigate learning control systems, we aimed for a body with flexible musculoskeletal structure, redundant sensors, and easily reconfigurable structure. For this purpose, we develop joint modules that can directly measure joint angles, muscle modules that can realize various muscle routes, and nonlinear elastic units with soft structures, etc. Next, we develop MusashiLarm, a musculoskeletal platform composed of only joint modules, muscle modules, generic bone frames, muscle wire units, and a few attachments. Finally, we develop Musashi, a musculoskeletal humanoid platform which extends MusashiLarm to the whole body design, and conduct several basic experiments and learning control experiments to verify the effectiveness of its concept.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Shogo Makino;Kei Tsuzuki;Moritaka Onitsuka;Yuya Nagamatsu;Koki Shinjo;Tasuku Makabe;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Kento Kawaharazuka;Shogo Makino;Kei Tsuzuki;Moritaka Onitsuka;Yuya Nagamatsu;Koki Shinjo;Tasuku Makabe;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086101930;/37086105354;/37086598284;/37086573419;/37086275431;/37087324644;/37086579382;/38238750500;/37280639000;/37085684621;/37286658200;/37086101930;/37086105354;/37086598284;/37086573419;/37086275431;/37087324644;/37086579382;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968068/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9846619093818266408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hongo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968150",
        "title": "Computing a Minimal Set of t-Spanning Motion Primitives for Lattice Planners",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we consider the problem of computing an optimal set of motion primitives for a lattice planner. The objective we consider is to compute a minimal set of motion primitives that t-span a configuration space lattice. A set of motion primitives t-span a lattice if, given a real number t greater or equal to one, any configuration in the lattice can be reached via a sequence of motion primitives whose cost is no more than t times the cost of the optimal path to that configuration. Determining the smallest set of t-spanning motion primitives allows for quick traversal of a state lattice in the context of robotic motion planning, while maintaining a t-factor adherence to the theoretically optimal path. While several heuristics exist to determine a t-spanning set of motion primitives, these are presented without guarantees on the size of the set relative to optimal. This paper provides a proof that the minimal t-spanning control set problem for a lattice defined over an arbitrary robot configuration space is NP-complete, and presents a compact mixed integer linear programming formulation to compute an optimal t-spanner. We show that solutions obtained by the mixed integer linear program have significantly fewer motion primitives than state of the art heuristic algorithms, and out perform a set of standard primitives used in robotic path planning.",
        "primary_area": "",
        "author": "Alexander Botros;Stephen L. Smith;Alexander Botros;Stephen L. Smith",
        "authorids": "/37086438755;/37335139700;/37086438755;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, 200 University Ave W, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, 200 University Ave W, Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968150/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6759686232201275333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968572",
        "title": "Concept and Validation of a Large-scale Human-machine Safety System Based on Real-time UWB Indoor Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In production line, the conventional industrial robots and automatic machines require machinery safety protection to guarantee the safety of human operators. A scalable and easy-to-conFigure safety system concept called \u201cReal-time Safety Virtual Positioning\u201d (RSVP) is proposed, which could act as potentially key enabler for agile production systems by eliminating fixed safety installation and thus increasing productivity and flexibility. The RSVP provides easy access to robots of automatic assembly lines in plants, e.g., automotive OEM, and supports virtualization and transparent to fully automatic and semi-automatic assembly line by knowing the position of persons and relevant objects (e.g., tools, finished and/or semi-finished goods, and materials). The focus of the paper will discuss the functional safety certification realization (concept approved by T\u00dcV (Technical Inspection Association)) and validation details of indoor localization-based safety system developments. The detailed strategy of the functional safety requirements, danger diagnosis and reaction approach, communication among safety controller, robot and machine, and safe failure reaction are listed and analyzed. The physical hardware framework and software architecture of the safety system are built and developed with the 1oo2-architecture according to the Performance Levels (PL d) of ISO 13849 and the Safety Integrity Levels (SIL 2) of IEC 61508. The implicated algorithms and data process of the UWB-based (Ultra-Wide Band) indoor localization system are introduced. The safety system concept is validated and verified in an ABS (Anti-lock Braking System) production line with human-robot co-existence environment.",
        "primary_area": "",
        "author": "Wei Wang;Zhuoqi Zeng;Wan Ding;Huajun Yu;Hannes Rose;Wei Wang;Zhuoqi Zeng;Wan Ding;Huajun Yu;Hannes Rose",
        "authorids": "/37086273154;/37086262835;/37087325007;/37087324011;/37086577922;/37086273154;/37086262835;/37087325007;/37087324011;/37086577922",
        "aff": "Connected Industry, Internet of Things, and Computer Vision Group, Research and Technology Center Asia Pacific, Corporate Research, Bosch (China) Investment Ltd., 333 Fuquan (N.) Road, Shanghai, P. R. China; Connected Industry, Internet of Things, and Computer Vision Group, Research and Technology Center Asia Pacific, Corporate Research, Bosch (China) Investment Ltd., 333 Fuquan (N.) Road, Shanghai, P. R. China; Connected Industry, Internet of Things, and Computer Vision Group, Research and Technology Center Asia Pacific, Corporate Research, Bosch (China) Investment Ltd., 333 Fuquan (N.) Road, Shanghai, P. R. China; Connected Industry, Internet of Things, and Computer Vision Group, Research and Technology Center Asia Pacific, Corporate Research, Bosch (China) Investment Ltd., 333 Fuquan (N.) Road, Shanghai, P. R. China; Connected Industry, Internet of Things, and Computer Vision Group, Research and Technology Center Asia Pacific, Corporate Research, Bosch (China) Investment Ltd., 333 Fuquan (N.) Road, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968572/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13017369717377070360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Bosch (China) Investment Ltd.",
        "aff_unique_dep": "Connected Industry, Internet of Things, and Computer Vision Group",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968169",
        "title": "Concurrent Flow-Based Localization and Mapping in Time-Invariant Flow Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the concept of concurrent flow-based localization and mapping (FLAM) for autonomous field robots navigating within background flows. Different from the classical simultaneous localization and mapping (SLAM) problem, where the robot interacts with discrete features, FLAM utilizes the continuous flow fields as navigation references for mobile robots and provides flow field mapping capability with in-situ flow velocity observations. This approach is of importance to underwater vehicles in mid-depth oceans or aerial vehicles in GPS-denied atmospheric circulations. This article introduces the formulation of FLAM as a full SLAM solution motivated by the feature-based GraphSLAM framework. The performance of FLAM was demonstrated through simulation within artificial flow fields that represent typical geophysical circulation phenomena: a steady single-gyre flow field and a double-gyre flow field with unsteady turbulent perturbations. The results indicate that FLAM provides significant improvements in the robots' localization accuracy and a consistent approximation of the background flow field. It is also shown that FLAM leads to smooth robot trajectory estimates.",
        "primary_area": "",
        "author": "Zhuoyuan Song;Kamran Mohseni;Zhuoyuan Song;Kamran Mohseni",
        "authorids": "/37085342795;/37402398400;/37085342795;/37402398400",
        "aff": "Department of Mechanical and Aerospace Engineering, Department of Mechanical Engineering, University of Florida, University of Hawai\u00ed M\u0101noa, Honolulu, HI, USA; William P. Bushnell Endowed Chaired Professor, Institute for Networked Autonomous Systems, University of Florida, Gainesville, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968169/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3167366245611371501&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Gainesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967822",
        "title": "Conditional Generative Neural System for Probabilistic Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective understanding of the environment and accurate trajectory prediction of surrounding dynamic obstacles are critical for intelligent systems such as autonomous vehicles and wheeled mobile robotics navigating in complex scenarios to achieve safe and high-quality decision making, motion planning and control. Due to the uncertain nature of the future, it is desired to make inference from a probability perspective instead of deterministic prediction. In this paper, we propose a conditional generative neural system (CGNS) for probabilistic trajectory prediction to approximate the data distribution, with which realistic, feasible and diverse future trajectory hypotheses can be sampled. The system combines the strengths of conditional latent space learning and variational divergence minimization, and leverages both static context and interaction information with soft attention mechanisms. We also propose a regularization method for incorporating soft constraints into deep neural networks with differentiable barrier functions, which can regulate and push the generated samples into the feasible regions. The proposed system is evaluated on several public benchmark datasets for pedestrian trajectory prediction and a roundabout naturalistic driving dataset collected by ourselves. The experimental results demonstrate that our model achieves better performance than various baseline approaches in terms of prediction accuracy.",
        "primary_area": "",
        "author": "Jiachen Li;Hengbo Ma;Masayoshi Tomizuka;Jiachen Li;Hengbo Ma;Masayoshi Tomizuka",
        "authorids": "/37086309095;/37086547315;/37281933000;/37086309095;/37086547315;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967822/",
        "gs_citation": 239,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11914486876061036004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967659",
        "title": "Configuration Modeling of a Soft Robotic Element with Selectable Bending Axes",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an approach for modeling new soft robotic materials which possess the ability to control directional stiffness. These materials are inspired by biological systems where movements are enabled by variable stiffness tissue and contraction of localized muscle groups. Here a low-melting-point (LMP) material lattice embedded in an elastomer serves as a rigid skeleton that may be locally melted to allow bending at selectable joint locations. The forward kinematics of the lattice has been modeled using the product of exponentials method with the incorporation of bending axis selectivity. In this paper, we develop this model to account for torques imposed by tendons, and we model the elastomer's resistance to bending as a torsional spring at the selected joints. Thus we obtain a two-way relationship between tendon forces and joint angles/axes. The concept of applying traditional robot modeling strategies to selectively compliant robotic structures could enable precise control of dexterous soft robots that satisfy stringent safety criteria.",
        "primary_area": "",
        "author": "Emily A. Allen;Brandon C. Townsend;John P. Swensen;Emily A. Allen;Brandon C. Townsend;John P. Swensen",
        "authorids": "/37087322023;/37087323175;/37949206100;/37087322023;/37087323175;/37949206100",
        "aff": "School of Mechanical and Materials Engineering, Washington State University, Pullman, WA; School of Mechanical and Materials Engineering, Washington State University, Pullman, WA; School of Mechanical and Materials Engineering, Washington State University, Pullman, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967659/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:m9aJwDZuaO0J:scholar.google.com/&scioq=Configuration+Modeling+of+a+Soft+Robotic+Element+with+Selectable+Bending+Axes&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Washington State University",
        "aff_unique_dep": "School of Mechanical and Materials Engineering",
        "aff_unique_url": "https://wsu.edu",
        "aff_unique_abbr": "WSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pullman",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968279",
        "title": "Connectivity-Preserving Swarm Teleoperation With A Tree Network",
        "track": "main",
        "status": "Poster",
        "abstract": "During swarm teleoperation, the operator may threaten the distance-dependent inter-robot communications and, with them, the connectivity of the slave swarm. To prevent the operator from disconnecting the swarm, this paper develops a constructive strategy to dynamically modulate the interconnections of, and the local damping injections at, all slave robots. Lyapunov-based set invariance analysis shows that the strategy preserves all interaction links in the tree network while synchronizing the slave swarm. By properly limiting the impact of the user command rather than rejecting it entirely, the proposed explicit gain update law enables the operator to guide the motion of the slave swarm to the extent to which it does not endanger swarm connectivity. An experiment illustrates that the proposed strategy can maintain the tree network connectivity of a teleoperated swarm.",
        "primary_area": "",
        "author": "Yuan Yang;Daniela Constantinescu;Yang Shi;Yuan Yang;Daniela Constantinescu;Yang Shi",
        "authorids": "/37086995217;/37425419400;/37420083500;/37086995217;/37425419400;/37420083500",
        "aff": "Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968279/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14078528874162766770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Victoria",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.uvic.ca",
        "aff_unique_abbr": "UVic",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Victoria",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968299",
        "title": "Constrained Heterogeneous Vehicle Path Planning for Large-area Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a strong demand for covering a large area autonomously by multiple UAVs (Unmanned Aerial Vehicles) supported by a ground vehicle. Limited by UAVs' battery life and communication distance, complete coverage of large areas typically involves multiple take-offs and landings to recharge batteries, and the transportation of UAVs between operation areas by a ground vehicle. In this paper, we introduce a novel large-area-coverage planning framework which collectively optimizes the paths for aerial and ground vehicles. Our method first partitions a large area into sub-areas, each of which a given fleet of UAVs can cover without recharging batteries. UAV operation routes, or trails, are then generated for each sub-area. Next, the assignment of trials to different UAVs and the order in which UAVs visit their assigned trails are simultaneously optimized to minimize the total UAV flight distance. Finally, a ground vehicle transportation path which visits all sub-areas is found by solving an asymmetric traveling salesman problem (ATSP). Although finding the globally optimal trail assignment and transition paths can be formulated as a Mixed Integer Quadratic Program (MIQP), the MIQP is intractable even for small problems. We show that the solution time can be reduced to close-to-real-time levels by first finding a feasible solution using a Random Key Genetic Algorithm (RKGA), which is then locally optimized by solving a much smaller MIQP.",
        "primary_area": "",
        "author": "Di Deng;Wei Jing;Yuhe Fu;Ziyin Huang;Jiahong Liu;Kenji Shimada;Di Deng;Wei Jing;Yuhe Fu;Ziyin Huang;Jiahong Liu;Kenji Shimada",
        "authorids": "/37086577056;/37085809046;/37087323027;/37087323088;/37087322478;/37324632500;/37086577056;/37085809046;/37087323027;/37087323088;/37087322478;/37324632500",
        "aff": "Faculty of Mechanical Engineering, Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA, USA; Dept.of CS, IHPC, A* STAR; 1, A* STAR Artificial Intelligence Initiative (A* AI), Fusionopolis Way, Singapore; Faculty of Mechanical Engineering, Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA, USA; Faculty of Mechanical Engineering, Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA, USA; Faculty of Mechanical Engineering, Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA, USA; Faculty of Mechanical Engineering, Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968299/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7332271586729978416&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Institute of High Performance Computing, A*STAR;A* STAR Artificial Intelligence Initiative",
        "aff_unique_dep": "Faculty of Mechanical Engineering;Department of Computer Science;Artificial Intelligence",
        "aff_unique_url": "https://www.cmu.edu;https://www.ihpc.a-star.edu.sg;",
        "aff_unique_abbr": "CMU;IHPC;A* AI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1;1;0;0;0;0",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "8967724",
        "title": "Constructing a Highly Interactive Vehicle Motion Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in the areas related to driving behavior, e.g., behavior modeling and prediction, requires datasets with highly interactive vehicle motions. Existing public vehicle motion datasets emphasize increasing the number of vehicles and time duration, but behavior-related researchers are suffering from two factors. First, strong interactions among vehicles are not well addressed and datasets are of relatively low-density to observe meaningful interactions. Second, most of the existing datasets are missing the map information with reference paths which is essential for driving-behavior-related research. To address this issue, a dataset with highly interactive vehicle motions is constructed in this paper. A variety of challenging driving scenarios such as unsignalized intersections and roundabouts are included. Reference paths are also constructed from motion data along with high-definition maps so that key features can be generated for both prediction and planning algorithms. Moreover, we propose a set of metrics to extract the interactive motions in different maps, including the minimum difference of time to collision point (MDTTC) and duration of waiting period. Such metrics are used to quantity the interaction density of the dataset. We also give several representative results on prediction and motion generation utilizing the constructed dataset to demonstrate how the dataset can facilitate research in the area of driving behavior.",
        "primary_area": "",
        "author": "Wei Zhan;Liting Sun;Di Wang;Yinghan Jin;Masayoshi Tomizuka;Wei Zhan;Liting Sun;Di Wang;Yinghan Jin;Masayoshi Tomizuka",
        "authorids": "/37067099600;/37085425729;/37086061043;/37087323144;/37281933000;/37067099600;/37085425729;/37086061043;/37087323144;/37281933000",
        "aff": "Mechanical Systems Control Laboratory (MSC Lab), University of California, Berkeley, CA, USA; Mechanical Systems Control Laboratory (MSC Lab), University of California, Berkeley, CA, USA; Xi\u2019an Jiaotong University, Xi\u2019an, P.R. China; Zhejiang University, Hangzhou, P.R. China; Mechanical Systems Control Laboratory (MSC Lab), University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967724/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=428229522807388123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of California, Berkeley;Xi'an Jiao Tong University;Zhejiang University",
        "aff_unique_dep": "Mechanical Systems Control Laboratory (MSC Lab);;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.xjtu.edu.cn;http://www.zju.edu.cn",
        "aff_unique_abbr": "UC Berkeley;XJTU;ZJU",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Berkeley;Xi'an;Hangzhou",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967523",
        "title": "Contact Skill Imitation Learning for Robot-Independent Assembly Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic automation is a key driver for the advancement of technology. The skills of human workers, however, are difficult to program and seem currently unmatched by technical systems. In this work we present a data-driven approach to extract and learn robot-independent contact skills from human demonstrations in simulation environments, using a Long Short Term Memory (LSTM) network. Our model learns to generate error-correcting sequences of forces and torques in task space from object-relative motion, which industrial robots carry out through a Cartesian force control scheme on the real setup. This scheme uses forward dynamics computation of a virtually conditioned twin of the manipulator to solve the inverse kinematics problem. We evaluate our methods with an assembly experiment, in which our algorithm handles part tilting and jamming in order to succeed. The results show that the skill is robust towards localization uncertainty in task space and across different joint configurations of the robot. With our approach, non-experts can easily program force-sensitive assembly tasks in a robot-independent way.",
        "primary_area": "",
        "author": "Stefan Scherzinger;Arne Roennau;R\u00fcdiger Dillmann;Stefan Scherzinger;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37086279085;/37590849800;/37280242100;/37086279085;/37590849800;/37280242100",
        "aff": "FZI Research Center for Information Technology Haid-und-Neu-Str. 10-14, Karlsruhe, Germany; FZI Research Center for Information Technology Haid-und-Neu-Str. 10-14, Karlsruhe, Germany; IAR Institute for Anthropomatics and Robotics, HIS Humanoids and Intelligence Systems Lab, KIT Karlsruhe Institute of Technology, Adenauerring 2, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967523/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17863216879053332056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "FZI Research Center for Information Technology;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.fzi.de;https://www.kit.edu",
        "aff_unique_abbr": "FZI;KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968194",
        "title": "Contact-Implicit Trajectory Optimization for Dynamic Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a reformulation of a contact-implicit optimization (CIO) approach that computes optimal trajectories for rigid-body systems in contact-rich settings. A hard-contact model is assumed, and the unilateral constraints are imposed in the form of complementarity conditions. Newton's impact law is adopted for enhanced physical correctness. The optimal control problem is formulated as a multi-staged program through a multiple-shooting scheme. This problem structure is exploited within the FORCES Pro framework to retrieve optimal motion plans, contact sequences and control inputs with increased computational efficiency. We investigate our method on a variety of dynamic object manipulation tasks, performed by a six degrees of freedom robot. The dynamic feasibility of the optimal trajectories, as well as the repeatability and accuracy of the task-satisfaction are verified through simulations and real hardware experiments on one of the manipulation problems.",
        "primary_area": "",
        "author": "Jean-Pierre Sleiman;Jan Carius;Ruben Grandia;Martin Wermelinger;Marco Hutter;Jean-Pierre Sleiman;Jan Carius;Ruben Grandia;Martin Wermelinger;Marco Hutter",
        "authorids": "/37087322472;/37086291987;/37086355336;/37086003710;/37545251000;/37087322472;/37086291987;/37086355336;/37086003710;/37545251000",
        "aff": "Robotic Systems Lab ETH Zurich, Zurich, Switzerland; Robotic Systems Lab ETH Zurich, Zurich, Switzerland; Robotic Systems Lab ETH Zurich, Zurich, Switzerland; Robotic Systems Lab ETH Zurich, Zurich, Switzerland; Robotic Systems Lab ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968194/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11090513413697372224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967960",
        "title": "ContactGrasp: Functional Multi-finger Grasp Synthesis from Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping and manipulating objects is an important human skill. Since most objects are designed to be manipulated by human hands, anthropomorphic hands can enable richer human-robot interaction. Desirable grasps are not only stable, but also functional: they enable post-grasp actions with the object. However, functional grasp synthesis for high degree-of-freedom anthropomorphic hands from object shape alone is challenging. We present ContactGrasp, a framework for functional grasp synthesis from object shape and contact on the object surface. Contact can be manually specified or obtained through demonstrations. Our contact representation is object-centric and allows functional grasp synthesis even for hand models different than the one used for demonstration. Using a dataset of contact demonstrations from humans grasping diverse household objects, we synthesize functional grasps for three hand models and two functional intents. The project webpage is https://contactdb.cc.gatech.edu/contactgrasp.html.",
        "primary_area": "",
        "author": "Samarth Brahmbhatt;Ankur Handa;James Hays;Dieter Fox;Samarth Brahmbhatt;Ankur Handa;James Hays;Dieter Fox",
        "authorids": "/37085458304;/37546502600;/37410626800;/37284329000;/37085458304;/37546502600;/37410626800;/37284329000",
        "aff": "Institute of Robotics and Intelligent Machines, Georgia Tech, Atlanta, GA, USA; NVIDIA Robotics, Seattle, USA; Institute of Robotics and Intelligent Machines, Georgia Tech, Atlanta, GA, USA; NVIDIA Robotics, Seattle, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967960/",
        "gs_citation": 132,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7211209751732663493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines;NVIDIA Robotics",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Georgia Tech;NVIDIA",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Atlanta;Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967873",
        "title": "Context and Intention Aware Planning for Urban Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel autonomous driving system which uses the road contextual information and intentions of other road users for urban driving. Unlike highways, urban environments require the drivers to follow traffic signs and signals while using their best judgment for anomalous situations. In such scenarios, a self-driving car needs to understand and take into account the uncertainties in the environment to plan and decide its action accordingly. Our planner models the intentions of the surrounding vehicles leveraging a neural network, and integrates the road contextual information to reduce its environment uncertainties and also speed up the decision making process. We validate our planner in simulation and in a real urban environment. Our experimental results show that integrating intention inference and road contextual information for prediction, planning and decision making help improve safety and efficiency of our autonomous driving system.",
        "primary_area": "",
        "author": "Malika Meghjani;Yuanfu Luo;Qi Heng Ho;Panpan Cai;Shashwat Verma;Daniela Rus;David Hsu;Malika Meghjani;Yuanfu Luo;Qi Heng Ho;Panpan Cai;Shashwat Verma;Daniela Rus;David Hsu",
        "authorids": "/37393934900;/37086426724;/37087321977;/37086341020;/37086452953;/37279652300;/37421581500;/37393934900;/37086426724;/37087321977;/37086341020;/37086452953;/37279652300;/37421581500",
        "aff": "Singapore-MIT Alliance for Research and Technology1, Singapore; National University of Singapore3, Singapore; Singapore-MIT Alliance for Research and Technology1, Singapore; National University of Singapore3, Singapore; Singapore University of Technology and Design2; Massachusetts Institute of Technology4, Cambridge, MA, USA; National University of Singapore3, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967873/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10441623633676918781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;2;3;1",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology;National University of Singapore;Singapore University of Technology and Design;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": ";https://www.nus.edu.sg;https://www.sutd.edu.sg;https://web.mit.edu",
        "aff_unique_abbr": "SMART;NUS;SUTD;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8967865",
        "title": "Context-Dependent Search for Generating Paths for Redundant Manipulators in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a context-dependent bi-directional tree-search framework for point-to-point path planning for manipulators. Conceptually, our framework is composed of six modules: tree selection, focus selection, node selection, target selection, extend selection and connection type selection. Each module consists of a set of interchangeable strategies. By exploiting synergistic interaction between these strategies and selecting appropriate strategies based the contextual cues from the search state, we show an instance of our framework that computes high-quality solutions in a variety of complex scenarios with a low failure rate. We also show that some popular path planning methods in the literature can be easily represented in our framework. We compare our approach with these popular methods in a diverse set of test scenarios. We report a 15-fold reduction in failure rate coupled with at least a 26% drop in solution suboptimality when compared to the best of the alternative methods.",
        "primary_area": "",
        "author": "Pradeep Rajendran;Shantanu Thakar;Ariyan M. Kabir;Brual C. Shah;Satyandra K. Gupta;Pradeep Rajendran;Shantanu Thakar;Ariyan M. Kabir;Brual C. Shah;Satyandra K. Gupta",
        "authorids": "/37086458768;/37085804412;/37085768994;/37085571133;/37878971100;/37086458768;/37085804412;/37085768994;/37085571133;/37878971100",
        "aff": "Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, U.S.A; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, U.S.A; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, U.S.A; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, U.S.A; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967865/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6314613294859314718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Center for Advanced Manufacturing",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967836",
        "title": "Continuous Collision Detection for a Robotic Arm Mounted on a Cable-Driven Parallel Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "A continuous collision checking method for a cable-driven parallel robot with an embarked robotic arm is proposed in this paper. The method aims at validating paths by checking for collisions between any pair of robot bodies (mobile platform, cables, and arm links). For a pair of bodies, an upper bound on their relative velocity and a lower bound on the distance between the bodies are computed and used to validate a portion of the path. These computations are done repeatedly until a collision is found or the path is validated. The method is integrated within the Humanoid Path Planner (HPP) software, tested with the cable-driven parallel robot CoGiRo, and compared to a discretized validation method.",
        "primary_area": "",
        "author": "Diane Bury;Jean-Baptiste Izard;Marc Gouttefarde;Florent Lamiraux;Diane Bury;Jean-Baptiste Izard;Marc Gouttefarde;Florent Lamiraux",
        "authorids": "/37087322534;/37391770800;/37542917900;/37279738200;/37087322534;/37391770800;/37542917900;/37279738200",
        "aff": "Tecnalia France, Bat 6 CSU, 950 rue Saint-Priest, Montpellier, France; Tecnalia France, Bat 6 CSU, 950 rue Saint-Priest, Montpellier, France; LIRMM, Universit\u00e9 de Montpellier, CNRS, Montpellier, France; Tecnalia France, LAAS-CNRS, University of Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967836/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1115169943493543732&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Tecnalia France;Universit\u00e9 de Montpellier",
        "aff_unique_dep": ";LIRMM",
        "aff_unique_url": ";https://www.univ-montp2.fr",
        "aff_unique_abbr": ";UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montpellier;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968220",
        "title": "Continuous Modeling of Affordances in a Symbolic Knowledge Base",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots start to execute complex manipulation tasks, they are expected to improve their skill set over time as humans do. A prominent approach to accomplish this is having robots to keep models of their actions based on their experiences in order to improve their action executions in the future. In this paper, we present such a methodology where robots start to execute some actions with random parameters and record their generic execution logs with semantic annotations in a symbolic knowledge base for robots. Using the data inside logs, multivariate Gaussian mixture models are fitted to the high-level action parameters for later executions. These affordance models are being updated whenever a new execution is carried on. In essence, robots can use these continuously-updated probabilistic model for improving their actions To prove the applicability we demonstrate opening-a-fridge-door experiments with a PR2 robot.",
        "primary_area": "",
        "author": "Asil Kaan Bozcuo\u011flu;Yuki Furuta;Kei Okada;Michael Beetz;Masayuki Inaba;Asil Kaan Bozcuo\u011flu;Yuki Furuta;Kei Okada;Michael Beetz;Masayuki Inaba",
        "authorids": "/37085664845;/37086176926;/37280639000;/37279125900;/37286658200;/37085664845;/37086176926;/37280639000;/37279125900;/37286658200",
        "aff": "Institute for Artificial Intelligence, Universit\u00e4t Bremen, Bremen, Germany; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Institute for Artificial Intelligence, Universit\u00e4t Bremen, Bremen, Germany; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968220/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5791039706980395546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Universit\u00e4t Bremen;University of Tokyo",
        "aff_unique_dep": "Institute for Artificial Intelligence;Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.uni-bremen.de;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": ";UTokyo",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Bremen;Tokyo",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "8967761",
        "title": "Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We address one-shot imitation learning, where the goal is to execute a previously unseen task based on a single demonstration. While there has been exciting progress in this direction, most of the approaches still require a few hundred tasks for meta-training, which limits the scalability of the approaches. Our main contribution is to formulate one-shot imitation learning as a symbolic planning problem along with the symbol grounding problem. This formulation disentangles the policy execution from the inter-task generalization and leads to better data efficiency. The key technical challenge is that the symbol grounding is prone to error with limited training data and leads to subsequent symbolic planning failures. We address this challenge by proposing a continuous relaxation of the discrete symbolic planner that directly plans on the probabilistic outputs of the symbol grounding model. Our continuous relaxation of the planner can still leverage the information contained in the probabilistic symbol grounding and significantly improve over the baseline planner for the one-shot imitation learning tasks without using large training data.",
        "primary_area": "",
        "author": "De-An Huang;Danfei Xu;Yuke Zhu;Animesh Garg;Silvio Savarese;Li Fei-Fei;Juan Carlos Niebles;De-An Huang;Danfei Xu;Yuke Zhu;Animesh Garg;Silvio Savarese;Li Fei-Fei;Juan Carlos Niebles",
        "authorids": "/37086255410;/37086228189;/37086080772;/37086330576;/37298502600;/38273560700;/38272274300;/37086255410;/37086228189;/37086080772;/37086330576;/37298502600;/38273560700;/38272274300",
        "aff": "Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967761/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8485296356028373958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967580",
        "title": "Continuous close-range 3D object pose estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of future manufacturing lines, removing fixtures will be a fundamental step to increase the flexibility of autonomous systems in assembly and logistic operations. Vision-based 3D pose estimation is a necessity to accurately handle objects that might not be placed at fixed positions during the robot task execution. Industrial tasks bring multiple challenges for the robust pose estimation of objects such as difficult object properties, tight cycle times and constraints on camera views. In particular, when interacting with objects, we have to work with close-range partial views of objects that pose a new challenge for typical view-based pose estimation methods.In this paper, we present a 3D pose estimation method based on a gradient-ascend particle filter that integrates new observations on-the-fly to improve the pose estimate. Thereby, we can apply this method online during task execution to save valuable cycle time. In contrast to other view-based pose estimation methods, we model potential views in full 6dimensional space that allows us to cope with close-range partial objects views. We demonstrate the approach on a real assembly task, in which the algorithm usually converges to the correct pose within 10-15 iterations with an average accuracy of less than 8mm.",
        "primary_area": "",
        "author": "Bjarne Grossmann;Francesco Rovida;Volker Kruger;Bjarne Grossmann;Francesco Rovida;Volker Kruger",
        "authorids": "/37086212293;/37085541867;/37274543000;/37086212293;/37085541867;/37274543000",
        "aff": "Robotics, Vision, and Machine Intelligence (RVMI) Lab, Aalborg University Copenhagen, Copenhagen, Denmark; Robotics, Vision, and Machine Intelligence (RVMI) Lab, Aalborg University Copenhagen, Copenhagen, Denmark; Robotics, Vision, and Machine Intelligence (RVMI) Lab, Aalborg University Copenhagen, Copenhagen, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967580/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14472017940366472928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalborg University Copenhagen",
        "aff_unique_dep": "Robotics, Vision, and Machine Intelligence (RVMI) Lab",
        "aff_unique_url": "https://www.aau.dk",
        "aff_unique_abbr": "AAU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Copenhagen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8967641",
        "title": "Continuous-Time Collision Avoidance for Trajectory Optimization in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Common formulations to consider collision avoidance in trajectory optimization often use either preprocessed environments or only check and penalize collisions at discrete time steps. However, when only checking at discrete states, this requires either large margins that prevent manipulation close to obstacles or dense time discretization increasing the dimensionality of the optimization problem in complex environments. Nonetheless, collisions may still occur in the interpolation/transition between two valid states or in environments with thin obstacles. In this work, we introduce a computationally inexpensive continuous-time collision avoidance term in presence of static and moving obstacles. Our penalty is based on conservative advancement and harmonic potential fields and can be used as either a cost or constraint in off-the-shelf non-linear programming solvers. Due to the use of conservative advancement (collision checks) rather than distance computations, our method outperforms discrete collision avoidance based on signed distance constraints resulting in smooth motions with continuous-time safety while planning in discrete time. We evaluate our proposed continuous collision avoidance on scenarios including manipulation of moving targets, locomanipulation on mobile robots, manipulation trajectories for humanoids, and quadrotor path planning and compare penalty terms based on harmonic potential fields with ones derived from contact normals.",
        "primary_area": "",
        "author": "Wolfgang Merkt;Vladimir Ivan;Sethu Vijayakumar;Wolfgang Merkt;Vladimir Ivan;Sethu Vijayakumar",
        "authorids": "/37086118415;/37085552022;/37295595500;/37086118415;/37085552022;/37295595500",
        "aff": "Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh (Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh (Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh (Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967641/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14821531278140182164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967697",
        "title": "Contour based Reconstruction of Underwater Structures Using Sonar, Visual, Inertial, and Depth Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a systematic approach on realtime reconstruction of an underwater environment using Sonar, Visual, Inertial, and Depth data. In particular, low lighting conditions, or even complete absence of natural light inside caves, results in strong lighting variations, e.g., the cone of the artificial video light intersecting underwater structures, and the shadow contours. The proposed method utilizes the well defined edges between well lit areas and darkness to provide additional features, resulting into a denser 3D point cloud than the usual point clouds from a visual odometry system. Experimental results in an underwater cave at Ginnie Springs, FL, with a custom-made underwater sensor suite demonstrate the performance of our system. This will enable more robust navigation of autonomous underwater vehicles using the denser 3D point cloud to detect obstacles and achieve higher resolution reconstructions.",
        "primary_area": "",
        "author": "Sharmin Rahman;Alberto Quattrini Li;Ioannis Rekleitis;Sharmin Rahman;Alberto Quattrini Li;Ioannis Rekleitis",
        "authorids": "/37085989996;/37085808885;/37281356300;/37085989996;/37085808885;/37281356300",
        "aff": "Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967697/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14790525920917857697&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of South Carolina;Dartmouth College",
        "aff_unique_dep": "Computer Science and Engineering Department;Department of Computer Science",
        "aff_unique_url": "https://www.sc.edu;https://www.dartmouth.edu",
        "aff_unique_abbr": "USC;Dartmouth",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Columbia;Hanover",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967599",
        "title": "Control and Perception Framework for Deep Sea Mining Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the control and perception framework used in the ROBUST EU Horizon 2020 project, aimed at integrate different technologies for developing an underwater autonomous robotic system for exploring deep-sea mining sites. The vehicle firstly collects data of the initial zone of interest and it selects a sub area which is the most probable to contain a manganese nodule field; then it carries out a low altitude survey. When a possible nodule is detected by the cameras, the vehicle lands on the seafloor, allowing the following fixed based manipulation which is designed to perform the nodule analysis. The work reports the implemented control and perception architecture and the preliminary pool experiments results.",
        "primary_area": "",
        "author": "Carlotta Sartore;Ricard Campos;Josep Quintana;Enrico Simetti;Rafael Garcia;Giuseppe Casalino;Carlotta Sartore;Ricard Campos;Josep Quintana;Enrico Simetti;Rafael Garcia;Giuseppe Casalino",
        "authorids": "/37089922201;/37901642800;/37085419686;/37601568800;/37276526000;/37273114600;/37089922201;/37901642800;/37085419686;/37601568800;/37276526000;/37273114600",
        "aff": "Interuniversity Research Center on Integrated Systems for the Marine Environment, Via Opera Pia 13, Genova, Italy; Coronis Computing, Parc Cientific i Tecnologic UdG - Edifici Giroempren C/Picde Peguera, Girona, Spain; Coronis Computing, Parc Cientific i Tecnologic UdG - Edifici Giroempren C/Picde Peguera, Girona, Spain; Interuniversity Research Center on Integrated Systems for the Marine Environment, Via Opera Pia 13, Genova, Italy; Coronis Computing, Parc Cientific i Tecnologic UdG - Edifici Giroempren C/Picde Peguera, Girona, Spain; Interuniversity Research Center on Integrated Systems for the Marine Environment, Via Opera Pia 13, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967599/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6183906514708907873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;0",
        "aff_unique_norm": "Interuniversity Research Center on Integrated Systems for the Marine Environment;Coronis Computing",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;1;0",
        "aff_country_unique": "Italy;Spain"
    },
    {
        "id": "8968075",
        "title": "Cooperative Audio-Visual System for Localizing Small Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Employing small size aerial robots, acting as mobile airborne sensors, to work alongside ground robots can be extremely useful in many different robotic missions. Due to the strict constraints in terms of size, weight, 3D coverage, processing power and power consumption. There are not many technological possibilities for performing independent self-localization for such tiny robots. This paper describes a cooperative audio-visual localization system to robustly estimate the position of a small aerial robot from a ground robot. Experimental results with a 40-gram quadrotor assess the performance of the system and demonstrate the reliability gained through fusion of sound measurements with visual information.",
        "primary_area": "",
        "author": "Jose Rosa;Meysam Basiri;Jose Rosa;Meysam Basiri",
        "authorids": "/37086012687;/37403004200;/37086012687;/37403004200",
        "aff": "Institute for Systems and Robotics of the Instituto Superior Tecnico, Universidade de Lisboa, Portugal; Institute for Systems and Robotics of the Instituto Superior Tecnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968075/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13867853639685001870&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Instituto Superior Tecnico",
        "aff_unique_dep": "Institute for Systems and Robotics",
        "aff_unique_url": "https://www.ist.utl.pt",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "8967646",
        "title": "Cooperative Range-only SLAM based on Sum of Gaussian Filter in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Most range-only simultaneous localization and mapping (RO-SLAM) algorithms have considered direct measurements between robot and its neighbor nodes only, even though other inter-node measurements can be actively used to improve the performance. In addition, most of them assume nodes are static, i.e., fixed on one place and cannot be applied to dynamic environments where some or all of nodes are moving. To address the aforementioned issues, a cooperative dynamic RO-SLAM (CDRO-SLAM) is proposed in this paper, which is a RO-SLAM algorithm based on sum of Gaussian (SoG) filter with cooperative measurements in dynamic environments. The proposed CDRO-SLAM integrates all the inter-node measurements for localization, which results in a smaller map estimation error with a faster convergence speed than the conventional ROSLAM. Moreover, the proposed CDRO-SLAM can also track movement of any nodes under the dynamic environment by resetting and updating the SoG variables. Such advantages of the proposed CDRO-SLAM algorithm are verified with the real experimental data.",
        "primary_area": "",
        "author": "Jung-Hee Kim;Doik Kim;Jung-Hee Kim;Doik Kim",
        "authorids": "/37086478886;/37291959500;/37086478886;/37291959500",
        "aff": "Center for Intelligent Robotics Research, Robotics and Media Institute, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent Robotics Research, Robotics and Media Institute, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967646/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18328978140533570945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology",
        "aff_unique_dep": "Center for Intelligent Robotics Research, Robotics and Media Institute",
        "aff_unique_url": "http://www.kist.re.kr",
        "aff_unique_abbr": "KIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967975",
        "title": "Cooperative Schedule-Driven Intersection Control with Connected and Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work in decentralized, schedule-driven traffic control has demonstrated the ability to improve the efficiency of traffic flow in complex urban road networks. In this approach, a scheduling agent is associated with each intersection. Each agent senses the traffic approaching its intersection and in real-time constructs a schedule that minimizes the cumulative wait time of vehicles approaching the intersection over the current look-ahead horizon. In this paper, we propose a cooperative algorithm that utilizes both connected and autonomous vehicles (CAV) and schedule-driven traffic control to create better traffic flow in the city. The algorithm enables an intersection scheduling agent to adjust the arrival time of an approaching platoon through use of wireless communication to control the velocity of vehicles. The sequence of approaching platoons is thus shifted toward a new shape that has smaller cumulative delay. We demonstrate how this algorithm outperforms the original approach in a real-time traffic signal control problem.",
        "primary_area": "",
        "author": "Hsu-Chieh Hu;Stephen F. Smith;Rick Goldstein;Hsu-Chieh Hu;Stephen F. Smith;Rick Goldstein",
        "authorids": "/37087321971;/38183671500;/37087324816;/37087321971;/38183671500;/37087324816",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967975/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16355749314191915222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967632",
        "title": "Cooperative decentralised circumnavigation with application to algal bloom tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Harmful algal blooms occur frequently and deteriorate water quality. A reliable method is proposed in this paper to track algal blooms using a set of autonomous surface robots. A satellite image indicates the existence and initial location of the algal bloom for the deployment of the robot system. The algal bloom area is approximated by a circle with time varying location and size. This circle is estimated and circumnavigated by the robots which are able to locally sense its boundary. A multi-agent control algorithm is proposed for the continuous monitoring of the dynamic evolution of the algal bloom. Such algorithm comprises of a decentralised least squares estimation of the target and a controller for circumnavigation. We prove the convergence of the robots to the circle and in equally spaced positions around it. Simulation results with data provided by the SINMOD ocean model are used to illustrate the theoretical results.",
        "primary_area": "",
        "author": "Joana Fonseca;Jieqiang Wei;Karl H. Johansson;Tor Ame Johansen;Joana Fonseca;Jieqiang Wei;Karl H. Johansson;Tor Ame Johansen",
        "authorids": "/37087325321;/37086030610;/37270842500;/37086943789;/37087325321;/37086030610;/37270842500;/37086943789",
        "aff": "ACCESS Linnaeus Centre, School of Elecmcal Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; ACCESS Linnaeus Centre, School of Elecmcal Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; ACCESS Linnaeus Centre, School of Elecmcal Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Engineenng Cybernetics, Norwegian University of Science and Teclmology, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967632/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13819024015600436888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "KTH Royal Institute of Technology;Norwegian University of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;Department of Engineering Cybernetics",
        "aff_unique_url": "https://www.kth.se;https://www.ntnu.edu",
        "aff_unique_abbr": "KTH;NTNU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Stockholm;Trondheim",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Sweden;Norway"
    },
    {
        "id": "8967684",
        "title": "Coupling Disturbance Compensated MIMO Control of Parallel Ankle Rehabilitation Robot Actuated by Pneumatic Muscles",
        "track": "main",
        "status": "Poster",
        "abstract": "To solve the poor compliance and safety problems in current rehabilitation robots, a novel two-degrees-of-freedom (2-DOF) soft ankle rehabilitation robot driven by pneumatic muscles (PMs) is presented, taking advantages of the PM's inherent compliance and the parallel structure's high stiffness and payload capacity. However, the PM's nonlinear, time-varying and hysteresis characteristics, and the coupling interference from parallel structure, as well as the unpredicted disturbance caused by arbitrary human behavior all raise difficulties in achieving high-precision control of the robot. In this paper, a multi-input-multi-output disturbance compensated sliding mode controller (MIMO-DCSMC) is proposed to tackle these problems. The proposed control method can tackle the un-modeled uncertainties and the coupling interference existed in multiple PMs' synchronous movement, even with the subject's participation. Experiment results on a healthy subject confirmed that the PMs-actuated ankle rehabilitation robot controlled by the proposed MIMO-DCSMC is able to assist patients to perform high-accuracy rehabilitation tasks by tracking the desired trajectory in a compliant manner.",
        "primary_area": "",
        "author": "Jie Zuo;Wei Meng;Quan Liu;Qingsong Ai;Sheng Q. Xie;Zude Zhou;Jie Zuo;Wei Meng;Quan Liu;Qingsong Ai;Sheng Q. Xie;Zude Zhou",
        "authorids": "/37086885551;/38019686000;/37535790800;/37085385186;/37833367900;/37278613900;/37086885551;/38019686000;/37535790800;/37085385186;/37833367900;/37278613900",
        "aff": "School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK; School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967684/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=458526232389957799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Wuhan University of Technology;University of Leeds",
        "aff_unique_dep": "School of Information Engineering;School of Electronic and Electrical Engineering",
        "aff_unique_url": "http://www.wut.edu.cn;https://www.leeds.ac.uk",
        "aff_unique_abbr": ";Leeds",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "Wuhan;Leeds",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "8967886",
        "title": "Covariance Pre-Integration for Delayed Measurements in Multi-Sensor Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Delay compensation in filter based sensor fusion frameworks for multiple sensors with varying delays and different rates quickly results in large computational overhead should the delayed measurements be incorporated in a statistically meaningful way. Even more so if high rate propagation sensors (e.g. IMU) are used. This work presents an approach to implement such frameworks with significant complexity reduction compared to standard implementations. We set particular focus on the state covariance propagation as this chain of re-computations (i.e. FPFT + Q per propagation step) upon a delayed update is the dominant bottleneck. We draw our inspiration from the scattering theory and propose a method which projects the idea of wave propagation to an efficient concatenation of covariance propagation steps between filter updates. Through this approach, we reach a speed-up of more than a factor of 10 for the covariance propagation and render the computational complexity independent of the number of propagation steps between filter updates. We evaluated our method in simulation and with real data.",
        "primary_area": "",
        "author": "Eren Allak;Roland Jung;Stephan Weiss;Eren Allak;Roland Jung;Stephan Weiss",
        "authorids": "/37086580226;/37087323495;/37535323400;/37086580226;/37087323495;/37535323400",
        "aff": "Department of Smart Systems Technologies in the Control of Networked Systems Group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Karl Popper School on Networked Autonomous Aerial Vehicles, Alpen-Adria-Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967886/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18225841046410041485&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt;Alpen-Adria-Universit\u00e4t Klagenfurt",
        "aff_unique_dep": "Department of Smart Systems Technologies;Karl Popper School on Networked Autonomous Aerial Vehicles",
        "aff_unique_url": "https://www.uni-klagenfurt.at;https://www.aau.at",
        "aff_unique_abbr": "Uni Klagenfurt;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Klagenfurt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "8967969",
        "title": "Coverage Path Planning using Path Primitive Sampling and Primitive Coverage Graph for Visual Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning the path to gather the surface information of the target objects is crucial to improve the efficiency of and reduce the overall cost, for visual inspection applications with Unmanned Aerial Vehicles (UAVs). Coverage Path Planning (CPP) problem is often formulated for these inspection applications because of the coverage requirement. Traditionally, researchers usually plan and optimize the viewpoints to capture the surface information first, and then optimize the path to visit the selected viewpoints. In this paper, we propose a novel planning method to directly sample and plan the inspection path for a camera-equipped UAV to acquire visual and geometric information of the target structures as a video stream setting in complex 3D environment. The proposed planning method first generates via-points and path primitives around the target object by using sampling methods based on voxel dilation and subtraction. A novel Primitive Coverage Graph (PCG) is then proposed to encode the topological information, flying distances, and visibility information, with the sampled via-points and path primitives. Finally graph search is performed to find the resultant path in the PCG to complete the inspection task with the coverage requirements. The effectiveness of the proposed method is demonstrated through simulation and field tests in this paper.",
        "primary_area": "",
        "author": "Wei Jing;Di Deng;Zhe Xiao;Yong Liu;Kenji Shimada;Wei Jing;Di Deng;Zhe Xiao;Yong Liu;Kenji Shimada",
        "authorids": "/37085809046;/37086577056;/37089404819;/37089074090;/37324632500;/37085809046;/37086577056;/37089404819;/37089074090;/37324632500",
        "aff": "A*TAR Artificial Intelligence Initiative (A*AI), 1 Fusionopolis Way, Singapore; Department of Mechanical Engineering, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA, USA; Department of Computing Science, Institute of High Performance Computing, 1 Fusionopolis Way, Singapore; A*TAR Artificial Intelligence Initiative (A*AI), 1 Fusionopolis Way, Singapore; Department of Mechanical Engineering, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967969/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8386126315270839754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "A*TAR Artificial Intelligence Initiative;Carnegie Mellon University;Institute of High Performance Computing",
        "aff_unique_dep": "Artificial Intelligence Initiative;Department of Mechanical Engineering;Department of Computing Science",
        "aff_unique_url": ";https://www.cmu.edu;https://www.aicloud.sg",
        "aff_unique_abbr": "A*AI;CMU;IHPC",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Fusionopolis;Pittsburgh",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8967735",
        "title": "Coverage Sampling Planner for UAV-enabled Environmental Exploration and Field Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial Vehicles (UAVs) have been implemented for environmental monitoring by using their capabilities of mobile sensing, autonomous navigation, and remote operation. However, in real-world applications, the limitations of on-board resources (e.g., power supply) of UAVs will constrain the coverage of the monitored area and the number of the acquired samples, which will hinder the performance of field estimation and mapping. Therefore, the issue of constrained resources calls for an efficient sampling planner to schedule UAV-based sensing tasks in environmental monitoring. This paper presents a mission planner of coverage sampling and path planning for a UAV-enabled mobile sensor to effectively explore and map an unknown environment that is modeled as a random field. The proposed planner can generate a coverage path with an optimal coverage density for exploratory sampling, and the associated energy cost is subjected to a power supply constraint. The performance of the developed framework is evaluated and compared with the existing state-of-the-art algorithms, using a real-world dataset that is collected from an environmental monitoring program as well as physical field experiments. The experimental results illustrate the reliability and accuracy of the presented coverage sampling planner in a prior survey for environmental exploration and field mapping.",
        "primary_area": "",
        "author": "Teng Li;Chaoqun Wang;Meng Max Q.-H.;Clarence W. de Silva;Teng Li;Chaoqun Wang;Meng Max Q.-H.;Clarence W. de Silva",
        "authorids": "/37085461964;/37085492449;/37086597021;/37087323488;/37085461964;/37085492449;/37086597021;/37087323488",
        "aff": "Teng Li and Clarence W. de Silva are with Department of Mechanical Engineering, University of British Columbia, BC, Canada; Chaoqun Wang and Max Q. -H. Meng are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong; Chaoqun Wang and Max Q. -H. Meng are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong; Teng Li and Clarence W. de Silva are with Department of Mechanical Engineering, University of British Columbia, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967735/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7432348406694335144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of British Columbia;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electronic Engineering",
        "aff_unique_url": "https://www.ubc.ca;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "UBC;CUHK",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Vancouver;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "8968592",
        "title": "Criteria for Maintaining Desired Contacts for Quasi-Static Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic manipulation, finding a feasible motion plan doesn't guarantee a successful execution. The real world could bring all kinds of unexpected changes to the planned motion, the most deadly ones are usually marked by or caused by unexpected changes of contacts (object slipping away between fingers; getting stuck somewhere, etc). We notice that some actions are more likely to maintain desired contacts than others. To help finding these actions, in this work we propose a set of criteria to quantify the robustness of contacts against modeling uncertainties and disturbance forces. Under the quasi-static assumption, we analyze the causes of contact mode (sticking, sliding, disengaged) transitions and discuss how to endure larger uncertainties and disturbances. We summarize our results into several physically meaningful and easy-to-compute scores, which can be used to evaluate the quality of each individual contacts in a manipulation system. We illustrate the meaning of the scores with a simple example.",
        "primary_area": "",
        "author": "Yifan Hou;Matthew T. Mason;Yifan Hou;Matthew T. Mason",
        "authorids": "/37086454260;/37273994200;/37086454260;/37273994200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968592/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3567591952339149432&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968020",
        "title": "Crowd-sourced Semantic Edge Mapping for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly accurate maps of the road infrastructure are a crucial cornerstone for self-driving cars to enable navigation in complex traffic scenarios. Traditional methods for creating detailed maps of road environments involve expensive survey vehicles that cannot keep up with the frequent changes in the road network. In this paper, we propose a novel method to derive detailed high-definition maps by crowd sourcing data using commodity sensors. Our system uses multi-session feature-based visual SLAM to align submaps recorded by individual vehicles on a central backend server. We reconstruct 3D boundaries of road infrastructure elements such as road markings and road boundaries from semantic object contours detected in keyframes by a neural network. The result is a concise map of semantically meaningful objects suitable both for localization and higher-level planning tasks of automated vehicles. We evaluate our method on real-world data against a globally referenced ground-truth map demonstrating a high level of detail and metric accuracy.",
        "primary_area": "",
        "author": "Markus Herb;Tobias Weiherer;Nassir Navab;Federico Tombari;Markus Herb;Tobias Weiherer;Nassir Navab;Federico Tombari",
        "authorids": "/37086308051;/38492400600;/37282965500;/37593332100;/37086308051;/38492400600;/37282965500;/37593332100",
        "aff": "Department Sensorfusion/MapLearning, AUDI AG, Ingolstadt, Germany; Department Sensorfusion/MapLearning, AUDI AG, Ingolstadt, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968020/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12972360904680023084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "AUDI AG;Technical University of Munich",
        "aff_unique_dep": "Department Sensorfusion/MapLearning;Chair for Computer Aided Medical Procedures",
        "aff_unique_url": "https://www.audi.de;https://www.tum.de",
        "aff_unique_abbr": "AUDI;TUM",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Ingolstadt;Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968026",
        "title": "Curved-Voxel Clustering for Accurate Segmentation of 3D LiDAR Point Clouds with Real-Time Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "Given 3D LiDAR point clouds, how can we segment them fast and accurately? Fast and accurate segmentation of 3D LiDAR points is an important issue in mobile robotics with various applications in classification, tracking, SLAM, etc. Despite its importance, existing methods do not provide both speed and accuracy; in particular, methods performing segmentation in the 3D domain are too slow, disabling its use in real-time processing. In this paper, we propose Curved-Voxel Clustering (CVC), a fast and accurate method for segmenting 3D LiDAR point clouds utilizing LiDAR-optimized curved-voxel. CVC attains fine discriminations by considering three important aspects for clustering 3D LiDAR points: distance from the sensor, directional resolutions, and rarity of points. CVC succeeds in providing real-time performance by carefully managing curved-voxels with a hash table. Especially, CVC works well on sparse 3D point clouds. Through experiments, we show that our method is up to 1.7\u00d7 faster and 30% more accurate than other segmentation methods. CVC enables real-time segmentation with more than 20 runs in a second.",
        "primary_area": "",
        "author": "Seungcheol Park;Shuyu Wang;Hunjung Lim;U Kang;Seungcheol Park;Shuyu Wang;Hunjung Lim;U Kang",
        "authorids": "/37087321968;/37087325031;/37087323105;/37085655621;/37087321968;/37087325031;/37087323105;/37085655621",
        "aff": "Department of Computer Science and Engineering, Seoul National University, Republic of Korea; Department of Computer Science and Engineering, Seoul National University, Republic of Korea; Samsung Electronics; Department of Computer Science and Engineering, Seoul National University, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968026/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7626678382081636000&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Seoul National University;Samsung",
        "aff_unique_dep": "Department of Computer Science and Engineering;Samsung Electronics",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.samsung.com",
        "aff_unique_abbr": "SNU;Samsung",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968108",
        "title": "DEDUCE: Diverse scEne Detection methods in Unseen Challenging Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there has been a rapid increase in the number of service robots deployed for aiding people in their daily activities. Unfortunately, most of these robots require human input for training in order to do tasks in indoor environments. Successful domestic navigation often requires access to semantic information about the environment, which can be learned without human guidance. In this paper, we propose a set of DEDUCE1 - Diverse scEne Detection methods in Unseen Challenging Environments algorithms which incorporate deep fusion models derived from scene recognition systems and object detectors. The five methods described here have been evaluated on several popular recent image datasets, as well as real-world videos acquired through multiple mobile platforms. The final results show an improvement over the existing state-of-the-art visual place recognition systems.",
        "primary_area": "",
        "author": "Anwesan Pal;Carlos Nieto-Granda;Henrik I. Christensen;Anwesan Pal;Carlos Nieto-Granda;Henrik I. Christensen",
        "authorids": "/37087322272;/38270145500;/37281307400;/37087322272;/38270145500;/37281307400",
        "aff": "Contextual Robotics Institute, University of California, San Diego, La Jolla, CA, USA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA, USA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968108/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3827570038228952464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Contextual Robotics Institute",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967760",
        "title": "DESK: A Robotic Activity Dataset for Dexterous Surgical Skills Transfer to Medical Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Datasets are an essential component for training effective machine learning models. In particular, surgical robotic datasets have been key to many advances in semi-autonomous surgeries, skill assessment, and training. Simulated surgical environments can enhance the data collection process by making it faster, simpler and cheaper than real systems. In addition, combining data from multiple robotic domains can provide rich and diverse training data for transfer learning algorithms. In this paper, we present the DESK (DExterous Surgical SKills) dataset. It comprises a set of surgical robotic skills collected during a surgical training task using three robotic platforms: the Taurus II robot, Taurus II simulated robot, and the YuMi robot. This dataset was used to test the idea of transferring knowledge across different domains (e.g. from Taurus to YuMi robot) for a surgical gesture classification task with seven gestures/surgemes. We explored two different scenarios: 1) No transfer and 2) Domain transfer (simulated Taurus to real Taurus and YuMi robots). We conducted extensive experiments with three supervised learning models and provided baselines in each of these scenarios. Results show that using simulation data during training enhances the performance on the real robots, where limited real data is available. In particular, we obtained an accuracy of 55% on the real Taurus data using a model that is trained only on the simulator data, but that accuracy improved to 82% when the ratio of real to simulated data was increased to 0.18 in the training set.",
        "primary_area": "",
        "author": "Naveen Madapana;Md Masudur Rahman;Natalia Sanchez-Tamayo;Mythra V. Balakuntala;Glebys Gonzalez;Jyothsna Padmakumar Bindu;L. N. Vishnunandan Venkatesh;Xingguang Zhang;Juan Barragan Noguera;Thomas Low;Richard M. Voyles;Yexiang Xue;Juan Wachs;Naveen Madapana;Md Masudur Rahman;Natalia Sanchez-Tamayo;Mythra V. Balakuntala;Glebys Gonzalez;Jyothsna Padmakumar Bindu;L. N. Vishnunandan Venkatesh;Xingguang Zhang;Juan Barragan Noguera;Thomas Low;Richard M. Voyles;Yexiang Xue;Juan Wachs",
        "authorids": "/37085639904;/37085473999;/37086940865;/37087236032;/37087236532;/37087235947;/37088731848;/37088742268;/37088736560;/37532299200;/37283531400;/37086866298;/37327560600;/37085639904;/37085473999;/37086940865;/37087236032;/37087236532;/37087235947;/37088731848;/37088742268;/37088736560;/37532299200;/37283531400;/37086866298;/37327560600",
        "aff": "School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; SRI International; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967760/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10530496601456712329&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "Purdue University;SRI International",
        "aff_unique_dep": "School of Industrial Engineering;",
        "aff_unique_url": "https://www.purdue.edu;https://www.sri.com",
        "aff_unique_abbr": "Purdue;SRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "West Lafayette;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967839",
        "title": "DISC: A Large-scale Virtual Dataset for Simulating Disaster Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the first large-scale synthetic dataset for visual perception in disaster scenarios, and analyze state-of-the-art methods for multiple computer vision tasks with reference baselines. We simulated before and after disaster scenarios such as fire and building collapse for fifteen different locations in realistic virtual worlds. The dataset consists of more than 300K high-resolution stereo image pairs, all annotated with ground-truth data for semantic segmentation, depth, optical flow, surface normal estimation and camera pose estimation. To create realistic disaster scenes, we manually augmented the effects with 3D models using physical-based graphics tools. We use our dataset to train state-of-the-art methods and evaluate how well these methods can recognize the disaster situations and produce reliable results on virtual scenes as well as real-world images. The results obtained from each task are then used as inputs to the proposed visual odometry network for generating 3D maps of buildings on fire. Finally, we discuss challenges for future research.",
        "primary_area": "",
        "author": "Hae-Gon Jeon;Sunghoon Im;Byeong-Uk Lee;Dong-Geol Choi;Martial Hebert;In So Kweon;Hae-Gon Jeon;Sunghoon Im;Byeong-Uk Lee;Dong-Geol Choi;Martial Hebert;In So Kweon",
        "authorids": "/37085431469;/37085624852;/37086937392;/38542186000;/37271437400;/37270474800;/37085431469;/37085624852;/37086937392;/38542186000;/37271437400;/37270474800",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics and Computer Vision Lab., KAIST, Daejeon, Republic of Korea; The Robotics and Computer Vision Lab., KAIST, Daejeon, Republic of Korea; Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics and Computer Vision Lab., KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967839/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10218233017202953270&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;1",
        "aff_unique_norm": "Carnegie Mellon University;KAIST;Hanbat National University",
        "aff_unique_dep": "The Robotics Institute;The Robotics and Computer Vision Lab.;Department of Information and Communication Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.kaist.ac.kr;http://www.hanbat.ac.kr",
        "aff_unique_abbr": "CMU;KAIST;HNU",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "Pittsburgh;Daejeon",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "8967921",
        "title": "DISCOMAN: Dataset of Indoor SCenes for Odometry, Mapping And Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel dataset for training and benchmarking semantic SLAM methods. The dataset consists of 200 long sequences, each one containing 3000-5000 data frames. We generate the sequences using realistic home layouts. For that we sample trajectories that simulate motions of a simple home robot, and then render the frames along the trajectories. Each data frame contains a) RGB images generated using physically-based rendering, b) simulated depth measurements, c) simulated IMU readings and d) ground truth occupancy grid of a house. Our dataset serves a wider range of purposes compared to existing datasets and is the first large-scale benchmark focused on the mapping component of SLAM. The dataset is split into train/validation/test parts sampled from different sets of virtual houses. We present benchmarking results for both classical geometry-based [1], [2] and recent learning-based [3] SLAM algorithms, a baseline mapping method [4], semantic segmentation [5] and panoptic segmentation [6]. The dataset and source code for reproducing our experiments will be publicly available at the time of publication.",
        "primary_area": "",
        "author": "Pavel Kirsanov;Airat Gaskarov;Filipp Konokhov;Konstantin Sofiiuk;Anna Vorontsova;Igor Slinko;Dmitry Zhukov;Sergey Bykov;Olga Barinova;Anton Konushin;Pavel Kirsanov;Airat Gaskarov;Filipp Konokhov;Konstantin Sofiiuk;Anna Vorontsova;Igor Slinko;Dmitry Zhukov;Sergey Bykov;Olga Barinova;Anton Konushin",
        "authorids": "/37087323666;/37088825915;/37088824924;/37087323964;/37086880204;/37088824753;/37085806100;/37085394224;/37398706600;/38306221200;/37087323666;/37088825915;/37088824924;/37087323964;/37086880204;/37088824753;/37085806100;/37085394224;/37398706600;/38306221200",
        "aff": "Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967921/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8732399158439206886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/careers/ai-center/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967891",
        "title": "DISR: Deep Infrared Spectral Restoration Algorithm for Robot Sensing and Intelligent Visual Tracking Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Infrared imaging spectrometer (IRIS) often suffers from overlapped bands and random noises, which limit the precision of subsequent processing in robot vision sensing. To address this problem, we propose a novel Gabor transform-based infrared spectrum restoration method by successfully exploring the intrinsic structure of the clean IR spectrum from the degraded one. At first, a total variation (TV) regularized Gabor coefficients adjustment descriptor is designed and incorporated into the spectrum restoration model. Then, the proposed model is inferred via an efficient optimization approach based on split Bregman iteration method. Comprehensive experiments illustrate the significant and consistent improvements of the developed model over state-of-the-art approaches. The restored high-resolution spectrum can be utilized for detecting the different materials in the robot visual tracking systems.",
        "primary_area": "",
        "author": "Hai Liu;You-Fu Li;Dan Su;Zhaoli Zhang;Sannyuya Liu;Tingting Liu;Hai Liu;You-Fu Li;Dan Su;Zhaoli Zhang;Sannyuya Liu;Tingting Liu",
        "authorids": "/37085682440;/37279884400;/37086117273;/37085691850;/37086233798;/37085692765;/37085682440;/37279884400;/37086117273;/37085691850;/37086233798;/37085692765",
        "aff": "National Engineering Research Center for E-Learning, Central China Normal University, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong; National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China; National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China; National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967891/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8949481183173394856&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;0",
        "aff_unique_norm": "Central China Normal University;City University of Hong Kong",
        "aff_unique_dep": "National Engineering Research Center for E-Learning;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.ccnu.edu.cn;https://www.cityu.edu.hk",
        "aff_unique_abbr": "CCNU;CityU",
        "aff_campus_unique_index": "1;1;2;2;2",
        "aff_campus_unique": ";Hong Kong SAR;Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968062",
        "title": "DLD: A Deep Learning Based Line Descriptor for Line Feature Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an appearance based line descriptor which was developed with the help of machine learning. Our descriptor uses a ResNet which we modified in its size to improve the performance. We utilized the Unreal Engine and multiple scenes provided for it to create training data. The training was performed using a triplet loss, where the loss of the network is calculated with triplets each consisting of three lines including a matching pair and another non-matching line. During learning, the goal of the minimization function is to calculate descriptors with minimal descriptor distance to matching lines' descriptors and maximal descriptor distance to other lines' descriptors. We evaluate the performance of our descriptor on our synthetic datasets, on real-world stereo images from the Middlebury Stereo Dataset and on a benchmark for line segment matching. The results show that in comparison to state-of-the-art line descriptors our method achieves a greatly improved line matching accuracy.",
        "primary_area": "",
        "author": "Manuel Lange;Fabian Schweinfurth;Andreas Schilling;Manuel Lange;Fabian Schweinfurth;Andreas Schilling",
        "authorids": "/37086173327;/37087324264;/37321436400;/37086173327;/37087324264;/37321436400",
        "aff": "Manuel Lange; Fabian Schweinfurth; Andreas Schilling",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968062/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10623590786430359898&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8967855",
        "title": "Data Association Aware Semantic Mapping and Localization via a Viewpoint-Dependent Classifier Model",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach for localization and semantic mapping in ambiguous scenarios by incrementally maintaining a hybrid belief over continuous states and discrete classification and data association variables. Unlike existing incremental approaches, we explicitly maintain data association components over time, which allows us to deal with perceptual aliasing. Crucially, we utilize a viewpoint-dependent classifier model over rich classifier outputs and leverage the coupling between poses and semantic measurements both for disambiguating data association and in pose estimation. We demonstrate in simulation that incorporating semantic measurements with a viewpoint-dependent classifier model enhances disambiguation of both data association and localization over usage of only geometric measurements or viewpoint independent models, further contributing to the tractability of the approach in practice, and providing better estimates.",
        "primary_area": "",
        "author": "Vladimir Tchuiev;Yuri Feldman;Vadim Indelman;Vladimir Tchuiev;Yuri Feldman;Vadim Indelman",
        "authorids": "/37086447716;/37086454791;/37541538000;/37086447716;/37086454791;/37541538000",
        "aff": "Department of Aerospace Engineering, Technion - Israel Institute of Technology; Department of Computer Science, Technion - Israel Institute of Technology, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967855/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2691962885928527363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "8967814",
        "title": "Data Flow ORB-SLAM for Real-time Performance on Embedded GPU Boards",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of embedded boards on robots, including unmanned aerial and ground vehicles, is increasing thanks to the availability of GPU equipped low-cost embedded boards in the market. Porting algorithms originally designed for desktop CPUs on those boards is not straightforward due to hardware limitations. In this paper, we present how we modified and customized the open source SLAM algorithm ORB-SLAM2 to run in real-time on the NVIDIA Jetson TX2. We adopted a data flow paradigm to process the images, obtaining an efficient CPU/GPU load distribution that results in a processing speed of about 30 frames per second. Quantitative experimental results on four different sequences of the KITTI datasets demonstrate the effectiveness of the proposed approach. The source code of our data flow ORB-SLAM2 algorithm is publicly available on GitHub.",
        "primary_area": "",
        "author": "Stefano Aldegheri;Nicola Bombieri;Domenico D. Bloisi;Alessandro Farinelli;Stefano Aldegheri;Nicola Bombieri;Domenico D. Bloisi;Alessandro Farinelli",
        "authorids": "/37086310565;/37273824500;/38111727700;/37266396700;/37086310565;/37273824500;/38111727700;/37266396700",
        "aff": "Department of Computer Science, University of Verona, Strada le Grazie 15 - 37134 Verona, Italy; Department of Computer Science, University of Verona, Strada le Grazie 15 - 37134 Verona, Italy; Department of Mathematics, Computer Science, and Economics, University of Basilicata, Viale dell\u2019Ateneo Lucano, 10 - 85100 Potenza, Italy; Department of Computer Science, University of Verona, Strada le Grazie 15 - 37134 Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967814/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4183805602354825660&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Verona;University of Basilicata",
        "aff_unique_dep": "Department of Computer Science;Department of Mathematics, Computer Science, and Economics",
        "aff_unique_url": "https://www.univr.it;https://www.unibas.it",
        "aff_unique_abbr": "UniVR;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Verona;Potenza",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967810",
        "title": "Decentralized Control for 3D M-Blocks for Path Following, Line Formation, and Light Gradient Aggregation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a decentralized control frame-work for lattice-based Modular Self-Reconfigurable Robots (MSRR) which utilizes a novel magnetic fiducial system to facilitate neighbor identification and to enable algorithms which promise scalable functionality for systems with many modules. In this system individual modules autonomously follow simple behaviors while periodically accepting input from a centralized controller. This system is demonstrated with three initial behaviors: (1) Path following: modules follow a three dimensional path based on magnetic fiducial tags embedded in their neighbors, (2) Line formation: modules transform from a 3D structure into a line following a partially decentralized control algorithm, and (3) Light gradient aggregation: the formation of a group of modules guided by a global stimulus (i.e. visible light). This paper provides details of the neighbor identification system, introduces the three behaviors and presents the results of physical experiments performed with a system of twelve 3D M-Block robotic modules.",
        "primary_area": "",
        "author": "John W. Romanishin;John Mamish;Daniela Rus;John W. Romanishin;John Mamish;Daniela Rus",
        "authorids": "/37077931000;/37087322049;/37279652300;/37077931000;/37087322049;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA; Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA; Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967810/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10989389827780487811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967619",
        "title": "Decentralized Coordination Mechanism between Neck and Limbs for Efficient Quadrupedal Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "An optional robotic arm unit, like animals' neck, allows quadruped robot to achieve multifunctional tasks such as manipulation and patrol. However, increases in body weight due to the neck unit will make energetic issues in legged robots' locomotion more serious. This study presents a minimal decentralized coordination mechanism between a neck and limbs, especially focusing on quadruped mammals' nodding behaviors for efficient walking. The results of two dimensional (2D) simulation suggest that bilateral sensory feedback mechanism between neck and limbs plays essential roles for the quadruped robot to coordinate neck and limbs in response to the physical situation of the body parts, achieving efficient quadrupedal walking.",
        "primary_area": "",
        "author": "Akira Fukuhara;Shura Suzuki;Takeshi Kano;Akio Ishiguro;Akira Fukuhara;Shura Suzuki;Takeshi Kano;Akio Ishiguro",
        "authorids": "/37086249383;/37086261019;/37603654600;/37275189900;/37086249383;/37086261019;/37603654600;/37275189900",
        "aff": "Research Institute of Electrical Communication, Tohoku University, Aoba-ku, Sendai, Japan; Research Institute of Electrical Communication, Tohoku University, Aoba-ku, Sendai, Japan; Research Institute of Electrical Communication, Tohoku University, Aoba-ku, Sendai, Japan; Research Institute of Electrical Communication, Tohoku University, Aoba-ku, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967619/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4614253359683729297&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Research Institute of Electrical Communication",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967698",
        "title": "Decentralized Pose Control of Modular Reconfigurable Robots Operating in Liquid Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular reconfigurable robots are touted for their flexibility, as their bodies can assume a wide range of shapes. A particular challenge is to make them move efficiently in 3D without compromising the scalability of the system. This paper proposes decentralized and fully reactive controllers for pose control of 3D modular reconfigurable robots. The robots operate in liquid environments, and move by routing fluid through themselves. Each module uses only two bits of sensory information per face. Additionally, the modules can use up to five bits of information that are exchanged via shared power lines. We prove that robots of convex shape are guaranteed to reach a goal object with a preferred orientation. Using computer simulations of Modular Hydraulic Propulsion robots, all controllers are assessed for different environments, system sizes and noise, and their performances compared against a centralized controller. Given the simplicity of the solutions, modules could be realized at scales below a millimeter-cube, where robots of high spatial resolution could perform accurate movements in 3D liquid environments.",
        "primary_area": "",
        "author": "Jo\u00e3o V. Amorim Marques;Anil \u00d6zdemir;Matthew J. Doyle;Daniela Rus;Roderich Gro\u00df;Jo\u00e3o V. Amorim Marques;Anil \u00d6zdemir;Matthew J. Doyle;Daniela Rus;Roderich Gro\u00df",
        "authorids": "/37087322161;/37086276883;/37085822269;/37279652300;/37086937590;/37087322161;/37086276883;/37085822269;/37279652300;/37086937590",
        "aff": "Department of Automatic Control and Systems Engineering, The University of Sheffield, Mappin St, Sheffield, S1 3JD, UK; Department of Automatic Control and Systems Engineering, The University of Sheffield, Mappin St, Sheffield, S1 3JD, UK; Department of Automatic Control and Systems Engineering, The University of Sheffield, Mappin St, Sheffield, S1 3JD, UK; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, USA; Department of Automatic Control and Systems Engineering, The University of Sheffield, Mappin St, Sheffield, S1 3JD, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967698/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10340303406157250559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Sheffield;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Automatic Control and Systems Engineering;Computer Science and Artificial Intelligence Lab",
        "aff_unique_url": "https://www.sheffield.ac.uk;https://www.mit.edu",
        "aff_unique_abbr": "Sheffield;MIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Sheffield;Cambridge",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8967804",
        "title": "Decentralized Visual-Inertial Localization and Mapping on Mobile Devices for Augmented Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel approach to shared augmented reality (AR) for mobile devices operating in the same area that does not rely on cloud computing. In particular, each user's device processes the visual and inertial data received from its sensors and almost immediately broadcasts a partial feature map of its surroundings. In parallel, every device localizes against the broadcasted maps by employing feature observations to determine its 4-DOF transformation to each of the gravity-aligned maps. By doing so, virtual content placed by any of the users is quickly and accurately displayed in all other users' views. Furthermore, to reduce the effect of inconsistency introduced by relocalizing against incrementally created and updated maps, their transformations w.r.t. the device are modeled as random processes driven by white noise instead of constant, unknown parameters. Lastly, we assess the accuracy of our approach for the case of two users in a room-scale environment against VICON ground-truth.",
        "primary_area": "",
        "author": "Kourosh Sartipi;Ryan C. DuToit;Christopher B. Cobar;Stergios I. Roumeliotis;Kourosh Sartipi;Ryan C. DuToit;Christopher B. Cobar;Stergios I. Roumeliotis",
        "authorids": "/37085803736;/37085805993;/37087321721;/37274078800;/37085803736;/37085805993;/37087321721;/37274078800",
        "aff": "Google, CA; Google, CA; Google, CA; Google, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967804/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1347196009722981366&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967874",
        "title": "Deep Dive into Faces: Pose & Illumination Invariant Multi-Face Emotion Recognition System",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the advancements in humanization of robots is its ability to recognize human emotions. Facial expression plays a key role in identifying human emotions relative to other cues. In this research, an intelligent network capable of real-time emotion recognition from multiple faces using deep learning technique is presented. The proposed network is based on Convolution Neural Network (CNN) in which three blocks of Convolution layers for feature extraction and two blocks of Dense layers for classification are used. The novelty of this method lies in recognizing emotions from multiple faces simultaneously in real time and its invariance to head pose, illumination and age factor. Most of reported work in literature for multiple faces is for frontal face without illumination variation. The proposed emotion recognition system is deployed on Raspberry Pi3 B+ for human robot interaction applications and achieved an average accuracy of 95.8% in real time.",
        "primary_area": "",
        "author": "Suchitra Saxena;Shikha Tripathi;T S B Sudarshan;Suchitra Saxena;Shikha Tripathi;T S B Sudarshan",
        "authorids": "/37087324228;/37978658500;/37429087000;/37087324228;/37978658500;/37429087000",
        "aff": "Faculty of Engineering, PES University, Bangalore, India; Faculty of Engineering, PES University, Bangalore, India; Faculty of Engineering, PES University, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967874/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17485821144676882992&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "PES University",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://pes.edu",
        "aff_unique_abbr": "PESU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968535",
        "title": "Deep Generative Modeling of LiDAR Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Building models capable of generating structured output is a key challenge for AI and robotics. While generative models have been explored on many types of data, little work has been done on synthesizing lidar scans, which play a key role in robot mapping and localization. In this work, we show that one can adapt deep generative models for this task by unravelling lidar scans into a 2D point map. Our approach can generate high quality samples, while simultaneously learning a meaningful latent representation of the data. We demonstrate significant improvements against state-of-the-art point cloud generation methods. Furthermore, we propose a novel data representation that augments the 2D signal with absolute positional information. We show that this helps robustness to noisy and imputed input; the learned model can recover the underlying lidar scan from seemingly uninformative data.",
        "primary_area": "",
        "author": "Lucas Caccia;Herke van Hoof;Aaron Courville;Joelle Pineau;Lucas Caccia;Herke van Hoof;Aaron Courville;Joelle Pineau",
        "authorids": "/37087324814;/37087322569;/37079943300;/37442456400;/37087324814;/37087322569;/37079943300;/37442456400",
        "aff": "MILA, McGill University; MILA, McGill University; MILA, Universit\u00e9 de Montr\u00e9al; MILA, McGill University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968535/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12320836480605130970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "McGill University;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": "MILA;MILA",
        "aff_unique_url": "https://www.mcgill.ca;https://www.umontreal.ca",
        "aff_unique_abbr": "McGill;UdeM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Montreal;Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968225",
        "title": "Deep Imitation Learning for Autonomous Driving in Generic Urban Scenarios with Enhanced Safety",
        "track": "main",
        "status": "Poster",
        "abstract": "The decision and planning system for autonomous driving in urban environments is hard to design. Most current methods manually design the driving policy, which can be expensive to develop and maintain at scale. Instead, with imitation learning we only need to collect data and the computer will learn and improve the driving policy automatically. However, existing imitation learning methods for autonomous driving are hardly performing well for complex urban scenarios. Moreover, the safety is not guaranteed when we use a deep neural network policy. In this paper, we proposed a framework to learn the driving policy in urban scenarios efficiently given offline connected driving data, with a safety controller incorporated to guarantee safety at test time. The experiments show that our method can achieve high performance in realistic simulations of urban driving scenarios.",
        "primary_area": "",
        "author": "Jianyu Chen;Bodi Yuan;Masayoshi Tomizuka;Jianyu Chen;Bodi Yuan;Masayoshi Tomizuka",
        "authorids": "/37086004703;/37086375844;/37281933000;/37086004703;/37086375844;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968225/",
        "gs_citation": 178,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18079295172846642526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968268",
        "title": "Deep Lagrangian Networks for end-to-end learning of energy-based control for under-actuated systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Applying Deep Learning to control has a lot of potential for enabling the intelligent design of robot control laws. Unfortunately common deep learning approaches to control, such as deep reinforcement learning, require an unrealistic amount of interaction with the real system, do not yield any performance guarantees, and do not make good use of extensive insights from control theory. In particular, common black-box approaches - that abandon all insight from control - are not suitable for complex robot systems. We propose a deep control approach as a bridge between the solid theoretical foundations of energy-based control and the flexibility of deep learning. To accomplish this goal, we extend Deep Lagrangian Networks (DeLaN) to not only adhere to Lagrangian Mechanics but also ensure conservation of energy and passivity of the learned representation. This novel extension is embedded within a energy control law to control under-actuated systems. The resulting DeLaN for energy control (DeLaN 4EC) is the first model learning approach using generic function approximation that is capable of learning energy control because existing approaches cannot learn the system energies directly. DeLaN 4EC exhibits excellent real-time control on the physical Furuta pendulum and learns to swing-up the pendulum while the control law using system identification does not.",
        "primary_area": "",
        "author": "Michael Lutter;Kim Listmann;Jan Peters;Michael Lutter;Kim Listmann;Jan Peters",
        "authorids": "/37086598847;/37085688589;/37533077600;/37086598847;/37085688589;/37533077600",
        "aff": "Department of Computer Science, Technische Universit\u2019 Darmstadt, Germany; ABB Corporate Research Center Germany Wallstadter Str. 59, Germany; Department of Computer Science, Technische Universit\u2019 Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968268/",
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15975017982326564072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Technische Universit\u2019 Darmstadt;ABB Corporate Research Center",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://new.abb.com/research",
        "aff_unique_abbr": "TUD;ABB CRC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968052",
        "title": "Deep Learning of Proprioceptive Models for Robotic Force Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotic tasks require fast and accurate force sensing capabilities to ensure adaptive behavior execution. While dedicated force-torque (FT) sensors are a common option, such devices induce extra costs, need additional power supply, and add weight to otherwise light-weight robotic systems. This paper presents a machine learning approach for estimating external forces acting on a robot based on common internal sensors only. In the training phase, a behavior-specific proprioceptive model is learned as compact representation of the expected proprioceptive feedback during task execution. First, the proprioceptive sensors relevant for the given behavior are identified using information-theoretic measures. Then, the proprioceptive model is learned using deep learning techniques. During behavior execution, the proprioceptive model is applied to actual sensor readings for estimation of external forces. Experiments performed with the UR5 robot demonstrate the ability for fast and accurate force estimation even in situations where a dedicated commercial FT sensor is not applicable.",
        "primary_area": "",
        "author": "Erik Berger;Daniel Eger Passos;Steve Grehl;Heni Ben Amor;Bernhard Jung;Erik Berger;Daniel Eger Passos;Steve Grehl;Heni Ben Amor;Bernhard Jung",
        "authorids": "/37085365368;/37087323123;/37085801323;/37293927700;/37289795700;/37085365368;/37087323123;/37085801323;/37293927700;/37289795700",
        "aff": "Digital Enterprise & Digital Services, Siemens AG, Sch\u00fctzenstr. 4-10, Leipzig, Germany; Institute of Computer Science, Technical University Bergakademie Freiberg, Bernhard-von-Cotta-Str. 2, Freiberg, Germany; Institute of Computer Science, Technical University Bergakademie Freiberg, Bernhard-von-Cotta-Str. 2, Freiberg, Germany; School of Computing, Informatics and, Decision Systems Engineering, Arizona State University, 699 S Mill Ave, Tempe, AZ, USA; Institute of Computer Science, Technical University Bergakademie Freiberg, Bernhard-von-Cotta-Str. 2, Freiberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968052/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10520244522967306252&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Siemens AG;Technical University Bergakademie Freiberg;Arizona State University",
        "aff_unique_dep": "Digital Enterprise & Digital Services;Institute of Computer Science;School of Computing, Informatics and Decision Systems Engineering",
        "aff_unique_url": "https://www.siemens.com;https://www.tu-freiberg.de;https://asu.edu",
        "aff_unique_abbr": "Siemens;;ASU",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Freiberg;Tempe",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "8967574",
        "title": "Deep Learning-Based Mutual Detection and Collaborative Localization for Mobile Robot Fleets Using Solely 2D LIDAR Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization for mobile robots in dynamic, large-scale environments is a challenging task, especially when relying solely on odometry and 2D LIDAR data. When operating in fleets, mutual detection and the exchange of localization information can be highly valuable. Detecting and classifying different robot types in a heterogeneous fleet, however, is nontrivial with 2D LIDAR data due to the sparse observation information. In this paper a novel approach for mutual robot detection, classification and relative pose estimation based on a combination of convolutional and ConvLSTM layers is presented in order to solve this issue. The algorithm learns an end-to-end classification and pose estimation of robot shapes using 2D LIDAR information transformed into a grid-map. Subsequently a mixture model representing the probability distribution of the pose measurement for each robot type is extracted out of the heatmap output of the network. The output is then used in a cloud-based collaborative localization system in order to increase the localization of the individual robots. The effectiveness of our approach is demonstrated in both, simulation and real-world experiments. The results of our evaluation show that the classification network is able to achieve a precision of 90% on real-world data with an average position estimation error of 14 cm. Moreover, the collaborative localization system is able to increase the localization accuracy of a robot equipped with low-cost sensors by 63%.",
        "primary_area": "",
        "author": "Robin Dietrich;Stefan D\u00f6rr;Robin Dietrich;Stefan D\u00f6rr",
        "authorids": "/37087321840;/37085991518;/37087321840;/37085991518",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967574/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13377029452509737885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "8967753",
        "title": "Deep Multi-Task Learning for Anomalous Driving Detection Using CAN Bus Scalar Sensor Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Corner cases are the main bottlenecks when applying Artificial Intelligence (AI) systems to safety-critical applications. An AI system should be intelligent enough to detect such situations so that system developers can prepare for subsequent planning. In this paper, we propose semi-supervised anomaly detection considering the imbalance of normal situations: In particular, driving data consists of multiple normal situations (e.g., right turn, going straight), some of which (e.g., U-turn) could be as rare as anomalous ones. Existing machine learning based anomaly detection approaches do not fare sufficiently well when applied to such imbalanced data. In this paper, we present a novel multi-task learning (LSTM autoencoder and predictor) based approach that leverages domain-knowledge (maneuver labels) for anomaly detection in driving data. We evaluate the proposed approach both quantitatively and qualitatively on 150 hours of real-world driving data and show improved performance over baseline/existing approaches.",
        "primary_area": "",
        "author": "Vidyasagar Sadhu;Teruhisa Misu;Dario Pompili;Vidyasagar Sadhu;Teruhisa Misu;Dario Pompili",
        "authorids": "/37085829505;/37085998814;/37269715300;/37085829505;/37085998814;/37269715300",
        "aff": "Department of ECE, Rutgers University-New Brunswick, NJ; Honda Research Institute, Mountain View, CA; Department of ECE, Rutgers University-New Brunswick, NJ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967753/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7778572661637498359&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Rutgers University;Honda Research Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.rutgers.edu;https://honda-ri.com",
        "aff_unique_abbr": "Rutgers;HRI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "New Brunswick;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968532",
        "title": "Deep Neural Network Approach in Electrical Impedance Tomography-based Real-time Soft Tactile Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a whole-body tactile sensing have emerged in robotics for safe human-robot interaction. A key issue in the whole-body tactile sensing is ensuring large-area manufacturability and high durability. To fulfill these requirements, a reconstruction method called electrical impedance tomography (EIT) was adopted in large-area tactile sensing. This method maps voltage measurements to conductivity distribution using only a few number of measurement electrodes. A common approach for the mapping is using a linearized model derived from the Maxwell's equation. This linearized model shows fast computation time and moderate robustness against measurement noise but reconstruction accuracy is limited. In this paper, we propose a novel nonlinear EIT algorithm through Deep Neural Network (DNN) approach to improve the reconstruction accuracy of EIT-based tactile sensors. The neural network architecture with rectified linear unit (ReLU) function ensured extremely low computational time (0.002 seconds) and nonlinear network structure which provides superior measurement accuracy. The DNN model was trained with dataset synthesized in simulation environment. To achieve the robustness against measurement noise, the training proceeded with additive Gaussian noise that estimated through actual measurement noise. For real sensor application, the trained DNN model was transferred to a conductive fabric-based soft tactile sensor. For validation, the reconstruction error and noise robustness were mainly compared using conventional linearized model and proposed approach in simulation environment. As a demonstration, the tactile sensor equipped with the trained DNN model is presented for a contact force estimation.",
        "primary_area": "",
        "author": "Hyunkyu Park;Hyosang Lee;Kyungseo Park;Sangwoo Mo;Jung Kim;Hyunkyu Park;Hyosang Lee;Kyungseo Park;Sangwoo Mo;Jung Kim",
        "authorids": "/37086495963;/37599331300;/37067235600;/37087324052;/37407273800;/37086495963;/37599331300;/37067235600;/37087324052;/37407273800",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Max Planck Institute of Intelligent Systems, Stuttgart, Germany; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968532/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5103804161781315851&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Max Planck Institute of Intelligent Systems",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "KAIST;MPI-IS",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Daejeon;Stuttgart",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "South Korea;Germany"
    },
    {
        "id": "8968195",
        "title": "Deep Neural Network based Visual Inspection with 3D Metric Measurement of Concrete Defects using Wall-climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel metric inspection robot system using a deep neural network to detect and measure surface flaws (i.e., crack and spalling) on concrete structures performed by a wall-climbing robot. The system consists of four modules: robotics data collection module to obtain RGB-D images and IMU measurement, visual-inertial SLAM module to generate pose coupled key-frames with depth information, InspectionNet module to classify each pixel into three classes (back-ground, crack and spalling), and 3D registration and map fusion module to register the flaw patch into registered 3D model overlaid and highlighted with detected flaws for spatial-contextual visualization. The system enables the metric model of each surface flaw patch with pixel-level accuracy and determines its location in 3D space that is significant for structural health assessment and monitoring. The InspectionNet achieves an average accuracy of 87.64% for crack and spalling inspection. We also demonstrate our InspectionNet is robust to view angle, scale and illumination variation. Finally, we design a metric voxel volume map to highlight the flaw in 3D model and provide location and metric information.",
        "primary_area": "",
        "author": "Liang Yang;Bing Li;Guoyong Yang;Yong Chang;Zhaoming Liu;Biao Jiang;Jizhong Xiaol;Liang Yang;Bing Li;Guoyong Yang;Yong Chang;Zhaoming Liu;Biao Jiang;Jizhong Xiaol",
        "authorids": "/37085495533;/37405869400;/37085829548;/37898766900;/37085762118;/37086412441;/37087321846;/37085495533;/37405869400;/37085829548;/37898766900;/37085762118;/37086412441;/37087321846",
        "aff": "The CCNY Robotics Lab, Shenyang Institute of Automation, New York, USA; Department of Automotive Engineering, Clemson University, South Carolina, USA; Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shenyang Institute of Automation; Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shenyang Institute of Automation; Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shenyang Institute of Automation; Department of Natural Sciences, Hostos Community College, New York, NY, USA; The CCNY Robotics Lab, Shenyang Institute of Automation, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968195/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9831164399593713873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;2;3;0",
        "aff_unique_norm": "Shenyang Institute of Automation;Clemson University;Chinese Academy of Sciences;Hostos Community College",
        "aff_unique_dep": "CCNY Robotics Lab;Department of Automotive Engineering;;Department of Natural Sciences",
        "aff_unique_url": ";https://www.clemson.edu;http://www.cas.cn;https://www.hostos.cuny.edu",
        "aff_unique_abbr": ";Clemson;CAS;HCC",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "New York;South Carolina;",
        "aff_country_unique_index": "0;0;1;1;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967708",
        "title": "Deep Predictive Autonomous Driving Using Multi-Agent Joint Trajectory Prediction and Traffic Rules",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving is a challenging problem because the autonomous vehicle must understand complex and dynamic environment. This understanding consists of predicting future behavior of nearby vehicles and recognizing predefined rules. It is observed that not all rules have equivalent values, and the priority of the rules may change depending on the situation or the driver's driving style. In this work, we jointly reason both a future trajectories of vehicles and degree of satisfaction of each rule in the deep learning framework. Joint reasoning allows modeling interactions between vehicles, and leads to better prediction results. A rule is represented as a signal temporal logic (STL) formula, and a robustness slackness, a margin to the satisfaction of the rule, is predicted for the both autonomous and other vehicle, in addition to future trajectories. Learned robustness slackness decides which rule should be prioritized for the given situation for the autonomous vehicle, and filter out non-valid predicted trajectories for surrounding vehicles. The predicted information from the deep learning framework is used in model predictive control (MPC), which allows the autonomous vehicle navigate efficiently and safely. We test the feasibility of our approach in publicly available NGSIM datasets. Proposed method shows a driving style similar to the human one and considers the safety related to the rules through the future prediction of the surrounding vehicles.",
        "primary_area": "",
        "author": "Kyunghoon Cho;Timothy Ha;Gunmin Lee;Songhwai Oh;Kyunghoon Cho;Timothy Ha;Gunmin Lee;Songhwai Oh",
        "authorids": "/37086074089;/37086455599;/37087323658;/37068116900;/37086074089;/37086455599;/37087323658;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967708/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17598694461096043259&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967899",
        "title": "Deep Reinforcement Learning for Robotic Pushing and Picking in Cluttered Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel robotic grasping system is established to automatically pick up objects in cluttered scenes. A composite robotic hand composed of a suction cup and a gripper is designed for grasping the object stably. The suction cup is used for lifting the object from the clutter first and the gripper for grasping the object accordingly. We utilize the affordance map to provide pixel-wise lifting point candidates for the suction cup. To obtain a good affordance map, the active exploration mechanism is introduced to the system. An effective metric is designed to calculate the reward for the current affordance map, and a deep Q-Network (DQN) is employed to guide the robotic hand to actively explore the environment until the generated affordance map is suitable for grasping. Experimental results have demonstrated that the proposed robotic grasping system is able to greatly increase the success rate of the robotic grasping in cluttered scenes.",
        "primary_area": "",
        "author": "Yuhong Deng;Xiaofeng Guo;Yixuan Wei;Kai Lu;Bin Fang;Di Guo;Huaping Liu;Fuchun Sun;Yuhong Deng;Xiaofeng Guo;Yixuan Wei;Kai Lu;Bin Fang;Di Guo;Huaping Liu;Fuchun Sun",
        "authorids": "/37087323947;/37677003800;/37089316414;/37087323042;/37089577630;/37085360957;/37310126400;/37279269000;/37087323947;/37677003800;/37089316414;/37087323042;/37089577630;/37085360957;/37310126400;/37279269000",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967899/",
        "gs_citation": 103,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6862550490276630947&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967803",
        "title": "Deep Sensor Fusion for Real-Time Odometry Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cameras and 2D laser scanners, in combination, are able to provide low-cost, light-weight and accurate solutions, which make their fusion well-suited for many robot navigation tasks. However, correct data fusion depends on precise calibration of the rigid body transform between the sensors. In this paper we present the first framework that makes use of Convolutional Neural Networks (CNNs) for odometry estimation fusing 2D laser scanners and mono-cameras. The use of CNNs provides the tools to not only extract the features from the two sensors, but also to fuse and match them without needing a calibration between the sensors. We transform the odometry estimation into an ordinal classification problem in order to find accurate rotation and translation values between consecutive frames. Results on a real road dataset show that the fusion network runs in real-time and is able to improve the odometry estimation of a single sensor alone by learning how to fuse two different types of data information.",
        "primary_area": "",
        "author": "Michelle Valente;Cyril Joly;Atnaud de La Fortelle;Michelle Valente;Cyril Joly;Atnaud de La Fortelle",
        "authorids": "/37086558816;/37410404000;/37087324833;/37086558816;/37410404000;/37087324833",
        "aff": "Center for Robotics, MINES ParisTech, PSL Research University, 60 boulevard Saint Michel, Paris, France; Center for Robotics, MINES ParisTech, PSL Research University, 60 boulevard Saint Michel, Paris, France; Center for Robotics, MINES ParisTech, PSL Research University, 60 boulevard Saint Michel, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967803/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5105581353608995289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "MINES ParisTech",
        "aff_unique_dep": "Center for Robotics",
        "aff_unique_url": "https://www.mines-paristech.fr",
        "aff_unique_abbr": "MINES ParisTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968599",
        "title": "Deep Supervised Hashing with Similar Hierarchy for Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition as one of the most significant requirements for long-term simultaneous localization and mapping (SLAM) has been developed rapidly in recent years. Also, deep learning is proved to be more capable than traditional methods to extract features under some complex environments. However, in real-world environments, there are many challenging problems such as viewpoint changes and illumination changes. The existing deep learning-based place recognition in extracting feature phases and matching process is both time-consuming. Moreover, features extracted from convolution neural network (CNN) are floating-point type with high dimension. In this paper, we propose deep supervised hashing for place recognition, where we design a similar hierarchy loss function to learn a model. The model can distinguish the similar images more accurately which is well suitable to place recognition. Besides the model can learn high quality hash codes by maximizing the likelihood of triplet labels. Experiments on several benchmark datasets for place recognition show that our approach is robust to viewpoints, illuminations and season changes with high accuracy. Furthermore, the trained model can extract features and match in real time on CPU with less memory consumption.",
        "primary_area": "",
        "author": "Lang Wu;Yihong Wu;Lang Wu;Yihong Wu",
        "authorids": "/37087322722;/37337262300;/37087322722;/37337262300",
        "aff": "National Laboratory of Pattern Recognition, School of Software & Microelectronics of Peking University, Institute of Automation, Chinese Academy of Sciences, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968599/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16388450784838595254&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Peking University;Chinese Academy of Sciences;University of Chinese Academy of Sciences",
        "aff_unique_dep": "School of Software & Microelectronics;Institute of Automation;",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.ia.cas.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "PKU;CAS;UCAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968506",
        "title": "Deep orientation: Fast and Robust Upper Body orientation Estimation for Mobile Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "An essential feature for navigating socially with a mobile robot is the upper body orientation of persons in its vicinity. For example, in a supermarket orientation indicates whether a person is looking at goods on the shelves or where a person is likely to go. However, given limited computing and battery capabilities, it is not possible to rely on high-performance graphics cards to run large, computationally expensive deep neural networks for orientation estimation in real time. Nevertheless, deep learning performs quite well for regression problems. Therefore, we tackle the problem of upper body orientation estimation with small yet efficient deep neural networks on a mobile robot in this paper. We employ a fast person detection approach as preprocessing that outputs fixed size person images before the actual estimation of the orientation is done. The combination with lightweight networks allows us to estimate a continuous angle in real time, even using a CPU only. We experimentally evaluate the performance of our system on a new, self-recorded data set consisting of more than 100,000 RGB-D samples from 37 persons, which is made publicly available. We also do an extensive comparison of different network architectures and output encodings for their applicability in estimating orientations. Furthermore, we show that depth images are more suitable for the task of orientation estimation than RGB images or the combination of both.",
        "primary_area": "",
        "author": "Benjamin Lewandowski;Daniel Seichter;Tim Wengefeld;Lennard Pfennig;Helge Drumm;Horst-Michael Gross;Benjamin Lewandowski;Daniel Seichter;Tim Wengefeld;Lennard Pfennig;Helge Drumm;Horst-Michael Gross",
        "authorids": "/37086317277;/37085814238;/37085449849;/37087049337;/38223375500;/37270612700;/37086317277;/37085814238;/37085449849;/37087049337;/38223375500;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab and University Computer Center, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968506/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7987044322202382042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968236",
        "title": "DeepControl: Energy-Efficient Control of a Quadrotor using a Deep Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthesis of a feedback controller for nonlinear dynamical systems like a quadrotor requires to deal with the trade-off between performance and online computation requirement of the controller. Model predictive controllers (MPC) provide excellent control performance, but at the cost of high online computation. In this paper, we present our experience in approximating the behavior of an MPC for a quadrotor with a feed-forward neural network. To facilitate the collection of training data, we create a faithful model of the quadrotor and use Gazebo simulator to collect sufficient training data. The deep neural network (DNN) controller learned from the training data has been tested on various trajectories to compare its performance with a model-predictive controller. Our experimental results show that our DNN controller can provide almost similar trajectory tracking performance at a lower control computation cost, which helps in increasing the flight time of the quadrotor. Moreover, the hardware requirement for our DNN controller is significantly less than that for the MPC controller. Thus, the use of DNN based controller also helps in reducing the overall price of a quadrotor.",
        "primary_area": "",
        "author": "Pratyush Varshney;Gajendra Nagar;Indranil Saha;Pratyush Varshney;Gajendra Nagar;Indranil Saha",
        "authorids": "/37087324847;/37087321717;/37542496500;/37087324847;/37087321717;/37542496500",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology, Kanpur, India; Department of Aerospace Engineering, Indian Institute of Technology, Kanpur, India; Department of Computer Science and Engineering, Indian Institute of Technology, Kanpur, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968236/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5233295465008752066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8967767",
        "title": "DeepLocNet: Deep Observation Classification and Ranging Bias Regression for Radio Positioning Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "WiFi technology has been used pervasively in fine-grained indoor localization, gesture recognition, and adaptive communication. Achieving better performance in these tasks generally boils down to differentiating Line-Of-Sight (LOS) from Non-Line-Of-Sight (NLOS) signal propagation reliably which generally requires expensive/specialized hardware due to the complex nature of indoor environments. Hence, the development of low-cost accurate positioning systems that exploit available infrastructure is not entirely solved. In this paper, we develop a framework for indoor localization and tracking of ubiquitous mobile devices such as smartphones using on-board sensors. We present a novel deep LOS/NLOS classifier which uses the Received Signal Strength Indicator (RSSI), and can classify the input signal with an accuracy of 85%. The proposed algorithm can globally localize and track a smartphone (or robot) with a priori unknown location, and with a semi-accurate prior map (error within 0.8m) of the WiFi Access Points (AP). Through simultaneously solving for the trajectory and the map of access points, we recover a trajectory of the device and corrected locations for the access points. Experimental evaluations of the framework show that localization accuracy is increased by using the trained deep network; furthermore, the system becomes robust to any error in the map of APs.",
        "primary_area": "",
        "author": "Sahib Singh Dhanjal;Maani Ghaffari;Ryan M. Eustice;Sahib Singh Dhanjal;Maani Ghaffari;Ryan M. Eustice",
        "authorids": "/37085811153;/37087056400;/37283587600;/37085811153;/37087056400;/37283587600",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967767/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7312338753096250136&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967756",
        "title": "DeepPCO: End-to-End Point Cloud Odometry through Deep Parallel Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Odometry is of key importance for localization in the absence of a map. There is considerable work in the area of visual odometry (VO), and recent advances in deep learning have brought novel approaches to VO, which directly learn salient features from raw images. These learning-based approaches have led to more accurate and robust VO systems. However, they have not been well applied to point cloud data yet. In this work, we investigate how to exploit deep learning to estimate point cloud odometry (PCO), which may serve as a critical component in point cloud-based downstream tasks or learning-based systems. Specifically, we propose a novel end-to-end deep parallel neural network called DeepPCO, which can estimate the 6-DOF poses using consecutive point clouds. It consists of two parallel sub-networks to estimate 3D translation and orientation respectively rather than a single neural network. We validate our approach on KITTI Visual Odometry/SLAM benchmark dataset with different baselines. Experiments demonstrate that the proposed approach achieves good performance in terms of pose accuracy.",
        "primary_area": "",
        "author": "Wei Wang;Muhamad Risqi U. Saputra;Peijun Zhao;Pedro Gusmao;Bo Yang;Changhao Chen;Andrew Markham;Niki Trigoni;Wei Wang;Muhamad Risqi U. Saputra;Peijun Zhao;Pedro Gusmao;Bo Yang;Changhao Chen;Andrew Markham;Niki Trigoni",
        "authorids": "/37086943823;/37086934305;/37086940063;/37086933895;/37086306785;/37086940474;/37410667900;/37297514400;/37086943823;/37086934305;/37086940063;/37086933895;/37086306785;/37086940474;/37410667900;/37297514400",
        "aff": "Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967756/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2586427859857896631&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968467",
        "title": "DeepVIO: Self-supervised Deep Learning of Monocular Visual Inertial Odometry using 3D Geometric Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an self-supervised deep learning network for monocular visual inertial odometry (named DeepVIO). DeepVIO provides absolute trajectory estimation by directly merging 2D optical flow feature (OFF) and Inertial Measurement Unit (IMU) data. Specifically, it firstly estimates the depth and dense 3D point cloud of each scene by using stereo sequences, and then obtains 3D geometric constraints including 3D optical flow and 6-DoF pose as supervisory signals. Note that such 3D optical flow shows robustness and accuracy to dynamic objects and textureless environments. In DeepVIO training, 2D optical flow network is constrained by the projection of its corresponding 3D optical flow, and LSTM-style IMU preintegration network and the fusion network are learned by minimizing the loss functions from ego-motion constraints. Furthermore, we employ an IMU status update scheme to improve IMU pose estimation through updating the additional gyroscope and accelerometer bias. The experimental results on KITTI and EuRoC datasets show that DeepVIO outperforms state-of-the-art learning based methods in terms of accuracy and data adaptability. Compared to the traditional methods, DeepVIO reduces the impacts of inaccurate Camera-IMU calibrations, unsynchronized and missing data.",
        "primary_area": "",
        "author": "Liming Han;Yimin Lin;Guoguang Du;Shiguo Lian;Liming Han;Yimin Lin;Guoguang Du;Shiguo Lian",
        "authorids": "/37086934485;/37086937458;/37087323137;/37086232924;/37086934485;/37086937458;/37087323137;/37086232924",
        "aff": "AI Department, CloudMinds Technologies Inc, Beijing, China; AI Department, CloudMinds Technologies Inc, Beijing, China; AI Department, CloudMinds Technologies Inc, Beijing, China; AI Department, CloudMinds Technologies Inc, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968467/",
        "gs_citation": 131,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7517937224844918713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "CloudMinds Technologies Inc",
        "aff_unique_dep": "AI Department",
        "aff_unique_url": "https://www.cloudminds.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967912",
        "title": "Degeneracy in Self-Calibration Revisited and a Deep Learning Solution for Uncalibrated SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-calibration of camera intrinsics and radial distortion has a long history of research in the computer vision community. However, it remains rare to see real applications of such techniques to modern Simultaneous Localization And Mapping (SLAM) systems, especially in driving scenarios. In this paper, we revisit the geometric approach to this problem, and provide a theoretical proof that explicitly shows the ambiguity between radial distortion and scene depth when two-view geometry is used to self-calibrate the radial distortion. In view of such geometric degeneracy, we propose a learning approach that trains a convolutional neural network (CNN) on a large amount of synthetic data. We demonstrate the utility of our proposed method by applying it as a checkerboard-free calibration tool for SLAM, achieving comparable or superior performance to previous learning and hand-crafted methods.",
        "primary_area": "",
        "author": "Bingbing Zhuang;Quoc-Huy Tran;Gim Hee Lee;Loong Fah Cheong;Manmohan Chandraker;Bingbing Zhuang;Quoc-Huy Tran;Gim Hee Lee;Loong Fah Cheong;Manmohan Chandraker",
        "authorids": "/37086291246;/37086180008;/37860021400;/37334210200;/37397476800;/37086291246;/37086180008;/37860021400;/37334210200;/37397476800",
        "aff": "National University of Singapore; NEC Laboratories America, Inc.; National University of Singapore; National University of Singapore; NEC Laboratories America, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967912/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=568808962328453511&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "National University of Singapore;NEC Laboratories America",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.nec-labs.com",
        "aff_unique_abbr": "NUS;NEC Labs America",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8968577",
        "title": "Degeneracy-Aware Factors with Applications to Underwater SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is commonly formulated as an optimization over a graph. A popular approach is the pose graph, which seeks to solve for robots poses that are constrained by pose-to-pose measurements, such as odometry measurements or loop closures. For range sensors, these pose-to-pose constraints can be achieved by performing scan matching techniques, such as Iterative Closest Point (ICP). However, in environments with insufficient or degenerate geometric features, the ICP solution can be unreliable and lead to significant drift in the trajectory of the graph optimization solution. In this paper, we propose a degeneracy-aware approach which has two stages: (1) a degeneracy-aware ICP algorithm and (2) a partially constrained loop closure factor to incorporate the results from (1) into the SLAM pose graph optimization. Our approach performs updates and optimizes both ICP and the pose graph in only the well constrained directions of the state space. These directions are selected on the basis of a dynamic threshold, which updates at each iteration. We apply the proposed algorithm to autonomous underwater mapping with sonar. To evaluate the performance of this algorithm, we conduct experiments in both simulation and real world scenarios, and show the method's robustness to navigational drift and ability to reject poor loop closures in degenerate environments, which would otherwise degrade the accuracy of the trajectory and the quality of the resulting map.",
        "primary_area": "",
        "author": "Akshay Hinduja;Bing-Jui Ho;Michael Kaess;Akshay Hinduja;Bing-Jui Ho;Michael Kaess",
        "authorids": "/37086454167;/37086574547;/37324200400;/37086454167;/37086574547;/37324200400",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Aptiv AMoD, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968577/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13086912498648575555&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Aptiv",
        "aff_unique_dep": "Department of Mechanical Engineering;Aptiv AMoD",
        "aff_unique_url": "https://www.cmu.edu;https://www.aptiv.com",
        "aff_unique_abbr": "CMU;Aptiv",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968576",
        "title": "Delivering Cognitive Behavioral Therapy Using A Conversational Social Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Social robots are becoming an integrated part of our daily life due to their ability to provide companionship and entertainment. A subfield of robotics, Socially Assistive Robotics (SAR), is particularly suitable for expanding these benefits into the healthcare setting because of its unique ability to provide cognitive, social, and emotional support. This paper presents our recent research on developing SAR by evaluating the ability of a life-like conversational social robot, called Ryan, to administer internet-delivered cognitive behavioral therapy (iCBT) to older adults with depression. For Ryan to administer the therapy, we developed a dialogue-management system, called Program-R. Using an accredited CBT manual for the treatment of depression, we created seven hour-long iCBT dialogues and integrated them into Program-R using Artificial Intelligence Markup Language (AIML). To assess the effectiveness of Robot-based iCBT and users' likability of our approach, we conducted an HRI study with a cohort of elderly people with mild-to-moderate depression over a period of four weeks. Quantitative analyses of participant's spoken responses (e.g. word count and sentiment analysis), face-scale mood scores, and exit surveys, strongly support the notion robot-based iCBT is a viable alternative to traditional human-delivered therapy.",
        "primary_area": "",
        "author": "Francesca Dino;Rohola Zandie;Hojjat Abdollahi;Sarah Schoeder;Mohammad H. Mahoor;Francesca Dino;Rohola Zandie;Hojjat Abdollahi;Sarah Schoeder;Mohammad H. Mahoor",
        "authorids": "/37087322453;/37087322600;/37086100485;/37087322011;/37300477500;/37087322453;/37087322600;/37086100485;/37087322011;/37300477500",
        "aff": "Department of Psychology, University of Denver; Department of Electrical and Computer Engineering, University of Denver, Colorado, USA; Department of Electrical and Computer Engineering, University of Denver, Colorado, USA; Eaton Senior Community, Lakewood, CO; Department of Electrical and Computer Engineering, University of Denver, Colorado, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968576/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11972526989881331662&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Denver;Eaton Senior Community",
        "aff_unique_dep": "Department of Psychology;",
        "aff_unique_url": "https://www.du.edu;",
        "aff_unique_abbr": "DU;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Denver",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967610",
        "title": "Dempster Shafer Grid-based Hybrid Fusion of Virtual Lanes for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Lane estimation plays a central role in the context of self-driving vehicles, requiring clear road markings and a high quality infrastructure. To meet the safety requirements and manage difficult use cases (i.e. poor quality or absence of road- marking, traffic jams, severe weather conditions, etc.) without depending on cartography and lane markings, we propose a lidar-based Virtual Lanes (VL) generation system to provide a comfortable and safe ride. For this purpose, hybrid fusion based on Dempster-Shafer Theory (DST) coupled with a particle filter is introduced. Two VL strategies are merged: the first constructs virtual lanes based on independent road-borders detection, while the second uses moving objects trajectories. A novel lane similarity computation is also adopted in order to estimate an effective lane comparison. The performance is reported through extensive experiments with Valeo demo-car on highway and beltway roads. Experimental results demonstrate the accurate and robust performance of the proposed system.",
        "primary_area": "",
        "author": "Ferit Uzer;Rachid Benmokhtar;Salma Moujtahid;Xavier Perrotton;Ferit Uzer;Rachid Benmokhtar;Salma Moujtahid;Xavier Perrotton",
        "authorids": "/37086682867;/37321628900;/37085642762;/37395168300;/37086682867;/37321628900;/37085642762;/37395168300",
        "aff": "Valeo Vision - Driving Assistance Research (DAR), France; Valeo Vision - Driving Assistance Research (DAR), France; Valeo Vision - Driving Assistance Research (DAR), France; Valeo Vision - Driving Assistance Research (DAR), France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967610/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16131478707093734175&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Valeo Vision",
        "aff_unique_dep": "Driving Assistance Research (DAR)",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967577",
        "title": "Dense 3D Reconstruction for Visual Tunnel Inspection using Unmanned Aerial Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Advances in Unmanned Aerial Vehicle (UAV) opens venues for application such as tunnel inspection. Owing to its versatility to fly inside the tunnels, it can quickly identify defects and potential problems related to safety. However, long tunnels, especially with repetitive or uniform structures pose a significant problem for UAV navigation. Furthermore, post-processing visual data from the camera mounted on the UAV is required to generate useful information for the inspection task. In this work, we design a UAV with a single rotating camera to accomplish the task. Compared to other platforms, our solution can fit the stringent requirement for tunnel inspection, in terms of battery life, size and weight. While the current state-of-the-art can estimate camera pose and 3D geometry from a sequence of images, they assume large overlap, small rotational motion, and many distinct matching points between images. These assumptions severely limit their effectiveness in tunnel-like scenarios where the camera has erratic or large rotational motion, such as the one mounted on the UAV. This paper presents a novel solution which exploits Structure-from-Motion, Bundle Adjustment, and available geometry priors to robustly estimate camera pose and automatically reconstruct a fully-dense 3D scene using the least possible number of images in various challenging tunnel-like environments. We validate our system with both Virtual Reality application and experimentation with a real dataset. The results demonstrate that the proposed reconstruction along with texture mapping allows for remote navigation and inspection of tunnel-like environments, even those which are inaccessible for humans.",
        "primary_area": "",
        "author": "Ramanpreet Singh Pahwa;Kennard Yanting Chan;Jiamin Bai;Vincensius Billy Saputra;Minh N. Do;Shaohui Foong;Ramanpreet Singh Pahwa;Kennard Yanting Chan;Jiamin Bai;Vincensius Billy Saputra;Minh N. Do;Shaohui Foong",
        "authorids": "/37397832200;/37087321976;/37087323513;/37085734838;/37267984500;/37542925800;/37397832200;/37087321976;/37087323513;/37085734838;/37267984500;/37542925800",
        "aff": "Institute for Infocomm Research (I2R), A*STAR, Singapore; Nanyang Technological University (NTU), Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore; University of Illinois at Urbana-Champaign (UIUC), USA; Singapore University of Technology and Design (SUTD), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967577/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8098685761756537970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;3",
        "aff_unique_norm": "Institute for Infocomm Research;Nanyang Technological University;University of Illinois Urbana-Champaign;Singapore University of Technology and Design",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg;https://www.ntu.edu.sg;https://illinois.edu;https://www.sutd.edu.sg",
        "aff_unique_abbr": "I2R;NTU;UIUC;SUTD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8968071",
        "title": "Dense, Sonar-based Reconstruction of Underwater Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Typically, the reconstruction problem is addressed in three independent steps: first, sensor processing techniques are used to filter and segment sensor data as required by the front end. Second, the front end builds the factor graph for the problem to obtain an accurate estimate of the robot\u2019s full trajectory. Finally, the end product is obtained by further processing of sensor data, now re-projected from the optimized trajectory. In this paper we present an approach to model the reconstruction problem in a way that unifies the aforementioned problems under a single framework for a particular application: sonar-based inspection of underwater structures. This is achieved by formulating both the sonar segmentation and point cloud reconstruction problems as factor graphs, in tandem with the SLAM problem. We provide experimental results using data from a ship hull inspection test.",
        "primary_area": "",
        "author": "Pedro V. Teixeira;Dehann Fourie;Michael Kaess;John J. Leonard;Pedro V. Teixeira;Dehann Fourie;Michael Kaess;John J. Leonard",
        "authorids": "/37089939750;/37670490400;/37324200400;/37329387400;/37089939750;/37670490400;/37324200400;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968071/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3303002493740625135&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Robotics Institute",
        "aff_unique_url": "https://www.mit.edu;https://www.cmu.edu",
        "aff_unique_abbr": "MIT;CMU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Cambridge;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968470",
        "title": "DensePeds: Pedestrian Tracking in Dense Crowds Using Front-RVO and Sparse Features",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a pedestrian tracking algorithm, DensePeds, that tracks individuals in highly dense crowds (>2 pedestrians per square meter). Our approach is designed for videos captured from front-facing or elevated cameras. We present a new motion model called Front-RVO (FRVO) for predicting pedestrian movements in dense situations using collision avoidance constraints and combine it with state-of-the-art Mask R-CNN to compute sparse feature vectors that reduce the loss of pedestrian tracks (false negatives). We evaluate DensePeds on the standard MOT benchmarks as well as a new dense crowd dataset. In practice, our approach is 4.5 \u00d7 faster than prior tracking algorithms on the MOT benchmark and we are state-of-the-art in dense crowd videos by over 2.6% on the absolute scale on average.",
        "primary_area": "",
        "author": "Rohan Chandra;Uttaran Bhattacharya;Aniket Bera;Dinesh Manocha;Rohan Chandra;Uttaran Bhattacharya;Aniket Bera;Dinesh Manocha",
        "authorids": "/37086365992;/37087234810;/37085393882;/37267825600;/37086365992;/37087234810;/37085393882;/37267825600",
        "aff": "University of Maryland; University of Maryland; University of North Carolina; University of Maryland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968470/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13216376391078996362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Maryland;University of North Carolina",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www/umd.edu;https://www.unc.edu",
        "aff_unique_abbr": "UMD;UNC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968602",
        "title": "Design and Analysis of a New 3-DOF Active-Type Constant-Force Compliant Parallel Stage",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design, analysis and testing of a novel three-degree-of-freedom (3-DOF) compliant parallel-kinematic active constant-force stage. The active constant-force property enables a large travel and constant driving property, which is enabled by introducing symmetrical bistable flexure hinges. The folded flexure mechanism is adopted to guide the driving input and to balance the stiffness of the stage to zero. In addition, leaf flexure hinges are employed to decouple the cross-axis motion of the 3-DOF parallel stage. Analytical modeling is conducted to evaluate the stage performance. To verify the performance of the constant-force property and motion decoupling, finite-element analysis simulation study is carried out. By minimizing the fluctuation of the constant-force value, design optimization of the stage parameters is implemented with multi-objective genetic algorithm. Moreover, a prototype is fabricated for demonstration of the proposed concept design.",
        "primary_area": "",
        "author": "Xiaozhi Zhang;Qingsong Xu;Yuzhang Wei;Xiaozhi Zhang;Qingsong Xu;Yuzhang Wei",
        "authorids": "/37085378990;/37290823000;/37086169563;/37085378990;/37290823000;/37086169563",
        "aff": "Department of Electromechanical Engineering, University of Macau, Avenida da Universidade, Taipa, China; Department of Electromechanical Engineering, University of Macau, Avenida da Universidade, Taipa, China; Department of Electromechanical Engineering, University of Macau, Avenida da Universidade, Taipa, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968602/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:sfpINgx15lkJ:scholar.google.com/&scioq=Design+and+Analysis+of+a+New+3-DOF+Active-Type+Constant-Force+Compliant+Parallel+Stage&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Macau",
        "aff_unique_dep": "Department of Electromechanical Engineering",
        "aff_unique_url": "https://www.um.edu.mo",
        "aff_unique_abbr": "UMacau",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taipa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967999",
        "title": "Design and Characterization of a Fully Autonomous Under-actuated Soft Batoid-like Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Batoids use their large pectoral fins to achieve unique maneuverability and propulsive performance. In this work, the design, fabrication and characterization a soft batoid-like robot is presented. The robot is designed to mimic un-dulatory rajiform locomotion. The design is under-actuated, simple and robust and well suited for propulsive performance experiments thanks to its full autonomy, long battery life, and wireless recharging capabilities. The robot has a 180mm body length, a maximum flapping amplitude of 60deg, and reaches a peak speed of 0.93 body length per second. In order to characterize its swimming kinematics and propulsive forces a special setup was built using an instrumented holder and high speed video. Experiments were conducted to characterize propulsive force generation with varying fin flapping frequencies (from 1hz to 2. 4hz), amplitudes, and wavelengths. The results show that while both flapping frequency and amplitude influence propulsive forces, for the locomotion modes tested, flapping frequency has a stronger effect on both thrust and side forces. Furthermore, larger side forces than thrust forces are produced for the same swimming parameters.",
        "primary_area": "",
        "author": "T.V. Truong;V.K. Viswanathan;V.S. Joseph;P. Valdivia y Alvarado;T.V. Truong;V.K. Viswanathan;V.S. Joseph;P. Valdivia y Alvarado",
        "authorids": "/37087324738;/37087323093;/37086840438;/38235509800;/37087324738;/37087323093;/37086840438;/38235509800",
        "aff": "SUTD International Design Centre (IDC); SUTD International Design Centre (IDC); SUTD Digital Manufacturing and Design Centre (DManD); SUTD International Design Centre (IDC)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967999/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12586323609285031891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "International Design Centre (IDC)",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8967692",
        "title": "Design and Comparative Analysis of 1D Hopping Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Hopping is a highly dynamic motion requiring precise input over brief moments of ground contact in order to achieve desired performance. While this problem has been approached from multiple perspectives, this work provides a comparative analysis of two robot models. The first model uses an actuator to store energy in a spring and release it during the ground phase, while the second uses an actuator to move an additional mass vertically to generate force on the spring. In the first model, analytic expressions are used to find the desired controllers, while trajectory optimization is used in the latter. Orbital stability of each model under the conditions of uncertain damping and poor estimation of the hop height is examined. To this end, Poincar\u00e9 analysis is used to give a metric of stability in the presence of different initial conditions and parameter uncertainty. Simulations show that the first model converges quickly to a point near the desired height determined by the amount of uncertain damping present. The second model is less robust to uncertainty, but is be made to converge to a desired height with the addition of PD control around the optimal trajectory. This robustness is improved with different gains in the controller. In experiments performed on hardware for the second model, stability is observed through convergence to a periodic orbit within several hops.",
        "primary_area": "",
        "author": "Eric Ambrose;Noel Csomay-Shanklin;Yizhar Or;Aaron Ames;Eric Ambrose;Noel Csomay-Shanklin;Yizhar Or;Aaron Ames",
        "authorids": "/37086010769;/37086862522;/37283242500;/37300877900;/37086010769;/37086862522;/37283242500;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology in Pasadena, CA; Department of Mechanical Engineering, Georgia Institute of Technology in Atlanta, GA; Department of Mechanical Engineering, Technion-Israel Institute of Technology, Haifa, Israel; Department of Mechanical and Civil Engineering, California Institute of Technology in Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967692/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5430067868205403955&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "California Institute of Technology;Georgia Institute of Technology;Technion-Israel Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering;Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.gatech.edu;https://www.technion.ac.il",
        "aff_unique_abbr": "Caltech;Georgia Tech;Technion",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Pasadena;Atlanta;Haifa",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "8967838",
        "title": "Design and Development of Compactly Folding Parallel Open-Close Gripper with Wide Stroke",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel compact parallel gripper with wide stroke is proposed in this paper. Conventional parallel grippers with linear guide mechanisms have been widely utilized as end effectors of robots, especially in industrial fields, because of its simple mechanism and low cost nature. However, the width of the gripper is larger than the stroke due to the mechanical structure of its linear guide mechanism. When objects with various dimensions need to be grasped by a gripper, the width of the gripper is determined by the largest distance between fingers necessary for grasping all of the objects. This makes the collision avoidance of robot difficult even when handling a small object compared to the width of the gripper. The novel compact gripper proposed in this article has three features: long finger stroke with compact dimensions, fingers\u2019 parallel motion along a single linear trajectory, and driven by a single actuator. The finger backlash and the gripping force of the proposed mechanism are analyzed, and the parallel gripper with the mechanism is designed based on the analyses. A prototype gripper with minimum width 64 mm, whose maximum fingers stroke is 121 mm, is developed, and experimental results illustrate the performance of the developed gripper.",
        "primary_area": "",
        "author": "Akinari Kobayashi;Jun Kinugawa;Shogo Arai;Kazuhiro Kosuge;Akinari Kobayashi;Jun Kinugawa;Shogo Arai;Kazuhiro Kosuge",
        "authorids": "/37089939795;/37592334300;/37530262300;/37278595800;/37089939795;/37592334300;/37530262300;/37278595800",
        "aff": "Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Miyagi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967838/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16782791746216655141&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968123",
        "title": "Design and Implementation of a Contact Aerial Manipulator System for Glass-Wall Inspection Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Glass curtain walls have been widely used in modern architecture. This makes it urgent to inspect and clean these glasses at regular intervals. Up to now, most of these work is performed by workers, which is expensive and inefficient. Therefore, a novel robot-the contact aerial manipulator system-is developed. The new designed system presents priorities in the aspects of high flexibility and easy operation. In this paper, the system mechanical structure is first introduced. Subsequently, the hybrid force/motion control framework is utilized to realize the precise and steady motion on the two-dimensional plane and maintain a certain sustained contact force, simultaneously. Finally, two flight experiments (including continuous square-wave trajectory tracking and aerial drawing task) are performed and the results indicate that the developed contact aerial manipulator works and presents good performance.",
        "primary_area": "",
        "author": "Xiangdong Meng;Yuqing He;Jianda Han;Xiangdong Meng;Yuqing He;Jianda Han",
        "authorids": "/37086051641;/37288326300;/37290381900;/37086051641;/37288326300;/37290381900",
        "aff": "State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968123/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14786720152429066063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Chinese Academy of Sciences;Shenyang Institute of Automation, Chinese Academy of Sciences",
        "aff_unique_dep": "State Key Laboratory of Robotics;State Key Laboratory of Robotics",
        "aff_unique_url": "http://www.cas.cn;http://www.sia.cas.cn",
        "aff_unique_abbr": "CAS;SIA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenyang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967600",
        "title": "Design and Take-Off Flight of a Samara-Inspired Revolving-Wing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by a winged seed, which takes advantage of a wing with high angles of attack and its associated leading-edge vortex to boost lift, we propose a powered 13.8gram aerial robot with the maximum take-off weight of 310 mN (31.6 gram) or thrust-to-weight ratio of 2.3. The robot, consisting of two airfoils and two horizontally directed motor-driven propellers, revolves around its vertical axis to hover. To amplify the thrust production while retaining a minimal weight, we develop an optimization framework for the robot and airfoil geometries. The analysis integrates quasi-steady aerodynamic models for the airfoils and the propellers with the motor model. We fabricated the robots according to the optimized design. The prototypes are experimentally tested. The revolving-wing robot produces approximately 50% higher lift compared to conventional multirotor designs. Finally, an uncontrolled hovering flight is presented.",
        "primary_area": "",
        "author": "Songnan Bai;Pakpong Chirarattananon;Songnan Bai;Pakpong Chirarattananon",
        "authorids": "/37086482319;/38364343100;/37086482319;/38364343100",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967600/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10880654119018696719&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968542",
        "title": "Design and Verification of A Portable Master Manipulator Based on an Effective Workspace Analysis Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Master manipulators represent a key component of Robot-Assisted Minimally Invasive Surgery (RAMIS). In this paper, an Analytic Hierarchy Process (AHP) method is used to construct an effective workspace analysis framework, which can assist the configuration selection and design evaluation of a portable master manipulator for surgical robot control and training. The proposed framework is designed based on three criteria: 1) compactness, 2) workspace quality, and 3) mapping efficiency. A hardware prototype, called the Hamlyn Compact Robotic Master (Hamlyn CRM), is constructed following the proposed framework. Experimental verification of the platform is conducted on the da Vinci Research Kit (dVRK) with which a da Vinci robot is controlled as a slave. The proposed Hamlyn CRM is compared with Phantom Omni, a commercial portable master device, with results demonstrating the relative merits of the new platform in terms of task completion time, average control speed and number of clutching.",
        "primary_area": "",
        "author": "Dandan Zhang;Jindong Liu;Lin Zhang;Guang-Zhong Yang;Dandan Zhang;Jindong Liu;Lin Zhang;Guang-Zhong Yang",
        "authorids": "/37086595836;/37879388800;/37085358176;/37276270800;/37086595836;/37879388800;/37085358176;/37276270800",
        "aff": "Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968542/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15060624539312410201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967609",
        "title": "Design of Compact Variable Gravity Compensator (CVGC) Based on Cam and Variable Pivot of a Lever Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new compact variable gravity compensation mechanism (CVGC). The CVGC can be used to generate gravity compensation torque by using the cam and lever mechanism and can also amplify the target gravity compensation torque by varying the pivot point of the lever. The feature of variable gravity compensation is very useful to the mobile platform, which needs to handle unstandardized tasks with a high variation of the workpiece weight. The proposed CVGC has many advantages. Most importantly, it is designed as a compact, independent one-piece structure and is lightweight, meaning it can easily be used as a mobile platform with a simple modification. The CVGC can also have a full range of compensation angle (360\u00b0), so it does not restrict any of the original workspaces of the target platform when it is installed. First, the mechanism concept and details are explained. Next, the mechanics of the prototype for force analysis are presented. Based on these mechanics and cam theory, the methodology of the cam profile design is presented. Finally, the performance of variable gravity compensation is verified through experiments that compare the designed and measured gravity compensation torque. The verification test shows adequate performance, as we had hoped, which shows potential for the development of the CVGC.",
        "primary_area": "",
        "author": "Jehyeok Kim;Junyoung Moon;Jongwon Kim;Giuk Lee;Jehyeok Kim;Junyoung Moon;Jongwon Kim;Giuk Lee",
        "authorids": "/37087322900;/37087322154;/37337246300;/38241158500;/37087322900;/37087322154;/37337246300;/38241158500",
        "aff": "School of Mechanical Engineering, Seoul National University, Seoul, Korea; School of Mechanical Engineering, Chung-Ang University, Seoul, Korea; School of Mechanical Engineering, Seoul National University, Seoul, Korea; School of Mechanical Engineering, Chung-Ang University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967609/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5828548018979344797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Seoul National University;Chung-Ang University",
        "aff_unique_dep": "School of Mechanical Engineering;School of Mechanical Engineering",
        "aff_unique_url": "https://www.snu.ac.kr;http://www.cau.ac.kr",
        "aff_unique_abbr": "SNU;CAU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967701",
        "title": "Design of Low-Profile Compliant Transmission Mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic origami design allows creating meso-scale robotic systems and mechanisms not limited by degrees of freedom, miniaturization and assembly downsides of conventional transmission mechanisms. However, unlike the traditional rigid approaches, robotic origami application has been limited by the complex deformation and kinematics of the compliant joints and actuation based on active materials or conventional electric motors. To generalize their application at meso-scale requires a combination of the predictability of traditional rigid kinematics and the manufacturing flexibility of robotic origami. Here we present a study of conventional transmission mechanisms, including a slider-crank and cam-follower, made in quasi-2D form by selective machining and stacking of multiple layers of composite material with minimal assembly. Owing to a compliant design powered by low-profile piezoelectric motors, our 5.3 mm thick and lightweight mechanisms transmit rotational motion to translational movements in and out-of-plane. We develop analytic models that we validate in terms of force and motion output on our prototypes.",
        "primary_area": "",
        "author": "Frederic H. Giraud;Zhenishbek Zhakypov;Jamie Paik;Frederic H. Giraud;Zhenishbek Zhakypov;Jamie Paik",
        "authorids": "/37266057300;/38667695300;/37085372758;/37266057300;/38667695300;/37085372758",
        "aff": "Frederic H. Giraud; Zhenishbek Zhakypov; Jamie Paik",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967701/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9459615153329291455&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Jamie Paik",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8968034",
        "title": "Design of Robot Leg with Variable Reduction Ratio Crossed Four-bar Linkage Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Generally, large knee joint torque is required when a leg is flexed. However, the large torque motor will increase the robot size and total weight. Also, a large reduction ratio gear box to realize the large torque will decrease output speed and lower backdrivability of the joint. It makes the robot difficult to perform agile and flexible motion like animals. In this paper, we propose a robot leg with a knee joint mechanism consisting of a variable reduction ratio crossed four-bar linkage mechanism (VRRCFLM) based on cruciate ligament of an animal. The VRRCFLM is to increase the reduction ratio for large knee flexion postures without greatly reducing the total backdrivability. In this paper, we developed a robot leg with a knee joint mechanism consisting of the VRRCFLM. In order to design the link parameters of the leg mechanism, optimization design aimed at maximizing the jumping height of the robot was performed. The robot model with the designed mechanism was evaluated through the dynamics simulations. Thanks to the VRRCFLM, the required torque of the knee motor at the large flexion postures was decreased. Moreover, the vertical jumping height was improved by 24.6 % comparing with a model without the mechanism. In experiments using the prototype, the required static torque was decreased as in simulation, and the jumping height was more than one leg length.",
        "primary_area": "",
        "author": "Kohei Tomishiro;Ryuki Sato;Yasuji Harada;Aiguo Ming;Fei Meng;Huaxin Liu;Xuxiao Fan;Xuechao Chen;Zhangguo Yu;Qiang Huang;Kohei Tomishiro;Ryuki Sato;Yasuji Harada;Aiguo Ming;Fei Meng;Huaxin Liu;Xuxiao Fan;Xuechao Chen;Zhangguo Yu;Qiang Huang",
        "authorids": "/37087322923;/37075648800;/37088734081;/37293972500;/38196787600;/38547812200;/37086354396;/37694180400;/37631550600;/37279982900;/37087322923;/37075648800;/37088734081;/37293972500;/38196787600;/38547812200;/37086354396;/37694180400;/37631550600;/37279982900",
        "aff": "Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Laboratory of Surgery, Nippon Veterinary and Life Science University, 1-7-1, Kyonann-cho, Musashinoshi, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, Japan; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968034/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5278434761116121367&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;0;2;2;2;2;2;2",
        "aff_unique_norm": "University of Electro-Communications;Nippon Veterinary and Life Science University;Beijing Advanced Innovation Center for Intelligent Robots and Systems",
        "aff_unique_dep": "Department of Mechanical Engineering and Intelligent Systems;Laboratory of Surgery;",
        "aff_unique_url": "https://www.uec.ac.jp;https://www.nvlsu.ac.jp;",
        "aff_unique_abbr": "UEC;NVLSU;",
        "aff_campus_unique_index": "0;0;1;0;2;2;2;2;2;2",
        "aff_campus_unique": "Chofu;Tokyo;Beijing",
        "aff_country_unique_index": "0;0;0;0;1;1;1;1;1;1",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "8968011",
        "title": "Design of Soft Flexible Wire-driven Finger Mechanism for Contact Pressure Distribution",
        "track": "main",
        "status": "Poster",
        "abstract": "We proposed the soft flexible wire-driven finger mechanism with the soft skin and the multi-joint skeletal structure using two coil springs. The multi-joint skeletal structure is mainly composed of two coil springs, multiple skeletal members and a fiber wire, and the soft skin is formed outside of them. The soft skin and the multi-joint skeletal structure make it possible to distribute the contact pressure, which is necessary for not only touching a living body such as a human or an agricultural crop, but also for touching an artificial object such as pastry or an industrial product without damaging it or its package. In this paper, we describe the design of the soft flexible wire-driven finger mechanism and development of the three-fingered hand using the finger mechanism we proposed.",
        "primary_area": "",
        "author": "Toshinori Hirose;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Toshinori Hirose;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37666290300;/38242437800;/37280639000;/37286658200;/37666290300;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo 7-3-1 Hongo, Bunkyoku, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo 7-3-1 Hongo, Bunkyoku, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo 7-3-1 Hongo, Bunkyoku, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo 7-3-1 Hongo, Bunkyoku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968011/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9397833250036433873&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hongo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968037",
        "title": "Design of a 3-DOF Linkage-Driven Underactuated Finger for Multiple Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a 3-DOF linkage-driven underactuated finger for achieving several different grasp modes. This finger mechanism is constructed by stacking one five-bar mechanism over one double parallelogram. This special architecture allows for installing all of the actuators on the base. A 2-finger robotic gripper having three actuators is developed for performing self-adaptive power grasping, parallel precision grasping, grasping during contact with the environment, and other grasping tasks through changing the orientation of the distal phalanx actively. The performance of the gripper is confirmed through both simulation and practical grasping experiment.",
        "primary_area": "",
        "author": "Long Kang;Jong-Tae Seo;Dukchan Yoon;Sang-Hwa Kim;Il Hong Suh;Byung-Ju Yi;Long Kang;Jong-Tae Seo;Dukchan Yoon;Sang-Hwa Kim;Il Hong Suh;Byung-Ju Yi",
        "authorids": "/37085447348;/37292425200;/37085639396;/37086176431;/37385851500;/37273970700;/37085447348;/37292425200;/37085639396;/37086176431;/37385851500;/37273970700",
        "aff": "Department of Electronic Systems Engineering, Hanyang University, South Korea; Department of Electronic Systems Engineering, Hanyang University, South Korea; Department of Electronic Systems Engineering, Hanyang University, South Korea; Department of Electronic Systems Engineering, Hanyang University, South Korea; Division of Electrical Engineering, Hanyang University, South Korea; Division of Computer Science and Engineering, Hanyang University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968037/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11051734615339393207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hanyang University",
        "aff_unique_dep": "Department of Electronic Systems Engineering",
        "aff_unique_url": "http://www.hanyang.ac.kr",
        "aff_unique_abbr": "HYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968549",
        "title": "Design of a Ballistically-Launched Foldable Multirotor",
        "track": "main",
        "status": "Poster",
        "abstract": "The operation of multirotors in crowded environments requires a highly reliable takeoff method, as failures during takeoff can damage more valuable assets nearby. The addition of a ballistic launch system imposes a deterministic path for the multirotor to prevent collisions with its environment, as well as increases the multirotor's range of operation and allows deployment from an unsteady platform. In addition, outfitting planetary rovers or entry vehicles with such deployable multirotors has the potential to greatly extend the data collection capabilities of a mission. A proof-of-concept multirotor aircraft has been developed, capable of transitioning from a ballistic launch configuration to a fully controllable flight configuration in midair after launch. The transition is accomplished via passive unfolding of the multirotor arms, triggered by a nichrome burn wire release mechanism. The design is 3D printable, launches from a three-inch diameter barrel, and has sufficient thrust to carry a significant payload. The system has been fabricated and field tested from a moving vehicle up to 50mph to successfully demonstrate the feasibility of the concept and experimentally validate the design's aerodynamic stability and deployment reliability. SUPPLEMENTARY MATERIAL Videos of the experiments: https://youtu.be/sQuKJfllyRM.",
        "primary_area": "",
        "author": "Daniel Pastor;Jacob Izraelevitz;Paul Nadan;Amanda Bouman;Joel Burdick;Brett Kennedy;Daniel Pastor;Jacob Izraelevitz;Paul Nadan;Amanda Bouman;Joel Burdick;Brett Kennedy",
        "authorids": "/37087323301;/37087324446;/37087323168;/37087322528;/37265975700;/38300763400;/37087323301;/37087324446;/37087323168;/37087322528;/37265975700;/38300763400",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, USA; California Institute of Tehcnology, Pasadena; Olin College, Needham; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, USA; California Institute of Tehcnology, Pasadena",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968549/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12085830377482938089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "California Institute of Technology;Olin College",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering;",
        "aff_unique_url": "https://www.caltech.edu;https://www.olin.edu",
        "aff_unique_abbr": "Caltech;Olin",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Pasadena;Needham",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967956",
        "title": "Design of a Fail-Safe Wearable Robot with Novel Extendable Arms for Ergonomic Accommodation during Floor Work",
        "track": "main",
        "status": "Poster",
        "abstract": "Aircraft manufacturing, construction, and agricultural production often involve workers maintaining uncomfortable postures, such as stooping and kneeling, for extended periods of time. We present a wearable robot, called MantisBot Alpha, that consists of two expandable robotic arms that brace a worker near the ground and allows them to perform bi-manual tasks. The key component of this new design is a novel linkage mechanism that provides adjustment of both the worker's distance to the ground and their torso tilt. The mechanism link parameters are optimized such that a) its expansion rate is high enough to push off the human body from the ground and fully contract the scissor arm when not used, and b) it allows the worker to reach within a large space while c) it is light enough for wearability. The linkage mechanism also avoids the singularity problem in standard scissor mechanisms. The actuator design provides a fail-safe system. A prototype has been fabricated to demonstrate the feasibility of the system.",
        "primary_area": "",
        "author": "Katie S. Hahm;H. Harry Asada;Katie S. Hahm;H. Harry Asada",
        "authorids": "/37087323234;/37279023100;/37087323234;/37279023100",
        "aff": "d\u07e3Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, USA; d\u07e3Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967956/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14220223268912424427&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Arbeloff Laboratory for Information Systems and Technology",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968200",
        "title": "Design of a Growing Robot Inspired by Plant Growth",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel design concept of expandable robotic arm inspired by plant growth is presented. The robot can construct its own structure by converting a type of fluidized material into a rigid structure at its growing point. The robot can extend its structure in multiple directions, and move through a winding space to reach a point, which is otherwise difficult to access. The robot with the rigid structure can also bear a significant load, has a plate to attach an end-effector, and can transport an object. The robot satisfies three key functional requirements that are characteristic to plant growth. First, the robot is capable of transporting structural materials to its growing point. Second, the robot is capable of transforming the material into a rigid structure. Third, it is capable of steering its growing point so that it is expanded in a desired direction. A proof-of concept prototype is then presented that consists of a special sprocket chain that can be switched between flexible/fluidized and rigid states, a winch that can pull/transport the chain, and a steering system to direct the growing direction. Unlike plants, this growing robot can retract its extended body, and can extend in a different direction. The prototype demonstrates that it meets all the functional requirements, and that it can make sharp turns and move through obstacles.",
        "primary_area": "",
        "author": "Tongxi Yan;Seiichi Teshigawara;H. Harry Asada;Tongxi Yan;Seiichi Teshigawara;H. Harry Asada",
        "authorids": "/37087323842;/37089267372;/37279023100;/37087323842;/37089267372;/37279023100",
        "aff": "d\u2019Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, MA, USA; d\u2019Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, MA, USA; d\u2019Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968200/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8544134449584834004&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "d\u2019Arbeloff Laboratory for Information Systems and Technology",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968134",
        "title": "Design of a Novel Gripper System with 3D- and Inkjet-printed Multimodal Sensors for Automated Grasping of a Forestry Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Future industrial robotic systems increasingly rely on automation of dangerous and tedious tasks. The acquisition of diverse and partially redundant information using reliable and rugged multimodal sensors helps to improve the safety an dependability of such systems. In this paper we propose proximity sensors suitable for the integration into the gripper of a forestry robot. The suggested sensors are complementary to vision based data acquisition as it can in particular provide information on objects close to the gripper that could otherwise not be obtained due to occlusion and missing direct line of sight. We present the design, fabrication and evaluation of 3Dand inkjet-printed capacitive sensors for grasping applications in harsh industrial environment, especially forestry robotics. The sensor elements have been developed along with a complete gripper re-design. The suggested fabrication strategy allows retrofitting of various industry components and reduced maintenance and costs as well as application-specific design and optimization and are also suitable for wireless operation. The developed gripper allows the support of grasping tasks by providing proximity and contact information.",
        "primary_area": "",
        "author": "Lisa-Marie Faller;Christian Stetco;Hubert Zangl;Lisa-Marie Faller;Christian Stetco;Hubert Zangl",
        "authorids": "/37085771774;/37086935354;/37273010900;/37085771774;/37086935354;/37273010900",
        "aff": "Department of Engineering & IT, Chair of Robotics, FH K\u00e4rnten, Europastrasse 4, Villach, Austria; Sensors and Actuators Department, Institute of Smart System Technologies, Alpen-Adria-Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Sensors and Actuators Department, Institute of Smart System Technologies, Alpen-Adria-Universit\u00e4t Klagenfurt, Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968134/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15576941612441009983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "FH K\u00e4rnten;Alpen-Adria-Universit\u00e4t Klagenfurt",
        "aff_unique_dep": "Department of Engineering & IT, Chair of Robotics;Sensors and Actuators Department, Institute of Smart System Technologies",
        "aff_unique_url": "https://www.fh-kaernten.at;https://www.aau.at",
        "aff_unique_abbr": "FH K\u00e4rnten;AAU",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Villach;Klagenfurt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "8967859",
        "title": "Design of a Semi-Humanoid Telepresence Robot for Plant Disaster Response and Prevention",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce the end-to-end design of WRSTelebot, a semi-humanoid telepresence robot platform for disaster response. Its software design focuses on enabling highfidelity immersive telepresence control of its manipulators and proactive multilateral control enabled by anomaly detection of the operator's physical state. The robot's key mechanical design features include a transformable mobile base that allows the robot to switch between two drive systems: caterpillar-track and differential drive, depending on the encountered terrain. The upper body is composed of a retractable dynamically balanced 20-DoF humanoid torso, that can fold entirely, allowing the robot to navigate through space-constrained environments. We evaluateits performance during off-site tests to show its usability.",
        "primary_area": "",
        "author": "Irvin Steve Cardenas;Jong-Hoon Kim;Irvin Steve Cardenas;Jong-Hoon Kim",
        "authorids": "/37061207000;/37086560302;/37061207000;/37086560302",
        "aff": "Computer Science Department, Kent State University, Kent, OH, USA; Computer Science Department, Kent State University, Kent, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967859/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11284414932820236787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kent State University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.kent.edu",
        "aff_unique_abbr": "KSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kent",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967978",
        "title": "Design of an Adhesion-Aware Fa\u00e7ade Cleaning Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Cleaning requirements of glass fa\u00e7ades of high-rise buildings have been significantly increased in recent years due to the growth of the construction industry. The conventional cleaning methods for high-rise buildings require human labor where efficiency, cost, and safety are major concerns. Therefore, robotic systems that can climb and clean glass fagades in high-rise buildings have been developed. Capability to attach to a fa\u00e7ade surface is one of the critical requirements of a glass fa\u00e7ade cleaning robot. Diverse approaches have been proposed for adhesion of cleaning robots to a glass fa\u00e7ade. Active vacuum suction mechanisms are widely used for these robots since they provide better controllability to move the robots smartly on the surface. Notably, those are decent for a reconfigurable robot that can transit between window frames. The suction mechanism of a glass fa\u00e7ade cleaning robot must provide a reliable suction force to make the robot stay safely and move smartly on a fa\u00e7ade. Nevertheless, these suction mechanisms can be failed due to improper fastening between a fa\u00e7ade and the mechanism, which may lead to safety and operational issues. Therefore, this paper proposes a novel method to realize the adhesion-awareness of a glass fa\u00e7ade cleaning robot. The adhesion-awareness is realized by analyzing The current drawn by the motors attached to the impellers of the vacuum mechanisms. Experiment results validate the capability of the proposed approach in raising the adhesion-awareness of a fa\u00e7ade cleaning robot.",
        "primary_area": "",
        "author": "M. A. Viraj J. Muthugala;M. Vega-Heredia;A. Vengadesh;G. Sriharsha;Mohan Rajesh Elara;M. A. Viraj J. Muthugala;M. Vega-Heredia;A. Vengadesh;G. Sriharsha;Mohan Rajesh Elara",
        "authorids": "/37085785341;/37087322480;/37086601795;/37085768280;/37546093700;/37085785341;/37087322480;/37086601795;/37085768280;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967978/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8573537307666266708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8968497",
        "title": "Design, Characterization, and Mechanical Programming of Fabric-Reinforced Textile Actuators for a Soft Robotic Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the design, fabrication, and evaluation of robust, fabric-reinforced textile actuators, which are capable of performing a variety and combination of motions, such as axial extension, radial expansion, bending, and twisting along its central axis. A simple fabrication procedure using a combination of lamination and sewing is described. The relationship between the fabric reinforcement characteristics and the actuator deformation is studied and experimentally verified. Multi-segment actuators can be created by tailoring different sections of fabric-reinforcements together in order to generate combination of motions to perform specific tasks. We demonstrate this by designing an anthropomorphic soft robotic hand and providing preliminary evaluations on grasping daily living objects of various size and shapes.",
        "primary_area": "",
        "author": "Pham H. Nguyen;Francisco Lopez-Arellano;Wenlong Zhang;Panagiotis Polygerinos;Pham H. Nguyen;Francisco Lopez-Arellano;Wenlong Zhang;Panagiotis Polygerinos",
        "authorids": "/37086331506;/37087324558;/37085823780;/37546532200;/37086331506;/37087324558;/37085823780;/37546532200",
        "aff": "Polytechnic School Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; The School of Biological Health Systems Engineering, Ira A. Fulton Schools of Engineering, Arizona State University, Tempe, AZ, USA; Polytechnic School Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; Polytechnic School Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968497/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15247495703396859620&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Ira A. Fulton Schools of Engineering",
        "aff_unique_url": "https://asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Mesa;Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967725",
        "title": "Design, Modeling and Control of Fully Actuated 2D Transformable Aerial Robot with 1 DoF Thrust Vectorable Link Module",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel transformable multilinked aerial robot which consists of link modules with 1 DoF thrust vectoring mechanism. Commonly used UAV is underactuated due to its simplicity and high flight duration, but can not control the position and orientation independently. To overcome this problem, fully actuated multirotor aerial robots have been developed. In our previous work we developed fully actuated multilinked aerial robot which can transform in the air. However, the transformation range was limited because of a singularity problem. In this paper we propose a new design of link module with a tilted rotor and 1 DoF thrust vectoring joint which enables to avoid singularity forms and keep the flight stable during transformation. We describe modeling and control for the fully actuated multilinked multirotor. Then we propose a transformation planning method utilizing the 1 DoF thrust vectoring angle with consideration of guaranteed minimum force/torque. Finally we perform an aerial transformation experiment with a real platform to demonstrate the feasibility of our proposed design and methods.",
        "primary_area": "",
        "author": "Tomoki Anzai;Moju Zhao;Masaki Murooka;Fan Shi;Kei Okada;Masayuki Inaba;Tomoki Anzai;Moju Zhao;Masaki Murooka;Fan Shi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086287194;/37085684946;/37085365946;/37086162286;/37280639000;/37286658200;/37086287194;/37085684946;/37085365946;/37086162286;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-Ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967725/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17520168911655535809&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967700",
        "title": "Design, Modeling and Testing of a Flagellum-inspired Soft Underwater Propeller Exploiting Passive Elasticity",
        "track": "main",
        "status": "Poster",
        "abstract": "Flagellated micro-organism are regarded as excellent swimmers within their size scales. This, along with the simplicity of their actuation and the richness of their dynamics makes them a valuable source of inspiration to design continuum, self-propelled underwater robots. Here we introduce a soft, flagellum-inspired system which exploits the compliance of its own body to passively attain a range of geometrical configurations from the interaction with the surrounding fluid. The spontaneous formation of stable helical waves along the length of the flagellum is responsible for the generation of positive net thrust. We investigate the relationship between actuation frequency and material elasticity in determining the steady-state configuration of the system and its thrust output. This is ultimately used to perform a parameter identification procedure of an elastodynamic model aimed at investigating the scaling laws in the propulsion of flagellated robots.",
        "primary_area": "",
        "author": "Marcello Calisti;Francesco Giorgio-Serchi;Cesare Stefanini;Madiha Farman;Irfan Hussain;Costanza Armanini;Dongming Gan;Lakmal Seneviratne;Federico Renda;Marcello Calisti;Francesco Giorgio-Serchi;Cesare Stefanini;Madiha Farman;Irfan Hussain;Costanza Armanini;Dongming Gan;Lakmal Seneviratne;Federico Renda",
        "authorids": "/37601977800;/37085546251;/37283623700;/37087322513;/37085379035;/37087321953;/37707343300;/37265268500;/38252431400;/37601977800;/37085546251;/37283623700;/37087322513;/37085379035;/37087321953;/37707343300;/37265268500;/38252431400",
        "aff": "The BioRobotics Institute, Scuola Superiore Sant\u2019Anna, Pisa, Italy; Institute of Integrated Micro and Nano Systems of the University of Edinburgh, Edinburgh, UK; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967700/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14380074021025420934&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;2;2;2;2;2;2",
        "aff_unique_norm": "Scuola Superiore Sant\u2019Anna;University of Edinburgh;Khalifa University of Science and Technology",
        "aff_unique_dep": "The BioRobotics Institute;Institute of Integrated Micro and Nano Systems;Center for Autonomous Robotic Systems (KUCARS)",
        "aff_unique_url": "https://www.sssup.it;https://www.ed.ac.uk;https://www.kustar.ac.ae",
        "aff_unique_abbr": ";Edinburgh;KUST",
        "aff_campus_unique_index": "0;1;2;2;2;2;2;2;2",
        "aff_campus_unique": "Pisa;Edinburgh;Abu Dhabi",
        "aff_country_unique_index": "0;1;2;2;2;2;2;2;2",
        "aff_country_unique": "Italy;United Kingdom;United Arab Emirates"
    },
    {
        "id": "8968449",
        "title": "Design, modelling and control of a novel agricultural robot with interlock drive system",
        "track": "main",
        "status": "Poster",
        "abstract": "A current problem in the design of small and lightweight autonomous agricultural robots is how to create sufficient traction on soil to pull an agricultural implement or load. One promising solution is offered by the interlock drive system, which penetrates spikes into the soil to create traction. The combination of soil penetrating spikes and a push-pull design offers new possibilities for vehicle control. By controlling the interlocking of the spikes and pushing and pulling them against the main frame, the vehicle can perform tight maneuvers. To validate this idea, we designed a robot, capable of creating high traction and performing headland turns. The navigation of the new robot system is performed by actively pushing the spikes, mounted on a slide into the soil, while the main frame is pushed back and pulled forward. The vehicle of 3-meter length was able to turn on the spot and could follow a straight line, just using the spikes and the push-pull mechanism for locomotion.",
        "primary_area": "",
        "author": "David Reiser;Volker Nannen;Gero Hubel;Hans W. Griepentrog;David Reiser;Volker Nannen;Gero Hubel;Hans W. Griepentrog",
        "authorids": "/37087324132;/37087324793;/37087324964;/37087321713;/37087324132;/37087324793;/37087324964;/37087321713",
        "aff": "Institute of Agricultural Engineering, University Hohenheim, Garbenstr. 9, Germany; Mobile Systems Engineering, Koblenz-Landau University, Koblenz, Germany; Institute of Agricultural Engineering, University Hohenheim, Garbenstr. 9, Germany; Institute of Agricultural Engineering, University Hohenheim, Garbenstr. 9, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968449/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14383152136605869496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University Hohenheim;Koblenz-Landau University",
        "aff_unique_dep": "Institute of Agricultural Engineering;Mobile Systems Engineering",
        "aff_unique_url": "https://www.uni-hohenheim.de;https://www.uni-koblenz-landau.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Koblenz",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968093",
        "title": "Detecting layered structures of partially occluded objects for bin picking",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots engage in bin picking of multiple objects, a failure in grasping partially occluded objects may occur because other objects may overlap the desired ones. Therefore, the layered structure of objects needs to be detected, and the picking order needs to be established. In this paper, we propose a new dataset that evaluates not only the area of objects but also the layered structures of objects. In this dataset, three tasks are targeted: object detection, semantic segmentation, and segmentation of occluded areas for bin picking of multiple objects. The dataset, called \u201cthe Amazon Robotics Challenge (ARC) Multi-task Dataset\u201d contains 1,500 RGB images and depth images, including all scenes containing bounding box labels, semantic segmentation labels, and occluded area labels. This enables representing the layered structure of overlapped objects with a tree structure. A benchmark of the ARC multi-task dataset demonstrated that occluded areas could be segmented using a Mask regional convolutional neural network (R-CNN) and that layered structures of objects could be predicted. Our dataset is available at the following URL:http://mprg.jp/research/arc_dataset_2017_e.",
        "primary_area": "",
        "author": "Yusuke Inagaki;Ryosuke Araki;Takayoshi Yamashita;Hironobu Fujiyoshi;Yusuke Inagaki;Ryosuke Araki;Takayoshi Yamashita;Hironobu Fujiyoshi",
        "authorids": "/37087323741;/37086382640;/37085338365;/37270300700;/37087323741;/37086382640;/37085338365;/37270300700",
        "aff": "Dept. of Robotics Science and Technology, Grad, Chubu Univ, Aichi, JP; Dept. of Computer Science, Grad, Chubu Univ, Aichi, JP; Faculty of Computer Science, Chubu Univ, Aichi, JP; Faculty of Robotics Science and Technology, Chubu Univ, Aichi, JP",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968093/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13783541241817236774&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chubu University",
        "aff_unique_dep": "Dept. of Robotics Science and Technology",
        "aff_unique_url": "https://www.chubu-u.ac.jp",
        "aff_unique_abbr": "Chubu Univ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967826",
        "title": "Development of Adjustable Knee Assist Device for Wearable Robot based on Linkage and Rolling Joint",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an adjustable knee joint for a wearable robot for the elderly, to provide physical gait assistance. In order to compensate for the translational and rotational movements of the knee in the sagittal plane as well as aligning the frontal plane, the proposed knee joint is implemented with a rolling joint, two aligning passive joints, four-bar linkage, and a sliding mechanism. Because the sliding mechanism, four-bar linkage, and rolling joint exist between the actuator and the joint mechanism, the rotation angle of the actuator and the flexion angle of the rolling joint do not change equally due to the kinematic characteristics. In order to define the flexion angle change of the rolling joint with respect to the change to the actuator angle in the flexion/extension motion of knee, the design parameters and flexion model are proposed in this paper. The proposed artificial knee joint effectively delivers the torque required for assistance while adapting to the joint motion of the wearer. This paper describes the mechanical design of this knee mechanism and its implementation on a wearable robot and in preliminary experiments. The performance of the proposed mechanism was verified by simulations and experiments. Finally, preliminary experiments were performed to demonstrate the possibility of reducing the metabolic cost of using a knee assist.",
        "primary_area": "",
        "author": "Byungiune Choi;Younbaek Lee;Jongwon Lee;Minhyung Lee;Bokman Lim;Young Jin Park;Kyungrock Kim;Yong-Jae Kim;Youngbo Shim;Byungiune Choi;Younbaek Lee;Jongwon Lee;Minhyung Lee;Bokman Lim;Young Jin Park;Kyungrock Kim;Yong-Jae Kim;Youngbo Shim",
        "authorids": "/37085906575;/37085433497;/37085753084;/38252785200;/38252097700;/37293567900;/38543062400;/37085566845;/37278689900;/37085906575;/37085433497;/37085753084;/38252785200;/38252097700;/37293567900;/38543062400;/37085566845;/37278689900",
        "aff": "Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea; Korea University of Technology and Education, Dongnam-gu, Cheonan-si, Chungcheongnam-do, Repulic of Korea; Samsung Advanced Institute of Technology, Samsung Electronics Co. Samsung-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Repulic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967826/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7882563819959668866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Samsung;Korea University of Technology and Education",
        "aff_unique_dep": "Samsung Advanced Institute of Technology;",
        "aff_unique_url": "https://www.sait.samsung.com;http://www.kute.ac.kr",
        "aff_unique_abbr": "SAIT;KUTE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cheonan-si",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967664",
        "title": "Development of Flexible Dual-type Proximity Sensor with Resonant Frequency for Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a flexible dual-type proximity sensor forrobotic applications such as human collaborative robots(HCRs) todetect the surroundings. The sensor consists of two parts; sensing transducer and a shielding layer. To amplify the sensing performance, a resonant frequency is formed by an inductive(L-type) electrode and two capacitive(C-type) electrodes, which are placed in coplanar with an LCR circuit. An optimal frequency range is suggested to amplify the proximity detecting performance with a consistent response of impedance change. The developed sensor has a size of 100 x120x2.8 mm3. To obtain the flexibility for various robot surfaces attachment, the electrode layer is made of Flexible Printed (a) Circuit Board(FPCB). Combined with the grounded shielding layer, the sensor can detect objects up to 300 mm in 10 mm resolution when attached to a grounded surface. The sensor is evaluated in diverse circumstances to validity for practical use on robotics.",
        "primary_area": "",
        "author": "Taeseung Kim;Jiho Noh;Tien Dat Nguyen;Hyouk Ryeol Choi;Taeseung Kim;Jiho Noh;Tien Dat Nguyen;Hyouk Ryeol Choi",
        "authorids": "/38184383800;/37087324807;/37085347041;/37290854100;/38184383800;/37087324807;/37085347041;/37290854100",
        "aff": "School of Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967664/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13154639348266342072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sungkyunkwan University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "http://www.skku.edu",
        "aff_unique_abbr": "SKKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968232",
        "title": "Development of Joint Module with Two-speed Gear Transmission and Joint Lock Mechanism during Driving for Task Adaptable Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to achieve tasks in the real world environment, humanoid robots have motors and reduction drives optimized in relation to weight and size for providing the necessary torque and angle speed. Therefore, having torque or angle speed outside of the predicted range will usually cause the task to fail. In this research, we propose a joint module with a two-stage transmission mechanism during driving and a joint locking mechanism during non-driving so that the appropriate torque and joint speed can be attained during the task. By applying the joint module to a tricycle type robot and switching the driving state during the task execution, we were able to both reduce the motor load when lifting heavy objects at driving time and keep high rigidity of the joint at non-driving time.",
        "primary_area": "",
        "author": "Tasuku Makabe;Takuma Shirai;Yuya Nagamatsu;Kento Kawaharazuka;Fumihito Sugai;Kei Okada;Masayuki Inaba;Tasuku Makabe;Takuma Shirai;Yuya Nagamatsu;Kento Kawaharazuka;Fumihito Sugai;Kei Okada;Masayuki Inaba",
        "authorids": "/37086579382;/38237530400;/37086275431;/37086101930;/37085651948;/37280639000;/37286658200;/37086579382;/38237530400;/37086275431;/37086101930;/37085651948;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968232/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6231644305161937157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968289",
        "title": "Development of Load Weight and Height Classifier in Lifting-Up Task Using Body Motion Metrics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new weight and height class classifier for the lift-up task, focusing on future use in the control of wearable power assist devices. The proposed classifier retrieves body motion feature metrics using small accelerometers and determines the weight class (0 ky40% of the subject body weight but not exceeding 25 kg) and the height of the handle (0cm/30cm/60 cm) of the load. Three different classifiers have been trained/configured and tested. The trained classifiers are shown to correctly classify the evaluation dataset with 80-90% accuracy. An additional experiment was conducted to collect feature quantities in which subjects were requested to lift up a weight placed inside a jute bag on the floor. A discrimination accuracy of approximately 80% for the jute bag experiment verifies the versatility of the classifier for more general on-the-job lifting tasks.",
        "primary_area": "",
        "author": "Naoya Ishibashi;Fumitake Fujii;Naoya Ishibashi;Fumitake Fujii",
        "authorids": "/37087321792;/38227830000;/37087321792;/38227830000",
        "aff": "Department of Mechanical Engineering, Yamaguchi University, 2-16-1 Tokiwadai Ube, Yamaguchi, Japan; Department of Mechanical Engineering, Yamaguchi University, 2-16-1 Tokiwadai Ube, Yamaguchi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968289/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:uORUddQquCQJ:scholar.google.com/&scioq=Development+of+Load+Weight+and+Height+Classifier+in+Lifting-Up+Task+Using+Body+Motion+Metrics&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yamaguchi University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.yamaguchi-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968476",
        "title": "Development of Micro Ultrasonic Actuator and Micro Rotor Blade for Micro Aerial Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial vehicles (UAVs) are now a regular feature of modern society which are highly needed for the rescue mission and collecting information at unreachable places. But while the current generation of UAVs are undoubtedly useful, people around the world are increasingly talking of the need for smaller, more agile systems that can be easily transported and operated in narrow places. This leads to the development of Micro Aerial Vehicles (MAVs). However, miniaturizing MAVs is very challenging because various problems still remain unsolved. Among those, miniaturizing actuator and rotor blade are the most common. Hence, in this paper, we describe the development and trial production of micro ultrasonic actuator and micro rotor blade for the development of the smallest MAV in the world.",
        "primary_area": "",
        "author": "Eric Tan Kai Chiang;Tomoaki Mashimo;Eric Tan Kai Chiang;Tomoaki Mashimo",
        "authorids": "/37087321937;/37545169100;/37087321937;/37545169100",
        "aff": "The Toyohashi University of Technology, Toyohashi, Japan; Department of Mechanical Engineering, Toyohashi University of Technology, Toyohashi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968476/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10097538711369856514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyohashi University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tut.ac.jp",
        "aff_unique_abbr": "TUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toyohashi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967831",
        "title": "Development of a Continuous Vertical-pulling Automatic Doffing Robot for the Ring Spinning",
        "track": "main",
        "status": "Poster",
        "abstract": "Doffing robot is an important part of the spinning process in the textile production. This paper analyzes the doffing process of spinning machines and points out the requirements of the structure and functions of the doffer. The locking two-finger gripper, the three-dimensional circulating operation mechanism, the collaborating locating mechanism with the toothed disc and the pre-loosening mechanism by rotating spindles are designed. On this basis the continuous vertical-pulling automatic doffing robot, named CVP doffing robot, for the ring spinning is developed. The kinematics and dynamics analysis of the CVP doffing robot are carried out. The structural parameters of the CVP doffing robot are optimized by establishing kinematics and dynamics models. The forces of pulling out cops before and after the pre-loosing operation are tested. On this basis, the strength of the key components is designed and checked. Finally, the performance of the CVP doffing robot is verified by the doffing experiment.",
        "primary_area": "",
        "author": "Wenzeng Zhang;Sicheng Yang;Chao Luo;Siyun Liu;Hong Fu;Wenzeng Zhang;Sicheng Yang;Chao Luo;Siyun Liu;Hong Fu",
        "authorids": "/37278432000;/37085647151;/37085884518;/37087007318;/37952392700;/37278432000;/37085647151;/37085884518;/37087007318;/37952392700",
        "aff": "Department of Mechanical engineering, Key Laboratory for Advanced Materials Processing Technology (MOE), Tsinghua University, Beijing, China; Department of Mechanical engineering, Key Laboratory for Advanced Materials Processing Technology (MOE), Tsinghua University, Beijing, China; Department of Mechanical engineering, Key Laboratory for Advanced Materials Processing Technology (MOE), Tsinghua University, Beijing, China; Department of Mechanical engineering, Key Laboratory for Advanced Materials Processing Technology (MOE), Tsinghua University, Beijing, China; Department of Mechanical engineering, Key Laboratory for Advanced Materials Processing Technology (MOE), Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967831/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3661290010192361288&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968273",
        "title": "Development of a Location estimation System for Minute Sound Source by Using Human Acoustic System with Stochastic Resonance",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this study is to develop a system that enables location estimation of a small sound source. The location estimation of a small sound source has some difficulties such as high computational costs or disturbances from the ambient noises and reflected waves. The proposed system is composed of a biologically-inspired system which uses a hearing mechanism based on the human auditory model and a mechanism for perceiving weak sound signals that use stochastic resonance. The location estimation mechanism in the proposed system is based on the time-lag detecting architecture. On the other hand, the stochastic resonance mechanism can pick up the small sound signals among the ambient noises. Using this proposed system, we implemented the location estimation of the small sound source through hardware experiments. Good results were obtained for the small sound source location estimation.",
        "primary_area": "",
        "author": "Katsuyoshi Tsujita;Katsuyoshi Tsujita",
        "authorids": "/37267477600;/37267477600",
        "aff": "Katsuyoshi Tsujita",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968273/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7RJDcJrsXHkJ:scholar.google.com/&scioq=Development+of+a+Location+estimation+System+for+Minute+Sound+Source+by+Using+Human+Acoustic+System+with+Stochastic+Resonance&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2
    },
    {
        "id": "8968036",
        "title": "Development of a Navigation Algorithm for Optimal Path Planning for Autonomous Electric Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "There are many different driver assistance systems that help the driver controlling their vehicle. These systems do not have full control of the car; however, there are more and more systems in development that take over individual driving functions completely. We are working towards a fully autonomous future. The goal is not only to transport people to their desired destination, but to make commuting on roads safer. Navigation is one of the essential tasks of autonomous driving. The software must independently calculate a route from its current location to the destination. If the vehicle is not guided precisely through the road network, it can never reach that destination. To cope with the problem, the data of the road network must be available to the vehicle. Based on this data, the vehicle must be able to calculate a route to its destination. This paper deals with the development of a navigation algorithm, for optimal path planning, within the framework of an industrial project. The various requirements for the realization of a navigation system are listed. Solution strategies of such systems are identified and compared. Based on this, approaches for solving the task are developed and implemented.",
        "primary_area": "",
        "author": "Marco Dinges;Daniel Schilberg;Stephan Ciethier;Marco Dinges;Daniel Schilberg;Stephan Ciethier",
        "authorids": "/37087324318;/37590565600;/37087323455;/37087324318;/37590565600;/37087323455",
        "aff": "Bertrandt Ingenieurb\u00fcro GmbH, Cologne, Germany; Hochschule Bochum, Bochum, Germany; Bertrandt Ingenieurb\u00fcro GmbH, Cologne, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968036/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4444153746156438742&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Bertrandt Ingenieurb\u00fcro GmbH;Hochschule Bochum",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bertrandt.com;https://www.hs-bochum.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bochum",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967748",
        "title": "Development of a Steel Bridge Climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by a high demand for automated inspection of civil infrastructure, this work presents an efficient design and development of a tank-like robot for structural health monitoring. Unlike most existing magnetic wheeled mobile robot designs, which may be suitable for climbing on flat steel surface, our proposed tank-like robot design uses reciprocating mechanism and roller-chains to make it capable of climbing on different structural shapes (e.g., cylinder, cube) with coated or non-coated steel surfaces. The developed robot is able to pass through the joints and transition from one surface to the other (e.g., from flat to curving surfaces). Taking into account several strict considerations (including tight dimension, efficient adhesion and climbing flexibility) to adapt with various shapes of steel structures, a prototype tank-like robot integrating multiple sensors (hall-effects, sonars, inertial measurement unit, Eddy current and cameras), has been developed. Rigorous analysis of robot kinematics, adhesion force, sliding failure and turn-over failure has been conducted to demonstrate the stability of the proposed design. Mechanical and magnetic force analysis together with sliding/turn-over failure investigation can serve as an useful framework for designing various steel climbing robots in the future. The robot is integrated with cameras and Eddy current sensor for visual and in-depth fatigue crack inspection of steel structures. Experimental results and field deployments confirm the adhesion, climbing, inspection capability of the developed robot.",
        "primary_area": "",
        "author": "Son Thanh Nguyen;Hung Manh La;Son Thanh Nguyen;Hung Manh La",
        "authorids": "/37087321874;/37542872700;/37087321874;/37542872700",
        "aff": "Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967748/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11211597822970336536&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Advanced Robotics and Automation (ARA) Lab",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968259",
        "title": "Development of an Arm Curl Machine with Variable Resistance Using Pneumatic Artificial Rubber Muscle",
        "track": "main",
        "status": "Poster",
        "abstract": "A method to improve quality of life of elderly people is to increase muscle strength. The purpose of this study is to develop a machine to improve muscle strength effectively. In this paper, we proposed a muscle strength training machine that exerts variable resistance using pneumatic artificial rubber muscle. In addition, we observed the effect on muscle activity by using the proposed machine with predictable and unpredictable load change patterns. Experimental results showed that there was a difference between the rising time of muscle activity and the maximum amplitude of electromyogram depending on predictability of the load change and showed the possibility of effective muscle strength improvement against unpredictable load using the arm curl machine.",
        "primary_area": "",
        "author": "Tomoya Nakanishi;Toshihiro Kawase;Junya Aizawa;Shintaro Yoshida;Shingo Ohno;Ryo Sakurai;Tetsuro Miyazaki;Takahiro Kanno;Kenji Kawashima;Tomoya Nakanishi;Toshihiro Kawase;Junya Aizawa;Shintaro Yoshida;Shingo Ohno;Ryo Sakurai;Tetsuro Miyazaki;Takahiro Kanno;Kenji Kawashima",
        "authorids": "/37087322328;/37086578826;/37087322665;/37087324288;/37087323170;/37087323096;/37086294776;/37085394750;/37280901500;/37087322328;/37086578826;/37087322665;/37087324288;/37087323170;/37087323096;/37086294776;/37085394750;/37280901500",
        "aff": "Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University 2-3-10 Kandasurugadai Chiyoda-ku, Tokyo, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University 2-3-10 Kandasurugadai Chiyoda-ku, Tokyo, Japan; Clinical Center for Sports Medicine and Sports Dentistry, Tokyo Medical and Dental University: 1-5-45 Yushima, Bunkyo-ku, Tokyo, Japan; Bridgestone Corporation: 3-1-1 Ogawahigashi-cho, Kodaira-shi, Tokyo, Japan; Bridgestone Corporation: 3-1-1 Ogawahigashi-cho, Kodaira-shi, Tokyo, Japan; Bridgestone Corporation: 3-1-1 Ogawahigashi-cho, Kodaira-shi, Tokyo, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University 2-3-10 Kandasurugadai Chiyoda-ku, Tokyo, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University 2-3-10 Kandasurugadai Chiyoda-ku, Tokyo, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University 2-3-10 Kandasurugadai Chiyoda-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968259/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4957090083149617988&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;1;1;0;0;0",
        "aff_unique_norm": "Tokyo Medical and Dental University;Bridgestone Corporation",
        "aff_unique_dep": "Institute of Biomaterials and Bioengineering;",
        "aff_unique_url": "https://www.tmd.ac.jp;https://www.bridgestone.com",
        "aff_unique_abbr": "TMDU;Bridgestone",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968067",
        "title": "Development of an Autonomous Sanding Robot with Structured-Light Technology",
        "track": "main",
        "status": "Poster",
        "abstract": "Large demand for robotics and automation has been reflected in the sanding works, as current manual operations are labor-intensive, without consistent quality, and also subject to safety and health issues. While several machines have been developed to automate one or two steps in the sanding works, the autonomous capability of existing solutions is relatively low, and the human assistance or supervision is still heavily required in the calibration of target objects or the planning of robot motion and tasks. This paper presents the development of an autonomous sanding robot, which is able to perform the sanding works on an unknown object automatically, without any prior calibration or human intervention. The developed robot works as follows. First, the target object is scanned then modeled with the structured-light camera. Second, the robot motion is planned to cover all the surfaces of the object with an optimized transition sequence. Third, the robot is controlled to perform the sanding on the object under the desired impedance model. A prototype of the sanding robot is fabricated and its performance is validated in the task of sanding a batch of wooden boxes. With sufficient degrees of freedom (DOFs) and the customization of the end effector, the developed robot is able to provide a general solution to the autonomous sanding on many other different objects.",
        "primary_area": "",
        "author": "Yingxin Huo;Diancheng Chen;Xiang Li;Peng Li;Yun-Hui Liu;Yingxin Huo;Diancheng Chen;Xiang Li;Peng Li;Yun-Hui Liu",
        "authorids": "/37087322105;/37087325137;/37280877200;/132178398280570;/37279412600;/37087322105;/37087325137;/37280877200;/132178398280570;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Automation, Tsinghua University, CUHK Shenzhen Research Institute; Department of Mechanical Engineering and Automation, Harbin Institute of Technology; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968067/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5370794601313503258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Tsinghua University;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Automation;Department of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.tsinghua.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "CUHK;THU;HIT",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Hong Kong SAR;Beijing;Harbin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968158",
        "title": "Development of an adaptive hexapod robot based on Follow-the-contact-point gait control and Timekeeper control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new control method for a hexapod robot walking on irregular terrain based on a human operator's foot-placement navigation is proposed and evaluated. The control method is based on the Follow-the-contact-point (FCP) gait control that operates on the principle that each leg follows the contact point of its foreleg. Hence, planning the contact points for all the legs are summarized to one of the front legs. To dedicate the FCP gait control to a hexapod robot, three control architectures are added. First, new constraints in the transition from a stance phase to a swing phase are added to maintain static stability when a leg leaves the ground. Second, a real-time posture control system for contacting legs is added. The third is an adaptive control to adjust the time elapsed in each control mode, by which specifications of deadlock-free and static stability are satisfied. The proposed control architecture is installed to a small hexapod robot, and its performance is evaluated through experiments wherein the robot walks on uneven terrain.",
        "primary_area": "",
        "author": "Yuki Murata;Shinkichi Inagaki;Tatsuya Suzuki;Yuki Murata;Shinkichi Inagaki;Tatsuya Suzuki",
        "authorids": "/37087028975;/37302232800;/37276136600;/37087028975;/37302232800;/37276136600",
        "aff": "Department of Mechanical System Engineering, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Aichi, Japan; Department of Mechanical System Engineering, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Aichi, Japan; Department of Mechanical System Engineering, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Aichi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968158/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18088197738715120205&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nagoya University",
        "aff_unique_dep": "Department of Mechanical System Engineering",
        "aff_unique_url": "https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Nagoya U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968525",
        "title": "Did You Miss the Sign? A False Negative Alarm System for Traffic Sign Detectors",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection is an integral part of an autonomous vehicle for its safety-critical and navigational purposes. Traffic sign as an object plays a vital role in guiding such systems. However, if the vehicle fails to locate any critical sign, it might make a catastrophic failure. In this paper, we are proposing an approach to identify traffic signs that have been mistakenly discarded by the object detector. The proposed method raises an alarm when it discovers a failure by the object detector to detect a traffic sign. This approach can be useful to evaluate the performance of the detector during the deployment phase. We trained a single shot multi-box object detector to detect traffic signs and used its internal features to train a separate false negative detector (FND). During deployment, FND decides whether the traffic sign detector (TSD) has missed a sign or not. We are using precision and recall to measure the accuracy of FND in two different datasets. For 80% recall, FND has achieved 89.9% precision in Belgium Traffic Sign Detection dataset and 90.8% precision in German Traffic Sign Recognition Benchmark dataset respectively. To the best of our knowledge, our method is the first to tackle this critical aspect of false negative detection in robotic vision. Such a fail-safe mechanism for object detection can improve the engagement of robotic vision systems in our daily life.",
        "primary_area": "",
        "author": "Quazi Marufur Rahman;Niko S\u00fcnderhauf;Feras Dayoub;Quazi Marufur Rahman;Niko S\u00fcnderhauf;Feras Dayoub",
        "authorids": "/37087324639;/37563890800;/37866588000;/37087324639;/37563890800;/37866588000",
        "aff": "Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968525/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14124621855004799224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8968264",
        "title": "Directional TSDF: Modeling Surface Orientation for Coherent Meshes",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time 3D reconstruction from RGB-D sensor data plays an important role in many robotic applications, such as object modeling and mapping. The popular method of fusing depth information into a truncated signed distance function (TSDF) and applying the marching cubes algorithm for mesh extraction has severe issues with thin structures: not only does it lead to loss of accuracy, but it can generate completely wrong surfaces. To address this, we propose the directional TSDF-a novel representation that stores opposite surfaces separate from each other. The marching cubes algorithm is modified accordingly to retrieve a coherent mesh representation. We further increase the accuracy by using surface gradient-based ray casting for fusing new measurements. We show that our method outperforms state-of-the-art TSDF reconstruction algorithms in mesh accuracy.",
        "primary_area": "",
        "author": "Malte Splietker;Sven Behnke;Malte Splietker;Sven Behnke",
        "authorids": "/37085335477;/37295987100;/37085335477;/37295987100",
        "aff": "Autonomous Intelligent Systems Group, University of Bonn, Germany; Autonomous Intelligent Systems Group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968264/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15896524790394165030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems Group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967586",
        "title": "Disaster Response Robot\u2019s Autonomous Manipulation of Valves in Disaster Sites Based on Visual Analyses of RGBD Images",
        "track": "main",
        "status": "Poster",
        "abstract": "For building a disaster response robot, WAREC-l's fully-automated system for manipulating a valve, this paper proposes a method for (1) detecting a valve which is far away from the robot, (2) estimating the position and orientation for grasping the valve by the robot at a closer position. Our methods do not need any prior information about a valve for the above-mentioned detection and estimation for grasping. In addition, our estimation for grasping provides useful information, by which WAREC-I can rotate a valve autonomously. The method (1) uses the RGB image and the point cloud data captured by Multisense SL as the input, and estimate the position and orientation of a valve far away from the robot. The method (2) uses both the RGB and depth images captured by KinectV2 as input and estimate information for grasping the valve. Our experiments are conducted using a real disaster response robot. Our experimental results show the error of the estimation by the (a) two methods are small enough to achieve a fully-automated system for detecting and rotating the valve by WAREC-I.",
        "primary_area": "",
        "author": "Keishi Nishikawa;Asaki Imai;Kazuya Miyakawa;Takuya Kanda;Takashi Matsuzawa;Kenji Hashimoto;Atsuo Takanishi;Hiroyuki Ogata;Jun Ohya;Keishi Nishikawa;Asaki Imai;Kazuya Miyakawa;Takuya Kanda;Takashi Matsuzawa;Kenji Hashimoto;Atsuo Takanishi;Hiroyuki Ogata;Jun Ohya",
        "authorids": "/37086610075;/37086217919;/37087324860;/37087324176;/37085848034;/37537963700;/37280756700;/37340820600;/37269392200;/37086610075;/37086217919;/37087324860;/37087324176;/37085848034;/37537963700;/37280756700;/37340820600;/37269392200",
        "aff": "Mitsubishi Electric; Department of Modern Mechanical Engineering, Waseda University; Department of Modern Mechanical Engineering, Waseda University; Department of Modern Mechanical Engineering, Waseda University; Department of Modern Mechanical Engineering, Waseda University; Department of Mechanical Engineering Informatics, Meiji University; Department of Modern Mechanical Engineering, Waseda University; Department of System Design Engineering, Seikei Univeristy; Department of Modern Mechanical Engineering, Waseda University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967586/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4975272265013085083&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;2;1;3;1",
        "aff_unique_norm": "Mitsubishi Electric Corporation;Waseda University;Meiji University;Seikei University",
        "aff_unique_dep": ";Department of Modern Mechanical Engineering;Department of Mechanical Engineering Informatics;Department of System Design Engineering",
        "aff_unique_url": "https://www.mitsubishielectric.com;https://www.waseda.jp/top;https://www.meiji.ac.jp;https://www.seikei-u.ac.jp",
        "aff_unique_abbr": "MELCO;Waseda;Meiji;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968600",
        "title": "Discrete N-Dimensional Entropy of Behavior: DNDEB",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared control for human-robot teams - where both the human and the robot's autonomy provide commands to the hardware - offers advantages over fully teleoperated or fully autonomous systems by utilizing the unique skill sets of both the human and robot's autonomy simultaneously. However, the mechanism by which control is shared is often static and many teams could benefit from adjusting this mechanism, such that the human or autonomy alternatively receive more control authority in different scenarios. The question then is: how do we know when these scenarios occur? In this paper, we present a method to estimate the performance of human-robot teams using a novel metric called Discrete N-Dimensional Entropy of Behavior (DNDEB). DNDEB utilizes knowledge of a high-performing human-robot team to build a model of how the team should operate. The model is used to predict the human's command. The error between the prediction and actual command is tracked and after a certain number of samples, entropy is estimated. A higher level of entropy corresponds to deviations from the high-performance model, which can be interpreted as poor performance by the human-robot team (e.g., long task time or a collision). Our formulation offers several advantages: it (1) accepts discrete inputs of any size, (2) does not require additional sensors, and (3) is tunable to the specific application. To validate this, we conduct a 15person study where subjects operated a powered wheelchair under three different shared-control paradigms. We find that entropy is higher for cases with longer task durations and cases where there is a collision. Moreover, we use DNDEB thresholds as a mechanism to predict the performance of the human-robot team online and find an average accuracy of 91% with a prescience rate of 72%.",
        "primary_area": "",
        "author": "Michael Young;Mahdieh Nejati Javaremi;Brenna D. Argall;Michael Young;Mahdieh Nejati Javaremi;Brenna D. Argall",
        "authorids": "/37086919393;/37086919826;/37568669000;/37086919393;/37086919826;/37568669000",
        "aff": "Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968600/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12211672830203391526&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968197",
        "title": "Distributed Dynamic Sensor Assignment of Multiple Mobile Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed scalable algorithms are sought in many multi-robot contexts. In this work we address the dynamic optimal linear assignment problem, exemplified as a target tracking mission in which mobile robots visually track mobile targets in a one-to-one capacity. We adapt our previous work on formation achievement by means of a distributed simplex variant, which results in a conceptually simple consensus solution, asynchronous in nature and requiring only local broadcast communications. This approach seamlessly tackles dynamic changes in both costs and network topology. Improvements designed to accelerate the global convergence in the face of dynamically evolving task rewards are described and evaluated with simulations that highlight the efficiency and scalability of the proposal. Experiments with a team of three Turtlebot robots are finally shown to validate the applicability of the algorithm.",
        "primary_area": "",
        "author": "Eduardo Montijano;Danilo Tardioli;Alejandro R. Mosteo;Eduardo Montijano;Danilo Tardioli;Alejandro R. Mosteo",
        "authorids": "/37681715400;/37681377900;/37681666900;/37681715400;/37681377900;/37681666900",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Centro Universitario de la Defensa, Zaragoza, Spain; Centro Universitario de la Defensa, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968197/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2849631381208168203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universidad de Zaragoza;Centro Universitario de la Defensa",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A);",
        "aff_unique_url": "https://www.unizar.es;",
        "aff_unique_abbr": "UniZar;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968471",
        "title": "Disturbance Estimation and Rejection for High-Precision Multirotor Position Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Many multirotor Unmanned Aerial Systems applications have a critical need for precise position control in environments with strong dynamic external disturbances such as wind gusts or ground and wall effects. Moreover, to maximize flight time, small multirotor platforms have to operate within strict constraints on payload and thus computational performance. In this paper, we present the design and experimental comparison of Model Predictive and PID multirotor position controllers augmented with a disturbance estimator to reject strong wind gusts up to 12 m/s and ground effect. For disturbance estimation, we compare Extended and Unscented Kalman filtering. In extensive in- and outdoor flight tests, we evaluate the suitability of the developed control and estimation algorithms to run on a computationally constrained platform. This allows to draw a conclusion on whether potential performance improvements justify the increased computational complexity of MPC for multirotor position control and UKF for disturbance estimation.",
        "primary_area": "",
        "author": "Daniel Hentzen;Thomas Stastny;Roland Siegwart;Roland Brockers;Daniel Hentzen;Thomas Stastny;Roland Siegwart;Roland Brockers",
        "authorids": "/37086582049;/37085387015;/37281398300;/37266435300;/37086582049;/37085387015;/37281398300;/37266435300",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr, Pasadena, CA, USA; Autonomous Systems Lab, Leonhardstrasse 21, Swiss Federal Institute of Technology (ETH) Zurich, Zurich, Switzerland; Autonomous Systems Lab, Leonhardstrasse 21, Swiss Federal Institute of Technology (ETH) Zurich, Zurich, Switzerland; Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968471/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9694070403205722023&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "California Institute of Technology;Swiss Federal Institute of Technology (ETH) Zurich",
        "aff_unique_dep": "Jet Propulsion Laboratory;Autonomous Systems Lab",
        "aff_unique_url": "https://www.caltech.edu;https://www.ethz.ch",
        "aff_unique_abbr": "Caltech;ETH Zurich",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Pasadena;Zurich",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "8968508",
        "title": "Domain-Independent Unsupervised Detection of Grasp Regions to grasp Novel Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main challenges in the vision-based grasping is the selection of feasible grasp regions while interacting with novel objects. Recent approaches exploit the power of convolutional neural network (CNN) to achieve accurate grasping at the cost of high computational power and time. In this paper, we present a novel unsupervised learning based algorithm for the selection of feasible grasp regions. Unsupervised learning infers the pattern in dataset without any external labels. We applied k-means clustering at every sampling stage in image plane to identify the grasp regions, followed by axes assignment method. We define a novel concept of Grasp Decide Index (GDI) to select the best grasp pose in the image plane. We have conducted several experiments in clutter or isolated environment on standard objects of Amazon Robotics Challenge 2017 and Amazon Picking Challenge 2016. We compared the results with prior learning based approaches to validate the robustness and adaptive nature of our algorithm for a variety of novel objects in different domains.",
        "primary_area": "",
        "author": "Siddhartha Vibhu Pharswan;Mohit Vohra;Ashish Kumar;Laxmidhar Behera;Siddhartha Vibhu Pharswan;Mohit Vohra;Ashish Kumar;Laxmidhar Behera",
        "authorids": "/37087323142;/37087236592;/37085729269;/37352203400;/37087323142;/37087236592;/37085729269;/37352203400",
        "aff": "Intelligent Systems and Control Lab (ISL), Indian Institute of Technology, Kanpur, Uttar Pradesh, India; Intelligent Systems and Control Lab (ISL), Indian Institute of Technology, Kanpur, Uttar Pradesh, India; Intelligent Systems and Control Lab (ISL), Indian Institute of Technology, Kanpur, Uttar Pradesh, India; Intelligent Systems and Control Lab (ISL), Indian Institute of Technology, Kanpur, Uttar Pradesh, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968508/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14698774969238356695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Intelligent Systems and Control Lab (ISL)",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968488",
        "title": "Dot-to-Dot: Explainable Hierarchical Reinforcement Learning for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems are ever more capable of automation and fulfilment of complex tasks, particularly with reliance on recent advances in intelligent systems, deep learning and artificial intelligence in general. However, as robots and humans come closer together in their interactions, the matter of interpretability, or explainability of robot decision-making processes for the human grows in importance. A successful interaction and collaboration would only be possible through mutual understanding of underlying representations of the environment and the task at hand. This is currently a challenge in deep learning systems. We present a hierarchical deep reinforcement learning system, consisting of a low-level agent handling the large actions/states space of a robotic system efficiently, by following the directives of a high-level agent which is learning the high-level dynamics of the environment and task. This high-level agent forms a representation of the world and task at hand that is interpretable for a human operator. The method, which we call Dot-to-Dot, is tested on a MuJoCo-based model of the Fetch Robotics Manipulator, as well as a Shadow Hand, to test its performance. Results show efficient learning of complex actions/states spaces by the low-level agent, and an interpretable representation of the task and decision-making process learned by the high-level agent.",
        "primary_area": "",
        "author": "Benjamin Beyret;Ali Shafti;A. Aldo Faisal;Benjamin Beyret;Ali Shafti;A. Aldo Faisal",
        "authorids": "/37087325296;/37085616628;/37089852945;/37087325296;/37085616628;/37089852945",
        "aff": "Dept. of Computing, Brain and Behaviour Lab; Dept. of Computing, Brain and Behaviour Lab; Dept. of Computing, Brain and Behaviour Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968488/",
        "gs_citation": 103,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17363893106715569733&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Dept. of Computing",
        "aff_unique_dep": "Brain and Behaviour Lab",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8968227",
        "title": "Double Refinement Network for Efficient Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation is the task of obtaining a measure of distance for each pixel using a single image. It is an important problem in computer vision and is usually solved using neural networks. Though recent works in this area have shown significant improvement in accuracy, the state-of-the-art methods tend to require massive amounts of memory and time to process an image. The main purpose of this work is to improve the performance of the latest solutions with no decrease in accuracy. To this end, we introduce the Double Refinement Network architecture. The proposed method achieves state-of-the-art results on the standard benchmark RGB-D dataset NYU Depth v2, while its frames per second rate is significantly higher (up to 18 times speedup per image at batch size 1) and the RAM usage is lower.",
        "primary_area": "",
        "author": "Nikita Durasov;Mikhail Romanov;Valeriya Bubnova;Pavel Bogomolov;Anton Konushin;Nikita Durasov;Mikhail Romanov;Valeriya Bubnova;Pavel Bogomolov;Anton Konushin",
        "authorids": "/37086616867;/37086031176;/37087323058;/37087323579;/38306221200;/37086616867;/37086031176;/37087323058;/37087323579;/38306221200",
        "aff": "Samsung AI Center Moscow; Samsung AI Center Moscow; Samsung AI Center Moscow; Samsung AI Center Moscow; Samsung AI Center Moscow",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968227/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4913247156284694891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "8968205",
        "title": "Driving with Style: Inverse Reinforcement Learning in General-Purpose Planning for Automated Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior and motion planning play an important role in automated driving. Traditionally, behavior planners instruct local motion planners with predefined behaviors. Due to the high scene complexity in urban environments, unpredictable situations may occur in which behavior planners fail to match predefined behavior templates. Recently, general-purpose planners have been introduced, combining behavior and local motion planning. These general-purpose planners allow behavior-aware motion planning given a single reward function. However, two challenges arise: First, this function has to map a complex feature space into rewards. Second, the reward function has to be manually tuned by an expert. Manually tuning this reward function becomes a tedious task. In this paper, we propose an approach that relies on human driving demonstrations to automatically tune reward functions. This study offers important insights into the driving style optimization of general-purpose planners with maximum entropy inverse reinforcement learning. We evaluate our approach based on the expected value difference between learned and demonstrated policies. Furthermore, we compare the similarity of human driven trajectories with optimal policies of our planner under learned and expert-tuned reward functions. Our experiments show that we are able to learn reward functions exceeding the level of manual expert tuning without prior domain knowledge.",
        "primary_area": "",
        "author": "Sascha Rosbach;Vinit James;Simon Gro\u00dfjohann;Silviu Homoceanu;Stefan Roth;Sascha Rosbach;Vinit James;Simon Gro\u00dfjohann;Silviu Homoceanu;Stefan Roth",
        "authorids": "/37087324291;/37087323667;/37087323047;/37889212600;/37282906600;/37087324291;/37087323667;/37087323047;/37889212600;/37282906600",
        "aff": "Volkswagen AG, Wolfsburg, Germany; Volkswagen AG, Wolfsburg, Germany; Volkswagen AG, Wolfsburg, Germany; Volkswagen AG, Wolfsburg, Germany; Visual Inference Lab, Technische Universit\u00e4t Darmstadt, Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968205/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18072723024241758166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Volkswagen AG;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": ";Visual Inference Lab",
        "aff_unique_url": "https://www.volkswagenag.com;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "VW;TUD",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Wolfsburg;Darmstadt",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967883",
        "title": "Dual-arm Assembly Planning Considering Gravitational Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning dual-arm assembly of more than three objects is a challenging Task and Motion Planning (TAMP) problem. The assembly planner shall consider not only the pose constraints of objects and robots, but also the gravitational constraints that may break the finished part. This paper proposes a planner to plan the dual-arm assembly of more than three objects. It automatically generates the grasp configurations and assembly poses, and simultaneously searches and backtracks the grasp space and assembly space to accelerate the motion planning of robot arms. Meanwhile, the proposed method considers gravitational constraints during robot motion planning to avoid breaking the finished part. In the experiments and analysis section, the time cost of each process and the influence of different parameters used in the proposed planner are compared and analyzed. The optimal values are used to perform real-world executions of various robotic assembly tasks. The planner is proved to be robust and efficient through the experiments.",
        "primary_area": "",
        "author": "Ryota Moriyama;Weiwei Wan;Kensuke Harada;Ryota Moriyama;Weiwei Wan;Kensuke Harada",
        "authorids": "/37087324901;/37085689483;/37277067400;/37087324901;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967883/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12501357258133419222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Graduate School of Engineering Science",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967798",
        "title": "Duckiepond: An Open Education and Research Environment for a Fleet of Autonomous Maritime Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Duckiepond is an education and research development environment that includes software systems, educational materials, and of a fleet of autonomous surface vehicles Duckieboat. Duckieboats are designed to be easily reproducible with parts from a 3D printer and other commercially available parts, with flexible software that leverages several open source packages. The Duckiepond environment is modeled after Duckietown and AI Driving Olympics environments: Duckieboats rely only on one monocular camera, IMU, and GPS, and perform all ML processing using onboard embedded computers. Duckiepond coordinates commonly used middlewares (ROS and MOOS) and containerized software packages in Docker, making it easy to deploy. The combination of learning-based methods together with classic methods enables important maritime missions: track and trail, navigation, and coordinate among Duckieboats to avoid collisions. Duckieboats have been operating in a man-made lake, reservoir and river environments. All software, hardware, and educational materials are openly available (https://robotx-nctu.github.io/duckiepond), with the goal of supporting research and education communities across related domains.",
        "primary_area": "",
        "author": "Ni-Ching Lin;Yu-Chieh Hsiao;Yi-Wei Huang;Ching-Tung Hung;Tzu-Kuan Chuang;Pin-Wei Chen;Jui-Te Huang;Chao-Chun Hsu;Andrea Censi;Michael Benjamin;Chi-Fang Chen;Hsueh-Cheng Wang;Ni-Ching Lin;Yu-Chieh Hsiao;Yi-Wei Huang;Ching-Tung Hung;Tzu-Kuan Chuang;Pin-Wei Chen;Jui-Te Huang;Chao-Chun Hsu;Andrea Censi;Michael Benjamin;Chi-Fang Chen;Hsueh-Cheng Wang",
        "authorids": "/37087322854;/38239779800;/37086454577;/37086859431;/37086453371;/37088732988;/37088734706;/37088746146;/37398994000;/37425900600;/37423343700;/37066008300;/37087322854;/38239779800;/37086454577;/37086859431;/37086453371;/37088732988;/37088734706;/37088746146;/37398994000;/37425900600;/37423343700;/37066008300",
        "aff": "Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Engineering Science and Ocean Engineering, National Taiwan University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Switzerland; Department of Mechanical Engineering, Massachusetts Institute of Technology, USA; Department of Engineering Science and Ocean Engineering, National Taiwan University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967798/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4339174669389017541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;1;0;0;0;0;2;3;1;0",
        "aff_unique_norm": "National Chiao Tung University;National Taiwan University;ETH Zurich;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Engineering Science and Ocean Engineering;Department of Mechanical and Process Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.ntu.edu.tw;https://www.ethz.ch;https://web.mit.edu",
        "aff_unique_abbr": "NCTU;NTU;ETH;MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;2;0;0",
        "aff_campus_unique": "Taiwan;;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1;2;0;0",
        "aff_country_unique": "China;Switzerland;United States"
    },
    {
        "id": "8967668",
        "title": "Dynamic Control of Soft Robots with Internal Constraints in the Presence of Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of effective reduced order models for soft robots is paving the way toward the development of a new generation of model based techniques, which leverage classic rigid robot control. However, several soft robot features differentiate the soft-bodied case from the rigid-bodied one. First, soft robots are built to work in the environment, so the presence of obstacles in their path should always be explicitly accounted by their control systems. Second, due to the complex kinematics, the actuation of soft robots is mapped to the state space nonlinearly resulting in spaces with different sizes. Moreover, soft robots often include internal constraints and thus actuation is typically limited in the range of action and it is often unidirectional. This paper proposes a control pipeline to tackle the challenge of controlling soft robots with internal constraints in environments with obstacles. We show how the constraints on actuation can be propagated and integrated with geometrical constraints, taking into account physical limits imposed by the presence of obstacles. We present a hierarchical control architecture capable of handling these constraints, with which we are able to regulate the position in space of the tip of a soft robot with the discussed characteristics.",
        "primary_area": "",
        "author": "Cosimo Della Santina;Antonio Bicchi;Daniela Rus;Cosimo Della Santina;Antonio Bicchi;Daniela Rus",
        "authorids": "/37085627033;/37278626700;/37279652300;/37085627033;/37278626700;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology 32 Vassar St, Cambridge, MA, USA; Research Center \u201cE. Piaggio\u201d and the, University of Pisa, Italy; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology 32 Vassar St, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967668/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17136855739053537753&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Pisa",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Research Center \u201cE. Piaggio\u201d",
        "aff_unique_url": "https://web.mit.edu;https://www.unipi.it",
        "aff_unique_abbr": "MIT;UNIP",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "8968003",
        "title": "Dynamic Density Topological Structure Generation for Real-Time Ladder Affordance Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method with dynamic density topological structure generation for low-cost real-time vertical ladder detection from 3D point cloud data. Dynamic Density Growing Neural Gas (DD-GNG) is proposed to generate a dynamic density of the topological structure. The density of the structure and the number of nodes will be increased in the targeted object area. Feature extraction model is required to classify suspected objects for being processed in the next time process. After that, rungs of the vertical ladder is processed using an inlier-outlier method. Thus, the ladder detection model represents the ladder with a set of nodes and edges. Next, affordance detection is processed for detecting the feasible grasped location. To validate the effectiveness of the proposed method, a series of experiments are conducted on a 4-legged robot with a non-GPU board for real-time vertical ladder detection and climbing to validate the effectiveness of the proposed method. Results show that our proposed method able to detect and track the ladder structure in real-time with a much lower computational cost. The affordance of the ladder provides safety information for robot grasping.",
        "primary_area": "",
        "author": "Azhar Aulia Saputra;Wei Hong Chin;Yuichiro Toda;Naoyuki Takesue;Naoyuki Kubota;Azhar Aulia Saputra;Wei Hong Chin;Yuichiro Toda;Naoyuki Takesue;Naoyuki Kubota",
        "authorids": "/37085403752;/37085658939;/37720856200;/37295990600;/37275324300;/37085403752;/37085658939;/37720856200;/37295990600;/37275324300",
        "aff": "Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan; Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan; Graduate School of Natural Science, Okayama University, Okayama, Japan; Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan; Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968003/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11470222584579421555&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Tokyo Metropolitan University;Okayama University",
        "aff_unique_dep": "Graduate School of System Design;Graduate School of Natural Science",
        "aff_unique_url": "https://www.tmuc.ac.jp;https://www.okayama-u.ac.jp",
        "aff_unique_abbr": "TMU;Okayama U",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Hino;Okayama",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968161",
        "title": "Dynamic Flex-and-Flip Manipulation of Deformable Linear Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the technique of flex-and-flip manipulation. It is suitable for grasping thin, flexible linear objects lying on a flat surface. During the manipulation process, the object is first flexed by a robotic gripper whose fingers are placed on top of it, and later the increased internal energy of the object helps the gripper obtain a stable pinch grasp while the object flips into the space between the fingers. The dynamic interaction between the flexible object and the gripper is elaborated by analyzing how energy is exchanged. We also discuss the condition on friction to prevent loss of contact. Our flex-and-flip manipulation technique can be implemented with open-loop control and lends itself to underactuated, compliant finger mechanism. A set of experiments in robotic page turning performed with our customized hardware and software system demonstrates the effectiveness and robustness of the manipulation technique.",
        "primary_area": "",
        "author": "Chunli Jiang;Abdullah Nazir;Ghasem Abbasnejad;Jungwon Seo;Chunli Jiang;Abdullah Nazir;Ghasem Abbasnejad;Jungwon Seo",
        "authorids": "/37089640314;/37086938255;/37085382041;/38252779400;/37089640314;/37086938255;/37085382041;/38252779400",
        "aff": "The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; Departments of Mechanical and Aerospace/-Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968161/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5133901431793541897&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968560",
        "title": "Dynamic Input for Deep Reinforcement Learning in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real-world decision making problems, reaching an optimal decision requires taking into account a variable number of objects around the agent. Autonomous driving is a domain in which this is especially relevant, since the number of cars surrounding the agent varies considerably over time and affects the optimal action to be taken. Classical methods that process object lists can deal with this requirement. However, to take advantage of recent high-performing methods based on deep reinforcement learning in modular pipelines, special architectures are necessary. For these, a number of options exist, but a thorough comparison of the different possibilities is missing. In this paper, we elaborate limitations of fully-connected neural networks and other established approaches like convolutional and recurrent neural networks in the context of reinforcement learning problems that have to deal with variable sized inputs. We employ the structure of Deep Sets in off-policy reinforcement learning for high-level decision making, highlight their capabilities to alleviate these limitations, and show that Deep Sets not only yield the best overall performance but also offer better generalization to unseen situations than the other approaches.",
        "primary_area": "",
        "author": "Maria Huegle;Gabriel Kalweit;Branka Mirchevska;Moritz Werling;Joschka Boedecker;Maria Huegle;Gabriel Kalweit;Branka Mirchevska;Moritz Werling;Joschka Boedecker",
        "authorids": "/37087322877;/37087323482;/37086546750;/37542759200;/37888921900;/37087322877;/37087323482;/37086546750;/37542759200;/37888921900",
        "aff": "Dept. of Computer Science, University of Freiburg, Germany; Dept. of Computer Science, University of Freiburg, Germany; BMWGroup, Unterschleissheim, Germany; BMWGroup, Unterschleissheim, Germany; Dept. of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968560/",
        "gs_citation": 95,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2617917098979957378&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Freiburg;BMW Group",
        "aff_unique_dep": "Dept. of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.bmwgroup.com",
        "aff_unique_abbr": "Uni Freiburg;BMW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967906",
        "title": "Dynamic Spatiotemporal Pattern Identification and Analysis Using a Fingertip-based Electro-Tactile Display Array",
        "track": "main",
        "status": "Poster",
        "abstract": "This study is designed to validate the feasibility of generating identifiable moving patterns using electro-tactile stimulation. An electro-tactile display is built using an array of 16 contacts to deliver the electrical signal to the fingertip skin. This signal can have varying voltages, frequencies or duty cycles to form the most comfortable sensation. Moving patterns can be generated by individually or collectively switching on or off the contacts on the display. This is done to stimulate a moving pattern. In this case, a moving pattern is comparable to a group of frame-by-frame pictures constructing a movie. Similarly, by toggling the contacts in a specific order, a moving pattern can be achieved. A program on a single-board computer (Raspberry Pi) was used to control and generate 6 different patterns. These patterns are delivered to the display and consequently to the fingertip skin of the participants. A total of 8 subjects participated in this study. They filled a questionnaire to indicate the corresponding movement. The results of these experiments were analyzed and a conclusion regarding the direction of the movement was drawn. It became clear that the direction of the movement had a significant impact on the recognition of the patterns.",
        "primary_area": "",
        "author": "Mehdi Rahimi;Fang Jiang;Cang Ye;Yantao Shen;Mehdi Rahimi;Fang Jiang;Cang Ye;Yantao Shen",
        "authorids": "/37085381800;/37087049985;/37291591400;/37274462800;/37085381800;/37087049985;/37291591400;/37274462800",
        "aff": "Department of Electrical and Biomedical Engineering, University of Nevada-Reno, NV, USA; Department of Psychology, University of Nevada-Reno, NV, USA; Department of Computer Science, Virginia Commonwealth University, VA, USA; Department of Electrical and Biomedical Engineering, University of Nevada-Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967906/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15072075784129680019&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Nevada, Reno;Virginia Commonwealth University",
        "aff_unique_dep": "Department of Electrical and Biomedical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.unr.edu;https://www.vcu.edu",
        "aff_unique_abbr": "UNR;VCU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Reno;Richmond",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967923",
        "title": "Dynamic Task Control Method of a Flexible Manipulator Using a Deep Recurrent Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The flexible body has advantages over the rigid body in terms of environmental contact thanks to its underactuation. On the other hand, when applying conventional control methods to realize dynamic tasks with the flexible body, there are two difficulties: accurate modeling of the flexible body and the derivation of intermediate postures to achieve the tasks. Learning-based methods are considered to be more effective than accurate modeling, but they require explicit intermediate postures. To solve these two difficulties at the same time, we developed a real-time task control method with a deep recurrent neural network named Dynamic Task Execution Network (DTXNET), which acquires the relationship among the control command, robot state including image information, and task state. Once the network is trained, only the target event and its timing are needed to realize a given task. To demonstrate the effectiveness of our method, we applied it to the task of Wadaiko (traditional Japanese drum) drumming as an example, and verified the best configuration of DTXNET.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Toru Ogawa;Cota Nabeshima;Kento Kawaharazuka;Toru Ogawa;Cota Nabeshima",
        "authorids": "/37086101930;/37086937035;/37947185000;/37086101930;/37086937035;/37947185000",
        "aff": "Department of Mechano-Informatics, The University of Tokyo; Preferred Networks, Inc.; Preferred Networks, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967923/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12851121376661682253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Tokyo;Preferred Networks, Inc.",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.preferred-networks.com",
        "aff_unique_abbr": "UTokyo;PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968165",
        "title": "EARLY FUSION for Goal Directed Robotic Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Building perceptual systems for robotics which perform well under tight computational budgets requires novel architectures which rethink the traditional computer vision pipeline. Modern vision architectures require the agent to build a summary representation of the entire scene, even if most of the input is irrelevant to the agent's current goal. In this work, we flip this paradigm, by introducing EARLYFUSION vision models that condition on a goal to build custom representations for downstream tasks. We show that these goal specific representations can be learned more quickly, are substantially more parameter efficient, and more robust than existing attention mechanisms in our domain. We demonstrate the effectiveness of these methods on a simulated item retrieval problem that is trained in a fully end-to-end manner via imitation learning.",
        "primary_area": "",
        "author": "Aaron Walsman;Yonatan Bisk;Saadia Gabriel;Dipendra Misra;Yoav Artzi;Yejin Choi;Dieter Fox;Aaron Walsman;Yonatan Bisk;Saadia Gabriel;Dipendra Misra;Yoav Artzi;Yejin Choi;Dieter Fox",
        "authorids": "/37085357749;/37086936955;/37087322059;/37087232827;/37087232485;/37085726739;/37284329000;/37085357749;/37086936955;/37087322059;/37087232827;/37087232485;/37085726739;/37284329000",
        "aff": "Paul G. Allen School of Computer Science and Engineering, University of Washington; Paul G. Allen School of Computer Science and Engineering, University of Washington; Paul G. Allen School of Computer Science and Engineering, University of Washington; Cornell University; Cornell University; Paul G. Allen School of Computer Science and Engineering, University of Washington; Paul G. Allen School of Computer Science and Engineering, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968165/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4824103666654548855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "University of Washington;Cornell University",
        "aff_unique_dep": "Paul G. Allen School of Computer Science and Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UW;Cornell",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967705",
        "title": "EPN: Edge-Aware PointNet for Object Recognition from Multi-View 2.5D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Performance of current 3D point based detectors is limited by the number of points they can process, consequently limiting their accuracy. In this paper we propose a novel architecture coined as Edge-Aware PointNet, that incorporates geometric shape priors as binary maps, integrated in parallel with the PointNet++ framework, through convolutional neural networks (CNNs). The proposed architecture takes individual object instances as input and learns the task of object recognition for 3D shapes. To train the network, we present a dataset of 31k 2.5D synthetic point clouds rendered from ModelNet40. Through 2.5D representation, the network learns object recognition despite occlusion that enables improved performance on objects from real world, while 2D binary maps enable feature learning that is independent of number of points in the point cloud. Comprehensive experimentation shows that the proposed network is able to improve performance by 2.5% on ModelNet40 and 2.6% on ModelNet10 datasets, as compared to the baseline PointNet++. We also show improved performance as compared to state-of-the-art methods, on a real world RGBD dataset where our network improves results by 8%. Our code and dataset is publicly available at github.com/Merium88/Edge-Aware-PointNet.",
        "primary_area": "",
        "author": "Syeda Mariam Ahmed;Pan Liang;Chee Meng Chew;Syeda Mariam Ahmed;Pan Liang;Chee Meng Chew",
        "authorids": "/37085641472;/37087322790;/37289929100;/37085641472;/37087322790;/37289929100",
        "aff": "Department of Mechanical Engineering, National University of Singapore; Advanced Robotics Center, National University of Singapore; Department of Mechanical Engineering, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967705/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14964176048930563338&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8967937",
        "title": "ESKO6d - A Binocular and RGB-D Dataset of Stored Kitchen Objects with 6d Poses",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object pose estimation especially for stored porcelain and glass crockery in kitchen scenes. Specifically the ESKO 6d (EASE Stored Kitchen Objects with 6d poses) dataset features texture-less, glossy or glassy ordinary used objects which were naturally stored in a cupboard, drawer or dishwasher. There is a large degree of occlusion being the specific challenge in these scenes. Each scene was recorded in video sequences by two cameras (RGB-D (Kinect) and binocular) within multiple setup stages. The dataset contains an RGB-D image or binocular RGB image plus stereo-matched depth image as well as 6d pose ground truth and instance segmentation. Our dataset contains twelve stored object scenes with a combined amount of 47 video sequences captured by each camera, resulting in over 17k annotated Kinect images and more than 42k annotated stereo images showing around 50 different objects. The ground truth annotation is precise to 3. 5mm ADD (details see paper). The dataset can be accessed under http://www.informatik.uni-bremen.de/esko6d-dataset. Besides the concrete dataset we propose a method of ground truth pose measurement based on an external 3d tracking system that allows on the one hand to precisely measure the object\u2019s pose inside a tight packed storage and on the other hand to obtain the object pose in several images with just one manual measurement.",
        "primary_area": "",
        "author": "Jesse Richter-Klug;Constantin Wellhausen;Udo Frese;Jesse Richter-Klug;Constantin Wellhausen;Udo Frese",
        "authorids": "/37087322060;/37087323599;/37419163800;/37087322060;/37087323599;/37419163800",
        "aff": "Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany; Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany; Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967937/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7016581205073820792&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Faculty of Mathematics and Computer Science",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968520",
        "title": "EV-IMO: Motion Segmentation Dataset and Learning Pipeline for Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first event-based learning approach for motion segmentation in indoor scenes and the first event-based dataset - EV-IMO- which includes accurate pixel-wise motion masks, egomotion and ground truth depth. Our approach is based on an efficient implementation of the SfM learning pipeline using a low parameter neural network architecture on event data. In addition to camera egomotion and a dense depth map, the network estimates independently moving object segmentation at the pixel-level and computes per-object 3D translational velocities of moving objects. We also train a shallow network with just 40k parameters, which is able to compute depth and egomotion. Our EV-IMO dataset features 32 minutes of indoor recording with up to 3 fast moving objects in the camera field of view. The objects and the camera are tracked using a VICON\u00ae motion capture system. By 3D scanning the room and the objects, ground truth of the depth map and pixel-wise object masks are obtained. We then train and evaluate our learning pipeline on EV-IMO and demonstrate that it is well suited for scene constrained robotics applications. SUPPLEMENTARY MATERIAL The supplementary video, code, trained models, appendix and a dataset will be made available at http://prg.cs.umd.edu/EV-IMO.html.",
        "primary_area": "",
        "author": "Anton Mitrokhin;Chengxi Ye;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Tobi Delbruck;Anton Mitrokhin;Chengxi Ye;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Tobi Delbruck",
        "authorids": "/37086581371;/37086125021;/37269887600;/37282631400;/37269976700;/37086581371;/37086125021;/37269887600;/37282631400;/37269976700",
        "aff": "University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; Department of Neuroinformatics, ETH Zurich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968520/",
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13933257485342902997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Maryland;ETH Zurich",
        "aff_unique_dep": "Institute for Advanced Computer Studies;Department of Neuroinformatics",
        "aff_unique_url": "https://www/umd.edu;https://www.ethz.ch",
        "aff_unique_abbr": "UMD;ETHZ",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "College Park;Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "8968070",
        "title": "Effect of Planning Period on MPC-based Navigation for a Biped Robot in a Crowd",
        "track": "main",
        "status": "Poster",
        "abstract": "We control a biped robot moving in a crowd with a Model Predictive Control (MPC) scheme that generates stable walking motions, with automatic footstep placement. Most walking strategies propose to re-plan the walking motion to adapt to changing environments only once at every footstep. This is because a footstep is planted on the ground, it usually stays there at a constant position until the next footstep is initiated, what naturally constrains the capacity for the robot to react and adapt its motion in between footsteps. The objective of this paper is to measure if re-planning the walking motion more often than once at every footstep can lead to an improvement in collision avoidance when navigating in a crowd. Our result is that re-planning twice (or more) during each footstep leads to a significant reduction of the number of collisions when walking in a crowd, but depends on the density of the crowd.",
        "primary_area": "",
        "author": "Matteo Ciocca;Pierre-Brice Wieber;Thierry Fraichard;Matteo Ciocca;Pierre-Brice Wieber;Thierry Fraichard",
        "authorids": "/37086171985;/37295495700;/37275795700;/37086171985;/37295495700;/37275795700",
        "aff": "LIG, Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France; LIG, Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968070/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11498881058897307316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University Grenoble Alpes;Universite Grenoble Alpes",
        "aff_unique_dep": "Laboratoire d'Informatique de Grenoble (LIG);",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA;UGA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Grenoble",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968212",
        "title": "Effect of Vibration on Twisted String Actuation Through Conduit at High Bending Angles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies an effect of vibration on twisted string actuation through conduit at high bending angles. In our previous work [1], we have demonstrated that twisted string actuators can be used to transmit power even at significant deflection angles of the conduit. However, several undesirable effects, namely pull-back, hysteresis, and chattering, were present during actuation due to friction between strings and the internal sheath of the conduit. This paper reports the results of experimental study on effects of vibration on twisted string actuation inside deflected conduits. We have demonstrated that applying vibration generated near natural frequency of the system during the later stages of twisting and untwisting cycles helped reduce pull-back and hysteresis and increase string contraction. In case when sheath was deflected by 180\u00b0 under a constant load of 3 kg, we were able to achieve over 70% decrease in pull-back and 30% decrease in hysteresis, compared with no vibration case.",
        "primary_area": "",
        "author": "Donghyee Lee;Igor Gaponov;Jee-Hwan Ryu;Donghyee Lee;Igor Gaponov;Jee-Hwan Ryu",
        "authorids": "/37087322043;/37691627300;/37274994300;/37087322043;/37691627300;/37274994300",
        "aff": "School of Mechanical Engineering, KOREATECH, Cheonan, South Korea; Faculty of Computer Science and Engineering, Innopolis University, Innopolis, Russia; Dept. of Civil and Environmental Engineering, KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968212/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=750603771567638002&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Korea University of Technology and Education;Innopolis University;KAIST",
        "aff_unique_dep": "School of Mechanical Engineering;Faculty of Computer Science and Engineering;Dept. of Civil and Environmental Engineering",
        "aff_unique_url": "http://www.koreatech.ac.kr;;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KOREATECH;;KAIST",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Cheonan;Innopolis;Daejeon",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "South Korea;Russian Federation"
    },
    {
        "id": "8968302",
        "title": "Effect of arm swinging and trunk twisting on bipedal locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "It is expected that human locomotion, in which the trunk twists and arms swing, provides stability as well as compensation for the angular momentum because the trunk and arms are placed over legs and then their position and the acceleration influence the bipedal locomotion. This paper presents a bipedal robot equipped with a trunk, embedding a viscoelastic joint and two arms away from the midline of the trunk. Physical experiments show that a passive oscillation of the viscoelastic trunk joint around the yaw axis vertical to the ground and a swing of heavy arms provided an oscillation of zero moment point (ZMP) in the lateral direction and a small oscillation in the anteroposterior direction. This is despite the fact that the robot does not have a roll joint and the arm swings back and forth. Numerical analysis supports the results of the physical experiments through a simple model and by expressing ZMP trajectory, showing that the arm swinging facilitates antiphase locomotion in which right arm and left leg swings ahead and vice versa.",
        "primary_area": "",
        "author": "Ryo Onishi;Ryoma Kitamura;Takashi Takuma;Wataru Kase;Ryo Onishi;Ryoma Kitamura;Takashi Takuma;Wataru Kase",
        "authorids": "/37087321897;/37087323506;/37287479300;/37297686500;/37087321897;/37087323506;/37287479300;/37297686500",
        "aff": "Faculty of Engineering, Osaka Institute of Technology, Japan; Faculty of Engineering, Osaka Institute of Technology, Japan; Faculty of Engineering, Osaka Institute of Technology, Japan; Faculty of Engineering, Osaka Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968302/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3309968974009128355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Osaka Institute of Technology",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://www.oit.ac.jp",
        "aff_unique_abbr": "OIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968206",
        "title": "Effects of Limb Morphology on Transient Locomotion in Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The natural world hosts a few mammals that display both a high degree of agility and speed. However these animals have complex leg morphologies. Robot designers are thus faced with the dilemma of which morphology to employ when designing the next generation of agile legged robots. Thus this letter presents a novel investigation into the effects of limb morphology of quadrupeds during rapid transient maneuvers such as acceleration and deceleration. Three leg configurations inspired by nature (O-, X-Type and All-Ankle) as well as All-Knee configurations are compared. Extensive large scale Monte Carlo simulations utilizing contact-implicit trajectory optimization methods were employed on 100 randomly generated robots of varying sizes to determine the optimal configuration for the task of rapid transient locomotion. After extensive analysis, the investigation revealed that an X-Type leg configuration outperformed all other configurations. Ultimately, these results will provide insight for the mechanical design of future agile quadruped robots.",
        "primary_area": "",
        "author": "Leanne Raw;Callen Fisher;Amir Patel;Leanne Raw;Callen Fisher;Amir Patel",
        "authorids": "/37087325083;/37085623300;/38029333400;/37087325083;/37085623300;/38029333400",
        "aff": "Faculty of Electrical Engineering, University of Cape Town, Rondebosch, South Africa; Faculty of Electrical Engineering, University of Cape Town, Rondebosch, South Africa; Faculty of Electrical Engineering, University of Cape Town, Rondebosch, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968206/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15047365995471452329&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.uct.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rondebosch",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "8967965",
        "title": "Effects of a Bio-mimicked Flapping Path on Propulsion Efficiency of Two-segmental Fish Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Having an appropriate flapping path to yield efficient propulsion is an interesting issue in fish robotics. In most works, especially two-segmental structures, the flapping motion is limited to sinusoidal functions. In this paper, to cope with the aforementioned limitation, a conceptual non-sinusoidal path is proposed. The proposed flapping path and the conventional one, both are optimized for a sample fish robot. According to some simulation results, it is shown that if a proper actuator is employed to generate both optimized paths, the proposed approach yields more propulsion efficiency. Furthermore, it is discussed that our method can better imitate fish muscle output power. Finally, through experiments, some practical issues are considered.",
        "primary_area": "",
        "author": "Majid Abedinzadeh Shahri;Ali Rouhollahi;Majid Nili Ahmadabadi;Majid Abedinzadeh Shahri;Ali Rouhollahi;Majid Nili Ahmadabadi",
        "authorids": "/37085576735;/37086357121;/37293861300;/37085576735;/37086357121;/37293861300",
        "aff": "Cognitive Systems Lab., School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; Cognitive Systems Lab., School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; Cognitive Systems Lab., School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967965/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4862790349437080192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tehran",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ut.ac.ir",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tehran",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Iran"
    },
    {
        "id": "8968563",
        "title": "Efficient Environment Guided Approach for Exploration of Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Remote inspection of a complex environment is a difficult, time consuming task for human operators to perform. The need to manually avoid obstacles whilst considering other performance factors i.e. time taken, joint effort and information gained represents significant challenges to continuous operation. This paper proposes an autonomous robotic solution for exploration of an unknown, complex environment using a high DoF robot arm with an eye in hand depth sensor. The main contribution of this work is a new strategy to find the next best view by evaluating frontier regions of the map to maximise coverage, in contrast to many current approaches which densely sample joint or workspace configurations of the robot. Multiple utility functions were evaluated that showed different behaviours. Our results indicated that the presented algorithm can explore an arbitrary environment efficiently while optimising various performance criteria based on the utility function chosen, application constraints and the desires of the user.",
        "primary_area": "",
        "author": "Daniel Butters;Emil T. Jonasson;Robert Stuart-Smith;Vijay M. Pawar;Daniel Butters;Emil T. Jonasson;Robert Stuart-Smith;Vijay M. Pawar",
        "authorids": "/37086578643;/37087322186;/37086575032;/38191148100;/37086578643;/37087322186;/37086575032;/38191148100",
        "aff": "Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Remote Applications in Challenging Environments (RACE), UK Atomic Energy Authority, Culham Science Centre, Abingdon, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968563/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=741218638649471416&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University College London;UK Atomic Energy Authority",
        "aff_unique_dep": "Autonomous Manufacturing Laboratory;Remote Applications in Challenging Environments (RACE)",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ukaea.ukri.org",
        "aff_unique_abbr": "UCL;UKAEA",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Gower Street;Culham Science Centre",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968044",
        "title": "Efficient and Guaranteed Planar Pose Graph optimization Using the Complex Number Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present CPL-Sync, a certifiably correct algorithm to solve planar pose graph optimization (PGO) using the complex number representation. We formulate planar PGO as the maximum likelihood estimation (MLE) on the product of unit complex numbers, and relax this nonconvex quadratic complex optimization problem to complex semidefinite programming (SDP). Furthermore, we simplify the corresponding semidefinite programming to Riemannian staircase optimization (RSO) on complex oblique manifolds that can be solved with the Riemannian trust region (RTR) method. In addition, we prove that the SDP relaxation and RSO simplification are tight as long as the noise magnitude is below a certain threshold. The efficacy of this work is validated through comparisons with existing methods as well as applications on planar PGO in simultaneous localization and mapping (SLAM), which indicates that the proposed algorithm is capable of solving planar PGO certifiably, and is more efficient in numerical computation and more robust to measurement noises than existing state-of-the-art methods. The C++ code for CPL-Sync is available at https://github.com/fantaosha/CPL-Sync.",
        "primary_area": "",
        "author": "Taosha Fan;Hanlin Wang;Michael Rubenstein;Todd Murphey;Taosha Fan;Hanlin Wang;Michael Rubenstein;Todd Murphey",
        "authorids": "/37085741874;/37087323331;/37282496500;/37329499800;/37085741874;/37087323331;/37282496500;/37329499800",
        "aff": "McCormick School of Engineering, Northwestern University, Evanston, IL, USA; McCormick School of Engineering, Northwestern University, Evanston, IL, USA; McCormick School of Engineering, Northwestern University, Evanston, IL, USA; McCormick School of Engineering, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968044/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2719039487697946721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "McCormick School of Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967573",
        "title": "Eigen-Factors: Plane Estimation for Multi-Frame and Time-Continuous Point Cloud Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce the Eigen-Factor (EF) method, which estimates a planar surface from a set of point clouds (PCs), with the peculiarity that these points have been observed from different poses, i.e. the trajectory described by a sensor. We propose to use multiple Eigen-Factors (EFs) or different planes' estimations, that allow to solve the multi-frame alignment over a sequence of observed PCs. Moreover, the complexity of the EFs optimization is independent of the number of points, but depends on the number of planes and poses. To achieve this, a closed-form of the gradient is derived by differentiating over the minimum eigenvalue with respect to poses, hence the name Eigen-Factor. In addition, a time-continuous trajectory version of EFs is proposed. The EFs approach is evaluated on a simulated environment and compared with two variants of ICP, showing that it is possible to optimize over all point errors, improving both the accuracy and computational time. Code has been made publicly available.",
        "primary_area": "",
        "author": "Gonzalo Ferrer;Gonzalo Ferrer",
        "authorids": "/38469245200;/38469245200",
        "aff": "Skolkovo Institute of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967573/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4529875076885225712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.skoltech.ru",
        "aff_unique_abbr": "Skoltech",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "8968121",
        "title": "ElevateNet: A Convolutional Neural Network for Estimating the Missing Dimension in 2D Underwater Sonar Images",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we address the challenge of predicting the missing dimension (elevation angle) from 2D underwater sonar images. The high noise levels in these images, from phenomena such as non-diffuse reflections, frequently limits the usefulness of physical models. We thus propose the utilization of Convolutional Neural Networks (CNNs) as a powerful method to extract meaningful information without being misled by noisy data. We also introduce a self-supervised method that uses the physics of the sonar sensor to train the network on real data without ground-truth elevation maps. Our method can produce accurate elevation angle estimates given only a single image. Finally, we demonstrate that our method produces more accurate 3D reconstructions than competing methods, both in simulation and on real data.",
        "primary_area": "",
        "author": "Robert DeBortoli;Fuxin Li;Geoffrey A. Hollinger;Robert DeBortoli;Fuxin Li;Geoffrey A. Hollinger",
        "authorids": "/37086455190;/37533886800;/37543482700;/37086455190;/37533886800;/37543482700",
        "aff": "The Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon; The Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon; The Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968121/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10129153449185853641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "The Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967626",
        "title": "Empirical Characterization of a High-performance Exterior-rotor Type Brushless DC Motor and Drive",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, brushless motors with especially high torque densities have been developed for applications in autonomous aerial vehicles (i.e. drones), which usually employ exterior rotortype geometries (ER-BLDC motors). These motors are promising for other applications, such as humanoids and wearable robots; however, the emerging companies that produce motors for drone applications do not typically provide adequate technical specifications that would permit their general use across robotics-for example, the specifications are often tested in unrealistic forced convection environments, or are drone-specific, such as thrust efficiency. Furthermore, the high magnetic pole count in many ER-BLDC motors restricts the brushless drives able to efficiently commutate these motors at speeds needed for lightly-geared operation. This paper provides an empirical characterization of a popular ER-BLDC motor and a new brushless drive, which includes efficiencies of the motor across different power regimes, identification of the motor transfer function coefficients, thermal response properties, and closed loop control performance in the time and frequency domains. The intent of this work is to serve as a benchmark and reference for other researchers seeking to utilize these exciting and emerging motor geometries.",
        "primary_area": "",
        "author": "Ung Hee Lee;Chen-Wen Pan;Elliott J. Rouse;Ung Hee Lee;Chen-Wen Pan;Elliott J. Rouse",
        "authorids": "/37085897953;/37087322952;/37991140400;/37085897953;/37087322952;/37991140400",
        "aff": "Department of Mechanical Engineering, Robotics Institute, University of Michigan, Ann Arbor, USA; Robotics Institute, University of Michigan, Ann Arbor, USA; Department of Mechanical Engineering, Robotics Institute, University of Michigan, Ann Arbor, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967626/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10458383776967798969&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967939",
        "title": "Employing Magnets to Improve the Force Exertion Capabilities of Adaptive Robot Hands in Precision Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive, underactuated and compliant robot hands have received an increased interest over the last decade. Possible applications of these systems range from the development of simple grippers for industrial automation to the creation of anthropomorphic devices that can be used as prosthetic hands. These hands are particularly capable of extracting stable grasps even under significant object pose or other environmental uncertainties, due to the underactuation and the structural compliance of their designs. Despite the increased interest and the promising performance, adaptive hands suffer from several disadvantages and drawbacks. For example, the use of underactuation can lead to a post-contact reconfiguration of the fingers that compromises the force exertion capabilities of the system during pinch grasping. In this paper, we focus on the design, modelling, development, and evaluation of an adaptive robot gripper that uses magnets to adjust the reconfiguration profile of the fingers. The effect of the magnets increases the gripper's force exertion capabilities in pinch grasps, without compromising the full/caging grasps. The efficiency of the proposed gripper is experimentally validated through two different tests: i) a contact force test that compares the results of a theoretical model with the actual experimental results and ii) a grasping test that assesses the force exertion capabilities and the reconfiguration behaviour of the adaptive fingers for different implementations of the magnetic joints.",
        "primary_area": "",
        "author": "Lucas Gerez;Geng Gao;Minas Liarokapis;Lucas Gerez;Geng Gao;Minas Liarokapis",
        "authorids": "/37086448935;/37087027460;/38558084100;/37086448935;/37087027460;/38558084100",
        "aff": "New Dexterity research group, University of Auckland, New Zealand; New Dexterity research group, University of Auckland, New Zealand; New Dexterity research group, University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967939/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=986282886269499235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "New Dexterity research group",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "8967772",
        "title": "Employing Whole-Body Control in Assistive Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Light-weight robotic manipulators in combination with power wheelchairs can help to restore the mobility of people with disabilities. While such systems are available on the market, they typically are limited to fully manual control modes. In research, shared control methods are employed, to increase the usability of these systems. Here, we present an additional extension, by introducing a whole-body control concept to the assistive robotic system EDAN. Combined with shared control, the whole-body controller allows the realization of complex tasks which necessitate the coordination of arm and platform, while ensuring compliant behavior resulting from the impedance control law. The implemented approach is analyzed and validated in an exemplary task of opening a door, passing through it and closing it afterwards. While this task would exceed the reachability of the arm in a classical approach, the combination of whole-body control with a shared control scheme allows for quick and efficient execution.",
        "primary_area": "",
        "author": "Maged Iskandar;Gabriel Quere;Annette Hagengruber;Alexander Dietrich;J\u00f6rn Vogel;Maged Iskandar;Gabriel Quere;Annette Hagengruber;Alexander Dietrich;J\u00f6rn Vogel",
        "authorids": "/37086454969;/37086933696;/37086040849;/37970388100;/37602887100;/37086454969;/37086933696;/37086040849;/37970388100;/37602887100",
        "aff": "German Aerospace Center(DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center(DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center(DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center(DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center(DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967772/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2967000625763996991&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968473",
        "title": "Empowered Optical Inspection by Using Robotic Manipulator in Industrial Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Nowadays the inspection of products at the end of line represents a critical phase. At this stage, it is necessary to look for defects in order to prevent the quality check to fail, and to provide information for improving the production as well. This task can be performed by using several sensing technologies, and the contactless optical inspection plays a key role. In this regard, the use of advanced robotic manipulators offers the capability to change the viewpoint of a given object and to inspect its multiple faces. We propose an approach that combines the use of photometric stereo to derive a 3D model of objects, empowered by the super-resolution that is applied on the original dataset (upstream) or on the normal images (downstream) in order to increase the quality of the final 3D model. The vision system is mounted on a robotic manipulator, able to grasp and change the viewpoint, thus offering a more complete view of the object to be inspected. The obtained results show that the developed solution increases the quality of the derived 3D models used for inspection tasks on different faces of the objects; this is achieved by using the manipulation ability offered by the adopted robotic platform.",
        "primary_area": "",
        "author": "Alessandro Galdelli;Daniele Proietti Pagnotta;Adriano Mancini;Alessandro Freddi;Andrea Monteri\u00f9;Emanuele Frontoni;Alessandro Galdelli;Daniele Proietti Pagnotta;Adriano Mancini;Alessandro Freddi;Andrea Monteri\u00f9;Emanuele Frontoni",
        "authorids": "/37086448818;/37085406271;/38182762500;/37592408000;/37546782400;/37300940500;/37086448818;/37085406271;/38182762500;/37592408000;/37546782400;/37300940500",
        "aff": "Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 Politecnica delle Marche, Ancona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968473/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6897136486262648469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e0 Politecnica delle Marche",
        "aff_unique_dep": "Dipartimento di Ingegneria dell\u2019Informazione",
        "aff_unique_url": "https://www.univpm.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ancona",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968120",
        "title": "Enabling Human-Like Task Identification From Natural Conversation",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot as a coworker or a cohabitant is becoming mainstream day-by-day with the development of low-cost sophisticated hardware. However, an accompanying software stack that can aid the usability of the robotic hardware remains the bottleneck of the process, especially if the robot is not dedicated to a single job. Programming a multi-purpose robot requires an on the fly mission scheduling capability that involves task identification and plan generation. The problem dimension increases if the robot accepts tasks from a human in natural language. Though recent advances in NLP and planner development can solve a variety of complex problems, their amalgamation for a dynamic robotic task handler is used in a limited scope. Specifically, the problem of formulating a planning problem from natural language instructions is not studied in details. In this work, we provide a non-trivial method to combine an NLP engine and a planner such that a robot can successfully identify tasks and all the relevant parameters and generate an accurate plan for the task. Additionally, some mechanism is required to resolve the ambiguity or missing pieces of information in natural language instruction. Thus, we also develop a dialogue strategy that aims to gather additional information with minimal question-answer iterations and only when it is necessary. This work makes a significant stride towards enabling a human-like task understanding capability in a robot.",
        "primary_area": "",
        "author": "Pradip Pramanick;Chayan Sarkar;P Balamuralidhar;Ajay Kattepur;Indrajit Bhattacharya;Arpan Pal;Pradip Pramanick;Chayan Sarkar;P Balamuralidhar;Ajay Kattepur;Indrajit Bhattacharya;Arpan Pal",
        "authorids": "/37086512563;/37085392494;/37391532000;/37545391300;/37087235763;/37087322261;/37086512563;/37085392494;/37391532000;/37545391300;/37087235763;/37087322261",
        "aff": "TCS Research & Innovation, India; TCS Research & Innovation, India; TCS Research & Innovation, India; TCS Research & Innovation, India; TCS Research & Innovation, India; TCS Research & Innovation, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968120/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10521538250971309793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Research & Innovation",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968453",
        "title": "End-to-End Driving Model for Steering Control of Autonomous Vehicles with Future Spatiotemporal Features",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end deep learning has gained considerable interests in autonomous driving vehicles in both academic and industrial fields, especially in decision making process. One critical issue in decision making process of autonomous driving vehicles is steering control. Researchers has already trained different artificial neural networks to predict steering angle with front-facing camera data stream. However, existing end-to-end methods only consider the spatiotemporal relation on a single layer and lack the ability of extracting future spatiotemporal information. In this paper, we propose an end-to-end driving model based on Convolutional Long Short-Term Memory (Conv-LSTM) neural network with a Multi-scale Spatiotemporal Integration (MSI) module, which aiming to encode the spatiotemporal information from different scales for steering angle prediction. Moreover, we employ future sequential information to enhance spatiotemporal features of the end-to-end driving model. We demonstrate the efficiency of proposed end-to-end driving model on the public Udacity dataset with comparison of some existing methods. Experimental results show that the proposed model has better performances than other existing methods, especially in some complex scenarios. Furthermore, we evaluate the proposed driving model on a real-time autonomous vehicle, and results show that the proposed driving model is able to predict the steering angle with high accuracy compared to skilled human driver.",
        "primary_area": "",
        "author": "Tianhao Wu;Ao Luo;Rui Huang;Hong Cheng;Yang Zhao;Tianhao Wu;Ao Luo;Rui Huang;Hong Cheng;Yang Zhao",
        "authorids": "/37087323146;/37089014361;/37085625169;/37280209600;/37897003800;/37087323146;/37089014361;/37085625169;/37280209600;/37897003800",
        "aff": "School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968453/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5071614636408323325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "School of Automation Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967612",
        "title": "End-to-end sensorimotor control problems of AUVs with deep reinforcement learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies on sensorimotor control problems of Autonomous Underwater Vehicles (AUVs) using deep reinforcement learning. We design an end-to-end learning architecture mapping original sensor input to continuous control output without referring to the dynamics of vehicles. To avoid difficult and noisy underwater localization, we implement the learning without knowing the positions of AUVs by proposing novel state encoder and reward shaping strategies. Two distinct underwater tasks, obstacle avoidance with sonar sensor and pipeline following with visual sensor, are simulated to validate the effectiveness of proposed architecture and strategies. For the latter, we test the learned policy on realistic images of underwater pipelines to check its generalization ability.",
        "primary_area": "",
        "author": "Hui Wu;Shiji Song;Yachu Hsu;Keyou You;Cheng Wu;Hui Wu;Shiji Song;Yachu Hsu;Keyou You;Cheng Wu",
        "authorids": "/37086316547;/37332904400;/37087087066;/37391177800;/37276423900;/37086316547;/37332904400;/37087087066;/37391177800;/37276423900",
        "aff": "Department of Automation, Tsinghua University, Beijing, P.R.China; Department of Automation, Tsinghua University, Beijing, P.R.China; Department of Automation, Tsinghua University, Beijing, P.R.China; Department of Automation, Tsinghua University, Beijing, P.R.China; Department of Automation, Tsinghua University, Beijing, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967612/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4157561272960222544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968531",
        "title": "Endoscopic Bi-Manual Robotic Instrument Design Using a Genetic Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last few years, there has been a significant rise in designing small, agile and flexible medical systems that can navigate through natural orifices. In the case of endoscopic surgery, existing systems vary significantly from each other which raises the question of the existence of a general design that can do it all. In this context, this paper proposes to use a genetic algorithm combined with recorded suturing and anatomical data to automatically design a pair of robotic instruments for the i2 Snake under strict mechanical constraints. The resulting automatically generated instrument designs include a 6 degrees of freedom instrument that can follow a predefined trajectory accurately and a more simple 4 degrees of freedom instrument that can accomplish most of the task. The results also showed the importance of having a prismatic joint to gain the precision required for endoscopic surgery.",
        "primary_area": "",
        "author": "Andreas Schmitz;Pierre Berthet-Rayne;Guang-Zhong Yang;Andreas Schmitz;Pierre Berthet-Rayne;Guang-Zhong Yang",
        "authorids": "/37086334951;/37085821774;/37276270800;/37086334951;/37085821774;/37276270800",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968531/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1432911189520467261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968143",
        "title": "Energy Harvesting across Temporal Temperature Gradients using Vaporization",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy harvesting is an attractive alternative to carrying onboard power for mobile robots, especially for long duration missions. While solar is a powerful option, alternatives are needed for situations where direct sunlight is unavailable. One intriguing concept was proposed in the 17th century to power clocks: energy harvesting based on temporal, rather than spatial, temperature gradients, using a low boiling point fluid that vaporizes at ambient temperatures. This concept has many strengths: it offers all-in-one energy harvesting and storage; direct high-force and large displacement mechanical output, eliminating the need for a motor; and temporal gradients are ubiquitous, due to diurnal thermal fluctuations. The challenge for robotic applications, however, is to create large enough amounts of work in a small enough package to power a mobile device while using a non-toxic and readily available working fluid. Here we present a simple, low-cost energy harvesting actuator, powered by the vaporization of butane and isobutane, with an isobaric energy density of up to 38000 J/m3 (i.e. energy extracted per total volume expansion) each time the temperature fluctuates 13.1\u00b0C, enough to power a small car to drive 10m. Two principles enable this: i) precompression of the working fluid, allowing us to tune the boiling point and choose among many non-toxic fluids that do more work than non-compressed fluids; and ii) a constant force profile of the return springs, allowing more work than a linear spring. We present a simple model of the actuator and experimental results characterizing its behavior. Our work lays the foundation for energy harvesting across temporal temperature gradients using vaporization as a viable option for powering mobile robots.",
        "primary_area": "",
        "author": "Charles Xiao;Nicholas D. Naclerio;Elliot W. Hawkes;Charles Xiao;Nicholas D. Naclerio;Elliot W. Hawkes",
        "authorids": "/37087322201;/37086581043;/37681388800;/37087322201;/37086581043;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California Santa Barbara, Santa Barbara, USA; Department of Mechanical Engineering, University of California Santa Barbara, Santa Barbara, USA; Department of Mechanical Engineering, University of California Santa Barbara, Santa Barbara, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968143/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15011352537782761627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California Santa Barbara",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968086",
        "title": "Energy-Efficient Locomotion Strategies and Performance Benchmarks using Point Mass Tensegrity Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "This work introduces a novel 12-motor paired-cable actuation scheme to achieve rolling locomotion with a spherical tensegrity structure. Using a new point mass tensegrity dynamic formulation which we present, we utilize Model Predictive Control to generate optimal state-action trajectories for benchmark evaluation. In particular, locomotive performance is assessed based on the practical criteria of rolling speed, energy efficiency, and directional trajectory-tracking accuracy. Through simulation of 6-motor, 12-motor paired cable, and 24-motor fully-actuated policies, we demonstrate that the 12-motor schema is superior to the 6-motor policy in all benchmark categories, comparable to the 24-motor policy in rolling speed, and is over five times more energy efficient than the fully-actuated 24-motor configuration.",
        "primary_area": "",
        "author": "Brian M. Cera;Anthony A. Thompson;Alice M. Agogino;Brian M. Cera;Anthony A. Thompson;Alice M. Agogino",
        "authorids": "/37085538832;/37087324152;/37358366200;/37085538832;/37087324152;/37358366200",
        "aff": "Brian M. Cera; Anthony A. Thompson; Alice M. Agogino",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968086/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13555301360099460269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8968249",
        "title": "Energy-based Adaptive Control and Learning for Patient-Aware Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel energy-based control scheme for an assist-as-needed rehabilitation strategy, which both adapts the level of support based on patient participation and allows the patient to deviate from the prescribed motion in favor of his/her safety. We build an energy network model, with which we can monitor the energy flow through the system and prescribe a threshold on stored energy. We also develop an adaptive motion control law that shapes the desired trajectory in order to respect the stored energy threshold. Next, we show how adapting the stored energy threshold can be used to change the level of responsiveness to the patient as well as to prevent excessive energy transfer to the human by the system. A criterion is defined for setting this energy threshold, which can be further used for monitoring the patient active participation and for adapting and learning the appropriate assistance level during rehabilitation. Experimental results based on implementation in MATLAB Simscape\u00ae and on the VEMO robotic system demonstrate the feasibility of the suggested approach. The presented control scheme can be applied to any system, including position- and torque-controlled robots, and does not require the use of EMG sensors or precise force measurements.",
        "primary_area": "",
        "author": "Erfan Shahriari;Dinmukhamed Zardykhan;Alexander Koenig;Elisabeth Jensen;Sami Haddadin;Erfan Shahriari;Dinmukhamed Zardykhan;Alexander Koenig;Elisabeth Jensen;Sami Haddadin",
        "authorids": "/37085822407;/37086328374;/37275595300;/37967991000;/37542865300;/37085822407;/37086328374;/37275595300;/37967991000;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Reactive Robotics GmbH, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968249/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11306997268117313675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Technical University of Munich;Reactive Robotics GmbH",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence;",
        "aff_unique_url": "https://www.tum.de;",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968287",
        "title": "EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although imitation learning is often used in robotics, the approach frequently suffers from data mismatch and compounding errors. DAgger is an iterative algorithm that addresses these issues by aggregating training data from both the expert and novice policies, but does not consider the impact of safety. We present a probabilistic extension to DAgger, which attempts to quantity the confidence of the novice policy as a proxy for safety. Our method, EnsembleDAgger, approximates a Gaussian Process using an ensemble of neural networks. Using the variance as a measure of confidence, we compute a decision rule that captures how much we doubt the novice, thus determining when it is safe to allow the novice to act. With this approach, we aim to maximize the novice's share of actions, while constraining the probability of failure. We demonstrate improved safety and learning performance compared to other DAgger variants and classic imitation learning on an inverted pendulum and in the MuJoCo HalfCheetah environment.",
        "primary_area": "",
        "author": "Kunal Menda;Katherine Driggs-Campbell;Mykel J. Kochenderfer;Kunal Menda;Katherine Driggs-Campbell;Mykel J. Kochenderfer",
        "authorids": "/37086806652;/37085509519;/37596929200;/37086806652;/37085509519;/37596929200",
        "aff": "Stanford University, Stanford, CA, USA; University of Illinois at Urbana-Champaign, IL, USA; Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968287/",
        "gs_citation": 127,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9768056084315204139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://illinois.edu",
        "aff_unique_abbr": "Stanford;UIUC",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967950",
        "title": "Enthusiastic Robots Make Better Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and evaluation of human-like welcoming behaviors for a humanoid robot to draw the attention of passersby by following a three-step model: (1) selecting a target (person) to engage, (2) executing behaviors to draw the target's attention, and (3) monitoring the attentive response. A computer vision algorithm was developed to select the person, start the behaviors and monitor the response automatically. To vary the robot's enthusiasm when engaging passersby, a waving gesture was designed as basic welcoming behavioral element, which could be successively combined with an utterance and an approach movement. This way, three levels of enthusiasm were implemented: Mild (waving), moderate (waving and utterance) and high (waving, utterance and approach movement). The three levels of welcoming behaviors were tested with a Pepper robot at the entrance of a university building. We recorded data and observation sheets from several hundreds of passersby (N = 364) and conducted post-interviews with randomly selected passersby (N = 28). The level selection was done at random for each participant. The passersby indicated that they appreciated the robot at the entrance and clearly recognized its role as a welcoming robot. In addition, the robot proved to draw more attention when showing high enthusiasm (i.e., more welcoming behaviors), particularly for female passersby.",
        "primary_area": "",
        "author": "Elie Saad;Joost Broekens;Mark A. Neerincx;Koen V. Hindriks;Elie Saad;Joost Broekens;Mark A. Neerincx;Koen V. Hindriks",
        "authorids": "/37086803694;/37670664900;/37296193500;/37828283800;/37086803694;/37670664900;/37296193500;/37828283800",
        "aff": "Department of Intelligent Systems - II Group, Delft University of Technology, Delft, The Netherlands; LIACS, Leiden University, Leiden, The Netherlands; Department of Intelligent Systems - II Group, Delft University of Technology, Delft, The Netherlands; Department of Computer Science, Vrije Universiteit, Amsterdam, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967950/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5241426802806420556&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Delft University of Technology;Leiden University;Vrije Universiteit",
        "aff_unique_dep": "Department of Intelligent Systems - II Group;LIACS;Department of Computer Science",
        "aff_unique_url": "https://www.tudelft.nl;https://www.universiteitleiden.nl/en;https://www.vu.nl",
        "aff_unique_abbr": "TUDelft;LU;VU",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Delft;Leiden;Amsterdam",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "8967699",
        "title": "Entropic Risk Measure in Policy Search",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing pace of automation, modern robotic systems need to act in stochastic, non-stationary, partially observable environments. A range of algorithms for finding parameterized policies that optimize for long-term average performance have been proposed in the past. However, the majority of the proposed approaches does not explicitly take into account the variability of the performance metric, which may lead to finding policies that although performing well on average, can perform spectacularly bad in a particular run or over a period of time. To address this shortcoming, we study an approach to policy optimization that explicitly takes into account higher order statistics of the reward function. In this paper, we extend policy gradient methods to include the entropic risk measure in the objective function and evaluate their performance in simulation experiments and on a real-robot task of learning a hitting motion in robot badminton.",
        "primary_area": "",
        "author": "David Nass;Boris Belousov;Jan Peters;David Nass;Boris Belousov;Jan Peters",
        "authorids": "/37087324559;/37087324763;/37533077600;/37087324559;/37087324763;/37533077600",
        "aff": "Intelligent Autonomous Systems Lab, Technische Universit\u00e4t Darmstadt, Germany; Intelligent Autonomous Systems Lab, Technische Universit\u00e4t Darmstadt, Germany; Intelligent Autonomous Systems Lab, Technische Universit\u00e4t Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967699/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1128587291134835443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Intelligent Autonomous Systems Lab",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967954",
        "title": "Environmental sound segmentation utilizing Mask U-Net",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an environmental sound segmentation method using Mask U-Net. Recent research in robot audition has analyzed noise reduction, section detection, and sound source separation for use in a real-world environment with many noises and overlaps. However, conventional methods apply respective functions in cascades. The biggest problem of cascade systems is the accumulation of errors generated at each function block. Although many methods of human voice separation have been proposed, robots operating in a real-world environment must be able to separate not only human voices but other environmental sounds. Unlike traditional sound source separation using spatial information, environmental sound segmentation must simultaneously detect sections and separate sound sources based on pre-trained features. One such method, U-Net, which was proposed for semantic segmentation of images, has been applied to the separation of singing voices. However, this method deals only with limited classes of sounds. The current study proposes an environmental sound segmentation method using Mask U-Net, which combines segmentation using U-Net with sound event detection using CNN to 75-classes of environmental sounds. Experimental application confirmed that this method improved learning speed and sound source separation compared with the conventional method.",
        "primary_area": "",
        "author": "Yui Sudo;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai;Yui Sudo;Katsutoshi Itoyama;Kenji Nishida;Kazuhiro Nakadai",
        "authorids": "/37087324347;/37667838300;/37086508904;/37274046900;/37087324347;/37667838300;/37086508904;/37274046900",
        "aff": "Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967954/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5730566873805294689&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Systems and Control Engineering",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ookayama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967820",
        "title": "Episodic Learning with Control Lyapunov Functions for Uncertain Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Many modern nonlinear control methods aim to endow systems with guaranteed properties, such as stability or safety, and have been successfully applied to the domain of robotics. However, model uncertainty remains a persistent challenge, weakening theoretical guarantees and causing implementation failures on physical systems. This paper develops a machine learning framework centered around Control Lyapunov Functions (CLFs) to adapt to parametric uncertainty and unmodeled dynamics in general robotic systems. Our proposed method proceeds by iteratively updating estimates of Lyapunov function derivatives and improving controllers, ultimately yielding a stabilizing quadratic program model-based controller. We validate our approach on a planar Segway simulation, demonstrating substantial performance improvements by iteratively refining on a base model-free controller.",
        "primary_area": "",
        "author": "Andrew J. Taylor;Victor D. Dorobantu;Hoang M. Le;Yisong Yue;Aaron D. Ames;Andrew J. Taylor;Victor D. Dorobantu;Hoang M. Le;Yisong Yue;Aaron D. Ames",
        "authorids": "/37087322409;/37087325294;/37087323118;/37085390468;/37300877900;/37087322409;/37087325294;/37087323118;/37085390468;/37300877900",
        "aff": "Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967820/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10922406171201146242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Computing and Mathematical Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968265",
        "title": "Ergodic Flocking",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing efficient control strategies is well studied. Due to recent technological advancements and applications to the field of robotics, exploring ways to design optimal control for multi robot systems is gaining interest. In this respect, ergodicity has been successfully applied as an effective control technique for tracking and coverage. Generating flocking behaviour is a problem with many interesting special cases that include both tracking and coverage. The main contribution of this paper is the application of ergodicity to emulate flocking behaviour. Our approach is appealing, as control and communication are all assumed to be local, and so this behaviour is self-organized. Simulation results show that the proposed approach is effective.",
        "primary_area": "",
        "author": "Conan Veitch;Duncan Render;Alex Aravind;Conan Veitch;Duncan Render;Alex Aravind",
        "authorids": "/37086597248;/37087322676;/37425219700;/37086597248;/37087322676;/37425219700",
        "aff": "Department of Computer Science, University of Northern British Columbia, Canada; Department of Computer Science, University of Northern British Columbia, Canada; Department of Computer Science, University of Northern British Columbia, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968265/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10215219759571692175&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Northern British Columbia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unbc.ca",
        "aff_unique_abbr": "UNBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8967815",
        "title": "Escaping Local Minima in Search-Based Planning using Soft Duplicate Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Search-based planning for relatively low-dimensional motion-planning problems such as for autonomous navigation and autonomous flight has been shown to be very successful. Such framework relies on laying a grid over a state-space and constructing a set of actions (motion primitives) that connect the centers of cells. However, in some cases such as kinodynamic motion planning, planning for bipedal robots with high balance requirements, computing these actions can be highly non-trivial and often impossible depending on the dynamic constraints. In this paper, we explore a soft version of discretization, wherein the state-space remains to be continuous but the search tries to avoid exploring states that are likely to be duplicates of states that have already been explored. We refer to this property of the search as soft duplicate detection and view it as a relaxation of the standard notion of duplicate detection. Empirically, we show that the search can efficiently compute paths in highly-constrained settings and outperforms alternatives on several domains.",
        "primary_area": "",
        "author": "Wei Du;Sung-Kyun Kim;Oren Salzman;Maxim Likhachev;Wei Du;Sung-Kyun Kim;Oren Salzman;Maxim Likhachev",
        "authorids": "/37087325228;/37598024600;/37077497700;/37309318800;/37087325228;/37598024600;/37077497700;/37309318800",
        "aff": "Wei Du; Sung-Kyun Kim; Oren Salzman; Maxim Likhachev",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967815/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8706504278967922307&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8967919",
        "title": "Estimating Metric Scale Visual Odometry from Videos using 3D Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an end-to-end deep learning approach for performing metric scale-sensitive regression tasks such visual odometry with a single camera and no additional sensors. We propose a novel 3D convolutional architecture, 3DC-VO, that can leverage temporal relationships over a short moving window of images to estimate linear and angular velocities. The network makes local predictions on stacks of images that can be integrated to form a full trajectory. We apply 3DC-VO to the KITTI visual odometry benchmark and the task of estimating a pilot\u2019s control inputs from a first-person video of a quadrotor flight. Our method exhibits increased accuracy relative to comparable learning-based algorithms trained on monocular images. We also show promising results for quadrotor control input prediction when trained on a new dataset collected with a UAV simulator.",
        "primary_area": "",
        "author": "Alexander S. Koumis;James A. Preiss;Gaurav S. Sukhatme;Alexander S. Koumis;James A. Preiss;Gaurav S. Sukhatme",
        "authorids": "/37087323220;/37086138258;/37278934100;/37087323220;/37086138258;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967919/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2491846178998294960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968234",
        "title": "Evaluating the Acceptability of Assistive Robots for Early Detection of Mild Cognitive Impairment",
        "track": "main",
        "status": "Poster",
        "abstract": "The employment of Social Assistive Robots (SARs) for monitoring elderly users represents a valuable gateway for at-home assistance. Their deployment in the house of the users can provide effective opportunities for early detection of Mild Cognitive Impairment (MCI), a condition of increasing impact in our aging society, by means of digitalized cognitive tests. In this work, we present a system where a specific set of cognitive tests is selected, digitalized, and integrated with a robotic assistant, whose task is the guidance and supervision of the users during the completion of such tests. The system is then evaluated by means of an experimental study involving potential future users, in order to assess its acceptability and identify key directions for technical improvements.",
        "primary_area": "",
        "author": "Matteo Luperto;Marta Romeo;Francesca Lunardini;Nicola Basilico;Carlo Abbate;Ray Jones;Angelo Cangelosi;Simona Ferrante;N. Alberto Borghese;Matteo Luperto;Marta Romeo;Francesca Lunardini;Nicola Basilico;Carlo Abbate;Ray Jones;Angelo Cangelosi;Simona Ferrante;N. Alberto Borghese",
        "authorids": "/37085688878;/37086509073;/37085671708;/37545501600;/37087278945;/37086510391;/37428592400;/38263701500;/37274539800;/37085688878;/37086509073;/37085671708;/37545501600;/37087278945;/37086510391;/37428592400;/38263701500;/37274539800",
        "aff": "Dep. of Computer Science, University of Milan; School of Computer Science, The University of Manchester and AIST Artificial Intelligence Research Center, Tokyo Waterfront; Dep. of Electronics, Information and Bioengineering, Politecnico di Milano; Dep. of Computer Science, University of Milan; Fondazione IRCCS Ca\u2019 Granda, Ospedale Maggiore Policlinico, Milan; School of Nursing and Midwifery, University of Plymouth; School of Computer Science, The University of Manchester and AIST Artificial Intelligence Research Center, Tokyo Waterfront; Dep. of Electronics, Information and Bioengineering, Politecnico di Milano; Dep. of Computer Science, University of Milan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968234/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8005046299083410436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;3;4;1;2;0",
        "aff_unique_norm": "University of Milan;University of Manchester;Politecnico di Milano;Fondazione IRCCS Ca\u2019 Granda;University of Plymouth",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science;Department of Electronics, Information and Bioengineering;Ospedale Maggiore Policlinico;School of Nursing and Midwifery",
        "aff_unique_url": "https://www.unimi.it;https://www.manchester.ac.uk;https://www.polimi.it;;https://www.plymouth.ac.uk",
        "aff_unique_abbr": "UniMi;UoM;Politecnico di Milano;;Plymouth",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Manchester",
        "aff_country_unique_index": "0;1;0;0;0;1;1;0;0",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "8968213",
        "title": "Evaluation System for Hydraulic Excavator Operation Skill Using Remote Controlled Excavator and Virtual Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "We developed a system to evaluate the skill of operating a hydraulic excavator using a remotely controlled (RC) excavator and virtual reality (VR) technology. We re-modeled the RC excavator such that it can be operated in the same manner as an actual excavator, and proceeded to measure the excavator's state. To evaluate the skill of operating this system, we calculated several indices from data recorded during excavation work. We calculated the same indices from data recorded during excavation performed by an actual excavator, and verified that there exists a high correlation between the indices of the RC excavator and those of the actual excavator.",
        "primary_area": "",
        "author": "Ryota Sekizuka;Masaru Ito;Seiji Saiki;Yoichiro Yamazaki;Yuichi Kurita;Ryota Sekizuka;Masaru Ito;Seiji Saiki;Yoichiro Yamazaki;Yuichi Kurita",
        "authorids": "/37086276362;/37087323444;/37086280661;/37085827124;/37281580400;/37086276362;/37087323444;/37086280661;/37085827124;/37281580400",
        "aff": "Graduate School of Engineering, Hiroshima University, Hiroshima, Japan; Graduate School of Engineering, Hiroshima University, Hiroshima, Japan; Kobelco Construction Machinery Co., Ltd, Hiroshima, Japan; Kobelco Construction Machinery Co., Ltd, Hiroshima, Japan; Graduate School of Engineering, Hiroshima University, Hiroshima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968213/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1079675053872174717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Hiroshima University;Kobelco Construction Machinery Co., Ltd",
        "aff_unique_dep": "Graduate School of Engineering;",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp;https://www.kobelco.co.jp",
        "aff_unique_abbr": "Hiroshima U;Kobelco",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hiroshima;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967867",
        "title": "Executing Underspecified Actions in Real World Based on Online Projection",
        "track": "main",
        "status": "Poster",
        "abstract": "Plan execution on real robots in realistic environments is underdetermined and often leads to failures. The choice of action parameterization is crucial for task success. In this paper, we present a mechanism for a robot that is acting in a real-world environment to think ahead of time with fast plan projection and, thereby, choose action parameterizations that are predicted to lead to successful execution. For finding causal relationships between action parameterizations and task success, we provide the robot with means for plan introspection and propose a systematic and hierarchical plan structure to support that. We evaluate our approach by showing how a PR2 robot, when equipped with the proposed system, is able to choose action parameterizations that increase task execution success rates and overall performance of fetch and place actions in a real world setting.",
        "primary_area": "",
        "author": "Gayane Kazhoyan;Michael Beetz;Gayane Kazhoyan;Michael Beetz",
        "authorids": "/37086314230;/37279125900;/37086314230;/37279125900",
        "aff": "Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967867/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5314613030270214914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968545",
        "title": "Experience Reuse with Probabilistic Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Acquiring new robot motor skills is cumbersome, as learning a skill from scratch and without prior knowledge requires the exploration of a large space of motor configurations. Accordingly, for learning a new task, time could be saved by restricting the parameter search space by initializing it with the solution of a similar task. We present a framework which is able of such knowledge transfer from already learned movement skills to a new learning task. The framework combines probabilistic movement primitives with descriptions of their effects for skill representation. New skills are first initialized with parameters inferred from related movement primitives and thereafter adapted to the new task through relative entropy policy search. We compare two different transfer approaches to initialize the search space distribution with data of known skills with a similar effect. We show the different benefits of the two knowledge transfer approaches on an object pushing task for a simulated 3-DOF robot. We can show that the quality of the learned skills improves and the required iterations to learn a new task can be reduced by more than 60% when past experiences are utilized.",
        "primary_area": "",
        "author": "Svenja Stark;Jan Peters;Elmar Rueckert;Svenja Stark;Jan Peters;Elmar Rueckert",
        "authorids": "/37086308508;/37533077600;/37085389924;/37086308508;/37533077600;/37085389924",
        "aff": "Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Hochschulstr. 10, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Hochschulstr. 10, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Hochschulstr. 10, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968545/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17582827584291538746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968049",
        "title": "Experimental Comparison of Open Source Visual-Inertial-Based State Estimation Algorithms in the Underwater Domain",
        "track": "main",
        "status": "Poster",
        "abstract": "A plethora of state estimation techniques have appeared in the last decade using visual data, and more recently with added inertial data. Datasets typically used for evaluation include indoor and urban environments, where supporting videos have shown impressive performance. However, such techniques have not been fully evaluated in challenging conditions, such as the marine domain. In this paper, we compare ten recent open-source packages to provide insights on their performance and guidelines on addressing current challenges. Specifically, we selected direct and indirect methods that fuse camera and Inertial Measurement Unit (IMU) data together. Experiments are conducted by testing all packages on datasets collected over the years with underwater robots in our laboratory. All the datasets are made available online.",
        "primary_area": "",
        "author": "Bharat Joshi;Sharmin Rahman;Michail Kalaitzakis;Brennan Cain;James Johnson;Marios Xanthidis;Nare Karapetyan;Alan Hernandez;Alberto Quattrini Li;Nikolaos Vitzilaios;Ioannis Rekleitis;Bharat Joshi;Sharmin Rahman;Michail Kalaitzakis;Brennan Cain;James Johnson;Marios Xanthidis;Nare Karapetyan;Alan Hernandez;Alberto Quattrini Li;Nikolaos Vitzilaios;Ioannis Rekleitis",
        "authorids": "/37087324582;/37085989996;/37086942753;/37086599440;/37087321754;/37085810183;/37086299803;/37088742585;/37085808885;/37571943800;/37281356300;/37087324582;/37085989996;/37086942753;/37086599440;/37087321754;/37085810183;/37086299803;/37088742585;/37085808885;/37571943800;/37281356300",
        "aff": "Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Mechanical Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science Department, MiraCosta College, Oceanside, CA, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA; Mechanical Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968049/",
        "gs_citation": 119,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18382186568933212139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;1;2;0;0",
        "aff_unique_norm": "University of South Carolina;MiraCosta College;Dartmouth College",
        "aff_unique_dep": "Computer Science and Engineering Department;Computer Science Department;Department of Computer Science",
        "aff_unique_url": "https://www.sc.edu;https://www.miracosta.edu;https://www.dartmouth.edu",
        "aff_unique_abbr": "USC;;Dartmouth",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;2;0;0",
        "aff_campus_unique": "Columbia;Oceanside;Hanover",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967691",
        "title": "Experimental Study on Microfluidic Mixing with Trapezoidal Obstacles in a 1000-Fold Span of Reynolds Number",
        "track": "main",
        "status": "Poster",
        "abstract": "Mixing is important for microfluidic systems and placing obstacles in a flow path for generating advection, or splitting/recombination flows, is a very popular method for enhancing the mixing. In this paper, we present experimental investigations on such microfluidic mixing with four different shapes of trapezoidal obstacles and tested them in a 1000-fold span of Reynolds number (Re). The obstacles have four different base ratios 1, 3, 6 and 9, which indicate the ratios between the upper and lower bases of a trapezoid. Two different dyes, yellow and blue, were used for visualizing and evaluating the performance of mixing. The results show that, when the base ratio is 1, the mixing surprisingly becomes worse with the increase of the flowrate. When the ratio is 3 or 6, the mixing performance is first reduced with the increase of Re and then went through a transition around Re of 10 before it rapidly increases. When the ratio is 9, two transition points were found around Re of 10 and 100, respectively. The work provides useful information for realizing shape-dependent mixing performance, as well as for developing an intelligent lab-on-a-chip system.",
        "primary_area": "",
        "author": "Xin-Yu Lin;Hiroaki Ito;Makoto Kaneko;Chia-Hung Dylan Tsai;Xin-Yu Lin;Hiroaki Ito;Makoto Kaneko;Chia-Hung Dylan Tsai",
        "authorids": "/37087324246;/37085784718;/37274087200;/37075476600;/37087324246;/37085784718;/37274087200;/37075476600",
        "aff": "Department of Mechanical Engineering, National Chiao Tung University, Taiwan; Department of Mechanical Engineering, Osaka University, Japan; Department of Mechanical Engineering, Osaka University, Japan; Department of Mechanical Engineering, National Chiao Tung University, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967691/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:gLTwiEyTkc4J:scholar.google.com/&scioq=Experimental+Study+on+Microfluidic+Mixing+with+Trapezoidal+Obstacles+in+a+1000-Fold+Span+of+Reynolds+Number&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "National Chiao Tung University;Osaka University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "NCTU;Osaka U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8968253",
        "title": "Experimental Validation of Hydraulic Interlocking Drive System for Biped Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Biped robots require substantial amounts of power on each leg alternately while walking, hopping, and running. However, it is difficult to adopt large high-power electrical motors in conventional mechanical transmission systems owing to spatial limitations. To address this problem, a hydraulic interlocking drive system that incorporates two hydraulic direct-drive systems is proposed for biped humanoid robots. The hydraulic interlocking drive system connects the two hydraulic direct-drive systems and concentrates the pump output on one side cylinder. The other side cylinder meter-in flow rate is controlled by the meter-out flow rate from the cylinder on which the pump is concentrated. Good position tracking and excellent energy saving are achieved with the proposed system. A performance comparison with a single hydraulic direct-drive system shows that the motor power of the hip pitch joint is reduced by 27.3% for walking patterns. This result shows that the rated output of the motor can be reduced, and smaller and lighter motors can be installed in biped robots.",
        "primary_area": "",
        "author": "J. Shimizu;T. Otani;H. Mizukami;K. Hashimoto;A. Takanishi;J. Shimizu;T. Otani;H. Mizukami;K. Hashimoto;A. Takanishi",
        "authorids": "/38189562800;/38251798500;/37086936017;/37537963700;/37280756700;/38189562800;/38251798500;/37086936017;/37537963700;/37280756700",
        "aff": "Graduate School of Advanced Science and Engineering, Waseda University; Department of Modern Mechanical Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; School of Science and Technology, Meiji University; Department of Modern Mechanical Engineering, Waseda University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968253/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9454222627746762676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Waseda University;Meiji University",
        "aff_unique_dep": "Graduate School of Advanced Science and Engineering;School of Science and Technology",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.meiji.ac.jp",
        "aff_unique_abbr": "Waseda;Meiji",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968122",
        "title": "Exploiting Sparse Semantic HD Maps for Self-Driving Vehicle Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel semantic localization algorithm that exploits multiple sensors and has precision on the order of a few centimeters. Our approach does not require detailed knowledge about the appearance of the world, and our maps require orders of magnitude less storage than maps utilized by traditional geometry- and LiDAR intensity-based localizers. This is important as self-driving cars need to operate in large environments. Towards this goal, we formulate the problem in a Bayesian filtering framework, and exploit lanes, traffic signs, as well as vehicle dynamics to localize robustly with respect to a sparse semantic map. We validate the effectiveness of our method on a new highway dataset consisting of 312km of roads. Our experiments show that the proposed approach is able to achieve 0.05m lateral accuracy and 1.12m longitudinal accuracy on average while taking up only 0.3% of the storage required by previous LiDAR intensity-based approaches.",
        "primary_area": "",
        "author": "Wei-Chiu Ma;Ignacio Tartavull;Ioan Andrei B\u00e2rsan;Shenlong Wang;Min Bai;Gellert Mattyus;Namdar Homayounfar;Shrinidhi Kowshika Lakshmikanth;Andrei Pokrovsky;Raquel Urtasun;Wei-Chiu Ma;Ignacio Tartavull;Ioan Andrei B\u00e2rsan;Shenlong Wang;Min Bai;Gellert Mattyus;Namdar Homayounfar;Shrinidhi Kowshika Lakshmikanth;Andrei Pokrovsky;Raquel Urtasun",
        "authorids": "/37087231773;/37088735439;/37086454262;/37085699650;/37088730670;/37085564132;/37086255781;/37086577397;/37086569295;/37269502900;/37087231773;/37088735439;/37086454262;/37085699650;/37088730670;/37085564132;/37086255781;/37086577397;/37086569295;/37269502900",
        "aff": "Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968122/",
        "gs_citation": 147,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3595921139547332126&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Uber",
        "aff_unique_dep": "Advanced Technologies Group",
        "aff_unique_url": "https://www.uber.com",
        "aff_unique_abbr": "Uber ATG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968500",
        "title": "Exploiting linearity in dynamics solvers for the design of composable robotic manipulation architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate two major limiting factors in the design and implementation of modern dynamics solvers that interfere with their full utilization in versatile, manipulation-driven robotic software architectures. The first limitation originates from the design of those solvers which aims at computational efficiency while neglecting composability. Instead, we advocate to design the solvers in such a way that they exploit linearity in the equations of motion to fully decompose the state of a kinematic chain. This enables a versatile recomposition and more flexible applications. Secondly, we have observed that most implementations follow the programming principle of information hiding. Consequently, the internal state that is used to compute motion control commands is withheld from other parts of the software architecture. We tackle this problem by following a dataflow programming paradigm and separating the software's dataflow from the control flow. Thereafter, we demonstrate those two simple, yet effective strategies to overcome the limitations along various case studies.",
        "primary_area": "",
        "author": "Sven Schneider;Herman Bruyninckx;Sven Schneider;Herman Bruyninckx",
        "authorids": "/37085594507;/37278642900;/37085594507;/37278642900",
        "aff": "Dept. of Computer Science, Bonn-Rhein-Sieg University of Applied Sciences, Germany; Dept. of Computer Science, Bonn-Rhein-Sieg University of Applied Sciences, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968500/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18140323994131308084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bonn-Rhein-Sieg University of Applied Sciences",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.bonn-rhein-sieg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967805",
        "title": "Explore, Approach, and Terminate: Evaluating Subtasks in Active Visual Object Search Based on Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Searching for objects and distinguishing task-relevant objects from others is a key requirement for service robots. We propose a reinforcement learning solution to the active visual object search problem. Our method successfully learns to explore the environment, to approach the target object, and to decide when to terminate the search as the target object has been found. We demonstrate the efficiency of our solution on a dataset of real-world images collected by a robot. Our approach outperforms state-space planning or other baseline search strategies, reaching a higher success rate in a shorter time. We also study individual subtasks of active visual object search. Although strong baselines exist for the subtasks, our RL solution outperforms them in the overall search task.",
        "primary_area": "",
        "author": "Jan Fabian Schmid;Mikko Lauri;Simone Frintrop;Jan Fabian Schmid;Mikko Lauri;Simone Frintrop",
        "authorids": "/37087324095;/37857377500;/37402784100;/37087324095;/37857377500;/37402784100",
        "aff": "Depaitment of Informatics, University of Hamburg, Hamburg, Germany; Depaitment of Informatics, University of Hamburg, Hamburg, Germany; Depaitment of Informatics, University of Hamburg, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967805/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7916162099999872594&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hamburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968243",
        "title": "Exploring Low-level and High-level Transfer Learning for Multi-task Facial Recognition with a Semi-supervised Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Facial recognition tasks like identity, age, gender, and emotion recognition received substantial attention in recent years. Their deployment in robotic platforms became necessary for the characterization of most of the non-verbal Human-Robot Interaction (HRI) scenarios. In this regard, deep convolution neural networks have shown to be effective on processing different facial representations but with a high cost: to achieve maximum generalization, they require an enormous amount of task-specific labeled data. This paper proposes a unified semi-supervised deep neural model to address this problem. Our hybrid model is composed of an unsupervised deep generative adversarial network which learns fundamental characteristics of facial representations, and a set of convolution channels that fine-tunes the high-level facial concepts for the recognition of identity, age group, gender, and facial expressions. Our network employs progressive lateral connections between the convolution channels so that they share the high-abstraction particularities of each of these tasks in order to reduce the necessity of a large amount of strongly labeled training data. We propose a series of experiments to evaluate each individual mechanism of our hybrid model, in particular, the impact of the progressive connections on learning the specific facial recognition tasks and we observe that our model achieves a better performance when compared to task-specific models.",
        "primary_area": "",
        "author": "Pablo Barros;Erik Fliesswasser;Matthias Kerzel;Stefan Wermter;Pablo Barros;Erik Fliesswasser;Matthias Kerzel;Stefan Wermter",
        "authorids": "/37085578534;/37087323814;/37086049282;/37323875400;/37085578534;/37087323814;/37086049282;/37323875400",
        "aff": "Knowledge Technology, University of Hamburg, Germany; Knowledge Technology, University of Hamburg, Germany; Knowledge Technology, University of Hamburg, Germany; Knowledge Technology, University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968243/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1124294379010979027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Knowledge Technology",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967758",
        "title": "Exploring logical consistency and viewport sensitivity in compositional VQA models",
        "track": "main",
        "status": "Poster",
        "abstract": "The most recent architectures for Visual Question Answering (VQA), such as TbD or DDRprog, have already outperformed human-level accuracy on benchmark datasets (e.g. CLEVR). We administered an advanced analysis of their performance based on novel metrics called consistency (sum of all object feature instances in the scene (e.g. shapes) equals the total number of the objects in the scene) and revealed only 56% consistency for the most accurate architecture (TbD). In respect to this finding, we propose a new method of the VQA training, which reaches 98% consistency. Furthermore, testing of the VQA model in real world brings out a problem with precise mimicking of the camera position from the original dataset. We therefore created a virtual environment along with its real-world counterpart with variable camera positions to test the accuracy and consistency from different viewports. Based on these errors, we were able to estimate optimal position of the camera. The proposed method thus allows us to find the optimal camera viewport in the real environment without knowing the geometry and the exact position of the camera in the synthetic training environment.",
        "primary_area": "",
        "author": "Gabriela Sejnova;Michal Vavrecka;Michael Tesar;Radoslav Skoviera;Gabriela Sejnova;Michal Vavrecka;Michael Tesar;Radoslav Skoviera",
        "authorids": "/37087325270;/37991069300;/37087324001;/37086145621;/37087325270;/37991069300;/37087324001;/37086145621",
        "aff": "Department of Cybernetics, Czech Technical University; Czech Institute of Informatics, Robotics, and Cybernetics of the Czech Technical University; Department of Cybernetics, Czech Technical University; Czech Institute of Informatics, Robotics, and Cybernetics of the Czech Technical University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967758/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15833081394171434008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Czech Technical University",
        "aff_unique_dep": "Department of Cybernetics",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8968272",
        "title": "Extending Monocular Visual Odometry to Stereo Camera Systems by Scale optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel approach for extending monocular visual odometry to a stereo camera system. The proposed method uses an additional camera to accurately estimate and optimize the scale of the monocular visual odometry, rather than triangulating 3D points from stereo matching. Specifically, the 3D points generated by the monocular visual odometry are projected onto the other camera of the stereo pair, and the scale is recovered and optimized by directly minimizing the photometric error. It is computationally efficient, adding minimal overhead to the stereo vision system compared to straightforward stereo matching, and is robust to repetitive texture. Additionally, direct scale optimization enables stereo visual odometry to be purely based on the direct method. Extensive evaluation on public datasets (e.g., KITTI), and outdoor environments (both terrestrial and underwater) demonstrates the accuracy and efficiency of a stereo visual odometry approach extended by scale optimization, and its robustness in environments with challenging textures.",
        "primary_area": "",
        "author": "Jiawei Mo;Junaed Sattar;Jiawei Mo;Junaed Sattar",
        "authorids": "/37087322233;/37546394500;/37087322233;/37546394500",
        "aff": "Department of Computer Science and Engineering, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968272/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3696418117842887771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Twin Cities",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968491",
        "title": "FA-Harris: A Fast and Asynchronous Corner Detector for Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the emerging bio-inspired event cameras have demonstrated potentials for a wide range of robotic applications in dynamic environments. In this paper, we propose a novel fast and asynchronous event-based corner detection method which is called FA-Harris. FA-Harris consists of several components, including an event filter, a Global Surface of Active Events (G-SAE) maintaining unit, a corner candidate selecting unit, and a corner candidate refining unit. The proposed G-SAE maintenance algorithm and corner candidate selection algorithm greatly enhance the real-time performance for corner detection, while the corner candidate refinement algorithm maintains the accuracy of performance by using an improved event-based Harris detector. Additionally, FA-Harris does not require artificially synthesized event-frames and can operate on asynchronous events directly. We implement the proposed method in C++ and evaluate it on public Event Camera Datasets. The results show that our method achieves approximately 8\u00d7 speed-up when compared with previously reported event-based Harris detector, and with no compromise on the accuracy of performance.",
        "primary_area": "",
        "author": "Ruoxiang Li;Dianxi Shi;Yongjun Zhang;Kaiyue Li;Ruihao Li;Ruoxiang Li;Dianxi Shi;Yongjun Zhang;Kaiyue Li;Ruihao Li",
        "authorids": "/37086640438;/37401070600;/37086947806;/37086948352;/38468746700;/37086640438;/37401070600;/37086947806;/37086948352;/38468746700",
        "aff": "College of Computer, National University of Defense Teclmology, Changsha, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; College of Computer, National University of Defense Teclmology, Changsha, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968491/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=967525193764186789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "National University of Defense Technology;National Innovation Institute of Defense Technology",
        "aff_unique_dep": "College of Computer;Artificial Intelligence Research Center",
        "aff_unique_url": "http://www.nudt.edu.cn;",
        "aff_unique_abbr": "NUDT;NIIDT",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Changsha;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968021",
        "title": "FASTER: Fast and Safe Trajectory Planner for Flights in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "High-speed trajectory planning through unknown environments requires algorithmic techniques that enable fast reaction times while maintaining safety as new information about the operating environment is obtained. The requirement of computational tractability typically leads to optimization problems that do not include the obstacle constraints (collision checks are done on the solutions) or use a convex decomposition of the free space and then impose an ad-hoc time allocation scheme for each interval of the trajectory. Moreover, safety guarantees are usually obtained by having a local planner that plans a trajectory with a final \u201cstop\u201d condition in the freeknown space. However, these two decisions typically lead to slow and conservative trajectories. We propose FASTER (Fast and Safe Trajectory Planner) to overcome these issues. FASTER obtains high-speed trajectories by enabling the local planner to optimize in both the free-known and unknown spaces. Safety guarantees are ensured by always having a feasible, safe back-up trajectory in the free-known space at the start of each replanning step. Furthermore, we present a Mixed Integer Quadratic Program formulation in which the solver can choose the trajectory interval allocation, and where a time allocation heuristic is computed efficiently using the result of the previous replanning iteration. This proposed algorithm is tested extensively both in simulation and in real hardware, showing agile flights in unknown cluttered environments with velocities up to 3.6 m/s.",
        "primary_area": "",
        "author": "Jesus Tordesillas;Brett T. Lopez;Jonathan P. How;Jesus Tordesillas;Brett T. Lopez;Jonathan P. How",
        "authorids": "/37086933970;/37085654767;/37276347700;/37086933970;/37085654767;/37276347700",
        "aff": "Aerospace Controls Laboratory, MIT, 77 Massachusetts Ave., Cambridge, MA, USA; Aerospace Controls Laboratory, MIT, 77 Massachusetts Ave., Cambridge, MA, USA; Aerospace Controls Laboratory, MIT, 77 Massachusetts Ave., Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968021/",
        "gs_citation": 221,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12474427762482272612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Aerospace Controls Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968199",
        "title": "FIESTA: Fast Incremental Euclidean Distance Fields for Online Motion Planning of Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Euclidean Signed Distance Field (ESDF) is useful for online motion planning of aerial robots since it can easily query the distance and gradient information against obstacles. Fast incrementally built ESDF map is the bottleneck for conducting real-time motion planning. In this paper, we investigate this problem and propose a mapping system called FIESTA to build global ESDF map incrementally. By introducing two independent updating queues for inserting and deleting obstacles separately, and using Indexing Data Structures and Doubly Linked Lists for map maintenance, our algorithm updates as few as possible nodes using a BFS framework. Our ESDF map has high computational performance and produces near-optimal results. We show our method outperforms other up-to-date methods in term of performance and accuracy by both theory and experiments. We integrate FIESTA into a completed quadrotor system and validate it by both simulation and onboard experiments. We release our method as open-source software for the community.",
        "primary_area": "",
        "author": "Luxin Han;Fei Gao;Boyu Zhou;Shaojie Shen;Luxin Han;Fei Gao;Boyu Zhou;Shaojie Shen",
        "authorids": "/37086690176;/37086045143;/37086574790;/37954847200;/37086690176;/37086045143;/37086574790;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968199/",
        "gs_citation": 241,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5643018814063346103&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968082",
        "title": "FLAME: Feature-Likelihood Based Mapping and Localization for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate vehicle localization is arguably the most critical and fundamental task for autonomous vehicle navigation. While dense 3D point-cloud-based maps enable precise localization, they impose significant storage and transmission burdens when used in city-scale environments. In this paper, we propose a highly compressed representation for LiDAR maps, along with an efficient and robust real-time alignment algorithm for on-vehicle LiDAR scans. The proposed mapping framework, which we refer to as Feature Likelihood Acquisition Map Emulation (FLAME), requires less than 0.1% of the storage space of the original 3D point cloud map. In essence, FLAME emulates an original map through feature likelihood functions. In particular, FLAME models planar, pole and curb features. These three feature classes are long-term stable, distinct and common among vehicular roadways. Multiclass feature points are extracted from LiDAR scans through feature detection. A new multiclass-based point-to-distribution alignment method is proposed to find the association and alignment between the multiclass feature points and the FLAME map. The experimental results show that the proposed framework can achieve the same level of accuracy (less than 10cm) as the 3D point cloud based localization.",
        "primary_area": "",
        "author": "Su Pang;Daniel Kent;Daniel Morris;Hayder Radha;Su Pang;Daniel Kent;Daniel Morris;Hayder Radha",
        "authorids": "/37086815663;/37313202000;/37085641369;/37269513400;/37086815663;/37313202000;/37085641369;/37269513400",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, 220 Trowbridge Road, East Lansing, Michigan, United States; Department of Electrical and Computer Engineering, Michigan State University, 220 Trowbridge Road, East Lansing, Michigan, United States; Department of Electrical and Computer Engineering, Michigan State University, 220 Trowbridge Road, East Lansing, Michigan, United States; Department of Electrical and Computer Engineering, Michigan State University, 220 Trowbridge Road, East Lansing, Michigan, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968082/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18048466557675173145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967924",
        "title": "Fast Adaptation with Meta-Reinforcement Learning for Trust Modelling in Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In socially assistive robotics, an important research area is the development of adaptation techniques and their effect on human-robot interaction. We present a meta-learning based policy gradient method for addressing the problem of adaptation in human-robot interaction and also investigate its role as a mechanism for trust modelling. By building an escape room scenario in mixed reality with a robot, we test our hypothesis that bi-directional trust can be influenced by different adaptation algorithms. We found that our proposed model increased the perceived trustworthiness of the robot and influenced the dynamics of gaining human's trust. Additionally, participants evaluated that the robot perceived them as more trustworthy during the interactions with the meta-learning based adaptation compared to the previously studied statistical adaptation model.",
        "primary_area": "",
        "author": "Yuan Gao;Elena Sibirtseva;Ginevra Castellano;Danica Kragic;Yuan Gao;Elena Sibirtseva;Ginevra Castellano;Danica Kragic",
        "authorids": "/37086510385;/37086513242;/37321909500;/37281296000;/37086510385;/37086513242;/37321909500;/37281296000",
        "aff": "Department of Information and Technology, Uppsala University, Sweden; Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden; Department of Information and Technology, Uppsala University, Sweden; Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967924/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17164301367667926895&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Uppsala University;KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Information and Technology;EECS",
        "aff_unique_url": "https://www.uu.se;https://www.kth.se",
        "aff_unique_abbr": "UU;KTH",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stockholm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "8967584",
        "title": "Fast Free-viewpoint Video Synthesis Algorithm for Sports Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we report on a parallel free-viewpoint video synthesis algorithm that can efficiently reconstruct a high-quality 3D scene representation of sports scenes. The proposed method focuses on a scene that is captured by multiple synchronized cameras featuring wide-baselines. The following strategies are introduced to accelerate the production of a free-viewpoint video taking the improvement of visual quality into account: (1) a sparse point cloud is reconstructed using a volumetric visual hull approach, and an exact 3D ROI is found for each object using an efficient connected components labeling algorithm. Next, the reconstruction of a dense point cloud is accelerated by implementing visual hull only in the ROIs; (2) an accurate polyhedral surface mesh is built by estimating the exact intersections between grid cells and the visual hull; (3) the appearance of the reconstructed presentation is reproduced in a view-dependent manner that respectively renders the non-occluded and occluded region with the nearest camera and its neighboring cameras. The production for volleyball and judo sequences demonstrates the effectiveness of our method in terms of both execution time and visual quality.",
        "primary_area": "",
        "author": "Jun Chen;Ryosuke Watanabe;Keisuke Nonaka;Tomoaki Konno;Hiroshi Sankoh;Sei Naito;Jun Chen;Ryosuke Watanabe;Keisuke Nonaka;Tomoaki Konno;Hiroshi Sankoh;Sei Naito",
        "authorids": "/37086250907;/37086487104;/37086103418;/37087322450;/37601429000;/37281653700;/37086250907;/37086487104;/37086103418;/37087322450;/37601429000;/37281653700",
        "aff": "Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan; Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan; Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan; Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan; Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan; Ultra-realistic Communication Group, KDDI Research, Inc., Fujimino, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967584/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14793865055741111903&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KDDI Research, Inc.",
        "aff_unique_dep": "Ultra-realistic Communication Group",
        "aff_unique_url": "https://www.kddi-research.com",
        "aff_unique_abbr": "KDDI Research",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Fujimino",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967614",
        "title": "Fast Handovers with a Robot Character: Small Sensorimotor Delays Improve Perceived Qualities",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for fast and robust handovers with a robot character, together with a user study investigating the effect of robot speed and reaction time on perceived interaction quality. The system can match and exceed human speeds and confirms that users prefer human-level timing. The system has the appearance of a robot character, with a bear-like head and a soft anthropomorphic hand and uses B\u00e9zier curves to achieve smooth minimum-jerk motions. Fast timing is enabled by low latency motion capture and real-time trajectory generation: the robot initially moves towards an expected handover location and the trajectory is updated on-the-fly to converge smoothly to the actual handover location. A hybrid automaton provides robustness to failure and unexpected human actions. In a 3x3 user study, we vary the speed of the robot and add variable sensorimotor delays. We evaluate the social perception of the robot using the Robot Social Attribute Scale (RoSAS). Inclusion of a small delay, mimicking the delay of the human sensorimotor system, leads to an improvement in perceived qualities over both no delay and long delay conditions. Specifically, with no delay the robot is perceived as more discomforting, and with a long delay it is perceived as less warm.",
        "primary_area": "",
        "author": "Matthew K.X.J. Pan;Espen Knoop;Moritz B\u00e4cher;G\u00fcnter Niemeyer;Matthew K.X.J. Pan;Espen Knoop;Moritz B\u00e4cher;G\u00fcnter Niemeyer",
        "authorids": "/37085376434;/37077370800;/37877709100;/37283232500;/37085376434;/37077370800;/37877709100;/37283232500",
        "aff": "MP and GN are with Disney Research, Glendale, CA; EK and MB are with Disney Research, Zurich, Switzerland; EK and MB are with Disney Research, Zurich, Switzerland; MP and GN are with Disney Research, Glendale, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967614/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13683545070591517278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Disney Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.disney.com",
        "aff_unique_abbr": "Disney Research",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Glendale;Zurich",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "8968441",
        "title": "Fast Manipulability Maximization Using Continuous-Time Trajectory optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "A significant challenge in manipulation motion planning is to ensure agility in the face of unpredictable changes during task execution. This requires the identification and possible modification of suitable joint-space trajectories, since the joint velocities required to achieve a specific endeffector motion vary with manipulator configuration. For a given manipulator configuration, the joint space-to-task space velocity mapping is characterized by a quantity known as the manipulability index. In contrast to previous control-based approaches, we examine the maximization of manipulability during planning as a way of achieving adaptable and safe joint space-to-task space motion mappings in various scenarios. By representing the manipulator trajectory as a continuous-time Gaussian process (GP), we are able to leverage recent advances in trajectory optimization to maximize the manipulability index during trajectory generation. Moreover, the sparsity of our chosen representation reduces the typically large computational cost associated with maximizing manipulability when additional constraints exist. Results from simulation studies and experiments with a real manipulator demonstrate increases in manipulability, while maintaining smooth trajectories with more dexterous (and therefore more agile) arm configurations.",
        "primary_area": "",
        "author": "Filip Mari\u0107;Oliver Limoyo;Luka Petrovi\u0107;Trevor Ablett;Ivan Petrovi\u0107;Jonathan Kelly;Filip Mari\u0107;Oliver Limoyo;Luka Petrovi\u0107;Trevor Ablett;Ivan Petrovi\u0107;Jonathan Kelly",
        "authorids": "/37085833266;/37086453462;/37086323129;/37086453021;/37564131900;/37085364182;/37085833266;/37086453462;/37086323129;/37086453021;/37564131900;/37085364182",
        "aff": "Space and Terrestrial Autonomous Robotic Systems Laboratory, University of Toronto, Institute for Aerospace Studies, Canada; Space and Terrestrial Autonomous Robotic Systems Laboratory, University of Toronto, Institute for Aerospace Studies, Canada; Laboratory for Autonomous Systems and Mobile Robotics, University of Zagreb, Faculty of Elecmcal Engineenng and Computing, Croatia; Space and Terrestrial Autonomous Robotic Systems Laboratory, University of Toronto, Institute for Aerospace Studies, Canada; Laboratory for Autonomous Systems and Mobile Robotics, University of Zagreb, Faculty of Elecmcal Engineenng and Computing, Croatia; Space and Terrestrial Autonomous Robotic Systems Laboratory, University of Toronto, Institute for Aerospace Studies, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968441/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2732490903981187371&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "University of Toronto;University of Zagreb",
        "aff_unique_dep": "Institute for Aerospace Studies;Faculty of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.utoronto.ca;https://www.unizg.hr",
        "aff_unique_abbr": "U of T;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "Canada;Croatia"
    },
    {
        "id": "8968474",
        "title": "Fast Motion Planning via Free C-space Estimation Based on Deep Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel learning-based method for fast motion planning in high-dimensional spaces. A deep neural network is designed to predict the free configuration space rapidly given the environment point cloud. With a generated roadmap as an approximate view of the free C-space, LazyPRM is applied to find and check the path with A* search. Due to the application of LazyPRM, the presented method can preserve probabilistic completeness and asymptotic optimality. The new algorithm is tested on a 3-DOF robot arm and a 6-DOF UR3 robot to plan in randomly generated obstacle environments. Results indicate that compared to planners including PRM, RRT*, RRT-connect and the original LazyPRM, our method is of the lowest time consumption and relatively short path length, showing good performance on both planning speed and path quality.",
        "primary_area": "",
        "author": "Xiang Li;Qixin Cao;Mingjing Sun;Ganggang Yang;Xiang Li;Qixin Cao;Mingjing Sun;Ganggang Yang",
        "authorids": "/37085438256;/37271507500;/37087324727;/37087246520;/37085438256;/37271507500;/37087324727;/37087246520",
        "aff": "Master students of School of Mechanical Engineering, Shanghai Jiao Tong University; Professor of School of Mechanical Engineering, Shanghai Jiao Tong University; Master students of School of Mechanical Engineering, Shanghai Jiao Tong University; Master students of School of Mechanical Engineering, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968474/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7856326303224576394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968064",
        "title": "Fast Perception, Planning, and Execution for a Robotic Butler: Wheeled Humanoid M-Hubo",
        "track": "main",
        "status": "Poster",
        "abstract": "As the aging population grows at a rapid rate, there is an ever growing need for service robot platforms that can provide daily assistance at practical speed with reliable performance. In order to assist with daily tasks such as fetching a beverage, a service robot must be able to perceive its environment and generate corresponding motion trajectories. This becomes a challenging and computationally complex problem when the environment is unknown and thus the path planner must sample numerous trajectories that often are sub-optimal, extending the execution time. To address this issue, we propose a unique strategy of integrating a 3D object detection pipeline with a kinematically optimal manipulation planner to significantly increase speed performance at run-time. In addition, we develop a new robotic butler system for a wheeled humanoid that is capable of fetching requested objects at 24% of the speed a human needs to fulfill the same task. The proposed system was evaluated and demonstrated in a real-world environment setup as well as in public exhibition.",
        "primary_area": "",
        "author": "Moonyoung Lee;Yujin Heo;Jinyong Park;Hyun-Dae Yang;Ho-Deok Jang;Philipp Benz;Hyunsub Park;In So Kweon;Jun-Ho Oh;Moonyoung Lee;Yujin Heo;Jinyong Park;Hyun-Dae Yang;Ho-Deok Jang;Philipp Benz;Hyunsub Park;In So Kweon;Jun-Ho Oh",
        "authorids": "/37087323875;/37087323364;/37087323982;/37087325175;/37087322226;/37086383961;/37087324305;/37270474800;/37292052500;/37087323875;/37087323364;/37087323982;/37087325175;/37087322226;/37086383961;/37087324305;/37270474800;/37292052500",
        "aff": "Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Robotics and Computer Vision Laboratory that is in charge of object perception part, Korea Advanced Institute of Science and Technology, 291 Daehakro, Yuseong-gu, Daejeon, Korea; Robotics and Computer Vision Laboratory that is in charge of object perception part, Korea Advanced Institute of Science and Technology, 291 Daehakro, Yuseong-gu, Daejeon, Korea; Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea; Robotics and Computer Vision Laboratory that is in charge of object perception part, Korea Advanced Institute of Science and Technology, 291 Daehakro, Yuseong-gu, Daejeon, Korea; Research Center, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968064/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16742548347729206552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Research Center",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968498",
        "title": "Fast Run-time Monitoring, Replanning, and Recovery for Safe Autonomous System Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a fast run-time monitoring framework for safety assurance during autonomous system operations in uncertain environments. Modern unmanned vehicles rely on periodic sensor measurements for motion planning and control. However, a vehicle may not always be able to obtain its state information due to various reasons such as sensor failures, signal occlusions, and communication problems. To guarantee the safety of a system during these circumstances under the presence of disturbance and noise, we propose a novel fast reachability analysis approach that leverages Gaussian process regression theory to predict future states of the system at run-time. We also propose a self/event-triggered monitoring and replanning approach which leverages our fast reachability scheme to recover the system when needed and replan its trajectory to guarantee safety constraints (i.e., the system will not collide with any obstacles). Our technique is validated both with simulations and experiments on unmanned aerial vehicles case studies in cluttered environments under the effect of unknown wind disturbance at run-time.",
        "primary_area": "",
        "author": "Esen Yel;Nicola Bezzo;Esen Yel;Nicola Bezzo",
        "authorids": "/37086422921;/37546843800;/37086422921;/37546843800",
        "aff": "Departments of Systems and Information Engineering, University of Virginia, Charlottesville; Departments of Systems and Information Engineering, University of Virginia, Charlottesville",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968498/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13455572568833812043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Departments of Systems and Information Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968103",
        "title": "Fast Time-optimal Avoidance of Moving Obstacles for High-Speed MAV Flight",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a method to efficiently compute smooth, time-optimal trajectories for micro aerial vehicles (MAVs) evading a moving obstacle. Our approach first computes an n-dimensional trajectory from the start- to an arbitrary target state including position, velocity and acceleration. It respects input- and state-constraints and is thus dynamically feasible. The trajectory is then efficiently checked for collisions, exploiting the piecewise polynomial formulation. If collisions occur, viastates are inserted into the trajectory to circumvent the obstacle and still maintain time-optimality. These viastates are described by position, velocity, and acceleration. The evaluation shows that the computational demands of the proposed method are minimal such that obstacle avoidance can begin within few milliseconds. Optimality of generated trajectories, combined with the ability for frequent online re-planning from non-hover initial conditions, make the approach well suited for evasion of suddenly perceived obstacles during fast flight.",
        "primary_area": "",
        "author": "Marius Beul;Sven Behnke;Marius Beul;Sven Behnke",
        "authorids": "/37085448737;/37295987100;/37085448737;/37295987100",
        "aff": "Autonomous Intelligent Systems Group, University of Bonn, Germany; Autonomous Intelligent Systems Group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968103/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3992863143392024803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems Group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968502",
        "title": "Fast Trajectory Planning for Multiple Quadrotors using Relative Safe Flight Corridor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new trajectory planning method for multiple quadrotors in obstacle-dense environments. We suggest a relative safe flight corridor (RSFC) to model safe region between a pair of agents, and it is used to generate linear constraints for inter-collision avoidance by utilizing the convex hull property of relative Bernstein polynomial. Our approach employs a graph-based multi-agent pathfinding algorithm to generate an initial trajectory, which is used to construct a safe flight corridor (SFC) and RSFC. We express the trajectory as a piecewise Bernstein polynomial and formulate the trajectory planning problem into one quadratic programming problem using linear constraints from SFC and RSFC. The proposed method can compute collision-free trajectory for 16 agents within a second and for 64 agents less than a minute, and it is validated both through simulation and indoor flight test.",
        "primary_area": "",
        "author": "Jungwon Park;H. Jin Kim;Jungwon Park;H. Jin Kim",
        "authorids": "/37087323909;/37599626400;/37087323909;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968502/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7755654361434077866&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968043",
        "title": "Fast and Incremental Loop Closure Detection Using Proximity Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual loop closure detection, which can be considered as an image retrieval task, is an important problem in SLAM (Simultaneous Localization and Mapping) systems. The frequently used bag-of-words (BoW) models can achieve high precision and moderate recall. However, the requirement for lower time costs and fewer memory costs for mobile robot applications is not well satisfied. In this paper, we propose a novel loop closure detection framework titled FILD\u2019 (Fast and Incremental Loop closure Detection), which focuses on an on-line and incremental graph vocabulary construction for fast loop closure detection. The global and local features of frames are extracted using the Convolutional Neural Networks (CNN) and SURF on the GPU, which guarantee extremely fast extraction speeds. The graph vocabulary construction is based on one type of proximity graph, named Hierarchical Navigable Small World (HNSW) graphs, which is modified to adapt to this specific application. In addition, this process is coupled with a novel strategy for real-time geometrical verification, which only keeps binary hash codes and significantly saves on memory usage. Extensive experiments on several publicly available datasets show that the proposed approach can achieve fairly good recall at 100% precision compared to other state-of-the-art methods. The source code can be downloaded at https://github.comlAnshanTJU/FILD for further studies.",
        "primary_area": "",
        "author": "Shan An;Guangfu Che;Fangru Zhou;Xianglong Liu;Xin Ma;Yu Chen;Shan An;Guangfu Che;Fangru Zhou;Xianglong Liu;Xin Ma;Yu Chen",
        "authorids": "/37086923915;/37086928129;/37089184724;/37539073000;/37405313600;/37087323386;/37086923915;/37086928129;/37089184724;/37539073000;/37405313600;/37087323386",
        "aff": "AR/VR department, JD.com, Beijing, China; AR/VR department, JD.com, Beijing, China; AR/VR department, JD.com, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Control Science and Engineering, Shandong University, Jinan, China; AR/VR department, JD.com, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968043/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10458869520152578232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "JD.com;Beihang University;Shandong University",
        "aff_unique_dep": "AR/VR department;School of Computer Science and Engineering;School of Control Science and Engineering",
        "aff_unique_url": "https://www.jd.com;http://www.buaa.edu.cn;http://www.sdu.edu.cn",
        "aff_unique_abbr": "JD;BUAA;SDU",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Beijing;Jinan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967690",
        "title": "Fast and Robust 3-D Sound Source Localization with DSVD-PHAT",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a variant of the Singular Value Decomposition with Phase Transform (SVD-PHAT), named Difference SVD-PHAT (DSVD-PHAT), to achieve robust Sound Source Localization (SSL) in noisy conditions. Experiments are performed on a Baxter robot with a four-microphone planar array mounted on its head. Results show that this method offers similar robustness to noise as the state-of-the-art Multiple Signal Classification based on Generalized Singular Value Decomposition (GSVD-MUSIC) method, and considerably reduces the computational load by a factor of 250. This performance gain thus makes DSVD-PHAT appealing for real-time application on robots with limited on-board computing power.",
        "primary_area": "",
        "author": "Fran\u00e7ois Grondin;James Glass;Fran\u00e7ois Grondin;James Glass",
        "authorids": "/38243208000;/37284185800;/38243208000;/37284185800",
        "aff": "Computer Science & Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science & Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967690/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12472885617628652228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science & Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967966",
        "title": "Fast and Safe Policy Adaptation via Alignment-based Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Applying deep reinforcement learning to physical systems, as opposed to learning in simulation, presents additional challenges in terms of sample efficiency and safety. Collecting large amounts of hardware demonstration data is time-consuming and the exploratory behavior of reinforcement learning algorithms may lead the system into dangerous states, especially during the early stages of training. To address these challenges, we apply transfer learning to reuse a previously learned policy instead of learning from scratch. In this paper, we propose a method where given a source policy, policy adaptation is performed via transfer learning to produce a target policy suitable for real-world deployment. For policy adaptation, alignment-based transfer learning is applied to trajectories generated by the source policy and their corresponding safe target trajectories. We apply this method to manipulators and show that the proposed method is applicable to both inter-task and inter-robot transfer whilst considering safety. We also show that the resulting target policy is robust and can be further improved with reinforcement learning.",
        "primary_area": "",
        "author": "Jigang Kim;Seungwon Choi;H. Jin Kim;Jigang Kim;Seungwon Choi;H. Jin Kim",
        "authorids": "/37087322157;/686476490207098;/37599626400;/37087322157;/686476490207098;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967966/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17795204112131776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968024",
        "title": "Feasibility of Gait Entrainment to Hip Mechanical Perturbation for Locomotor Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "While rehabilitation of upper-limb motor function with human-interactive robots has been met with success, robot-aided locomotor rehabilitation has proven challenging. To inform more effective approaches to robotic gait therapy, it is important to understand neuro-mechanical dynamics and control of unimpaired locomotion. Our previous studies reported that human gait entrained to periodic mechanical perturbations at the ankle when the perturbation period was close to preferred walking cadence. Moreover, entrainment was accompanied by synchronizing the perturbations to a constant gait phase, the same for all subjects, where they provided mechanical assistance. To test the generality of entrainment-based assistance, the present study evaluated the behavior of live unimpaired subjects who walked overground while wearing a hip exoskeleton robot. Periodic torque pulses were applied to the subjects' hips, with a period different from, but close to, their preferred stride cadence. Results indicated that unimpaired subjects entrained their gait to periodic mechanical perturbations at the hip. Convergence of relative phase between gait and perturbations was observed, but clustered around two distinct gait phases, in contrast to the single converged phase observed in entrainment to periodic ankle torques. These entrainment studies quantify important aspects of the nonlinear neuro-mechanical dynamics underlying the control of walking, which will inform the development of effective approaches to robotic walking therapy.",
        "primary_area": "",
        "author": "Jongwoo Lee;Devon Goetz;Meghan E. Huber;Neville Hogan;Jongwoo Lee;Devon Goetz;Meghan E. Huber;Neville Hogan",
        "authorids": "/37085770535;/37087323522;/37085363999;/37298867300;/37085770535;/37087323522;/37085363999;/37298867300",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968024/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15541760545818551244&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968251",
        "title": "Feedback MPC for Torque-Controlled Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The computational power of mobile robots is currently insufficient to achieve torque level whole-body Model Predictive Control (MPC) at the update rates required for complex dynamic systems such as legged robots. This problem is commonly circumvented by using a fast tracking controller to compensate for model errors between updates. In this work, we show that the feedback policy from a Differential Dynamic Programming (DDP) based MPC algorithm is a viable alternative to bridge the gap between the low MPC update rate and the actuation command rate. We propose to augment the DDP approach with a relaxed barrier function to address inequality constraints arising from the friction cone. A frequency-dependent cost function is used to reduce the sensitivity to high-frequency model errors and actuator bandwidth limits. We demonstrate that our approach can find stable locomotion policies for the torque-controlled quadruped, ANYmal, both in simulation and on hardware.",
        "primary_area": "",
        "author": "Ruben Grandia;Farbod Farshidian;Ren\u00e9 Ranftl;Marco Hutter;Ruben Grandia;Farbod Farshidian;Ren\u00e9 Ranftl;Marco Hutter",
        "authorids": "/37086355336;/37085428006;/38252786800;/37545251000;/37086355336;/37085428006;/38252786800;/37545251000",
        "aff": "Robotic Systems Lab, ETH, Zurich, Switzerland; Robotic Systems Lab, ETH, Zurich, Switzerland; Intel Labs, Munich, Germany; Robotic Systems Lab, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968251/",
        "gs_citation": 191,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=583821004639159793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "ETH Zurich;Intel",
        "aff_unique_dep": "Robotic Systems Lab;Intel Labs",
        "aff_unique_url": "https://www.ethz.ch;https://www.intel.de",
        "aff_unique_abbr": "ETHZ;Intel",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Zurich;Munich",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "8967657",
        "title": "Feedback-based Fabric Strip Folding",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate manipulation of a deformable body such as a piece of fabric is difficult because of its many degrees of freedom and unobservable properties affecting its dynamics. To alleviate these challenges, we propose the application of feedback-based control to robotic fabric strip folding. The feedback is computed from the low dimensional state extracted from a camera image. We trained the controller using reinforcement learning in simulation which was calibrated to cover the real fabric strip behaviors. The proposed feedback-based folding was experimentally compared to two state-of-the-art folding methods and our method outperformed both of them in terms of accuracy.",
        "primary_area": "",
        "author": "Vladim\u00edr Petr\u00edk;Ville Kyrki;Vladim\u00edr Petr\u00edk;Ville Kyrki",
        "authorids": "/37085341098;/37274001900;/37085341098;/37274001900",
        "aff": "Aalto University, Finland; Aalto University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967657/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11471274507109711519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "8967783",
        "title": "Filter Early, Match Late: Improving Network-Based Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "CNNs have excelled at performing place recognition over time, particularly when the neural network is optimized for localization in the current environmental conditions. In this paper we investigate the concept of feature map filtering, where, rather than using all the activations within a convolutional tensor, only the most useful activations are used. Since specific feature maps encode different visual features, the objective is to remove feature maps that detract from the ability to recognize a location across appearance changes. Our key innovation is to filter the feature maps in an early convolutional layer, but then continue to run the network and extract a feature vector using a later, more viewpoint invariant layer in the same network. Our approach improves the condition and viewpoint invariance of a pre-trained network, using as little as a single training image pair from the deployment environment. An exhaustive experimental analysis is performed to determine the full scope of causality between early layer filtering and late layer extraction. For validity, we use three datasets: Oxford RobotCar, Nordland, and Gardens Point, achieving overall superior performance to NetVLAD. The work provides a number of new avenues for exploring CNN optimizations, without requiring any re-training of the network weights.",
        "primary_area": "",
        "author": "Stephen Hausler;Adam Jacobson;Michael Milford;Stephen Hausler;Adam Jacobson;Michael Milford",
        "authorids": "/37086694610;/37077582600;/37283633100;/37086694610;/37077582600;/37283633100",
        "aff": "ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967783/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10879884375754610235&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "ARC Centre of Excellence for Robotic Vision",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8968189",
        "title": "First Steps Towards Full Model Based Motion Planning and Control of Quadrupeds: A Hybrid Zero Dynamics Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "The hybrid zero dynamics (HZD) approach has become a powerful tool for the gait planning and control of bipedal robots. This paper aims to extend the HZD methods to address walking, ambling and trotting behaviors on a quadrupedal robot. We present a framework that systematically generates a wide range of optimal trajectories and then provably stabilizes them for the full-order, nonlinear and hybrid dynamical models of quadrupedal locomotion. The gait planning is addressed through a scalable nonlinear programming using direct collocation and HZD. The controller synthesis for the exponential stability is then achieved through the Poincar\u00e9 sections analysis. In particular, we employ an iterative optimization algorithm involving linear and bilinear matrix inequalities (LMIs and BMIs) to design HZD-based controllers that guarantee the exponential stability of the fixed points for the Poincar\u00e9 return map. The power of the framework is demonstrated through gait generation and HZD-based controller synthesis for an advanced quadruped robot, - Vision 60, with 36 state variables and 12 control inputs. The numerical simulations as well as real world experiments confirm the validity of the proposed framework.",
        "primary_area": "",
        "author": "Wen-Loong Ma;Kaveh Akbari Hamed;Aaron D. Ames;Wen-Loong Ma;Kaveh Akbari Hamed;Aaron D. Ames",
        "authorids": "/37085547381;/37592529600;/37300877900;/37085547381;/37592529600;/37300877900",
        "aff": "department of mechanical engineering, California Institute of Technology, Pasadena, CA; faulty of mechanical engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA; faculty of the department of Control + Dynamical Systems, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968189/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13895141413138920783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2+0",
        "aff_unique_norm": "California Institute of Technology;Virginia Polytechnic Institute and State University;Control Department",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering;Department of Control",
        "aff_unique_url": "https://www.caltech.edu;https://www.vt.edu;",
        "aff_unique_abbr": "Caltech;VT;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pasadena;Blacksburg;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "8967787",
        "title": "Flexible Layouts for Fiducial Tags",
        "track": "main",
        "status": "Poster",
        "abstract": "Fiducials are artificial features with a variety of uses in computer vision such as object tracking and localization. We propose the idea of flexible tag layouts for visual fiducial systems. In contrast to traditional square tags, flexible tag layouts allow circular, annular, or other shapes as desired. One use of layout flexibility is to increase the data density of standard square shaped tags. In addition, we describe a detector that is faster and has higher recall than both the AprilTag 2 and ArUco detectors while maintaining precision.",
        "primary_area": "",
        "author": "Maximilian Krogius;Acshi Haggenmiller;Edwin Olson;Maximilian Krogius;Acshi Haggenmiller;Edwin Olson",
        "authorids": "/37086936723;/37086934968;/37413277900;/37086936723;/37086934968;/37413277900",
        "aff": "Computer Science and Engineering Department, University of Michigan, Ann Arbor, MI, USA; Computer Science and Engineering Department, University of Michigan, Ann Arbor, MI, USA; Computer Science and Engineering Department, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967787/",
        "gs_citation": 207,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7281694727475004514&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967651",
        "title": "Flexible Trinocular: Non-rigid Multi-Camera-IMU Dense Reconstruction for UAV Navigation and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a visual-inertial framework able to efficiently estimate the camera poses of a non-rigid trinocular baseline for long-range depth estimation on-board a fast moving aerial platform. The estimation of the time-varying baseline is based on relative inertial measurements, a photometric relative pose optimizer, and a probabilistic wing model fused in an efficient Extended Kalman Filter (EKF) formulation. The estimated depth measurements can be integrated into a geo-referenced global map to render a reconstruction of the environment useful for local replanning algorithms. Based on extensive real-world experiments we describe the challenges and solutions for obtaining the probabilistic wing model, reliable relative inertial measurements, and vision-based relative pose updates and demonstrate the computational efficiency and robustness of the overall system under challenging conditions.",
        "primary_area": "",
        "author": "Timo Hinzmann;Cesar Cadena;Juan Nieto;Roland Siegwart;Timo Hinzmann;Cesar Cadena;Juan Nieto;Roland Siegwart",
        "authorids": "/37085820525;/37593590400;/37085778635;/37281398300;/37085820525;/37593590400;/37085778635;/37281398300",
        "aff": "Autonomous Systems Lab, Leonhardstrasse 21, LEE, ETH, the Swiss Federal Institute of Technology Zurich, Zurich, Switzerland; Autonomous Systems Lab, Leonhardstrasse 21, LEE, ETH, the Swiss Federal Institute of Technology Zurich, Zurich, Switzerland; Autonomous Systems Lab, Leonhardstrasse 21, LEE, ETH, the Swiss Federal Institute of Technology Zurich, Zurich, Switzerland; Autonomous Systems Lab, Leonhardstrasse 21, LEE, ETH, the Swiss Federal Institute of Technology Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967651/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2808672108115560213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967759",
        "title": "Flexure Mechanisms with Variable Stiffness and Damping Using Layer Jamming",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexures provide precise motion control without friction or wear. Variable impedance mechanisms enable adaptable and robust interactions with the environment. This paper combines the advantages of both approaches through layer jamming. Thin sheets of complaint material are encased in an airtight envelope, and when connected to a vacuum, the bending stiffness and damping increase dramatically. Using layer jamming structures as flexure elements leads to mechanical systems that can actively vary stiffness and damping. This results in flexure mechanisms with the versatility to transition between degrees of freedom and degrees of constraint and to tune impact response. This approach is used to create a 2-DOF, jamming-based, tunable impedance robotic wrist that enables passive hybrid force/position control for contact tasks. Keywords: Compliant Joint/Mechanism, Compliance and Impedance Control, Mechanism Design.",
        "primary_area": "",
        "author": "Buse Akta\u015f;Robert D. Howe;Buse Akta\u015f;Robert D. Howe",
        "authorids": "/37087321888;/37279555200;/37087321888;/37279555200",
        "aff": "Paulson School of Engineering and Applied Sciences at Harvard University, Cambridge, MA, USA; Paulson School of Engineering and Applied Sciences at Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967759/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16933555150202955980&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968145",
        "title": "Flight Recovery of MAVs with Compromised IMU",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro Aerial Vehicles (MAVs) rely on onboard attitude and position sensors for autonomous flight. Due to their size, weight, and power (SWaP) constraints, most modern MAVs use miniaturized inertial measurement units (IMUs) to provide attitude feedback, which is critical for flight stabilization and control. However, recent adversarial attack studies have demonstrated that many commonly used IMUs are vulnerable to attacks exploiting their physical characteristics. Conventional redundancy-based approaches are not effective against such attacks because redundant IMUs have the same or similar physical vulnerabilities. In this paper, we present a novel fault-tolerant solution for IMU compromised scenarios, using separate position and heading information to restore the failed attitude states. Rather than adding more IMU alternatives for recovery, the proposed method is intended to minimize any modifications to the existing system and control program. Thus, it is particularly useful for vehicles that have tight SWaP constraints while requiring simultaneous high performance and safety demands. To execute the recovery logic properly, a robust estimator was designed for fine-grained detection and isolation of the faulty sensors. The effectiveness of the proposed approach was validated on a quadcopter MAV through both simulation and experimental flight tests.",
        "primary_area": "",
        "author": "Zhan Tu;Fan Fei;Matthew Eagon;Dongyan Xu;Xinyan Deng;Zhan Tu;Fan Fei;Matthew Eagon;Dongyan Xu;Xinyan Deng",
        "authorids": "/37086047175;/37085343855;/37087321915;/37278439300;/37571648700;/37086047175;/37085343855;/37087321915;/37278439300;/37571648700",
        "aff": "School of Mechanical Engineering, Purdue University; School of Mechanical Engineering, Purdue University; School of Mechanical Engineering, Purdue University; Department of Computer Science, Purdue University; School of Mechanical Engineering, Purdue University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968145/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12295069570117719948&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "West Lafayette;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968116",
        "title": "FlightGoggles: Photorealistic Sensor Simulation for Perception-driven Robotics using Photogrammetry and Virtual Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "FlightGoggles is a photorealistic sensor simulator for perception-driven robotic vehicles. The key contributions of FlightGoggles are twofold. First, FlightGoggles provides photorealistic exteroceptive sensor simulation using graphics assets generated with photogrammetry. Second, it provides the ability to combine (i) synthetic exteroceptive measurements generated in silico in real time and (ii) vehicle dynamics and proprioceptive measurements generated in motio by vehicle(s) in flight in a motion-capture facility. FlightGoggles is capable of simulating a virtual-reality environment around autonomous vehicle(s) in flight. While a vehicle is in flight in the Flight-Goggles virtual reality environment, exteroceptive sensors are rendered synthetically in real time while all complex dynamics are generated organically through natural interactions of the vehicle. The FlightGoggles framework allows for researchers to accelerate development by circumventing the need to estimate complex and hard-to-model interactions such as aerodynamics, motor mechanics, battery electrochemistry, and behavior of other agents. The ability to perform vehicle-in-the-loop experiments with photorealistic exteroceptive sensor simulation facilitates novel research directions involving, e.g., fast and agile autonomous flight in obstacle-rich environments, safe human interaction, and flexible sensor selection. FlightGoggles has been utilized as the main test for selecting nine teams that will advance in the AlphaPilot autonomous drone racing challenge. We survey approaches and results from the top AlphaPilot teams, which may be of independent interest. FlightGoggles is distributed as open-source software along with the photorealistic graphics assets for several simulation environments, under the MIT license at http://flightgoggles.mit.edu.",
        "primary_area": "",
        "author": "Winter Guerra;Ezra Tal;Varun Murali;Gilhyun Ryou;Sertac Karaman;Winter Guerra;Ezra Tal;Varun Murali;Gilhyun Ryou;Sertac Karaman",
        "authorids": "/37086067990;/37086431381;/37086855117;/37086326985;/37304113000;/37086067990;/37086431381;/37086855117;/37086326985;/37304113000",
        "aff": "Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968116/",
        "gs_citation": 166,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15875859320003454134&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems (LIDS)",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967752",
        "title": "Flower Interaction Subsystem for a Precision Pollination Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic pollinators not only can aid farmers by providing more cost effective and stable methods for pollinating plants but also benefit crop production in environments not suitable for bees such as greenhouses, growth chambers, and in outer space. Robotic pollination requires a high degree of precision and autonomy but few systems have addressed both of these aspects in practice. In this paper, a fully autonomous robot is presented, capable of precise pollination of individual small flowers. Experimental results show that the proposed system is able to achieve a 93.1% detection accuracy and a 76.9% `pollination' success rate tested with high-fidelity artificial flowers.",
        "primary_area": "",
        "author": "Jared Strader;Jennifer Nguyen;Christopher Tatsch;Yixin Du;Kyle Lassak;Benjamin Buzzo;Ryan Watson;Henry Cerbone;Nicholas Ohi;Chizhao Yang;Yu Gu;Jared Strader;Jennifer Nguyen;Christopher Tatsch;Yixin Du;Kyle Lassak;Benjamin Buzzo;Ryan Watson;Henry Cerbone;Nicholas Ohi;Chizhao Yang;Yu Gu",
        "authorids": "/37085782368;/37087191435;/37086103417;/37088730517;/37088745500;/37086423418;/37086250454;/37088744424;/37086456776;/37088728030;/37288787100;/37085782368;/37087191435;/37086103417;/37088730517;/37088745500;/37086423418;/37086250454;/37088744424;/37086456776;/37088728030;/37288787100",
        "aff": "Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967752/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17264360262303501093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "West Virginia University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.wvu.edu",
        "aff_unique_abbr": "WVU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Morgantown",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967944",
        "title": "Flying through a narrow gap using neural network: an end-to-end planning and control approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the problem of enabling a drone to fly through a tilted narrow gap, without a traditional planning and control pipeline. To this end, we propose an end-to-end policy network, which imitates from the traditional pipeline and is fine-tuned using reinforcement learning. Unlike previous works which plan dynamical feasible trajectories using motion primitives and track the generated trajectory by a geometric controller, our proposed method is an end-to-end approach which takes the flight scenario as input and directly outputs thrust-attitude control commands for the quadrotor. Key contributions of our paper are: 1) presenting an imitate-reinforce training framework. 2) flying through a narrow gap using an end-to-end policy network, showing that learning based method can also address the highly dynamic control problem as the traditional pipeline does (see attached video1). 3) propose a robust imitation of an optimal trajectory generator using multilayer perceptrons. 4) show how reinforcement learning can improve the performance of imitation learning, and the potential to achieve higher performance over the model-based method.",
        "primary_area": "",
        "author": "Jiarong Lin;Luqi Wang;Fei Gao;Shaojie Shen;Fu Zhang;Jiarong Lin;Luqi Wang;Fei Gao;Shaojie Shen;Fu Zhang",
        "authorids": "/37087012222;/37086690004;/37086045143;/37954847200;/38245883800;/37087012222;/37086690004;/37086045143;/37954847200;/38245883800",
        "aff": "Department of Mechanical Engineering, Hong Kong University, Hong Kong SAR., China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR., China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR., China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR., China; Department of Mechanical Engineering, Hong Kong University, Hong Kong SAR., China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967944/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17225553047152520747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Hong Kong University;Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.hku.hk;https://www.ust.hk",
        "aff_unique_abbr": "HKU;HKUST",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Hong Kong;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967656",
        "title": "Follow The Robot: Modeling Coupled Human-Robot Dyads During Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robot applications being explored involve robots leading humans during navigation. Developing effective robots for this task requires a way for robots to understand and model a human's following behavior. In this paper, we present results from a user study of how humans follow a guide robot in the halls of an office building. We then present a data-driven Markovian model of this following behavior, and demonstrate its generalizability across time interval and trajectory length. Finally, we integrate the model into a global planner and run a simulation experiment to investigate the benefits of coupled human-robot planning. Our results suggest that the proposed model effectively predicts how humans follow a robot, and that the coupled planner, while taking longer, leads the human significantly closer to the target position.",
        "primary_area": "",
        "author": "Amal Nanavati;Xiang Zhi Tan;Joe Connolly;Aaron Steinfeld;Amal Nanavati;Xiang Zhi Tan;Joe Connolly;Aaron Steinfeld",
        "authorids": "/37087323481;/37086511822;/37087324389;/37284961500;/37087323481;/37086511822;/37087324389;/37284961500",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science, Yale University, New Haven, CT, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967656/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5124345890588485467&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Yale University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.yale.edu",
        "aff_unique_abbr": "CMU;Yale",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pittsburgh;New Haven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967519",
        "title": "Foot with a Core-shell Structural Six-axis Force Sensor for Pedal Depressing and Recovering from Foot Slipping during Pedal Pushing Toward Autonomous Driving by Humanoids",
        "track": "main",
        "status": "Poster",
        "abstract": "To realize a robust automobile driving behavior of musculoskeletal tendon-driven humanoids, we developed a six-axis force measurement module with a core-shell structure. This sensor enables space saving, high load capacity and wholebody sensing at the same time. By developing a foot unit incorporating a core-shell structural force sensor on its toe, we realized behaviors of depressing a pedal and recovering from foot slipping during the depressing with a lifesized musculoskeletal humanoid \u201dMusashi\u201d.",
        "primary_area": "",
        "author": "Koki Shinjo;Kento Kawaharaduka;Yuki Asano;Shinsuke Nakashima;Shogo Makino;Moritaka Onitsuka;Kei Tsuzuki;Kei Okada;Koji Kawasaki;Masayuki Inaba;Koki Shinjo;Kento Kawaharaduka;Yuki Asano;Shinsuke Nakashima;Shogo Makino;Moritaka Onitsuka;Kei Tsuzuki;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37087324644;/37088741696;/38238750500;/37086104250;/37086105354;/37086573419;/37086598284;/37280639000;/37085684621;/37286658200;/37087324644;/37088741696;/38238750500;/37086104250;/37086105354;/37086573419;/37086598284;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967519/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8620258477558460313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967813",
        "title": "Force Field-Based Indirect Manipulation Of UAV Flight Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "For a variety of applications remote navigation of an unmanned aerial vehicle (UAV) along a flight trajectory is an essential task. For instance, during search and rescue missions in outdoor scenes, an important goal is to ensure safe navigation. Assessed by the remote operator, this could mean avoiding collisions with obstacles, but moreover avoiding hazardous flight areas. State of the art approaches enable navigation along trajectories, but do not allow for indirect manipulation during motion. In addition, they suggest to use egocentric views which could limit understanding of the remote scene. With this work we introduce a novel indirect manipulation method, based on gravitational law, to recover safe navigation in the presence of hazardous flight areas. The indirect character of our method supports manipulation at far distances where common direct manipulation methods typically fail. We combine it with an immersive exocentric view to improve understanding of the scene. We designed three flavors of our method and compared them during a user study in a simulated scene. While with this method we present a first step towards a more extensive navigation interface, as future work we plan experiments in dynamic real-world scenes.",
        "primary_area": "",
        "author": "Werner Alexander Isop;Friedrich Fraundorfer;Werner Alexander Isop;Friedrich Fraundorfer",
        "authorids": "/37086344118;/37266352400;/37086344118;/37266352400",
        "aff": "Department of Computer Science, Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Department of Computer Science, Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967813/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:d4i3GeSBX14J:scholar.google.com/&scioq=Force+Field-Based+Indirect+Manipulation+Of+UAV+Flight+Trajectories&hl=en&as_sdt=0,5",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Graz University of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tugraz.at",
        "aff_unique_abbr": "TUGraz",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Graz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "8967889",
        "title": "Force-and-Motion Constrained Planning for Tool Use",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of hand tools presents a challenge for robot manipulation in part because it calls for motions requiring continuous force application over a whole trajectory, usually involving large joint-angle excursions. The feasible application of a tool, such as pulling a nail with a hammer claw, requires careful coordination of the choice of grasp and joint trajectories to ensure kinematic and force limits are not exceeded - in the grasp as well as the robot mechanism. In this paper, we formulate this type of problem as choosing the values of decision variables in the presence of various constraints. We evaluate the impact of the various constraints in some representative instances of tool use. To aid others in further investigating this class of problems, we have released materials such as printable tool models and experimental data. We hope that these can serve as the basis of a benchmark problem for investigating tasks that involve many kinematic, actuation, friction, and environment constraints.",
        "primary_area": "",
        "author": "Rachel Holladay;Tom\u00e1s Lozano-P\u00e9rez;Alberto Rodriguez;Rachel Holladay;Tom\u00e1s Lozano-P\u00e9rez;Alberto Rodriguez",
        "authorids": "/37085574181;/38273814000;/38194796600;/37085574181;/38273814000;/38194796600",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Mechanical Engineenng Department, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967889/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14312443481394220369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967730",
        "title": "Forecasting Time-to-Collision from Monocular Video: Feasibility, Dataset, and Challenges",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore the possibility of using a single monocular camera to forecast the time to collision between a suitcase-shaped robot being pushed by its user and other nearby pedestrians. We develop a purely image-based deep learning approach that directly estimates the time to collision without the need of relying on explicit geometric depth estimates or velocity information to predict future collisions. While previous work has focused on detecting immediate collision in the context of navigating Unmanned Aerial Vehicles, the detection was limited to a binary variable (i.e., collision or no collision). We propose a more fine-grained approach to collision forecasting by predicting the exact time to collision in terms of milliseconds, which is more helpful for collision avoidance in the context of dynamic path planning. To evaluate our method, we have collected a novel dataset of over 13,000 indoor video segments each showing a trajectory of at least one person ending in a close proximity (a near collision) with the camera mounted on a mobile suitcase-shaped platform. Using this dataset, we do extensive experimentation on different temporal windows as input using an exhaustive list of state-of-the-art convolutional neural networks (CNNs). Our results show that our proposed multi-stream CNN is the best model for predicting time to near-collision. The average prediction error of our time to near-collision is 0.75 seconds across the test videos. The project webpage can be found at https://aashi7.github.io/NearCollision.html.",
        "primary_area": "",
        "author": "Aashi Manglik;Xinshuo Weng;Eshed Ohn-Bar;Kris M. Kitanil;Aashi Manglik;Xinshuo Weng;Eshed Ohn-Bar;Kris M. Kitanil",
        "authorids": "/37085900136;/37086376142;/37073869900;/37087321884;/37085900136;/37086376142;/37073869900;/37087321884",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Max Planck Institute for Intelligent Systems; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967730/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5322001334901373751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Robotics Institute;Intelligent Systems",
        "aff_unique_url": "https://www.cmu.edu;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "CMU;MPI-IS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "8967885",
        "title": "Forest Tree Detection and Segmentation using High Resolution Airborne LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an autonomous approach to tree detection and segmentation from high resolution airborne LiDAR pointclouds, such as those collected from a UAV, that utilises region-based CNN and 3D-CNN deep learning algorithms. Trees are first detected in 2D before individual trees are further characterised in 3D. If the number of training examples for a site is low, it is shown to be beneficial to transfer a segmentation network learnt from a different site with more training data and fine-tune it. The algorithm was validated using airborne laser scanning over two different commercial pine plantations. The results show that the proposed approach performs favourably in comparison to other methods for tree detection and segmentation.",
        "primary_area": "",
        "author": "Lloyd Windrim;Mitch Bryson;Lloyd Windrim;Mitch Bryson",
        "authorids": "/37086228866;/37295622000;/37086228866;/37295622000",
        "aff": "Australian Centre for Field Robotics, The University of Sydney, 2006, Australia; Australian Centre for Field Robotics, The University of Sydney, 2006, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967885/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9733764478990663310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Australian Centre for Field Robotics",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967654",
        "title": "Formation of PVDF Piezoelectric Film on 3D Bellows Surface of Robotic Suction Cup for Providing Force Sensing Ability -Feasibility Study on Two Methods of Dip-coating and Lamination-",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new object handling device for a robot, in which a conventional vacuum suction cup is provided with force sensing ability by coating a piezoelectric thin film polymer, i.e., PolyVinylidene DiFluoride (PVDF), on its surface. It can detect the applied force by piezoelectric effect of coated thin film. The feature of our study is that the suction cup can work not only as a grasping tool but also as a force sensor. PVDF thin film was prepared by dip-coating method which can coat thin film directly on a three dimensional (3D) surface. Although the film with sufficient piezoelectric d 33 constant, e.g., 34 pC/N, was achieved after polarization process in case of flat surface, it was not achieved, however, on 3D bellows surface. To address this problem, as an alternative method, the feasibility of lamination of already polarized film was investigated.",
        "primary_area": "",
        "author": "Seiji Aoyagi;Tatsuki Morita;Takuto Shintani;Hiroki Takise;Tomokazu Takahashi;Masato Suzuki;Seiji Aoyagi;Tatsuki Morita;Takuto Shintani;Hiroki Takise;Tomokazu Takahashi;Masato Suzuki",
        "authorids": "/37390760000;/37087321839;/37087324863;/37087323841;/37855758800;/37400874100;/37390760000;/37087321839;/37087324863;/37087323841;/37855758800;/37400874100",
        "aff": "Faculty of Engineering Science, Kansai University, Osaka, JAPAN; Faculty of Engineering Science, Kansai University, Osaka, JAPAN; Faculty of Engineering Science, Kansai University, Osaka, JAPAN; Engineering Science Major, Mechanical Engineering, Kansai University, Osaka, JAPAN; Faculty of Engineering Science, Kansai University, Osaka, JAPAN; Faculty of Engineering Science, Kansai University, Osaka, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967654/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16353997003038879833&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Kansai University",
        "aff_unique_dep": "Faculty of Engineering Science",
        "aff_unique_url": "https://www.kansai-u.ac.jp",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967683",
        "title": "Free-Space Features: Global Localization in 2D Laser SLAM Using Distance Function Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "In many applications, maintaining a consistent map of the environment is key to enabling robotic platforms to perform higher-level decision making. Detection of already visited locations is one of the primary ways in which map consistency is maintained, especially in situations where external positioning systems are unavailable or unreliable. Mapping in 2D is an important field in robotics, largely due to the fact that man-made environments such as warehouses and homes, where robots are expected to play an increasing role, can often be approximated as planar. Place recognition in this context remains challenging: 2D lidar scans contain scant information with which to characterize, and therefore recognize, a location. This paper introduces a novel approach aimed at addressing this problem. At its core, the system relies on the use of the distance function for representation of geometry. This representation allows extraction of features which describe the geometry of both surfaces and free-space in the environment. We propose a feature for this purpose. Through evaluations on public datasets, we demonstrate the utility of free-space in the description of places, and show an increase in localization performance over a state-of-the-art descriptor extracted from surface geometry.",
        "primary_area": "",
        "author": "Alexander Millane;Helen Oleynikova;Juan Nieto;Roland Siegwart;C\u00e9sar Cadena;Alexander Millane;Helen Oleynikova;Juan Nieto;Roland Siegwart;C\u00e9sar Cadena",
        "authorids": "/37085729647;/37085472384;/37085778635;/37281398300;/37593590400;/37085729647;/37085472384;/37085778635;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967683/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7823136888257213528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967568",
        "title": "From Pixels to Buildings: End-to-end Probabilistic Deep Networks for Large-scale Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce TopoNets, end-to-end probabilistic deep networks for modeling semantic maps with structure reflecting the topology of large-scale environments. TopoNets build a unified deep network spanning multiple levels of abstraction and spatial scales, from pixels representing geometry of local places to high-level descriptions of semantics of buildings. To this end, TopoNets leverage complex spatial relations expressed in terms of arbitrary, dynamic graphs. We demonstrate how TopoNets can be used to perform end-to-end semantic mapping from partial sensory observations and noisy topological relations discovered by a robot exploring large-scale office spaces. Thanks to their probabilistic nature and generative properties, TopoNets extend the problem of semantic mapping beyond classification. We show that TopoNets successfully perform uncertain reasoning about yet unexplored space and detect novel and incongruent environment configurations unknown to the robot. Our implementation of TopoNets achieves real-time, tractable and exact inference, which makes these new deep models a promising, practical solution to mobile robot spatial understanding at scale.",
        "primary_area": "",
        "author": "Kaiyu Zheng;Andrzej Pronobis;Kaiyu Zheng;Andrzej Pronobis",
        "authorids": "/37087321724;/37590836200;/37087321724;/37590836200",
        "aff": "Computer Science Dept., Brown University, Providence, RI, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967568/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3081197376100039088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Brown University;University of Washington",
        "aff_unique_dep": "Computer Science Dept.;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.brown.edu;https://www.washington.edu",
        "aff_unique_abbr": "Brown;UW",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Providence;Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968513",
        "title": "Frustum ConvNet: Sliding Frustums to Aggregate Local Point-Wise Features for Amodal 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a novel method termed Frustum ConvNet (F-ConvNet) for amodal 3D object detection from point clouds. Given 2D region proposals in an RGB image, our method first generates a sequence of frustums for each region proposal, and uses the obtained frustums to group local points. F-ConvNet aggregates point-wise features as frustum-level feature vectors, and arrays these feature vectors as a feature map for use of its subsequent component of fully convolutional network (FCN), which spatially fuses frustum-level features and supports an end-to-end and continuous estimation of oriented boxes in the 3D space. We also propose component variants of F-ConvNet, including an FCN variant that extracts multi-resolution frustum features, and a refined use of F-ConvNet over a reduced 3D space. Careful ablation studies verify the efficacy of these component variants. F-ConvNet assumes no prior knowledge of the working 3D environment and is thus dataset-agnostic. We present experiments on both the indoor SUN-RGBD and outdoor KITTI datasets. F-ConvNet outperforms all existing methods on SUN-RGBD, and at the time of submission it outperforms all published works on the KITTI benchmark. Code has been made available at: https://github.com/zhixinwang/frustum-convnet.",
        "primary_area": "",
        "author": "Zhixin Wang;Kui Jia;Zhixin Wang;Kui Jia",
        "authorids": "/37087324262;/37683115500;/37087324262;/37683115500",
        "aff": "School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968513/",
        "gs_citation": 626,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17879737561988714969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "South China University of Technology",
        "aff_unique_dep": "School of Electronic and Information Engineering",
        "aff_unique_url": "https://www.scut.edu.cn",
        "aff_unique_abbr": "SCUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967711",
        "title": "Fusing Lidar Data and Aerial Imagery with Perspective Correction for Precise Localization in Urban Canyons",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a vehicle localization method that fuses aerial maps and lidar data in urban canyon environments where global positioning system (GPS) signals are inaccurate. The boundaries of buildings are extracted from the aerial map and they are matched to point cloud data provided by the lidar. However, most aerial maps contain perspective projection distortions which can be significant in urban canyons with tall buildings. In this study, a new method to correct such projection distortion is proposed and it is applied to precise localization by fusing the corrected map and lidar data. In order to achieve this, the semantic segmentation of an aerial image is performed using a convolutional neural network, and the mutual information between the lidar measurements and the building boundaries is obtained to measure their similarity. A particle filter framework is employed to localize the vehicle and match the map using the mutual information as the weight of a particle. An experimental dataset is then used to validate the feasibility of the proposed method.",
        "primary_area": "",
        "author": "Jonghwi Kim;Jinwhan Kim;Jonghwi Kim;Jinwhan Kim",
        "authorids": "/37086440746;/38241886900;/37086440746;/38241886900",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967711/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11457151442969809027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968138",
        "title": "Fusion of fluxgate sensors with navigational data for the improvement of the detection of underwater metal-containing objects",
        "track": "main",
        "status": "Poster",
        "abstract": "With the underwater human activity actively developing and the rise of the autonomous unmanned underwater vehicles (AUV) industry, researchers and engineers face the task of maintenance and repair of communications. For this purpose AUVs can be used, with e.g. the task of inspecting pipelines. The article describes the processing algorithm for the signal from passive ferromagnetic (fluxgate) sensors mounted on an AUV carrier used to search for metal-containing objects at the sea bottom. A scheme for such a measurement is proposed - the installation of two sensors at the opposite ends of the carrier. This allows to measure the gradient of magnetic field between the sensors. The characteristic form of such a signal and the dependence of the signal on the motion parameters of the vehicle and external factors are determined. To eliminate false positives, filters are used based on the readings of the position, speed and orientation sensors of the navigation system. Using data on the motion parameters of the device allows to generate a reference signal, which is used to validate the detection of an object using the cross-correlation method. The use of data on orientation angles makes it possible to compensate for the influence of the orientation of the device in the Earths magnetic field.",
        "primary_area": "",
        "author": "D A Frolov;D A Gromoshinskiy;A M Korsakov;A V Bakshiev;E Yu Smirnova;D A Frolov;D A Gromoshinskiy;A M Korsakov;A V Bakshiev;E Yu Smirnova",
        "authorids": "/37087325319;/37087324575;/37087323779;/37087324285;/37087322250;/37087325319;/37087324575;/37087323779;/37087324285;/37087322250",
        "aff": "Russian State Scientific Center for Robotics And Technical Cybernetics 21 Tikhoretsky Prospect, Saint Petersburg, Russia; Russian State Scientific Center for Robotics And Technical Cybernetics 21 Tikhoretsky Prospect, Saint Petersburg, Russia; Russian State Scientific Center for Robotics And Technical Cybernetics 21 Tikhoretsky Prospect, Saint Petersburg, Russia; Russian State Scientific Center for Robotics And Technical Cybernetics 21 Tikhoretsky Prospect, Saint Petersburg, Russia; Russian State Scientific Center for Robotics And Technical Cybernetics 21 Tikhoretsky Prospect, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968138/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:g8ZDsOOQ1q0J:scholar.google.com/&scioq=Fusion+of+fluxgate+sensors+with+navigational+data+for+the+improvement+of+the+detection+of+underwater+metal-containing+objects&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Russian State Scientific Center for Robotics and Technical Cybernetics",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Saint Petersburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "8968061",
        "title": "GLFP: Global Localization from a Floor Plan",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we describe a method for global localization in a previously unvisited environment using only a schematic floor plan as a prior map. The floor plan need not be a precision map-it can be the sort of image found in buildings to guide people or aid evacuation. The core idea is to identify features that are stable across both a drawn floor plan and robot point-of-view LIDAR data, for example wall intersections, which appear as corners from overhead and as vertical lines from the ground. We introduce a factor graph-based global localization method that uses these features as landmarks. The detections of such descriptorless features are noisy and often ambiguous. We therefore propose robust data association based on a pairwise measurement consistency check and max-mixtures error model. We evaluate the resulting system in a real-world indoor environment, demonstrating performance comparable to a baseline system that uses a conventional LIDAR-based prior map.",
        "primary_area": "",
        "author": "Xipeng Wang;Ryan J. Marcotte;Edwin Olson;Xipeng Wang;Ryan J. Marcotte;Edwin Olson",
        "authorids": "/37086144666;/37085782873;/37413277900;/37086144666;/37085782873;/37413277900",
        "aff": "Computer Science and Engineering Department, University of Michigan, Ann Arbor, USA; Computer Science and Engineering Department, University of Michigan, Ann Arbor, USA; Computer Science and Engineering Department, University of Michigan, Ann Arbor, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968061/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15956076409151768142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967693",
        "title": "GPU Accelerated Robust Scene Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a fast and accurate 3D reconstruction system that takes a sequence of RGB-D frames and produces a globally consistent camera trajectory and a dense 3D geometry. We redesign core modules of a state-of-the-art offline reconstruction pipeline to maximally exploit the power of GPU. We introduce GPU accelerated core modules that include RGBD odometry, geometric feature extraction and matching, point cloud registration, volumetric integration, and mesh extraction. Therefore, while being able to reproduce the results of the high-fidelity offline reconstruction system, our system runs more than 10 times faster on average. Nearly 10Hz can be achieved in medium size indoor scenes, making our offline system even comparable to online Simultaneous Localization and Mapping (SLAM) systems in terms of the speed. Experimental results show that our system produces more accurate results than several state-of-the-art online systems. The system is open source at https://github.com/theNded/Open3D.",
        "primary_area": "",
        "author": "Wei Dong;Jaesik Park;Yi Yang;Michael Kaess;Wei Dong;Jaesik Park;Yi Yang;Michael Kaess",
        "authorids": "/37086933483;/38240904400;/37087324154;/37324200400;/37086933483;/38240904400;/37087324154;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, PA, USA; Compute Vision Lab, POSTECH, Pohang, South Korea; Robotics Institute, Carnegie Mellon University, PA, USA; Robotics Institute, Carnegie Mellon University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967693/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7434306429930395937&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;POSTECH",
        "aff_unique_dep": "Robotics Institute;Compute Vision Lab",
        "aff_unique_url": "https://www.cmu.edu;https://www.postech.ac.kr",
        "aff_unique_abbr": "CMU;POSTECH",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Pohang",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "8967785",
        "title": "GQ-STN: Optimizing One-Shot Grasp Detection based on Robustness Classifier",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping is a fundamental robotic task needed for the deployment of household robots or furthering warehouse automation. However, few approaches are able to perform grasp detection in real time (frame rate). To this effect, we present Grasp Quality Spatial Transformer Network (GQ-STN), a one-shot grasp detection network. Being based on the Spatial Transformer Network (STN), it produces not only a grasp configuration, but also directly outputs a depth image centered at this configuration. By connecting our architecture to an externally-trained grasp robustness evaluation network, we can train efficiently to satisfy a robustness metric via the backpropagation of the gradient emanating from the evaluation network. This removes the difficulty of training detection networks on sparsely annotated databases, a common issue in grasping. We further propose to use this robustness classifier to compare approaches, being more reliable than the traditional rectangle metric. Our GQ-STN is able to detect robust grasps on the depth images of the Dex-Net 2.0 dataset with 92.4 % accuracy in a single pass of the network. We finally demonstrate in a physical benchmark that our method can propose robust grasps more often than previous sampling-based methods, while being more than 60 times faster.",
        "primary_area": "",
        "author": "Alexandre Gari\u00e9py;Jean-Christophe Ruel;Brahim Chaib-draa;Philippe Gigu\u00e8re;Alexandre Gari\u00e9py;Jean-Christophe Ruel;Brahim Chaib-draa;Philippe Gigu\u00e8re",
        "authorids": "/37087322427;/37087323693;/38274564000;/37560636500;/37087322427;/37087323693;/38274564000;/37560636500",
        "aff": "Alexandre Gari\u00e9py; Jean-Christophe Ruel; Brahim Chaib-draa; Philippe Gigu\u00e8re",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967785/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13848596880942592582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8967983",
        "title": "GRIP: Generative Robust Inference and Perception for Semantic Robot Manipulation in Adversarial Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements have led to a proliferation of machine learning systems used to assist humans in a wide range of tasks. However, we are still far from accurate, reliable, and resource-efficient operations of these systems. For robot perception, convolutional neural networks (CNNs) for object detection and pose estimation are recently coming into widespread use. However, neural networks are known to suffer from overfitting during the training process and are less robust under unforeseen conditions (which makes them especially vulnerable to adversarial scenarios). In this work, we propose Generative Robust Inference and Perception (GRIP) as a two-stage object detection and pose estimation system that aims to combine the relative strengths of discriminative CNNs and generative inference methods to achieve robust estimation. Our results show that a second stage of sample-based generative inference is able to recover from false object detections by CNNs, and produce robust estimations in adversarial conditions. We demonstrate the efficacy of GRIP robustness through comparison with state-of-the-art learning-based pose estimators and pick-and-place manipulation in dark and cluttered environments.",
        "primary_area": "",
        "author": "Xiaotong Chen;Rui Chen;Zhiqiang Sui;Zhefan Ye;Yanqi Liu;R. Iris Bahar;Odest Chadwicke Jenkins;Xiaotong Chen;Rui Chen;Zhiqiang Sui;Zhefan Ye;Yanqi Liu;R. Iris Bahar;Odest Chadwicke Jenkins",
        "authorids": "/37087322826;/37087322231;/37085719413;/37086573971;/37086579462;/38556836200;/37297252400;/37087322826;/37087322231;/37085719413;/37086573971;/37086579462;/38556836200;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Computer Science and the School of Engineering, Brown University, Providence, RI, USA; Department of Computer Science and the School of Engineering, Brown University, Providence, RI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967983/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4637605949668861709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "University of Michigan;Brown University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Computer Science and School of Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.brown.edu",
        "aff_unique_abbr": "UM;Brown",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Ann Arbor;Providence",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968275",
        "title": "Gaussian Mixture Model (GMM) Based Object Detection and Tracking using Dynamic Patch Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we have developed a Gaussian Mixture Model (GMM) based algorithm with dynamic patch estimation for real-time detection and tracking of a known object. This research work detects the object of interest, estimates its 3-D position using Extended Kalman Filter (EKF) and generates the control output to the quad-rotor to track the target. The proposed algorithm is capable of tracking the object with a high Frame Per Second (FPS). Rigorous experiments are carried out to demonstrate the efficacy of the proposed approach in outdoor environment.",
        "primary_area": "",
        "author": "Vishnu Anand;Durgakant Pushp;Rishin Raj;Kaushik Das;Vishnu Anand;Durgakant Pushp;Rishin Raj;Kaushik Das",
        "authorids": "/37086941060;/37086945943;/37086451214;/37086084983;/37086941060;/37086945943;/37086451214;/37086084983",
        "aff": "Tata Consultancy Services (TCS) Research and Innovation Labs, Bangalore, India; Tata Consultancy Services (TCS) Research and Innovation Labs, Bangalore, India; Tata Consultancy Services (TCS) Research and Innovation Labs, Bangalore, India; Tata Consultancy Services (TCS) Research and Innovation Labs, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968275/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14958342184399279038&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Research and Innovation Labs",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8967843",
        "title": "Gaze Training by Modulated Dropout Improves Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning by behavioral cloning is a prevalent method that has achieved some success in vision-based autonomous driving. The basic idea behind behavioral cloning is to have the neural network learn from observing a human expert's behavior. Typically, a convolutional neural network learns to predict the steering commands from raw driver-view images by mimicking the behaviors of human drivers. However, there are other cues, such as gaze behavior, available from human drivers that have yet to be exploited. Previous researches have shown that novice human learners can benefit from observing experts' gaze patterns. We present here that deep neural networks can also profit from this. We propose a method, gaze-modulated dropout, for integrating this gaze information into a deep driving network implicitly rather than as an additional input. Our experimental results demonstrate that gaze-modulated dropout enhances the generalization capability of the network to unseen scenes. Prediction error in steering commands is reduced by 23.5% compared to uniform dropout. Running closed loop in the simulator, the gaze-modulated dropout net increased the average distance travelled between infractions by 58.5%. Consistent with these results, the gazemodulated dropout net shows lower model uncertainty.",
        "primary_area": "",
        "author": "Yuying Chen;Congcong Liu;Lei Tai;Ming Liu;Bertram E. Shi;Yuying Chen;Congcong Liu;Lei Tai;Ming Liu;Bertram E. Shi",
        "authorids": "/37086602838;/37086126145;/37086024718;/37085398677;/37275989700;/37086602838;/37086126145;/37086024718;/37085398677;/37275989700",
        "aff": "Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967843/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12157091433113400143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967779",
        "title": "Gaze-based Intention Anticipation over Driving Manoeuvres in Semi-Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Anticipating a human collaborator's intention enables safe and efficient interaction between a human and an autonomous system. Specifically, in the context of semiautonomous driving, studies have revealed that correct and timely prediction of the driver's intention needs to be an essential part of Advanced Driver Assistance System (ADAS) design. To this end, we propose a framework that exploits drivers' time-series eye gaze and fixation patterns to anticipate their real-time intention over possible future manoeuvres, enabling a smart and collaborative ADAS that can aid drivers to overcome safety-critical situations. The method models human intention as the latent states of a hidden Markov model and uses probabilistic dynamic time warping distributions to capture the temporal characteristics of the observation patterns of the drivers. The method is evaluated on a data set of 124 experiments from 75 drivers collected in a safety-critical semi-autonomous driving scenario. The results illustrate the efficacy of the framework by correctly anticipating the drivers' intentions about 3 seconds beforehand with over 90% accuracy.",
        "primary_area": "",
        "author": "Min Wu;Tyron Louw;Morteza Lahijanian;Wenjie Ruan;Xiaowei Huang;Natasha Merat;Marta Kwiatkowska;Min Wu;Tyron Louw;Morteza Lahijanian;Wenjie Ruan;Xiaowei Huang;Natasha Merat;Marta Kwiatkowska",
        "authorids": "/37087324865;/37087325135;/37398443600;/37085341447;/37086944121;/37086543788;/37271265100;/37087324865;/37087325135;/37398443600;/37085341447;/37086944121;/37086543788;/37271265100",
        "aff": "Department of Computer Science, University of Oxford, UK; Institute for Transport Studies, University of Leeds, UK; Dept. of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Computer Science, University of Oxford, UK; Department of Computer Science, University of Liverpool, UK; Institute for Transport Studies, University of Leeds, UK; Department of Computer Science, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967779/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2423236905719980649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;3;1;0",
        "aff_unique_norm": "University of Oxford;University of Leeds;University of Colorado Boulder;University of Liverpool",
        "aff_unique_dep": "Department of Computer Science;Institute for Transport Studies;Department of Aerospace Engineering Sciences;Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.leeds.ac.uk;https://www.colorado.edu;https://www.liverpool.ac.uk",
        "aff_unique_abbr": "Oxford;Leeds;CU Boulder;Liv Uni",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Boulder",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8967649",
        "title": "General Hand Guidance Framework using Microsoft HoloLens",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand guidance emerged from the safety requirements for collaborative robots, namely possessing joint-torque sensors. Since then it has proven to be a powerful tool for easy trajectory programming, allowing lay-users to reprogram robots intuitively. Going beyond, a robot can learn tasks by user demonstrations through kinesthetic teaching, enabling robots to generalise tasks and further reducing the need for reprogramming. However, hand guidance is still mostly relegated to collaborative robots. Here we propose a method that does not require any sensors on the robot or in the robot cell, by using a Microsoft HoloLens augmented reality head mounted display. We reference the robot using a registration algorithm to match the robot model to the spatial mesh. The in-built hand tracking and localisation capabilities are then used to calculate the position of the hands relative to the robot. By decomposing the hand movements into orthogonal rotations and propagating it down through the kinematic chain, we achieve a generalised hand guidance without the need to build a dynamic model of the robot itself. We tested our approach on a commonly used industrial manipulator, the KUKA KR-5.",
        "primary_area": "",
        "author": "David Puljiz;Erik St\u00f6hr;Katharina S. Riesterer;Bj\u00f6rn Hein;Torsten Kr\u00f6ger;David Puljiz;Erik St\u00f6hr;Katharina S. Riesterer;Bj\u00f6rn Hein;Torsten Kr\u00f6ger",
        "authorids": "/37086575797;/37086803282;/37086804557;/37604448500;/37283223400;/37086575797;/37086803282;/37086804557;/37604448500;/37283223400",
        "aff": "Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967649/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=337418865910625033&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967979",
        "title": "Generalized Contact Constraints of Hybrid Trajectory optimization for Different Terrains and Analysis of Sensitivity to Randomized Initial Guesses",
        "track": "main",
        "status": "Poster",
        "abstract": "To generate a dynamic bipedal walking with foot rolling motion for bipedal robot, hybrid trajectory optimization is capable of planning level walking with great energetic efficiency. However, the direct implementation of this optimization requires different sets of variables to express different active contact constraints, which can be complicated to implement. To simplify the optimization formulation, we propose the generalized contact constraints where the same set of variables are used through all the walking phases. By changing the variable and constraint bounds, different contact constraints for different contact conditions can be generally expressed. The proposed modifications are applied on the bipedal robot AMBER 3, where the optimization results on different terrains are compared and discussed. On the other hand, it is known that a randomized initial guess can be used to solve this optimization, yet its effect on the gaits on different terrains is unclear. As a result, we analyzed the sensitivity of the optimization to a set of randomized initial guesses. The level and downslope walking gaits are also validated via the experiments on AMBER 3.",
        "primary_area": "",
        "author": "Kenneth Chao;Pilwon Hur;Kenneth Chao;Pilwon Hur",
        "authorids": "/37085873416;/38317004800;/37085873416;/38317004800",
        "aff": "Department of Mechanical Engineering, Texas A & M University, 3123 TAMU, College Station, TX, USA; Department of Mechanical Engineering, Texas A & M University, 3123 TAMU, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967979/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11939481266471468058&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A & M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967884",
        "title": "Generalized Multiple Correlation Coefficient as a Similarity Measurement between Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Similarity distance measure between two trajectories is an essential tool to understand patterns in motion, for example, in Human-Robot Interaction or Imitation Learning. The problem has been faced in many fields, from Signal Processing, Probabilistic Theory field, Topology field or Statistics field. Anyway, up to now, none of the trajectory similarity measurement metrics are invariant to all possible linear transformation of the trajectories (rotation, scaling, reflection, shear mapping or squeeze mapping). Also not all of them are robust in front of noisy signals or fast enough for real-time trajectory classification. To overcome this limitation this paper proposes a similarity distance metric that will remain invariant in front of any possible linear transformation. Based on Pearson's Correlation Coefficient and the Coefficient of Determination, our similarity metric, the Generalized Multiple Correlation Coefficient (GMCC) is presented like the natural extension of the Multiple Correlation Coefficient. The motivation of this paper is two-fold: First, to introduce a new correlation metric that presents the best properties to compute similarities between trajectories invariant to linear transformations and compare it with some state of the art similarity distances. Second, to present a natural way of integrating the similarity metric in an Imitation Learning scenario for clustering robot trajectories.",
        "primary_area": "",
        "author": "Julen Urain;Jan Peters;Julen Urain;Jan Peters",
        "authorids": "/37086435541;/37533077600;/37086435541;/37533077600",
        "aff": "Intelligent Autonomous Systems, TU Darmstadt; Intelligent Autonomous Systems, TU Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967884/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1444091950331018498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TU Darmstadt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967616",
        "title": "Generate What You Can\u2019t See - a View-dependent Image Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to operate autonomously, a robot should explore the environment and build a model of each of the surrounding objects. A common approach is to carefully scan the whole workspace. This is time-consuming. It is also often impossible to reach all the viewpoints required to acquire full knowledge about the environment. Humans can perform shape completion of occluded objects by relying on past experience. Therefore, we propose a method that generates images of an object from various viewpoints using a single input RGB image. A deep neural network is trained to imagine the object appearance from many viewpoints. We present the whole pipeline, which takes a single RGB image as input and returns a sequence of RGB and depth images of the object. The method utilizes a CNN-based object detector to extract the object from the natural scene. Then, the proposed network generates a set of RGB and depth images. We show the results both on a synthetic dataset and on real images.",
        "primary_area": "",
        "author": "Karol Piaskowski;Rafal Staszak;Dominik Belter;Karol Piaskowski;Rafal Staszak;Dominik Belter",
        "authorids": "/37086494392;/37086934953;/37542853100;/37086494392;/37086934953;/37542853100",
        "aff": "Institute of Control, Robotics and Information Engineering Poznan University of Technology, Poznan, Poland; Institute of Control, Robotics and Information Engineering Poznan University of Technology, Poznan, Poland; Institute of Control, Robotics and Information Engineering Poznan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967616/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2066234297020652422&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Poznan University of Technology",
        "aff_unique_dep": "Institute of Control, Robotics and Information Engineering",
        "aff_unique_url": "https://www.put.poznan.pl/",
        "aff_unique_abbr": "PUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Poznan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "8968115",
        "title": "Generating Grasp Poses for a High-DOF Gripper Using Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a learning-based method for representing grasp poses of a high-DOF hand using neural networks. Due to redundancy in such high-DOF grippers, there exists a large number of equally effective grasp poses for a given target object, making it difficult for the neural network to find consistent grasp poses. We resolve this ambiguity by generating an augmented dataset that covers many possible grasps for each target object and train our neural networks using a consistency loss function to identify a one-to-one mapping from objects to grasp poses. We further enhance the quality of neural-network-predicted grasp poses using a collision loss function to avoid penetrations. We use an object dataset that combines the BigBIRD Database, the KIT Database, the YCB Database, and the Grasp Dataset to show that our method can generate high-DOF grasp poses with higher accuracy than supervised learning baselines. The quality of the grasp poses is on par with the groundtruth poses in the dataset. In addition, our method is robust and can handle noisy object models such as those constructed from multi-view depth images, allowing our method to be implemented on a 25-DOF Shadow Hand hardware platform.",
        "primary_area": "",
        "author": "Min Liu;Zherong Pan;Kai Xu;Kanishka Ganguly;Dinesh Manocha;Min Liu;Zherong Pan;Kai Xu;Kanishka Ganguly;Dinesh Manocha",
        "authorids": "/37087325367;/37086067204;/37085628970;/37086087472;/37267825600;/37087325367;/37086067204;/37085628970;/37086087472;/37267825600",
        "aff": "School of Computer, National University of Defense Technology; Department of Computer Science, University of North Carolina at Chapel Hill; School of Computer, National University of Defense Technology; UMIACS (Institute for Advanced Computer Studies), University of Maryland at College Park; Department of Computer Science and Electrical & Computer Engineering, University of Maryland at College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968115/",
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15458137054833574404&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "National University of Defense Technology;University of North Carolina at Chapel Hill;University of Maryland",
        "aff_unique_dep": "School of Computer;Department of Computer Science;Institute for Advanced Computer Studies",
        "aff_unique_url": "http://www.nudt.edu.cn/;https://www.unc.edu;https://www.umd.edu",
        "aff_unique_abbr": "NUDT;UNC Chapel Hill;UMD",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";Chapel Hill;College Park",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8967902",
        "title": "Generating a Key Pose Sequence Based on Kinematics and Statics Optimization for Manipulating a Heavy Object by a Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "When a humanoid robot manipulates a heavy object, balance and heavy loads become problems. To solve these problems, we provide a method to generate a key pose sequence of the robot and the object which balance constraints and joint torque limits are kept. As we consider the configurations of both the robot and the object, the key poses of them are optimized in a view of kinematics and statics. Moreover, we generate a smooth key pose sequence by adding an objective function which makes adjacent poses closer. By using the proposed method, we make a humanoid robot RHP4B place a heavy suitcase on a step.",
        "primary_area": "",
        "author": "Riku Shigematsu;Masaki Murooka;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Riku Shigematsu;Masaki Murooka;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086599351;/37085365946;/38242437800;/37280639000;/37286658200;/37086599351;/37085365946;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967902/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11093191925085150558&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967795",
        "title": "Generating an image of an object\u2019s appearance from somatosensory information during haptic exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual occlusions caused by the environment or by the robot itself can be a problem for object recognition during manipulation by a robot hand. Under such conditions, tactile and somatosensory information are useful for object recognition during manipulation. Humans can visualize the appearance of invisible objects from only the somatosensory information provided by their hands. In this paper, we propose a method to generate an image of an invisible object's posture from the joint angles and touch information provided by robot fingers while touching the object. We show that the object's posture can be estimated from the time-series of the joint angles of the robot hand via regression analysis. In addition, conditional generative adversarial networks can generate an image to show the appearance of the invisible objects from their estimated postures. Our approach enables user-friendly visualization of somatosensory information in remote control applications.",
        "primary_area": "",
        "author": "Kento Sekiya;Yoshiyuki Ohmura;Yasuo Kuniyoshi;Kento Sekiya;Yoshiyuki Ohmura;Yasuo Kuniyoshi",
        "authorids": "/37087322369;/37581602900;/37299294900;/37087322369;/37581602900;/37299294900",
        "aff": "Faculty of Engineering, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967795/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16004113745674200315&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967852",
        "title": "Geometric and Physical Constraints for Drone-Based Head Plane Crowd Density Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density in the image plane. While useful for this purpose, this image-plane density has no immediate physical meaning because it is subject to perspective distortion. This is a concern in sequences acquired by drones because the viewpoint changes often. This distortion is usually handled implicitly by either learning scale-invariant features or estimating density in patches of different sizes, neither of which accounts for the fact that scale changes must be consistent over the whole scene.In this paper, we explicitly model the scale changes and reason in terms of people per square-meter. We show that feeding the perspective model to the network allows us to enforce global scale consistency and that this model can be obtained on the fly from the drone sensors. In addition, it also enables us to enforce physically-inspired temporal consistency constraints that do not have to be learned. This yields an algorithm that outperforms state-of-the-art methods in inferring crowd density from a moving drone camera especially when perspective effects are strong.",
        "primary_area": "",
        "author": "Weizhe Liu;Krzysztof Lis;Mathieu Salzmann;Pascal Fua;Weizhe Liu;Krzysztof Lis;Mathieu Salzmann;Pascal Fua",
        "authorids": "/37087230959;/37089854917;/37397917300;/37281288800;/37087230959;/37089854917;/37397917300;/37281288800",
        "aff": "School of Communication and Computer Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; School of Communication and Computer Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; School of Communication and Computer Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; School of Communication and Computer Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967852/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5230199567686211192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "School of Communication and Computer Sciences",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967685",
        "title": "GlassLoc: Plenoptic Grasp Pose Detection in Transparent Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Transparent objects are prevalent across many environments of interest for dexterous robotic manipulation. Such transparent material leads to considerable uncertainty for robot perception and manipulation, and remains an open challenge for robotics. This problem is exacerbated when multiple transparent objects cluster into piles of clutter. In household environments, for example, it is common to encounter piles of glassware in kitchens, dining rooms, and reception areas, which are essentially invisible to modern robots. We present the GlassLoc algorithm for grasp pose detection of transparent objects in transparent clutter using plenoptic sensing. GlassLoc classifies graspable locations in space informed by a Depth Likelihood Volume (DLV) descriptor. We extend the DLV to infer the occupancy of transparent objects over a given space from multiple plenoptic viewpoints. We demonstrate and evaluate the GlassLoc algorithm on a Michigan Progress Fetch mounted with a first generation Lytro. The effectiveness of our algorithm is evaluated through experiments for grasp detection and execution with a variety of transparent glassware in minor clutter.",
        "primary_area": "",
        "author": "Zheming Zhou;Tianyang Pan;Shiyu Wu;Haonan Chang;Odest Chadwicke Jenkins;Zheming Zhou;Tianyang Pan;Shiyu Wu;Haonan Chang;Odest Chadwicke Jenkins",
        "authorids": "/37086284210;/37086938153;/37086933335;/37087323802;/37297252400;/37086284210;/37086938153;/37086933335;/37087323802;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967685/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=669108525986028710&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968301",
        "title": "Global Vision-Based Impedance Control for Robotic Wall Polishing",
        "track": "main",
        "status": "Poster",
        "abstract": "Wall polishing is a typical and essential procedure in the interior renovation. However, such works are mainly carried out by humans, which have the disadvantages of low efficiency, inconsistent quality, and issues of safety and health. A new vision-based impedance controller is proposed for polishing robots to automate the labor-intensive works. The desired impedance model is specified as the control objective to regulate the dynamic relationship between the interaction force and the motion of the robot end effector, where the motion is measured with the vision feedback. The use of the vision feedback guarantees the performance of the robot from two aspect. First, the vision feedback from the high-resolution camera ensures the accuracy of measurement of the robot end effector and hence guarantees the quality of polishing. Second, the concept of image moment is introduced such that the image Jacobian matrix is non-singular in a global sense, which guarantees the large working range of the robot. The dynamic stability of the closed-loop system is rigorously proved with Lyapunov methods, and experimental results are presented to illustrate the performance of the proposed controller.",
        "primary_area": "",
        "author": "Yang Zhou;Xiang Li;Linzhu Yue;Linhai Gui;Guangli Sun;Xin Jiang;Yun-Hui Liu;Yang Zhou;Xiang Li;Linzhu Yue;Linhai Gui;Guangli Sun;Xin Jiang;Yun-Hui Liu",
        "authorids": "/37086348797;/37280877200;/37087053034;/37087052837;/37086356287;/37086028734;/37279412600;/37086348797;/37280877200;/37087053034;/37087052837;/37086356287;/37086028734;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Automation, Tsinghua University; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968301/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3130264135879608595&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Tsinghua University;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Automation;School of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.tsinghua.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "CUHK;THU;HIT",
        "aff_campus_unique_index": "0;0;0;0;2;0",
        "aff_campus_unique": "Hong Kong SAR;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968597",
        "title": "Goal-Directed Behavior under Variational Predictive Coding: Dynamic organization of Visual Attention and Working Memory",
        "track": "main",
        "status": "Poster",
        "abstract": "Mental simulation is a critical cognitive function for goal-directed behavior because it is essential for assessing actions and their consequences. When a self-generated or externally specified goal is given, a sequence of actions that is most likely to attain that goal is selected among other candidates via mental simulation. Therefore, better mental simulation leads to better goal-directed action planning. However, developing a mental simulation model is challenging because it requires knowledge of self and the environment. The current paper studies how adequate goal-directed action plans of robots can be mentally generated by dynamically organizing top-down visual attention and visual working memory. For this purpose, we propose a neural network model based on variational Bayes predictive coding, where goal-directed action planning is formulated by Bayesian inference of latent intentional space. Our experimental results showed that cognitively meaningful competencies, such as autonomous top-down attention to the robot end effector (its hand) as well as dynamic organization of occlusion-free visual working memory, emerged. Furthermore, our analysis of comparative experiments indicated that the introduction of visual working memory and the inference mechanism using variational Bayes predictive coding significantly improved the performance in planning adequate goal-directed actions.",
        "primary_area": "",
        "author": "Minju Jung;Takazumi Matsumoto;Jun Tani;Minju Jung;Takazumi Matsumoto;Jun Tani",
        "authorids": "/37085380803;/37087323550;/37281617800;/37085380803;/37087323550;/37281617800",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, Korea; Okinawa Institute of Science and Technology, Okinawa, Japan; Okinawa Institute of Science and Technology, Okinawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968597/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12681373571648690585&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Okinawa Institute of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.oist.jp",
        "aff_unique_abbr": "KAIST;OIST",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Daejeon;Okinawa",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "South Korea;Japan"
    },
    {
        "id": "8968252",
        "title": "Graph-Based Design of Hierarchical Reinforcement Learning Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "There is an increasing interest in Reinforcement Learning to solve new and more challenging problems, as those emerging in robotics and unmanned autonomous vehicles. To face these complex systems, a hierarchical and multi-scale representation is crucial. This has brought the interest on Hierarchical Deep Reinforcement learning systems. Despite their successful application, Deep Reinforcement Learning systems suffer from a variety of drawbacks: they are data hungry, they lack of interpretability, and it is difficult to derive theoretical properties about their behavior. Classical Hierarchical Reinforcement Learning approaches, while not suffering from these drawbacks, are often suited for finite actions, and finite states, only. Furthermore, in most of the works, there is no systematic way to represent domain knowledge, which is often only embedded in the reward function. We present a novel Hierarchical Reinforcement Learning framework based on the hierarchical design approach typical of control theory. We developed our framework extending the block diagram representation of control systems to fit the needs of a Hierarchical Reinforcement Learning scenario, thus giving the possibility to integrate domain knowledge in an effective hierarchical architecture.",
        "primary_area": "",
        "author": "Davide Tateo;\u0130dil Su Erdenli\u011f;Andrea Bonarini;Davide Tateo;\u0130dil Su Erdenli\u011f;Andrea Bonarini",
        "authorids": "/37086271891;/37087323316;/37374420900;/37086271891;/37087323316;/37374420900",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano Piazza Leonardo da Vinci 32, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968252/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3412522547859797559&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968151",
        "title": "Graph-based Path Planning for Autonomous Robotic Exploration in Subterranean Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel strategy for autonomous graph-based exploration path planning in subterranean environments. Attuned to the fact that subterranean settings, such as underground mines, are often large-scale networks of narrow tunnel-like and multi-branched topologies, the proposed planner is structured around a bifurcated local-and global-planner architecture. The local planner employs a rapidly-exploring random graph to reliably and efficiently identify collision-free paths that optimize an exploration gain within a local subspace. Accounting for the robot endurance limitations and the possibility that the local planner reaches a dead-end (e.g. a mine heading), the global planner is engaged when a return-to-home path must be derived or when the robot should be re-positioned towards an edge of the exploration space. The proposed planner is field evaluated in a collection of deployments inside both active and abandoned underground mines in the U.S. and in Switzerland.",
        "primary_area": "",
        "author": "Tung Dang;Frank Mascarich;Shehryar Khattak;Christos Papachristos;Kostas Alexis;Tung Dang;Frank Mascarich;Shehryar Khattak;Christos Papachristos;Kostas Alexis",
        "authorids": "/37086410051;/37086409687;/37086181358;/37681703400;/37546514600;/37086410051;/37086409687;/37086181358;/37681703400;/37546514600",
        "aff": "Autonomous Robots Lab, University of Nevada, Reno 1664 N. Virginia 89557, Reno, NV, USA; Autonomous Robots Lab, University of Nevada, Reno 1664 N. Virginia 89557, Reno, NV, USA; Autonomous Robots Lab, University of Nevada, Reno 1664 N. Virginia 89557, Reno, NV, USA; Autonomous Robots Lab, University of Nevada, Reno 1664 N. Virginia 89557, Reno, NV, USA; Autonomous Robots Lab, University of Nevada, Reno 1664 N. Virginia 89557, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968151/",
        "gs_citation": 196,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=236804425845118932&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Autonomous Robots Lab",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967989",
        "title": "Grasping Unknown Objects Based on Gripper Workspace Spheres",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel grasp planning algorithm for unknown objects given a registered point cloud of the target from different views. The proposed methodology requires no prior knowledge of the object, nor offline learning. In our approach, the gripper kinematic model is used to generate a point cloud of each finger workspace, which is then filled with spheres. At run-time, first the object is segmented, its major axis is computed, in a plane perpendicular to which, the main grasping action is constrained. The object is then uniformly sampled and scanned for various gripper poses that assure at least one object point is located in the workspace of each finger. In addition, collision checks with the object or the table are performed using computationally inexpensive gripper shape approximation. Our methodology is both time efficient (consumes less than 1.5 seconds in average) and versatile. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand).",
        "primary_area": "",
        "author": "Mohamed Sorour;Khaled Elgeneidy;Aravinda Srinivasan;Marc Hanheide;Gerhard Neumann;Mohamed Sorour;Khaled Elgeneidy;Aravinda Srinivasan;Marc Hanheide;Gerhard Neumann",
        "authorids": "/37085622077;/37086581226;/37087323379;/37270387300;/38542033100;/37085622077;/37086581226;/37087323379;/37270387300;/38542033100",
        "aff": "Lincoln Center for Autonomous Systems (L-CAS), School of Computer Science, University of Lincoln, Brayford Pool, LN6 7TS Lincoln, United Kingdom; Lincoln Center for Autonomous Systems (L-CAS), School of Computer Science, University of Lincoln, Brayford Pool, LN6 7TS Lincoln, United Kingdom; Lincoln Center for Autonomous Systems (L-CAS), School of Computer Science, University of Lincoln, Brayford Pool, LN6 7TS Lincoln, United Kingdom; Lincoln Center for Autonomous Systems (L-CAS), School of Computer Science, University of Lincoln, Brayford Pool, LN6 7TS Lincoln, United Kingdom; Lincoln Center for Autonomous Systems (L-CAS), School of Computer Science, University of Lincoln, Brayford Pool, LN6 7TS Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967989/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7143193392385085979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Brayford Pool",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968603",
        "title": "Grounding Language Attributes to Objects using Bayesian Eigenobjects",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a system to disambiguate object instances within the same class based on simple physical descriptions. The system takes as input a natural language phrase and a depth image containing a segmented object and predicts how similar the observed object is to the object described by the phrase. Our system is designed to learn from only a small amount of human-labeled language data and generalize to viewpoints not represented in the language-annotated depth image training set. By decoupling 3D shape representation from language representation, this method is able to ground language to novel objects using a small amount of language-annotated depth-data and a larger corpus of unlabeled 3D object meshes, even when these objects are partially observed from unusual viewpoints. Our system is able to disambiguate between novel objects, observed via depth images, based on natural language descriptions. Our method also enables viewpoint transfer; trained on human-annotated data on a small set of depth images captured from frontal viewpoints, our system successfully predicted object attributes from rear views despite having no such depth images in its training set. Finally, we demonstrate our approach on a Baxter robot, enabling it to pick specific objects based on human-provided natural language descriptions.",
        "primary_area": "",
        "author": "Vanya Cohen;Benjamin Burchfiel;Thao Nguyen;Nakul Gopalan;Stefanie Tellex;George Konidaris;Vanya Cohen;Benjamin Burchfiel;Thao Nguyen;Nakul Gopalan;Stefanie Tellex;George Konidaris",
        "authorids": "/37087322494;/37086580390;/37087324360;/37077656800;/37402794800;/38318614200;/37087322494;/37086580390;/37087324360;/37077656800;/37402794800;/38318614200",
        "aff": "Vanya Cohen; Benjamin Burchfiel; Thao Nguyen; Nakul Gopalan; Stefanie Tellex; George Konidaris",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968603/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8619798204396011679&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 17,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "8967968",
        "title": "Guinea fowl Jumping Robot with Balance Control Mechanism: Modeling, simulation, and experiment results",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, diverse research has actively been conducted to control the posture of jumping robots using an inertial tail mechanism. However, the inertial tail mechanism has a high probability of collision with obstacles. In this study, a momentum wheel mechanism is proposed to achieve the same attitude control performance while reducing the volume occupied by the inertial tail mechanism. To verify the performance of the momentum wheel mechanism, we proposed a jumping robot with a momentum wheel mechanism and performed a dynamic analysis, simulation, and experiments on a jumping robot with a momentum wheel mechanism. In addition, it has been demonstrated that the momentum wheel mechanism can contribute to control of the body angle of the jumping robot. As a result, the momentum wheel mechanism can enhance the stability of the jumping robot more than the tail mechanism, and the momentum wheel mechanism contributes to the attitude control of the body angle, which allows the jumping robot to perform continuous jumping.",
        "primary_area": "",
        "author": "Myeongjin Kim;Dongwon Yun;Myeongjin Kim;Dongwon Yun",
        "authorids": "/37086268881;/37589762000;/37086268881;/37589762000",
        "aff": "Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967968/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11140125383667506934&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967773",
        "title": "HaptiCube: a Compact 5-DoF Finger-wearable Tactile Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a novel cube-shaped finger-wearable haptic interface named as HaptiCube. With the aim of implementing the tactile device with improved functionality and wearability, we focus on designing the device to have two characteristics: multi-DOF force feedback displayability and large force capability with compact and lightweight structure. In designing the device, we mainly consider the type and configuration of actuator and driving mechanism, since both have a great effect on the size, weight, and output force of the device. As the actuator, we select the shape memory alloy exhibiting high energy density. And, as the driving mechanism, two different types of compliant mechanism are designed for two important functions: to convert contraction of the SMA to the desired motion as a motion guide and to apply bias-force to the SMA as a bias-spring. The device is designed as the miniature interface that can display 3-DOF pressure and 2-DOF shearing force to user\u2019s fingerpad. And, it is implemented as the functional prototype with the total weight of 26 g including actuators and all mechanical components. The experimental results on working performances (e.g. stroke, output force, and bandwidth) demonstrate that the device has superiority in terms of multi-DOF displayability, compact-sizability and wearability.",
        "primary_area": "",
        "author": "Byeongkyu Lim;Keehoon Kim;Sang-Rok Oh;Donghyun Hwang;Byeongkyu Lim;Keehoon Kim;Sang-Rok Oh;Donghyun Hwang",
        "authorids": "/37086355008;/37066398600;/37279130300;/38017242900;/37086355008;/37066398600;/37279130300;/38017242900",
        "aff": "Department of Mechanical Engineering, Korea University, Seoul, South Korea; Center for Intelligent and Interactive Robotics Research, Korea Institute of Science and Technology, Seoul, South Korea; Center for Intelligent and Interactive Robotics Research, Korea Institute of Science and Technology, Seoul, South Korea; Center for Intelligent and Interactive Robotics Research, Korea Institute of Science and Technology, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967773/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Korea University;Korea Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Center for Intelligent and Interactive Robotics Research",
        "aff_unique_url": "http://www.korea.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "KU;KIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967712",
        "title": "Haptic Guidance for Robot-Assisted Endovascular Procedures: Implementation and Evaluation on Surgical Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Vascular diseases are the most common precursors to ischemic heart disease and stroke, which are two of the leading causes of death worldwide. Endovascular intervention is a minimally invasive surgical approach to treat such diseases. Compared to open surgery, it has the advantages of faster recovery, reduced need for general anesthesia, reduced blood loss and significantly lower mortality. Endovascular procedures require high surgical skills to minimize contacts between the manipulated instruments (catheters and guidewires) and the vessel wall, which represent one of the major risks for the patient. Robotic assistance can potentially improve the precision and stability of instruments manipulation. One key limitation of current commercial robotic platforms is the lack of haptic feedback, preventing their acceptance and limiting the clinical usability. This paper proposes to bring the benefit of haptic feedback to robot-assisted endovascular intervention. Here we hypothesize that the introduction of 3D haptic guidance during robot-assisted endovascular procedure can further improve the surgical performance and safety while overcoming the limitations of currently available technology. The proposed 3D haptic guidance allows the surgeon to sense the vasculature while controlling a catheter through a robotic haptic manipulator. Validation of the system is performed through end-user experiments with vascular surgeons on a bespoke surgical simulator. The obtained results demonstrate that 3D haptic guidance has the potential of improving effectiveness, precision, and safety of endovascular intervention. Furthermore, vascular surgeons found the proposed technology safe and overall easy to use, indicating its potential on real surgical procedures.",
        "primary_area": "",
        "author": "M. B. Molinero;G. Dagnino;J. Liu;W. Chi;M. E. M. K. Abdelaziz;T.M.Y. Kwok;C. Riga;G.Z. Yang;M. B. Molinero;G. Dagnino;J. Liu;W. Chi;M. E. M. K. Abdelaziz;T.M.Y. Kwok;C. Riga;G.Z. Yang",
        "authorids": "/37087323226;/38229367400;/37879388800;/37086143479;/37086453351;/37087324672;/37085591245;/37276270800;/37087323226;/38229367400;/37879388800;/37086143479;/37086453351;/37087324672;/37085591245;/37276270800",
        "aff": "Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Department of Surgery & Cancer, Imperial College London, UK; Department of Surgery & Cancer, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967712/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10382118281634289940&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968528",
        "title": "Haptic Perception of Liquids Enclosed in Containers",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots will require several important manipulation skills, including the ability to accurately measure and pour liquids. Prior work on robotic liquid pouring has primarily focused on visual techniques for sensing liquids, but these techniques fall short when liquids are obscured by opaque or closed containers. This paper proposes a complementary method for liquid perception via haptic sensing. The robot moves a container through a series of tilting motions and observes the wrenches induced at the manipulator's wrist by the liquid's shifting center of mass. That data is then analyzed with a physics-based model to estimate the liquid's mass and volume. In experiments, this method achieves error margins of less than lg and 2mL for an unknown liquid in a 600mL cylindrical container. The model can also predict the viscosity of fluids, which can be used for classifying water, oil, and honey with an accuracy of 98%. The estimated volume is used to precisely pour 100mL of water with less than 4% average error.",
        "primary_area": "",
        "author": "Carolyn Matl;Robert Matthew;Ruzena Bajcsy;Carolyn Matl;Robert Matthew;Ruzena Bajcsy",
        "authorids": "/37087324669;/37085613583;/37298488400;/37087324669;/37085613583;/37298488400",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968528/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9936786145880303706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968494",
        "title": "Haptic Shared-Control Methods for Robotic Cutting under Nonholonomic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted cutting is considered an important task in several fields, such as robotic surgery, nuclear decommissioning, waste management, and manufacturing. Despite the complex dexterity requirements of cutting tasks, very simple mechanically-linked master-slave manipulators still dominate many of the above fields (e.g., nuclear robotics). Moreover, even when more dexterous manipulators are available (e.g., in robot-assisted surgery), the employed systems show little or no autonomy, delegating all control to the experience of the human operator. To ameliorate this situation, we present two haptic shared-control approaches for robotic cutting. They are designed to assist the human operator by enforcing different nonholonomic-like constraints representative of the cutting kinematics. To validate our approach, we carried out a human-subject experiment in a real cutting scenario. We compared our shared-control techniques with each other and with a standard haptic teleoperation scheme. Results show the usefulness of assisted control schemes in complex applications such as cutting. However, they also show a discrepancy between objective and subjective metrics.",
        "primary_area": "",
        "author": "Rahaf Rahal;Firas Abi-Farraj;Paolo Robuffo Giordano;Claudio Pacchierotti;Rahaf Rahal;Firas Abi-Farraj;Paolo Robuffo Giordano;Claudio Pacchierotti",
        "authorids": "/37087323548;/37086034393;/37544316400;/38513576600;/37087323548;/37086034393;/37544316400;/38513576600",
        "aff": "Univ Rennes, Inria, CNRS, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968494/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6379312156576747236&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Rennes;CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.univ-rennes1.fr;https://www.cnrs.fr",
        "aff_unique_abbr": "Univ Rennes;CNRS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Rennes;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968109",
        "title": "Haptic-guided shared control for needle grasping optimization in minimally invasive robotic surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "During suturing tasks performed with minimally invasive surgical robots, configuration singularities and joint limits often force surgeons to interrupt the task and re-grasp the needle using dual-arm movements. This yields an increased operator's cognitive load, time-to-completion and performance degradation. In this paper, we propose a haptic-guided shared control method for grasping the needle with the Patient Side Manipulator (PSM) of the da Vinci robot avoiding such issues. We suggest a cost function consisting of (i) the distance from robot joint limits and (ii) the task-oriented manipulability along the suturing trajectory. Evaluating the cost and its gradient on the needle grasping manifold allows us to obtain the optimal grasping pose for joint-limit and singularity free robot movements during suturing. We compute force cues and display them through the Master Tool Manipulator (MTM) to guide the surgeon towards the optimal grasp. As such, our system helps the operator to choose a grasping configuration that allows the robot to avoid joint limits and singularities during post-grasp suturing movements. We show the effectiveness of the proposed haptic-guided shared control method during suturing using both simulated and real experiments. The results illustrate that our approach significantly improves the performance in terms of needle re-grasping.",
        "primary_area": "",
        "author": "Mario Selvaggio;Amir M. Ghalamzan E;Rocco Moccia;Fanny Ficuciello;Bruno Siciliano;Mario Selvaggio;Amir M. Ghalamzan E;Rocco Moccia;Fanny Ficuciello;Bruno Siciliano",
        "authorids": "/37085859695;/37087325238;/37087325268;/37594404000;/37282449100;/37085859695;/37087325238;/37087325268;/37594404000;/37282449100",
        "aff": "Universit\u00e0 degli Studi di Napoli Federico II, Italy; University of Lincoln, UK; Universit\u00e0 degli Studi di Napoli Federico II, Italy; Universit\u00e0 degli Studi di Napoli Federico II, Italy; Universit\u00e0 degli Studi di Napoli Federico II, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968109/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2139644477836107327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Napoli Federico II;University of Lincoln",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unina.it;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UNINA;UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "8967721",
        "title": "Harmonious Sampling for Mobile Manipulation Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulation planning commonly adopts a decoupled approach that performs planning separately on the base and the manipulator. While this approach is fast, it can generate sub-optimal paths. Another direction is a coupled approach jointly adjusting the base and manipulator in a high-dimensional configuration space. This coupled approach addresses sub-optimality and incompleteness of the decoupled approach, but has not been widely used due to its excessive computational overhead. Given this trade-off space, we present a simple, yet effective mobile manipulation sampling method, harmonious sampling, to perform the coupled approach mainly in difficult regions, where we need to simultaneously maneuver the base and the manipulator. Our method identifies such difficult regions through a low-dimensional base space by utilizing a reachability map given the target end-effector pose and narrow passage detected by generalized Voronoi diagram. For the rest of simple regions, we perform sampling mainly on the base configurations with a predefined joint configuration, accelerating the planning process. We compare our method with the decoupled and coupled approaches in six different problems with varying difficulty. Our method shows meaningful improvements experimentally in terms of time to find an initial solution (up to 5.6 times faster) and final solution cost (up to 17% lower) over the decoupled approach, especially in difficult scenes with narrow space. We also demonstrate these benefits with a real, mobile Hubo robot.",
        "primary_area": "",
        "author": "Mincheul Kang;Donghyuk Kim;Sung-Eui Yoon;Mincheul Kang;Donghyuk Kim;Sung-Eui Yoon",
        "authorids": "/37086439291;/37085771730;/37066068100;/37086439291;/37085771730;/37066068100",
        "aff": "School of Computing; School of Computing; Faculty of School of Computing, KAIST at Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967721/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11412507381896695185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "School of Computing;KAIST",
        "aff_unique_dep": "Computing;School of Computing",
        "aff_unique_url": ";https://www.kaist.ac.kr",
        "aff_unique_abbr": ";KAIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Daejeon",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";South Korea"
    },
    {
        "id": "8967904",
        "title": "Heuristic-based Multiple Mobile Depots Route Planning for Recharging Persistent Surveillance Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Persistent surveillance of a target space using multiple unmanned aerial vehicles (UAVs) has multiple applications such as geographical surveys, air quality monitoring, and security monitoring. The limited onboard battery capacity challenges the continuous operation in these applications of persistent robots. We consider the problem for recharging persistent robots using mobile depots. The mobile depots collectively compute a set of tours to recharge all persistent robots with the minimum total cost. Compared to other works, the persistent UAVs are not required to detour to a static depot for energy replenishment such as recharging or battery swapping. We formulate this problem as a Generalized Multiple Depots Travelling Salesman Problem (GMDTSP) on a complete graph. A heuristic-based algorithm Multiple Depots Random Select (RSMD) is proposed to solve the recharging problem efficiently. The RSMD has proved to have an analytical constant upper bound in the worst-case scenario. We also propose a post-processing heuristic (RSMD-IM) to improve the solution quality further. We demonstrate the efficiency and effectiveness of our algorithm via benchmark on multiple instances from TSPLIB and GTSPLIB. The simulation results show that RSMD and RSMD-IM will perform significantly faster than the state of the art heuristic solver LKH with a loss of about 10% of solution quality.",
        "primary_area": "",
        "author": "Yifan Ding;Wenhao Luo;Katia Sycara;Yifan Ding;Wenhao Luo;Katia Sycara",
        "authorids": "/37087088807;/37085748889;/37268476900;/37087088807;/37085748889;/37268476900",
        "aff": "School of Computer Science, Robotics Institute, Carnegie Mellon University Pittsburgh, Pennsylvania, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University Pittsburgh, Pennsylvania, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University Pittsburgh, Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967904/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12060290689014079764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science, Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968149",
        "title": "Hierarchical Reinforcement Learning for Concurrent Discovery of Compound and Composable Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "A common strategy to deal with the expensive reinforcement learning (RL) of complex tasks is to decompose them into a collection of subtasks that are usually simpler to learn as well as reusable for new problems. However, when a robot learns the policies for these subtasks, common approaches treat every policy learning process separately. Therefore, all these individual (composable) policies need to be learned before tackling the learning process of the complex task through policies composition. Moreover, such composition of individual policies is usually performed sequentially, which is not suitable for tasks that require to perform the subtasks concurrently. In this paper, we propose to combine a set of composable Gaussian policies corresponding to these subtasks using a set of activation vectors, resulting in a complex Gaussian policy that is a function of the means and covariances matrices of the composable policies. Moreover, we propose an algorithm for learning both compound and composable policies within the same learning process by exploiting the off-policy data generated from the compound policy. The algorithm is built on a maximum entropy RL approach to favor exploration during the learning process. The results of the experiments show that the experience collected with the compound policy permits not only to solve the complex task but also to obtain useful composable policies that successfully perform in their corresponding subtasks.",
        "primary_area": "",
        "author": "Domingo Esteban;Leonel Rozo;Darwin G. Caldwell;Domingo Esteban;Leonel Rozo;Darwin G. Caldwell",
        "authorids": "/37086148546;/38228060200;/37295680400;/37086148546;/38228060200;/37295680400",
        "aff": "Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Bosch Center for Artificial Intelligence, Renningen, Germany; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968149/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1745201483571909999&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Department of Advanced Robotics;Artificial Intelligence",
        "aff_unique_url": "https://www.iit.it;https://www.bosch-ai.com",
        "aff_unique_abbr": "IIT;BCAI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Genova;Renningen",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "8967913",
        "title": "Hierarchical Reinforcement Learning for Quadruped Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged locomotion is a challenging task for learning algorithms, especially when the task requires a diverse set of primitive behaviors. To solve these problems, we introduce a hierarchical framework that can automatically learn to decompose complex locomotion tasks. A high-level policy issues commands in the form of a latent vector and also selects for how long the low-level policy will execute the latent command. Concurrently, the low-level policy uses the latent command and only the robot's on-board sensors to control the robot's actuators. Our approach allows the high-level policy to run at a lower frequency than the low-level one. We test our framework on a path-following task for a dynamic quadruped robot and we show that steering behaviors automatically emerge in the latent command space as low-level skills are needed for this task. We then show efficient adaptation of the trained policy to new tasks by transfer of the trained low-level policy. Finally, we validate the policies on a real quadruped robot. To the best of our knowledge, this is the first application of end-to-end hierarchical learning to a real robotic locomotion task.",
        "primary_area": "",
        "author": "Deepali Jain;Atil Iscen;Ken Caluwaerts;Deepali Jain;Atil Iscen;Ken Caluwaerts",
        "authorids": "/37087325315;/37085362056;/37586652300;/37087325315;/37085362056;/37586652300",
        "aff": "Robotics at Google, New York, USA; Robotics at Google, New York, USA; Robotics at Google, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967913/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16801297130140592754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967987",
        "title": "High-dimensional Motion Segmentation by Variational Autoencoder and Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans perceive continuous high-dimensional information by dividing it into significant segments such as words and units of motion. We believe that such unsupervised segmentation is also important for robots to learn topics such as language and motion. To this end, we previously proposed a hierarchical Dirichlet process-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). However, an important drawback to this model is that it cannot divide high-dimensional time-series data. Further, low-dimensional features must be extracted in advance. Segmentation largely depends on the design of features, and it is difficult to design effective features, especially in the case of high-dimensional data. To overcome this problem, this paper proposes a hierarchical Dirichlet process-variational autoencoder-Gaussian process-hidden semi-Markov model (HVGH). The parameters of the proposed HVGH are estimated through a mutual learning loop of the variational autoencoder and our previously proposed HDP-GP-HSMM. Hence, HVGH can extract features from high-dimensional time-series data, while simultaneously dividing it into segments in an unsupervised manner. In an experiment, we used various motion-capture data to show that our proposed model estimates the correct number of classes and more accurate segments than baseline methods. Moreover, we show that the proposed method can learn latent space suitable for segmentation.",
        "primary_area": "",
        "author": "Masatoshi Nagano;Tomoaki Nakamura;Takayuki Nagai;Daichi Mochihashi;Ichiro Kobayashi;Wataru Takano;Masatoshi Nagano;Tomoaki Nakamura;Takayuki Nagai;Daichi Mochihashi;Ichiro Kobayashi;Wataru Takano",
        "authorids": "/37086580934;/37536789800;/37280601500;/37704486700;/37325070100;/37295985700;/37086580934;/37536789800;/37280601500;/37704486700;/37325070100;/37295985700",
        "aff": "Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Systems Innovation, Osaka University, Toyonaka-shi, Japan; Department of Statistical Inference and Mathematics, The Institute of Statistical Mathematics, Tachikawa, Japan; Department of Information Sciences, Ochanomizu University, Bunkyoku, Japan; Department of Systems Innovation, Osaka University, Toyonaka-shi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967987/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10777190291684303255&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;1",
        "aff_unique_norm": "University of Electro-Communications;Osaka University;Institute of Statistical Mathematics;Ochanomizu University",
        "aff_unique_dep": "Department of Mechanical Engineering and Intelligent Systems;Department of Systems Innovation;Department of Statistical Inference and Mathematics;Department of Information Sciences",
        "aff_unique_url": "https://www.uec.ac.jp;https://www.osaka-u.ac.jp;;https://www.ocha.ac.jp",
        "aff_unique_abbr": "UEC;Osaka U;;",
        "aff_campus_unique_index": "0;0;1;2;3;1",
        "aff_campus_unique": "Chofu-shi;Toyonaka-shi;Tachikawa;Bunkyoku",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968160",
        "title": "Homography-Based Deep Visual Servoing Methods for Planar Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a visual servoing framework for learning to improve grasps of objects. RGB and depth images from grasp attempts are collected using an automated data collection process. The data is then used to train a Grasp Quality Network (GQN) that predicts the outcome of grasps from visual information. A grasp optimization pipeline uses homography models with the trained network to optimize the grasp success rate. We evaluate and compare several algorithms for adjusting the current gripper pose based on the current observation from a gripper-mounted camera to perform visual servoing. Evaluations in both simulated and hardware environments show considerable improvement in grasp robustness with models trained using less than 30K grasp trials. Success rates for grasping novel objects unseen during training increased from 18.5% to 81.0% in simulation, and from 17.8% to 78.0% in the real world.",
        "primary_area": "",
        "author": "Austin S. Wang;Wuming Zhang;Daniel Troniak;Jacky Liang;Oliver Kroemer;Austin S. Wang;Wuming Zhang;Daniel Troniak;Jacky Liang;Oliver Kroemer",
        "authorids": "/37086934263;/37087324058;/37072530800;/37088504798;/37593222300;/37086934263;/37087324058;/37072530800;/37088504798;/37593222300",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; National Robotics Engineering Center, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968160/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4210395436613999992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;National Robotics Engineering Center",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.cmu.edu;",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967832",
        "title": "Htetran \u2013 A Polyabolo Inspired Self Reconfigurable Tiling Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Research focuses on robots related to area coverage applications such as cleaning, painting, demining, lawn moving, and inspection is gaining significant momentum in recent years. The majority of such research platforms faces significant performance issues while accessing narrow and constrained spaces due to their fixed morphology. To this end, we have developed a novel self-reconfigurable robot platform named as \u201chTetran\u201d inspired from Polyabolo which can change its morphology to any of the six tetrabolo shapes with an objective of maximizing the area coverage. This paper presents the system design, reconfiguration theory, and locomotion modules of the developed robot, including the adaptation of Polyabolo tiling theory as a coverage path planning strategy for autonomous navigation. The paper concludes with a set of experiments in a mocked office room setup that validates the efficiency of the proposed robot in terms of area coverage. Our experimental trials indicate that the \u201chTetran\u201d brings out a higher area coverage performance in all considered experimental cases.",
        "primary_area": "",
        "author": "Prabakaran Veerajagadheswar;Vinu Sivanantham;ManojKumar Devarassu;Mohan Rajesh Elara;Prabakaran Veerajagadheswar;Vinu Sivanantham;ManojKumar Devarassu;Mohan Rajesh Elara",
        "authorids": "/37086413184;/37086598815;/37086445807;/37546093700;/37086413184;/37086598815;/37086445807;/37546093700",
        "aff": "Singapore University of Technology and Deisgn, Singapore; Singapore University of Technology and Deisgn, Singapore; Singapore University of Technology and Deisgn, Singapore; EPD Singapore University of Technology and Deisgn, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967832/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4205617375551569184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8968192",
        "title": "Human Intention Inference and On-Line Human Hand Motion Prediction for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "With recent development of robotic technology, it is increasingly common that robot coexist with human, in which humans and robots share a common workspace and work in close proximity. To maintain efficiency and ensure safety under these circumstances, robot should have the ability to predict the future human motion based on the observed on-going motion. In this paper, we present a methodology for on-line inference of human intention and prediction of human hand motion. The proposed framework is built using Probabilistic Dynamic Movement Primitive (PDMP). In the off-line stage, a set of PDMPs is constructed based on the recorded demonstrations and they will then be used for inferring human intention and predicting human hand motion in the on-line stage. A proof of concept evaluation is carried out in a tabletop manipulation task. Experimental result shows the proposed framework achieve high performance in human intention inference and in the trajectory similarity between the predicted and the actual hand movement under the normally defined environment. We also show the proposed framework can adapt and generalize to the newly defined environment.",
        "primary_area": "",
        "author": "Ren.C Luo;Licong Mai;Ren.C Luo;Licong Mai",
        "authorids": "/37268829000;/37087323704;/37268829000;/37087323704",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan 106; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan 106",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968192/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14042093007700069441&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Taiwan University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.ntu.edu.tw",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967604",
        "title": "Human-Robot Visual Interface for 3D Steering of a Flexible, Bioinspired Needle for Neurosurgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic minimally invasive surgery has been a subject of intense research and development over the last three decades, due to the clinical advantages it holds for patients and doctors alike. Particularly for drug delivery mechanisms, higher precision and the ability to follow complex trajectories in three dimensions (3D), has led to interest in flexible, steerable needles such as the programmable bevel-tip needle (PBN). Steering in 3D, however, holds practical challenges for surgeons, as interfaces are traditionally designed for straight line paths. This work presents a pilot study undertaken to evaluate a novel human-machine visual interface for the steering of a robotic PBN, where both qualitative evaluation of the interface and quantitative evaluation of the performance of the subjects in following a 3D path are measured. A series of needle insertions are performed in phantom tissue (gelatin) by the experiment subjects. User could adequately use the system with little training and low workload, and reach the target point at the end of the path with millimeter range accuracy.",
        "primary_area": "",
        "author": "Eloise Matheson;Riccardo Secoli;Stefano Galvan;Ferdinando Rodriguez y Baena;Eloise Matheson;Riccardo Secoli;Stefano Galvan;Ferdinando Rodriguez y Baena",
        "authorids": "/37086800490;/37669464200;/37572025200;/37294842800;/37086800490;/37669464200;/37572025200;/37294842800",
        "aff": "Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom; Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom; Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom; Mechatronics in Medicine Laboratory, Imperial College, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967604/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16558463900116694382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Mechatronics in Medicine Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968239",
        "title": "Humanoid Robot Next Best View Planning Under Occlusions Using Body Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents an approach for humanoid Next Best View (NBV) planning that exploits full body motions to observe objects occluded by obstacles. The task is to explore a given region of interest in an initially unknown environment. The robot is equipped with a depth sensor, and it can perform both 2D and 3D mapping. As main contribution with respect to previous work, the proposed method does not rely on simple motions of the head and it was evaluated in real environments. The robot is guided by two behaviors: a target behavior that aims at observing the region of interest by exploiting body movements primitives, and an exploration behavior that aims at observing other unknown areas. Experiments show that the humanoid is able to peer around obstacles to reach a favourable point of view. Moreover, the proposed approach results in a more complete reconstruction of objects than a conventional algorithm that only changes the orientation of the head.",
        "primary_area": "",
        "author": "Riccardo Monica;Jacopo Aleotti;Davide Piccinini;Riccardo Monica;Jacopo Aleotti;Davide Piccinini",
        "authorids": "/37073241500;/37330820900;/37087323069;/37073241500;/37330820900;/37087323069",
        "aff": "Department of Engineering and Architecture, University of Parma, Italy; Department of Engineering and Architecture, University of Parma, Italy; Department of Engineering and Architecture, University of Parma, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968239/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13965435392048746390&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Parma",
        "aff_unique_dep": "Department of Engineering and Architecture",
        "aff_unique_url": "https://www.unipr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968256",
        "title": "Humanoid Robot\u2019s Force-Based Heavy Manipulation Tasks with Torque-Controlled Arms and Wrist Force Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a torque controller for humanoid robot's arm and a method to execute heavy-load tasks under that controller. Torque control of arms can reduce the joint load when an impulsive force is applied to the robot's hand. This feature is important for robots that will work among many humans or obstacles because accidental collisions may happen in such situations. We also developed a static force filter for force sensors at the end-effectors. This filter is utilized for the compensation for the static reaction force during heavy-load tasks. A life-sized humanoid robot JAXON digs soil with a shovel and carries soil with a wheelbarrow using our proposed controller.",
        "primary_area": "",
        "author": "Shintaro Komatsu;Yuya Nagamatsu;Tatsuya Ishikawa;Takuma Shirai;Kunio Kojima;Yohei Kakiuchi;Fumihito Sugai;Kei Okada;Masayuki Inaba;Shintaro Komatsu;Yuya Nagamatsu;Tatsuya Ishikawa;Takuma Shirai;Kunio Kojima;Yohei Kakiuchi;Fumihito Sugai;Kei Okada;Masayuki Inaba",
        "authorids": "/37086329076;/37086275431;/38148331500;/38237530400;/37085360901;/38242437800;/37085651948;/37280639000;/37286658200;/37086329076;/37086275431;/38148331500;/38237530400;/37085360901;/38242437800;/37085651948;/37280639000;/37286658200",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968256/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8704739539203534894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967808",
        "title": "Hybrid Force/Motion Control and Implementation of an Aerial Manipulator towards Sustained Contact Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact-based operation in moving process is a challenging problem for aerial manipulators. It requires the whole system to maintain steady contact with external environment, to track some predefined trajectories on surfaces, and simultaneously to present some fixed contact force. Aiming at this problem, a hybrid force/motion control framework is proposed in this paper. In this framework, contact force control and position control are performed separately in two orthogonal subspaces: constrained space and free-flight space. To control the contact force, the closed-loop unmanned aerial vehicle is first theoretically shown to behave dynamically as a spring-mass-damper system. Further, an inverse-dynamics-based controller is proposed. To control the moving along the contact surface, trajectory planning and position controller are combined to achieve the steady behavior in a free-flight subspace. In the end, an aerial manipulator system with a roller-type end-effector was designed, and practical flight experiments was performed. The results indicate that the proposed framework is effective and validity.",
        "primary_area": "",
        "author": "Xiangdong Meng;Yuqing He;Jianda Han;Xiangdong Meng;Yuqing He;Jianda Han",
        "authorids": "/37086051641;/37288326300;/37290381900;/37086051641;/37288326300;/37290381900",
        "aff": "Chinese Academy of Sciences, Shenyang Institute of Automation Institutes for Robotics and Intelligent Manufacturing; Chinese Academy of Sciences, Shenyang Institute of Automation Institutes for Robotics and Intelligent Manufacturing; Chinese Academy of Sciences, Shenyang Institute of Automation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967808/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13693134806638619926&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation",
        "aff_unique_url": "http://www.ia.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenyang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968000",
        "title": "Hybrid Visual Servoing for Autonomous Robotic Laser Tattoo Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "Laser tattoo removal is a standard non-invasive method for removing color pigments on the skin. Increasing number of tattooed people who want to remove their tattoo has driven the medical laser market to develop new technologies for painless, scar-free and complete tattoo removal. However, manual use of such laser systems creates post-operative complications since they do not guarantee (i) protection on nontattooed skin from laser exposure, nor (ii) precise control of the laser focus during the operations for best performance. This paper introduces deTattoo, a robotic system to improve tattoo removal operations. A robotic arm is equipped with a RGB-D camera and a visible laser, in eye-in-end configuration. A hybrid visual servoing control is proposed to guarantee the correct pose of the laser with respect to the tattooed tissue while compensating body motions. 2D features tracked with a mass-spring-damper deformable mesh model are combined with the 3D reconstruction retrieved from a RGB-D camera in order to build the control law. Several experiments were conducted to evaluate the performance of the system with a fixed or moving tattooed surface, at different inclinations. Results showed that the proposed framework is able to fulfil the laser-based tattoo removal requirements, providing high positioning accuracy (<; 1mm) orientation (<; 0.2\u00b0) and body motion compensation.",
        "primary_area": "",
        "author": "Veronica Penza;Damiano Salerno;Alperen Acemoglu;Jes\u00fas Ortiz;Leonardo S. Mattos;Veronica Penza;Damiano Salerno;Alperen Acemoglu;Jes\u00fas Ortiz;Leonardo S. Mattos",
        "authorids": "/37085895473;/37087324346;/37086117935;/37545079600;/37283193500;/37085895473;/37087324346;/37086117935;/37545079600;/37283193500",
        "aff": "Biomedical Robotics Lab, Istituto Italiano di Tecnologia, via Morego, 30, Genoa, Italy; Biomedical Robotics Lab, Istituto Italiano di Tecnologia, via Morego, 30, Genoa, Italy; Biomedical Robotics Lab, Istituto Italiano di Tecnologia, via Morego, 30, Genoa, Italy; Biomedical Robotics Lab, Istituto Italiano di Tecnologia, via Morego, 30, Genoa, Italy; Biomedical Robotics Lab, Istituto Italiano di Tecnologia, via Morego, 30, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968000/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10398748946728286210&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Biomedical Robotics Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968039",
        "title": "Hysteresis Compensator with Learning-based Pose Estimation for a Flexible Endoscopic Surgery Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of the tendon-sheath mechanism (TSM) is common in flexible surgery robots, because it can flexibly work in limited spaces and provides efficient power transmission. However, hysteresis from nonlinearities such as friction and backlash poses a challenge in controlling precise motion in the surgical instrument. Moreover, this hysteresis is also affected by changes in the various configurations of sheath which limits traditional model-based compensation approaches. Recently, feedback approach using an endoscopic camera is presented, but they use markers which are not appropriate for applying to a real surgical instruments. In this paper, a novel hysteresis compensator with learning-based pose estimation is proposed. Unlike previous studies, the proposed compensator can reduce hysteresis of the surgical instrument in various sheath configurations without using markers. In order to estimate an actual angle of the surgical instrument's joint, we employ the learning-based pose estimation using a siamese convolutional neural network (SCNN). The proposed compensator reduces hysteresis by partially controlling the position command, similar to the instinctive adjustments that physicians make with their visual feedback. To validate the proposed method, a testbed was constructed considering several requirements of flexible surgery robots. As a result, the results show the proposed method reduces hysteresis to less than 10\u00b0, for various configurations of sheath. In addition, we confirmed that the learning-based pose estimation is sufficient to apply to the proposed compensator for reducing hysteresis in real-time.",
        "primary_area": "",
        "author": "Donghoon Baek;Ju-Hwan Seo;Joonhwan Kim;Dong-Soo Kwon;Donghoon Baek;Ju-Hwan Seo;Joonhwan Kim;Dong-Soo Kwon",
        "authorids": "/37086439599;/38503016100;/37086836112;/37278487100;/37086439599;/38503016100;/37086836112;/37278487100",
        "aff": "robotics program, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968039/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9849057001269383379&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "robotics program",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968553",
        "title": "INFER: INtermediate representations for FuturE pRediction",
        "track": "main",
        "status": "Poster",
        "abstract": "In urban driving scenarios, forecasting future trajectories of surrounding vehicles is of paramount importance. While several approaches for the problem have been proposed, the best-performing ones tend to require extremely detailed input representations (e.g. image sequences). As a result, such methods do not generalize to datasets they have not been trained on. In this paper, we propose intermediate representations that are particularly well-suited for future prediction. As opposed to using texture (color) information from images, we condition on semantics and train an autoregressive model to accurately predict future trajectories of traffic participants (vehicles) (see Fig. above). We demonstrate that semantics provide a significant boost over techniques that operate over raw pixel intensities/disparities. Uncharacteristic of state-of-the-art approaches, our representations and models generalize across different sensing modalities (stereo imagery, LiDAR, a combination of both), and also across completely different datasets, collected across several cities, and also across countries where people drive on opposite sides of the road (left-handed vs right-handed driving). Additionally, we demonstrate an application of our approach in multi-object tracking (data association). To foster further research in transferable representations and ensure reproducibility, we release all our code and data.33More qualitative and quantitative results, along with code and data can be found at https://rebrand.ly/INFER-results.",
        "primary_area": "",
        "author": "Shashank Srikanth;Junaid Ahmed Ansari;R. Karnik Ram;Sarthak Sharma;J. Krishna Murthy;K. Madhava Krishna;Shashank Srikanth;Junaid Ahmed Ansari;R. Karnik Ram;Sarthak Sharma;J. Krishna Murthy;K. Madhava Krishna",
        "authorids": "/37088537972;/37086452989;/37086579467;/37086264065;/37086135299;/38201465600;/37088537972;/37086452989;/37086579467;/37086264065;/37086135299;/38201465600",
        "aff": "Robotics Research Center, KCIS, IIIT, Hyderabad, India; Robotics Research Center, KCIS, IIIT, Hyderabad, India; Robotics Research Center, KCIS, IIIT, Hyderabad, India; Robotics Research Center, KCIS, IIIT, Hyderabad, India; Mila - Quebec AI Institute, Montreal, Canada; Robotics Research Center, KCIS, IIIT, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968553/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9602287142832211398&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;Quebec AI Institute",
        "aff_unique_dep": "Robotics Research Center;AI Institute",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://mila.quebec",
        "aff_unique_abbr": "IIIT Hyderabad;Mila",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Hyderabad;Montreal",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "India;Canada"
    },
    {
        "id": "8968176",
        "title": "IVOA: Introspective Vision for Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision, as an inexpensive yet information rich sensor, is commonly used for perception on autonomous mobile robots. Unfortunately, accurate vision-based perception requires a number of assumptions about the environment to hold - some examples of such assumptions, depending on the perception algorithm at hand, include purely lambertian surfaces, texture-rich scenes, absence of aliasing features, and refractive surfaces. In this paper, we present an approach for introspective vision for obstacle avoidance (IVOA) - by leveraging a supervisory sensor that is occasionally available, we detect failures of stereo vision-based perception from divergence in plans generated by vision and the supervisory sensor. By projecting the 3D coordinates where the plans agree and disagree onto the images used for vision-based perception, IVOA generates a training set of reliable and unreliable image patches for perception. We then use this training dataset to learn a model of which image patches are likely to cause failures of the vision-based perception algorithm. Using this model, IVOA is then able to predict whether the relevant image patches in the observed images are likely to cause failures due to vision (both false positives and false negatives). We empirically demonstrate with extensive real-world data from both indoor and outdoor environments, the ability of IVOA to accurately predict the failures of two distinct vision algorithms.",
        "primary_area": "",
        "author": "Sadegh Rabiee;Joydeep Biswas;Sadegh Rabiee;Joydeep Biswas",
        "authorids": "/37086933532;/37538259200;/37086933532;/37538259200",
        "aff": "College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968176/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2677778164401192217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968530",
        "title": "Identification of Rat Ultrasonic Vocalizations from Mix Sounds of a Robotic Rat in a Noisy Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Social interaction between a robot and rats is important since the robot can generate reproducible social behaviors across trials. However, lacking internal state feedback from the rat makes current robot-rat interaction a very preliminary level comparing with rat-rat interaction. Previous biological studies showed that ultrasonic vocalizations (USVs) emitted by a rat are expressions of its internal emotional states, which therefore can be used as part of feedback for a robot-rat interaction. The challenge is to accurately identify rat USVs in real-time from mix sounds generated by the robot in a noisy environment. To address these problems, we propose an SVM-based rat USVs identification method. This SVM method uses three types of features to represents the characteristics of mix sound and use these multidimensional features to identify rat USVs. Results show that our identification method has an accuracy of 84.29% with only 4.84% false-positive rate. Furthermore, we carefully design the filter window length with respect to sound chunk length and use only one microphone to record the mix sound. All of these efforts are to reduce the calculation time to realize real-time identification. Eventually, the identification process can be executed within 3. 5ms, which definitely meet the real-time demand. This research lays the foundation of the feedback based interaction between rat and robot, and also shows promise in the study of ethology and the interaction between robot and animals.",
        "primary_area": "",
        "author": "Chang Li;Qing Shi;Zihang Gao;Hiroyuki Ishii;Atsuo Takanishi;Qiang Huang;Toshio Fukuda;Chang Li;Qing Shi;Zihang Gao;Hiroyuki Ishii;Atsuo Takanishi;Qiang Huang;Toshio Fukuda",
        "authorids": "/37086076350;/37593189500;/37086594901;/37277282200;/37280756700;/37279982900;/37279174500;/37086076350;/37593189500;/37086594901;/37277282200;/37280756700;/37279982900;/37279174500",
        "aff": "Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968530/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4326197801101199968&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;Waseda University",
        "aff_unique_dep": "School of Mechatronical Engineering;",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.waseda.ac.jp",
        "aff_unique_abbr": "BIT;Waseda",
        "aff_campus_unique_index": "0;0;0;1;1;0;0",
        "aff_campus_unique": "Beijing;Tokyo",
        "aff_country_unique_index": "0;0;0;1;1;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8967603",
        "title": "Identifying Opportunities for Relationship-Focused Robotic Interventions in Strained Hierarchical Relationships",
        "track": "main",
        "status": "Poster",
        "abstract": "When disagreements arise in hierarchical relationships, relationship members sometimes prefer conflict management strategies that avoid or quickly end the overt conflict even if the relationship is left in a state of dissatisfaction. Our lab has proposed that a peripheral robotic agent may be able to support these types of relationships during conflict. In this paper, we present the results of an IRB-approved human-robot interaction study that examines how the members of a hierarchical relationship involved in conflict respond to the presence of an unengaged robot. This study serves as a baseline for additional studies. The unengaged robot appears to have a minimal influence on the interaction. The observed conflicts followed the patterns typically described in mediation literature. Our lab previously proposed a computational model to identify weakness and alienation in these relationships. We discuss a partial implementation of this model, and its ability to recognize problems in certain relationships within the data collected. Based on our observations, and the performance of the model\u2019s partial implementation, we suggest considerations that need to be made for an intervening robotic agent.",
        "primary_area": "",
        "author": "Michael J. Pettinati;Ronald C. Arkin;Michael J. Pettinati;Ronald C. Arkin",
        "authorids": "/37089396789;/37278162600;/37089396789;/37278162600",
        "aff": "School of Interactive Computing at Georgia Tech, Atlanta, USA; School of Interactive Computing at Georgia Tech, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967603/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2368172738370917654&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Interactive Computing",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967665",
        "title": "Ignorance is Not Bliss: An Analysis of Central-Place Foraging Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Central-place foraging (CPF) is a canonical task in collective robotics with applications to planetary exploration, automated mining, warehousing, and search and rescue operations. We compare the performance of three Central-Place Foraging Algorithms (CPFAs), variants of which have been shown to work well in real robots: spiral-based, rotating-spoke, and random-ballistic. To understand the difference in performance between these CPFAs, we define the price of ignorance and show how this metric explains our previously published empirical results. We obtain upper-bounds for expected complete collection times for each algorithm and evaluate their performance in simulation. We show that site-fidelity (i.e. returning to the location of the last found target) and avoiding search redundancy are key-factors that determine the efficiency of CPFAs. Our formal analysis suggests the following efficiency ranking from best to worst: spiral, spoke, and the stochastic ballistic algorithm.",
        "primary_area": "",
        "author": "Abhinav Aggarwal;Diksha Gupta;William F. Vining;G. Matthew Fricke;Melanie E. Moses;Abhinav Aggarwal;Diksha Gupta;William F. Vining;G. Matthew Fricke;Melanie E. Moses",
        "authorids": "/37087321795;/37086960981;/37087323638;/37717654600;/37637091600;/37087321795;/37086960981;/37087323638;/37717654600;/37637091600",
        "aff": "Computer Science Department, University of New Mexico, Albuquerque, USA; Computer Science Department, University of New Mexico, Albuquerque, USA; Computer Science Department, University of New Mexico, Albuquerque, USA; Computer Science Department, University of New Mexico, Albuquerque, USA; Computer Science Department, University of New Mexico, Albuquerque, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967665/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2401903314816945864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of New Mexico",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.unm.edu",
        "aff_unique_abbr": "UNM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Albuquerque",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967583",
        "title": "Implementation of a Natural Dynamic Controller on an Under-actuated Compass-Biped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural dynamic controllers aim to perform the desired task by exploiting the natural dynamics of the system. This can be accomplished by generating torque patterns to actuate the system rather than accurately following a predefined trajectory. We have previously demonstrated natural dynamic control of compass-biped in simulations. Here we demonstrate successful implementation of this dynamic controller on an under-actuated compass-biped robot. The parameters of the controller, and in particular the magnitude and timing of torque primitives, were optimized using multi-objective optimization via genetic algorithm, accounting for speed and energy efficiency. While the current implementation is in open-loop, this strategy can be extended to include feedback to enhance walking over a wide range of terrains. This proof-of concept provides the basis for future extensions to more complex robots.",
        "primary_area": "",
        "author": "Ron Hartston;Rea Yakar;Reuven Katz;Miriam Zacksenhouse;Ron Hartston;Rea Yakar;Reuven Katz;Miriam Zacksenhouse",
        "authorids": "/37087325151;/37087323576;/37087322379;/37265222800;/37087325151;/37087323576;/37087322379;/37265222800",
        "aff": "Sensory-Motor Integration Laboratory, Faculty of Mechanical Engineering, Technion - Israel\u2019s Institute of Technology, Haifa, Israel; Sensory-Motor Integration Laboratory, Faculty of Mechanical Engineering, Technion - Israel\u2019s Institute of Technology, Haifa, Israel; Sensory-Motor Integration Laboratory, Faculty of Mechanical Engineering, Technion - Israel\u2019s Institute of Technology, Haifa, Israel; Sensory-Motor Integration Laboratory, Faculty of Mechanical Engineering, Technion - Israel\u2019s Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967583/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11806881766111050243&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technion - Israel\u2019s Institute of Technology",
        "aff_unique_dep": "Faculty of Mechanical Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "8968031",
        "title": "Implementing Regularized Predictive Control for Simultaneous Real-Time Footstep and Ground Reaction Force Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a successful implementation of a nonlinear optimization-based Regularized Predictive Control (RPC) for legged locomotion on the MIT Cheetah 3 robot platform. Footstep placements and ground reaction forces at the contact feet are simultaneously solved for over a prediction horizon in real-time. Often in academic literature not enough attention is given to the implementation details that make the theory work in practice and many times it is precisely these details that end up being critical to the success or failure of the theory in real world applications. Nonlinear optimization for real-time legged locomotion control in particular is one of the techniques that has shown promise, but falls short when implemented on hardware systems subjected to computation limits and undesirable local minima. We discuss various algorithms and techniques developed to overcome some of the challenges faced when implementing nonlinear optimization-based controllers for dynamic legged locomotion.",
        "primary_area": "",
        "author": "Gerardo Bledt;Sangbae Kim;Gerardo Bledt;Sangbae Kim",
        "authorids": "/37086288149;/37537397200;/37086288149;/37537397200",
        "aff": "Department of Mechanical Engineering, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968031/",
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2253153700316825550&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967896",
        "title": "Improved Exploration through Latent Trajectory Optimization in Deep Deterministic Policy Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-free reinforcement learning algorithms such as Deep Deterministic Policy Gradient (DDPG) often require additional exploration strategies, especially if the actor is of deterministic nature. This work evaluates the use of model-based trajectory optimization methods used for exploration in Deep Deterministic Policy Gradient when trained on a latent image embedding. In addition, an extension of DDPG is derived using a value function as critic, making use of a learned deep dynamics model to compute the policy gradient. This approach leads to a symbiotic relationship between the deep reinforcement learning algorithm and the latent trajectory optimizer. The trajectory optimizer benefits from the critic learned by the RL algorithm and the latter from the enhanced exploration generated by the planner. The developed methods are evaluated on two continuous control tasks, one in simulation and one in the real world. In particular, a Baxter robot is trained to perform an insertion task, while only receiving sparse rewards and images as observations from the environment.",
        "primary_area": "",
        "author": "Kevin Sebastian Luck;Mel Vecerik;Simon Stepputtis;Heni Ben Amor;Jonathan Scholz;Kevin Sebastian Luck;Mel Vecerik;Simon Stepputtis;Heni Ben Amor;Jonathan Scholz",
        "authorids": "/37085473872;/37086933926;/37086175304;/37293927700;/37970047400;/37085473872;/37086933926;/37086175304;/37293927700;/37970047400",
        "aff": "Interactive Robotics Lab, Arizona State University, Tempe, AZ, USA; Google DeepMind, London, UK; Interactive Robotics Lab, Arizona State University, Tempe, AZ, USA; Interactive Robotics Lab, Arizona State University, Tempe, AZ, USA; Google DeepMind, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967896/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8301397131645969414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Arizona State University;Google",
        "aff_unique_dep": "Interactive Robotics Lab;Google DeepMind",
        "aff_unique_url": "https://www.asu.edu;https://deepmind.com",
        "aff_unique_abbr": "ASU;DeepMind",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Tempe;London",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "8968274",
        "title": "Improved Learning Accuracy for Learning Stable Control from Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) has been identified as an effective method for making robots adapt to a similar kind of tasks. In this work, a framework of learning from demonstration has been proposed for modelling robot motions. We present an approach based on dimension ascending to learn a dynamical system, so that the reproduced motions can closely follow the demonstrations. In addition, the reproductions can ultimately reach and stop at the target, which reflects the robustness of the method. Therefore, the system accuracy and stability can be better guaranteed simultaneously. The effectiveness of the proposed approach is verified by performing handwriting experiments on the LASA data set.",
        "primary_area": "",
        "author": "Shaokun Jin;Zhiyang Wang;Yongsheng Ou;Yimin Zhou;Shaokun Jin;Zhiyang Wang;Yongsheng Ou;Yimin Zhou",
        "authorids": "/37085827097;/37085731428;/37264969100;/37085357270;/37085827097;/37085731428;/37264969100;/37085357270",
        "aff": "Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences 1068 Xueyuan Blvd, Guangdong Provincial Key Laboratory of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968274/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5017573810118450221&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Shenzhen Institutes of Advanced Technology",
        "aff_unique_url": "http://www.siat.ac.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968610",
        "title": "Improved Mechanical Design and Simplified Motion Planning of Hybrid Active and Passive Cable-Driven Segmented Manipulator with Coupled Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-driven segmented manipulators (CDSMs) featured by superior dexterity, light and slender body are excellent candidates for operations in confined environments. However, the stiffness and load capacity of such manipulators have been a challenge due to their structural elasticity. In this paper, we propose an improved mechanism design based on the preliminary work to enhance the linkage accuracy and arm continuity without sacrificing the dexterity, high stiffness and load capacity of CDSM. The manipulator is composed of 4 improved hybrid active-passive linkage segments. Its short and long linkage cables with pretension mechanism are designed to keep equal angles of adjacent joints. An improved separable small driving control box is also designed with both quick release and load mechanism and stroke amplification mechanism. Then the size of control box can still remain small, even the number of segments and the joint limit angles increase. Considering the improved in-segment linkage characteristic, traditional kinematic equations and Jacobian matrix are greatly simplified with Denavit-Hartenberg (D-H) method. Further trajectory tracking planning based on the simplified kinematics solved the Cartesian space planning for task design. Finally, a prototype system is developed to perform the linkage accuracy and comprehensive obstacle avoidance experiments. Experimental results show that the developed hybrid active and passive CDSM has relatively high accuracy and super dexterity.",
        "primary_area": "",
        "author": "Tianliang Liu;Zonggao Mu;Wenfu Xu;Taiwei Yang;Kailing You;Haiming Fu;Yangmin Li;Tianliang Liu;Zonggao Mu;Wenfu Xu;Taiwei Yang;Kailing You;Haiming Fu;Yangmin Li",
        "authorids": "/37086083960;/37085472784;/37291470000;/37087246558;/37087322768;/37086600485;/37279899000;/37086083960;/37085472784;/37291470000;/37087246558;/37087322768;/37086600485;/37279899000",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Department of Industrial and Systems Engineering, Hong Kong Polytechnic University, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968610/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1130276320322014959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Hong Kong Polytechnic University",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Industrial and Systems Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.polyu.edu.hk",
        "aff_unique_abbr": "HIT;PolyU",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967634",
        "title": "Improved Planetary Rover Inertial Navigation and Wheel Odometry Performance through Periodic Use of Zero-Type Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach to enhance wheeled planetary rover dead-reckoning localization performance by leveraging the use of zero-type constraint equations in the navigation filter. Without external aiding, inertial navigation solutions inherently exhibit cubic error growth. Furthermore, for planetary rovers that are traversing diverse types of terrain, wheel odometry is often unreliable for use in localization, due to wheel slippage. For current Mars rovers, computer vision-based approaches are generally used whenever there is a high possibility of positioning error; however, these strategies require additional computational power, energy resources, adequate features in the environment, and significantly slow down the rover traverse speed. To this end, we propose a navigation approach that compensates for the high likelihood of odometry errors by providing a reliable navigation solution that leverages non-holonomic vehicle constraints as well as state-aware pseudo-measurements (e.g., zero velocity and zero angular rate) updates during periodic stops. By using this, computationally expensive visual-based corrections could be performed less often. Experimental tests that compare against GPS-based localization are used to demonstrate the accuracy of the proposed approach. The source code, post-processing scripts, and example datasets associated with the paper are published in a public repository.",
        "primary_area": "",
        "author": "Cagri Kilic;Jason N. Gross;Nicholas Ohi;Ryan Watson;Jared Strader;Thomas Swiger;Scott Harper;Yu Gu;Cagri Kilic;Jason N. Gross;Nicholas Ohi;Ryan Watson;Jared Strader;Thomas Swiger;Scott Harper;Yu Gu",
        "authorids": "/37072611600;/38269010800;/37086456776;/37086250454;/37085782368;/37087322648;/37086457051;/37288787100;/37072611600;/38269010800;/37086456776;/37086250454;/37085782368;/37087322648;/37086457051;/37288787100",
        "aff": "Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967634/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8824352601803084753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "West Virginia University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.wvu.edu",
        "aff_unique_abbr": "WVU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Morgantown",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968242",
        "title": "Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately estimating the orientation of pedestrians is an important and challenging task for autonomous driving because this information is essential for tracking and predicting pedestrian behavior. This paper presents a flexible Virtual Multi-View Synthesis module that can be adopted into 3D object detection methods to improve orientation estimation. The module uses a multi-step process to acquire the fine-grained semantic information required for accurate orientation estimation. First, the scene's point cloud is densified using a structure preserving depth completion algorithm and each point is colorized using its corresponding RGB pixel. Next, virtual cameras are placed around each object in the densified point cloud to generate novel viewpoints, which preserve the object's appearance. We show that this module greatly improves the orientation estimation on the challenging pedestrian class on the KITTI benchmark. When used with the open-source 3D detector AVOD-FPN, we outperform all other published methods on the pedestrian Orientation, 3D, and Bird's Eye View benchmarks.",
        "primary_area": "",
        "author": "Jason Ku;Alex D. Pon;Sean Walsh;Steven L. Waslander;Jason Ku;Alex D. Pon;Sean Walsh;Steven L. Waslander",
        "authorids": "/37087234619;/37086577117;/37086546939;/37301169100;/37087234619;/37086577117;/37086546939;/37301169100",
        "aff": "Institute for Aerospace Studies, University of Toronto, 4925 Dufferin St, North York, ON, Canada; Institute for Aerospace Studies, University of Toronto, 4925 Dufferin St, North York, ON, Canada; Institute for Aerospace Studies, University of Toronto, 4925 Dufferin St, North York, ON, Canada; Institute for Aerospace Studies, University of Toronto, 4925 Dufferin St, North York, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968242/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1704189677690704170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Institute for Aerospace Studies",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "North York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968515",
        "title": "Improving Learning-based Ego-motion Estimation with Homomorphism-based Losses and Drift Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual odometry is an essential problem for mobile robots. Traditional methods for solving VO mostly utilize geometric optimization. While capable of achieving high accuracy, these methods require accurate sensor calibration and complicated parameter tuning to work well in practice. With the rise of deep learning, there has been increased interest in the end-to-end, learning-based methods for VO, which have the potential to improve robustness. However, learning-based methods for VO so far are less accurate than geometric methods. We argue that one of the main issues is that the current ego-motion estimation task is different from other problems where deep learning has been successful such as object detection. We define a novel cost function for learning-based VO considering the mathematical properties of the group homomorphism. In addition to the standard L2 loss, we incorporate losses based on the identity, inverse and closure properties of SE(3) rigid motion. Furthermore, we propose to reduce the VO drift by estimating the drivable regions using semantic segmentation and incorporate this information into a pose graph optimization. Experiments on KITTI datasets show that the novel cost function can improve ego-motion estimation compared to the state-of-the-art and the drivable region-based correction further reduces the VO drift.",
        "primary_area": "",
        "author": "Xiangwei Wang;Daniel Maturana;Shichao Yang;Wenshan Wang;Qijun Chen;Sebastian Scherer;Xiangwei Wang;Daniel Maturana;Shichao Yang;Wenshan Wang;Qijun Chen;Sebastian Scherer",
        "authorids": "/37086319918;/37540464600;/37085818650;/37087322184;/37276133600;/37584159000;/37086319918;/37540464600;/37085818650;/37087322184;/37276133600;/37584159000",
        "aff": "Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Department of Control Science and Engineering, Tongji University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968515/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13550323569844884035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Tongji University",
        "aff_unique_dep": ";Department of Control Science and Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.tongji.edu.cn",
        "aff_unique_abbr": "CMU;Tongji",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967980",
        "title": "Improving Local Trajectory Optimisation using Probabilistic Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Local trajectory optimisation techniques are a powerful tool for motion planning. However, they often get stuck in local optima depending on the quality of the initial solution and consequently, often do not find a valid (i.e. collision free) trajectory. Moreover, they often require fine tuning of a cost function to obtain the desired motions. In this paper, we address both problems by combining local trajectory optimisation with learning from demonstrations. The human expert demonstrates how to reach different target end-effector locations in different ways. From these demonstrations, we estimate a trajectory distribution, represented by a Probabilistic Movement Primitive (ProMP). For a new target location, we sample different trajectories from the ProMP and use these trajectories as initial solutions for the local optimisation. As the ProMP generates versatile initial solutions for the optimisation, the chance of finding poor local minima is significantly reduced. Moreover, the learned trajectory distribution is used to specify the smoothness costs for the optimisation, resulting in solutions of similar shape as the demonstrations. We demonstrate the effectiveness of our approach in several complex obstacle avoidance scenarios.",
        "primary_area": "",
        "author": "RB Ashith Shyam;Peter Lightbody;Gautham Das;Pengcheng Liu;Sebastian Gomez-Gonzalez;Gerhard Neumann;RB Ashith Shyam;Peter Lightbody;Gautham Das;Pengcheng Liu;Sebastian Gomez-Gonzalez;Gerhard Neumann",
        "authorids": "/37087323763;/37086840727;/38242544200;/37087012621;/37086025491;/38542033100;/37087323763;/37086840727;/38242544200;/37087012621;/37086025491;/38542033100",
        "aff": "Lincoln Centre for Autonomous System, University of Lincoln, UK; Lincoln Centre for Autonomous System, University of Lincoln, UK; Lincoln Centre for Autonomous System, University of Lincoln, UK; Cardiff School of Technologies, Cardiff Metropolitan University, UK; Max Plank Institute for Intelligent Systems, Tabingen, Germany; Lincoln Centre for Autonomous System, University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967980/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11880707630294590997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "University of Lincoln;Cardiff Metropolitan University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Lincoln Centre for Autonomous System;School of Technologies;",
        "aff_unique_url": "https://www.lincoln.ac.uk;https://www.cardiffmet.ac.uk;https://www.mpi-iis.mpg.de",
        "aff_unique_abbr": ";Cardiff Met;MPI-IS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Cardiff;T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "8968142",
        "title": "Improving Robot Success Detection using Static Object Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We use static object data to improve success detection for stacking objects on and nesting objects in one another. Such actions are necessary for certain robotics tasks, e.g., clearing a dining table or packing a warehouse bin. However, using an RGB-D camera to detect success can be insufficient: same-colored objects can be difficult to differentiate, and reflective silverware cause noisy depth camera perception. We show that adding static data about the objects themselves improves the performance of an end-to-end pipeline for classifying action outcomes. Images of the objects, and language expressions describing them, encode prior geometry, shape, and size information that refine classification accuracy. We collect over 13 hours of egocentric manipulation data for training a model to reason about whether a robot successfully placed unseen objects in or on one another. The model achieves up to a 57% absolute gain over the task baseline on pairs of previously unseen objects.",
        "primary_area": "",
        "author": "Rosario Scalise;Jesse Thomason;Yonatan Bisk;Siddhartha Srinivasa;Rosario Scalise;Jesse Thomason;Yonatan Bisk;Siddhartha Srinivasa",
        "authorids": "/37085901034;/37086936057;/37086936955;/37339877600;/37085901034;/37086936057;/37086936955;/37339877600",
        "aff": "School of Computer Science and Engineering, University of Washington; School of Computer Science and Engineering, University of Washington; School of Computer Science and Engineering, University of Washington; School of Computer Science and Engineering, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968142/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6437334990214315561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967688",
        "title": "Improving Task-Parameterised Movement Learning Generalisation with Frame-Weighted Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration depends on a robot learner generalising its learned model to unseen conditions. Generally, it is not feasible for a person to provide demonstrations that account for all possible variations in non-trivial tasks. While there are many learning methods that can handle interpolation of observed data effectively, extrapolation from observed data offers a much greater challenge. To address this problem, this paper proposes a modified Task-Parameterised Gaussian Mixture Regression method that considers the relevance of task parameters during trajectory generation, as determined by variance in the data. The benefits of the proposed method are first explored using a simulated reaching task data set. Here it is shown that the proposed method offers far-reaching, low-error extrapolation abilities that are different in nature to existing learning methods. Data collected from novice users for a real-world manipulation task is then considered, where it is shown that the proposed method is able to effectively reduce grasping performance errors by \\sim \\sim 40% and extrapolate to unseen grasp targets under real-world conditions. These results indicate the proposed method can benefit novice users by placing less reliance on the user to provide high quality demonstration data sets.",
        "primary_area": "",
        "author": "Aran Sena;Brendan Michael;Matthew Howard;Aran Sena;Brendan Michael;Matthew Howard",
        "authorids": "/37086454492;/37085555241;/37301483600;/37086454492;/37085555241;/37301483600",
        "aff": "Robot Learning Lab, King\u2019s College London; Robot Learning Lab, King\u2019s College London; Robot Learning Lab, King\u2019s College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967688/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10115537784023940911&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "King\u2019s College London",
        "aff_unique_dep": "Robot Learning Lab",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967601",
        "title": "Inchworm-inspired soft climbing robot using microspine arrays",
        "track": "main",
        "status": "Poster",
        "abstract": "Animals in nature, such as geckos, inchworms, and felines can climb on various surfaces using different mechanisms and serve as references for the study of bio-inspired robots. This paper presents an inchworm-inspired climbing robot that consists of soft body and feet. The soft robot is actuated by shape memory alloy wires and utilizes microspine arrays to attach its feet to rough or soft surfaces. A series of experiments to test the functionality of the feet and torso of the designed robot have verified the theoretical feasibility of the robot. Results have shown that the designed bio-inspired robot can climb on inclined or vertical curved surfaces and flat surfaces. The robot can also adapt to the underwater environment. Thus, this robot has great potential for various applications such as pipeline inspection.",
        "primary_area": "",
        "author": "Qiqiang Hu;Erbao Dong;Gang Cheng;Hu Jin;Jie Yang;Dong Sun;Qiqiang Hu;Erbao Dong;Gang Cheng;Hu Jin;Jie Yang;Dong Sun",
        "authorids": "/37087321729;/37969776300;/37087323044;/37073258200;/37292636300;/37277362800;/37087321729;/37969776300;/37087323044;/37073258200;/37292636300;/37277362800",
        "aff": "CAS Key Laboratory of Mechanical Behavior and Design of Materials, University of Science and Technology of China, Hefei, China; CAS Key Laboratory of Mechanical Behavior and Design of Materials, University of Science and Technology of China, Hefei, PRC, Anhui; Beijing Key Laboratory of Intelligent Space Robotic Systems Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, PRC; CAS Key Laboratory of Mechanical Behavior and Design of Materials, University of Science and Technology of China, Hefei, PRC, Anhui; CAS Key Laboratory of Mechanical Behavior and Design of Materials, University of Science and Technology of China, Hefei, PRC, Anhui; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, SAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967601/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=657662278092991260&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "University of Science and Technology of China;Beijing Institute of Spacecraft System Engineering;City University of Hong Kong",
        "aff_unique_dep": "CAS Key Laboratory of Mechanical Behavior and Design of Materials;Beijing Key Laboratory of Intelligent Space Robotic Systems Technology and Applications;Department of Biomedical Engineering",
        "aff_unique_url": "http://www.ustc.edu.cn;;https://www.cityu.edu.hk",
        "aff_unique_abbr": "USTC;;CityU",
        "aff_campus_unique_index": "0;0;1;0;0;2",
        "aff_campus_unique": "Hefei;Beijing;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967727",
        "title": "Inertial-based Motion Capturing and Smart Training System",
        "track": "main",
        "status": "Poster",
        "abstract": "Smart coaching platforms are emerging which combine BodySensor-Networks with AI-based training software to monitor and analyze body motions of athletes, workers, or medical patients. This allows for new opportunities to explore algorithms to interpret body sensor data and provide analytical feedback for learning a physical task, refining body motions, or to protect from work-related injuries. This paper presents a solution to non-invasively equip a person with sensors of a Smart Training System (STS) to improve training efficiency during sport activities. Our system calculates the significance of each body part during physical activities and provides targeted feedback on which body locations are under-performing. In experiments, the system collected data from 13 inertial sensors attached to the entire body of inexperienced golf learners. Using an indoor golf training net with a central target with 3 concentric zones, 1,080 real-world golf swings of 11 participants were analyzed. During the first 30 swings of each participant, the system learned distributions of motions from each sensor, conditioned on swing performance reported by users from their hitting location on the target. In the later 70 swings, feedback was provided to a subgroup of 8 participants, by computing, for an optimal set of features determined during training, the largest discrepancy. The remaining 3 (control) participants received no feedback. From only 100 golf swings for each participant, our system led to significantly improved scores by on average 3.7x (t-test, p <; 0.0001) over the latter 70 swings. Our results suggest that the combination of motion sensors and processing developed here was able to yield significantly improved golf swing training.",
        "primary_area": "",
        "author": "Jens Windau;Laurent Itti;Jens Windau;Laurent Itti",
        "authorids": "/37546422000;/37282718300;/37546422000;/37282718300",
        "aff": "iLab and Computer Science Dept., University of Southern California, Los Angeles, CA, USA; iLab and Computer Science Dept., University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967727/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7487812795979761482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Computer Science Dept.",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968203",
        "title": "Inference of user-intention in remote robot wheelchair assistance using multimodal interfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared control methodologies have the potential of enabling wheelchair-bound users with limited motor abilities to perform tasks that would usually be beyond their capabilities. Deriving such methodologies in advance is challenging, since they are frequently heavily dependent on unique characteristics of users. Learning Assistance by Demonstration paradigms allow derivation of customized policies by recording how remote human assistants assist particular users. However, for accurate determination of the optimal policies for each user and context, the remote assistant needs to infer the intention of the driver, which is frequently obscured by noisy signals dependent on the user's motor impairment. In this paper, we propose a multimodal teleoperation interface, incorporating map information, haptic feedback and user eye-gaze data, and examine which of these factors are most important for allowing accurate determination of user intention in a simulated tremor experiment. Our study indicates that, for expert assistants, presence of additional haptic and gaze information increases their ability to accurately infer the user's intention, providing supporting evidence for the utility of multimodal interfaces in remote assistance scenarios for Learning Assistance by Demonstration. Our study also reveals strong individual preferences on the different modalities, with large variations of performance occurring depending on whether supplemental eye-gaze or haptic information was given.",
        "primary_area": "",
        "author": "Vinicius Schettino;Yiannis Demiris;Vinicius Schettino;Yiannis Demiris",
        "authorids": "/37086676945;/37296338900;/37086676945;/37296338900",
        "aff": "Personal Robotics Laboratory, Imperial College London, United Kingdom; Personal Robotics Laboratory, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968203/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6666825532733166338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Personal Robotics Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968065",
        "title": "Inferring Distributions Over Depth from a Single Image",
        "track": "main",
        "status": "Poster",
        "abstract": "When building a geometric scene understanding system for autonomous vehicles, it is crucial to know when the system might fail. Most contemporary approaches cast the problem as depth regression, whose output is a depth value for each pixel. Such approaches cannot diagnose when failures might occur. One attractive alternative is a deep Bayesian network, which captures uncertainty in both model parameters and ambiguous sensor measurements. However, estimating uncertainties is often slow and the distributions are often limited to be uni-modal. In this paper, we recast the continuous problem of depth regression as discrete binary classification, whose output is an un-normalized distribution over possible depths for each pixel. Such output allows one to reliably and efficiently capture multi-modal depth distributions in ambiguous cases, such as depth discontinuities and reflective surfaces. Results on standard benchmarks show that our method produces accurate depth predictions and significantly better uncertainty estimations than prior art while running near real-time. Finally, by making use of uncertainties of the predicted distribution, we significantly reduce streak-like artifacts and improves accuracy as well as memory efficiency in 3D map reconstruction. Video and code can be found on the project website1.",
        "primary_area": "",
        "author": "Gengshan Yang;Peiyun Hu;Deva Ramanan;Gengshan Yang;Peiyun Hu;Deva Ramanan",
        "authorids": "/37087233133;/37086248445;/37393712400;/37087233133;/37086248445;/37393712400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968065/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16696542529560684398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967942",
        "title": "Influence of parameters uncertainties on the positioning of cable-driven parallel robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Positioning accuracy of cable-driven parallel robots is influenced by many factors such as geometry, actuator sensor accuracy and disturbances in the applied wrench. Another uncertainty source is the elasticity of the cables. While the influence of many factors may be decreased by calibration and/or sensor fusion, elasticity parameters are difficult to estimate and their effect on the positioning errors has yet to be determined. In this paper we consider a generic cable model that includes cable elasticity and the effect of cable weight and we propose a generic algorithm that allows one to safely calculate the minimum and maximum of the positioning error at a given pose when the elasticity parameters are constrained to lie within some given bounds. The algorithm is designed for being able to manage the effect of different uncertainties sources and we compare the influence of elasticity versus the effect of uncertainties in the cable lengths.",
        "primary_area": "",
        "author": "J-P. Merlet;J-P. Merlet",
        "authorids": "/37277013900;/37277013900",
        "aff": "HEPHAISTOS project, INRIA, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967942/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13384700103966957482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "HEPHAISTOS project",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "INRIA",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968609",
        "title": "Information Filter Occupancy Mapping using Decomposable Radial Kernels",
        "track": "main",
        "status": "Poster",
        "abstract": "Building occupancy maps of the environment is a fundamental problem for robot autonomy. A common assumption in early work was that the occupancy states of different map elements are independent. Recently, Gaussian Process (GP) techniques were proposed to capture correlation, which is important not only for improved accuracy but also for uncertainty quantification and autonomous exploration based on the predicted occupancy of nearby unexplored areas. Despite these desirable properties, current GP mapping techniques are limited to small maps and slow inference speeds. This paper proposes an information space formulation of the GP mapping problem. If a decomposable radial kernel is evaluated over a latent grid of pseudo-input points, the resulting kernel matrix has a Kronecker-product-of-Toeplitz-matrices structure that allows very efficient representation of the occupancy distribution. We utilize this structure to design an information filter occupancy mapping algorithm with linear time and memory complexity that still permits continuous space observations and predictions.",
        "primary_area": "",
        "author": "Siwei Guo;Nikolay A. Atanasov;Siwei Guo;Nikolay A. Atanasov",
        "authorids": "/37087322321;/37670511000;/37087322321;/37670511000",
        "aff": "Brain Corp, San Diego, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968609/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15369496318273814668&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Brain Corp;University of California, San Diego",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.braincorp.com;https://www.ucsd.edu",
        "aff_unique_abbr": ";UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967722",
        "title": "Informed Region Selection for Efficient UAV-based Object Detectors: Altitude-aware Vehicle Detection with CyCAR Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.",
        "primary_area": "",
        "author": "Alexandros Kouris;Christos Kyrkou;Christos-Savvas Bouganis;Alexandros Kouris;Christos Kyrkou;Christos-Savvas Bouganis",
        "authorids": "/37086094316;/37393167400;/37299183200;/37086094316;/37393167400;/37299183200",
        "aff": "Dept. of Electrical and Electronic Engineering, Imperial College, London, UK; KIOS Research and Innovation Center of Excellence, University of Cyprus, Nicosia, Cyprus; Dept. of Electrical and Electronic Engineering, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967722/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13191642107367508864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Imperial College London;University of Cyprus",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering;KIOS Research and Innovation Center of Excellence",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ucy.ac.cy",
        "aff_unique_abbr": "Imperial;UCY",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "London;Nicosia",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Cyprus"
    },
    {
        "id": "8967554",
        "title": "Infrastructure-free NLoS Obstacle Detection for Autonomous Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "Current perception systems mostly require direct line of sight to anticipate and ultimately prevent potential collisions at intersections with other road users. We present a fully integrated autonomous system capable of detecting shadows or weak illumination changes on the ground caused by a dynamic obstacle in NLoS scenarios. This additional virtual sensor \u201cShadowCam\u201d extends the signal range utilized so far by computer-vision ADASs. We show that (1) our algorithm maintains the mean classification accuracy of around 70% even when it doesn't rely on infrastructure - such as AprilTags - as an image registration method. We validate (2) in real-world experiments that our autonomous car driving in night time conditions detects a hidden approaching car earlier with our virtual sensor than with the front facing 2-D LiDAR.",
        "primary_area": "",
        "author": "Felix Naser;Igor Gilitschenski;Alexander Amini;Christina Liao;Guy Rosman;Sertac Karaman;Daniela Rus;Felix Naser;Igor Gilitschenski;Alexander Amini;Christina Liao;Guy Rosman;Sertac Karaman;Daniela Rus",
        "authorids": "/37086101119;/38469566100;/37086454594;/37087324126;/37393688300;/37304113000;/37279652300;/37086101119;/38469566100;/37086454594;/37087324126;/37393688300;/37304113000;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute for Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute for Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute for Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute for Technology, Cambridge, MA, USA; Toyota Research Institute (TRI), Cambridge, MA, USA; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute for Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute for Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967554/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9034368325446741285&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968479",
        "title": "Integer Programming as a General Solution Methodology for Path-Based Optimization in Robotics: Principles, Best Practices, and Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Integer programming (IP) has proven to be highly effective in solving many path-based optimization problems in robotics. However, the applications of IP are generally done in an ad-hoc, problem-specific manner. In this work, after examined a wide range of path-based optimization problems, we describe an IP solution methodology for these problems that is both easy to apply (in two simple steps) and high-performance in terms of the computation time and the achieved optimality. We demonstrate the generality of our approach through the application to three challenging path-based optimization problems: multi-robot path planning(MPP), minimum constraint removal(MCR), and reward collection problems(RCPs). Associated experiments show that the approach can efficiently produce (near-)optimal solutions for problems with large state spaces, complex constraints, and complicated objective functions. In conjunction with the proposition of the IP methodology, we introduce two new and practical robotics problems: multi-robot minimum constraint removal(MMCR) and multi-robot path planning(MPP) with partial solutions, which can be quickly and effectively solved using our proposed IP solution pipeline.",
        "primary_area": "",
        "author": "Shuai D. Han;Jingjin Yu;Shuai D. Han;Jingjin Yu",
        "authorids": "/37086094452;/37536570700;/37086094452;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968479/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12793139674976175740&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968478",
        "title": "Interaction-aware Decision Making with Adaptive Strategies under Merging Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to drive safely and efficiently under merging scenarios, autonomous vehicles should be aware of their surroundings and make decisions by interacting with other road participants. Moreover, different strategies should be made when the autonomous vehicle is interacting with drivers having different level of cooperativeness. Whether the vehicle is on the merge-lane or main-lane will also influence the driving maneuvers since drivers will behave differently when they have the right-of-way than otherwise. Many traditional methods have been proposed to solve decision making problems under merging scenarios. However, these works either are incapable of modeling complicated interactions or require implementing hand-designed rules which cannot properly handle the uncertainties in real-world scenarios. In this paper, we proposed an interaction-aware decision making with adaptive strategies (IDAS) approach that can let the autonomous vehicle negotiate the road with other drivers by leveraging their cooperativeness under merging scenarios. A single policy is learned under the multi-agent reinforcement learning (MARL) setting via the curriculum learning strategy, which enables the agent to automatically infer other drivers' various behaviors and make decisions strategically. A masking mechanism is also proposed to prevent the agent from exploring states that violate common sense of human judgment and increase the learning efficiency. An exemplar merging scenario was used to implement and examine the proposed method.",
        "primary_area": "",
        "author": "Yeping Hu;Alireza Nakhaei;Masayoshi Tomizuka;Kikuo Fujimura;Yeping Hu;Alireza Nakhaei;Masayoshi Tomizuka;Kikuo Fujimura",
        "authorids": "/37086307227;/37659247900;/37281933000;/37269959700;/37086307227;/37659247900;/37281933000;/37269959700",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Honda Research Institute, Mountain View, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Honda Research Institute, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968478/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11234305928198001457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;Honda Research Institute",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.berkeley.edu;https://honda-ri.com",
        "aff_unique_abbr": "UC Berkeley;HRI",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968571",
        "title": "Interactive Trajectory Adaptation through Force-guided Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible manufacturing processes demand robots to easily adapt to changes in the environment and interact with humans. In such dynamic scenarios, robotic tasks may be programmed through learning-from-demonstration (LfD) approaches, where a nominal plan of the task is learned by the robot. However, the learned plan may need to be adapted in order to fulfill additional requirements or overcome unexpected environment changes. When the required adaptation occurs at the end-effector trajectory level, a human operator may want to intuitively show the robot the desired changes by physically interacting with it. In this scenario, the robot needs to understand the human intended changes from noisy haptic data, quickly adapt accordingly and execute the nominal task plan when no further adaptation is needed. This paper addresses the aforementioned challenges by leveraging LfD and Bayesian optimization to endow the robot with data-efficient adaptation capabilities. Our approach exploits the sensed interaction forces to guide the robot adaptation, and speeds up the optimization process by defining local search spaces extracted from the learned task model. We show how our framework quickly adapts the learned spatial-temporal patterns of the task, leading to deformed trajectory distributions that are consistent with the nominal plan and the changes introduced by the human.",
        "primary_area": "",
        "author": "Leonel Rozo;Leonel Rozo",
        "authorids": "/38228060200;/38228060200",
        "aff": "Bosch Center for Artificial Intelligence, Robert-Bosch-Campus 1, Renningen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968571/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2716590143967832039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://www.bosch-ai.com",
        "aff_unique_abbr": "BCAI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Renningen",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967521",
        "title": "Introducing a Scalable and Modular Control Framework for Low-cost Monocular Robots in Hazardous Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotics for hazardous environments is currently an important area of research, with the ambition of reducing human risk in potentially devastating situations. Here, we are presenting a Modular Control Framework (MCF) for a low-cost robot with limited sensory resources to address this issue. As a proof of concept, we emulate 3 scenarios - (1) adaptive planning for obstruction avoidance (road block), (2) object identification and support-case-based behaviour adjustment (search and rescue) and (3) autonomous navigation through the environment with reporting of structural status (patrol and monitoring). These were implemented and validated using a Cozmo robot in a small-scale Lego environment. We found that our system can reroute in 90%, can help an injured person 80% and report about failing equipment in 80% of all tested cases, where most of the fails were caused by the object detection used. Our MCF is implemented using ROS, making it easy to use and adjust for other robotic platforms.",
        "primary_area": "",
        "author": "Hazel M. Taylor;Christian Dondrup;Katrin S. Lohan;Hazel M. Taylor;Christian Dondrup;Katrin S. Lohan",
        "authorids": "/37087322522;/37085355401;/37888866100;/37087322522;/37085355401;/37888866100",
        "aff": "School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK; School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UK; School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967521/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2164319755162987107&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "School of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967903",
        "title": "Inverse Dynamics Modeling of Robotic Manipulator with Hierarchical Recurrent Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverse dynamics modeling is a critical problem for the computed-torque control of robotic manipulator. This paper presents a novel recurrent network based on the modified Simple Recurrent Unit (SRU) with hierarchical memory (SRU-HM), which is achieved by the nested SRU structure. In this way, it enables the capability to retain the long-term information in the distant past, compared with the conventional stacked structure. The hidden state of SRU is able to provide more complete information relevant to current prediction. Experimental results demonstrate that the proposed method can improve the accuracy of dynamics model greatly, and outperforms the state-of-the-art methods.",
        "primary_area": "",
        "author": "Pengfei Sun;Zhenzhou Shao;Ying Qu;Yong Guan;Jindong Tan;Pengfei Sun;Zhenzhou Shao;Ying Qu;Yong Guan;Jindong Tan",
        "authorids": "/37087325230;/37085555595;/37085888305;/37308153300;/37065245900;/37087325230;/37085555595;/37085888305;/37308153300;/37065245900",
        "aff": "College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; Department of Mechanical, Aerospace, and Biomedical Engineering, The University of Tennessee, Knoxville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967903/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6635405857739256390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Capital Normal University;University of Tennessee",
        "aff_unique_dep": "College of Information Engineering;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "http://www.cnu.edu.cn;https://www.utk.edu",
        "aff_unique_abbr": "CNU;UT Knoxville",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Beijing;Knoxville",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968190",
        "title": "Inverse Kinematics and Sensitivity Minimization of an n-Stack Stewart Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "The method of Frobenius Norm (FN) minimization of forward kinematic Jacobians is presented to minimize the sensitivity of a robotic manipulator. We demonstrate the effectiveness of this approach with a Monte Carlo simulation of an Assembler robot. The Assembler is described as a stack of Stewart Platforms designed for in-space assembly to aide NASA in deep space exploration. The translations and rotations between each Stewart Platform define the forward kinematics of the Assember, which analytically determine the end effector position and orientation. However, selecting the poses of each Stewart Platform which yield a desired end effector state, defined as the inverse kinematics, is an underconstrained nonlinear optimization problem for large Assembler stacks.",
        "primary_area": "",
        "author": "David Balaban;John Cooper;Erik Komendera;David Balaban;John Cooper;Erik Komendera",
        "authorids": "/37086579954;/37087324159;/37071755500;/37086579954;/37087324159;/37071755500",
        "aff": "College of Information and Computer Sciences, former NIFS intern at NASA Langley Research Center, University of Massachusetts Amherst; Research Aerospace Technologist at NASA Langley Research Center, Autonomous Integrated Systems Research Branch; Department of Mechanical Engineering, formerly NASA Langley Research Center, faculty member at Virginia Polytechnic Institute and State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968190/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16718723192108554817&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Massachusetts Amherst;NASA Langley Research Center;Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "College of Information and Computer Sciences;Autonomous Integrated Systems Research Branch;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umass.edu;https://www.nasa.gov/centers/langley;https://www.vt.edu",
        "aff_unique_abbr": "UMass Amherst;NASA LaRC;VT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Amherst;Hampton;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968460",
        "title": "Inverse Optimal Planning for Air Traffic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We envision a system that concisely describes the rules of air traffic control, assists human operators and supports dense autonomous air traffic around commercial airports. We develop a method to learn the rules of air traffic control from real data as a cost function via maximum entropy inverse reinforcement learning. This cost function is used as a penalty for a search-based motion planning method that discretizes both the control and the state space. We illustrate the methodology by showing that our approach can learn to imitate the airport arrival routes and separation rules of dense commercial air traffic. The resulting trajectories are shown to be safe, feasible, and efficient.",
        "primary_area": "",
        "author": "Ekaterina Tolstaya;Alejandro Ribeiro;Vijay Kumar;Ashish Kapoor;Ekaterina Tolstaya;Alejandro Ribeiro;Vijay Kumar;Ashish Kapoor",
        "authorids": "/37086432156;/37266493600;/37280341400;/37397699500;/37086432156;/37266493600;/37280341400;/37397699500",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Microsoft Corporation, Redmond, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968460/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11931653800570590017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Pennsylvania;Microsoft",
        "aff_unique_dep": "Department of Electrical and Systems Engineering;Microsoft Corporation",
        "aff_unique_url": "https://www.upenn.edu;https://www.microsoft.com",
        "aff_unique_abbr": "UPenn;Microsoft",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Philadelphia;Redmond",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967636",
        "title": "Iterative Learning Control for Fast and Accurate Position Tracking with an Articulated Soft Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the application of an iterative learning control scheme to improve the position tracking performance for an articulated soft robotic arm during aggressive maneuvers. Two antagonistically arranged, inflatable bellows actuate the robotic arm and provide high compliance while enabling fast actuation. Switching valves are used for pressure control of the soft actuators. A norm-optimal iterative learning control scheme based on a linear model of the system is presented and applied in parallel with a feedback controller. The learning scheme is experimentally evaluated on an aggressive trajectory involving set point shifts of 60 degrees within 0.2 seconds. The effectiveness of the learning approach is demonstrated by a reduction of the root-mean-square tracking error from 13 degrees to less than 2 degrees after applying the learning scheme for less than 30 iterations.",
        "primary_area": "",
        "author": "Matthias Hofer;Lukas Spannagl;Raffaello D\u2019Andrea;Matthias Hofer;Lukas Spannagl;Raffaello D\u2019Andrea",
        "authorids": "/37085792603;/37087322237;/38525077800;/37085792603;/37087322237;/38525077800",
        "aff": "Institute for Dynamic Systems and Control ETH Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control ETH Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967636/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17904983647748523819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968097",
        "title": "JISAP: Joint Inference for Surgeon Attributes Prediction during Robot-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "In Robot-Assisted Surgery, predicting surgeon attributes such as task workload, operation performance, and expertise levels is important in providing tailored assistance. This paper proposes Joint Inference for Surgeon Attributes Prediction (JISAP), a computational framework to jointly infer surgeon attributes (i.e., task workload, operation performance, and expertise level) from multimodal physiological signals (heart rate variability, wrist motion, electrodermal, electromyography, and electroencephalogram activity). JISAP was evaluated with a dataset of twelve surgeons operating on the da Vinci Skills Simulator. It was found that JISAP can simultaneously predict surgeon attributes with a percentage error of 11.05%. Additionally, joint inference was found to outperform isolated inference with a boost of 10%.",
        "primary_area": "",
        "author": "Tian Zhou;Jackie S. Cha;Glebys T. Gonzalez;Chandru P. Sundaram;Juan P. Wachs;Denny Yu;Tian Zhou;Jackie S. Cha;Glebys T. Gonzalez;Chandru P. Sundaram;Juan P. Wachs;Denny Yu",
        "authorids": "/37086453230;/37087322617;/37087236532;/37086224660;/37327560600;/37087324843;/37086453230;/37087322617;/37087236532;/37086224660;/37327560600;/37087324843",
        "aff": "School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; Department of Urology, School of Medicine at Indiana University, Indianapolis, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968097/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:aHiZSWkMWmQJ:scholar.google.com/&scioq=JISAP:+Joint+Inference+for+Surgeon+Attributes+Prediction+during+Robot-Assisted+Surgery&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Purdue University;Indiana University",
        "aff_unique_dep": "School of Industrial Engineering;School of Medicine, Department of Urology",
        "aff_unique_url": "https://www.purdue.edu;https://iu.edu",
        "aff_unique_abbr": "Purdue;IU",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "West Lafayette;Indianapolis",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968168",
        "title": "Joint Torque Estimation toward Dynamic and Compliant Control for Gear-Driven Torque Sensorless Quadruped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates dynamic and compliant control based on joint output torque estimation for electrically actuated quadruped robots with large-reduction-ratio harmonic gear. Compared with position control, force control exhibits better performance of dynamics and compliance for the robot's interactions with complex environments. However, force control without direct feedbacks from torque sensors may come with poor tracking performance of joint compliance when the robot equipped with gears of high reduction. To solve this problem, we propose a new method to estimate joint torque from motor current and rotation velocity detected on each joint, using a more precise friction model of the harmonic gear. We also introduce a pre-stance phase to the whole cycle of leg alternating swing/stance based on hybrid force and position control to dynamically absorb feet impacts on the ground. Our controller performance is validated by standing experiment and walking experiment.",
        "primary_area": "",
        "author": "Bingchen Jin;Caiming Sun;Aidong Zhang;Ning Ding;Jing Lin;Ganyu Deng;Zuwen Zhu;Zhenglong Sun;Bingchen Jin;Caiming Sun;Aidong Zhang;Ning Ding;Jing Lin;Ganyu Deng;Zuwen Zhu;Zhenglong Sun",
        "authorids": "/37086282585;/37086270576;/37086269590;/37086099653;/37087246146;/37086272302;/37087324227;/37086799406;/37086282585;/37086270576;/37086269590;/37086099653;/37087246146;/37086272302;/37087324227;/37086799406",
        "aff": "Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), the Chinese University of Hong Kong (CUHK), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968168/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1667442767747427073&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Institute of Robotics and Intelligent Manufacturing",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968475",
        "title": "Joint Velocity and Acceleration Estimation in Serial Chain Rigid Body and Flexible Joint Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the problem of accurately computing and estimating joint velocity and acceleration in robotic manipulators. Generally, it is well known that numerical differentiation of noisy position signals even with significant filtering is no viable solution. This is especially true for computing joint acceleration. Specifically, our solution to this problem fuses joint position measurement with link accelerometers, which are affordable and easy to install. Since the sensor readings are affected by noise, drift and bias, suitable data fusion and filtering methods are proposed for improving the estimation for practical use. Simulation results based on a realistic dynamics model of a 7-DoF robot including various parasitic effects and experimental results with a 7-DoF robot demonstrate the effectiveness of our approach. This method would have multiple use, e.g., in monitoring external joint torques and handle possibly unforeseen collisions. Furthermore, other applications such as load identification and compensation as well as state feedback linearization for flexible joint robots could finally become possible also practical.",
        "primary_area": "",
        "author": "Seyed Ali Baradaran Birjandi;Johannes K\u00fchn;Sami Haddadin;Seyed Ali Baradaran Birjandi;Johannes K\u00fchn;Sami Haddadin",
        "authorids": "/37087324803;/37086397704;/37542865300;/37087324803;/37086397704;/37542865300",
        "aff": "Chair of Robotics Science and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University Munich (TUM), He\u00dfstr. 134, Munich, GERMANY; Chair of Robotics Science and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University Munich (TUM), He\u00dfstr. 134, Munich, GERMANY; Chair of Robotics Science and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University Munich (TUM), He\u00dfstr. 134, Munich, GERMANY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968475/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13303394746745087879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University Munich",
        "aff_unique_dep": "Chair of Robotics Science and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967615",
        "title": "Jointly Learnable Behavior and Trajectory Planning for Self-Driving Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "The motion planners used in self-driving vehicles need to generate trajectories that are safe, comfortable, and obey the traffic rules. This is usually achieved by two modules: behavior planner, which handles high-level decisions and produces a coarse trajectory, and trajectory planner that generates a smooth, feasible trajectory for the duration of the planning horizon. These planners, however, are typically developed separately, and changes in the behavior planner might affect the trajectory planner in unexpected ways. Furthermore, the final trajectory outputted by the trajectory planner might differ significantly from the one generated by the behavior planner, as they do not share the same objective. In this paper, we propose a jointly learnable behavior and trajectory planner. Unlike most existing learnable motion planners that address either only behavior planning, or use an uninterpretable neural network to represent the entire logic from sensors to driving commands, our approach features an interpretable cost function on top of perception, prediction and vehicle dynamics, and a joint learning algorithm that learns a shared cost function employed by our behavior and trajectory components. Experiments on real-world self-driving data demonstrate that jointly learned planner performs significantly better in terms of both similarity to human driving and other safety metrics, compared to baselines that do not adopt joint behavior and trajectory learning.",
        "primary_area": "",
        "author": "Abbas Sadat;Mengye Ren;Andrei Pokrovsky;Yen-Chen Lin;Ersin Yumer;Raquel Urtasun;Abbas Sadat;Mengye Ren;Andrei Pokrovsky;Yen-Chen Lin;Ersin Yumer;Raquel Urtasun",
        "authorids": "/37087231701;/37086213738;/37086569295;/37087323198;/37086161237;/37269502900;/37087231701;/37086213738;/37086569295;/37087323198;/37086161237;/37269502900",
        "aff": "Uber Advanced Technologies Group, 661 University Avenue, Suite 720, Toronto, Ontario, Canada; Uber Advanced Technologies Group, 661 University Avenue, Suite 720, Toronto, Ontario, Canada; GraphCore, Uber; Uber, Massachusetts Institute of Technology; Uber Advanced Technologies Group, 661 University Avenue, Suite 720, Toronto, Ontario, Canada; Uber Advanced Technologies Group, 661 University Avenue, Suite 720, Toronto, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967615/",
        "gs_citation": 107,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14847064137056194652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;2;0;0",
        "aff_unique_norm": "Uber Advanced Technologies Group;;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uber.com;;https://web.mit.edu",
        "aff_unique_abbr": "Uber ATG;;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;2;0;0",
        "aff_country_unique": "Canada;;United States"
    },
    {
        "id": "8967776",
        "title": "Kinematic Modeling of a Soft Pneumatic Actuator Using Cubic Hermite Splines",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft material robotic systems provide increased adaptability and flexibility compared to conventional rigid metal robots. The soft systems benefit from their inherent compliance, which enables them to be used in applications that require safe interaction between humans and robots or manipulation in cluttered environment. Despite advancements in recent years research on soft material robots still needs to make progress in terms of modeling for model based control or path planning. The high nonlinearity of soft material robots makes efficient and accurate modeling difficult. In this work we introduce a kinematic modeling approach based on cubic hermite splines. The method is applied to a soft pneumatic actuator and evaluated against the widely used constant curvature approach. The hermite spline offers the possibility of accurate shape reconstruction from simulated or measured deformation data. Both the shape of a robot's segment and its orientation can be approximated this way. In this paper a machine learning approach is used to train the kinematic relation between actuating pressure and configuration parameters.",
        "primary_area": "",
        "author": "Mats Wiese;Kenneth R\u00fcstmann;Annika Raatz;Mats Wiese;Kenneth R\u00fcstmann;Annika Raatz",
        "authorids": "/37086148951;/37087323112;/37394383100;/37086148951;/37087323112;/37394383100",
        "aff": "Institute of Assembly Technology, Leibniz Universit\u00e4t Hannover, Germany; Institute of Assembly Technology, Leibniz Universit\u00e4t Hannover, Germany; Institute of Assembly Technology, Leibniz Universit\u00e4t Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967776/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10387108180537141897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Leibniz Universit\u00e4t Hannover",
        "aff_unique_dep": "Institute of Assembly Technology",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968570",
        "title": "Kinematics, Design and Experimental Validation of a Novel Parallel Robot for Two-Fingered Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Two-fingered manipulation robotic systems are widely used in many application sand notably at small scales. The commonly employed solution is based on the attachment of a gripper on a robot. This paper introduces a new eight degrees of freedom (DoF) mechanism intended for two-fingered dexterous manipulation. The eight DoFs are obtained via a parallel architecture moved by eight actuators that are attached to the base of the robot. The novelty lies in the use of a 2-DoF configurable platform that insures two relative rotations of the gripper jaws (opening and twisting) in addition to the 6-DoF Cartesian movements. The paper presents the kinematics and the design of a proof-of-concept able to grasp, roll, translate and rotate objects in a single compact design. A prototype is operated to manipulate and insert a 2-mm screw.",
        "primary_area": "",
        "author": "Wissem Haouas;Guillaume J. Laurent;S\u00e9bastien Thibaud;Redwan Dahmouche;Wissem Haouas;Guillaume J. Laurent;S\u00e9bastien Thibaud;Redwan Dahmouche",
        "authorids": "/37086199057;/37553268000;/37087323312;/37546446600;/37086199057;/37553268000;/37087323312;/37546446600",
        "aff": "FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, CNRS/UFC/ENSMM, Besan\u00e7on, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, CNRS/UFC/ENSMM, Besan\u00e7on, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, CNRS/UFC/ENSMM, Besan\u00e7on, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, CNRS/UFC/ENSMM, Besan\u00e7on, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968570/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3468427864058859667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "FEMTO-ST Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Besan\u00e7on",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968503",
        "title": "LEGO: Leveraging Experience in Roadmap Generation for Sampling-Based Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of leveraging prior experience to generate roadmaps in sampling-based motion planning. A desirable roadmap is one that is sparse, allowing for fast search, with nodes spread out at key locations such that a low- cost feasible path exists. An increasingly popular approach is to learn a distribution of nodes that would produce such a roadmap. State-of-the-art is to train a conditional variational auto-encoder (CVAE) on the prior dataset with the shortest paths as target input. While this is quite effective on many problems, we show it can fail in the face of complex obstacle configurations or mismatch between training and testing. We present an algorithm LEGO that addresses these issues by training the CVAE with target samples that satisfy two important criteria. Firstly, these samples belong only to bottleneck regions along near-optimal paths that are otherwise difficult- to-sample with a uniform sampler. Secondly, these samples are spread out across diverse regions to maximize the likelihood of a feasible path existing. We formally define these properties and prove performance guarantees for LEGO. We extensively evaluate LEGO on a range of planning problems, including robot arm planning, and report significant gains over heuristics as well as learned baselines.",
        "primary_area": "",
        "author": "Rahul Kumar;Aditya Mandalika;Sanjiban Choudhury;Siddhartha Srinivasa;Rahul Kumar;Aditya Mandalika;Sanjiban Choudhury;Siddhartha Srinivasa",
        "authorids": "/37087323790;/37087323492;/37077381500;/37339877600;/37087323790;/37087323492;/37077381500;/37339877600",
        "aff": "Department of Computer Science, Indian Institute of Technology, Kharagpur; Department of Computer Science, Indian Institute of Technology, Kharagpur; Department of Computer Science, Indian Institute of Technology, Kharagpur; Department of Computer Science, Indian Institute of Technology, Kharagpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968503/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16855180319707983016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology, Kharagpur",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iitkgp.ac.in",
        "aff_unique_abbr": "IIT Kharagpur",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kharagpur",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8967746",
        "title": "LIC-Fusion: LiDAR-Inertial-Camera Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a tightly-coupled multi-sensor fusion algorithm termed LiDAR-inertial-camera fusion (LIC-Fusion), which efficiently fuses IMU measurements, sparse visual features, and extracted LiDAR points. In particular, the proposed LIC-Fusion performs online spatial and temporal sensor calibration between all three asynchronous sensors, in order to compensate for possible calibration variations. The key contribution is the optimal (up to linearization errors) multi-modal sensor fusion of detected and tracked sparse edge/surf feature points from LiDAR scans within an efficient MSCKF-based framework, alongside sparse visual feature observations and IMU readings. We perform extensive experiments in both indoor and outdoor environments, showing that the proposed LIC-Fusion outperforms the state-of-the-art visual-inertial odometry (VIO) and LiDAR odometry methods in terms of estimation accuracy and robustness to aggressive motions.",
        "primary_area": "",
        "author": "Xingxing Zuo;Patrick Geneva;Woosik Lee;Yong Liu;Guoquan Huang;Xingxing Zuo;Patrick Geneva;Woosik Lee;Yong Liu;Guoquan Huang",
        "authorids": "/37086314032;/37086125563;/37087323297;/37066946100;/37077670600;/37086314032;/37086125563;/37087323297;/37066946100;/37077670600",
        "aff": "Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China; Department of Computer and Information Sciences, University of Delaware, Newark, DE, USA; Department of Mechanical Engineering, University of Delaware, Newark, DE, USA; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967746/",
        "gs_citation": 230,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15828349280894870695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Zhejiang University;University of Delaware",
        "aff_unique_dep": "Institute of Cyber-System and Control;Department of Computer and Information Sciences",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.udel.edu",
        "aff_unique_abbr": "ZJU;UD",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Hangzhou;Newark",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968100",
        "title": "Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding. The risk of navigation is usually said to be the probability of collision. This notion of risk is not well defined in the literature, especially when dealing with occupancy grids. The Bayesian occupancy grid is the most used method to deal with complex environments. However, this is not fitted to compute the risk along a path by its discrete nature. In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path. We then define the risk as the force of collision that would occur for a given obstacle. Using this framework, we are able to generate navigation paths ensuring the safety of the robot.",
        "primary_area": "",
        "author": "Johann Laconte;Christophe Debain;Roland Chapuis;Fran\u00e7ois Pomerleau;Romuald Aufr\u00e8re;Johann Laconte;Christophe Debain;Roland Chapuis;Fran\u00e7ois Pomerleau;Romuald Aufr\u00e8re",
        "authorids": "/37086937678;/37295668300;/37284680500;/37594916100;/37443102500;/37086937678;/37295668300;/37284680500;/37594916100;/37443102500",
        "aff": "Universit\u00e9 Clermont Auvergne, CNRS, SIGMA Clermont, Institut Pas-cal, CLERMONT-FERRAND, FRANCE; Irstea, Campus des Cezeaux, Aubier\u00e8 Cedex, France; Universit\u00e9 Clermont Auvergne, CNRS, SIGMA Clermont, Institut Pas-cal, CLERMONT-FERRAND, FRANCE; Northern Robotics Laboratory, Universit\u00e9 Laval, Canada; Universit\u00e9 Clermont Auvergne, CNRS, SIGMA Clermont, Institut Pas-cal, CLERMONT-FERRAND, FRANCE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968100/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=500401366618414778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;Irstea;Universit\u00e9 Laval",
        "aff_unique_dep": ";;Northern Robotics Laboratory",
        "aff_unique_url": "https://www.uca.fr;;https://www.ulaval.ca",
        "aff_unique_abbr": "UCA;;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Clermont-Ferrand;Aubier\u00e8 Cedex;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "8967522",
        "title": "Laminated foam-based soft actuator for actuatable flexible structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, in the search for alternatives to conventional robots, various types of soft actuators and their applications have been studied. In particular, pneumatic soft actuators have the advantage of being lightweight and high power. One of the uses of these soft actuators is as a substitute for an electric motor to actuate the joint of a structure, such as a link mechanism. Another use involves their fusion with a flexible structure. The features of this concept are a simplified system, in which almost all interfaces can be configured as flexible structures. However, because these actuatable flexible structures are made with rubber, silicone, or flexible resin, it is difficult for them to support their own weight owing to the effect of the square-cube law in the case of increasing size. Hence, these structures are limited to a size of approximately 1 \u00d7 10-2 1 \u00d7 10-1 m. If an actuatable flexible structure with a size of 1 \u00d7 100 m can be realized, the concept of soft actuator-flexible structure fusion is expected to provide novel solutions and applications. Herein, as a feasibility study, large actuatable flexible structures were developed. The proposed structure, LayerCAKE, is a laminated open-cell and closed-cell foam structure; cell foam is a lightweight and flexible material that can be used to realize large actuatable flexible structures. LayerCAKE is actuated by using the concept that openand closed-cell foams contract differently when they are vacuumed. The bending-motion model and was experimentally verified, and different types of LayerCAKE models that could exhibit various types of motion were developed and tested. Furthermore, a complex-shaped LayerCAKE model (in the shape of a human hand) was developed. A large actuatable flexible structure of approximately 900 mm was realized. Furthermore, it was confirmed that the bending motion could be controlled by pressure.",
        "primary_area": "",
        "author": "Yasuyuki Yamada;Taro Nakamura;Yasuyuki Yamada;Taro Nakamura",
        "authorids": "/37085823730;/37309580500;/37085823730;/37309580500",
        "aff": "Research and Development Initiative, Chuo University 1-13-27 Kasuga, Bunkyo-ku, Tokyo, Japan; Faculty of Science and Engineering, Chuo University 1-13-27 Kasuga, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967522/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17666130605584313953&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chuo University",
        "aff_unique_dep": "Research and Development Initiative",
        "aff_unique_url": "https://www.chuo-u.ac.jp",
        "aff_unique_abbr": "Chuo U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968529",
        "title": "Landing of a Multirotor Aerial Vehicle on an Uneven Surface Using Multiple On-board Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe the concept, design and implementation of a unique manipulator system for a multirotor aerial vehicle. The proposed manipulator system consists of three robotic arms attached to a multirotor airframe with the objective to provide the ability to manipulate single or multiple objects as well as aid in complex navigation tasks by doing contact based obstacle avoidance and acting as adaptive landing gear in uneven terrain. In this paper we primarily focus on the description and experimentation of one of the tasks achievable by the proposed aerial multi-manipulator system: landing a multirotor aerial vehicle on an uneven surface. Deploying the on-board manipulator as landing gears reduces the hardware carried by the vehicle while additionally providing the ability to land in unstructured and commonly difficult to land terrain.",
        "primary_area": "",
        "author": "Hannibal Paul;Ryo Miyazaki;Robert Ladig;Kazuhiro Shimonomura;Hannibal Paul;Ryo Miyazaki;Robert Ladig;Kazuhiro Shimonomura",
        "authorids": "/37086449686;/37086579328;/37085512842;/37296093100;/37086449686;/37086579328;/37085512842;/37296093100",
        "aff": "Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968529/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9952443691120287963&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967818",
        "title": "Lane Marking Learning based on Crowdsourced Data",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new algorithm that derives lane marking maps from crowdsourced data. We process the data in four steps: (i) We make use of a point landmark map and, if available, an existent lane marking map for trajectory optimization and alignment, (ii) use a custom DBSCAN variant to cluster observations that belong to the same lane marking, (iii) apply a novel graph fitting approach to extract lane marking dashes, lines and even complex structures such as splits and merges and (iv) optimize the graph geometry with domain knowledge. The process of point-landmark- and lane marking-based trajectory alignment and the lane marking derivation is repeated iteratively to improve the results. Evaluation is carried out on a 9km highway section by comparison with high accuracy aerial photographs and manually labeled ground truth lane markings.",
        "primary_area": "",
        "author": "David Pannen;Martin Liebner;Wolfram Burgard;David Pannen;Martin Liebner;Wolfram Burgard",
        "authorids": "/37086935175;/38252116700;/37270485300;/37086935175;/38252116700;/37270485300",
        "aff": "BMW Group, Munich, Germany; BMW Group, Munich, Germany; Department of Computer Science, University of Freiburg, Georges-K\u00f6hler-Allee 080, Freiburg i. Br., Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967818/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2490144134254535650&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "BMW Group;University of Freiburg",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.bmwgroup.com;https://www.uni-freiburg.de",
        "aff_unique_abbr": "BMW;Uni Freiburg",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Munich;Freiburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967594",
        "title": "Large-scale 6D Object Pose Estimation Dataset for Industrial Bin-Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a new public dataset for 6D object pose estimation and instance segmentation for industrial bin-picking. The dataset comprises both synthetic and real-world scenes. For both, point clouds, depth images, and annotations comprising the 6D pose (position and orientation), a visibility score, and a segmentation mask for each object are provided. Along with the raw data, a method for precisely annotating real-world scenes is proposed.To the best of our knowledge, this is the first public dataset for 6D object pose estimation and instance segmentation for bin-picking containing sufficiently annotated data for learning-based approaches. Furthermore, it is one of the largest public datasets for object pose estimation in general. The dataset is publicly available at http://www.bin-picking.ai/en/ dataset.html.",
        "primary_area": "",
        "author": "Kilian Kleeberger;Christian Landgraf;Marco F. Huber;Kilian Kleeberger;Christian Landgraf;Marco F. Huber",
        "authorids": "/37087323129;/37087323588;/37392400600;/37087323129;/37087323588;/37392400600",
        "aff": "Department Robot and Assistive Systems and Marco Huber is with the Center for Cyber Cognitive Intelligence (CCI), Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Nobelstra\u00dfe 12, Stuttgart, Germany; Department Robot and Assistive Systems and Marco Huber is with the Center for Cyber Cognitive Intelligence (CCI), Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Nobelstra\u00dfe 12, Stuttgart, Germany; Department Robot and Assistive Systems and Marco Huber is with the Center for Cyber Cognitive Intelligence (CCI), Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Nobelstra\u00dfe 12, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967594/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8306792727411933930&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "Center for Cyber Cognitive Intelligence (CCI)",
        "aff_unique_url": "https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967962",
        "title": "Lazy Compilation of Variants of Multi-robot Path Planning with Satisfiability Modulo Theory (SMT) Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We address variants of multi-robot path planning in graphs (MRPP). We assume robots placed in vertices of an undirected graph with at most one robot per vertex. Robots can move across edges while various problem specific constraints must be satisfied. We introduce a general problem formulation that encompasses known types of robot relocation problems such as multi-robot path planning (MRPP), token swapping (TSWAP), token rotation (TROT), and token permutation (TPERM). We generalize SMT-CBS, a recent solving approach for MRPP based on satisfiability modulo theories (SMT). SMT- CBS compiles MRPP lazily within the SMT framework, starting with the basic model that is refined with a collision resolution constraints whenever collisions between robots occur in the current solution. We show modifications the SMT-CBS algorithm for variants of MRPP and evaluate them experimentally.",
        "primary_area": "",
        "author": "Pavel Surynek;Pavel Surynek",
        "authorids": "/37698202400;/37698202400",
        "aff": "FIT, Czech Teclmical University in Prague, Th\u00e1kurova 9, Praha 6, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967962/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4352001268005767254&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Information Technology",
        "aff_unique_url": "https://www.fit.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8967624",
        "title": "Learning 2D to 3D Lifting for Object Detection in 3D for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of 3D object detection from 2D monocular images in autonomous driving scenarios. We propose to lift the 2D images to 3D representations using learned neural networks and leverage existing networks working directly on 3D data to perform 3D object detection and localization. We show that, with carefully designed training mechanism and automatically selected minimally noisy data, such a method is not only feasible, but gives higher results than many methods working on actual 3D inputs acquired from physical sensors. On the challenging KITTI benchmark, we show that our 2D to 3D lifted method outperforms many recent competitive 3D networks while significantly outperforming previous state-of-the-art for 3D detection from monocular images. We also show that a late fusion of the output of the network trained on generated 3D images, with that trained on real 3D images, improves performance. We find the results very interesting and argue that such a method could serve as a highly reliable backup in case of malfunction of expensive 3D sensors, if not potentially making them redundant, at least in the case of low human injury risk autonomous navigation scenarios like warehouse automation.",
        "primary_area": "",
        "author": "Siddharth Srivastava;Frederic Jurie;Gaurav Sharma;Siddharth Srivastava;Frederic Jurie;Gaurav Sharma",
        "authorids": "/37085783892;/37267287700;/37274173200;/37085783892;/37267287700;/37274173200",
        "aff": "Indian Institute of Technology, Delhi, India; Normandie Univ., UNICAEN, ENSICAEN, CNRS, France; NEC Labs America, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967624/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17780332527141161487&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Indian Institute of Technology Delhi;Normandie University;NEC Labs America",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.iitdelhi.ac.in;https://www.unicaen.fr;https://www.nec-labs.com",
        "aff_unique_abbr": "IIT Delhi;UNICAEN;NEC Labs",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Delhi;",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "India;France;United States"
    },
    {
        "id": "8968278",
        "title": "Learning Actions from Human Demonstration Video for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning actions from human demonstration is an emerging trend for designing intelligent robotic systems, which can be referred as video to command. The performance of such approach highly relies on the quality of video captioning. However, the general video captioning methods focus more on the understanding of the full frame, lacking of consideration on the specific object of interests in robotic manipulations. We propose a novel deep model to learn actions from human demonstration video for robotic manipulation. It consists of two deep networks, grasp detection network (GNet) and video captioning network (CNet). GNet performs two functions: providing grasp solutions and extracting the local features for the object of interests in robotic manipulation. CNet outputs the captioning results by fusing the features of both full frames and local objects. Experimental results on UR5 robotic arm show that our method could produce more accurate command from video demonstration than state-of-the-art work, thereby leading to more robust grasping performance.",
        "primary_area": "",
        "author": "Shuo Yang;Wei Zhang;Weizhi Lu;Hesheng Wang;Yibin Li;Shuo Yang;Wei Zhang;Weizhi Lu;Hesheng Wang;Yibin Li",
        "authorids": "/37087322435;/37085379581;/37086026380;/37292567100;/37279897500;/37087322435;/37085379581;/37086026380;/37292567100;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, China; School of Control Science and Engineering, Shandong University, China; School of Control Science and Engineering, Shandong University, China; Department of Automation, Shanghai Jiao Tong University, China; School of Control Science and Engineering, Shandong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968278/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6368055994471866371&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Shandong University;Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Control Science and Engineering;Department of Automation",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SDU;SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967981",
        "title": "Learning Barrier Functions for Constrained Motion Planning with Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Stable dynamical systems are a flexible tool to plan robotic motions in real-time. In the robotic literature, dynamical system motions are typically planned without considering possible limitations in the robot's workspace. This work presents a novel approach to learn workspace constraints from human demonstrations and to generate motion trajectories for the robot that lie in the constrained workspace. Training data are incrementally clustered into different linear subspaces and used to fit a low dimensional representation of each subspace. By considering the learned constraint subspaces as zeroing barrier functions, we are able to design a control input that keeps the system trajectory within the learned bounds. This control input is effectively combined with the original system dynamics preserving eventual asymptotic properties of the unconstrained system. Simulations and experiments on a real robot show the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Matteo Saveriano;Dongheui Lee;Matteo Saveriano;Dongheui Lee",
        "authorids": "/38542234400;/37068725100;/38542234400;/37068725100",
        "aff": "Intelligent and Interactive Systems and Digital Science Center (DiSC), University of Innsbruck, Innsbruck, Austria; Human-Centered Assistive Robotics, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967981/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9531550493683006050&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Innsbruck;Technical University of Munich",
        "aff_unique_dep": "Intelligent and Interactive Systems and Digital Science Center (DiSC);Human-Centered Assistive Robotics",
        "aff_unique_url": "https://www.uibk.ac.at;https://www.tum.de",
        "aff_unique_abbr": ";TUM",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Innsbruck;Munich",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Austria;Germany"
    },
    {
        "id": "8968295",
        "title": "Learning Based Robotic Bin-picking for Potentially Tangled Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "In this research, we tackle the challenge of picking only one object from a randomly stacked pile where the objects can potentially be tangled. No solution has been proposed to solve this challenge due to the complexity of picking one and only one object from the bin of tangled objects. Therefore, we propose a method for avoiding the situation where a robot picks multiple objects. In our proposed method, first, grasping pose candidates are computed by using the graspability index. Then, a Convolutional Neural Network (CNN) is trained to predict whether or not the robot can pick one and only one object from the bin. Additionally, since a physics simulator is used to collect data to train the CNN, an automatic picking system can be built. The effectiveness of the proposed method is confirmed through experiments on robot Nextage and compare with previous bin-picking methods.",
        "primary_area": "",
        "author": "Ryo Matsumura;Yukiyasu Domae;Weiwei Wan;Kensuke Harada;Ryo Matsumura;Yukiyasu Domae;Weiwei Wan;Kensuke Harada",
        "authorids": "/37087322552;/37840048000;/37085689483;/37277067400;/37087322552;/37840048000;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968295/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3315965618895571520&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968223",
        "title": "Learning Event-based Height from Plane and Parallax",
        "track": "main",
        "status": "Poster",
        "abstract": "Event-based cameras are a novel asynchronous sensing modality that provide exciting benefits, such as the ability to track fast moving objects with no motion blur and low latency, high dynamic range, and low power consumption. Given the low latency of the cameras, as well as their ability to work in challenging lighting conditions, these cameras are a natural fit for reactive problems such as fast local structure estimation. In this work, we propose a fast method to perform structure estimation for vehicles traveling in a roughly 2D environment (e.g. in an environment with a ground plane). Our method transfers the method of plane and parallax to events, which, given the homography to a ground plane and the pose of the camera, generates a warping of the events which removes the optical flow for events on the ground plane, while inducing flow for events above the ground plane. We then estimate dense flow in this warped space using a self-supervised neural network, which provides the height of all points in the scene. We evaluate our method on the Multi Vehicle Stereo Event Camera dataset, and show its ability to rapidly estimate the scene structure both at high speeds and in low lighting conditions.",
        "primary_area": "",
        "author": "Kenneth Chaney;Alex Zihao Zhu;Kostas Daniilidis;Kenneth Chaney;Alex Zihao Zhu;Kostas Daniilidis",
        "authorids": "/37087230389;/37086104530;/37270623200;/37087230389;/37086104530;/37270623200",
        "aff": "University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968223/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18033592531781481288&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967845",
        "title": "Learning Interactive Behaviors for Musculoskeletal Robots Using Bayesian Interaction Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Musculoskeletal robots that are based on pneumatic actuation have a variety of properties, such as compliance and back-drivability, that render them particularly appealing for human-robot collaboration. However, programming interactive and responsive behaviors for such systems is extremely challenging due to the nonlinearity and uncertainty inherent to their control. In this paper, we propose an approach for learning Bayesian Interaction Primitives for musculoskeletal robots given a limited set of example demonstrations. We show that this approach is capable of real-time state estimation and response generation for interaction with a robot for which no analytical model exists. Human-robot interaction experiments on a 'handshake' task show that the approach generalizes to new positions, interaction partners, and movement velocities.",
        "primary_area": "",
        "author": "Joseph Campbell;Arne Hitzmann;Simon Stepputtis;Shuhei Ikemoto;Koh Hosoda;Heni Ben Amor;Joseph Campbell;Arne Hitzmann;Simon Stepputtis;Shuhei Ikemoto;Koh Hosoda;Heni Ben Amor",
        "authorids": "/37085810305;/37087100760;/37086175304;/37659393100;/37270101900;/37293927700;/37085810305;/37087100760;/37086175304;/37659393100;/37270101900;/37293927700",
        "aff": "school of Computing, Informatics, and Decision Systems Engineering, Arizona State University; Graduate School of Engineering Science, Osaka University; school of Computing, Informatics, and Decision Systems Engineering, Arizona State University; Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology; Graduate School of Engineering Science, Osaka University; school of Computing, Informatics, and Decision Systems Engineering, Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967845/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9922732636072161420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "Arizona State University;Osaka University;Kyushu Institute of Technology",
        "aff_unique_dep": "School of Computing, Informatics, and Decision Systems Engineering;Graduate School of Engineering Science;Graduate School of Life Science and Systems Engineering",
        "aff_unique_url": "https://asu.edu;https://www.osaka-u.ac.jp;https://www.kyutech.ac.jp",
        "aff_unique_abbr": "ASU;Osaka U;Kyutech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Osaka",
        "aff_country_unique_index": "0;1;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "8967749",
        "title": "Learning Local Feature Descriptor with Motion Attribute For Vision-based Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, camera-based localization has been widely used for robotic applications, and most proposed algorithms rely on local features extracted from recorded images. For better performance, the features used for open-loop localization are required to be short-term globally static, and the ones used for re-localization or loop closure detection need to be long-term static. Therefore, the motion attribute of a local feature point could be exploited to improve localization performance, e.g., the feature points extracted from moving persons or vehicles can be excluded from these systems due to their unsteadiness. In this paper, we design a fully convolutional network (FCN), named MD-Net, to perform motion attribute estimation and feature description simultaneously. MD-Net has a shared backbone network to extract features from the input image and two network branches to complete each sub-task. With MD-Net, we can obtain the motion attribute while avoiding increasing much more computation. Experimental results demonstrate that the proposed method can learn distinct local feature descriptor along with motion attribute only using an FCN, by outperforming competing methods by a wide margin. We also show that the proposed algorithm can be integrated into a vision-based localization algorithm to improve estimation accuracy significantly.",
        "primary_area": "",
        "author": "Yafei Song;Di Zhu;Jia Li;Yonghong Tian;Mingyang Li;Yafei Song;Di Zhu;Jia Li;Yonghong Tian;Mingyang Li",
        "authorids": "/37085464432;/37087322885;/37085389450;/37398769200;/37086936897;/37085464432;/37087322885;/37085389450;/37398769200;/37086936897",
        "aff": "AI Labs, Alibaba Group, Hangzhou, China; AI Labs, Alibaba Group, Hangzhou, China; National Key Laboratory of Virtual Reality Technology and System, School of Computer Science and Engineering, Beihang University, Beijing, China; National Engineering Laboratory for Video Technology, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; AI Labs, Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967749/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1703952160016126867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Alibaba Group;Beihang University;Peking University",
        "aff_unique_dep": "AI Labs;School of Computer Science and Engineering;School of Electronics Engineering and Computer Science",
        "aff_unique_url": "https://www.alibaba.com;http://www.buaa.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "Alibaba;Beihang;PKU",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967635",
        "title": "Learning Multimodal Representations for Sample-efficient Recognition of Human Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans interact in rich and diverse ways with the environment. However, the representation of such behavior by artificial agents is often limited. In this work we present motion concepts, a novel multimodal representation of human actions in a household environment. A motion concept encompasses a probabilistic description of the kinematics of the action along with its contextual background, namely the location and the objects held during the performance. We introduce a novel algorithm which learns and recognizes motion concepts from action demonstrations, named Online Motion Concept Learning (OMCL). The algorithm is evaluated on a virtual-reality household environment with the presence of a human avatar. OMCL outperforms standard motion recognition algorithms on an one-shot recognition task, attesting to its potential for sample-efficient recognition of human actions.",
        "primary_area": "",
        "author": "Miguel Vasco;Francisco S. Melo;David Martins de Matos;Ana Paiva;Tetsunari Inamura;Miguel Vasco;Francisco S. Melo;David Martins de Matos;Ana Paiva;Tetsunari Inamura",
        "authorids": "/37087324547;/37885650900;/37089118955;/37267245800;/37294612600;/37087324547;/37885650900;/37089118955;/37267245800;/37294612600",
        "aff": "INESC-ID and Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID and Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID and Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID and Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; Department of Informatics, SOKENDAI (The Graduate University for Advanced Studies), 2-1-2 Hitotsubashi, National Institute of Informatics, Chiyoda-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967635/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8278830412549916531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Lisbon;SOKENDAI (The Graduate University for Advanced Studies)",
        "aff_unique_dep": "INESC-ID and Instituto Superior T\u00e9cnico;Department of Informatics",
        "aff_unique_url": "https://www.ulusiada.pt;https://www.soken.osakau.ac.jp",
        "aff_unique_abbr": "ULisbon;SOKENDAI",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Lisbon;Tokyo",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Portugal;Japan"
    },
    {
        "id": "8967780",
        "title": "Learning Multiple Sensorimotor Units to Complete Compound Tasks using an RNN with Multiple Attractors",
        "track": "main",
        "status": "Poster",
        "abstract": "As the complexity of the robot's tasks increases, we can consider many general tasks in a compound form that consists of shorter tasks. Therefore, for robots to generate various tasks, they need to be able to execute shorter tasks in succession, appropriately to the situation. With the design principle to construct the architecture for robots to execute complex tasks compounded with multiple subtasks, this study proposes a visuomotor-control framework with the characteristics of a state machine to train shorter tasks as sensorimotor units. The design procedure of training framework consists of 4 steps: (1) segment entire task into appropriate subtasks, (2) define subtasks as states and transitions in a state machine, (3) collect subtasks data, and (4) train neural networks: (a) autoencoder to extract visual features, (b) a single recurrent neural network to generate subtasks to realize a pseud-state-machine model with a constraint in hidden values. We implemented this framework on two different robots to allow their performance of repetitive tasks with error-recovery motion, subsequently, confirming the ability of the robot to switch the sensorimotor units from visual input at the attractors of the hidden values created by the constraint.",
        "primary_area": "",
        "author": "Kei Kase;Ryoichi Nakajo;Hiroki Mori;Tetsuya Ogata;Kei Kase;Ryoichi Nakajo;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37086051576;/37085622533;/37086432927;/37273829100;/37086051576;/37085622533;/37086432927;/37273829100",
        "aff": "Department of Intermedia Studies, Waseda University, Tokyo, Japan; Department of Intermedia Studies, Waseda University, Tokyo, Japan; Future Robotics Organization, Waseda University, Tokyo, Japan; Department of Intermedia Studies, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967780/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3533560785585364666&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Department of Intermedia Studies",
        "aff_unique_url": "https://www.waseda.ac.jp",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968211",
        "title": "Learning Object Models For Non-prehensile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Using models to represent information about the world is a well known paradigm for successful robot control in the real world. Numerous methods exist today that can leverage these models to make robots perform tasks, either by directly exploiting the model structure or by accessing the model via a simulation. In this work, we explore how robots can use demonstrations to quickly build descriptive models of objects for manipulation tasks. Our framework uses demonstrations to incrementally build task-relevant geometric and physics-based object models that can be used to build simulations of the world that the robot is interacting with. We present experiments that involve estimating geometric features of an object when demonstration data from a user interacting with the object is available. We also demonstrate our method on the task of toppling a box with a 7-DoF manipulator equipped with a palm at its end. Using our approach, the robot is able to complete the task using only a few demonstrations.",
        "primary_area": "",
        "author": "Siddharth Sanan;Mason Bretan;Larry Heck;Siddharth Sanan;Mason Bretan;Larry Heck",
        "authorids": "/37681772000;/38467143900;/38275102700;/37681772000;/38467143900;/38275102700",
        "aff": "AI Center, Samsung Research America, Mountain View, CA, USA; AI Center, Samsung Research America, Mountain View, CA, USA; AI Center, Samsung Research America, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968211/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5179202229506001823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/us/research/",
        "aff_unique_abbr": "SRA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967717",
        "title": "Learning Physics-Based Manipulation in Clutter: Combining Image-Based Generalization and Look-Ahead Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Physics-based manipulation in clutter involves complex interaction between multiple objects. In this paper, we consider the problem of learning, from interaction in a physics simulator, manipulation skills to solve this multi-step sequential decision making problem in the real world. Our approach has two key properties: (i) the ability to generalize and transfer manipulation skills (over the type, shape, and number of objects in the scene) using an abstract image-based representation that enables a neural network to learn useful features; and (ii) the ability to perform look-ahead planning in the image space using a physics simulator, which is essential for such multi-step problems. We show, in sets of simulated and real-world experiments (video available on https://youtu.be/EmkUQfyvwkY), that by learning to evaluate actions in an abstract image-based representation of the real world, the robot can generalize and adapt to the object shapes in challenging real-world environments.",
        "primary_area": "",
        "author": "Wissam Bejjani;Mehmet R. Dogar;Matteo Leonetti;Wissam Bejjani;Mehmet R. Dogar;Matteo Leonetti",
        "authorids": "/37086605415;/37591140400;/37593250400;/37086605415;/37591140400;/37593250400",
        "aff": "School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967717/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16237881223782730962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Leeds",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.leeds.ac.uk",
        "aff_unique_abbr": "Leeds",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968173",
        "title": "Learning Q-network for Active Information Acquisition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel Reinforcement Learning approach for solving the Active Information Acquisition problem, which requires an agent to choose a sequence of actions in order to acquire information about a process of interest using on-board sensors. The classic challenges in the information acquisition problem are the dependence of a planning algorithm on known models and the difficulty of computing information-theoretic cost functions over arbitrary distributions. In contrast, the proposed framework of reinforcement learning does not require any knowledge on models and alleviates the problems during an extended training stage. It results in policies that are efficient to execute online and applicable for real-time control of robotic systems. Furthermore, the state-of-the-art planning methods are typically restricted to short horizons, which may become problematic with local minima. Reinforcement learning naturally handles the issue of planning horizon in information problems as it maximizes a discounted sum of rewards over a long finite or infinite time horizon. We discuss the potential benefits of the proposed framework and compare the performance of the novel algorithm to an existing information acquisition method for multi-target tracking scenarios.",
        "primary_area": "",
        "author": "Heejin Jeong;Brent Schlotfeldt;Hamed Hassani;Manfred Morari;Daniel D. Lee;George J. Pappas;Heejin Jeong;Brent Schlotfeldt;Hamed Hassani;Manfred Morari;Daniel D. Lee;George J. Pappas",
        "authorids": "/37087322449;/37086113948;/37086178545;/37282929500;/37280609600;/37281547100;/37087322449;/37086113948;/37086178545;/37282929500;/37280609600;/37281547100",
        "aff": "department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968173/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1862977201872090467&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Cornell University",
        "aff_unique_dep": "Department of Electrical and Systems Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UPenn;Cornell",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Philadelphia;Ithaca",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967559",
        "title": "Learning Real-World Robot Policies by Dreaming",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning to control robots directly based on images is a primary challenge in robotics. However, many existing reinforcement learning approaches require iteratively obtaining millions of robot samples to learn a policy, which can take significant time. In this paper, we focus on learning a realistic world model capturing the dynamics of scene changes conditioned on robot actions. Our dreaming model can emulate samples equivalent to a sequence of images from the actual environment, technically by learning an action-conditioned future representation/scene regressor. This allows the agent to learn action policies (i.e., visuomotor policies) by interacting with the dreaming model rather than the real-world. We experimentally confirm that our dreaming model enables robot learning of policies that transfer to the real-world.",
        "primary_area": "",
        "author": "Aj Piergiovanni;Alan Wu;Michael S. Ryoo;Aj Piergiovanni;Alan Wu;Michael S. Ryoo",
        "authorids": "/37086571280;/37086571593;/37397559800;/37086571280;/37086571593;/37397559800",
        "aff": "School of Informatics, Computing Engineering Indiana University Bloomington; School of Informatics, Computing Engineering Indiana University Bloomington; School of Informatics, Computing Engineering Indiana University Bloomington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967559/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14374180129464620243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indiana University Bloomington",
        "aff_unique_dep": "School of Informatics, Computing Engineering",
        "aff_unique_url": "https://www.iu.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968136",
        "title": "Learning Real-time Closed Loop Robotic Reaching from Monocular Vision by Exploiting A Control Lyapunov Function Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual reaching and grasping is a fundamental problem in robotics research. This paper proposes a novel approach based on deep learning a control Lyapunov function and its derivatives by encouraging a differential constraint in addition to vanilla regression that directly regresses independent joint control inputs. A key advantage of the proposed approach is that an estimate of the value of the control Lyapunov function is available in real-time that can be used to monitor the system performance and provide a level of assurance concerning progress towards the goal. The results we obtain demonstrate that the proposed approach is more robust and more reliable than vanilla regression.",
        "primary_area": "",
        "author": "Zheyu Zhuang;J\u00fcrgen Leitner;Robert Mahony;Zheyu Zhuang;J\u00fcrgen Leitner;Robert Mahony",
        "authorids": "/37087324996;/37885671300;/37283743600;/37087324996;/37885671300;/37283743600",
        "aff": "Australian Centre for Robotic Vision, Research School of Engineering, The Australian National University, Canberra ACT, Australia; Australian Centre for Robotic Vision, Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision, Research School of Engineering, The Australian National University, Canberra ACT, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968136/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1809124650396389866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Australian National University;Queensland University of Technology",
        "aff_unique_dep": "Research School of Engineering;Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.anu.edu.au;https://www.qut.edu.au",
        "aff_unique_abbr": "ANU;QUT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Canberra;Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967970",
        "title": "Learning Residual Flow as Dynamic Motion from Stereo Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for decomposing the 3D scene flow observed from a moving stereo rig into stationary scene elements and dynamic object motion. Our unsupervised learning framework jointly reasons about the camera motion, optical flow, and 3D motion of moving objects. Three cooperating networks predict stereo matching, camera motion, and residual flow, which represents the flow component due to object motion and not from camera motion. Based on rigid projective geometry, the estimated stereo depth is used to guide the camera motion estimation, and the depth and camera motion are used to guide the residual flow estimation. We also explicitly estimate the 3D scene flow of dynamic objects based on the residual flow and scene depth. Experiments on the KITTI dataset demonstrate the effectiveness of our approach and show that our method outperforms other state-of-the-art algorithms on the optical flow and visual odometry tasks.",
        "primary_area": "",
        "author": "Seokju Lee;Sunghoon Im;Stephen Lin;In So Kweon;Seokju Lee;Sunghoon Im;Stephen Lin;In So Kweon",
        "authorids": "/37085378123;/37085624852;/37276532200;/37270474800;/37085378123;/37085624852;/37276532200;/37270474800",
        "aff": "Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea; Microsoft Research Asia, Beijing, China; Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967970/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9526683590594522133&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "KAIST;Microsoft",
        "aff_unique_dep": "Robotics and Computer Vision Laboratory;Research",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.microsoft.com/en-us/research/group/asia",
        "aff_unique_abbr": "KAIST;MSRA",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Daejeon;Beijing",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "South Korea;China"
    },
    {
        "id": "8968483",
        "title": "Learning Safe Unlabeled Multi-Robot Planning with Motion Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a learning approach to goal assignment and trajectory planning for unlabeled robots operating in 2D, obstacle-filled workspaces. More specifically, we tackle the unlabeled multi-robot motion planning problem with motion constraints as a multi-agent reinforcement learning problem with some sparse global reward. In contrast with previous works, which formulate an entirely new hand-crafted optimization cost or trajectory generation algorithm for a different robot dynamic model, our framework is a general approach that is applicable to arbitrary robot models. Further, by using the velocity obstacle, we devise a smooth projection that guarantees collision free trajectories for all robots with respect to their neighbors and obstacles. The efficacy of our algorithm is demonstrated through varied simulations. A video describing our method and results can be found here.",
        "primary_area": "",
        "author": "Arbaaz Khan;Chi Zhang;Shuo Li;Jiayue Wu;Brent Schlotfeldt;Sarah Y. Tang;Alejandro Ribeiro;Osbert Bastani;Vijay Kumar;Arbaaz Khan;Chi Zhang;Shuo Li;Jiayue Wu;Brent Schlotfeldt;Sarah Y. Tang;Alejandro Ribeiro;Osbert Bastani;Vijay Kumar",
        "authorids": "/37086407002;/37087325082;/37087323087;/37087321774;/37086113948;/37085534582;/37266493600;/37087323130;/37280341400;/37086407002;/37087325082;/37087323087;/37087321774;/37086113948;/37085534582;/37266493600;/37087323130;/37280341400",
        "aff": "GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; Nuro, Palo Alto, CA, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968483/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6948097717468690713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "University of Pennsylvania;Nuro",
        "aff_unique_dep": "GRASP Lab;",
        "aff_unique_url": "https://www.upenn.edu;https://www.nuro.ai",
        "aff_unique_abbr": "UPenn;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Palo Alto",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967990",
        "title": "Learning Singularity Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increase in complexity of robotic systems and the rise in non-expert users, it can be assumed that task constraints are not explicitly known. In tasks where avoiding singularity is critical to success, this paper provides an approach, especially for non-expert users, for the system to learn the constraints contained in a set of demonstrations, such that they can be used to optimise an autonomous controller to avoid singularity, without having to explicitly know them. The proposed approach avoids singularity, and thereby unpredictable behaviour when carrying out a task, by maximising the learnt manipulability throughout the motion of the constrained system, and is not limited to kinematic systems. Its benefits are demonstrated through comparisons with other control policies which show that the constrained manipulability of a system learnt through demonstration can be used to avoid singularities in cases where these other policies would fail. In the absence of the system's manipulability subject to a task's constraints, the proposed approach can be used instead to infer these with results showing errors less than 10-5 in 3DOF simulated systems and less than 10-2 using a 7DOF real world robotic system.",
        "primary_area": "",
        "author": "Jeevan Manavalan;Matthew Howard;Jeevan Manavalan;Matthew Howard",
        "authorids": "/37087322760;/37301483600;/37087322760;/37301483600",
        "aff": "Department of Informatics, King\u2019s College London, Centre for Robotics Research, London, UK; Department of Informatics, King\u2019s College London, Centre for Robotics Research, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967990/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16631590342332240216&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "King\u2019s College London",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968185",
        "title": "Learning State-Dependent, Sensor Measurement Models for Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot typically relies on sensor measurements to infer its state and the state of its environment. Unfortunately, sensor measurements are noisy, and the amount of noise can vary with state. The literature provides a collection of methods that estimate and adapt measurement noise over time. However, many methods do not assume that measurement noise is stochastic, or they do not estimate sensor measurement bias and noise based on state. In this paper, we propose a novel method called state-dependent, sensor measurement models(SDSMMs). This method: 1) learns to estimate measurement probability density functions directly from sensor measurements and 2) stochastically estimates an expected measurement (which includes measurement bias) and a measurement noise, both of which are conditioned upon the states of a robot and its environment. Throughout this paper, we discuss how to learn an SDSMM and use it with the Extended Kalman Filter (EKF). We then apply our method to solve an EKF localization problem using a real robot dataset. Our localization results showed that at least one of our proposed methods outperformed a standard EKF in all 15 cases for 2D position error and 10 of 15 cases for 1D orientation error. Our methods had a mean improvement of 39% for position and 15% for orientation.",
        "primary_area": "",
        "author": "Troi Williams;Yu Sun;Troi Williams;Yu Sun",
        "authorids": "/37087323394;/37291603500;/37087323394;/37291603500",
        "aff": "Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968185/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10790597784175162777&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968111",
        "title": "Learning Topometric Semantic Maps from Occupancy Grids",
        "track": "main",
        "status": "Poster",
        "abstract": "Today's mobile robots are expected to operate in complex environments they share with humans. To allow intuitive human-robot collaboration, robots require a human-like understanding of their surroundings in terms of semantically classified instances. In this paper, we propose a new approach for deriving such instance-based semantic maps purely from occupancy grids. We employ a combination of deep learning techniques to detect, segment and extract door hypotheses from a random-sized map. The extraction is followed by a post-processing chain to further increase the accuracy of our approach, as well as place categorization for the three classes room, door and corridor. All detected and classified entities are described as instances specified in a common coordinate system, while a topological map is derived to capture their spatial links. To train our two neural networks used for detection and map segmentation, we contribute a simulator that automatically creates and annotates the required training data. We further provide insight into which features are learned to detect doorways, and how the simulated training data can be augmented to train networks for the direct application on real-world grid maps. We evaluate our approach on several publicly available real-world data sets. Even though the used networks are solely trained on simulated data, our approach demonstrates high robustness and effectiveness in various real-world indoor environments.",
        "primary_area": "",
        "author": "Markus Hiller;Chen Qiu;Florian Particke;Christian Hofmann;J\u00f6rn Thielecke;Markus Hiller;Chen Qiu;Florian Particke;Christian Hofmann;J\u00f6rn Thielecke",
        "authorids": "/37086295290;/37087322400;/37085634201;/37705265700;/37388458100;/37086295290;/37087322400;/37085634201;/37705265700;/37388458100",
        "aff": "Institute of Information Technology, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU), Germany; Institute of Information Technology, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU), Germany; Institute of Information Technology, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU), Germany; Institute of Information Technology, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU), Germany; Institute of Information Technology, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968111/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18369264471620750069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg",
        "aff_unique_dep": "Institute of Information Technology",
        "aff_unique_url": "https://www fau.de",
        "aff_unique_abbr": "FAU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Erlangen-N\u00fcrnberg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968586",
        "title": "Learning Via-Point Movement Primitives with Inter- and Extrapolation Capabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "Movement Primitives (MPs) are a promising way for representing robot motions in a flexible and adaptable manner. Due to the simple and compact form, they have been widely used in robotics. A major goal of the research activities on MPs is to learn models, which can adapt to changing task constraints, e.g. new motion targets. However, the adaptability of current MPs is limited to a small set of constraints due to their simple structures. It is indeed not a trivial task to maintain the simplicity of MPs representation and, at the same time, enhance their adaptability. In this paper, we discuss the adaptability of popular MPs such as Dynamic Movement Primitives (DMP) and Probabilistic Movement Primitives (ProMP) and propose a new simple but efficient formulation of MPs, the Via-points Movement Primitive (VMP), that can adapt to arbitrary via-points using a simple structured model that is based on the previous approaches but outperforms those in terms of extrapolation abilities.",
        "primary_area": "",
        "author": "You Zhou;Jianfeng Gao;Tamim Asfour;You Zhou;Jianfeng Gao;Tamim Asfour",
        "authorids": "/37086046566;/37086604791;/37295529100;/37086046566;/37086604791;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968586/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3170004920099261158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967576",
        "title": "Learning Virtual Borders through Semantic Scene Understanding and Augmented Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtual borders are an opportunity to allow users the interactive restriction of their mobile robots' workspaces, e.g. to avoid navigation errors or to exclude certain areas from working. Currently, works in this field have focused on human-robot interaction (HRI) methods to restrict the workspace. However, recent trends towards smart environments and the tremendous progress in semantic scene understanding give new opportunities to enhance the HRI-based methods. Therefore, we propose a novel learning and support system (LSS) to support users during teaching of virtual borders. Our LSS learns from user interactions employing methods from visual scene understanding and supports users through recommendations for interactions. The bidirectional interaction between the user and system is realized using augmented reality. A validation of the approach shows that the LSS robustly recognizes a limited set of typical areas for virtual borders based on previous user interactions (F1 - Score= 91.5%) while preserving the high accuracy of standard HRI-based methods with a median of Mdn= 84.6%. Moreover, this approach allows the reduction of the interaction time to a constant mean value of M = 2 seconds making it independent of the border length. This avoids a linear interaction time of standard HRI-based methods.",
        "primary_area": "",
        "author": "Dennis Sprute;Philipp Viertel;Klaus T\u00f6nnies;Matthias K\u00f6nig;Dennis Sprute;Philipp Viertel;Klaus T\u00f6nnies;Matthias K\u00f6nig",
        "authorids": "/37085888678;/37087324602;/37333351000;/37086328819;/37085888678;/37087324602;/37333351000;/37086328819",
        "aff": "Campus Minden, Bielefeld University of Applied Sciences, Minden, Germany; Campus Minden, Bielefeld University of Applied Sciences, Minden, Germany; Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Campus Minden, Bielefeld University of Applied Sciences, Minden, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967576/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10902145569501115902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Bielefeld University of Applied Sciences;Otto-von-Guericke University Magdeburg",
        "aff_unique_dep": ";Faculty of Computer Science",
        "aff_unique_url": "https://www.fh-bielefeld.de;https://www.ovgu.de",
        "aff_unique_abbr": ";OVGU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Minden;Magdeburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968063",
        "title": "Learning Virtual Grasp with Failed Demonstrations via Bayesian Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose Bayesian Inverse Reinforcement Learning with Failure (BIRLF), which makes use of failed demonstrations that were often ignored or filtered in previous methods due to the difficulties to incorporate them in addition to the successful ones. Specifically, we leverage halfspaces derived from policy optimality conditions to incorporate failed demonstrations under Bayesian Inverse Reinforcement Learning (BIRL) framework. Under the continuous control setting, the reward function and policy are learned in an alternative manner, both of which are estimated by function approximators to guarantee the learning ability. Our approach is formulated as a model-free Inverse Reinforcement Learning (IRL) method that naturally accommodates more complex environments with continuous state and action spaces. In experiments, we demonstrate the proposed method in a virtual grasping task, achieving a significant performance boost compared to existing methods.",
        "primary_area": "",
        "author": "Xu Xie;Changyang Li;Chi Zhang;Yixin Zhu;Song-Chun Zhu;Xu Xie;Changyang Li;Chi Zhang;Yixin Zhu;Song-Chun Zhu",
        "authorids": "/37087324382;/37087323950;/37089107953;/37086172463;/37281407500;/37087324382;/37087323950;/37089107953;/37086172463;/37281407500",
        "aff": "UCLA Center for Vision, Cognition, Learning, and Autonomy; UCLA Center for Vision, Cognition, Learning, and Autonomy; UCLA Center for Vision, Cognition, Learning, and Autonomy; UCLA Center for Vision, Cognition, Learning, and Autonomy; UCLA Center for Vision, Cognition, Learning, and Autonomy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968063/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1278100192272561004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Center for Vision, Cognition, Learning, and Autonomy",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967567",
        "title": "Learning by Demonstration and Robust Control of Dexterous In-Hand Robotic Manipulation Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous robotic manipulation of unknown objects can open the way to novel tasks and applications of robots in semi-structured and unstructured settings, from advanced industrial manufacturing to exploration of harsh environments. However, it is challenging for at least three reasons: the desired motion of the object might be too complex to be described analytically, precise models of the manipulated objects are not available, the controller should simultaneously ensure both a robust grasp and an effective in-hand motion. To solve these issues we propose to learn in-hand robotic manipulation tasks from human demonstrations, using Dynamical Movement Primitives (DMPs), and to reproduce them with a robust compliant controller based on the Virtual Springs Framework (VSF), that employs real-time feedback of the contact forces measured on the robot fingertips. With this solution, the generalization capabilities of DMPs can be transferred successfully to the dexterous in-hand manipulation problem: we demonstrate this by presenting real-world experiments of in-hand translation and rotation of unknown objects.",
        "primary_area": "",
        "author": "Gokhan Solak;Lorenzo Jamone;Gokhan Solak;Lorenzo Jamone",
        "authorids": "/37086112812;/37295474600;/37086112812;/37295474600",
        "aff": "ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967567/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5803553064566721918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "School of Electronic Engineering and Computer Science",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967606",
        "title": "Learning footstep planning on irregular surfaces with partial placements",
        "track": "main",
        "status": "Poster",
        "abstract": "We present two contributions built upon on a previous footstep planner based on the ARA* search. Firstly, we have developed an improved foothold selection method using support polygons, to increase foothold availability in rough terrain. Secondly, we present a footstep classification method using the C5.0 algorithm, that takes advantage of cost similarity between adjacent steps. This is intended to learn feasibility and approximate transition costs for the ARA* planner.These contributions extend capabilities of the planner by increasing footstep availability and allowing to generate more complex plans, without compromising safety.",
        "primary_area": "",
        "author": "Germ\u00e1n Castro;Claude Sammut;Germ\u00e1n Castro;Claude Sammut",
        "authorids": "/37087322308;/37353499200;/37087322308;/37353499200",
        "aff": "School of Computer Science and Engineering, The University of New South Wales, Sydney, Australia; School of Computer Science and Engineering, The University of New South Wales, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967606/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4657388511846579814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of New South Wales",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.unsw.edu.au",
        "aff_unique_abbr": "UNSW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967917",
        "title": "Learning from Demonstration Based on a Mechanism to Utilize an Object\u2019s Invisibility",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel visual Learning from Demonstration (LfD) system that teaches robots to learn tasks in which an object is put into another object, stacked, or transported by a tool. In such tasks, observation targets become invisible owing to occlusion or frame-out. The proposed \u201cVisual Hierarchy-based Function Estimator (Hi-Fes)\u201d is inspired by the knowledge derived from the field of psychology that uses the visual hierarchy relationships to estimate the changes in observation targets. Hi-Fes employs a mechanism to interpolate the features when the targets are unrecognizable and state variables are incalculable directly. This method facilitated visual learning of complex state changes between multiple targets, in which the target becomes invisible or has a long period of invisibility, difficult for conventional learning methods. The proposed method was implemented in a life-sized humanoid robot and was evaluated in learning based on demonstration experiments. The results demonstrated the effectiveness of our approach.",
        "primary_area": "",
        "author": "Kotaro Nagahama;Kimitoshi Yamazaki;Kotaro Nagahama;Kimitoshi Yamazaki",
        "authorids": "/37842231800;/37274018600;/37842231800;/37274018600",
        "aff": "AIS Lab., Faculty of Engineering, Shinshu University, 410, Mech. Sys. Eng. Buidling, Nagano, Nagano, Japan; AIS Lab., Faculty of Engineering, Shinshu University, 410, Mech. Sys. Eng. Buidling, Nagano, Nagano, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967917/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17018846529258092900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Shinshu University",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://www.shinshu-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagano",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968013",
        "title": "Learning the Scope of Applicability for Task Planning Knowledge in Experience-Based Planning Domains",
        "track": "main",
        "status": "Poster",
        "abstract": "Experience-based planning domains (EBPDs) have been proposed to improve problem solving by learning from experience. They rely on acquiring and using task knowledge, i.e., activity schemata, for generating solutions to problem instances in a class of tasks. Using Three-Valued Logic Analysis (TVLA), we extend our previous work to generate a set of conditions that determine the scope of applicability of an activity schema. The inferred scope is an abstract representation of a potentially unbounded set of problems, in the form of a 3-valued logical structure, which is used to test the applicability of the respective activity schema for solving different task problems. We validate this work on two classical planning domains and a simulated PR2 in Gazebo.",
        "primary_area": "",
        "author": "Vahid Mokhtari;Roman Manevich;Lu\u00eds Seabra Lopes;Armando J. Pinho;Vahid Mokhtari;Roman Manevich;Lu\u00eds Seabra Lopes;Armando J. Pinho",
        "authorids": "/37296982400;/37086309516;/38199212400;/37267862000;/37296982400;/37086309516;/38199212400;/37267862000",
        "aff": "IEETA \u2014 Instituto de Engenharia Electr\u00f3nica e Telem\u00e1tica de Aveiro, The University of Aveiro, Portugal; The University of Texas, Austin, USA; IEETA \u2014 Instituto de Engenharia Electr\u00f3nica e Telem\u00e1tica de Aveiro, The University of Aveiro, Portugal; IEETA \u2014 Instituto de Engenharia Electr\u00f3nica e Telem\u00e1tica de Aveiro, The University of Aveiro, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968013/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16996503476654043228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Aveiro;University of Texas at Austin",
        "aff_unique_dep": "Instituto de Engenharia Electr\u00f3nica e Telem\u00e1tica de Aveiro;",
        "aff_unique_url": "https://www.ua.pt;https://www.utexas.edu",
        "aff_unique_abbr": "UA;UT Austin",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Aveiro;Austin",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Portugal;United States"
    },
    {
        "id": "8967622",
        "title": "Learning to Augment Synthetic Images for Sim2Real Policy Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision and learning have made significant progress that could improve robotics policies for complex tasks and environments. Learning deep neural networks for image understanding, however, requires large amounts of domain-specific visual data. While collecting such data from real robots is possible, such an approach limits the scalability as learning policies typically requires thousands of trials. In this work we attempt to learn manipulation policies in simulated environments. Simulators enable scalability and provide access to the underlying world state during training. Policies learned in simulators, however, do not transfer well to real scenes given the domain gap between real and synthetic data. We follow recent work on domain randomization and augment synthetic images with sequences of random transformations. Our main contribution is to optimize the augmentation strategy for sim2real transfer and to enable domain-independent policy learning. We design an efficient search for depth image augmentations using object localization as a proxy task. Given the resulting sequence of random transformations, we use it to augment synthetic depth images during policy learning. Our augmentation strategy is policy-independent and enables policy learning with no real images. We demonstrate our approach to significantly improve accuracy on three manipulation tasks evaluated on a real robot.",
        "primary_area": "",
        "author": "Alexander Pashevich;Robin Strudel;Igor Kalevatykh;Ivan Laptev;Cordelia Schmid;Alexander Pashevich;Robin Strudel;Igor Kalevatykh;Ivan Laptev;Cordelia Schmid",
        "authorids": "/37087324837;/37087323370;/37086727020;/37270740700;/37282990700;/37087324837;/37087323370;/37086727020;/37270740700;/37282990700",
        "aff": "Inria, CNRS, Grenoble INP, LJK, University Grenoble Alpes, Grenoble, France; Inria, CNRS, Grenoble INP, LJK, University Grenoble Alpes, Grenoble, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, CNRS, Grenoble INP, LJK, University Grenoble Alpes, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967622/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5204485612361601681&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Grenoble;Paris",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967678",
        "title": "Learning to Estimate Centers of Mass of Arbitrary Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a reinforcement learning algorithm with robot manipulation to learn an arbitrary object's center of mass whose physical material composition is unknown. Robot learning is through manipulation of the object in a sequence of actions. The effectiveness of the algorithm is demonstrated in simulation to locate the centers of mass of rocks with complex shapes, with even or uneven mass distributions, and confirmed by vertically stacking the rocks along their learned centers of mass both in simulation and in real experiments.",
        "primary_area": "",
        "author": "Sean McGovern;Huitan Mao;Jing Xiao;Sean McGovern;Huitan Mao;Jing Xiao",
        "authorids": "/37087322510;/37086111530;/37278646600;/37087322510;/37086111530;/37278646600",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute; Department of Computer Science, University of North Carolina at Charlotte; Robotics Engineering Program, Worcester Polytechnic Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967678/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13050322255178432477&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Worcester Polytechnic Institute;University of North Carolina at Charlotte",
        "aff_unique_dep": "Robotics Engineering Program;Department of Computer Science",
        "aff_unique_url": "https://www.wpi.edu;https://www.uncc.edu",
        "aff_unique_abbr": "WPI;UNCC",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Worcester;Charlotte",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967961",
        "title": "Learning to Estimate Pose and Shape of Hand-Held Objects from RGB Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a system for modeling hand-object interactions in 3D from RGB images that show a hand which is holding a novel object from a known category. We design a Convolutional Neural Network (CNN) for Hand-held Object Pose and Shape estimation called HOPS-Net and utilize prior work to estimate the hand pose and configuration. We leverage the insight that information about the hand facilitates object pose and shape estimation by incorporating the hand into both training and inference of the object pose and shape as well as the refinement of the estimated pose. The network is trained on a large synthetic dataset of objects in interaction with a human hand. To bridge the gap between real and synthetic images, we employ an image-to-image translation model (Augmented CycleGAN) that generates realistically textured objects given a synthetic rendering. This provides a scalable way of generating annotated data for training HOPS-Net. Our quantitative experiments show that even noisy hand parameters significantly help object pose and shape estimation. The qualitative experiments show results of pose and shape estimation of objects held by a hand \u201cin the wild\u201d.",
        "primary_area": "",
        "author": "Mia Kokic;Danica Kragic;Jeannette Bohg;Mia Kokic;Danica Kragic;Jeannette Bohg",
        "authorids": "/37086292454;/37281296000;/37591153900;/37086292454;/37281296000;/37591153900",
        "aff": "Robotics, Perception, and Learning, EECS, KTH, Stockholm, Sweden; Robotics, Perception, and Learning, EECS, KTH, Stockholm, Sweden; Computer Science Department, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967961/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16482130658307408445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "KTH - Royal Institute of Technology;Stanford University",
        "aff_unique_dep": "EECS;Computer Science Department",
        "aff_unique_url": "https://www.kth.se;https://www.stanford.edu",
        "aff_unique_abbr": "KTH;Stanford",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Stockholm;Stanford",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "8968584",
        "title": "Learning to Explore in Motion and Interaction Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Model free reinforcement learning suffers from the high sampling complexity inherent to robotic manipulation or locomotion tasks. Most successful approaches typically use random sampling strategies which leads to slow policy convergence. In this paper we present a novel approach for efficient exploration that leverages previously learned tasks. We exploit the fact that the same system is used across many tasks and build a generative model for exploration based on data from previously solved tasks to improve learning new tasks. The approach also enables continuous learning of improved exploration strategies as novel tasks are learned. Extensive simulations on a robot manipulator performing a variety of motion and contact interaction tasks demonstrate the capabilities of the approach. In particular, our experiments suggest that the exploration strategy can more than double learning speed, especially when rewards are sparse. Moreover, the algorithm is robust to task variations and parameter tuning, making it beneficial for complex robotic problems.",
        "primary_area": "",
        "author": "Miroslav Bogdanovic;Ludovic Righetti;Miroslav Bogdanovic;Ludovic Righetti",
        "authorids": "/37086937369;/37295828600;/37086937369;/37295828600",
        "aff": "Movement Generation and Control group, Max-Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Movement Generation and Control group, Max-Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968584/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14098770490041263657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Max-Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Movement Generation and Control group",
        "aff_unique_url": "https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968510",
        "title": "Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Referring to objects in a natural and unambiguous manner is crucial for effective human-robot interaction. Previous research on learning-based referring expressions has focused primarily on comprehension tasks, while generating referring expressions is still mostly limited to rule-based methods. In this work, we propose a two-stage approach that relies on deep learning for estimating spatial relations to describe an object naturally and unambiguously with a referring expression. We compare our method to the state of the art algorithm in ambiguous environments (e.g., environments that include very similar objects with similar relationships). We show that our method generates referring expressions that people find to be more accurate (~30% better) and would prefer to use (~32% more often).",
        "primary_area": "",
        "author": "Fethiye Irmak Do\u011fan;Sinan Kalkan;Iolanda Leite;Fethiye Irmak Do\u011fan;Sinan Kalkan;Iolanda Leite",
        "authorids": "/37085796270;/37836992800;/38576988500;/37085796270;/37836992800;/38576988500",
        "aff": "Division of Robotics, Perception and Learning from the School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; KOVAN Research Lab, Middle East Technical University, Ankara, Turkey; Division of Robotics, Perception and Learning from the School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968510/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=214252119108780272&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Middle East Technical University",
        "aff_unique_dep": "Division of Robotics, Perception and Learning;KOVAN Research Lab",
        "aff_unique_url": "https://www.kth.se;https://www.metu.edu.tr",
        "aff_unique_abbr": "KTH;METU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stockholm;Ankara",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;T\u00fcrkiye"
    },
    {
        "id": "8967638",
        "title": "Learning to Grasp Arbitrary Household Objects from a Single Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Upon the advent of Industry 4.0, collaborative robotics and intelligent automation gain more and more traction for enterprises to improve their production processes. In order to adapt to this trend, new programming, learning and collaborative techniques are investigated. Program-bydemonstration is one of the techniques that aim to reduce the burden of manually programming collaborative robots. However, this is often limited to teaching to grasp at a certain position, rather than grasping a certain object. In this paper, we propose a method that learns to grasp an arbitrary object from visual input. While other learning-based approaches for robotic grasping require collecting a large dataset, manually or automatically labeled in a real or simulated world, our approach requires a single demonstration. We present results on grasping various objects with the Franka Panda collaborative robot after capturing a single image from a wrist mounted RGB camera. From this image we learn a robot controller with a convolutional neural network to adapt to changes in the object's position and rotation with less than 5 minutes of training time on a NVIDIA Titan X GPU, achieving over 90% grasp success rate.",
        "primary_area": "",
        "author": "Elias De Coninck;Tim Verbelen;Pieter Van Molle;Pieter Simoens;Bart Dhoedt IDLab;Elias De Coninck;Tim Verbelen;Pieter Van Molle;Pieter Simoens;Bart Dhoedt IDLab",
        "authorids": "/37087324774;/37072400100;/37087322526;/37605392800;/37087322764;/37087324774;/37072400100;/37087322526;/37605392800;/37087322764",
        "aff": "Department of Information Technology, Ghent University imec; Department of Information Technology, Ghent University imec; Department of Information Technology, Ghent University imec; Department of Information Technology, Ghent University imec; Department of Information Technology, Ghent University imec",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967638/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13673709574730064709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ghent University",
        "aff_unique_dep": "Department of Information Technology",
        "aff_unique_url": "https://www.ugent.be",
        "aff_unique_abbr": "UGent",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "8968496",
        "title": "Learning to Sequence Multiple Tasks with Competing Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning offers a general framework where robots can efficiently acquire novel motor skills from demonstrations of a human teacher. While many promising achievements have been shown, the majority of them are only focused on single-stroke movements, without taking into account the problem of multi-tasks sequencing. Conceivably, sequencing different atomic tasks can further augment the robot's capabilities as well as avoid repetitive demonstrations. In this paper, we propose to address the issue of multi-tasks sequencing with emphasis on handling the so-called competing constraints, which emerge due to the existence of the concurrent constraints from Cartesian and joint trajectories. Specifically, we explore the null space of the robot from an information-theoretic perspective in order to maintain imitation fidelity during transition between consecutive tasks. The effectiveness of the proposed method is validated through simulated and real experiments on the iCub humanoid robot.",
        "primary_area": "",
        "author": "Anqing Duan;Raffaello Camoriano;Diego Ferigo;Yanlong Huang;Daniele Calandriello;Lorenzo Rosasco;Daniele Pucci;Anqing Duan;Raffaello Camoriano;Diego Ferigo;Yanlong Huang;Daniele Calandriello;Lorenzo Rosasco;Daniele Pucci",
        "authorids": "/37086600788;/37085821685;/37086581742;/37086454561;/37086606342;/37869474900;/37706167200;/37086600788;/37085821685;/37086581742;/37086454561;/37086606342;/37869474900;/37706167200",
        "aff": "Dynamic Interaction Control Lab, Istituto Italiano di Tecnologia, Via San Quirico 19D, Genoa, Italy; Laboratory for Computational and Statistical Learning (IIT@MIT), Istituto Italiano di Tecnologia and Massachusetts Institute of Technology, Cambridge, MA, USA; Dynamic Interaction Control Lab, Istituto Italiano di Tecnologia, Via San Quirico 19D, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genova, Italy; Laboratory for Computational and Statistical Learning (IIT@MIT), Istituto Italiano di Tecnologia and Massachusetts Institute of Technology, Cambridge, MA, USA; DIBRIS, Universit\u00e0 degli Studi di Genova, Genoa, Italy; Dynamic Interaction Control Lab, Istituto Italiano di Tecnologia, Via San Quirico 19D, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968496/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8912665903243903947&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;2;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Massachusetts Institute of Technology;Universit\u00e0 degli Studi di Genova",
        "aff_unique_dep": "Dynamic Interaction Control Lab;Laboratory for Computational and Statistical Learning;DIBRIS",
        "aff_unique_url": "https://www.iit.it;https://www.mit.edu;https://www.unige.it",
        "aff_unique_abbr": "IIT;MIT;",
        "aff_campus_unique_index": "0;1;0;2;1;0;0",
        "aff_campus_unique": "Genoa;Cambridge;Genova",
        "aff_country_unique_index": "0;1;0;0;1;0;0",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "8967525",
        "title": "Learning-based Nonlinear Model Predictive Control of Reconfigurable Autonomous Robotic Boats: Roboats",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Learning-based Nonlinear Model Predictive Control (LB-NMPC) algorithm for reconfigurable autonomous vessels to facilitate high-accurate path tracking. Each vessel is designed to latch to a pre-defined point of another vessel that allows the vessels to form a rigid body. The number of possible configurations of such vessels exponentially grows as the total number of vessels increases, which imposes a technical challenge in modeling and identification. In this work, we propose a framework consisting of a real-time parameter estimator and a feedback control strategy, which is capable of ensuring high-accurate path tracking for any feasible configuration of vessels. Novelty of our method is in that the parameter is estimated on-line and adjusts control parameters (e.g., cost function and dynamic model) simultaneously to improve path-tracking performance. Through experiments on different configurations of connected-vessels, we demonstrate stability of our proposed approach and its effectiveness in high-accuracy in path tracking.",
        "primary_area": "",
        "author": "Erkan Kayacan;Shinkyu Park;Carlo Ratti;Daniela Rus;Erkan Kayacan;Shinkyu Park;Carlo Ratti;Daniela Rus",
        "authorids": "/38468023200;/37086183848;/37590016800;/37279652300;/38468023200;/37086183848;/37590016800;/37279652300",
        "aff": "School of Mechanical & Mining Engineering University of Queensland, Brisbane, Australia; Senseable City Laboratory (SCL), Massachusetts Institute of Technology, Cambridge, MA, USA; Senseable City Laboratory (SCL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science & Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967525/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9140134741696738499&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Queensland;Massachusetts Institute of Technology",
        "aff_unique_dep": "School of Mechanical & Mining Engineering;Senseable City Laboratory (SCL)",
        "aff_unique_url": "https://www.uq.edu.au;https://web.mit.edu",
        "aff_unique_abbr": "UQ;MIT",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Brisbane;Cambridge",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "8967860",
        "title": "LiDAR Based Navigable Region Detection for Unmanned Surface Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Detection of the navigable regions for the unmanned surface vehicles (USVs) sailing on the narrow rivers is very important. Existing detection methods mostly depend on the cameras, which is sensitive to environments and cannot provide reliable navigable regions for sailing. In this paper, we propose a scheme to process 3D LiDAR data to achieve an accurate and robust navigable regions detection. We conduct field experiments in a narrow river in different scenarios to prove the performance of the proposed scheme, which reaches on average 93.8% precision and 92.7% recall.",
        "primary_area": "",
        "author": "Xiangtong Yao;Yunxiao Shan;Jieling Li;Donghui Ma;Kai Huang;Xiangtong Yao;Yunxiao Shan;Jieling Li;Donghui Ma;Kai Huang",
        "authorids": "/37086962477;/37086488957;/37087325050;/37087325327;/37534912900;/37086962477;/37086488957;/37087325050;/37087325327;/37534912900",
        "aff": "Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967860/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6380392886362787598&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Data and Computer Science",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967739",
        "title": "LiDAR-Flow: Dense Scene Flow Estimation from Sparse LiDAR and Stereo Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new approach called LiDAR-Flow to robustly estimate a dense scene flow by fusing a sparse LiDAR with stereo images. We take the advantage of the high accuracy of LiDAR to resolve the lack of information in some regions of stereo images due to textureless objects, shadows, ill-conditioned light environment and many more. Additionally, this fusion can overcome the difficulty of matching unstructured 3D points between LiDAR-only scans. Our LiDAR-Flow approach consists of three main steps; each of them exploits LiDAR measurements. First, we build strong seeds from LiDAR to enhance the robustness of matches between stereo images. The imagery part seeks the motion matches and increases the density of scene flow estimation. Then, a consistency check employs LiDAR seeds to remove the possible mismatches. Finally, LiDAR measurements constraint the edge-preserving interpolation method to fill the remaining gaps. In our evaluation we investigate the individual processing steps of our LiDAR-Flow approach and demonstrate the superior performance compared to image-only approach.",
        "primary_area": "",
        "author": "Ramy Battrawy;Ren\u00e9 Schuster;Oliver Wasenm\u00fcller;Qing Rao;Didier Stricker;Ramy Battrawy;Ren\u00e9 Schuster;Oliver Wasenm\u00fcller;Qing Rao;Didier Stricker",
        "authorids": "/37086784293;/37086375640;/37085789724;/37085391745;/37326112700;/37086784293;/37086375640;/37085789724;/37085391745;/37326112700",
        "aff": "DFKI \u2013 German Research Center for Artificial Intelligence, Germany; DFKI \u2013 German Research Center for Artificial Intelligence, Germany; DFKI \u2013 German Research Center for Artificial Intelligence, Germany; BMW Group, Germany; DFKI \u2013 German Research Center for Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967739/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1435401617852787901&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence;BMW Group",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.dFKI.de;https://www.bmwgroup.com",
        "aff_unique_abbr": "DFKI;BMW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967908",
        "title": "Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper was motivated by the problem of how to make robots fuse and transfer their experience so that they can effectively use prior knowledge and quickly adapt to new environments. To address the problem, we present a learning architecture for navigation in cloud robotic systems: Lifelong Federated Reinforcement Learning (LFRL). In the work, we propose a knowledge fusion algorithm for upgrading a shared model deployed on the cloud. Then, effective transfer learning methods in LFRL are introduced. LFRL is consistent with human cognitive science and fits well in cloud robotic systems. Experiments show that LFRL greatly improves the efficiency of reinforcement learning for robot navigation. The cloud robotic system deployment also shows that LFRL is capable of fusing prior knowledge. In addition, we release a cloud robotic navigation-learning website to provide the service based on LFRL: www.shared-robotics.com.",
        "primary_area": "",
        "author": "Boyi Liu;Lujia Wang;Ming Liu;Boyi Liu;Lujia Wang;Ming Liu",
        "authorids": "/37087061487;/37406752700;/37085398677;/37087061487;/37406752700;/37085398677",
        "aff": "Cloud Computing Lab of Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Cloud Computing Lab of Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Department of ECE, Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967908/",
        "gs_citation": 325,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11322300838263933402&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Shenzhen Institute of Advanced Technology;Hong Kong University of Science and Technology",
        "aff_unique_dep": "Cloud Computing Lab;Department of ECE",
        "aff_unique_url": "http://www.siat.ac.cn;https://www.ust.hk",
        "aff_unique_abbr": ";HKUST",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968444",
        "title": "Line-based Absolute and Relative Camera Pose Estimation in Structured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "3D lines in structured environments encode particular regularity like parallelism and orthogonality. We leverage this structural regularity to estimate the absolute and relative camera poses. We decouple the rotation and translation, and propose a novel rotation estimation method. We decompose the absolute and relative rotations and reformulate the problem as computing the rotation from the Manhattan frame to the camera frame. To compute this rotation, we propose an accurate and efficient two-step method. We first estimate its two degrees of freedom (DOF) by two image lines, and then estimate its third DOF by another image line. For these lines, we assume their associated 3D lines are mutually orthogonal, or two 3D lines are parallel to each other and orthogonal to the third. Thanks to our two-step DOF estimation, our absolute and relative pose estimation methods are accurate and efficient. Moreover, our relative pose estimation method relies on weaker assumptions or less correspondences than existing approaches. We also propose a novel strategy to reject outliers and identify dominant directions of the scene. We integrate it into our pose estimation methods, and show that it is more robust than RANSAC. Experiments on synthetic and real-world datasets demonstrated that our methods outperform state-of-the-art approaches.",
        "primary_area": "",
        "author": "Haoang Li;Ji Zhao;Jean-Charles Bazin;Wen Chen;Kai Chen;Yun-Hui Liu;Haoang Li;Ji Zhao;Jean-Charles Bazin;Wen Chen;Kai Chen;Yun-Hui Liu",
        "authorids": "/37086937885;/37963498600;/37395207000;/37087239966;/37089268250;/37279412600;/37086937885;/37963498600;/37395207000;/37087239966;/37089268250;/37279412600",
        "aff": "T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; TuSimple, Beijing, China; KAIST, Daejeon, South Korea; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Wuhan University, Wuhan, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968444/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12396437022063195283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "Chinese University of Hong Kong;TuSimple;Korea Advanced Institute of Science and Technology;Wuhan University",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;;;",
        "aff_unique_url": "https://www.cuhk.edu.hk;;https://www.kaist.ac.kr;http://www.whu.edu.cn/",
        "aff_unique_abbr": "CUHK;;KAIST;WHU",
        "aff_campus_unique_index": "0;1;2;0;3;0",
        "aff_campus_unique": "Hong Kong;Beijing;Daejeon;Wuhan",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "8967791",
        "title": "Local Online Motor Babbling: Learning Motor Abundance of a Musculoskeletal Robot Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Motor babbling and goal babbling has been used for sensorimotor learning of highly redundant systems in soft robotics. Recent works in goal babbling have demonstrated successful learning of inverse kinematics (IK) on such systems, and suggest that babbling in the goal space better resolves motor redundancy by learning as few yet efficient sensorimotor mappings as possible. However, for musculoskeletal robot systems, motor redundancy can provide useful information to explain muscle activation patterns, thus the term motor abundance. In this work, we introduce some simple heuristics to empirically define the unknown goal space, and learn the IK of a 10 DoF musculoskeletal robot arm using directed goal babbling. We then further propose local online motor babbling guided by Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which bootstraps on the goal babbling samples for initialization, such that motor abundance can be queried online for any static goal. Our approach leverages the resolving of redundancies and the efficient guided exploration of motor abundance in two stages of learning, allowing both kinematic accuracy and motor variability at the queried goal. The result shows that local online motor babbling guided by CMA-ES can efficiently explore motor abundance at queried goal positions on a musculoskeletal robot system and gives useful insights in terms of muscle stiffness and synergy.",
        "primary_area": "",
        "author": "Zinan Liu;Arne Hitzmann;Shuhei Ikemoto;Svenja Stark;Jan Peters;Koh Hosoda;Zinan Liu;Arne Hitzmann;Shuhei Ikemoto;Svenja Stark;Jan Peters;Koh Hosoda",
        "authorids": "/37087324340;/37087100760;/37659393100;/37086308508;/37533077600;/37270101900;/37087324340;/37087100760;/37659393100;/37086308508;/37533077600;/37270101900",
        "aff": "Department of Computer Science, TU Darmstadt, Hochschulstr, Darmstadt, Germany; School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology 2-4 Hibikino, Wakamatsu-ku, Kitakyushu, Japan; Department of Computer Science, TU Darmstadt, Hochschulstr, Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Hochschulstr, Darmstadt, Germany; School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967791/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13159692898936779456&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;1",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Osaka University;Kyushu Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;School of Engineering Science;Graduate School of Life Science and Systems Engineering",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.osaka-u.ac.jp;https://www.kyutech.ac.jp",
        "aff_unique_abbr": "TU Darmstadt;Osaka U;Kyutech",
        "aff_campus_unique_index": "0;1;2;0;0;1",
        "aff_campus_unique": "Darmstadt;Toyonaka;Kitakyushu",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "8968524",
        "title": "Local Pose optimization with an Attention-based Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel pose optimizer which can be inserted into either supervised or unsupervised end-to-end visual odometry for the purpose of local pose optimization. The pose optimizer is an analogue of the pose graph optimization used in traditional VSLAM algorithms. Local pose optimization is performed by an attention-based neural network which iteratively refines the predicted pose estimates of an image snippet. Instead of complicated graph convolutional network, the attention mechanism based on geometric consistency of trajectory constraint is utilized because pose features whose spatial distribution is not important can be flattened to vectors and then processed. The pose optimizer is aimed at improving pose estimation accuracy by redistributing errors of pose estimates. Quantitative and qualitative evaluation of the proposed approach on the KITTI Odometry dataset [1] is presented to demonstrate its effectiveness in improving pose estimation accuracy and minimizing pose drift.",
        "primary_area": "",
        "author": "Yiling Liu;Hesheng Wang;Fan Xu;Yong Wang;Weidong Chen;Qirong Tang;Yiling Liu;Hesheng Wang;Fan Xu;Yong Wang;Weidong Chen;Qirong Tang",
        "authorids": "/37086938082;/37292567100;/37086550869;/37090020060;/37279187800;/37089442737;/37086938082;/37292567100;/37086550869;/37090020060;/37279187800;/37089442737",
        "aff": "Department of Automation, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Robotics and System (HIT); Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Beijing Institute of Control Engineering; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Tongii University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968524/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10198053210139039490&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;3",
        "aff_unique_norm": "Shanghai Jiao Tong University;Harbin Institute of Technology;Beijing Institute of Control Engineering;Tongji University",
        "aff_unique_dep": "Department of Automation;State Key Laboratory of Robotics and System;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.hit.edu.cn/;http://www.bice.org.cn;https://www.tongji.edu.cn",
        "aff_unique_abbr": "SJTU;HIT;;Tongji",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967662",
        "title": "Localization and Mapping using Instance-specific Mesh Models",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on building semantic maps, containing object poses and shapes, using a monocular camera. This is an important problem because robots need rich understanding of geometry and context if they are to shape the future of transportation, construction, and agriculture. Our contribution is an instance-specific mesh model of object shape that can be optimized online based on semantic information extracted from camera images. Multi-view constraints on the object shape are obtained by detecting objects and extracting category-specific keypoints and segmentation masks. We show that the errors between projections of the mesh model and the observed keypoints and masks can be differentiated in order to obtain accurate instance-specific object shapes. We evaluate the performance of the proposed approach in simulation and on the KITTI dataset by building maps of car poses and shapes.",
        "primary_area": "",
        "author": "Qiaojun Feng;Yue Meng;Mo Shan;Nikolay Atanasov;Qiaojun Feng;Yue Meng;Mo Shan;Nikolay Atanasov",
        "authorids": "/37087322298;/37087232404;/37087321802;/37670511000;/37087322298;/37087232404;/37087321802;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967662/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2666672815865599728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968004",
        "title": "Long Range Neural Navigation Policies for the Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "Learned Neural Network based policies have shown promising results for robot navigation. However, most of these approaches fall short of being used on a real robot due to the extensive simulated training they require. These simulations lack the visuals and dynamics of the real world, which makes it infeasible to deploy on a real robot. We present a novel Neural Net based policy, NavNet, which allows for easy deployment on a real robot. It consists of two sub policies - a high level policy which can understand real images and perform long range planning expressed in high level commands; a low level policy that can translate the long range plan into low level commands on a specific platform in a safe and robust manner. For every new deployment, the high level policy is trained on an easily obtainable scan of the environment modeling its visuals and layout. We detail the design of such an environment and how one can use it for training a final navigation policy. Further, we demonstrate a learned low-level policy. We deploy the model in a large office building and test it extensively, achieving 0.80 success rate over long navigation runs and outperforming SLAM-based models in the same settings.",
        "primary_area": "",
        "author": "Ayzaan Wahid;Alexander Toshev;Marek Fiser;Tsang-Wei Edward Lee;Ayzaan Wahid;Alexander Toshev;Marek Fiser;Tsang-Wei Edward Lee",
        "authorids": "/37086937669;/37300077100;/37086043135;/37087324251;/37086937669;/37300077100;/37086043135;/37087324251",
        "aff": "Google AI, 1600 Amphitheatre Pkwy, Mountain View, CA, USA; Google AI, 1600 Amphitheatre Pkwy, Mountain View, CA, USA; Google AI, 1600 Amphitheatre Pkwy, Mountain View, CA, USA; Google AI, 1600 Amphitheatre Pkwy, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968004/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8759155858325475130&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google AI",
        "aff_unique_url": "https://ai.google",
        "aff_unique_abbr": "Google AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968017",
        "title": "Long-Term Visual Inertial SLAM based on Time Series Map Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advance in the field of mobile robots, autonomous robots are required for long-term deployment in dynamic and complex environments. However, the performance of Visual Inertial SLAM systems in long-term operation is not satisfactory, and most long-term SLAM systems assumes periodic changes in the environment. This paper presents a novel solution for long-term monocular VI SLAM system in dynamic environment based on autoregression(AR) modeling and map prediction. Map points are first classified into static and semi-static map points according to a memory model. Modeling and prediction of the different states of semi-static map points are performed that are derived from time series models. The predicted map is then fused with the current map to achieve a better forecast for the next frame if the prediction is not satisfactory enough. Experiments are carried out on an embedded system. The results indicate that the map prediction is reliable and the proposed approach improves the performance of long-term localization and mapping in dynamic environments.",
        "primary_area": "",
        "author": "Bowen Song;Weidong Chen;Jingchuan Wang;Hesheng Wang;Bowen Song;Weidong Chen;Jingchuan Wang;Hesheng Wang",
        "authorids": "/37086509273;/37279187800;/37539010600;/37292567100;/37086509273;/37279187800;/37539010600;/37292567100",
        "aff": "Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968017/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=564297318628555602&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968125",
        "title": "Long-term Prediction of Motion Trajectories Using Path Homology Clusters",
        "track": "main",
        "status": "Poster",
        "abstract": "In order for robots to share their workspace with people, they need to reason about human motion efficiently. In this work we leverage large datasets of paths in order to infer local models that are able to perform long-term predictions of human motion. Further, since our method is based on simple dynamics, it is conceptually simple to understand and allows one to interpret the predictions produced, as well as to extract a cost function that can be used for planning. The main difference between our method and similar systems, is that we employ a map of the space and translate the motion of groups of paths into vector fields on that map. We test our method on synthetic data and show its performance on the Edinburgh forum pedestrian long-term tracking dataset [1] where we were able to outperform a Gaussian Mixture Model tasked with extracting dynamics from the paths.",
        "primary_area": "",
        "author": "J. Frederico Carvalho;Mikael Vejdemo-Johansson;Florian T. Pokorny;Danica Kragic;J. Frederico Carvalho;Mikael Vejdemo-Johansson;Florian T. Pokorny;Danica Kragic",
        "authorids": "/37087323294;/38362453600;/37077268000;/37281296000;/37087323294;/38362453600;/37077268000;/37281296000",
        "aff": "CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden; Mathematics Department, CUNY College of Staten Island, New York, USA; CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden; CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968125/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4554857081634958614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Royal Institute of Technology;CUNY College of Staten Island",
        "aff_unique_dep": "CAS/RPL;Mathematics Department",
        "aff_unique_url": "https://www.kth.se;https://www.csi.cuny.edu",
        "aff_unique_abbr": "KTH;CSI",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Stocholm;Staten Island",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "8967823",
        "title": "Look Further to Recognize Better: Learning Shared Topics and Category-Specific Dictionaries for Open-Ended 3D Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots are expected to operate effectively in human-centric environments for long periods of time. In such realistic scenarios, fine-grained object categorization is as important as basic-level object categorization. We tackle this problem by proposing an open-ended object recognition approach which concurrently learns both the object categories and the local features for encoding objects. In this work, each object is represented using a set of general latent visual topics and category-specific dictionaries. The general topics encode the common patterns of all categories, while the category-specific dictionary describes the content of each category in details. The proposed approach discovers both sets of general and specific representations in an unsupervised fashion and updates them incrementally using new object views. Experimental results show that our approach yields significant improvements over the previous state-of-the-art approaches concerning scalability and object classification performance. Moreover, our approach demonstrates the capability of learning from very few training examples in a real-world setting. Regarding computation time, the best result was obtained with a Bag-of-Words method followed by a variant of the Latent Dirichlet Allocation approach.",
        "primary_area": "",
        "author": "S. Hamidreza Kasaei;S. Hamidreza Kasaei",
        "authorids": "/38014883700;/38014883700",
        "aff": "Department of Artificial Intelligence, University of Groningen, Groningen, AK, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967823/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11009234290056567105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Groningen",
        "aff_unique_dep": "Department of Artificial Intelligence",
        "aff_unique_url": "https://www.rug.nl",
        "aff_unique_abbr": "RUG",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Groningen",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "8967877",
        "title": "Low-cost Sonar Navigation System",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a sonar-based navigation system, designed to deploy a fleet of autonomous mobile platforms at a reasonable cost. In educational and hobbyist contexts, a large number of robots is required. By means of classical navigation approaches, every robot should be provided with accurate vision or range sensors. This limits the maximum number of robots in the fleet, due to the unaffordable cost of these sensors. In contrast to that, our system requires a single platform equipped with a higher quality sensor, used to perform calibration and mapping tasks. The rest of the fleet, able to localize and navigate, is equipped solely with low-cost sonars, providing a notable reduction in the overall cost. We achieve this task by presenting a novel calibration procedure to estimate the sonars extrinsic and adapting a classical monte-carlo localization algorithm to the sonar model, focusing on efficiency. We release an open source implementation of the system to the community.",
        "primary_area": "",
        "author": "Tiziano Guadagnino;Bartolomeo Della Corte;Giorgio Grisetti;Tiziano Guadagnino;Bartolomeo Della Corte;Giorgio Grisetti",
        "authorids": "/37087324270;/37085797612;/37324134600;/37087324270;/37085797612;/37324134600",
        "aff": "Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy; Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy; Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967877/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18034872473041997617&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sapienza University of Rome",
        "aff_unique_dep": "Department of Computer, Control, and Management Engineering",
        "aff_unique_url": "https://www.sapienza.uniroma.it",
        "aff_unique_abbr": "Sapienza",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rome",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968188",
        "title": "MPERL: Hardware and Software Co-design for Robotic Manipulators \u00a9",
        "track": "main",
        "status": "Poster",
        "abstract": "Building small custom robots is getting democratized thanks to affordable tools like 3D printers and micro controllers. However, it still requires expertise from a wide range of domains: from designing the mechanical parts to writing the code that controls the robot. We present MPERL, a tool to help non-experts build custom robotic manipulators. MPERL starts from an abstract description of the robot's kinematic structure which contains information about joints, actuators, and sensors. The structure is refined with an easily manufactured geometry. Furthermore, from the structure MPERL generates control code which can be used to move the robot to a target configuration. We evaluate MPERL on a range of common robotic manipulator architectures, both serial and parallel.",
        "primary_area": "",
        "author": "Marcus Pirron;Damien Zufferey;Marcus Pirron;Damien Zufferey",
        "authorids": "/37087322847;/37545905700;/37087322847;/37545905700",
        "aff": "Institute for Software Systems, Kaiserslautern, Germany; Institute for Software Systems, Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968188/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15982448924722110531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Institute for Software Systems",
        "aff_unique_dep": "Software Systems",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kaiserslautern",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967819",
        "title": "MRLift: a Semi-active Lower Back Support Exoskeleton based on MR Fluid and Force Retention Technology",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robots suffer from issues of usability, cost-performance, and battery life. These drawbacks hinder the development of their market and their implementation in healthcare and industry. Back support exoskeletons in particular rely heavily on mechanical storing of energy but are still mostly using traditional mechanical elements and actuators to achieve the task. The core technology of our work, named MRLink, uses a smart fluid in combination with a compression spring to produce a unique energy store-and-release functionality. With only 5 Watts MRLink can produce over 500N of braking force. The braking force, variable viscosity, can be continuously controlled through the supply current. With appropriate selection of the spring and control method, the required assist energy can be acquired from body weight and movement dynamics, stored momentarily and, released at the appropriate timing to assist the body motion. The MRLink does not require an external power source like pneumatic actuators, does not require gearboxes and large batteries like DC motors, and comes in a compact package. Thus, this technology has the potential to significantly contribute to wearable exoskeletons in general, and back support exoskeletons in particular. In this work we present the development of a back support exoskeleton prototype based on MRLink, we describe its functional details, and a pilot test partially verifying the proposed functions.",
        "primary_area": "",
        "author": "Modar Hassan;Maxwell Kennard;Keisuke Yagi;Hideki Kadone;Hiromi Mochiyama;Kenji Suzuki;Modar Hassan;Maxwell Kennard;Keisuke Yagi;Hideki Kadone;Hiromi Mochiyama;Kenji Suzuki",
        "authorids": "/38541427800;/37087324730;/37086020184;/37295550300;/37295991600;/37334425200;/38541427800;/37087324730;/37086020184;/37295550300;/37295991600;/37334425200",
        "aff": "Faculty of Systems, Information and Engineering, University of Tsukuba, Tsukuba, Japan; School of Integrative and Global Majors, University of Tsukuba, Tsukuba, Japan; Graduate School of Science and Engineering (Engineering), Ibaraki University, Hitachi, Japan; Center for Innovative Medicine and Engineering, University of Tsukuba Hospital, Japan; Faculty of Systems, Information and Engineering, University of Tsukuba, Tsukuba, Japan; Faculty of Systems, Information and Engineering, University of Tsukuba, Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967819/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17977065841837602740&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "University of Tsukuba;Ibaraki University;University of Tsukuba Hospital",
        "aff_unique_dep": "Faculty of Systems, Information and Engineering;Graduate School of Science and Engineering (Engineering);Center for Innovative Medicine and Engineering",
        "aff_unique_url": "https://www.tsukuba.ac.jp;https://www.ibaraki.ac.jp;",
        "aff_unique_abbr": ";Ibaraki U;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Tsukuba;Hitachi;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967578",
        "title": "MT-RRT: a general purpose multithreading library for path planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Rapidly Random exploring Trees are popular algorithms in the field of motion planning. A feasible path connecting two different poses is found by incrementally building a tree data structure. They are powerful and flexible, but also computationally intense, requiring thousands of iterations before their termination. The aim of this article is to show the capabilities of MT-RRT, a general purpose library which exploits four different multithreading strategies to speed up the planning process of Rapidly Random exploring Trees. MT-RRT will be proved to significantly reduce the computation time on various benchmarks.",
        "primary_area": "",
        "author": "Andrea Casalino;Andrea Maria Zanchettin;Paolo Rocco;Andrea Casalino;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086208346;/37546427600;/37274178600;/37086208346;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza L. Da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza L. Da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza L. Da Vinci 32, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967578/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5093920022940662295&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968219",
        "title": "Macro-Micro Multi-Arm Robot for Single-Port Access Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimally invasive surgery is now a well established field in surgery but continuous efforts are made to reduce invasiveness even further. This paper proposes a novel concept of small-diameter multi-arm robot for SinglePort Access Surgery. The concept introduces a combination of backbone and actuation principles in a macro-micro fashion to achieve an excellent decoupling of the triangulation platform (macro) and of the end-effectors (micro). Concentric tube robots are used for the triangulation platform, while compliant fluidic-actuated bending segments are used as end-effectors. The fluidic actuation is advantageous as it minimally interferes with the triangulation platform. The triangulation platform on the other hand provides a stable base for the end-effectors such that large distal actuation bandwidth can be achieved. A specific embodiment for Spina Bifida repair is developed and proposed. The surgical and technical requirements as well as the mechanical design are presented in details. A first prototype is built and characterization experiments are conducted to evaluate its performance.",
        "primary_area": "",
        "author": "T. Vandebroek;M. Ourak;C. Gruijthuijsen;A. Javaux;J. Legrand;T. Vercauteren;S. Ourselin;J. Deprest;E.Vander Poorten;T. Vandebroek;M. Ourak;C. Gruijthuijsen;A. Javaux;J. Legrand;T. Vercauteren;S. Ourselin;J. Deprest;E.Vander Poorten",
        "authorids": "/37087323972;/37085733198;/37085707344;/37086291002;/37086448266;/37283803200;/37293902000;/37085704530;/37293929100;/37087323972;/37085733198;/37085707344;/37086291002;/37086448266;/37283803200;/37293902000;/37085704530;/37293929100",
        "aff": "Faculty of Mechanical Engineering, Catholic University of Leuven; Faculty of Mechanical Engineering, Catholic University of Leuven; Faculty of Mechanical Engineering, Catholic University of Leuven; Faculty of Mechanical Engineering, Catholic University of Leuven; Faculty of Mechanical Engineering, Catholic University of Leuven; School of Biomedical Engineering and Imaging Sciences, King\u2019s College, London; School of Biomedical Engineering and Imaging Sciences, King\u2019s College, London; University Hospital Leuven; Faculty of Mechanical Engineering, Catholic University of Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968219/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8168925080867807934&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;1;2;0",
        "aff_unique_norm": "Catholic University of Leuven;King\u2019s College London;University Hospital Leuven",
        "aff_unique_dep": "Faculty of Mechanical Engineering;School of Biomedical Engineering and Imaging Sciences;",
        "aff_unique_url": "https://www.kuleuven.be;https://www.kcl.ac.uk;https://www.uhl.be",
        "aff_unique_abbr": "KU Leuven;KCL;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;0;1;1;0;0",
        "aff_country_unique": "Belgium;United Kingdom"
    },
    {
        "id": "8968001",
        "title": "Magnetic Needle Steering Model Identification Using Expectation-Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Brain Stimulation is used to treat Parkinson's disease and other neurological disorders by implanting an electrode into the brain via a straight-path needle insertion. Enabling course correction and curved trajectories by using a steerable needle has the potential to improve operative outcomes. In this work, a physically motivated dynamic model for an actively steered magnetic-tipped needle is derived. Process and measurement noise covariances and model parameter curvature gain are identified using an expectation-maximization (EM) algorithm. Parameter convergence and accuracy are evaluated, and an RMS position trajectory accuracy of 0. 81 mm is calculated for expected conditions. The EM algorithm converged for expected parameter variations in simulation, which supports the EM implementation's use in identifying the parameters of the model in a physical system.",
        "primary_area": "",
        "author": "Richard L. Pratt;Andrew J. Petruska;Richard L. Pratt;Andrew J. Petruska",
        "authorids": "/37087324511;/38230617900;/37087324511;/38230617900",
        "aff": "Mechanical Engineering, Colorado School of Mines, 1500 Illinois St, Golden, Colorado; Mechanical Engineering, Colorado School of Mines, 1500 Illinois St, Golden, Colorado",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968001/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3747951538127759580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Mechanical Engineering",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967848",
        "title": "Magnetic-Needle-Assisted Micromanipulation of Dynamically Self-Assembled Magnetic Droplets for Cargo Transportation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic self-assembly is treated as a promising approach for generating a robotic swarm to perform coordinated tasks, and the assembled pattern can be tuned by regulating the energy input. However, location of a dynamically assembled pattern is hard to be determined, especially under global fields, such as magnetic field. In this paper, we report the formation and manipulation of dynamic self-assembled droplets at the air-liquid interface with the assistance of a magnetic needle. Affected by the locally induced field gradient near the needle, reconfigurable assembled droplets are obtained with higher time-efficiency, and the location of the pattern can be determined. The pattern is reversibly tuned to exhibit expansion and shrinkage by adjusting the height of the needle. Assembled droplets are able to be steered via following the needle in a controlled manner. Moreover, cargo is trapped by exploiting the induced rotational flow around the droplets, and it can also be caged into the central area of the pattern and transported to the desired location. The proposed method opens new prospects of using energy-dissipative pattern as an untethered end-effector for microrobotic manipulation.",
        "primary_area": "",
        "author": "Qianqian Wang;Xingzhou Du;Fengtong Ji;Li Zhang;Qianqian Wang;Xingzhou Du;Fengtong Ji;Li Zhang",
        "authorids": "/37086080420;/37086593722;/37087325332;/37085379138;/37086080420;/37086593722;/37087325332;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967848/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6101864070637389224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shatin NT",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968303",
        "title": "Making Sense of Audio Vibration for Liquid Height Estimation in Robotic Pouring",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the challenging perception problem in robotic pouring. Most of the existing approaches either leverage visual or haptic information. However, these techniques may suffer from poor generalization performances on opaque containers or concerning measuring precision. To tackle these drawbacks, we propose to make use of audio vibration sensing and design a deep neural network PouringNet to predict the liquid height from the audio fragment during the robotic pouring task. PouringNet is trained on our collected real-world pouring dataset with multimodal sensing data, which contains more than 3000 recordings of audio, force feedback, video and trajectory data of the human hand that performs the pouring task. Each record represents a complete pouring procedure. We conduct several evaluations on PouringNet with our dataset and robotic hardware. The results demonstrate that our PouringNet generalizes well across different liquid containers, positions of the audio receiver, initial liquid heights and types of liquid, and facilitates a more robust and accurate audio-based perception for robotic pouring.",
        "primary_area": "",
        "author": "Hongzhuo Liang;Shuang Li;Xiaojian Ma;Norman Hendrich;Timo Gerkmann;Fuchun Sun;Jianwei Zhang;Hongzhuo Liang;Shuang Li;Xiaojian Ma;Norman Hendrich;Timo Gerkmann;Fuchun Sun;Jianwei Zhang",
        "authorids": "/37086700920;/37086938152;/37086936937;/37449613700;/37646480900;/37279269000;/37281460600;/37086700920;/37086938152;/37086936937;/37449613700;/37646480900;/37279269000;/37281460600",
        "aff": "TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Center for Vision, Cognition, Learning, and Autonomy, University of California, Los Angeles; TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; SP (Signal Processing), Universit\u00e4t Hamburg; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968303/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5949027326455733712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;2;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;University of California, Los Angeles;Tsinghua University",
        "aff_unique_dep": "TAMS (Technical Aspects of Multimodal Systems);Center for Vision, Cognition, Learning, and Autonomy;State Key Lab on Intelligent Technology and Systems",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.ucla.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";UCLA;Tsinghua",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Los Angeles;Beijing",
        "aff_country_unique_index": "0;0;1;0;0;2;0",
        "aff_country_unique": "Germany;United States;China"
    },
    {
        "id": "8967754",
        "title": "Manipulation Motion Taxonomy and Coding for Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a taxonomy of manipulations as seen especially in cooking for 1) grouping manipulations from the robotics point of view, 2) consolidating aliases and removing ambiguity for motion types, and 3) provide a path to transferring learned manipulations to new unlearned manipulations. Using instructional videos as a reference, we selected a list of common manipulation motions seen in cooking activities grouped into similar motions based on several trajectory and contact attributes. Manipulation codes are then developed based on the taxonomy attributes to represent the manipulation motions. The manipulation taxonomy is then used for comparing motion data in the Daily Interactive Manipulation (DIM) data set to reveal their motion similarities.",
        "primary_area": "",
        "author": "David Paulius;Yongqiang Huang;Jason Meloncon;Yu Sun;David Paulius;Yongqiang Huang;Jason Meloncon;Yu Sun",
        "authorids": "/37086208693;/37085721329;/37087321720;/37291603500;/37086208693;/37085721329;/37087321720;/37291603500",
        "aff": "Robot Perception and Action Lab (RPAL), University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL), University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL), University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL), University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967754/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17779238487700837110&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Robot Perception and Action Lab (RPAL)",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967625",
        "title": "Manipulation Purpose Underwater Agent Vehicle for Ghost Net Recovery Mission",
        "track": "main",
        "status": "Poster",
        "abstract": "We designed a manipulation purpose small agent vehicle and performed a ghost net recovery mission with the vehicle to test its control accuracy and capacity to be used in other tasks. We constructed a control model that allows the vehicle to perform the complex motion of 4-degrees-of-freedom (DOF) movements and underwater manipulation. Also, we implemented a ghost net recovery algorithm that can automatically detect, grip, and lift ghost nets. The test results show stable yaw, depth, and position control capabilities, and the manipulation performance was verified by automatically performing a ghost net recovery mission.",
        "primary_area": "",
        "author": "Juhwan Kim;Taesik Kim;Jason Kim;Son-Cheol Yu;Taesik Kim;Juhwan Kim;Taesik Kim;Jason Kim;Son-Cheol Yu;Taesik Kim",
        "authorids": "/37085645943;/37089603127;/37086550821;/37422355300;/37086851623;/37085645943;/37089603127;/37086550821;/37422355300;/37086851623",
        "aff": "Department of Creative IT Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, South Korea; Department of Creative IT Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, South Korea; Department of Creative IT Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, South Korea; Department of Creative IT Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, South Korea; Department of Creative IT Engineering, Pohang University of Science and Technology, Pohang, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967625/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16550631464956481446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Creative IT Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967742",
        "title": "Map Based Human Motion Prediction for People Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile service robots deployed in populated environments like train stations, airports or offices are not only required to move safely, but also in socially acceptable ways. In order to achieve this, robots need to be able to track people within their vicinity. This work presents an approach to tracking people from a mobile robot platform, incorporating a novel approach to human motion prediction. Unfavorable viewing angles, motion blur and ever-changing light conditions are constant issues for sensors on mobile vehicles. Therefore, a system is needed which increases the tracking quality of humans in order to cope with a low detection rate. The scientific contribution of this paper lies in a precise human model for tracking which utilizes historical spatial data of pedestrians from previous detection and from simulation. The model is embedded into a particle-filter based tracking approach designed for the use on a moving platform and is able to incorporate a variety of person detectors. Experiments conducted prove that the proposed method increases tracking quality, especially at a low detection rate.",
        "primary_area": "",
        "author": "Florian Beck;Markus Bader;Florian Beck;Markus Bader",
        "authorids": "/37085393727;/37297505900;/37085393727;/37297505900",
        "aff": "The Automation and Control Institute, Vienna University of Technology, Vienna, Austria; The Institute of Computer Engineering, Vienna University of Technology, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967742/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7529471274624859419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vienna University of Technology",
        "aff_unique_dep": "Automation and Control Institute",
        "aff_unique_url": "https://www.tuwien.ac.at",
        "aff_unique_abbr": "TU Wien",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "8968466",
        "title": "Map-Aware SLAM with Sparse Map Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is a key capability for autonomous vehicles. High-Definition maps are a popular method to represent the environment and to enable precise localization. However, the creation is very demanding and it is not always guaranteed to receive accurate map information, especially for unstructured areas. In this paper, we introduce a novel probabilistic localization and mapping framework that brings together the advantages of sparse feature maps, multi-target tracking for landmark detection, probabilistic global vehicle localization and a graph-based formulation to achieve a consistent map. The front-end of our Simultaneous Localization and Mapping framework is based on Monte Carlo Localization. Our novel measurement model integrates a virtual topological Path-Map with sparse map features to obtain global localization. The graph-based back-end optimizes online the vehicle trajectory and the landmarks' configuration to create a globally aligned map. Furthermore, our method allows weaker requirements in terms of accuracy of the sparse feature map as we represent the degree of uncertainty by means of probabilistic distribution. Additionally, the sparse feature map representation needs substantially less memory than other approaches, which is an advantage for autonomous vehicles. The framework has been tested and evaluated in real experiments for several autonomous runs. The results demonstrate the robustness of our system.",
        "primary_area": "",
        "author": "Patrick Burger;Benjamin Naujoks;Hans-Joachim Wuensche;Patrick Burger;Benjamin Naujoks;Hans-Joachim Wuensche",
        "authorids": "/37086351080;/37086349776;/37393701000;/37086351080;/37086349776;/37393701000",
        "aff": "Institute for Autonomous Systems Technology (TAS), Universit\u00e4t der Bundeswehr Munich, Neubiberg, Germany; Institute for Autonomous Systems Technology (TAS), Universit\u00e4t der Bundeswehr Munich, Neubiberg, Germany; Institute for Autonomous Systems Technology (TAS), Universit\u00e4t der Bundeswehr Munich, Neubiberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968466/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8115952394613496510&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e4t der Bundeswehr Munich",
        "aff_unique_dep": "Institute for Autonomous Systems Technology (TAS)",
        "aff_unique_url": "https://www.unibw.de",
        "aff_unique_abbr": "UniBW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Neubiberg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967984",
        "title": "Mapping for Planetary Rovers from Terramechanics Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "In an autonomous scientific exploration system, the terrain map generated from mapping process integrates sensing information from multiple aspects and lays the base for decision making processes. With the increasing challenges in planetary exploration, equipping planetary rovers with the principles of terramechanics is becoming more and more common, especially on rough or intricate terrain. However, it is difficult for conventional maps with elevation information only to reflect terrain mechanical properties, which play important roles in terramechanics-based simulation or motion control. This study extracts the dominant parameters in terrain bearing and shearing models, and presents a multi-layered grid map with fundamental geometric and mechanical elements. A corresponding mapping scheme based on dense visual input is designed to reconstruct elevation in the map and predict terrain mechanical parameters of the entire visual field. Experiments are conducted to verify the practicability of the approach proposed in a Mars emulation yard with a rover prototype.",
        "primary_area": "",
        "author": "Ruyi Zhou;Liang Ding;Haibo Gao;Wenhao Feng;Zongquan Deng;Nan Li;Ruyi Zhou;Liang Ding;Haibo Gao;Wenhao Feng;Zongquan Deng;Nan Li",
        "authorids": "/37086799540;/37529158200;/37535800300;/37087322981;/37271509900;/37085399452;/37086799540;/37529158200;/37535800300;/37087322981;/37271509900;/37085399452",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967984/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13602379891406648550&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968147",
        "title": "Maximum Information Bounds for Planning Active Sensing Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of planning trajectories for robots equipped with sensors whose task is to track an evolving target process in the world. We focus on processes which can be represented by a Gaussian random variable, which is known to reduce the general stochastic information acquisition problem to a deterministic problem, which is much simpler to solve. Previous work on solving the resulting deterministic problem focuses on computing a search tree by Forward Value Iteration and pruning uninformative nodes early on in the search via a domination criteria. In this work we formulate the Active Information Acquisition problem as a deterministic planning problem where algorithms like Dijkstra and A* can produce optimal solutions. To use A* effectively in long planning horizons we derive a consistent and admissible heuristic as a function of the sensor model which can be used in information acquisition tasks such as actively mapping static and moving targets in an environment with obstacles. We validate the results in several simulations indicating that the resulting heuristic informed algorithm can recover optimal solutions faster than existing search-based methods.",
        "primary_area": "",
        "author": "Brent Schlotfeldt;Nikolay Atanasov;George J. Pappas;Brent Schlotfeldt;Nikolay Atanasov;George J. Pappas",
        "authorids": "/37086113948;/37670511000;/37281547100;/37086113948;/37670511000;/37281547100",
        "aff": "GRASP Laboratory, University of Pennsylvania, USA; Electrical and Computer Engineering department, UC San Diego, USA; GRASP Laboratory, University of Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968147/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5534600432130801057&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Pennsylvania;University of California, San Diego",
        "aff_unique_dep": "GRASP Laboratory;Electrical and Computer Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "UPenn;UCSD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967828",
        "title": "Maximum Likelihood Path Planning for Fast Aerial Maneuvers and Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a planning method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle travels, updating the graph with data from onboard sensors is expensive as is the search on the graph especially if the paths must be kinodynamically feasible. We propose to avoid the online search to reduce the computational complexity. Our method models the environment differently in two separate regions. Obstacles are considered to be deterministically known within the sensor range and probabilistically known beyond the sensor range. Instead of searching for the path with the lowest cost (typically the shortest path), the method maximizes the likelihood to reach the goal in determining the immediate next step for navigation. With such a problem formulation, the online method realized by a trajectory library can determine a path within 0.2-0.3ms using a single CPU thread on a modem embedded computer. In experiments, it enables a lightweight UAV to fly at 10m/s in a cluttered forest environment (see Fig. 1 as an example).",
        "primary_area": "",
        "author": "Ji Zhang;Chen Hu;Rushat Gupta Chadha;Sanjiv Singh;Ji Zhang;Chen Hu;Rushat Gupta Chadha;Sanjiv Singh",
        "authorids": "/38541910000;/37087245354;/37086575702;/37085392083;/38541910000;/37087245354;/37086575702;/37085392083",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Near Earth Autonomy, Inc; Carnegie Mellon University and Near Earth Autonomy, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967828/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13162842287096287426&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Near Earth Autonomy",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.nearearthautonomy.com",
        "aff_unique_abbr": "CMU;NEA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967747",
        "title": "Measuring engagement elicited by eye contact in Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The present study aims at investigating how eye contact established by a humanoid robot affects engagement in human-robot interaction (HRI). To this end, we combined explicit subjective evaluations with implicit measures, i.e. reaction times and eye tracking. More specifically, we employed a gaze cueing paradigm in HRI protocol involving the iCub robot. Critically, before moving its gaze, iCub either established eye contact or not with the user. We investigated the patterns of fixations of participants' gaze on the robot's face, joint attention and the subjective ratings of engagement as a function of eye contact or no eye contact. We found that eye contact affected implicit measures of engagement, i.e. longer fixation times on the robot's face during eye contact. Moreover, we showed that joint attention was elicited only when the robot established eye contact, whereas no joint attention occurred when it did not. On the contrary, explicit measures of engagement with the robot did not vary across conditions. Our results highlight the value of combining explicit with implicit measures in an HRI protocol in order to unveil underlying human cognitive mechanisms, which might be at stake during the interactions. These mechanisms could be crucial for establishing an effective and engaging HRI, and provide guidelines to the robotics community with respect to better robot design.",
        "primary_area": "",
        "author": "K Kompatsiari;F Ciardo;D De Tommaso;A Wykowska;K Kompatsiari;F Ciardo;D De Tommaso;A Wykowska",
        "authorids": "/37086577959;/37086803925;/37086511317;/37085446614;/37086577959;/37086803925;/37086511317;/37085446614",
        "aff": "Istituto Italiano di Tecnologia, Genova; Istituto Italiano di Tecnologia, Genova; Istituto Italiano di Tecnologia, Genova; Istituto Italiano di Tecnologia, Genova",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967747/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13019886172811184053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968092",
        "title": "Meta-Learning for Multi-objective Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-objective reinforcement learning (MORL) is the generalization of standard reinforcement learning (RL) approaches to solve sequential decision making problems that consist of several, possibly conflicting, objectives. Generally, in such formulations, there is no single optimal policy which optimizes all the objectives simultaneously, and instead, a number of policies has to be found each optimizing a preference of the objectives. In this paper, we introduce a novel MORL approach by training a meta-policy, a policy simultaneously trained with multiple tasks sampled from a task distribution, for a number of randomly sampled Markov decision processes (MDPs). In other words, the MORL is framed as a meta-learning problem, with the task distribution given by a distribution over the preferences. We demonstrate that such a formulation results in a better approximation of the Pareto optimal solutions in terms of both the optimality and the computational efficiency. We evaluated our method on obtaining Pareto optimal policies using a number of continuous control problems with high degrees of freedom.",
        "primary_area": "",
        "author": "Xi Chen;Ali Ghadirzadeh;M\u00e5rten Bj\u00f6rkman;Patric Jensfelt;Xi Chen;Ali Ghadirzadeh;M\u00e5rten Bj\u00f6rkman;Patric Jensfelt",
        "authorids": "/37086265277;/37085340524;/37283063600;/37281289200;/37086265277;/37085340524;/37283063600;/37281289200",
        "aff": "RPL, KTH Royal Institute of Technology, Sweden; RPL, KTH Royal Institute of Technology, Sweden; RPL, KTH Royal Institute of Technology, Sweden; RPL, KTH Royal Institute of Technology, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968092/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1039851939610573651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "RPL",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "8968033",
        "title": "Metric Monocular Localization Using Signed Distance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "Metric localization plays a critical role in vision-based navigation. For overcoming the degradation of matching photometry under appearance changes, recent research resorted to introducing geometry constraints of the prior scene structure. In this paper, we present a metric localization method for the monocular camera, using the Signed Distance Field (SDF) as a global map representation. Leveraging the volumetric distance information from SDFs, we aim to relax the assumption of an accurate structure from the local Bundle Adjustment (BA) in previous methods. By tightly coupling the distance factor with temporal visual constraints, our system corrects the odometry drift and jointly optimizes global camera poses with the local structure. We validate the proposed approach on both indoor and outdoor public datasets. Compared to the state-of-the-art methods, it achieves a comparable performance with a minimal sensor configuration.",
        "primary_area": "",
        "author": "Huaiyang Huang;Yuxiang Sun;Haoyang Ye;Ming Liu;Huaiyang Huang;Yuxiang Sun;Haoyang Ye;Ming Liu",
        "authorids": "/37087103064;/37085435479;/37086022108;/37085398677;/37087103064;/37085435479;/37086022108;/37085398677",
        "aff": "Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology; Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology; Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology; Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968033/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16301332792055916352&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Robotics and Multi-Perception Laborotary, Robotics Institute",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968262",
        "title": "Miniaturization of MR Safe Pneumatic Rotational Stepper Motors",
        "track": "main",
        "status": "Poster",
        "abstract": "Pneumatic rotational stepper motors can be used to actuate MR (magnetic resonance) safe robotic systems. This paper describes novel techniques to minimize the volumetric size and/or step size of such motors in order to cope with the limited space requirements while still delivering high precision. Three designs are presented: the R-10 measures 1.0 cm3, has step size 12.9\u00b0 and torque 1.2 N mm. The R-40 measures 25.6 cm3, has step size 1.01\u00b0 and torque 470 N mm. The R-54 measures 46.7 cm3, has step size 1.01 m\u00b0 and torque 240 N mm. The particularly small step size in the R-54 motor is achieved by using a high-reduction planetary gear.These three motors demonstrate that small-scale rotational stepper motors with a wide range of step sizes and good torque characteristics can be constructed that surpass state-of-art designs by a considerable margin. This allows the advancement of MR safe robotics towards more compact and versatile designs, and also overcome certain existing limitations by combining multiple motors with different specifications.",
        "primary_area": "",
        "author": "Vincent Groenhuis;Fran\u00e7oise J. Siepel;Stefano Stramigioli;Vincent Groenhuis;Fran\u00e7oise J. Siepel;Stefano Stramigioli",
        "authorids": "/37085817635;/37085997643;/37282439300;/37085817635;/37085997643;/37282439300",
        "aff": "Robotics and Mechatronics, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics, University of Twente, Enschede, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968262/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4974361458155833232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Twente",
        "aff_unique_dep": "Robotics and Mechatronics",
        "aff_unique_url": "https://www.utwente.nl",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Enschede",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "8968007",
        "title": "Minimal Sensor Setup in Lower Limb Exoskeletons for Motion Classification based on Multi-Modal Sensor Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Exoskeletons are considered to be a promising technology for assisting and augmenting human performance. A number of challenges related to design, intuitive control and interfaces to the human body must be addressed. In this paper, we approach the question of a minimal sensor setup for the realization of control strategies which take into account the actions currently performed by the user. To this end, we extend our previous work on online classifications of a human wearing a lower limb exoskeleton in two directions. First, we investigate the minimal number of sensors that should be attached to the exoskeleton to achieve a certain classification accuracy by investigating different sensor setups. We compare results of motion classification of 14 different daily activities such as walking forward and going upstairs using Hidden Markov Models. Second, we analyse the influence of different window sizes, as well as the classification performance of different motion types when training on multi- and single-subjects. Our results reveal that we can reduce our sensor setup significantly while achieving about the same classification performance.",
        "primary_area": "",
        "author": "Isabel Patzer;Tamim Asfour;Isabel Patzer;Tamim Asfour",
        "authorids": "/37087325205;/37295529100;/37087325205;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968007/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5162902080252271153&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968058",
        "title": "Minimum k-Connectivity Maintenance for Robust Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In many multi-robot applications, it is critical to maintain connectivity within the robotic team to allow for information exchange and coordination. While most of the existing works focus on connectivity control that ensures robotic team remain connected as one component without faults, we consider the problem of robust connectivity maintenance that seeks to maintain k-connectivity, such that the multi-robot network could stay connected with the removal of fewer than k robots. In this paper, we propose provably minimum k-connectivity maintenance algorithms for multi-robot systems. This ensures the robustness of the multi-robot network connectivity at all time and also in a flexible and optimal way to provide the highest freedom for robots task-related controllers. Particularly, we propose a k-Connected Minimum Constraints Subgraph (k-CMCS) algorithm that activates the minimum k-connectivity constraints to the original controllers, and then revise the original controllers in a minimally invasive fashion. We demonstrate the effectiveness of our approach via simulations of up to 40 robots in the presence of multiple behaviors.",
        "primary_area": "",
        "author": "Wenhao Luo;Katia Sycara;Wenhao Luo;Katia Sycara",
        "authorids": "/37085748889;/37268476900;/37085748889;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968058/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1939817857805285320&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968277",
        "title": "Mobile Robot Learning from Human Demonstrations with Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning by imitation is a powerful way that can reduce the complexly in searching space. It could help the mobile robot to acquire new skills from interaction with a human-being in natural way. In this paper, the dynamic movement primitives (DMPs) is utilized to imitate the trajectory from human walking. DMPs is a modified formulation of virtual spring-dampers (VSD) system that enjoys better fitting performance in learning. Further, while dealing with the trajectory tracking problem of mobile robots, a novel nonlinear model predictive control (MPC) approach is proposed for motion control. The nonlinear MPC scheme applies a new neural network named Varying-parameter Lagrangian Neural Network (VP-LNN) to solve a Quadratic Programming (QP) problem by iterating over a finite receding horizon. The new network of VP-LNN can converge to the global optimal solution. Thus, a new human-robot interaction (HRI) scheme for mobile robot is proposed, which can reduce the complexity in motion planning in various applications.",
        "primary_area": "",
        "author": "Yingbai Hu;Guang Chen;Xiangyu Ning;Jinhu Dong;Shu Liu;Alois Knoll;Yingbai Hu;Guang Chen;Xiangyu Ning;Jinhu Dong;Shu Liu;Alois Knoll",
        "authorids": "/37085749138;/38251904000;/37087324739;/37087244876;/37087108152;/37276234100;/37085749138;/38251904000;/37087324739;/37087244876;/37087108152;/37276234100",
        "aff": "Chair of Robotics, Artificial Intelligence and Real-time Systems, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Chair of Robotics, Artificial Intelligence and Real-time Systems, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; College of Automotive Engineering, Tongii University, Shanghai, China; College of Automotive Engineering, Tongii University, Shanghai, China; D-MTEC, ETHZurich, Switzerland; Chair of Robotics, Artificial Intelligence and Real-time Systems, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968277/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9644531849644427299&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;2;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Tongji University;ETH Zurich",
        "aff_unique_dep": "Chair of Robotics, Artificial Intelligence and Real-time Systems;College of Automotive Engineering;D-MTEC",
        "aff_unique_url": "https://www.tum.de;https://www.tongji.edu.cn;https://www.ethz.ch",
        "aff_unique_abbr": "TUM;Tongji;ETHZ",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "M\u00fcnchen;Shanghai;",
        "aff_country_unique_index": "0;0;1;1;2;0",
        "aff_country_unique": "Germany;China;Switzerland"
    },
    {
        "id": "8967957",
        "title": "Mobile Robot Localization with Reinforcement Learning Map Update Decision aided by an Absolute Indoor Positioning System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new mobile robot localization solution consisting of two main modules: a Particle-Filter based Localization (PFL) and a Reinforcement-Learning based map updating, integrating relative measurements and absolute indoor positioning sensor (A-IPS) data. Concerning localization using 2D-LiDARs, featureless areas are known to be problematic. To solve this problem a classic PFL approach was modified to incorporate A-IPS position measurements in the prediction and update stages. The localization approach has the particularity of including the possibility of updating the map whenever major modifications are detected in the environment in relation to the current localization map. Due to the random sampling-based nature of the PFL, an associated map update solution is not trivial since small inconsistencies in the estimated pose can lead to erroneous map associations. The proposed method learns to decide by assigning higher rewards the greater is the overlap between the map and the 2DLIDAR scans, via RL, and then a proper update of the map is achieved. Validation of the proposed pipeline was carried out in a differential drive platform with algorithms developed in ROS. Tests were performed in two scenarios in order to assess the performance of both the localization module and the map update stage. The results show that the proposed localization method offers improvements in relation to known approaches, and consequently suggest promising perspectives for the proposed map update decision framework.",
        "primary_area": "",
        "author": "Lu\u00eds Garrote;Miguel Torres;Tiago Barros;Jo\u00e3o Perdiz;Cristiano Premebida;Urbano J. Nunes;Lu\u00eds Garrote;Miguel Torres;Tiago Barros;Jo\u00e3o Perdiz;Cristiano Premebida;Urbano J. Nunes",
        "authorids": "/38243509200;/37087325060;/37087120831;/37086111824;/37589826700;/37275938400;/38243509200;/37087325060;/37087120831;/37086111824;/37589826700;/37275938400",
        "aff": "Institute of Systems and Robotics, Department of Electrical and Computer Engineering, University of Coimbra, Portugal; Institute of Systems and Robotics, Department of Electrical and Computer Engineering, University of Coimbra, Portugal; Institute of Systems and Robotics, Department of Electrical and Computer Engineering, University of Coimbra, Portugal; Institute of Systems and Robotics, Department of Electrical and Computer Engineering, University of Coimbra, Portugal; Dept. of Aeronautical and Automotive Engineering, Loughborough University, UK; Institute of Systems and Robotics, Department of Electrical and Computer Engineering, University of Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967957/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12698876978329727038&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Coimbra;Loughborough University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Dept. of Aeronautical and Automotive Engineering",
        "aff_unique_url": "https://www.uc.pt;https://www.lboro.ac.uk",
        "aff_unique_abbr": "UC;Loughborough",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Portugal;United Kingdom"
    },
    {
        "id": "8967569",
        "title": "Model Free Calibration of Wheeled Robots Using Gaussian Process",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic calibration allows for the fusion of data from multiple sensors such as odometers, cameras, etc., by providing appropriate relationships between the corresponding reference frames. For wheeled robots equipped with camera/lidar along with wheel encoders, calibration entails learning the motion model of the sensor or the robot in terms of the data from the encoders and generally carried out before performing tasks such as simultaneous localization and mapping (SLAM). This work puts forward a novel Gaussian Process-based non-parametric approach for calibrating wheeled robots with arbitrary or unknown drive configurations. The procedure is more general as it learns the entire sensor/robot motion model in terms of odometry measurements. Different from existing non-parametric approaches, our method relies on measurements from the onboard sensors and hence does not require the ground truth information from external motion capture systems. Alternatively, we propose a computationally efficient approach that relies on the linear approximation of the sensor motion model. Finally, we perform experiments to calibrate robots with un-modelled effects to demonstrate the accuracy, usefulness, and flexibility of the proposed approach.",
        "primary_area": "",
        "author": "Mohan Krishna Nutalapati;Lavish Arora;Anway Bose;Ketan Rajawat;Rajesh M Hegde;Mohan Krishna Nutalapati;Lavish Arora;Anway Bose;Ketan Rajawat;Rajesh M Hegde",
        "authorids": "/37086934510;/37087322240;/37089733404;/37540472500;/37266490400;/37086934510;/37087322240;/37089733404;/37540472500;/37266490400",
        "aff": "Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967569/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14704280276251051884&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8967627",
        "title": "Model Predictive Control based Dynamic Path Tracking of a Four-Wheel Steering Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a new constrained model predictive control for a dynamic path tracking of an off-road mobile robot with a double steering axle. The controller is based on a dynamic model that includes wheel-ground lateral slippage and terrain geometry parameters. It is formulated as an optimization problem that computes at each time-step the optimal front and rear steering angles required to perform a desired path, with respect to multiple constraints, essentially the steering joint limits and the tire adhesion area bounds (i.e., pseudo-sliding zone limits). The capabilities of such a path tracking controller are shown and discussed through numerical simulations and experiments on a real off-road mobile robot at different speeds.",
        "primary_area": "",
        "author": "Mohamed Fnadi;Fr\u00e9d\u00e9ric Plumet;Fa\u00efz Benamar;Mohamed Fnadi;Fr\u00e9d\u00e9ric Plumet;Fa\u00efz Benamar",
        "authorids": "/37086933380;/37944925400;/37283664500;/37086933380;/37944925400;/37283664500",
        "aff": "Sorbonne Universit\u00e9, CNRS UMR 7222, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS UMR 7222, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS UMR 7222, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967627/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5199225957128131316&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9",
        "aff_unique_dep": "Institut des Syst\u00e9mes Intelligents et de Robotique",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967786",
        "title": "Model Simplification For Dynamic Control of Series-Parallel Hybrid Robots - A Representative Study on the Effects of Neglected Dynamics Shivesh",
        "track": "main",
        "status": "Poster",
        "abstract": "It is becoming increasingly popular to use parallel mechanisms as modular subsystem units in the design of various robots for their superior stiffness, payload-to-weight ratio and dynamic properties. This leads to series-parallel hybrid robotic systems which pose several challenges in their modeling and control e.g. resolution of loop closure constraints, large size of their spanning tree etc. These robots are typically position-controlled and when equipped with real time dynamic control, often a simplified inverse dynamic model of these systems is utilized. However, the trade-offs of this model simplification has not been studied previously. This paper presents a representative study of the neglected dynamics by introducing some error metrics which are useful in highlighting the advantages and disadvantages of such model simplification. The study is guided with the help of a series-parallel humanoid leg which has been recently developed at DFKI-RIC.",
        "primary_area": "",
        "author": "Shivesh Kumar;Julius Martensen;Andreas Mueller;Frank Kirchner;Shivesh Kumar;Julius Martensen;Andreas Mueller;Frank Kirchner",
        "authorids": "/37085850436;/37086441743;/37086479636;/37283559600;/37085850436;/37086441743;/37086479636;/37283559600",
        "aff": "Robotics Innovation Center, German Research Center for Artificial Intelligence (DFKI GmbH), Bremen, Germany; Department of Mathematics and Informatics, University of Bremen, Bremen, Germany; Institute of Robotics, Johannes Kepler University, Linz, Austria; Robotics Innovation Center, German Research Center for Artificial Intelligence (DFKI GmbH), Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967786/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12149586738325028570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence (DFKI GmbH);University of Bremen;Johannes Kepler University",
        "aff_unique_dep": "Robotics Innovation Center;Department of Mathematics and Informatics;Institute of Robotics",
        "aff_unique_url": "https://www.dFKI.de;https://www.uni-bremen.de;https://www.jku.at",
        "aff_unique_abbr": "DFKI;;JKU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Bremen;Linz",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "8968141",
        "title": "Model-less Active Compliance for Continuum Robots using Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Endowing continuum robots with compliance while it interacts with the internal environment of the human body is essential to prevent damage to the robot and the surrounding tissues. Compared with passive compliance, active compliance has the advantages in terms of increasing the force transmission ability and improving safety with monitored force output. Previous studies have demonstrated that active compliance can be achieved based on a complex model of the mechanics combined with a traditional machine learning technique such as a support vector machine. This paper proposes a recurrent neural network (RNN) based approach that avoids the complexity of modeling while capturing nonlinear factors such as hysteresis, friction and delay of the electronics that are not easy to model. The approach is tested on a 3-tendon single-segment continuum robot with force sensors on each cable. Experiments are conducted to demonstrate that the continuum robot with an RNN based feed-forward controller is capable of responding to external forces quickly and entering an unknown environment compliantly.",
        "primary_area": "",
        "author": "David Jakes;Zongyuan Ge;Liao Wu;David Jakes;Zongyuan Ge;Liao Wu",
        "authorids": "/37087323558;/37086431296;/37085418896;/37087323558;/37086431296;/37085418896",
        "aff": "School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia; eResearch Centre, Nvidia AI technology centre, Airdoc Research, Monash University, Melbourne, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968141/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3765655140256533776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Queensland University of Technology;Monash University;University of New South Wales",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;eResearch Centre;School of Mechanical and Manufacturing Engineering",
        "aff_unique_url": "https://www.qut.edu.au;https://www.monash.edu;https://www.unsw.edu.au",
        "aff_unique_abbr": "QUT;Monash;UNSW",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Brisbane;Melbourne;Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967900",
        "title": "Modeling and Force Control of a Terramechanical Wheel-Soil Contact for a Robotic Manipulator Used in the Planetary Rover Design Process",
        "track": "main",
        "status": "Poster",
        "abstract": "The German Aerospace Center (DLR) has developed the Terramechanics Robotics Locomotion Lab (TROLL) to provide a feasible testing facility for developing planetary exploration rovers, as well as validating terramechanical models. A robotic manipulator is used to provide the required degrees of freedom to the mounted wheel or subsystem, making it necessary to actively control the interaction force of the wheel-soil contact. This paper is concerned with the development of a feasible force control strategy for the testbench wheel-soil contact during single-wheel experiments. For this purpose, a terramechanical model has been developed to accurately map the dynamic processes relevant for the force control design, which is later used in a testbench simulation framework to predict and evaluate the performance of control strategies. The Adaptive Admittance Control (AAC) scheme developed is adapting the gain based on the current control deviation, the rotational velocity of the wheel and an estimated soil stiffness during the experiment. The AAC is evaluated using a benchmark single-wheel experiment and shows superior performance compared to standard admittance control.",
        "primary_area": "",
        "author": "Jan Wachter;Ralf Mikut;Fabian Buse;Jan Wachter;Ralf Mikut;Fabian Buse",
        "authorids": "/37087323846;/37271890000;/37087321869;/37087323846;/37271890000;/37087321869",
        "aff": "Institute for Automation and Applied Informatics (IAI), Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Automation and Applied Informatics (IAI), Karlsruhe Institute of Technology, Karlsruhe, Germany; German Aerospace Center (DLR), Institute of System Dynamics and Control, Oberpfaffenhofen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967900/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11944846648807246554&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute for Automation and Applied Informatics (IAI);Institute of System Dynamics and Control",
        "aff_unique_url": "https://www.kit.edu;https://www.dlr.de",
        "aff_unique_abbr": "KIT;DLR",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Karlsruhe;Oberpfaffenhofen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967741",
        "title": "Modeling and Identification for the Design of a Rotary Soft Actuator based on Wren Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we describe the use of calibration techniques to help improving prediction accuracy of models for soft actuators. A finite-difference model considering anisotropy of soft actuator flexible chamber is combined with experimental identification to assess actuator motion. Identifiability conditions are exploited to determine suitable experimental conditions, taking into account the manufacturing process capabilities, multimaterial additive manufacturing in this context. As a second contribution, a soft actuator with Wren mechanism for reinforcement is being developed. It is considered for rotary actuation, with the description of a proof of concept. The interest of the calibration technique and the actuator design are finally discussed.",
        "primary_area": "",
        "author": "Thibault Gayral;Lennart Rubbert;Pierre Renaud;Thibault Gayral;Lennart Rubbert;Pierre Renaud",
        "authorids": "/37077418900;/37086476458;/37277292000;/37077418900;/37086476458;/37277292000",
        "aff": "ICube laboratory, INSA - CNRS, University of Strasbourg; ICube laboratory, INSA - CNRS, University of Strasbourg; ICube laboratory, INSA - CNRS, University of Strasbourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967741/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16045358136838459591&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "UNistra",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968292",
        "title": "Modeling, Learning and Prediction of Longitudinal Behaviors of Human-Driven Vehicles by Incorporating Internal Human DecisionMaking Process using Inverse Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the behaviors of human-driven vehicles such as acceleration and braking are critical for the safety of the near-future mixed transportation systems which involve both automated and human-driven vehicles. Existing approaches in modeling human driving behaviors including driver-model-based approaches and heuristic approaches have issues in either model accuracy or scalability limitation to new situations. To address these issues, this paper proposes a new inverse model predictive control (IMPC) based approach to model longitudinal human driving behaviors. The approach incorporates the internal decision making process of humans, and achieves better predicting accuracy and improved scalability to different situations. The modeling, learning, and prediction of longitudinal human driving behaviors using the proposed IMPC approach are presented. Experimental results validate the effectiveness and advantages of the approach.",
        "primary_area": "",
        "author": "Longxiang Guo;Yunyi Jia;Longxiang Guo;Yunyi Jia",
        "authorids": "/37086350606;/37532721400;/37086350606;/37532721400",
        "aff": "Department of Automotive Engineering, Clemson University, Greenville, USA; Department of Automotive Engineering, Clemson University, Greenville, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968292/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4765837947986359552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Department of Automotive Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Greenville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968556",
        "title": "Modeling, Simulation and Experimental Validation of a Tendon-driven Soft-arm Robot Configuration - A Continuum Mechanics Method",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the mathematical derivation and experimental validation of a computational model, which accurately predicts static, large-strain deformations of tendon driven non-slender soft-arm manipulators subjected to gravity. The large strain behaviors are captured by employing the Green-Lagrange strain and by deriving analytical expressions for the variation of the equivalent Young modulus of the structure due to the large strains. No simplifying assumptions are made regarding the curvature of the structure, the stretching or the compression. Furthermore the paper proposes an iterative method for numerically solving the resultant non-linear system of coupled differential equations and demonstrates a number of application scenarios. The model is experimentally validated using a set-up comprising one segment of tendon driven soft-arm, which integrates stretchable and compressible hyperelastic (rubber-type) materials into its non-homogeneous back bone structure.",
        "primary_area": "",
        "author": "Nikolaos Charalampos Chairopoulos;Panagiotis Vartholomeos;Evangelos Papadopoulos;Nikolaos Charalampos Chairopoulos;Panagiotis Vartholomeos;Evangelos Papadopoulos",
        "authorids": "/37087321723;/37542879200;/37273090500;/37087321723;/37542879200;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens, Greece; School of Mechanical Engineering, National Technical University of Athens, Greece; School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968556/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16301004157951218546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "8967986",
        "title": "Modelling and Dynamic Tracking Control of Industrial Vehicles with Tractor-trailer Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing works on control of tractor-trailers systems only consider the kinematics model without taking dynamics into account. Also, most of them treat the issue as a pure control theory problem whose solutions are difficult to implement. This paper presents a trajectory tracking control approach for a full-scale industrial tractor-trailers vehicle composed of a carlike tractor and arbitrary number of passive full trailers. To deal with dynamic effects of trailing units, a force sensor is innovatively installed at the connection between the tractor and the first trailer to measure the forces acting on the tractor. The tractor's dynamic model that explicitly accounts for the measured forces is derived. A tracking controller that compensates the pulling/pushing forces in real time and simultaneously drives the system onto desired trajectories is proposed. The propulsion map between throttle opening and the propulsion force is proposed to be modeled with a fifth-order polynomial. The parameters are estimated by fitting experimental data, in order to provide accurate driving force. Stability of the control algorithm is rigorously proved by Lyapunov methods. Experiments of full-size vehicles are conducted to validate the performance of the control approach.",
        "primary_area": "",
        "author": "Hongchao Zhao;Zhe Liu;Zhiqiang Li;Shunbo Zhou;Wen Chen;Chuanzhe Suo;Yun-Hui Liu;Hongchao Zhao;Zhe Liu;Zhiqiang Li;Shunbo Zhou;Wen Chen;Chuanzhe Suo;Yun-Hui Liu",
        "authorids": "/37086346685;/38505849700;/37086611282;/37086345412;/37087239966;/37086937363;/37279412600;/37086346685;/38505849700;/37086611282;/37086345412;/37087239966;/37086937363;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR; Department of Mechanical and Automation Engineering, T Stone Robotics Institute and The Chinese University of Hong Kong, Shatin, HKSAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967986/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14477898620771945494&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967655",
        "title": "Modelling of Uniaxial EGaIn-Based Strain Sensors for Proprioceptive Sensing of Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft strain resistive sensors based on eutectic gallium-indium liquid metal can play an important role in proprioceptive sensing for soft robots. However, there are no available mathematical models to accurately estimate the strain as a function of the measured resistance. Furthermore, non-uniform strain in the microchannels has not been analysed yet. In this paper, we introduce a new model to estimate the strain or elongation in sub-millimetre scale, and analyse its accuracy through a customised testing set-up and procedure. The effect of strain rate on the measurement accuracy is also studied. We compare existing theoretical models with our experimental results, and discuss the differences between them. Moreover, we analyse the effect of strain rate on hysteresis caused by the viscoelastic behaviour and introduce a new model for it to be potentially used for future work. This paper demonstrates, among other things, that rational models could provide high accuracy in strain estimation, and might help to enhance proprioceptive sensing and state control of soft robots.",
        "primary_area": "",
        "author": "Abdullah Al-Azzawi;A. Mounir Boudali;He Kong;Ali H. G\u00f6kto\u011fan;Salah Sukkarieh;Abdullah Al-Azzawi;A. Mounir Boudali;He Kong;Ali H. G\u00f6kto\u011fan;Salah Sukkarieh",
        "authorids": "/37087324815;/37085667390;/37086935024;/38053290500;/37284368200;/37087324815;/37085667390;/37086935024;/38053290500;/37284368200",
        "aff": "Australian Centre for Field Robotics (ACFR), The University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), The University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), The University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), The University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), The University of Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967655/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2305040981980176149&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Australian Centre for Field Robotics (ACFR)",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8968187",
        "title": "Modular Volumetric Actuators Using Motorized Auxetics",
        "track": "main",
        "status": "Poster",
        "abstract": "Volume change has become a critical actuation method in robotics. However, the need for fluid flow or thermal processes to generate volume changes limits the durability, speed, and efficiency of these actuators. In this paper, we develop a new electromechanical actuator that volumetrically expands. By combining auxetic materials with a servo, we produce a simple isotropically expanding actuator that can be modularly composed. We discuss the symmetry considerations in selecting an appropriate auxetic framework for our actuator, eventually choosing a double-layered polyhedral auxetic design. Characterization shows that a single actuator can expand in radius to 119% of the original size and generate 90N of force, while maintaining a small package and a speedy expansion / contraction cycle. Finally, we demonstrate the modularity of our actuators by linking three actuators to create a vertical tube-crawling robot. The small package and fast cycle time of our system highlight how viable these electromechanical volumetric actuators can be as an important actuator modality.",
        "primary_area": "",
        "author": "Jeffrey Lipton;Lillian Chin;Jacob Miske;Daniela Rus;Jeffrey Lipton;Lillian Chin;Jacob Miske;Daniela Rus",
        "authorids": "/37086014107;/37086413893;/37087322281;/37279652300;/37086014107;/37086413893;/37087322281;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab, MIT, 32 Vassar Street, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab, MIT, 32 Vassar Street, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab, MIT, 32 Vassar Street, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab, MIT, 32 Vassar Street, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968187/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11830076467893326887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967677",
        "title": "Monocular Depth Estimation in New Environments With Absolute Scale",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we propose an unsupervised training method that finetunes a single image depth estimation CNN towards a new environment. The network, which has been pretrained on stereo data, only requires monocular input for finetuning. Unlike other unsupervised methods, it produces depth estimations with absolute scale - a feature that is essential for most practical applications, yet has mostly been overlooked in the literature. First, we show how our method allows adapting a network trained on one dataset (Cityscapes) to another (KITTI). Next, by splitting KITTI in subsets, we show the sensitivity of pretrained models to a domain shift. We then demonstrate that, by finetuning the model using our method, it is possible to improve the performance on the target subset, without using stereo or any form of groundtruth depth and with preservation of the correct absolute scale.",
        "primary_area": "",
        "author": "Tom Roussel;Luc Van Eycken;Tinne Tuytelaars;Tom Roussel;Luc Van Eycken;Tinne Tuytelaars",
        "authorids": "/37085994793;/37087323757;/37282935100;/37085994793;/37087323757;/37282935100",
        "aff": "KU Leuven; KU Leuven; KU Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967677/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12607484330584016154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Katholieke Universiteit Leuven",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "8968079",
        "title": "Monocular Outdoor Semantic Mapping with a Multi-task Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In many robotic applications, especially for the autonomous driving, understanding the semantic information and the geometric structure of surroundings are both essential. Semantic 3D maps, as a carrier of the environmental knowledge, are then intensively studied for their abilities and applications. However, it is still challenging to produce a dense outdoor semantic map from a monocular image stream. Motivated by this target, in this paper, we propose a method for large-scale 3D reconstruction from consecutive monocular images. First, with the correlation of underlying information between depth and semantic prediction, a novel multi-task Convolutional Neural Network (CNN) is designed for joint prediction. Given a single image, the network learns low-level information with a shared encoder and separately predicts with decoders containing additional Atrous Spatial Pyramid Pooling (ASPP) layers and the residual connection which merits disparities and semantic mutually. To overcome the inconsistency of monocular depth prediction for reconstruction, post-processing steps with the superpixelization and the effective 3D representation approach are obtained to give the final semantic map. Experiments are compared with other methods on both semantic labeling and depth prediction. We also qualitatively demonstrate the map reconstructed from large-scale, difficult monocular image sequences to prove the effectiveness and superiority.",
        "primary_area": "",
        "author": "Yucai Bai;Lei Fan;Ziyu Pan;Long Chen;Yucai Bai;Lei Fan;Ziyu Pan;Long Chen",
        "authorids": "/37087323473;/37085901181;/37086600620;/37085668482;/37087323473;/37085901181;/37086600620;/37085668482",
        "aff": "College of Computer Science, Sichuan University, Chengdu, Sichuang, P.R.China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, P.R.China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, P.R.China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968079/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13504269760926822009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Sichuan University;Sun Yat-sen University",
        "aff_unique_dep": "College of Computer Science;School of Data and Computer Science",
        "aff_unique_url": "https://www.scu.edu.cn;http://www.sysu.edu.cn",
        "aff_unique_abbr": "SCU;SYSU",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Chengdu;Guangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967897",
        "title": "Monocular Plan View Networks for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutions on monocular dash cam videos capture spatial invariances in the image plane but do not explicitly reason about distances and depth. We propose a simple transformation of observations into a bird's eye view, also known as plan view, for end-to-end control. We detect vehicles and pedestrians in the first person view and project them into an overhead plan view. This representation provides an abstraction of the environment from which a deep network can easily deduce the positions and directions of entities. Additionally, the plan view enables us to leverage advances in 3D object detection in conjunction with deep policy learning. We evaluate our monocular plan view network on the photo-realistic Grand Theft Auto V simulator. A network using both a plan view and front view causes less than half as many collisions as previous detection-based methods and an order of magnitude fewer collisions than pure pixel-based policies.",
        "primary_area": "",
        "author": "Dequan Wang;Coline Devin;Qi-Zhi Cai;Philipp Kr\u00e4henb\u00fchl;Trevor Darrell;Dequan Wang;Coline Devin;Qi-Zhi Cai;Philipp Kr\u00e4henb\u00fchl;Trevor Darrell",
        "authorids": "/37086568251;/37085995906;/37086933942;/38467067400;/37282910600;/37086568251;/37085995906;/37086933942;/38467067400;/37282910600",
        "aff": "UC Berkeley; UC Berkeley; Sinovation Ventures AI Institute; UT Austin; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967897/",
        "gs_citation": 95,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5474736499390491958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of California, Berkeley;Sinovation Ventures AI Institute;University of Texas at Austin",
        "aff_unique_dep": ";AI Institute;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.sinovationventures.com/;https://www.utexas.edu",
        "aff_unique_abbr": "UC Berkeley;SVAI;UT Austin",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Berkeley;;Austin",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8968215",
        "title": "Motion Decoupling and Composition via Reduced Order Model optimization for Dynamic Humanoid Walking with CLF-QP based Active Force Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, 3D humanoid walking is decoupled into periodic and transitional motion, each of which is decoupled into planar walking in the sagittal and lateral plane. Reduced order models (ROMs), i.e. actuated Spring-loaded Inverted Pendulum (aSLIP) models and Hybrid-Linear Inverted Pendulum (H-LIP) models, are utilized for motion generation on the desired center of mass (COM) dynamics for each type of planar motion. The periodic motion is planned via point foot (underactuated) ROMs for dynamic motion with minimum ankle actuation, while the transitional motion is planned via foot-actuated ROMs for fast and smooth transition. Composition of the planar COM dynamics yields the desired COM dynamics in 3D, which is embedded on the humanoid via control Lyapunov function based Quadratic programs (CLF-QPs). Additionally, the ground reaction force profiles of the aSLIP walking are used as desired references for ground contact forces in the CLF-QPs for smooth domain transitions. The proposed framework is realized on a lower-limb exoskeleton in simulation wherein different walking motions are achieved.",
        "primary_area": "",
        "author": "Xiaobin Xiong;Aaron D. Ames;Xiaobin Xiong;Aaron D. Ames",
        "authorids": "/37086275102;/37300877900;/37086275102;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968215/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7886126504397863971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967841",
        "title": "Motion Planning for a Continuum Robotic Mobile Lamp: Defining and Navigating the Configuration Space",
        "track": "main",
        "status": "Poster",
        "abstract": "We discuss motion planning in the configuration spaces of robots containing continuum elements. The configuration space structure of extensible continuum sections is first analyzed, with practical constraints unique to continuum elements identified. The results are applied to generate the configuration space of a hybrid continuum lamp/mobile base robot. A conventional motion planning RRT/A* approach is subsequently applied for the robot in an aging in place application scenario.",
        "primary_area": "",
        "author": "Zachary Hawks;Chase Frazelle;Keith E. Green;Ian D. Walker;Zachary Hawks;Chase Frazelle;Keith E. Green;Ian D. Walker",
        "authorids": "/37087322720;/37085792455;/37086537054;/37276152000;/37087322720;/37085792455;/37086537054;/37276152000",
        "aff": "Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967841/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15033900903364642010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Clemson University;Cornell University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Sibley School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.clemson.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Clemson;Cornell",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Clemson;Ithaca",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968257",
        "title": "Motor-propeller Matching of Aerial Propulsion Systems for Direct Aerial-aquatic Operation",
        "track": "main",
        "status": "Poster",
        "abstract": "Electric aerial propulsion systems are commonly used for many small-scale unmanned aerial vehicles (UAVs), providing a light and powerful method of generating thrust. In the emerging area of aerial-aquatic vehicles, most existing prototypes rely on such systems to propel themselves in both air and water. As the density of water is three orders of magnitude larger than that of air, a spinning aerodynamic body in the medium will experience significantly higher torque at the same speed. This results in aerial propulsion systems to be heavily mismatched underwater, as the required torque is higher than the drive torque that a typical aerial motor can provide. Here, an in-depth investigation of such off-design operation is conducted. Based on numerical simulation, we identify the feasible operating range of such systems and present an evaluation framework that identifies a motor-propeller combination from a component database that maximises underwater performance while ensuring aerial thrust requirements are met.",
        "primary_area": "",
        "author": "Yu Herng Tan;Ben M. Chen;Yu Herng Tan;Ben M. Chen",
        "authorids": "/37086150770;/38520079900;/37086150770;/38520079900",
        "aff": "Department of Electrical & Computer Engineering, National University of Singapore, Singapore; Department of Electrical & Computer Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968257/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10039940776202866984&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8967833",
        "title": "Moving onto High Steps for a Four-limbed Robot with Torso Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we describe approaches to enable a four-limbed robot to get over a step higher than its leg with torso contact. The higher the step becomes, the more difficult it is for legged robots to get over from the viewpoint of stability and kinematic reachability. Torso landing contributes to improving stability and robustness of motion for moving onto high step because of lower center of mass (CoM) and larger support polygon, which is seldomly utilized by previous human-sized legged robots. The approaches in this paper consist of the following two components. As for hardware, spikes are arranged on the bottom of robot\u2019 s body for stable torso landing on a high step. As for motion generation, Sequential Quadratic Programming (SQP) is utilized to generate motion with torso landing to guarantee stability of robots during getting over the high step. From experiments, it is confirmed that the fourlimbed robot WAREC-I succeeded in moving onto a step with the height of 865mm.",
        "primary_area": "",
        "author": "T. Matsuzawa;T. Matsubara;K. Namura;X. Sun;A. Imai;M. Ohkawara;S. Kimura;K. Kumagai;K. Yamaguchi;H. Naito;T. Sato;K. Terae;M. Murakami;S. Yoshida;A. Takanishi;K. Hashimoto;T. Matsuzawa;T. Matsubara;K. Namura;X. Sun;A. Imai;M. Ohkawara;S. Kimura;K. Kumagai;K. Yamaguchi;H. Naito;T. Sato;K. Terae;M. Murakami;S. Yoshida;A. Takanishi;K. Hashimoto",
        "authorids": "/37085848034;/37088742484;/37088729027;/37085840797;/37086217919;/37088734812;/37085997506;/37087199138;/37087199254;/37088724098;/37089267822;/37088739255;/37307757700;/37088737575;/37280756700;/37537963700;/37085848034;/37088742484;/37088729027;/37085840797;/37086217919;/37088734812;/37085997506;/37087199138;/37087199254;/37088724098;/37089267822;/37088739255;/37307757700;/37088737575;/37280756700;/37537963700",
        "aff": "Graduate School of Advanced Science and Engineering, Waseda University, 41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Advanced Science and Engineering, Waseda University, 41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Advanced Science and Engineering, Waseda University, 41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Advanced Science and Engineering, Waseda University, 41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo; Graduate School of Advanced Science and Engineering, Waseda University, 41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo; Department of Modern Mechanical Engineering, Waseda University and is the director of the Humanoid Robotics Institute (HRI), Waseda University; School of Science and Technology, Meiji University and is a researcher at the Humanoid Robotics Institute (HRI), Waseda University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967833/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6907458310786617909&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 32,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Waseda University;Meiji University",
        "aff_unique_dep": "Graduate School of Advanced Science and Engineering;School of Science and Technology",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.meiji.ac.jp",
        "aff_unique_abbr": "Waseda;Meiji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967893",
        "title": "MuSe: Multi-Sensor Integration Strategies Applied to Sequential Monte Carlo Methods",
        "track": "main",
        "status": "Poster",
        "abstract": "Recursive state estimation is often used to estimate a probability density function of a specific state, e.g. a robot's pose, over time. Compared to Kalman filters, Sequential Monte Carlo (SMC) methods are less constrained in regard to state propagation and update model definition, which makes it easier to implement any suitable problem. In this work, we present a generic Sequential Monte Carlo framework, which uses abstract formulations for importance weighting, propagation and resampling and provides an independent core algorithm that is usable for any problem instantiation, such that diverse SMC problems can be implemented easily and quickly, since the basic algorithms are already provided. Current applications include 2D localization, 2D tracking in a SLAM system and contact point localization on a manipulator surface. Further, we introduce concepts to deal with data input synchronization and fair execution of different weighting models, which makes it possible to incorporate data from as many update sources, e.g. sensors, as desired. As a typical application scenario, we provide a plugin-based and hence easily extensible instantiation for 2D localization and demonstrate the capabilities of our framework and methods based on a well-known dataset.",
        "primary_area": "",
        "author": "Richard Hanten;Cornelia Schulz;Adrian Zwiener;Andreas Zell;Richard Hanten;Cornelia Schulz;Adrian Zwiener;Andreas Zell",
        "authorids": "/37085619648;/37086579417;/37086455280;/37276583400;/37085619648;/37086579417;/37086455280;/37276583400",
        "aff": "The Cognitive Systems Group at the Computer Science Department, University of Tuebingen, Sand 1, Tuebingen, Germany; The Cognitive Systems Group at the Computer Science Department, University of Tuebingen, Sand 1, Tuebingen, Germany; The Cognitive Systems Group at the Computer Science Department, University of Tuebingen, Sand 1, Tuebingen, Germany; The Cognitive Systems Group at the Computer Science Department, University of Tuebingen, Sand 1, Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967893/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15962148055414156450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tuebingen",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "Uni Tuebingen",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tuebingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968465",
        "title": "Multi Robot Route Planning (MRRP): Extended Spatial-Temporal Prioritized Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles are, in contrast to classical automated guided vehicles (AGVs), less predictable in their behavior and drive time. Therefore, the issue of how to efficiently control these vehicles arises, because autonomous agents need to be coordinated and not controlled, to give autonomous behaviors and actions space. The scientific contribution of this paper is a novel approach, based on prioritized planning to target this issue as well as an open source framework for evaluation and comparison. Prioritized planning has the disadvantage of being neither optimal nor complete, however, it has the advantage of being computationally feasible. This work utilizes prioritized planning to significantly increase the set of feasible scenarios through collision prevention: by locally finding alternative routes and adding them to the search graph. The paper clearly formulates the extensions needed and delineates the approach\u2019s limits, as it is neither optimal nor complete. More importantly, however, our method calculates routes for each vehicle with inter-vehicle synchronization, enabling vehicles to execute the plan in a distributed fashion without centralized control, thereby allowing autonomous behavior. Finally, results are verified by comparing our Multi Robot Router (MRR) proposed in this work to classical approaches. The software developed as well as the test sets are publicly available for ROS and the simulation environment.",
        "primary_area": "",
        "author": "Benjamin Binder;Florian Beck;Felix K\u00f6nig;Markus Bader;Benjamin Binder;Florian Beck;Felix K\u00f6nig;Markus Bader",
        "authorids": "/37089655425;/37085393727;/37087323340;/37297505900;/37089655425;/37085393727;/37087323340;/37297505900",
        "aff": "DS AUTOMOTION GmbH, Lunzerstra\u00dfe 60, Linz, Austria; Automation and Control Institute, Vienna University of Technology, Vienna, Austria; Institute of Computer Aided Automation, Vienna University of Technology, Treitlstr. 1-3/4. Floor/E183-1, Vienna, Austria; Institute of Computer Aided Automation, Vienna University of Technology, Treitlstr. 1-3/4. Floor/E183-1, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968465/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1925132972646553629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "DS AUTOMOTION GmbH;Vienna University of Technology",
        "aff_unique_dep": ";Automation and Control Institute",
        "aff_unique_url": ";https://www.tuwien.ac.at",
        "aff_unique_abbr": ";TU Wien",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Vienna",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "8968129",
        "title": "Multi-Agent Image Classification via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate a classification problem using multiple mobile agents capable of collecting (partial) pose-dependent observations of an unknown environment. The objective is to classify an image over a finite time horizon. We propose a network architecture on how agents should form a local belief, take local actions, and extract relevant features from their raw partial observations. Agents are allowed to exchange information with their neighboring agents to update their own beliefs. It is shown how reinforcement learning techniques can be utilized to achieve decentralized implementation of the classification problem by running a decentralized consensus protocol. Our experimental results on the MNIST handwritten digit dataset demonstrates the effectiveness of our proposed framework.",
        "primary_area": "",
        "author": "Hossein K. Mousavi;Mohammadreza Nazari;Martin Tak\u00e1\u010d;Nader Motee;Hossein K. Mousavi;Mohammadreza Nazari;Martin Tak\u00e1\u010d;Nader Motee",
        "authorids": "/37085996801;/37087321820;/37085360273;/37299859900;/37085996801;/37087321820;/37085360273;/37299859900",
        "aff": "The depattment of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, USA; The department of Indusmal and Systems Engineering, Lehigh University, Bethlehem, USA; The department of Indusmal and Systems Engineering, Lehigh University, Bethlehem, USA; The depattment of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968129/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13444677018694331695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Department of Mechanical Engineering and Mechanics",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bethlehem",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968059",
        "title": "Multi-Contact Stabilization of a Humanoid Robot for Realizing Dynamic Contact Transitions on Non-coplanar Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on a stabilization control for multi-contact motion which enables a humanoid robot to locomote by realizing dynamic contact transitions on non-flat environment. In the stabilization process of the multi-contact motion, the desired Zero-Moment Point (ZMP) is modified by the position of the Divergent Component of Motion (DCM) error with respect to the 3D Center of Mass (CoM) motion generated from the force distribution ratio. The contact wrench of each end-effector is determined by quadratic optimization considering the centroidal dynamics and contact friction constraints so as to satisfy the modified ZMP. Each end-effector is controlled by optimized force reference through a projection of null space by force distribution ratio. We propose a multi-contact stabilization framework which can be designed not only to generate 3D CoM motion but also the CoM position estimation and the optimal force distribution around the reference ZMP in a unified manner from a balance controller, by using the force distribution ratio. The effectiveness of proposed method is validated by a quadruped locomotion leaning against a vertical wall using the joint position controlled humanoid HRP-5P in a dynamic simulator.",
        "primary_area": "",
        "author": "Mitsuharu Morisawa;Mehdi Benallegue;Rafael Cisneros;Iori Kumagai;Adrien Escande;Kenji Kaneko;Fumio Kanehiro;Mitsuharu Morisawa;Mehdi Benallegue;Rafael Cisneros;Iori Kumagai;Adrien Escande;Kenji Kaneko;Fumio Kanehiro",
        "authorids": "/37295668600;/37571999700;/38580560800;/38542440000;/37542914500;/37270434700;/37283667500;/37295668600;/37571999700;/38580560800;/38542440000;/37542914500;/37270434700;/37283667500",
        "aff": "Humanoid Research Group; Humanoid Research Group; Humanoid Research Group; Humanoid Research Group; Interactive Robotics Research Group, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; Humanoid Research Group; Humanoid Research Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968059/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16521795481198905233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Humanoid Research Group;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Humanoid Research;Interactive Robotics Research Group",
        "aff_unique_url": ";https://www.aist.go.jp",
        "aff_unique_abbr": ";AIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tsukuba",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";Japan"
    },
    {
        "id": "8968088",
        "title": "Multi-Hand Direct Manipulation of Complex Constrained Virtual Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to manipulate virtual objects which are constrained complexly and reconfigurable as if they would exist in a real world by using multiple hands simultaneously. A complexly constrained, and reconfigurable object, such as a Rubik's cube, is hard to describe its physical motion constraints, mainly because they are determined by the grasping situation and dynamically changeable. Rather than describing the physical motion constraints in a general form, we more focus on the multiple hand interaction of a complex object. A complex object is divided into multiple subparts which are grasped by each hand, and the constraints between the subparts are optimized for inducing natural and continuous movement. For this, we propose a dynamically adjustable data structure for representing object parts grasped by multiple hands, and an optimization-based pose estimation of the constrained subparts along with their grasped hands. The experiments show that human subjects can manipulate a complexly constrained object such as a Rubik's cube without any difficulty as if it exists in the real-world.",
        "primary_area": "",
        "author": "Jun-Sik Kim;MyungHwan Jeon;Jung-Min Park;Jun-Sik Kim;MyungHwan Jeon;Jung-Min Park",
        "authorids": "/37068806700;/37088439542;/37351422900;/37068806700;/37088439542;/37351422900",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Hwarangro 14 gil 5, Seongbuk-Gu, Korea; Robotics Program, KAIST, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Hwarangro 14 gil 5, Seongbuk-Gu, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968088/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16840781361953718425&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;KAIST",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Robotics Program",
        "aff_unique_url": "https://www.kist.re.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KIST;KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968455",
        "title": "Multi-Layer Environmental Affordance Map for Robust Indoor Localization, Event Detection and Social Friendly Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel system architecture called multi-layer environmental affordance map for social and service companion robots. Based on this architecture, robots can organize the perception and inference information efficiently and generate social friendly navigation strategies. In other words, robots are able to strengthen their perception and inference abilities to interact with domestic environment and users under our efficient framework. The main feature of this architecture is that the relations between layers can be viewed as affordances to improve the accuracy and the robustness of the detection and inference. The results show that our architecture achieves robust indoor localization, scene localization, human event detection and socially friendly navigation in real time under limited computational resource.",
        "primary_area": "",
        "author": "Ping-Tsang Wu;Chee-An Yu;Shao-Hung Chan;Ming-Li Chiang;Li-Chen Fu;Ping-Tsang Wu;Chee-An Yu;Shao-Hung Chan;Ming-Li Chiang;Li-Chen Fu",
        "authorids": "/37086578798;/37087324534;/37086580815;/37399201100;/37278448600;/37086578798;/37087324534;/37086580815;/37399201100;/37278448600",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Automation Technology, National Taipei University of Technology, Taipei, Taiwan; Director of NTU Center for Artificial Intelligence & Advanced Robotics, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968455/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4278697982629793865&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "National Taiwan University;National Taipei University of Technology",
        "aff_unique_dep": "Department of Electrical Engineering;Graduate Institute of Automation Technology",
        "aff_unique_url": "https://www.ntu.edu.tw;https://www.ntut.edu.tw",
        "aff_unique_abbr": "NTU;NTUT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968246",
        "title": "Multi-Robot Assembly Sequencing via Discrete Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot assembly has the potential to greatly reduce the cost and risk associated with the fabrication of large structures. Using teams of robots to perform assembly offers numerous advantages such as parallelism, robustness to single-agent failures, and flexibility in scheduling and task assignment. However, while previous work on multi-robot assembly focuses on generating feasible assembly plans and decentralized control strategies, we instead study the problem of planning optimal assembly sequences.To this end, we pose the problem of multi-robot assembly as a discrete optimization, specifically an integer linear program (ILP) or quadratic program (IQP), which aims to minimize the time to complete the assembly, or to minimize the distance traveled. We develop a model of multi-robot assembly that captures both geometric constraints and actuation constraints inherent to the problem. While the ILP and IQP can be solved exactly using commercial optimization software in a substantial amount of time, we also propose heuristic strategies which can be quickly computed, and can scale to structures of reasonable size. We also verify our methods empirically by comparing their performance on a variety of test structures.",
        "primary_area": "",
        "author": "Preston Culbertson;Saptarshi Bandyopadhyay;Mac Schwager;Preston Culbertson;Saptarshi Bandyopadhyay;Mac Schwager",
        "authorids": "/37086321694;/37927592300;/37424620600;/37086321694;/37927592300;/37424620600",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Aeronautics and Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968246/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9917865422813734443&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.stanford.edu;https://www.caltech.edu",
        "aff_unique_abbr": "Stanford;Caltech",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967686",
        "title": "Multi-Sensor 6-DoF Localization For Aerial Robots In Complex GNSS-Denied Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The need for robots autonomously navigating in more and more complex environments has motivated intense R& D efforts in making robot pose estimation more accurate and reliable. This paper presents a multi-sensor multi-hypothesis method for robust 6-DoF localization in complex environments. Robustness and accuracy requirements are addressed as follows. First, camera and LIDAR features are seamlessly integrated in the same statistical framework, benefiting from their synergies and providing robustness in scenarios with low or varying densities of LIDAR and visual features. Second, a multi-hypothesis approach is adopted to cope with scenario symmetries. The method has been carefully designed to operate in real time using feature and hypothesis filtering and efficient hypothesis refinement, and has been coded in a multi-core implementation. The proposed method has been extensively validated for closed-loop aerial robot navigation in different urban and industrial scenarios and has shown advantages over well-known single-sensor techniques.",
        "primary_area": "",
        "author": "J.L. Paneque;J.R. Mart\u00ednez-de Dios;A. Ollero;J.L. Paneque;J.R. Mart\u00ednez-de Dios;A. Ollero",
        "authorids": "/37086449695;/38303554600;/37265412000;/37086449695;/38303554600;/37265412000",
        "aff": "Robotics, Vision and Control Group, University of Seville, Seville, Spain; Robotics, Vision and Control Group, University of Seville, Seville, Spain; Robotics, Vision and Control Group, University of Seville, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967686/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1492178180496700567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "Robotics, Vision and Control Group",
        "aff_unique_url": "https://www.us.seville.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968442",
        "title": "Multi-Vehicle Cooperative Local Mapping Using Split Covariance Intersection Filter",
        "track": "main",
        "status": "Poster",
        "abstract": "Local mapping plays an important role in outdoor intelligent vehicle applications and multi-vehicle cooperative local mapping which takes advantage of vehicular communication can bring considerable benefits to this important task. In this paper, a multi-vehicle cooperative local mapping architecture using split covariance intersection filter (Split CIF) is proposed. In the proposed method, a vehicle can flexibly perform cooperative local mapping with other vehicles in decentralized way, without complicated monitoring and controlling of data flow among vehicles; fused maps can be shared freely among vehicles. An efficient and accurate implementation of the Split CIF is also introduced. A simulation-based comparative study demonstrates the potential and advantage of the proposed multi-vehicle cooperative local mapping architecture using Split CIF.",
        "primary_area": "",
        "author": "Hao Li;Ming Yang;Hao Li;Ming Yang",
        "authorids": "/37600684200;/37576820400;/37600684200;/37576820400",
        "aff": "Department of Automation, Shanghai Jiao Tong University (SJTU), Shanghai, China; Department of Automation, Shanghai Jiao Tong University (SJTU), Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968442/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15039704027331416002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967926",
        "title": "Multi-controller multi-objective locomotion planning for legged robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Different legged robot locomotion controllers offer different advantages; from speed of motion to energy, computational demand, safety and others. In this paper we propose a method for planning locomotion with multiple controllers and sub-planners, explicitly considering the multi-objective nature of the legged locomotion planning problem. The planner first obtains body paths extended with a choice of controller or sub-planner, and then fills the gaps by sub-planning. The method leads to paths with a mix of static and dynamic walking which only plan footsteps where necessary. We show that our approach is faster than pure footstep planning methods both in computation (2x) and mission time (1.4x), and safer than pure dynamic-walking methods. In addition, we propose two methods for aggregating the multiple objectives in search-based planning and reach desirable trade-offs without weight tuning. We show that they reach desirable Pareto-optimal solutions up to 8x faster than fairly-tuned traditional weighted-sum methods. Our conclusions are drawn from a combination of planning, physics simulation, and real robot experiments.",
        "primary_area": "",
        "author": "Martim Brand\u00e3o;Maurice Fallon;Ioannis Havoutis;Martim Brand\u00e3o;Maurice Fallon;Ioannis Havoutis",
        "authorids": "/38542529000;/37540365100;/37542879900;/38542529000;/37540365100;/37542879900",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967926/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11497997837110781439&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968294",
        "title": "Multi-step Pick-and-Place Tasks Using Object-centric Dense Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an object-centric method for efficiently performing two types of challenging pick-and-place tasks, namely sequential pick and place and object sorting. We propose multiclass dense object nets (MCDONs) for learning object-centric dense descriptors that maintain not only intra-class variations but also inter-class separation. Intra-class consistency is also inherently learned and is useful for our pick-and-place tasks. All the tasks only require a single demonstration from users, which can then be generalized to all class instances. A dataset containing eight classes and a total of 52 objects was provided in this study. We obtained a task success rate of 93.33% on a five-block stacking task and 97.41% on a three-class object sorting task.",
        "primary_area": "",
        "author": "Chun-Yu Chai;Keng-Fu Hsu;Shiao-Li Tsao;Chun-Yu Chai;Keng-Fu Hsu;Shiao-Li Tsao",
        "authorids": "/37087322536;/37087324928;/37301980000;/37087322536;/37087324928;/37301980000",
        "aff": "Department of Computer Science and Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science and Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science and Engineering, National Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968294/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8978486290405427880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NCTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968489",
        "title": "Multicamera 3D Reconstruction of Dynamic Surgical Cavities: Non-Rigid Registration and Point Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable objects and surfaces are ubiquitous in the daily lives of humans - from the garments in fashion to soft tissues within the body. Because of this routine interaction with soft materials, humans are adept and trained in manipulation of deformable objects while avoiding irreversible damage. The dexterity and care involved is largely facilitated through a combination of the human haptic sense of touch and visual observations of object deformation [1]. While this scenario presents itself as a trivially intuitive task, it becomes significantly more difficult and complex with the deprivation of both 3D depth perception and haptic senses. This deprived state is not dissimilar to the scenarios encountered in many robot-assisted minimally invasive surgeries. As a result, unintentional tissue damage can occur due to lack of force feedback and fine 3D visibility [2]. One approach to remediate these issues combines real-time dynamic 3D reconstruction and vision-based force estimation for haptic feedback. Toward that end, this work continues research in a series of studies focusing on multicamera 3D reconstruction of dynamic surgical cavities. Previous work introduced a novel approach of camera grouping and pair sequencing [3]. This paper builds upon that work by introducing a method for non-rigid, sparse point cloud registration and subsequent point classification. In particular, to enable deformation and force analyses, surfaces are locally classified into three categories: static, shifting and deforming. The topics addressed in this paper present open challenges and ongoing research directions for researchers to this day [4], and provide a step towards real-time 3D reconstruction and force feedback in robot-assisted surgery.",
        "primary_area": "",
        "author": "Yun-Hsuan Su;Kevin Huang;Blake Hannaford;Yun-Hsuan Su;Kevin Huang;Blake Hannaford",
        "authorids": "/37086366130;/37085541904;/37272234100;/37086366130;/37085541904;/37272234100",
        "aff": "Department of Electrical and Computer Engineering, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, University of Washington, Seattle, WA, USA; Dept. of Engineering, 300 Summit St, Trinity College, Hartford, CT, USA; Department of Electrical and Computer Engineering, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968489/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14885951047066822526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Washington;Trinity College",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Dept. of Engineering",
        "aff_unique_url": "https://www.washington.edu;https://www.trincoll.edu",
        "aff_unique_abbr": "UW;Trinity College",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Seattle;Hartford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968090",
        "title": "Multilevel Incremental Roadmap Spanners for Reactive Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating robot motions from a precomputed graph has proven to be an effective approach to solving many motion planning problems. After their generation, roadmaps reduce complex motion planning problems to that of solving a graph-based shortest path. However, generating the graph can involve tradeoffs, such as how sparse or dense to make the graph. Sparse graphs may not provide enough options to navigate around a new obstacle or may result in grossly suboptimal motions. Dense graphs may take too long to search and result in an unresponsive robot. In this paper we present an algorithm that generates a graph with multiple sparse levels- the sparsest level can be searched quickly, while the densest level allows for asymptotically optimal motions. With the paired multilevel shortest path algorithm, after the robot computes an initial solution, it can then incrementally refine the shortest-path as time allows. We demonstrate the algorithms on an articulated robot with 8 degrees of freedom, having them compute an initial solution in a fraction of the time required for a full graph search, and subsequently, incrementally refine the solution to the optimal shortest path from the densest level of the graph.",
        "primary_area": "",
        "author": "Jeffrey Ichnowski;Ron Alterovitz;Jeffrey Ichnowski;Ron Alterovitz",
        "authorids": "/38541287200;/37320259800;/38541287200;/37320259800",
        "aff": "Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968090/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17447535811859705599&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of North Carolina",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unc.edu",
        "aff_unique_abbr": "UNC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chapel Hill",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968171",
        "title": "Multimodal Uncertainty Reduction for Intention Recognition in Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive robots can potentially improve the quality of life and personal independence of elderly people by supporting everyday life activities. To guarantee a safe and intuitive interaction between human and robot, human intentions need to be recognized automatically. As humans communicate their intentions multimodally, the use of multiple modalities for intention recognition may not just increase the robustness against failure of individual modalities but especially reduce the uncertainty about the intention to be recognized. This is desirable as particularly in direct interaction between robots and potentially vulnerable humans a minimal uncertainty about the situation as well as knowledge about this actual uncertainty is necessary. Thus, in contrast to existing methods, in this work a new approach for multimodal intention recognition is introduced that focuses on uncertainty reduction through classifier fusion. For the four considered modalities speech, gestures, gaze directions and scene objects individual intention classifiers are trained, all of which output a probability distribution over all possible intentions. By combining these output distributions using the Bayesian method Independent Opinion Pool [1] the uncertainty about the intention to be recognized can be decreased. The approach is evaluated in a collaborative human-robot interaction task with a 7-DoF robot arm. The results show that fused classifiers, which combine multiple modalities, outperform the respective individual base classifiers with respect to increased accuracy, robustness, and reduced uncertainty.",
        "primary_area": "",
        "author": "Susanne Trick;Dorothea Koert;Jan Peters;Constantin A. Rothkopf;Susanne Trick;Dorothea Koert;Jan Peters;Constantin A. Rothkopf",
        "authorids": "/37086599960;/37085651782;/37533077600;/37888864900;/37086599960;/37085651782;/37533077600;/37888864900",
        "aff": "Psychology of Information Processing, TU Darmstadt, Germany; Centre for Cognitive Science, TU Darmstadt, Germany; Centre for Cognitive Science, TU Darmstadt, Germany; Psychology of Information Processing, TU Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968171/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13803275209060660161&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Psychology of Information Processing",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TU Darmstadt",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968468",
        "title": "Near-contact grasping strategies from awkward poses: When simply closing your fingers is not enough",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping a simple object from the side is easy \u2014 unless the object is almost as big as the hand or space constraints require positioning the robot hand awkwardly with respect to the object. We show that humans \u2014 when faced with this challenge \u2014 adopt coordinated finger movements which enable them to successfully grasp objects even from these awkward poses. We also show that it is relatively straight forward to implement these strategies autonomously. Our human-studies approach asks participants to perform grasping task by either \u201cpuppetteering\u201d a robotic manipulator that is identical (geometrically and kinematically) to a popular underactuated robotic manipulator (the Barrett hand), or using sliders to control the original Barrett hand. Unlike previous studies, this enables us to directly capture and compare human manipulation strategies with robotic ones. Our observation is that, while humans employ underactuation, how they use it is fundamentally different (and more effective) than that found in existing hardware.",
        "primary_area": "",
        "author": "Yi Herng Ong;John Morrow;Yu Qiu;Kartik Gupta;Ravi Balasubramanian;Cindy Grimm;Yi Herng Ong;John Morrow;Yu Qiu;Kartik Gupta;Ravi Balasubramanian;Cindy Grimm",
        "authorids": "/37086582239;/37085793315;/37087322106;/37089612483;/37399991400;/37085798146;/37086582239;/37085793315;/37087322106;/37089612483;/37399991400;/37085798146",
        "aff": "Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon; Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon; Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon; Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon; Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon; Collaborative Robotics and Intelligent Systems, Oregon State University, Corvallis, Oregon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968468/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4055242810942545144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968580",
        "title": "Neural Control with an Artificial Hormone System for Energy-Efficient Compliant Terrain Locomotion and Adaptation of Walking Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to use walking robots for exploration in a real complex environment, an adaptive control system is required to allow them to successfully and efficiently traverse the terrains. To achieve this, we propose here our adaptive locomotion control technique of a walking robot. It is based on a modular structure, combining neural control with an artificial hormone system. The neural control coordinates all leg joints of the robot and generates its locomotion with various insect-like gaits. In parallel, the artificial hormone system uses the motor commands from the neural control and foot contact feedback to estimate the walking state and automatically adapt the joint movements with respect to the terrain. The adaptability is quickly achieved in an online manner within a few seconds. Robot walking experiments show that this adaptive control technique enables a six-legged robot to adapt to various difficult terrains with energy efficiency. Such terrains include sand (loose ground), sponge with different softness levels (soft/compliant ground), grass (vegetated ground), and floor/pavement (hard ground). The technique does not require robot kinematics or an environmental model; and can, therefore, be potentially applied to different legged robots to achieve stable online adaptation and energy-efficient locomotion on unpredictable (compliant) terrains.",
        "primary_area": "",
        "author": "Jettanan Homchanthanakul;Potiwat Ngamkajornwiwat;Pitiwut Teerakittikul;Poramate Manoonpong;Jettanan Homchanthanakul;Potiwat Ngamkajornwiwat;Pitiwut Teerakittikul;Poramate Manoonpong",
        "authorids": "/37087323194;/37086331970;/37641618500;/37295679400;/37087323194;/37086331970;/37641618500;/37295679400",
        "aff": "School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, Bangkok, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, Bangkok, Thailand; School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, Thailand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968580/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17915499621372804242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Vidyasirimedhi Institute of Science and Technology;King Mongkut\u2019s University of Technology Thonburi",
        "aff_unique_dep": "School of Information Science and Technology;Institute of Field Robotics",
        "aff_unique_url": ";http://www.kmutt.ac.th",
        "aff_unique_abbr": ";KMUTT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Bangkok",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Thailand"
    },
    {
        "id": "8967689",
        "title": "Neural Network Based Heterogeneous Sensor Fusion for Robot Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a neural network based heterogeneous sensor fusion approach towards real-time traversability estimation of mobile robots using sensor data. Even though significant advances have been made for autonomous navigation in structured terrain conditions, obtaining reliable traversability estimates for tracked vehicle navigation in challenging terrain conditions is still an open research problem. In this regard, we propose a neural network architecture capable of fusing depth images along with roll and pitch measurements on board the robot to perform traversability estimation. The proposed architecture is trained in a variety of simulated structured and unstructured environments. As such, the proposed architecture is capable of extracting the relevant features from the sensor measurements in a data driven manner as compared to existing heuristic based approaches that fail to generalize for different environmental conditions. The reliability of the traversability estimates provided by the trained architecture was validated in indoor and outdoor conditions using real sensor data. In addition, the feasibility of using the traversability estimates in incremental path planning was also demonstrated through simulation. For both applications the proposed approach provided compelling results. Inferences based on the results of the experiments along with directions for future research are also outlined.",
        "primary_area": "",
        "author": "Bijo Sebastian;Hailin Ren;Pinhas Ben-Tzvi;Bijo Sebastian;Hailin Ren;Pinhas Ben-Tzvi",
        "authorids": "/37087244372;/37086809683;/38277770000;/37087244372;/37086809683;/38277770000",
        "aff": "Department of Mechanical Engineering, Virginia Tech Blacksburg, Virginia, USA; Department of Mechanical Engineering, Virginia Tech Blacksburg, Virginia, USA; Department of Mechanical Engineering, Virginia Tech Blacksburg, Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967689/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18302312485028152248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968089",
        "title": "Neural Path Planning: Fixed Time, Near-Optimal Path Generation via Oracle Imitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and efficient path generation is critical for robots operating in complex environments. This motion planning problem is often performed in a robot's actuation or configuration space, where popular pathfinding methods such as A*, RRT*, get exponentially more computationally expensive to execute as the dimensionality increases or the spaces become more cluttered and complex. On the other hand, if one were to save the entire set of paths connecting all pair of locations in the configuration space a priori, one would run out of memory very quickly. In this work, we introduce a novel way of producing fast and optimal motion plans for static environments by using a stepping neural network approach, called OracleNet. OracleNet uses Recurrent Neural Networks to determine end-to-end trajectories in an iterative manner that implicitly generates optimal motion plans with minimal loss in performance in a compact form. The algorithm is straightforward in implementation while consistently generating near-optimal paths in a single, iterative, end-to-end roll-out. In practice, OracleNet generally has fixed-time execution regardless of the configuration space complexity while outperforming popular pathfinding algorithms in complex environments and higher dimensions1.",
        "primary_area": "",
        "author": "Mayur J. Bency;Ahmed H. Qureshi;Michael C. Yip;Mayur J. Bency;Ahmed H. Qureshi;Michael C. Yip",
        "authorids": "/37086934449;/37086070898;/37085382768;/37086934449;/37086070898;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968089/",
        "gs_citation": 102,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2062017188379641664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968608",
        "title": "Neural-Learning Trajectory Tracking Control of Flexible-Joint Robot Manipulators with Unknown Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and precise motion control is important for industrial robots in manufacturing applications. However, some collaborative robots sacrifice precision for safety, particular for high motion speed. The performance degradation is caused by the inability of the joint servo controller to address the uncertain nonlinear dynamics of the robot arm, e.g., due to joint flexibility. We consider two approaches to improve the trajectory tracking performance through feedforward compensation. The first approach uses iterative learning control, with the gradient-based iterative update generated from the robot forward dynamics model. The second approach uses dynamic inversion to directly compensate for the robot forward dynamics. If the forward dynamics is strictly proper or is non-minimum-phase (e.g., due to time delays), its stable inverse would be non-causal. Both approaches require robot dynamical models. This paper presents results of using recurrent neural networks (RNNs) to approximate these dynamical models - forward dynamics in the first case, inverse dynamics (possibly non-causal) in the second case. We use the bi-directional RNN to capture the noncausality. The RNNs are trained based on a collection of commanded trajectories and the actual robot responses. We use a Baxter robot to evaluate the two approaches. The Baxter robot exhibits significant joint flexibility due to the series-elastic joint actuators. Both approaches achieve sizable improvement over the uncompensated robot motion, for both random joint trajectories and Cartesian motion. The inverse dynamics method is particularly attractive as it may be used to more accurately track a user input as in teleoperation.",
        "primary_area": "",
        "author": "Shuyang Chen;John T. Wen;Shuyang Chen;John T. Wen",
        "authorids": "/37086359141;/37278935000;/37086359141;/37278935000",
        "aff": "Department of Mechanical, Aerospace, and Nuclear Engineering, Rensselaer Polytechnic Institute 110 8th St, Troy, NY, USA; Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968608/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11631704115405933178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute",
        "aff_unique_dep": "Department of Mechanical, Aerospace, and Nuclear Engineering",
        "aff_unique_url": "https://www.rpi.edu",
        "aff_unique_abbr": "RPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Troy",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967985",
        "title": "Non-Uniform Robot Densities in Vibration Driven Swarms Using Phase Separation Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "In robot swarms operating under highly restrictive sensing and communication constraints, individuals may need to use direct physical proximity to facilitate information exchange. However, in certain task-related scenarios, this requirement might conflict with the need for robots to spread out in the environment, e.g., for distributed sensing or surveillance applications. This paper demonstrates how a swarm of minimally-equipped robots can form high-density robot aggregates that coexist with lower robot densities in space. We envision a scenario where a swarm of vibration-driven robots-which sit atop bristles and achieve directed motion by vibrating them-move randomly in an environment while colliding with each other. Theoretical techniques from the study of far-from-equilibrium collectives and statistical mechanics clarify the mechanisms underlying the formation of these high and low density regions. Specifically, we capitalize on a transformation that connects the collective properties of a system of self-propelled particles with that of a well-studied molecular fluid system, thereby inheriting the rich theory of equilibrium thermodynamics. Real robot experiments as well as simulations illustrate how inter-robot collisions can precipitate the formation of non-uniform robot densities in a closed and bounded region.",
        "primary_area": "",
        "author": "Siddharth Mayya;Gennaro Notomista;Dylan Shell;Seth Hutchinson;Magnus Egerstedt;Siddharth Mayya;Gennaro Notomista;Dylan Shell;Seth Hutchinson;Magnus Egerstedt",
        "authorids": "/37085621013;/37085607644;/37269198900;/37282386200;/37269707500;/37085621013;/37085607644;/37269198900;/37282386200;/37269707500",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967985/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15472379597556817281&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Texas A&M University",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.tamu.edu",
        "aff_unique_abbr": "Georgia Tech;TAMU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Atlanta;College Station",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967769",
        "title": "Non-myopic Planetary Exploration Combining In Situ and Remote Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Remote sensing measurements can provide crucial information about the material properties of a planetary surface but their application is limited by their spatial resolution, typically tens of meters per pixel, when constituent materials are mixed at much finer scale. Consequently the orbital observations must be validated with in situ measurements from a spectrometer on the ground. In planetary exploration this means that a rover must visit selected locations that jointly improve a model of the environment and satisfy mobility and sampling constraints. Conventional planning methods used in this situation follow sub-optimal greedy strategies that are not scalable to large areas. We show how the problem can be effectively defined in a Markov Decision Process framework and propose a planning algorithm based on Monte Carlo Tree Search, which is efficient but devoid of these drawbacks thereby providing superior performance. We evaluate our approach using hyperspectral imagery of a well-studied geologic site in Cuprite, Nevada.",
        "primary_area": "",
        "author": "Suhit Kodgule;Alberto Candela;David Wettergreen;Suhit Kodgule;Alberto Candela;David Wettergreen",
        "authorids": "/37087322897;/37086316796;/37270533700;/37087322897;/37086316796;/37270533700",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967769/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3258762048274327301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968209",
        "title": "Non-parametric Mixed-Manifold Products using Multiscale Kernel Densities",
        "track": "main",
        "status": "Poster",
        "abstract": "We extend the core operation of non-parametric belief propagation (NBP), also known as multi-scale sequential Gibbs sampling, to approximate products of kernel density estimated beliefs that reside on some manifold. The original algorithm, though multidimensional, implicitly assumes the beliefs to reside on the Euclidean \\mathbb{R}^{d}\\mathbb{R}^{d} space only. The proposed extension generalizes to any mixture of Riemannian manifolds, provided the primary operations\u2014addition and subtraction\u2014 are defined. Our motivation is primarily focused on state-estimation using non-Gaussian factor graphs for multimodal simultaneous localization and mapping in robotics. The paper presents the method as well as simulation and experimental results for validation. Our implementation is publicly available and allows for expansion with user-defined manifold mixtures.",
        "primary_area": "",
        "author": "Dehann Fourie;Pedro Vaz Teixeira;John Leonard;Dehann Fourie;Pedro Vaz Teixeira;John Leonard",
        "authorids": "/37670490400;/37089939750;/37329387400;/37670490400;/37089939750;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, USA; Mechanical Engineering Department, MIT, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968209/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16376014936114242033&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968229",
        "title": "Nonlinear optimization of Step Duration and Step Location",
        "track": "main",
        "status": "Poster",
        "abstract": "The modulation of step location and duration plays an important role in realizing robust bipedal walking. This paper formulates it as a nonlinear programming problem (NLP) and proposes a novel optimization approach to adjust step location and duration in real time. Based on state feedback, the Linear Inverted Pendulum dynamics is exploited to determine the optimal step parameters. Different from previous works, this work presents three main characteristics: i) the hyperbolic functions of step duration rather than the step duration itself are chosen to be optimization variables; ii) the approach can be switched from baseline two-steps-prediction optimization to one-step-prediction optimization through merely adding several equality constraints in problem formulation; iii) the approach can deal with relative step location tracking (velocity tracking) or absolute step location tracking (position tracking) via changing the reference step parameters. As a result, the first characteristic enables the NLP to be solved in a computational-efficient manner and the latter two endow the approach with versatility under different control modes. The effectiveness has been demonstrated by simulation experiments.",
        "primary_area": "",
        "author": "Jiatao Ding;Xiaohui Xiao;Nikos Tsagarakis;Jiatao Ding;Xiaohui Xiao;Nikos Tsagarakis",
        "authorids": "/37086353143;/37530896000;/37295830800;/37086353143;/37530896000;/37295830800",
        "aff": "Wuhan, Hubei Province, P. R. China; Wuhan, Hubei Province, P. R. China; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, via Morego, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968229/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17105013524019155788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Wuhan University;Istituto Italiano di Tecnologia",
        "aff_unique_dep": ";Humanoid and Human Centered Mechatronics Research Line",
        "aff_unique_url": "http://www.whu.edu.cn/;https://www.iit.it",
        "aff_unique_abbr": "WHU;IIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "8967876",
        "title": "Normal Distribution Mixture Matching based Model Free Object Tracking Using 2D LIDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel normal distribution mixture matching based model free object tracking algorithm using 2D LIDAR is proposed. Each target object is modeled as a normal distribution mixture that captures the distribution of the points scanned from the surface of the object. This novel representation enables normal distribution transform (NDT) to accurately estimate the motion of objects, even if the shape of the points differs depending on where it is observed. Our evaluation of the proposed algorithm shows good performance in practical applications. In addition, we provides an alternative way of segmentation and data association using occupancy grid map to avoid a problem that defines a distance metric between the mixture and the point cloud. As a result, the proposed algorithm works in real time in our experiments.",
        "primary_area": "",
        "author": "Baehoon Choi;HyungGi Jo;Euntai Kim;Baehoon Choi;HyungGi Jo;Euntai Kim",
        "authorids": "/37597868600;/37085471736;/37277101900;/37597868600;/37085471736;/37277101900",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967876/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5905228422985449218&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yonsei University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.yonsei.ac.kr",
        "aff_unique_abbr": "Yonsei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967572",
        "title": "ORBSLAM-Atlas: a robust and accurate multi-map system",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose ORBSLAM-Atlas, a system able to handle an unlimited number of disconnected sub-maps, that includes a robust map merging algorithm able to detect submaps with common regions and seamlessly fuse them. The outstanding robustness and accuracy of ORBSLAM are due to its ability to detect wide-baseline matches between keyframes, and to exploit them by means of non-linear optimization, however it only can handle a single map. ORBSLAM-Atlas brings the wide-baseline matching detection and exploitation to the multiple map arena. The result is a SLAM system significantly more general and robust, able to perform multisession mapping. If tracking is lost during exploration, instead of freezing the map, a new sub-map is launched, and it can be fused with the previous map when common parts are visited. Our criteria to declare the camera lost contrast with previous approaches that simply count the number of tracked points, we propose to discard also inaccurately estimated camera poses due to bad geometrical conditioning. As a result, the map is split into more accurate sub-maps, that are eventually merged in a more accurate global map, thanks to the multi-mapping capabilities.We provide extensive experimental validation in the EuRoC datasets, where ORBSLAM-Atlas obtains accurate monocular and stereo results in the difficult sequences where ORBSLAM failed. We also build global maps after multiple sessions in the same room, obtaining the best results to date, between 2 and 3 times more accurate than competing multi-map approaches. We also show the robustness and capability of our system to deal with dynamic scenes, quantitatively in the EuRoC datasets and qualitatively in a densely populated corridor where camera occlusions and tracking losses are frequent.",
        "primary_area": "",
        "author": "Richard Elvira;Juan D. Tard\u00f3s;J.M.M. Montiel;Richard Elvira;Juan D. Tard\u00f3s;J.M.M. Montiel",
        "authorids": "/37087322668;/37351680900;/37274019300;/37087322668;/37351680900;/37274019300",
        "aff": "Instituto de Investigation en ingeniena de Aragon (I3A), Universidad de Zaragoza, Spain; Instituto de Investigation en ingeniena de Aragon (I3A), Universidad de Zaragoza, Spain; Instituto de Investigation en ingeniena de Aragon (I3A), Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967572/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1176818325138029501&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968094",
        "title": "OREOS: Oriented Recognition of 3D Point Clouds in Outdoor Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a novel method for oriented place recognition with 3D LiDAR scans. A Convolutional Neural Network is trained to extract compact descriptors from single 3D LiDAR scans. These can be used both to retrieve near-by place candidates from a map, and to estimate the yaw discrepancy needed for bootstrapping local registration methods. We employ a triplet loss function for training and use a hard-negative mining strategy to further increase the performance of our descriptor extractor. In an extensive evaluation on the NCLT and KITTI datasets, we demonstrate that our method outperforms related state-of-the-art approaches based on both data-driven and handcrafted data representation in challenging long-term outdoor conditions.",
        "primary_area": "",
        "author": "Lukas Schaupp;Mathias B\u00fcrki;Renaud Dub\u00e9;Roland Siegwart;Cesar Cadena;Lukas Schaupp;Mathias B\u00fcrki;Renaud Dub\u00e9;Roland Siegwart;Cesar Cadena",
        "authorids": "/37089136088;/37085496641;/37085782572;/37281398300;/37593590400;/37089136088;/37085496641;/37085782572;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab (ASL), ETH Z\u00fcrich, Switzerland; Autonomous Systems Lab (ASL), ETH Z\u00fcrich, Switzerland; Autonomous Systems Lab (ASL), ETH Z\u00fcrich, Switzerland; Autonomous Systems Lab (ASL), ETH Z\u00fcrich, Switzerland; Autonomous Systems Lab (ASL), ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968094/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17074576065504859028&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab (ASL)",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967732",
        "title": "Object Placement Planning and optimization for Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of planning the placement of a rigid object with a dual-arm robot in a cluttered environment. In this task, we need to locate a collision-free pose for the object that a) facilitates the stable placement of the object, b) is reachable by the robot and c) optimizes a user-given placement objective. In addition, we need to select which robot arm to perform the placement with. To solve this task, we propose an anytime algorithm that integrates sampling-based motion planning with a novel hierarchical search for suitable placement poses. Our algorithm incrementally produces approach motions to stable placement poses, reaching placements with better objective as runtime progresses. We evaluate our approach for two different placement objectives, and observe its effectiveness even in challenging scenarios.",
        "primary_area": "",
        "author": "Joshua A. Haustein;Kaiyu Hang;Johannes Stork;Danica Kragic;Joshua A. Haustein;Kaiyu Hang;Johannes Stork;Danica Kragic",
        "authorids": "/37085453695;/37085393148;/37544515300;/37281296000;/37085453695;/37085393148;/37544515300;/37281296000",
        "aff": "Division of Robotics, Perception and Learning (RPL), CAS, CSC, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Mechanical Engineering and Material Science, Yale University, New Haven, USA; Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, \u00d6rebro, Sweden; Division of Robotics, Perception and Learning (RPL), CAS, CSC, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967732/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16739111467682288888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Yale University;\u00d6rebro University",
        "aff_unique_dep": "Division of Robotics, Perception and Learning (RPL);Department of Mechanical Engineering and Material Science;Center for Applied Autonomous Sensor Systems (AASS)",
        "aff_unique_url": "https://www.kth.se;https://www.yale.edu;https://www.oru.se",
        "aff_unique_abbr": "KTH;Yale;\u00d6rebro U",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Stockholm;New Haven;\u00d6rebro",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "8967830",
        "title": "Object Proposal Algorithms in the Wild: Are they Generalizable to Robot Perception?",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent emergence of object proposal algorithms in the computer vision community shows great promise to addressing difficult problems in robotic such as object discovery and salient object detection. However, it is difficult to determine how these algorithms actually perform for real-world robot vision applications, because the standard evaluation protocol uses datasets which do not adequately account for real-world noise (motion blur, occlusion, etc.). We evaluated several state-of-the-art object proposal algorithms using naturalistic datasets from the robotics community, and found a substantial performance drop across all algorithms. This suggests that many object proposal algorithms are not as generalizable as the computer vision literature purports, which can have a significant impact on how they are applied to robotics. We also conducted a study on how each algorithm is influenced by specific kinds of real-world robot vision challenges, including variable brightness, gamma correction, Gaussian blur, and Gaussian noise. Our results provide insight into certain weaknesses of object proposal algorithms, which can be used to gauge how they might be suitable for different robotics applications. It is our intent that this work will motivate future research about how to design more flexible and robust object proposal algorithms for the robotics community.",
        "primary_area": "",
        "author": "Darren M. Chan;Laurel D. Riek;Darren M. Chan;Laurel D. Riek",
        "authorids": "/37086312070;/38548291500;/37086312070;/38548291500",
        "aff": "Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967830/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3746205906720787222&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967548",
        "title": "Object Rearrangement with Nested Nonprehensile Manipulation Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of rearrangement planning, i.e finding a sequence of manipulation actions that displace multiple objects from an initial configuration to a given goal configuration. Rearrangement is a critical skill for robots so that they can effectively operate in confined spaces that contain clutter. Examples of tasks that require rearrangement include packing objects inside a bin, wherein objects need to lay according to a predefined pattern. In tight bins, collision-free grasps are often unavailable. Nonprehensile actions, such as pushing and sliding, are preferred because they can be performed using minimalistic end-effectors that can easily be inserted in the bin. Rearrangement with nonprehensile actions is a challenging problem as it requires reasoning about object interactions in a combinatorially large configuration space of multiple objects. This work revisits several existing rearrangement planning techniques and introduces a new one that exploits nested nonprehensile actions by pushing several similar objects simultaneously along the same path, which removes the need to rearrange each object individually. Experiments in simulation and using a real Kuka robotic arm show the ability of the proposed approach to solve difficult rearrangement tasks while reducing the length of the end-effector's trajectories.",
        "primary_area": "",
        "author": "Changkyu Song;Abdeslam Boularias;Changkyu Song;Abdeslam Boularias",
        "authorids": "/37086556487;/37542596800;/37086556487;/37542596800",
        "aff": "Department of Computer Science of Rutgers, University, Piscataway, New Jersey, USA; Department of Computer Science of Rutgers, University, Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967548/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=260363867034782410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968077",
        "title": "Object Singulation by Nonlinear Pushing for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we aim at grasping a single target object in a cluttered environment using a robotic arm. While dexterous grasp for various shapes of objects is not considered in this work, we focus on developing the method to mitigate clutter near the target object as soon as quickly. For this purpose, we propose a method to generate nonlinear pushing motions for object singulation based on an off-the-shelf machine learning algorithm and a typical semantic segmentation algorithm. Through experiments, we show that the success rate of robotic grasping is considerably improved by the proposed pushing behavior. And notably, the nonlinear pushing trajectories allows the robot to perform singulation of the target object in a cluttered environment with fewer trials than linear pushing usually pursued in related works.",
        "primary_area": "",
        "author": "Jongsoon Won;Youngbin Park;Byung-Ju Yi;Il Hong Suh;Jongsoon Won;Youngbin Park;Byung-Ju Yi;Il Hong Suh",
        "authorids": "/37087322504;/37600943000;/37273970700;/37385851500;/37087322504;/37600943000;/37273970700;/37385851500",
        "aff": "Department of Electronics and Computer Engineering, Hanyang University, Korea; Department of Electronics and Computer Engineering, Hanyang University, Korea; Department of Electronic Systems Engineering, Hanyang University, Korea; Division of Computer Science and Engineering, College of Engineering, Hanyang University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968077/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14114727204342443935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hanyang University",
        "aff_unique_dep": "Department of Electronics and Computer Engineering",
        "aff_unique_url": "http://www.hanyang.ac.kr",
        "aff_unique_abbr": "HYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968057",
        "title": "Observability Analysis of Position Estimation for Quadrotors With Modified Dynamics and Range Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "This study performs a nonlinear observability analysis on range assisted inertial navigation system (INS) for quadrotor micro-aerial vehicles (MAV). The INS is formulated incorporating the quadrotor dynamics with aerodynamic drag forces. The observability analysis is carried out for cases where three and two range measurements are available. The analysis facilitates the range assisted localization of MAVs when there are less than four range measurements are available. The primary objective of this study is to identify the conditions under which the INS becomes unobservable, and these conditions are validated through numerical simulation. The main contributions of this paper are as follows, 1. Nonlinear observability analysis of the range assisted INS for quadrotor MAVs. 2. Theoretical derivation and numerical validation of unobservable conditions for three and two range cases. 3. Experimental validations of estimator performance.",
        "primary_area": "",
        "author": "Eranga Fernando;Oscar De Silva;George K.I. Mann;Raymond G. Gosine;Eranga Fernando;Oscar De Silva;George K.I. Mann;Raymond G. Gosine",
        "authorids": "/37087323164;/37086935138;/37295686400;/37293905000;/37087323164;/37086935138;/37295686400;/37293905000",
        "aff": "Faculty of Engineering and Applied Sciences, Memorial University of Newfoundland, St. John\u2019s, NL, Canada; Faculty of Engineering and Applied Sciences, Memorial University of Newfoundland, St. John\u2019s, NL, Canada; Faculty of Engineering and Applied Sciences, Memorial University of Newfoundland, St. John\u2019s, NL, Canada; Faculty of Engineering and Applied Sciences, Memorial University of Newfoundland, St. John\u2019s, NL, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968057/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2365707470021327761&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Memorial University of Newfoundland",
        "aff_unique_dep": "Faculty of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "St. John\u2019s",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8967605",
        "title": "Obstacle Avoidance using a Capacitive Skin for Safe Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper describes a control framework using a capacitive skin for advanced and safe human-robot interactions. The skin consists of high density capacitive sensors which are able to detect objects at close distance. We propose a multitask kinematic control scheme which manages at once the control task of the end-effector and the obstacle avoidance task by using the capacitive skin measurements. To solve the multiobjective problem, a Weight-Prioritized solution based on a QP formalism is adopted. The robustness of the kinematic controller is enhanced by adding a local joint reconfiguration when the robot moves close to a singularity. Experimental results on manipulator arm equipped with the capacitive sensors are presented in realistic situations of human-robot interactions.",
        "primary_area": "",
        "author": "Kamal-Eddine M\u2019Colo;Bruno Luong;Andr\u00e9 Crosnier;Christian N\u00e9el;Philippe Fraisse;Kamal-Eddine M\u2019Colo;Bruno Luong;Andr\u00e9 Crosnier;Christian N\u00e9el;Philippe Fraisse",
        "authorids": "/37087321775;/37087323809;/37658453200;/37087323652;/37296822200;/37087321775;/37087323809;/37658453200;/37087323652;/37296822200",
        "aff": "LIRMM, University of Montpellier, UMR 5506 CNRS, Montpellier, France; Company FOGALE robotics, N\u00eemes, France; LIRMM, University of Montpellier, UMR 5506 CNRS, Montpellier, France; Company FOGALE robotics, N\u00eemes, France; LIRMM, University of Montpellier, UMR 5506 CNRS, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967605/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7498149666789031635&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Montpellier;FOGALE robotics",
        "aff_unique_dep": "LIRMM;",
        "aff_unique_url": "https://www.univ-montp2.fr;",
        "aff_unique_abbr": "UM;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montpellier;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967827",
        "title": "Occlusion-robust Deformable Object Tracking without Physics Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the state of a deformable object is crucial for robotic manipulation, yet accurate tracking is challenging when the object is partially-occluded. To address this problem, we propose an occlusion-robust RGBD sequence tracking framework based on Coherent Point Drift (CPD). To mitigate the effects of occlusion, our method 1) Uses a combination of locally linear embedding and constrained optimization to regularize the output of CPD, thus enforcing topological consistency when occlusions create disconnected pieces of the object; 2) Reasons about the free-space visible by an RGBD sensor to better estimate the prior on point location and to detect tracking failures during occlusion; and 3) Uses shape descriptors to find the most relevant previous state of the object to use for tracking after a severe occlusion. Our method does not rely on physics simulation or a physical model of the object, which can be difficult to obtain in unstructured environments. Despite having no physical model, our experiments demonstrate that our method achieves improved accuracy in the presence of occlusion as compared to a physics-based CPD method while maintaining adequate run-time.",
        "primary_area": "",
        "author": "Cheng Chi;Dmitry Berenson;Cheng Chi;Dmitry Berenson",
        "authorids": "/37089314569;/37542925700;/37089314569;/37542925700",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967827/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15730003219787344249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967920",
        "title": "Omnipush: accurate, diverse, real-world dataset of pushing dynamics with RGB-D video",
        "track": "main",
        "status": "Poster",
        "abstract": "Pushing is a fundamental robotic skill. Existing work has shown how to exploit models of pushing to achieve a variety of tasks, including grasping under uncertainty, in-hand manipulation and clearing clutter. Such models, however, are approximate, which limits their applicability.Learning-based methods can reason directly from raw sensory data with accuracy, and have the potential to generalize to a wider diversity of scenarios. However, developing and testing such methods requires rich-enough datasets. In this paper we introduce Omnipush, a dataset with high variety of planar pushing behavior.In particular, we provide 250 pushes for each of 250 objects, all recorded with RGB-D and a high precision tracking system. The objects are constructed so as to systematically explore key factors that affect pushing-the shape of the object and its mass distribution-which have not been broadly explored in previous datasets, and allow to study generalization in model learning.Omnipush includes a benchmark for meta-learning dynamic models, which requires algorithms that make good predictions and estimate their own uncertainty. We also provide an RGB video prediction benchmark and propose other relevant tasks that can be suited with this dataset. Data and code are available at https://web.mit.edu/mcube/omnipush-dataset/.",
        "primary_area": "",
        "author": "Maria Bauza;Ferran Alet;Yen-Chen Lin;Tom\u00e1s Lozano-P\u00e9rez;Leslie P. Kaelbling;Phillip Isola;Alberto Rodriguez;Maria Bauza;Ferran Alet;Yen-Chen Lin;Tom\u00e1s Lozano-P\u00e9rez;Leslie P. Kaelbling;Phillip Isola;Alberto Rodriguez",
        "authorids": "/37086003399;/37086453538;/37087323286;/38273814000;/37269373600;/37945396900;/38194796600;/37086003399;/37086453538;/37087323286;/38273814000;/37269373600;/37945396900;/38194796600",
        "aff": "Mechanical Engineering Department \u2014, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory \u2014, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory \u2014, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory \u2014, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory \u2014, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory \u2014, Massachusetts Institute of Technology; Mechanical Engineering Department \u2014, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967920/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9131977779842182555&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967617",
        "title": "On Data Sharing Strategy for Decentralized Collaborative Visual-Inertial Simultaneous Localization And Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "This article introduces and evaluates two decentralized data sharing algorithms for multi-robot visual-inertial simultaneous localization and mapping (VI-SLAM): Factor Sparsification for Visual-Inertial Packets (FS-VIP) and Min-K-Cover Selection for Visual-Inertial Packets (MKCS-VIP). Both methods make robots regularly build and exchange data packets which describe the successive portions of their map, but rely on distinct paradigms. While FS-VIP builds on consistent marginalization and sparsification techniques, MKCSVIP selects raw visual and inertial information which can best help to perform a faithful and consistent re-estimation while reducing the communication cost. Performances in terms of accuracy and communication loads are evaluated on multi-robot scenarios built on both available (EUROC) and custom datasets (SOTTEVILLE).",
        "primary_area": "",
        "author": "Rodolphe Dubois;Alexandre Eudes;Vincent Fr\u00e9mont;Rodolphe Dubois;Alexandre Eudes;Vincent Fr\u00e9mont",
        "authorids": "/37086521705;/37892221500;/37428082500;/37086521705;/37892221500;/37428082500",
        "aff": "DTIS, ONERA, Universit\u00e9 Paris Saclay, Palaiseau, France; DTIS, ONERA, Universit\u00e9 Paris Saclay, Palaiseau, France; DTIS, ONERA, Universit\u00e9 Paris Saclay, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967617/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18219719666806370096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ONERA",
        "aff_unique_dep": "DTIS",
        "aff_unique_url": "https://www.onera.fr",
        "aff_unique_abbr": "ONERA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Palaiseau",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968135",
        "title": "On Enhancing Ground Surface Detection from Sparse Lidar Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Ground surface detection in point cloud is widely used as a key module in autonomous driving systems. Different from previous approaches which are mostly developed for lidars with high beam resolution, e.g. Velodyne HDL-64, this paper proposes ground detection techniques applicable to much sparser point cloud captured by lidars with low beam resolution, e.g. Velodyne VLP-16. The approach is based on the RANSAC scheme of plane fitting. Inlier verification for plane hypotheses is enhanced by exploiting the point-wise tangent, which is a local feature available to compute regardless of the density of lidar beams. Ground surface which is not perfectly planar is fitted by multiple (specifically 4 in our implementation) disjoint plane regions. By assuming these plane regions to be rectanglar and exploiting the integral image technique, our approach approximately finds the optimal region partition and plane hypotheses under the RANSAC scheme with real-time computational complexity.",
        "primary_area": "",
        "author": "Bo Li;Bo Li",
        "authorids": "/37087324448;/37087324448",
        "aff": "TrunkTech",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968135/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10082292904937967753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "TrunkTech",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": ""
    },
    {
        "id": "8968573",
        "title": "On Flying Backwards: Preventing Run-away of Small, Low-speed, Fixed-wing UAVs in Strong Winds",
        "track": "main",
        "status": "Poster",
        "abstract": "Small, low-speed fixed-wing Unmanned Aerial Vehicles (UAVs) operating autonomously, beyond-visual-line-of-sight (BVLOS) will inevitably encounter winds rising to levels near or exceeding the vehicles' nominal airspeed. In this paper, we develop a nonlinear lateral-directional path following guidance law with explicit consideration of online wind estimates. Energy efficient airspeed reference compensation logic is developed for excess wind scenarios (i.e. when the wind speed rises above the airspeed), enabling either mitigation, prevention, or over-powering of excess wind induced run-away from a given path. The developed guidance law is demonstrated on a representative small, low-speed test UAV in two flight experiments conducted in mountainous regions of Switzerland with strong, turbulent wind conditions, gusts reaching up to 13 meters per second. We demonstrate track-keeping errors of less than 1 meter consistently maintained during a representative duration of gusting, excess winds and a mean ground speed undershoot of 0.5 meters per second from the commanded minimum forward ground speed demonstrated in over 5 minutes of the showcased flight results.",
        "primary_area": "",
        "author": "Thomas Stastny;Roland Siegwart;Thomas Stastny;Roland Siegwart",
        "authorids": "/37085387015;/37281398300;/37085387015;/37281398300",
        "aff": "Autonomous Systems Lab, Swiss Federal Institute of Technology (ETH Z\u00fcrich), Z\u00fcnch, Switzerland; Autonomous Systems Lab, Swiss Federal Institute of Technology (ETH Z\u00fcrich), Z\u00fcnch, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968573/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3567653736466566401&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH Z\u00fcrich",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968069",
        "title": "On Model-based Adhesion Control of a Vortex Climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, the adhesion modeling and control case of a Vortex Climbing Robot (VCR) is investigated against a surface of variable orientations. The critical adhesion force exerted from the implemented Vortex Actuator (VA) and the VCR's achievable payload are analyzed under 3-DOF rotations of the test surface, while extracted from both geometrical analysis and dynamically-simulated numerical results. A model-based control scheme is later proposed, with the goal of achieving adhesion while the VCR remains immobilized, limiting the power consumption and compensating for disturbances (e.g. moving cables) leading to Center-of-Mass (CoM) changes. Finally, the model-based control scheme is experimentally evaluated, with the VCR prototype on a rotating and moving flat surface. The presented results support the use of the proposed methodology in climbing robots targeting inspection and maintenance of stationary surfaces (flat, curved etc.), as well as future robotic solutions operating on moving structures (e.g. ships, cranes, folding bridges).",
        "primary_area": "",
        "author": "George Andrikopoulos;Andreas Papadimitriou;Angelica Brusell;George Nikolakopoulos;George Andrikopoulos;Andreas Papadimitriou;Angelica Brusell;George Nikolakopoulos",
        "authorids": "/37947798500;/37086943908;/37085838203;/37301305200;/37947798500;/37086943908;/37085838203;/37301305200",
        "aff": "Robotics Team, Control Engineering Group, Lule\u00e5 University of Technology, Sweden; Robotics Team, Control Engineering Group, Lule\u00e5 University of Technology, Sweden; Robotics Team, Control Engineering Group, Lule\u00e5 University of Technology, Sweden; Robotics Team, Control Engineering Group, Lule\u00e5 University of Technology, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968069/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7722627552306203127&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Lule\u00e5 University of Technology",
        "aff_unique_dep": "Control Engineering Group",
        "aff_unique_url": "https://www.ltu.se",
        "aff_unique_abbr": "LTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "8967520",
        "title": "On Modeling the Effects of Auditory Annoyance on Driving Style and Passenger Comfort",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the impressive progress being made in autonomous vehicles, human drivers will remain ubiquitous in the imminent years. Therefore, intelligent hybrid vehicular systems must be aware of the interactions between humans and the environment (e.g., sound, vibration, speed, etc.). In this paper, we evaluate the effect of acoustic annoyance on drivers in a real-world driving study. We found significant differences in driving styles elicited by annoying acoustics and present an online classifier that uses onboard inertial measurement unit measurements to distinguish whether a driver is annoyed with 77% accuracy. Moreover, we directly measured the forces applied on the passenger with a pressure mat lined on the car seat, and empirically confirm that our proposed passenger dynamics model is reasonable. However, due to our acoustically induced driving styles not being polarizing enough, we were unable to show that passengers' self-reported ride comfort changed with acoustic annoyance.",
        "primary_area": "",
        "author": "Edson Araujo;Michal Gregor;Isabella Huang;Erickson R. Nascimento;Ruzena Bajcsy;Edson Araujo;Michal Gregor;Isabella Huang;Erickson R. Nascimento;Ruzena Bajcsy",
        "authorids": "/37087111703;/38252792100;/37086538069;/38099290700;/37298488400;/37087111703;/38252792100;/37086538069;/38099290700;/37298488400",
        "aff": "Computer Science Department, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Department of Control and Information Systems, University of \u017dilina, Slovakia; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA; Computer Science Department, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967520/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1839146029035766167&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;2",
        "aff_unique_norm": "Universidade Federal de Minas Gerais;University of \u017dilina;University of California, Berkeley",
        "aff_unique_dep": "Computer Science Department;Department of Control and Information Systems;Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "http://www.ufmg.br;https://www.uniza.sk;https://www.berkeley.edu",
        "aff_unique_abbr": "UFMG;;UC Berkeley",
        "aff_campus_unique_index": "0;2;0;2",
        "aff_campus_unique": "Belo Horizonte;;Berkeley",
        "aff_country_unique_index": "0;1;2;0;2",
        "aff_country_unique": "Brazil;Slovakia;United States"
    },
    {
        "id": "8968516",
        "title": "On Training Flexible Robots using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of robotics in controlled environments has flourished over the last several decades and training robots to perform tasks using control strategies developed from dynamical models of their hardware have proven very effective. However, in many real-world settings, the uncertainties of the environment, the safety requirements and generalized capabilities that are expected of robots make rigid industrial robots unsuitable. This created great research interest in developing control strategies for flexible robot hardware for which building dynamical models are challenging. In this paper, inspired by the success of deep reinforcement learning (DRL), we systematically study the efficacy of policy search methods using DRL in training flexible robots. Our results indicate that DRL is successfully able to learn efficient and robust policies for complex tasks at various degrees of flexibility. We also note that DRL using Deep Deterministic Policy Gradients can be sensitive to the choice of sensors and adding more informative sensors does not necessarily make the task easier to learn.",
        "primary_area": "",
        "author": "Zach Dwiel;Madhavun Candadai;Mariano Phielipp;Zach Dwiel;Madhavun Candadai;Mariano Phielipp",
        "authorids": "/37087322799;/37085657389;/37087324977;/37087322799;/37085657389;/37087324977",
        "aff": "Intel AI Labs, Bloomington, IN, U.S.A; Program in Cognitive Science, and School of Informatics, Computing and Engineering, at Indiana University, Bloomington, IN, U.S.A; Intel AI Labs, Phoenix, AZ, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968516/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3179402622130530090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Intel;Indiana University",
        "aff_unique_dep": "AI Labs;School of Informatics, Computing and Engineering",
        "aff_unique_url": "https://www.intel.ai;https://www.indiana.edu",
        "aff_unique_abbr": "Intel AI;IU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Bloomington;Phoenix",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968164",
        "title": "On the Feasibility of Multi-Degree-of-Freedom Haptic Devices Using Passive Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Stability and transparency are key design requirements in haptic devices. Transparency can be significantly improved by replacing conventional electric motors with passive actuators such as brakes or dampers. Passive actuators can display a wide range of impedance and since they can only dis-sipate energy, stability is guaranteed. However, passive haptic devices suffer from a serious drawback; the direction of the force output is difficult to control. This issue was addressed extensively for planar manipulators but devices with higher degrees-of-freedom (DOF) have not been examined. In this paper, we introduce a new analytical framework to evaluate the feasibility and performance of non-redundant passive haptic manipulators with any DOF. The method identifies different regions in the workspace where a force can be created or approximated, and regions where a passive system cannot create force at all for a given user input. The results indicate that the range of forces a passive device can display increases with the number of DOF. This framework can aid in the design of control methods for multi-DOF passive haptic devices.",
        "primary_area": "",
        "author": "Maciej Lacki;Carlos Rossa;Maciej Lacki;Carlos Rossa",
        "authorids": "/37087324939;/38541890000;/37087324939;/38541890000",
        "aff": "Faculty of Engineering and Applied Science, Ontario Tech University, Oshawa, ON, Canada; Faculty of Engineering and Applied Science, Ontario Tech University, Oshawa, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968164/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6834033665710185089&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ontario Tech University",
        "aff_unique_dep": "Faculty of Engineering and Applied Science",
        "aff_unique_url": "https://www.ontariotechu.ca",
        "aff_unique_abbr": "Ontario Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oshawa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8967731",
        "title": "On the Tunable Sparse Graph Solver for Pose Graph Optimization in Visual SLAM Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "We report a tunable sparse optimization solver that can trade a slight decrease in accuracy for significant speed improvement in pose graph optimization in visual simultaneous localization and mapping (vSLAM). The solver is designed for devices with significant computation and power constraints such as mobile phones or tablets. Two approaches have been combined in our design. The first is a graph pruning strategy by exploiting objective function structure to reduce the optimization problem size which further sparsifies the optimization problem. The second step is to accelerate each optimization iteration in solving increments for the gradient-based search in Gauss-Newton type optimization solver. We apply a modified Cholesky factorization and reuse the decomposition result from last iteration by using Cholesky update/downdate to accelerate the computation. We have implemented our solver and tested it with open source data. The experimental results show that our solver can be twice as fast as the counterpart while maintaining a loss of less than 5% in accuracy.",
        "primary_area": "",
        "author": "Chieh Chou;Di Wang;Dezhen Song;Timothy A. Davis;Chieh Chou;Di Wang;Dezhen Song;Timothy A. Davis",
        "authorids": "/37085894675;/37086453325;/37275586600;/37086534935;/37085894675;/37086453325;/37275586600;/37086534935",
        "aff": "CSE Department, Texas A&M University, College Station, TX, USA; CSE Department, Texas A&M University, College Station, TX, USA; CSE Department, Texas A&M University, College Station, TX, USA; CSE Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967731/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14297778500213444152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "CSE Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967565",
        "title": "On the effect of semielliptical foot shape on the energetic efficiency of passive bipedal gait",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the effects of varying rollover curvature on the passive dynamic gait of a biped walker. The dynamic model of a compliant biped robot is extended with the implementation of semielliptical feet, to mimic human rollingradius progression during a step. The process of modeling the semielliptical foot shape and integrating its kinematics to the biped\u2019s dynamics is presented in detail. The passive dynamic behavior of the biped for elliptic feet of various dimensions is investigated through numerical simulations to provide results about gait stability, walking speed, energetic efficiency, and impact force levels. The concept of energetic efficiency in passive walking is discussed thoroughly, and an efficiency comparison methodology is proposed. Finally, it is shown that the biomimetically-inspired semielliptical foot profile can lead to higher gait efficiency. The results of this study can be used to optimize energetic efficiency in biped walking machines and/or gait assisting prosthetic equipment by means of foot shape optimization.",
        "primary_area": "",
        "author": "Aikaterini Smyrli;Mehdi Ghiassi;Andr\u00e9s Kecskem\u00e9thy;Evangelos Papadopoulos;Aikaterini Smyrli;Mehdi Ghiassi;Andr\u00e9s Kecskem\u00e9thy;Evangelos Papadopoulos",
        "authorids": "/37086455674;/37087323566;/37344718900;/37273090500;/37086455674;/37087323566;/37344718900;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens; Faculty of Engineering, University of Duisburg-Essen; Faculty of Engineering, University of Duisburg-Essen; School of Mechanical Engineering, National Technical University of Athens",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967565/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18305256476915153425&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "National Technical University of Athens;University of Duisburg-Essen",
        "aff_unique_dep": "School of Mechanical Engineering;Faculty of Engineering",
        "aff_unique_url": "https://www.ntua.gr;https://www.uni-due.de",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Greece;Germany"
    },
    {
        "id": "8967620",
        "title": "On-Chip Three-dimension Cell Rotation Using Whirling Flows Generated by Oscillating Asymmetrical Microstructures",
        "track": "main",
        "status": "Poster",
        "abstract": "The capability to precisely rotate the cells and other microscale objects is invaluable in biomedicine, bioengineering, and biophysics. We propose a novel on-chip three-dimension (3D) cell rotation method using whirling flows generated by oscillating asymmetrical microstructures. In an acoustic field excited by the vibration of a piezoelectric transducer, two different modes of microvortices are generated around our custom-designed microstructures that are utilized to precisely achieve in-plane and out-of-plane rotational manipulation of microparticles and cells. The rotation mechanism is studied and verified using numerical simulations. We also investigate the effect of various parameters on the acoustically induced flows such as the frequency, the driving voltage and the distance from the microstructure tip to the oocyte center, thus indicating the rotational speed can be effectively tuned on demand for single-cell studies. Finally, by observing the maturation stages of M2 after excluding the first polar body of operated oocytes, the proposed method is proved noninvasive. Comparing with the conventional works, our acoustofluidic cell rotation approach is simple-to-fabricate and easy-to-operate, thereby allowing rotations irrespective of the physical properties of the specimen under investigation.",
        "primary_area": "",
        "author": "Bin Song;Yanmin Feng;Qiang Zhou;Lin Feng;Bin Song;Yanmin Feng;Qiang Zhou;Lin Feng",
        "authorids": "/37086935548;/37087124241;/37086938008;/37403324400;/37086935548;/37087124241;/37086938008;/37403324400",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967620/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5506463872418111826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Mechanical Engineering & Automation",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "Beihang",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967745",
        "title": "One-Shot Composition of Vision-Based Skills from Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of learning multi-stage vision-based tasks on a real robot from a single video of a human performing the task, while leveraging demonstration data of subtasks with other objects. This problem presents a number of major challenges. Video demonstrations without teleoperation are easy for humans to provide, but do not provide any direct supervision. Learning policies from raw pixels enables full generality but calls for large function approximators with many parameters to be learned. Finally, compound tasks can require impractical amounts of demonstration data, when treated as a monolithic skill. To address these challenges, we propose a method that learns both how to learn primitive behaviors from video demonstrations and how to dynamically compose these behaviors to perform multi-stage tasks by \u201cwatching\u201d a human demonstrator. Our results on a simulated Sawyer robot and real PR2 robot illustrate our method for learning a variety of order fulfillment and kitchen serving tasks with novel objects and raw pixel inputs. Video results are linked at https://sites.google.com/view/one-shot-hil.",
        "primary_area": "",
        "author": "Tianhe Yu;Pieter Abbeel;Sergey Levine;Chelsea Finn;Tianhe Yu;Pieter Abbeel;Sergey Levine;Chelsea Finn",
        "authorids": "/37087323861;/37542877900;/37085481973;/37085523464;/37087323861;/37542877900;/37085481973;/37085523464",
        "aff": "Stanford University; Berkeley AI Research, UC Berkeley Computer Science; Berkeley AI Research, UC Berkeley Computer Science; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967745/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7367574326303062600&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;University of California, Berkeley",
        "aff_unique_dep": ";Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Stanford;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967881",
        "title": "One-Shot Object Localization Using Learnt Visual Cues via Siamese Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot that can operate in novel and unstructured environments must be capable of recognizing new, previously unseen, objects. In this work, a visual cue is used to specify a novel object of interest which must be localized in new environments. An end-to-end neural network equipped with a Siamese network is used to learn the cue, infer the object of interest, and then to localize it in new environments. We show that a simulated robot can pick-and-place novel objects pointed to by a laser pointer. We also evaluate the performance of the proposed approach on a dataset derived from the Omniglot handwritten character dataset and on a small dataset of toys.",
        "primary_area": "",
        "author": "Sagar Gubbi Venkatesh;Bharadwaj Amrutur;Sagar Gubbi Venkatesh;Bharadwaj Amrutur",
        "authorids": "/37087323447;/37370284100;/37087323447;/37370284100",
        "aff": "Dept. of Electrical Communication Engineering, Indian Institute of Science, Bangalore, India; Dept. of Electrical Communication Engineering, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967881/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12850331584145704335&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Dept. of Electrical Communication Engineering",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968231",
        "title": "Online Active Safety for Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Future manufacturing environments will see an increased need for cooperation between humans and machines. In this paper we propose a method that allows industrial manipulators to safely operate around humans. This approach guarantees that the manipulator will never collide with human operators while performing its normal tasks. This is done in an near-optimal way by considering how forward reachable sets of human operators grow with time, and by continuously updating these reachable sets based on current position estimates of the operators near the robot. An implicit active set invariance filter is then used to constrain the system-in a minimally invasive way-to stay in the complement of that forward reachable set. We demonstrate this approach in simulation on an industrial robotic arm: the ABB IRB 6640.",
        "primary_area": "",
        "author": "Andrew Singletary;Petter Nilsson;Thomas Gurriet;Aaron D. Ames;Andrew Singletary;Petter Nilsson;Thomas Gurriet;Aaron D. Ames",
        "authorids": "/37086449553;/37085352793;/37085817720;/37300877900;/37086449553;/37085352793;/37085817720;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968231/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13089130224140180606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967598",
        "title": "Online Motion Planning Over Multiple Homotopy Classes with Gaussian Process Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient planning in dynamic and uncertain environments is a fundamental challenge in robotics. In the context of trajectory optimization, the feasibility of paths can change as the environment evolves. Therefore, it can be beneficial to reason about multiple possible paths simultaneously. We build on prior work that considers graph-based trajectories to find solutions in multiple homotopy classes concurrently. Specifically, we extend this previous work to an online setting where the unreachable (in time) part of the graph is pruned and the remaining graph is reoptimized at every time step. As the robot moves within the graph on the path that is most promising, the pruning and reoptimization allows us to retain candidate paths that may become more viable in the future (a) as the environment changes, essentially enabling the robot to dynamically switch between numerous homotopy classes. We compare our approach against prior work without the homotopy switching capability and show improved performance across several metrics in simulation with a 2D robot in multiple dynamic environments under noisy measurements and execution.",
        "primary_area": "",
        "author": "Keshav Kolur;Sahit Chintalapudi;Byron Boots;Mustafa Mukadam;Keshav Kolur;Sahit Chintalapudi;Byron Boots;Mustafa Mukadam",
        "authorids": "/37087323449;/37087324297;/37085459219;/37085562050;/37087323449;/37087324297;/37085459219;/37085562050",
        "aff": "Robot Learning Lab, Georgia Institute of Technology, USA; Robot Learning Lab, Georgia Institute of Technology, USA; Robot Learning Lab, Georgia Institute of Technology, USA; Robot Learning Lab, Georgia Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967598/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9844249783090146049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Robot Learning Lab",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967696",
        "title": "Online Optimal Impedance Planning for Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Real world applications require robots to operate in unstructured environments. This kind of scenarios may lead to unexpected environmental contacts or undesired interactions, which may harm people or impair the robot. Adjusting the behavior of the system through impedance control techniques is an effective solution to these problems. However, selecting an adequate impedance is not a straightforward process. Normally, robot users manually tune the controller gains with trial and error methods. This approach is generally slow and requires practice. Moreover, complex tasks may require different impedance during different phases of the task. This paper introduces an optimization algorithm for online planning of the Cartesian robot impedance to adapt to changes in the task, robot configuration, expected disturbances, external environment and desired performance, without employing any direct force measurements. We provide an analytical solution leveraging the mass-spring-damper behavior that is conferred to the robot body by the Cartesian impedance controller. Stability during gains variation is also guaranteed. The effectiveness of the method is experimentally validated on the quadrupedal robot ANYmal. The variable impedance helps the robot to tackle challenging scenarios like walking on rough terrain and colliding with an obstacle.",
        "primary_area": "",
        "author": "Franco Angelini;Guiyang Xin;Wouter J. Wolfslag;Carlo Tiseo;Michael Mistry;Manolo Garabini;Antonio Bicchi;Sethu Vijayakumar;Franco Angelini;Guiyang Xin;Wouter J. Wolfslag;Carlo Tiseo;Michael Mistry;Manolo Garabini;Antonio Bicchi;Sethu Vijayakumar",
        "authorids": "/37086154079;/37085531864;/37085495847;/37085404832;/37542865600;/37947205100;/37278626700;/37295595500;/37086154079;/37085531864;/37085495847;/37085404832;/37542865600;/37947205100;/37278626700;/37295595500",
        "aff": "Centro di Ricerca \u201cEnrico Piaggio\u201d, Universit\u00e0 di Pisa, Largo Lucio Lazzarino 1, Pisa, Italy; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh, Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh, Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh, Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh, Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom; Centro di Ricerca \u201cEnrico Piaggio\u201d, Universit\u00e0 di Pisa, Largo Lucio Lazzarino 1, Pisa, Italy; Centro di Ricerca \u201cEnrico Piaggio\u201d, Universit\u00e0 di Pisa, Largo Lucio Lazzarino 1, Pisa, Italy; Institute for Perception, Action, and Behaviour, School of Informatics, The University of Edinburgh, Informatics Forum, 10 Crichton Street, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967696/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9984348585927519482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;0;0;1",
        "aff_unique_norm": "Universit\u00e0 di Pisa;University of Edinburgh",
        "aff_unique_dep": "Centro di Ricerca \u201cEnrico Piaggio\u201d;School of Informatics",
        "aff_unique_url": "https://www.unipi.it;https://www.ed.ac.uk",
        "aff_unique_abbr": ";Edinburgh",
        "aff_campus_unique_index": "0;1;1;1;1;0;0;1",
        "aff_campus_unique": "Pisa;Edinburgh",
        "aff_country_unique_index": "0;1;1;1;1;0;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "8967707",
        "title": "Online Performance Prediction and Profiling of Human Activities by Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "The capacity of a system to automatically analyze and predict the performance of a human in a particular task can provide important information in Human-Robot Interaction. Despite its usefulness, the above topic has received rather limited attention in the literature. In the current work, we introduce a method for performance prediction and profiling of human activities. Using little information about a task, our method is able to extract the characteristic motion patterns of an agent, analyze them and predict his/her performance in a given activity. We demonstrate the robustness of the method in several different activities, that involve both periodic and oscillatory primitive motions. In addition, we evaluate it thoroughly on data obtained from public datasets and discuss its usefulness for contemporary robotic applications.",
        "primary_area": "",
        "author": "Emmanouil Hourdakis;Michail Maniadakis;Panos Trahanias;Emmanouil Hourdakis;Michail Maniadakis;Panos Trahanias",
        "authorids": "/37313506700;/37564646400;/37329551300;/37313506700;/37564646400;/37329551300",
        "aff": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH); Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH); Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967707/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2482140542108478781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Foundation for Research and Technology - Hellas",
        "aff_unique_dep": "Institute of Computer Science",
        "aff_unique_url": "https://www.forth.gr",
        "aff_unique_abbr": "FORTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "8967898",
        "title": "Online Planning for Autonomous Underwater Vehicles Performing Information Gathering Tasks in Large Subsea Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an anytime Monte Carlo tree search (MCTS) algorithm to generate real-time, near-optimal search paths in large subsea environments. The MCTS planner continuously builds a tree of the search space until either the allowed time per move is reached or the budget constraint for the search mission is met. In order to improve the performance of the MCTS planner, we propose a novel heuristic action selection policy to determine the value of a leaf node. The proposed heuristic is tailored to problems where making a turn incurs a higher cost than moving straight, such as the case on autonomous underwater vehicles. Through extensive simulations, we show that our heuristic yields a significant performance improvement over a lawnmover path planner - a commonly employed approach in subsea search applications - and over a simple MCTS planner where actions are selected uniformly at random. In our numerical illustrations, we use a real data set abstracted from sonar measurements acquired from the Boston Harbor.",
        "primary_area": "",
        "author": "Harun Yetkin;James McMahon;Nicholay Topin;Artur Wolek;Zachary Waters;Daniel J. Stilwell;Harun Yetkin;James McMahon;Nicholay Topin;Artur Wolek;Zachary Waters;Daniel J. Stilwell",
        "authorids": "/37074562500;/37085353635;/37086113475;/37085650466;/37086271541;/37283170000;/37074562500;/37085353635;/37086113475;/37085650466;/37086271541;/37283170000",
        "aff": "Department of Mechatronics Engineering, Bartin University, Turkey; Code 7130, US Naval Research Laboratory, Washington DC, USA; University of Maryland, College Park, MD, USA; Center for Marine Autonomy and Robotics at Virginia Tech, Bart\u0131n University, Turkey; US Naval Research Laboratory, Washington, DC, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967898/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11050624489498610784&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;3",
        "aff_unique_norm": "Bartin University;US Naval Research Laboratory;University of Maryland;Virginia Tech",
        "aff_unique_dep": "Department of Mechatronics Engineering;Code 7130;;Center for Marine Autonomy and Robotics",
        "aff_unique_url": "https://www.bartin.edu.tr;https://www.nrl.navy.mil;https://www/umd.edu;https://www.vt.edu",
        "aff_unique_abbr": ";NRL;UMD;VT",
        "aff_campus_unique_index": "1;2;3;4",
        "aff_campus_unique": ";Washington DC;College Park;Washington, DC;Blacksburg",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "T\u00fcrkiye;United States"
    },
    {
        "id": "8968028",
        "title": "Online Relative Footstep Optimization for Legged Robots Dynamic Walking Using Discrete-Time Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a unified control framework that generates dynamic walking motions for biped and quadruped robots with online relative footstep optimization. The footstep optimization is formulated as a discrete-time Model Predictive Control problem which determines future footstep locations. The framework has a hierarchical structure consisting of three layers: footstep planner, trajectory generator and whole-body controller. The footstep planner plans next footstep position based on Linear Inverted Pendulum (LIP) model. Relative footstep optimization is proposed to enable automatic footstep planning without the use of any predefined footstep sequences. The trajectory generator will generate CoM and feet trajectory given the next footstep placement. In order to generalize to quadruped robots, \u201cvirtual leg\u201d concept has been used to coordinate leg pair movement. The whole-body inverse dynamic controller calculates joint torques to track given Cartesian reference trajectories. To include under-actuation into consideration, contact vertices formulation of ground reaction forces (GRFs) has been adopted. Generalized whole-body controller can handle biped robot with line feet as well as quadruped robots with point feet walking with dynamic gaits. Several simulations have been performed to demonstrate the robustness and generality of the proposed framework.",
        "primary_area": "",
        "author": "Songyan Xin;Romeo Orsolino;Nikos Tsagarakis;Songyan Xin;Romeo Orsolino;Nikos Tsagarakis",
        "authorids": "/37086099765;/37086265101;/37295830800;/37086099765;/37086265101;/37295830800",
        "aff": "Department of Advanced Robotics, Istituto Italiano di Tecnologia via Morego, 30, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia via Morego, 30, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia via Morego, 30, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968028/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3562020842728684702&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Advanced Robotics",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968461",
        "title": "Online System Identification Algorithm without Persistent Excitation for Robotic Systems: Application to Reconfigurable Autonomous Vessels",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates an online system identification problem of estimating unknown parameters in nonlinear system dynamics in the absence of persistently excitation. To estimate parameters, we develop an algorithm that updates parameter estimates using sensor data and a basis that is built on a finite number of recorded sensor data. Based on our proposed approach we show that the algorithm achieves exponential convergence in both state and parameter estimation errors without the persistent excitation condition. We demonstrate the effectiveness of the proposed approach using both simulations and experiments on a reconfiguration autonomous multi-vessel platform: Simulation results illustrate that the parameter estimated by the developed algorithm converge to their ground truths. Experiment results validate the performance of the developed algorithm in estimating platform's system parameters across different multi-vessel configurations.",
        "primary_area": "",
        "author": "Erkan Kayacan;Shinkyu Park;Carlo Ratti;Daniela Rus;Erkan Kayacan;Shinkyu Park;Carlo Ratti;Daniela Rus",
        "authorids": "/38468023200;/37086183848;/37590016800;/37279652300;/38468023200;/37086183848;/37590016800;/37279652300",
        "aff": "School of Mechanical &Mining Engineering, University of Queensland, Brisbane, Australia; Senseable City Laboratory (SCL), Massachusetts Institute of Technology, Cambridge, MA, USA; Senseable City Laboratory (SCL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science &Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968461/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10193821968222545331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Queensland;Massachusetts Institute of Technology",
        "aff_unique_dep": "School of Mechanical & Mining Engineering;Senseable City Laboratory (SCL)",
        "aff_unique_url": "https://www.uq.edu.au;https://web.mit.edu",
        "aff_unique_abbr": "UQ;MIT",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Brisbane;Cambridge",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "8967840",
        "title": "Online Trajectory Generation of a MAV for Chasing a Moving Target in 3D Dense Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This work deals with a moving target chasing mission of an aerial vehicle equipped with a vision sensor in a cluttered environment. In contrast to obstacle-free or sparse environments, the chaser should be able to handle collision and occlusion together with flight efficiency. In order to tackle these challenges in real-time, we introduce a metric for target visibility and propose a hierarchical chasing planner. In the first phase, we generate a sequence of waypoints and chasing corridors which ensure safety and optimize visibility. In the following phase, the corridors and waypoints are utilized as constraints and objective respectively in quadratic programming from which we complete a dynamically feasible trajectory for chasing. The proposed algorithm is tested in multiple dense environments. The simulator AutoChaser with full code implementation & GUI can be found in https://github.com/icsl-Jeon/traj_gen_vis and video is available at https://youtu.be/-2d3uDlYR_M.",
        "primary_area": "",
        "author": "Boseong Felipe Jeon;H. Jin Kim;Boseong Felipe Jeon;H. Jin Kim",
        "authorids": "/37087323064;/37599626400;/37087323064;/37599626400",
        "aff": "Department of mechanical and aerospace engineering, Seoul national university of South Korea; Department of mechanical and aerospace engineering, Seoul national university of South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967840/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2621907835461280989&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968266",
        "title": "Online Trajectory Generation: Reactive Control With Return Inside an Admissible Kinematic Domain",
        "track": "main",
        "status": "Poster",
        "abstract": "As humans and robots work more and more closely, robots must quickly react to unforeseen human behavior. Online Trajectory Generation (OTG), based on simple trajectory models like series of polynomial cubic functions, has demonstrated its efficiency to plan and control reactive motions of robots. However to ensure the safety and comfort of humans, fast trajectory adaptation algorithms are necessary to bring back the robot inside an acceptable domain that is defined by a set of kinematic constraints. The algorithm presented herein extends a time-optimal OTG to cope with non admissible robot's state. This feature enables time-variant kinematic constraints. With the possibility to specify velocity and acceleration at both ends under short computation times, it makes the robot able to react quickly to unforeseen events. Short computation times can lead to more refined architectures where sensors can be integrated to a low control level and make the system more reactive.",
        "primary_area": "",
        "author": "Kevin Desormeaux;Daniel Sidobre;Kevin Desormeaux;Daniel Sidobre",
        "authorids": "/37087323114;/37378284900;/37087323114;/37378284900",
        "aff": "CNRS, LAAS, 7 avenue du colonel Roche, Toulouse, France; CNRS, LAAS, 7 avenue du colonel Roche, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968266/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1916463614812550262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "LAAS",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967991",
        "title": "Online and Consistent Occupancy Grid Mapping for Planning in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Actively exploring and mapping an unknown environment requires integration of both simultaneous localization and mapping (SLAM) and path planning methods. Path planning relies on a map that contains free and occupied space information and is efficient to query, while the role of SLAM is to keep the map consistent as new measurements are continuously added. A key challenge, however, lies in ensuring a map representation compatible with both these objectives: that is, a map that maintains free space information for planning but can also adapt efficiently to dynamically changing pose estimates from a graph-based SLAM system. In this paper, we propose an online global occupancy map that can be corrected for accumulated drift efficiently based on incremental solutions from a sparse graph-based SLAM optimization. Our map maintains free space information for real-time path planning while undergoing a bounded number of updates in each loop closure iteration. We evaluate performance for both simulated and real-world datasets for an application involving underwater exploration and mapping.",
        "primary_area": "",
        "author": "Paloma Sodhi;Bing-Jui Ho;Michael Kaess;Paloma Sodhi;Bing-Jui Ho;Michael Kaess",
        "authorids": "/38469682300;/37086574547;/37324200400;/38469682300;/37086574547;/37324200400",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; AMoD Group at Aptiv, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967991/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6712966046352129657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Aptiv",
        "aff_unique_dep": "The Robotics Institute;AMoD Group",
        "aff_unique_url": "https://www.cmu.edu;https://www.aptiv.com",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967870",
        "title": "Operation of a pneumatic soft manipulator using a wearable interface with flexible strain sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a soft manipulator which mimics the muscle structure of an octopus arm and its operation by the master-slave method by using a wearable interface. The soft manipulator consists of a rubber structure and McKibben artificial muscles arranged in axial and oblique directions. This manipulator has high safety and shape adaptability and realizes smooth and continuous movement like the octopus arm such as bending and twisting. For the intuitive operation of the manipulator, the wearable interface using flexible strain sensors is developed. It is easy to wear on the human arm with high comfortability because it consists only of soft materials and stretches easily with following the arm motion. We can operate the soft manipulator by using the motions of the wrist and forearm as an operation input. The soft manipulator can move following the arm motion of the operator, and it shows the high possibility to conduct actual tasks.",
        "primary_area": "",
        "author": "Hiroki Hagihara;Shuichi Wakimoto;Takefumi Kanda;Shota Furukawa;Hiroki Hagihara;Shuichi Wakimoto;Takefumi Kanda;Shota Furukawa",
        "authorids": "/37086345912;/37393290900;/37273968800;/37087322143;/37086345912;/37393290900;/37273968800;/37087322143",
        "aff": "Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967870/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17836771171384581541&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Okayama University",
        "aff_unique_dep": "Graduate School of Natural Science and Technology",
        "aff_unique_url": "https://www.okayama-u.ac.jp",
        "aff_unique_abbr": "Okayama U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Okayama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967613",
        "title": "Operational Space Control Framework for Torque Controlled Humanoid Robots with Joint Elasticity",
        "track": "main",
        "status": "Poster",
        "abstract": "Torque controlled robots have the capability of implementing compliant behavior with back-drivability. In practice, however, joint elasticity often prevents an accurate position tracking performance of a robot. In particular, humanoid robots are influenced more by elasticity because of a long kinematic chain between the feet and hands. In this paper, we present a new inverse dynamics based control approach for torque controlled humanoid robots with joint elasticity. When formulating the operational space control framework, feedback control consists of only motor-related parts with measured motor angle values, and the link dynamics is compensated by the feedforward terms. The experiment results of the proposed approach show a noticeable improvement in the position tracking performance in 6-DoF manipulator. Finally, the proposed method was applied to a torque controlled biped robot for walking. Both stiff motion control of the CoM and compliant motion control of the foot were simultaneously achieved, demonstrating the advantage of the torque controlled robot.",
        "primary_area": "",
        "author": "Jaesug Jung;Donghyeon Kim;Jaeheung Park;Jaesug Jung;Donghyeon Kim;Jaeheung Park",
        "authorids": "/37085674476;/37087324205;/37281014000;/37085674476;/37087324205;/37281014000",
        "aff": "Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Korea; Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Korea; Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967613/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8715958476183619010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Graduate School of Convergence Science and Technology",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968193",
        "title": "Optical Coherence Tomography Guided Robotic Device for Autonomous Needle Insertion in Cornea Transplant Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports the design and evaluation of a novel robotic device for cornea transplant surgery. The device enables the OCT-sensor guided Big Bubble hydro-dissection approach for deep anterior lamellar keratoplasty (DALK) cornea transplant surgery. DALK is highly challenging because it requires precise placement of a needle into the stroma of the cornea down to Descemets Membrane (DM) and injects a fluid to separate the remaining stroma from Descemet's membrane. Finally, the stroma is removed and replaced with the donor cornea graft. Compared to traditional penetrating keratoplasty (PK), which involves a full-thickness graft, this method significantly reduces the risk of rejection of the donor cornea by keeping the DM intact. A comparison of autonomous OCT guided needle insertions with expert manual needle insertions showed that the device significantly increased the precision and consistency of the needle placement, which could lead to better visual outcomes and fewer complications. In a study on cadaver porcine eyes, the measured insertion depth as a percentage of cornea thickness for the robotic device was 90.05% +/- 2.33% compared to 79.16% +/- 5.68% for manual insertions.",
        "primary_area": "",
        "author": "S. Guo;N.R. Sarfaraz;W. Gensheimer;A. Krieger;J. U. Kang;S. Guo;N.R. Sarfaraz;W. Gensheimer;A. Krieger;J. U. Kang",
        "authorids": "/37087040645;/37087323385;/37087323356;/38484449800;/37273713000;/37087040645;/37087323385;/37087323356;/38484449800;/37273713000",
        "aff": "Electrical and Computer Science Engineering Department, Johns Hopkins University, Baltimore, MD; Department of Mechanical Engineering, University of Maryland, College Park, MD, 20742; Warfighter Eye Center, Malcolm Grow Medical Clinics and Surgery Center, Joint Base Andrews, MD; Department of Mechanical Engineering, University of Maryland, College Park, MD, 20742; Electrical and Computer Science Engineering Department, Johns Hopkins University, Baltimore, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968193/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10149124644641509446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Johns Hopkins University;University of Maryland, College Park;Malcolm Grow Medical Clinics and Surgery Center",
        "aff_unique_dep": "Electrical and Computer Science Engineering Department;Department of Mechanical Engineering;Warfighter Eye Center",
        "aff_unique_url": "https://www.jhu.edu;https://www/umd.edu;",
        "aff_unique_abbr": "JHU;UMD;",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Baltimore;College Park;Joint Base Andrews",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968113",
        "title": "Optimal Solving of Constrained Path-Planning Problems with Graph Convolutional Networks and Optimized Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based methods are growing prominence for planning purposes. However, there are very few approaches for learning-assisted constrained path-planning on graphs, while there are multiple downstream practical applications. This is the case for constrained path-planning for Autonomous Unmanned Ground Vehicles (AUGV), typically deployed in disaster relief or search and rescue applications. In off-road environments, the AUGV must dynamically optimize a source-destination path under various operational constraints, out of which several are difficult to predict in advance and need to be addressed on-line. We propose a hybrid solving planner that combines machine learning models and an optimal solver. More specifically, a graph convolutional network(GCN) is used to assist a branch and bound(B&B) algorithm in handling the constraints. We conduct experiments on realistic scenarios and show that GCN support enables substantial speedup and smoother scaling to harder problems.",
        "primary_area": "",
        "author": "Kevin Osanlou;Andrei Bursuc;Christophe Guettier;Tristan Cazenave;Eric Jacopin;Kevin Osanlou;Andrei Bursuc;Christophe Guettier;Tristan Cazenave;Eric Jacopin",
        "authorids": "/37087324349;/37547440400;/37620884700;/37296667900;/37086616559;/37087324349;/37547440400;/37620884700;/37296667900;/37086616559",
        "aff": "Safran Electronics & Defense; valeo.ai; Safran Electronics & Defense; LAMSADE, Paris-Dauphine University; CREC Saint-Cyr, Coetquidan School Campus",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968113/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14445067810640325477&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "Safran Electronics & Defense;Valeo;Paris-Dauphine University;CREC Saint-Cyr",
        "aff_unique_dep": ";;LAMSADE;",
        "aff_unique_url": "https://www.safran-group.com;https://www.valeo.com;https://www.univ-paris-dauphine.fr;",
        "aff_unique_abbr": "Safran;Valeo;Paris-Dauphine;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Paris;Coetquidan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968547",
        "title": "Optimal Temporal Logic Planning for Multi-Robot Systems in Uncertain Semantic Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a multi-robot motion planning problem in probabilistic maps obtained by semantic simultaneous localization and mapping (SLAM). The goal of the robots is to accomplish complex collaborative high level tasks captured by global temporal logic specifications in the presence of uncertainty in the workspace. Specifically, the robots operate in an unknown environment modeled as a semantic map determined by Gaussian distributions over landmark positions and arbitrary discrete distributions over landmark classes. We extend Linear Temporal Logic by including information-based predicates allowing us to incorporate uncertainty and probabilistic satisfaction requirements directly into the task specification. We propose a new highly scalable sampling-based approach that synthesizes paths that satisfy the assigned task specification while minimizing a user-specified motion cost function. Finally, we show that the proposed algorithm is probabilistically complete, asymptotically optimal and supported by convergence rate bounds. We provide extensive simulation results that corroborate the theoretical analysis and show that the proposed algorithm can address large-scale planning tasks.",
        "primary_area": "",
        "author": "Yiannis Kantaros;George J. Pappas;Yiannis Kantaros;George J. Pappas",
        "authorids": "/37085499544;/37281547100;/37085499544;/37281547100",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968547/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10258761403613003504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968261",
        "title": "Optimal temporal logic planning with cascading soft constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of temporal logic planning given both hard specifications of the robot's mission and soft preferences on the plans that achieve the mission. In particular, we consider a problem whose inputs are a transition system, a linear temporal logic (LTL) formula specifying the robot's mission, and an ordered sequence of formulas expressed in linear dynamic logic over finite traces (LDLf) specifying the user's preferences for how the mission should be completed. The planner's objective is to synthesize, on this transition system, an infinite trajectory that best fits the user's preferences over finite prefixes of that trajectory while nonetheless satisfying the overall objective. We describe an algorithm for this problem that constructs, from the inputs, a product automaton -which is, in fact, a special kind of state-weighted B\u00fcchi automaton- over which an optimal trajectory is synthesized. This synthesis problem is solved via reduction to the minimax path problem in vertex weighted graphs, which can be solved by variants of the standard algorithms for computing shortest paths in a graph or by algorithms for the all-pairs bottleneck paths problem on vertex-weighted graphs. We show the applicability of the approach via some case studies, for which we present results computed by an implementation.",
        "primary_area": "",
        "author": "Hazhar Rahmani;Jason M. O\u2019Kane;Hazhar Rahmani;Jason M. O\u2019Kane",
        "authorids": "/37086453006;/37279835400;/37086453006;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina 550 Assembly St, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina 550 Assembly St, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968261/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10242121820436306817&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968032",
        "title": "Optimization Based Motion Planning for Multi-Limbed Vertical Climbing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning trajectories for a multi-limbed robot to climb up walls requires a unique combination of constraints on torque, contact force, and posture. This paper focuses on motion planning for one particular setup wherein a six-legged robot braces itself between two vertical walls and climbs vertically with end effectors that only use friction. Instead of motion planning with a single nonlinear programming (NLP) solver, we decoupled the problem into two parts with distinct physical meaning: torso postures and contact forces. The first part can be formulated as either a mixed-integer convex programming (MICP) or NLP problem, while the second part is formulated as a series of standard convex optimization problems. Variants of the two wall climbing problem e.g., obstacle avoidance, uneven surfaces, and angled walls, help verify the proposed method in simulation and experimentation.",
        "primary_area": "",
        "author": "Xuan Lin;Jingwen Zhang;Junjie Shen;Gabriel Fernandez;Dennis W Hong;Xuan Lin;Jingwen Zhang;Junjie Shen;Gabriel Fernandez;Dennis W Hong",
        "authorids": "/37085891795;/37087323024;/37087324771;/37087324390;/37575333900;/37085891795;/37087323024;/37087324771;/37087324390;/37575333900",
        "aff": "Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968032/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17238650650755255846&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Robotics and Mechanisms Laboratory (RoMeLa)",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968133",
        "title": "Optimization based Trajectory Planning of Mobile Cable-Driven Parallel Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A Mobile Cable-Driven Parallel Robot (MCDPR) is composed of a classical Cable-Driven Parallel Robot (CDPR) carried by multiple mobile bases. The additional mobilities due the motion of the mobile bases allow such systems to autonomously modify their geometric architecture, and thus make them suitable for multiple manipulation tasks in constrained environments. Moreover, these additional mobilities mean MCDPRs are kinematically redundant and may use this redundancy to optimize secondary task criteria. However, the high dimensional state space and closed chain constraints add complexity to the motion planning problem. To overcome this, we propose a method for trajectory planning for MCDPRs performing pick and place operations in cluttered environments by using direct transcription optimization. Two different scenarios have been considered and their results are validated using a dynamic simulation software (V-REP) and experimentally.",
        "primary_area": "",
        "author": "Tahir Rasheed;Philip Long;Adolfo Suarez Roos;St\u00e9phane Caro;Tahir Rasheed;Philip Long;Adolfo Suarez Roos;St\u00e9phane Caro",
        "authorids": "/37086321889;/37085485728;/37086189874;/37589701400;/37086321889;/37085485728;/37086189874;/37589701400",
        "aff": "\u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9riquede Nantes, Nantes, France; RIVeR Lab, Northeastern University, USA; IRT Jules Verne, Chemin du Chaffault, Bouguenais, France; CNRS, Laboratoire des Sciences du Num\u00e9rique de Nantes, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968133/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2567939643999039515&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "\u00c9cole Centrale de Nantes;Northeastern University;IRT Jules Verne;CNRS",
        "aff_unique_dep": "Laboratoire des Sciences du Num\u00e9rique;RIVeR Lab;;Laboratoire des Sciences du Num\u00e9rique de Nantes",
        "aff_unique_url": "https://www.ecn.fr;https://www.northeastern.edu;;https://www.cnrs.fr",
        "aff_unique_abbr": "ECN;NU;;CNRS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nantes;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "8968162",
        "title": "Orbit Characterization, Stabilization and Composition on 3D Underactuated Bipedal Walking via Hybrid Passive Linear Inverted Pendulum Model",
        "track": "main",
        "status": "Poster",
        "abstract": "A Hybrid passive Linear Inverted Pendulum (H-LIP) model is proposed for characterizing, stabilizing and composing periodic orbits for 3D underactuated bipedal walking. Specifically, Period-l (P1) and Period -2 (P2) orbits are geometrically characterized in the state space of the H-LIP. Stepping controllers are designed for global stabilization of the orbits. Valid ranges of the gains and their optimality are derived. The optimal stepping controller is used to create and stabilize the walking of bipedal robots. An actuated Spring-loaded Inverted Pendulum (aSLIP) model and the underactuated robot Cassie are used for illustration. Both the aSLIP walking with PI or P2 orbits and the Cassie walking with all 3D compositions of the PI and P2 orbits can be smoothly generated and stabilized from a stepping-in-place motion. This approach provides a perspective and a methodology towards continuous gait generation and stabilization for 3D underactuated walking robots.",
        "primary_area": "",
        "author": "Xiaobin Xiong;Aaron D. Ames;Xiaobin Xiong;Aaron D. Ames",
        "authorids": "/37086275102;/37300877900;/37086275102;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968162/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17893321061657825411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967643",
        "title": "Outlier-Robust Manifold Pre-Integration for INS/GPS Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the INS/GPS sensor fusion problem for pose estimation, particularly in the common setting where the INS components (IMU and magnetometer) function at much higher frequencies than GPS, and where the magnetometer and GPS are prone to giving erroneous measurements (outliers) due to magnetic disturbances and glitches. Our main contribution is a novel non-linear optimization framework that (1) fuses pre-integrated IMU and magnetometer measurements with GPS, in a manner that respects the manifold structure of the state space; and (2) supports the usage of robust norms and efficient large scale optimization to effectively mitigate the effects of outliers. Through extensive experiments, we demonstrate the superior accuracy and robustness of our approach over filtering methods (which are customarily applied in the target setting) with minimal impact to computational efficiency. Our work further illustrates the strength of optimization approaches in state estimation problems and paves the way for their adoption in the control and navigation communities.",
        "primary_area": "",
        "author": "Shin-Fang Ch\u2019ng;Alireza Khosravian;Anh-Dzung Doan;Tat-Jun Chin;Shin-Fang Ch\u2019ng;Alireza Khosravian;Anh-Dzung Doan;Tat-Jun Chin",
        "authorids": "/37087226874;/37846542600;/37086526070;/37411757200;/37087226874;/37846542600;/37086526070;/37411757200",
        "aff": "School of Computer Science, The University of Adelaide; School of Computer Science, The University of Adelaide; School of Computer Science, The University of Adelaide; School of Computer Science, The University of Adelaide",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967643/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15071929418313713004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Adelaide",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.adelaide.edu.au",
        "aff_unique_abbr": "Adelaide",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8968174",
        "title": "Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms, and Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatial perception is the backbone of many robotics applications, and spans a broad range of research problems, including localization and mapping, point cloud alignment, and relative pose estimation from camera images. Robust spatial perception is jeopardized by the presence of incorrect data association, and in general, outliers. Although techniques to handle outliers do exist, they can fail in unpredictable manners (e.g., RANSAC, robust estimators), or can have exponential runtime (e.g., branch-and-bound). In this paper, we advance the state of the art in outlier rejection by making three contributions. First, we show that even a simple linear instance of outlier rejection is inapproximable: in the worst-case one cannot design a quasi-polynomial time algorithm that computes an approximate solution efficiently. Our second contribution is to provide the first per-instance sub-optimality bounds to assess the approximation quality of a given outlier rejection outcome. Our third contribution is to propose a simple general-purpose algorithm, named adaptive trimming, to remove outliers. Our algorithm leverages recently-proposed global solvers that are able to solve outlier-free problems, and iteratively removes measurements with large errors. We demonstrate the proposed algorithm on three spatial perception problems: 3D registration, two-view geometry, and SLAM. The results show that our algorithm outperforms several state-of-the-art methods across applications while being a general-purpose method.",
        "primary_area": "",
        "author": "Vasileios Tzoumas;Pasquale Antonante;Luca Carlone;Vasileios Tzoumas;Pasquale Antonante;Luca Carlone",
        "authorids": "/37085362607;/37087323827;/37545784100;/37085362607;/37087323827;/37545784100",
        "aff": "Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968174/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12987134714366672799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968152",
        "title": "Outlier-Robust State Estimation for Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Contemporary humanoids are equipped with visual and LiDAR sensors that are effectively utilized for Visual Odometry (VO) and LiDAR Odometry (LO). Unfortunately, such measurements commonly suffer from outliers in a dynamic environment, since frequently it is assumed that only the robot is in motion and the world is static. To this end, robust state estimation schemes are mandatory in order for humanoids to symbiotically co-exist with humans in their daily dynamic environments. In this article, the robust Gaussian Error-State Kalman Filter for humanoid robot locomotion is presented. The introduced method automatically detects and rejects outliers without relying on any prior knowledge on measurement distributions or finely tuned thresholds. Subsequently, the proposed method is quantitatively and qualitatively assessed in realistic conditions with the full-size humanoid robot WALK-MAN v2.0 and the mini-size humanoid robot NAO to demonstrate its accuracy and robustness when outlier VOLO measurements are present. Finally, in order to reinforce further research endeavours, our implementation is released as an open-source ROS/C++package.",
        "primary_area": "",
        "author": "Stylianos Piperakis;Dimitrios Kanoulas;Nikos G. Tsagarakis;Panos Trahanias;Stylianos Piperakis;Dimitrios Kanoulas;Nikos G. Tsagarakis;Panos Trahanias",
        "authorids": "/37085813142;/38230575500;/37295830800;/37329551300;/37085813142;/38230575500;/37295830800;/37329551300",
        "aff": "Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science, Heraklion, Greece; Humanoids and Human-Centered Mechatronics Department, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, Italy; Humanoids and Human-Centered Mechatronics Department, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, Italy; Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science, Heraklion, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968152/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4603507247414737366&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Foundation for Research and Technology - Hellas;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Institute of Computer Science;Humanoids and Human-Centered Mechatronics Department",
        "aff_unique_url": "https://www.forth.gr;https://www.iit.it",
        "aff_unique_abbr": "FORTH;IIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Heraklion;Genova",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Greece;Italy"
    },
    {
        "id": "8968296",
        "title": "PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose PASS3D to achieve point-wise semantic segmentation for 3D point cloud. Our framework combines the efficiency of traditional geometric methods with robustness of deep learning methods, consisting of two stages: At stage -1, our accelerated cluster proposal algorithm will generate refined cluster proposals by segmenting point clouds without ground, capable of generating less redundant proposals with higher recall in an extremely short time; stage -2 we will amplify and further process these proposals by a neural network to estimate semantic label for each point and meanwhile propose a novel data augmentation method to enhance the network's recognition capability for all categories especially for non-rigid objects. Evaluated on KITTI raw dataset, PASS3D stands out against the state-of-the-art on some results, making itself competent to 3D perception in autonomous driving system. Our source code will be open-sourced. A video demonstration is available at https://www.youtube.com/watch?v=cukEqDuP_Qw.",
        "primary_area": "",
        "author": "Xin Kong;Guangyao Zhai;Baoquan Zhong;Yong Liu;Xin Kong;Guangyao Zhai;Baoquan Zhong;Yong Liu",
        "authorids": "/37087322070;/37087322612;/37089123375;/37066946100;/37087322070;/37087322612;/37089123375;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968296/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=454323568815996993&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zhejiang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968214",
        "title": "PD based Robust Quadratic Programs for Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, inspired by Proportional-Derivative (PD) control laws, we present a class of Control Lyapunov Function (CLF) based Quadratic Programs (QPs) for robotic systems. Proportional-Derivative (PD) control laws are independent of the robot model, however, they fail to incorporate physical constraints, such as torque saturation. On the other hand, most optimization based control design approaches ensure satisfaction of the physical constraints, but they are sensitive to errors in the robot model. The PD based Quadratic Programs (PD-QPs), presented in this paper, are a first step towards bridging this gap between the PD and the optimization based controllers to bring the best of both together. We derive two versions of PD-QPs: model-based and model-free. Furthermore, for tracking time-varying trajectories, we establish asymptotic stability for the model-based PD-QP, and ultimate boundedness for the model-free PD-QP. The performance of the PD-QPs is evaluated on two robot models: a fully actuated cart-pole and an underactuated 5-DOF biped.",
        "primary_area": "",
        "author": "Shishir Kolathaya;Sushant Veer;Shishir Kolathaya;Sushant Veer",
        "authorids": "/37060909000;/37085702725;/37060909000;/37085702725",
        "aff": "Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru, India; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968214/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6892543125772048482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Indian Institute of Science;Princeton University",
        "aff_unique_dep": "Robert Bosch Center for Cyber Physical Systems;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.iisc.ac.in;https://www.princeton.edu",
        "aff_unique_abbr": "IISc;Princeton",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Bengaluru;Princeton",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "8967895",
        "title": "PPR-Net:Point-wise Pose Regression Network for Instance Segmentation and 6D Pose Estimation in Bin-picking Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate object 6D pose estimation is a core task for robot bin-picking applications, especially when objects are randomly stacked with heavy occlusion. To address this problem, this paper proposes a simple but novel Point-wise Pose Regression Network (PPR-Net). For each point in the point cloud, the network regresses a 6D pose of the object instance that the point belongs to. We argue that the regressed poses of points from the same object instance should be located closely in pose space. Thus, these points can be clustered into different instances and their corresponding objects' 6D poses can be estimated simultaneously. In our experiments, PPR-Net outperforms the state-of-the-art approach by 15% - 41% in average precision when evaluated on the benchmark Sil\u00e9ane dataset. In addition, it also works well in real world robot bin-picking tasks.",
        "primary_area": "",
        "author": "Zhikai Dong;Sicheng Liu;Tao Zhou;Hui Cheng;Long Zeng;Xingyao Yu;Houde Liu;Zhikai Dong;Sicheng Liu;Tao Zhou;Hui Cheng;Long Zeng;Xingyao Yu;Houde Liu",
        "authorids": "/37087324269;/37086476789;/37087323922;/38008557800;/37087324062;/37087324395;/37085401214;/37087324269;/37086476789;/37087323922;/38008557800;/37087324062;/37087324395;/37085401214",
        "aff": "International Graduate School at Shenzhen, Tsinghua University; International Graduate School at Shenzhen, Tsinghua University; SenseTime Research; Sun Yat-Sen University; International Graduate School at Shenzhen, Tsinghua University; SenseTime Research; International Graduate School at Shenzhen, Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967895/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16103378087142640613&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;1;0",
        "aff_unique_norm": "Tsinghua University;SenseTime;Sun Yat-sen University",
        "aff_unique_dep": "International Graduate School;SenseTime Research;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.sensetime.com;http://www.sysu.edu.cn/",
        "aff_unique_abbr": "THU;SenseTime;SYSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967890",
        "title": "PanopticFusion: Online Volumetric Semantic Mapping at the Level of Stuff and Things",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose PanopticFusion, a novel online volumetric semantic mapping system at the level of stuff and things. In contrast to previous semantic mapping systems, PanopticFusion is able to densely predict class labels of a background region (stuff) and individually segment arbitrary foreground objects (things). In addition, our system has the capability to reconstruct a large-scale scene and extract a labeled mesh thanks to its use of a spatially hashed volumetric map representation. Our system first predicts pixel-wise panoptic labels (class labels for stuff regions and instance IDs for thing regions) for incoming RGB frames by fusing 2D semantic and instance segmentation outputs. The predicted panoptic labels are integrated into the volumetric map together with depth measurements while keeping the consistency of the instance IDs, which could vary frame to frame, by referring to the 3D map at that moment. In addition, we construct a fully connected conditional random field (CRF) model with respect to panoptic labels for map regularization. For online CRF inference, we propose a novel unary potential approximation and a map division strategy. We evaluated the performance of our system on the ScanNet (v2) dataset. PanopticFusion outperformed or compared with state-of-the-art offline 3D DNN methods in both semantic and instance segmentation benchmarks. Also, we demonstrate a promising augmented reality application using a 3D panoptic map generated by the proposed system.",
        "primary_area": "",
        "author": "Gaku Narita;Takashi Seno;Tomoya Ishikawa;Yohsuke Kaji;Gaku Narita;Takashi Seno;Tomoya Ishikawa;Yohsuke Kaji",
        "authorids": "/37087323216;/37087325051;/37087322817;/37087325179;/37087323216;/37087325051;/37087322817;/37087325179",
        "aff": "R&D Center, Sony Corporation; R&D Center, Sony Corporation; R&D Center, Sony Corporation; R&D Center, Sony Corporation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967890/",
        "gs_citation": 232,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3765447842487556703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sony Corporation",
        "aff_unique_dep": "R&D Center",
        "aff_unique_url": "https://www.sony.com",
        "aff_unique_abbr": "Sony",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967781",
        "title": "Paper-based modular origami gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel method to construct a versatile gripper which can grasp various sizes and shapes of objects is proposed. The design and construction of this gripper is based on a paper folding technique called `modular origami' This particular type of origami is constructed from multiple modules which can transform its shape by rotation. The gripper is actuated by a single motor using a linkage mechanism. The grasping part of this gripper is made of paper, thus it provides sufficient compliance to bend itself and create multiple contact points around objects with different shapes. This gripper can be used in two modes: force grasping and cage grasping. The proposed gripper was tested on objects with various shapes, weights and sizes. Furthermore, how the property of the paper affects the performance of the gripper was also tested. The thickness of the gripper material affects the compliance of the gripper and the range of sizes of objects which can be successfully gripped.",
        "primary_area": "",
        "author": "Ratchatida Phummapooti;Natthanicha Jamroonpan;Pongsakorn Polchankajorn;Eakkachai Pengwang;Thavida Maneewarn;Ratchatida Phummapooti;Natthanicha Jamroonpan;Pongsakorn Polchankajorn;Eakkachai Pengwang;Thavida Maneewarn",
        "authorids": "/37087324458;/37087325118;/37704867800;/37869727200;/37330688800;/37087324458;/37087325118;/37704867800;/37869727200;/37330688800",
        "aff": "Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, 126, Prachautid Rd, Bangkok, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, 126, Prachautid Rd, Bangkok, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, 126, Prachautid Rd, Bangkok, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, 126, Prachautid Rd, Bangkok, Thailand; Institute of Field Robotics, King Mongkut\u2019s University of Technology Thonburi, 126, Prachautid Rd, Bangkok, Thailand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967781/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11673276043353077481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "King Mongkut\u2019s University of Technology Thonburi",
        "aff_unique_dep": "Institute of Field Robotics",
        "aff_unique_url": "http://www.kmutt.ac.th",
        "aff_unique_abbr": "KMUTT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bangkok",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Thailand"
    },
    {
        "id": "8967958",
        "title": "Partial Caging: A Clearance-Based Definition and Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Caging grasps limit the mobility of an object to a bounded component of configuration space. We introduce a notion of partial cage quality based on maximal clearance of an escaping path. As this is a computationally demanding task even in a two-dimensional scenario, we propose a deep learning approach. We design two convolutional neural networks and construct a pipeline for real-time partial cage quality estimation directly from 2D images of object models and planar caging tools. One neural network, CageMaskNN, is used to identify caging tool locations that can support partial cages, while a second network that we call CageClearanceNN is trained to predict the quality of those configurations. A dataset of 3811 images of objects and more than 19 million caging tool configurations is used to train and evaluate these networks on previously unseen objects and caging tool configurations. Furthermore, the networks are trained jointly on configurations for both 3 and 4 caging tool configurations whose shape varies along a 1-parameter family of increasing elongation. In experiments, we study how the networks' performance depends on the size of the training dataset, as well as how to efficiently deal with unevenly distributed training data. In further analysis, we show that the evaluation pipeline can approximately identify connected regions of successful caging tool placements and we evaluate the continuity of the cage quality score evaluation along caging tool trajectories. Experiments show that evaluation of a given configuration on a GeForce GTX 1080 GPU takes less than 6 ms.",
        "primary_area": "",
        "author": "Anastasiia Varava;Michael C. Welle;Jeffrey Mahler;Ken Goldberg;Danica Kragic;Florian T. Pokomy;Anastasiia Varava;Michael C. Welle;Jeffrey Mahler;Ken Goldberg;Danica Kragic;Florian T. Pokomy",
        "authorids": "/37086619259;/38202265300;/37085356014;/37273026700;/37281296000;/37085905972;/37086619259;/38202265300;/37085356014;/37273026700;/37281296000;/37085905972",
        "aff": "Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of technology varavar; Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of technology varavar; AUTOLab, Department of Electrical Engineenng and Computer Science, University of California, Berkeley; AUTOLab, Department of Electrical Engineenng and Computer Science, University of California, Berkeley; Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of technology varavar; Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of technology varavar",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967958/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6703180288337975245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;University of California, Berkeley",
        "aff_unique_dep": "Division of Robotics, Perception and Learning;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.kth.se;https://www.berkeley.edu",
        "aff_unique_abbr": "KTH;UC Berkeley",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;1;1;0;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "8967800",
        "title": "Passive Inverted Ultra-Short Baseline (piUSBL) Localization: An Experimental Evaluation of Accuracy",
        "track": "main",
        "status": "Poster",
        "abstract": "The underwater environment poses significant challenges for accurate autonomous underwater vehicle (AUV) navigation. Electromagnetic (EM) waves rapidly attenuate due to absorption by water, thereby preventing the use of traditional EM -based positioning methods such as Global Positioning System (GPS) or visible -light cameras. Consequently, underwater positioning is often performed using systems that operate in the hydro -acoustic frequency range (<; 10 MHz). Recent work has demonstrated the efficacy of a novel acoustic positioning approach for multi-AUV operations called passive inverted ultra -short baseline (piUSBL) localization - with each vehicle equipped with a time -synchronized USBL array, oneway travel -time (OWTT) range and angle between the AUV and a single acoustic beacon enables multi-AUV navigation relative to the beacon. In this work, a piUSBL system using a fi ve-hydrophone pyramidal array implemented on a WAM-V autonomous surface vehicle (ASV) was used to experimentally gather acoustic measurements and to compare the accuracy of piUSBL localization against ground -truth from a differential GPS unit. This paper provides a comprehensive analysis of the positioning accuracy of the system in a real -world environment, both prior to and after Bayesian fi ltering, using two independent acoustic beacons for validation. We demonstrate that piUSBL provides acoustic range and angle measurements with errors of about p, \u00b1 cr = 0.03 \u00b1 1.49 m and p, \u00b1 cr = -0.11 \u00b1 3.16 \u00b0 respectively. These experimental results suggest that piUSBL localization can provide a highly accurate, inexpensive, and low power navigation solution for the next generation of miniature, low-cost underwater vehicle.",
        "primary_area": "",
        "author": "Nicholas R. Rypkema;Henrik Schmidt;Nicholas R. Rypkema;Henrik Schmidt",
        "authorids": "/37086147172;/37332005100;/37086147172;/37332005100",
        "aff": "Mechanical Engineering Department, Massachusetts Institute of Technology (MIT), 77 Massachusetts Ave, Cambridge, MA, USA; Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology (MIT), 77 Massachusetts Ave, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967800/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15605580353869903170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968132",
        "title": "Passive Model Reduction and Switching for Fast Soft Object Simulation with Intermittent Contacts",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel fast simulation framework for soft objects/robots with intermittent contacts, whose contact areas/locations can be varying. We first perform a balanced model reduction of the full-order FEM (finite element method) model for each contact mode with the contact forcing as the input and the shape of the object/robot as the output. We then devise the strategy of passive model reduction and passive model switching of these reduced-order models (each with its contact mode) utilizing the techniques of our recently-proposed passive mid-point integration (for the passivity of each reduced-order model) and simultaneous diagonalization (for the passivity of model reduction and model switching). The efficacy of the theory is then demonstrated with simulation and experimental results.",
        "primary_area": "",
        "author": "Jaemin Yoon;Ilkwon Hong;Dongjun Lee;Jaemin Yoon;Ilkwon Hong;Dongjun Lee",
        "authorids": "/37085562778;/37087322740;/37077171500;/37085562778;/37087322740;/37077171500",
        "aff": "Department of Mechanical & Aerospace Engineering, IAMD of Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, IAMD of Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, IAMD of Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968132/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5821628062281962097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968153",
        "title": "Path Planning for Surgery Robot with Bidirectional Continuous Tree Search and Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving a thorny issue of real-time path planning for surgery robot in uncertain environments, a novel algorithm named bidirectional continuous tree search (BCTS) is proposed. Most partially observable markov decision process (POMDP) planners address challenges of unknown environments with discrete states, observations and actions, which are fail to automate the operative procedure. However, the BCTS method addresses the issue by handling POMDPs in continuous state, observation and action spaces. The proposed approach has a bidirectional search structure with the intent of greatly improving the calculation efficiency. Meanwhile, Bayesian optimization (BO) algorithm is considered to dynamically sample promising actions while we construct a belief tree. In view of the speed of BO process, the upper and lower bounds of the optimal action values given by fast informed bound (FIB) and point-based value iteration (PBVI) limit the search scope, so we can improve the speed of BO. In addition, we apply an optimal path planning generator, radial basis function neural network (RBFNN), to obtain a smoother trajectory. Finally, simulation of glaucoma surgery has been carried out to explore the best surgical approach. The results show that the introduced structure can effectively guide the surgery robot to perform surgical procedures and receive a real-time as well as smooth path.",
        "primary_area": "",
        "author": "Rui-Jian Huang;Gui-Bin Bian;Chen Xin;Zhen Li;Zeng-Guang Hou;Rui-Jian Huang;Gui-Bin Bian;Chen Xin;Zhen Li;Zeng-Guang Hou",
        "authorids": "/37087324135;/37540363100;/37087322004;/37087325405;/37279945000;/37087324135;/37540363100;/37087322004;/37087325405;/37279945000",
        "aff": "The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Beijing, China; Beijing Tongren Eye Center, Beijing Tongren Hospital, Beijing Institute of Ophthalmology; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968153/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17244120755188694843&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Institute of Automation, Chinese Academy of Sciences;Beijing Tongren Hospital",
        "aff_unique_dep": "State Key Laboratory of Management and Control for Complex Systems;Beijing Institute of Ophthalmology",
        "aff_unique_url": "http://www.ia.cas.cn;",
        "aff_unique_abbr": "IA-CAS;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967602",
        "title": "Path planning with Incremental Roadmap Update for Visibility-based Target Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the visibility-based target tracking problem in which a mobile observer moving along a p-route, which we define as a fixed path for target tracking, tries to keep a mobile target in its field-of-view. By drawing a connection to the watchman's route problem, we find a set of conditions that must be satisfied by the p-route. Then we propose a metric for tracking to estimate a sufficient speed for the observer given the geometry of the environment. We show that the problem of finding the p-route on which the observer requires minimum speed is computationally intractable. We present a technique to find a p-route on which the observer needs at most twice the minimum speed to track the intruder and a reactive motion strategy for the observer.",
        "primary_area": "",
        "author": "Guillermo J. Laguna;Sourabh Bhattacharya;Guillermo J. Laguna;Sourabh Bhattacharya",
        "authorids": "/37086179988;/37275362500;/37086179988;/37275362500",
        "aff": "Department of Computer Science and Department of Mechanical Engineering at, Iowa State University, Ames, Iowa, USA; Department of Computer Science and Department of Mechanical Engineering at, Iowa State University, Ames, Iowa, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967602/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11870296535233368018&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967763",
        "title": "Pedestrian Density Prediction for Efficient Mobile Robot Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to predict humans in unexplored map areas given limited observations of the environment. We used a geometric representation of the environment based on cost maps and semantic room categorization. Human density distributions were generated using a human tracker based on LiDAR data recorded by a mobile robot. A Gaussian Process (GP) regression model was created to predict human density in surrounding unobserved map locations. GP prediction performance was evaluated on density data recorded in a series of ten simulations of 25 persons in an office setting, and in real-world robot deployments in an office-like environment. Experimental results demonstrate that the current method can predict human locations with an accuracy average of 70%.",
        "primary_area": "",
        "author": "Marc Patrick Zapf;Motoaki Kawanabe;Luis Yoichi Morales Saiki;Marc Patrick Zapf;Motoaki Kawanabe;Luis Yoichi Morales Saiki",
        "authorids": "/37085553777;/37409624400;/37087324150;/37085553777;/37409624400;/37087324150",
        "aff": "CR/RTC5-AP, Bosch (China) Investment Co. Ltd., P.R. China; Department of Dynamic Brain Imaging, Advanced Telecommunications Research Institute International, Kyoto, Japan; Nagoya University Institute of Innovation for Future Society, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967763/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=271529434537106458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Bosch (China) Investment Co. Ltd.;Advanced Telecommunications Research Institute International;Nagoya University",
        "aff_unique_dep": ";Department of Dynamic Brain Imaging;Institute of Innovation for Future Society",
        "aff_unique_url": ";https://www.atr.org;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": ";ATR;Nagoya U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Kyoto",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "8968601",
        "title": "People\u2019s V-Formation and Side-by-Side Model Adapted to Accompany Groups of People by Social Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new method to allow robots to accompany a person or a group of people imitating pedestrians behavior. Two-people groups usually walk in a side-by-side formation and three-people groups walk in a V-formation so that they can see each other. For this reason, the proposed method combines a Side-by-side and V-formation pedestrian model with the Anticipative Kinodynamic Planner (AKP). Combining these methods, the robot is able to do an anticipatory accompaniment of groups of humans, as well as to avoid static and dynamic obstacles in advance, while keeping the prescribed formations. The proposed framework allows also a dynamical re-positioning of the robot, if the physical position of the partners change in the group formation. Furthermore, people have a randomness factor that the robot has to manage, for that reason, the system was adapted to deal with changes in people's velocity, orientation and occlusions. Finally, the method has been validated using synthetic experiments and real-life experiments with our Tibi robot. In addition, a user study has been realized to reveal the social acceptability of the method.",
        "primary_area": "",
        "author": "Ely Repiso;Francesco Zanlungo;Takayuki Kanda;Ana\u00eds Garrell;Alberto Sanfeliu;Ely Repiso;Francesco Zanlungo;Takayuki Kanda;Ana\u00eds Garrell;Alberto Sanfeliu",
        "authorids": "/37086279908;/38495607400;/38599608900;/37586306600;/37270957300;/37086279908;/38495607400;/38599608900;/37586306600;/37270957300",
        "aff": "Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Llorens Artigas 4\u20136,, Barcelona, Spain; ATR Intelligent Robotics Laboratories, 2-2-2 Hikaridai Seika-cho Soraku-gun, Kyoto, Japan; ATR Intelligent Robotics Laboratories, 2-2-2 Hikaridai Seika-cho Soraku-gun, Kyoto, Japan; Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Llorens Artigas 4\u20136,, Barcelona, Spain; Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Llorens Artigas 4\u20136,, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968601/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15923539634788322298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Rob\u00f2tica i Inform\u00e0tica Industrial;ATR Intelligent Robotics Laboratories",
        "aff_unique_dep": "CSIC-UPC;",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Barcelona;Kyoto",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Spain;Japan"
    },
    {
        "id": "8968078",
        "title": "Perception System Design for Low-Cost Commercial Ground Robots: Sensor Configurations, Calibration, Localization and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "For commercially successful ground robots, high degree of autonomy, low manufacturing and maintenance cost, as well as minimized deployment limitations in different environments are essential attributes. To deliver an `anywhere deployable' product, it is impractical to rely on one single sensor or one single piece of algorithm to overcome all related challenges. Instead, the entire robotic system should be dedicated designed, including the choices of sensors, processors, algorithm integration for various functionality, and so on.This paper presents our design of perception system for commercial ground robots, which is able to operate in most common environments. The designed system is equipped with low-cost sensors and processors. The first key contribution of this paper is the design of the robotic sensory system, which includes a monocular camera, a 2D laser range finder (LRF), wheel encoders, and an inertial measurement unit (IMU). Our sensory system can be built at a cost of as low as $100. Furthermore, the selected sensors provide complementary characteristics for perception of both robot ego-motion and its surrounding environments, which are the prerequisites for `anywhere' deployment. The second key contribution of this paper is that a complete set of technologies is proposed based on our sensor systems, including sensor calibration (factory calibration and online calibration), localization (environmental exploring and re-localization), as well as mapping. The proposed methodology includes both efficient engineering implementation and theoretical novelty for high performance systems. Experimental results from our robotic testing platform and off-the-shelf commercial robots are presented. These results demonstrate that the proposed system can be deployed in various environmental conditions without performance compromise.",
        "primary_area": "",
        "author": "Yiming Chen;Mingming Zhang;Dongsheng Hong;Chengcheng Deng;Mingyang Li;Yiming Chen;Mingming Zhang;Dongsheng Hong;Chengcheng Deng;Mingyang Li",
        "authorids": "/37087323948;/37087325241;/37087322977;/37087325256;/37086936897;/37087323948;/37087325241;/37087322977;/37087325256;/37086936897",
        "aff": "Alibaba A.I. Labs, Hangzhou, China; Alibaba A.I. Labs, Hangzhou, China; Alibaba A.I. Labs, Hangzhou, China; Alibaba A.I. Labs, Hangzhou, China; Alibaba A.I. Labs, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968078/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7422007506025410613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Alibaba A.I. Labs",
        "aff_unique_dep": "A.I. Labs",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba A.I. Labs",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968293",
        "title": "Perception as prediction using general value functions in autonomous driving applications",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose and demonstrate a framework called perception as prediction for autonomous driving that uses general value functions (GVFs) to learn predictions. Perception as prediction learns data-driven predictions relating to the impact of actions on the agent's perception of the world. It also provides a data-driven approach to predict the impact of the anticipated behavior of other agents on the world without explicitly learning their policy or intentions. We demonstrate perception as prediction by learning to predict an agent's front safety and rear safety with GVFs, which encapsulate anticipation of the behavior of the vehicle in front and in the rear, respectively. The safety predictions are learned through random interactions in a simulated environment containing other agents. We show that these predictions can be used to produce similar control behavior to an LQR-based controller in an adaptive cruise control problem as well as provide advanced warning when the vehicle behind is approaching dangerously. The predictions are compact policy-based predictions that support prediction of the long term impact on safety when following a given policy. We analyze two controllers that use the learned predictions in a racing simulator to understand the value of the predictions and demonstrate their use in the real-world on a Clearpath Jackal robot and an autonomous vehicle platform.",
        "primary_area": "",
        "author": "Daniel Graves;Kasra Rezaee;Sean Scheideman;Daniel Graves;Kasra Rezaee;Sean Scheideman",
        "authorids": "/37823099700;/38491501500;/37087321921;/37823099700;/38491501500;/37087321921",
        "aff": "Huawei Technologies Canada, Ltd., Edmonton, Canada; Huawei Technologies Canada, Ltd., Markham, Canada; University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968293/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5262508561751509179&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Huawei;University of Alberta",
        "aff_unique_dep": "Huawei Technologies;",
        "aff_unique_url": "https://www.huawei.com/ca-en/;https://www.ualberta.ca",
        "aff_unique_abbr": "Huawei;UAlberta",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Edmonton;Markham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968191",
        "title": "Perception of Pedestrian Avoidance Strategies of a Self-Balancing Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots moving in crowded environments have to navigate among pedestrians safely. Ideally, the way the robot avoids the pedestrians should not only be physically safe but also perceived safe and comfortable. Despite the rich literature in collision-free crowd navigation, limited research has been conducted on how humans perceive robot behaviors in the navigation context. In this paper, we implement three local pedestrian avoidance strategies inspired by human avoidance behaviors on a self-balancing mobile robot and evaluate their perception in a human-robot crossing scenario through a large-scale user study with 98 participants. The study reveals that the avoidance strategies positively affect the participants' perception of the robot's safety, comfort, and awareness to different degrees. Furthermore, the participants perceive the robot as more intelligent, friendly and reliable in the last trial than in the first even with the same strategy.",
        "primary_area": "",
        "author": "Shih-Yun Lo;Katsu Yamane;Ken-ichiro Sugiyama;Shih-Yun Lo;Katsu Yamane;Ken-ichiro Sugiyama",
        "authorids": "/37087323268;/37291289300;/37087323154;/37087323268;/37291289300;/37087323154",
        "aff": "University of Texas Austin, Austin, TX, USA; Honda Research Institute USA, Mountain View, CA, USA; Honda R&D Life Creation Center, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968191/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2953627767612844649&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Texas at Austin;Honda Research Institute USA;Honda R&D Life Creation Center",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utexas.edu;https://honda-ri.com;https://www.honda.com",
        "aff_unique_abbr": "UT Austin;HRI USA;",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Austin;Mountain View;Saitama",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "8968202",
        "title": "Performance Guarantees for Receding Horizon Search with Terminal Cost",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method of using terminal costs in the construction of a receding horizon search path. We prove that the proposed method of constructing search paths provides a theoretical lower bound on the performance of the search path. Our result can be interpreted as ensuring that the receding horizon path performs no worse in expectation than a given sub-optimal search path. This result is especially practical for subsea applications where, due to use of side-scan sonar in search applications, search paths typically consist of parallel straight lines. Thus for subsea search applications, our approach ensures that expected performance is no worse than the usual subsea search path, and it might be much better. We demonstrate the efficacy of the proposed method by planning search paths in simulation using real-world data that was acquired by an autonomous underwater vehicle during a subsea survey of Boston Harbor.",
        "primary_area": "",
        "author": "Benjamin Biggs;Daniel J. Stilwell;Harun Yetkin;James McMahon;Benjamin Biggs;Daniel J. Stilwell;Harun Yetkin;James McMahon",
        "authorids": "/37087324207;/37283170000;/37074562500;/37085353635;/37087324207;/37283170000;/37074562500;/37085353635",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechatronics Engineering, Bart\u0131n University, Turkey; US Naval Research Laboratory, Washington, D.C., USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968202/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7848443684387559517&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Virginia Tech;Bart\u0131n University;US Naval Research Laboratory",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering;Department of Mechatronics Engineering;",
        "aff_unique_url": "https://www.vt.edu;http://www.bartin.edu.tr;https://www.nrl.navy.mil",
        "aff_unique_abbr": "VT;;NRL",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Blacksburg;;Washington, D.C.",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;T\u00fcrkiye"
    },
    {
        "id": "8967765",
        "title": "Periodic Trajectory Planning and Robust Output Zeroing Control for Underactuated Bipedal Robots with Predicted Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "For underactuated bipedal robots, it is important to compensate disturbances which affects the zero dynamics to realize a stable locomotion when we use output zeroing controllers. In order to deal with such disturbances, this paper presents a framework of a periodic trajectory planning and a robust output zeroing controller using a disturbance model learned by Gaussian process regression (GPR). In particular, we propose a control method considering the modeling uncertainty of the disturbance model by using a variance information of GPR model. We show the effectiveness of the proposed method through a numerical simulation of walking control of an underactuated robot model affected by an external force.",
        "primary_area": "",
        "author": "Rin Takano;Junho Chang;Masaki Yamakita;Rin Takano;Junho Chang;Masaki Yamakita",
        "authorids": "/37086014041;/37086449236;/37279385100;/37086014041;/37086449236;/37279385100",
        "aff": "Department of Systems and Control, Tokyo Institute of Technology, 2-12-1 Oookayama, Meguro-ku, Tokyo, Japan; Department of Systems and Control, Tokyo Institute of Technology, 2-12-1 Oookayama, Meguro-ku, Tokyo, Japan; Department of Systems and Control, Tokyo Institute of Technology, 2-12-1 Oookayama, Meguro-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967765/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:jsOJgvZqHiYJ:scholar.google.com/&scioq=Periodic+Trajectory+Planning+and+Robust+Output+Zeroing+Control+for+Underactuated+Bipedal+Robots+with+Predicted+Disturbances&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Systems and Control",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oookayama",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968558",
        "title": "Permanent Magnets based Actuator for Microrobots Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel design of four permanent magnet based actuator for magnetic drug targeting of therapeutic microrobots. Drugs are transported through therapeutic magnetic boluses composed of magnetic particles controlled by magnetic gradients. In this study, to maximize the effect of the treatment and minimize adverse effects on the patient, a magnetic actuator have been developed to wirelessly control microrobots in a fluidic environment using four external magnets. Experimental validation is carried using the robotic arm Fanuc LR Mate 200iD to demonstrate the steerability of the magnetic microrobots under different trajectory constraints in viscous fluidic environment.",
        "primary_area": "",
        "author": "Manel Abbes;Karim Belharet;Hassen Mekki;Gerard Poisson;Manel Abbes;Karim Belharet;Hassen Mekki;Gerard Poisson",
        "authorids": "/37086449028;/37586616100;/37643055100;/37283044300;/37086449028;/37586616100;/37643055100;/37283044300",
        "aff": "Laboratoire NOCCS, Univ. de Sousse, Rue Khalifa Karoui, Sousse, Tunisie; Laboratoire PRISME, Hautes Etudes \u00c9tudes d\u2019Ing\u00e9nieur, campus Centre, Site Balsan, 2 allee Jean Vaill\u00e9, Chateauroux, France; Laboratoire NOCCS, Univ. de Sousse, Rue Khalifa Karoui, Sousse, Tunisie; Laboratoire PRISME, Univ. Orl\u00e9ans, Bourges, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968558/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14237700606403147851&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Sousse;Hautes Etudes \u00c9tudes d\u2019Ing\u00e9nieur;University of Orl\u00e9ans",
        "aff_unique_dep": "Laboratoire NOCCS;Laboratoire PRISME;Laboratoire PRISME",
        "aff_unique_url": ";;https://www.univ-orleans.fr",
        "aff_unique_abbr": "Univ. de Sousse;;Univ. Orl\u00e9ans",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Sousse;Centre;Bourges",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Tunisia;France"
    },
    {
        "id": "8967645",
        "title": "Person-following for Telepresence Robots Using Web Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Many existing mobile robotic telepresence systems have equipped with two web cameras, one is a forward-facing camera (FF camera) for video communication, and the other is a downward-facing camera (DF camera) for robot navigation. In this paper, we present a new framework of autonomous person-following for telepresence robots using the two web cameras. Based on correlation filters tracking methods, we use the FF camera to track the upper body of a person and the DF camera to localize and track the person's feet. We improve the robustness of feet trackers, consisting of a left foot tracker and a right foot tracker, by making full use of the spatial constraints of the human body parts. We conducted experiments on tracking in different environmental situations and real person-following scenario to evaluate the effectiveness of our method.",
        "primary_area": "",
        "author": "Xianda Cheng;Yunde Jia;Jingyu Su;Yuwei Wu;Xianda Cheng;Yunde Jia;Jingyu Su;Yuwei Wu",
        "authorids": "/37087323616;/37273296500;/37087323670;/37678166800;/37087323616;/37273296500;/37087323670;/37678166800",
        "aff": "Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, P.R. China; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, P.R. China; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, P.R. China; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967645/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11462209511287307092&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "Beijing Laboratory of Intelligent Information Technology",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968544",
        "title": "Physical Fatigue Analysis of Assistive Robot Teleoperation via Whole-body Motion Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot teleoperation via motion mapping has been demonstrated to be an efficient and intuitive approach for controlling and teaching the whole-body motion coordination of humanoid robots. However, the physical fatigue in the usage of such robot teleoperation interfaces may prevent this approach to be widely used in large scale by diverse workforce populations. As a result, this paper conducts a user study to investigate the physical fatigue of teleoperators in the whole-body motion mapping teleoperation of a mobile humanoid assistive robot. Through a Vicon motion capture system, participants teleoperated the robot to perform general purpose assistive tasks that involve reaching-to-grasp, bimanual manipulation, loco-manipulation and human-robot interaction. We assess the physical fatigue based on surface electromyography (sEMG) measurement, and compare it between different tasks and muscles. Our analysis results indicate that: (1) Fatigue happens more in the tasks that involve more precise manipulation and steady posture maintenance; (2) Deltoids, Biceps and Trapezius are used more for such tasks and thus have more fatigue than others. These findings imply that automating the fatigue-causing task components may reduce the physical fatigue in motion mapping teleoperation.",
        "primary_area": "",
        "author": "Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li;Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li",
        "authorids": "/37087325287;/37087323052;/37085821311;/37087325287;/37087323052;/37085821311",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Mechanical Engineering Department, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968544/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12529897201260535216&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering Program",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968018",
        "title": "Piecewise Rigid Scene Flow with Implicit Motion Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a novel variational approach to estimate the scene flow from RGB-D images. We regularize the ill-conditioned problem of scene flow estimation in a unified framework by enforcing piecewise rigid motion through decomposition into rotational and translational motion parts. Our model crucially regularizes these components by an L0 \u201cnorm\u201d, thereby facilitating implicit motion segmentation in a joint energy minimization problem. Yet, we also show that this energy can be efficiently minimized by a proximal primal-dual algorithm. By implementing this approximate L0 rigid motion regularization, our scene flow estimation approach implicitly segments the observed scene of into regions of nearly constant rigid motion. We evaluate our joint scene flow and segmentation estimation approach on a variety of test scenarios, with and without ground truth data, and demonstrate that we outperform current scene flow techniques.",
        "primary_area": "",
        "author": "Andreas G\u00f6rlitz;Jonas Geiping;Andreas Kolb;Andreas G\u00f6rlitz;Jonas Geiping;Andreas Kolb",
        "authorids": "/37087324616;/37087324410;/37394143400;/37087324616;/37087324410;/37394143400",
        "aff": "Computer Graphics and Multimedia Group, University of Siegen, Germany; Visual Scene Analysis Group, University of Siegen, Germany; Computer Graphics and Multimedia Group, University of Siegen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968018/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7827996144237099286&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Siegen",
        "aff_unique_dep": "Computer Graphics and Multimedia Group",
        "aff_unique_url": "https://www.uni-siegen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968263",
        "title": "Pixel-Attentive Policy Gradient for Multi-Fingered Grasping in Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in on-policy reinforcement learning (RL) methods enabled learning agents in virtual environments to master complex tasks with high-dimensional and continuous observation and action spaces. However, leveraging this family of algorithms in multi-fingered robotic grasping remains a challenge due to large sim-to-real fidelity gaps and the high sample complexity of on-policy RL algorithms. This work aims to bridge these gaps by first reinforcement-learning a multi-fingered robotic grasping policy in simulation that operates in the pixel space of the input: a single depth image. Using a mapping from pixel space to Cartesian space according to the depth map, this method transfers to the real world with high fidelity and introduces a novel attention mechanism that substantially improves grasp success rate in cluttered environments. Finally, the direct-generative nature of this method allows learning of multi-fingered grasps that have flexible end-effector positions, orientations and rotations, as well as all degrees of freedom of the hand.",
        "primary_area": "",
        "author": "Bohan Wu;Iretiayo Akinola;Peter K. Allen;Bohan Wu;Iretiayo Akinola;Peter K. Allen",
        "authorids": "/37087323203;/37086319261;/37280851400;/37087323203;/37086319261;/37280851400",
        "aff": "Columbia University Robotics Group, Columbia University, New York, USA; Columbia University Robotics Group, Columbia University, New York, USA; Columbia University Robotics Group, Columbia University, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968263/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8242018469084115630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Robotics Group",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968224",
        "title": "Pixels to Plans: Learning Non-Prehensile Manipulation by Imitating a Planner",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method enabling robots to quickly learn to manipulate objects by leveraging a motion planner to generate \u201cexpert\u201d training trajectories from a small amount of human-labeled data. In contrast to the traditional sense-plan-act cycle, we propose a deep learning architecture and training regimen called PtPNet that can estimate effective end-effector trajectories for manipulation directly from a single RGB-D image of an object. Additionally, we present a data collection and augmentation pipeline that enables the automatic generation of large numbers (millions) of training image and trajectory examples with almost no human labeling effort.We demonstrate our approach in a non-prehensile tool-based manipulation task, specifically picking up shoes with a hook. In hardware experiments, PtPNet generates motion plans (open-loop trajectories) that reliably (89% success over 189 trials) pick up four very different shoes from a range of positions and orientations, and reliably picks up a shoe it has never seen before. Compared with a traditional sense-plan-act paradigm, our system has the advantages of operating on sparse information (single RGB-D frame), producing high-quality trajectories much faster than the expert planner (300ms versus several seconds), and generalizing effectively to previously unseen shoes. Video available at https://youtu.be/voIkyiBtwn4.",
        "primary_area": "",
        "author": "Tarik Tosun;Eric Mitchell;Ben Eisner;Jinwook Huh;Bhoram Lee;Daewon Lee;Volkan Isler;H. Sebastian Seung;Daniel Lee;Tarik Tosun;Eric Mitchell;Ben Eisner;Jinwook Huh;Bhoram Lee;Daewon Lee;Volkan Isler;H. Sebastian Seung;Daniel Lee",
        "authorids": "/37085336253;/37087324611;/37087324209;/37085775953;/37859557700;/37599980600;/37298487800;/37087322312;/37280609600;/37085336253;/37087324611;/37087324209;/37085775953;/37859557700;/37599980600;/37298487800;/37087322312;/37280609600",
        "aff": "Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York; Samsung AI Center NY, 123 West 18th Street, New York, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968224/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14728449393680992795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967550",
        "title": "Planning Beyond The Sensing Horizon Using a Learned Context",
        "track": "main",
        "status": "Poster",
        "abstract": "Last-mile delivery systems commonly propose the use of autonomous robotic vehicles to increase scalability and efficiency. The economic inefficiency of collecting accurate prior maps for navigation motivates the use of planning algorithms that operate in unmapped environments. However, these algorithms typically waste time exploring regions that are unlikely to contain the delivery destination. Context is key information about structured environments that could guide exploration toward the unknown goal location, but the abstract idea is difficult to quantify for use in a planning algorithm. Some approaches specifically consider contextual relationships between objects, but would perform poorly in object-sparse environments like outdoors. Recent deep learning-based approaches consider context too generally, making training/transferability difficult. Therefore, this work proposes a novel formulation of utilizing context for planning as an image-to-image translation problem, which is shown to extract terrain context from semantic gridmaps, into a metric that an exploration-based planner can use. The proposed framework has the benefit of training on a static dataset instead of requiring a time-consuming simulator. Across 42 test houses with layouts from satellite images, the trained algorithm enables a robot to reach its goal 189% faster than with a context-unaware planner, and within 63% of the optimal path computed with a prior map. The proposed algorithm is also implemented on a vehicle with a forward-facing camera in a high-fidelity, Unreal simulation of neighborhood houses.",
        "primary_area": "",
        "author": "Michael Everett;Justin Miller;Jonathan P. How;Michael Everett;Justin Miller;Jonathan P. How",
        "authorids": "/37418751400;/37086030933;/37276347700;/37418751400;/37086030933;/37276347700",
        "aff": "Aerospace Controls Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA, USA; Robotics and Intelligent Vehicles, Ford Motor Company, Dearborn, MI, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967550/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10115604587525641357&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Ford Motor Company",
        "aff_unique_dep": "Aerospace Controls Laboratory;Robotics and Intelligent Vehicles",
        "aff_unique_url": "https://web.mit.edu;https://www.ford.com",
        "aff_unique_abbr": "MIT;Ford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cambridge;Dearborn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968172",
        "title": "Planning High-Quality Motions for Concentric Tube Robots in Point Clouds via Parallel Sampling and optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method that plans motions for a concentric tube robot to automatically reach surgical targets inside the body while avoiding obstacles, where the patient's anatomy is represented by point clouds. Point clouds can be generated intra-operatively via endoscopic instruments, enabling the system to update obstacle representations over time as the patient anatomy changes during surgery. Our new motion planning method uses a combination of sampling-based motion planning methods and local optimization to efficiently handle point cloud data and quickly compute high quality plans. The local optimization step uses an interior point optimization method, ensuring that the computed plan is feasible and avoids obstacles at every iteration. This enables the motion planner to run in an anytime fashion, i.e., the method can be stopped at any time and the best solution found up until that point is returned. We demonstrate the method's efficacy in three anatomical scenarios, including two generated from endoscopic videos of real patient anatomy.",
        "primary_area": "",
        "author": "Alan Kuntz;Mengyu Fu;Ron Alterovitz;Alan Kuntz;Mengyu Fu;Ron Alterovitz",
        "authorids": "/37085508764;/37086578786;/37320259800;/37085508764;/37086578786;/37320259800",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968172/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6118340282142783212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unc.edu",
        "aff_unique_abbr": "UNC Chapel Hill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chapel Hill",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968452",
        "title": "Planning Reactive Manipulation in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "When robots perform manipulation tasks, they need to determine their own movement, as well as how to make and break contact with objects in their environment. Reasoning about the motions of robots and objects simultaneously leads to a constrained planning problem in a high-dimensional state-space. Additionally, when environments change dynamically motions must be computed in real-time. To this end, we propose a feedback planner for manipulation. We model manipulation as constrained motion and use this model to automatically derive a set of constraint-based controllers. These controllers are used in a switching-control scheme, where the active controller is chosen by a reinforcement learning agent. Our approach is capable of addressing tasks with second-order dynamics, closed kinematic chains, and time-variant environments. We validated our approach in simulation and on a real, dual-arm robot. Extensive simulation of three distinct robots and tasks show a significant increase in robustness compared to a previous approach.",
        "primary_area": "",
        "author": "Philipp S. Schmitt;Florian Wirnshofer;Kai M. Wurm;Georg v. Wichert;Wolfram Burgard;Philipp S. Schmitt;Florian Wirnshofer;Kai M. Wurm;Georg v. Wichert;Wolfram Burgard",
        "authorids": "/37086094898;/37085450321;/37542754500;/37330987000;/37270485300;/37086094898;/37085450321;/37542754500;/37330987000;/37270485300",
        "aff": "Siemens Corporate Technology, Munich, Germany; Siemens Corporate Technology, Munich, Germany; Siemens Corporate Technology, Munich, Germany; Siemens Corporate Technology, Munich, Germany; Department of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968452/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3213759600664472798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Siemens AG;University of Freiburg",
        "aff_unique_dep": "Corporate Technology;Department of Computer Science",
        "aff_unique_url": "https://www.siemens.com;https://www.uni-freiburg.de",
        "aff_unique_abbr": "Siemens;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967718",
        "title": "Planning in Stochastic Environments with Goal Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the Goal Uncertain Stochastic Shortest Path (GUSSP) problem - a general framework to model path planning and decision making in stochastic environments with goal uncertainty. The framework extends the stochastic shortest path (SSP) model to dynamic environments in which it is impossible to determine the exact goal states ahead of plan execution. GUSSPs introduce flexibility in goal specification by allowing a belief over possible goal configurations. The unique observations at potential goals helps the agent identify the true goal during plan execution. The partial observability is restricted to goals, facilitating the reduction to an SSP with a modified state space. We formally define a GUSSP and discuss its theoretical properties. We then propose an admissible heuristic that reduces the planning time using FLARES - a start-of-the-art probabilistic planner. We also propose a determinization approach for solving this class of problems. Finally, we present empirical results on a search and rescue mobile robot and three other problem domains in simulation.",
        "primary_area": "",
        "author": "Sandhya Saisubramanian;Kyle Hollins Wray;Luis Pineda;Shlomo Zilberstein;Sandhya Saisubramanian;Kyle Hollins Wray;Luis Pineda;Shlomo Zilberstein",
        "authorids": "/37087104876;/37086208879;/37085690832;/37285091900;/37087104876;/37086208879;/37085690832;/37285091900",
        "aff": "College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967718/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14078192127945574822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967777",
        "title": "Plasticity in Collective Decision-Making for Robots: Creating Global Reference Frames, Detecting Dynamic Environments, and Preventing Lock-ins",
        "track": "main",
        "status": "Poster",
        "abstract": "Swarm robots operate as autonomous agents and a swarm as a whole gets autonomous by its capability of collective decision-making. Despite intensive research on models of collective decision-making, the implementation in multi-robot systems is still challenging. Here, we advance the state of the art by introducing more plasticity to the decision-making process and by increasing the scenario difficulty. Most studies on large-scale multi-robot decision-making are limited to one instance of an iterated exploration-dissemination phase followed by successful and permanent convergence. We investigate a dynamic environment that requires constant collective monitoring of option qualities. Once a significant change in qualities is detected by the swarm, it has to collectively reconsider its previous decision accordingly. This is only possible by preventing lock-ins, a global consensus state of no return (i.e., a dominant majority of robots prevents the swarm from switching to another, possibly better option). In addition, we introduce a scenario of increased difficulty as the robots must locate themselves to assess the quality of an option. Using local communication, swarm robots propagate hop-count information throughout the swarm to form a global reference frame. We successfully validate our implementation in many swarm robot experiments concerning robustness to disruptions of the reference frame, scalability, and adaptivity to a dynamic environment.",
        "primary_area": "",
        "author": "Mohammad Divband Soorati;Maximilian Krome;Marco Mora-Mendoza;Javad Ghofrani;Heiko Hamann;Mohammad Divband Soorati;Maximilian Krome;Marco Mora-Mendoza;Javad Ghofrani;Heiko Hamann",
        "authorids": "/37086204877;/37087321925;/37087324077;/37086353080;/37683321200;/37086204877;/37087321925;/37087324077;/37086353080;/37683321200",
        "aff": "School of Electronics and Computer Science, University of Southampton, UK; Institute of Computer Engineering, University of L\u00fcbeck, Germany; Department of Computer Science, Stanford University, Stanford, CA, US; Department of Informatics and Mathematics, Dresden University of Applied Sciences, Germany; Institute of Computer Engineering, University of L\u00fcbeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967777/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13035653166226904275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;1",
        "aff_unique_norm": "University of Southampton;University of L\u00fcbeck;Stanford University;Dresden University of Applied Sciences",
        "aff_unique_dep": "School of Electronics and Computer Science;Institute of Computer Engineering;Department of Computer Science;Department of Informatics and Mathematics",
        "aff_unique_url": "https://www.southampton.ac.uk;https://www.uni-luebeck.de;https://www.stanford.edu;https://www.htwdd.de",
        "aff_unique_abbr": "Southampton;;Stanford;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stanford;Dresden",
        "aff_country_unique_index": "0;1;2;1;1",
        "aff_country_unique": "United Kingdom;Germany;United States"
    },
    {
        "id": "8968486",
        "title": "PnS: a Perspective-n-Spheres Algorithm for Laparoscope Calibration in Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate endoscope localization is a key element for Computer-Assisted Laparoscopic Surgery (CALS). External localizers track the endoscope pose and reconstruct the camera geometry through a calibration matrix. Perspective-n-Points (PnP) methods estimate this matrix from a set of paired point coordinates, given by the simultaneous position of a spherical marker on the image (2D coordinates) and in the external localizer frame (3D coordinates). In this paper, the PnP calibration is restated as an iterative Perspective-n-Spheres (PnS) problem: the spherical geometry of the marker is taken into account when computing the projection of its 3D center into the 2D image plane. Using calibration residuals as evaluation matrix, the proposed PnS provides better results compared to the State-of-the-Art (SoA) PnP methods. Furthermore, results show that the calibration yields different estimates due to different camera poses in the working volume. This is assumed to result from a lack of absolute precision in the marker localization across the external localizer workspace.",
        "primary_area": "",
        "author": "Mario Aric\u00f2;Guillaume Morel;Mario Aric\u00f2;Guillaume Morel",
        "authorids": "/37086937893;/37274022000;/37086937893;/37274022000",
        "aff": "CNRS, INSERM, ISIR-Agathe, 4 Place Jussieu, Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, ISIR-Agathe, 4 Place Jussieu, Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968486/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16495178911752979506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967849",
        "title": "Policy Distillation and Value Matching in Multiagent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiagent reinforcement learning (MARL) algorithms have been demonstrated on complex tasks that require the coordination of a team of multiple agents to complete. Existing works have focused on sharing information between agents via centralized critics to stabilize learning or through communication to improve performance, but do not generally consider how information can be shared between agents to address the curse of dimensionality in MARL. We posit that a multiagent problem can be decomposed into a multi-task problem where each agent explores a subset of the state space instead of exploring the entire state space. This paper introduces a multiagent actor-critic algorithm for combining knowledge from homogeneous agents through distillation and value-matching that outperforms policy distillation alone and allows further learning in discrete and continuous action spaces.",
        "primary_area": "",
        "author": "Samir Wadhwania;Dong-Ki Kim;Shayegan Omidshafiei;Jonathan P. How;Samir Wadhwania;Dong-Ki Kim;Shayegan Omidshafiei;Jonathan P. How",
        "authorids": "/37087322377;/37087324178;/37085451777;/37276347700;/37087322377;/37087324178;/37085451777;/37276347700",
        "aff": "Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967849/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4632584707921183635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968087",
        "title": "Pose Estimation for Omni-directional Cameras using Sinusoid Fitting",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel pose estimation method for geometric vision of omni-directional cameras. On the basis of the regularity of the pixel movement after camera pose changes, we formulate and prove the sinusoidal relationship between pixels movement and camera motion. We use the improved Fourier-Mellin invariant (iFMI) algorithm to find the motion of pixels, which was shown to be more accurate and robust than the feature-based methods. While iFMI works only on pin-hole model images and estimates 4 parameters (x, y, yaw, scaling), our method works on panoramic images and estimates the full 6 DoF3D transform, up to an unknown scale factor. For that we fit the motion of the pixels in the panoramic images, as determined by iFMI, to two sinusoidal functions. The offsets, amplitudes and phase-shifts of the two functions then represent the 3D rotation and translation of the camera between the two images. We perform experiments for 3D rotation, which show that our algorithm outperforms the feature-based methods in accuracy and robustness. We leave the more complex 3D translation experiments for future work.",
        "primary_area": "",
        "author": "Haofei Kuang;Qingwen Xu;Xiaoling Long;S\u00f6ren Schwertfeger;Haofei Kuang;Qingwen Xu;Xiaoling Long;S\u00f6ren Schwertfeger",
        "authorids": "/37086559488;/37087243310;/37087014332;/37391715800;/37086559488;/37087243310;/37087014332;/37391715800",
        "aff": "School of Information Science Technology, ShanghaiTech University, China; School of Information Science Technology, ShanghaiTech University, China; School of Information Science Technology, ShanghaiTech University, China; School of Information Science Technology, ShanghaiTech University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968087/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16184460945959992789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "School of Information Science Technology",
        "aff_unique_url": "https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967755",
        "title": "Pose-Aware Placement of Objects with Semantic Labels - Brandname-based Affordance Prediction and Cooperative Dual-Arm Active Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The Amazon Picking Challenge and the Amazon Robotics Challenge have shown significant progress in object picking from a cluttered scene, yet object placement remains challenging. It is useful to have pose-aware placement based on human and machine readable pieces on an object. For example, the brandname of an object placed on a shelf should be facing the human customers. The robotic vision challenges in the object placement task: a) the semantics and geometry of the object to be placed need to be analysed jointly; b) and the occlusions among objects in a cluttered scene could make it hard for proper understanding and manipulation. To overcome these challenges, we develop a pose-aware placement approach by spotting the semantic labels (e.g., brandnames) of objects in a cluttered tote and then carrying out a sequence of actions to place the objects on a shelf or on a conveyor with desired poses. Our major contributions include 1) providing an open benchmark dataset of objects and brandnames with multi-view segmentation for training and evaluations; 2) carrying out comprehensive evaluations for our brandname-based fully convolutional network (FCN) that can predict the affordance and grasp to achieve pose-aware placement, whose success rates decrease along with clutters; 3) showing that active manipulation with two cooperative manipulators and grippers can effectively handle the occlusion of brandnames. We analyzed the success rates and discussed the failure cases to provide insights for future applications. All data and benchmarks are available at https://text-pick-n-place.github.io/TextPNP/.",
        "primary_area": "",
        "author": "Yung-Shan Su;Shao-Huang Lu;Po-Sheng Ser;Wei-Ting Hsu;Wei-Cheng Lai;Biao Xie;Hong-Ming Huang;Teng-Yok Lee;Hung-Wen Chen;Lap-Fai Yu;Hsueh-Cheng Wang;Yung-Shan Su;Shao-Huang Lu;Po-Sheng Ser;Wei-Ting Hsu;Wei-Cheng Lai;Biao Xie;Hong-Ming Huang;Teng-Yok Lee;Hung-Wen Chen;Lap-Fai Yu;Hsueh-Cheng Wang",
        "authorids": "/37087324026;/37088722547;/37088728370;/37088722462;/37088731659;/37086346075;/37088722885;/37086079673;/37088729071;/37085623338;/37066008300;/37087324026;/37088722547;/37088728370;/37088722462;/37088731659;/37086346075;/37088722885;/37086079673;/37088729071;/37085623338;/37066008300",
        "aff": "Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Computer Science, University of Massachusetts at Boston, USA; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Delta Research Center, Taiwan; Department of Computer Science, George Mason University, USA; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967755/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6812027405120930497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;1;0;2;3;4;0",
        "aff_unique_norm": "National Chiao Tung University;University of Massachusetts at Boston;Mitsubishi Electric Research Laboratories;Delta Research Center;George Mason University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science;;;Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.umb.edu;https://www.merl.com;;https://www.gmu.edu",
        "aff_unique_abbr": "NCTU;UMass Boston;MERL;;GMU",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;2;0;0",
        "aff_campus_unique": "Taiwan;Boston;Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;1;0;1;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968216",
        "title": "Position-based monocular visual servoing of an unknown target using online self-supervised learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual servoing, i.e. control with visual information, is a valuable capability in many robotic applications. In particular, position based visual servoing (PBVS) estimates position information from the observed image to generate visual servo control. However, the estimation of the position of an unknown target using monocular images is still difficult due to the complexity of the image information. For the target estimation problem, we propose to integrate three complementary techniques for monocular visual servoing. First, to estimate the probability of a target's existence, the learning model with spatial features from convolution neural network is proposed. Second, the extended Kalman filter based on epipolar geometry estimates the 3D position of the target; moreover, from this 3D position, the perception model is trained online by self-generated virtual ground-truth. Finally, visual servo control is generated, and the resulting movement helps to construct epipolar geometry. Finally. the experimental validation is performed in a challenging setting involving occlusion and target's shape change.",
        "primary_area": "",
        "author": "Chungkeun Lee;Hoseong Seo;H. Jin Kim;Chungkeun Lee;Hoseong Seo;H. Jin Kim",
        "authorids": "/37086178234;/37085446499;/37599626400;/37086178234;/37085446499;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Gwanak-gu, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Gwanak-gu, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Gwanak-gu, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968216/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17032247679098326084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gwanak-gu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967589",
        "title": "Precise Correntropy-based 3D Object Modelling With Geometrical Traffic Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust 3D perception using LiDAR is of prime importance for robotics, and its fundamental core lies in precise object modelling resisting to noise and outliers. In this paper, a precise 3D object modelling algorithm is designed especially for the intelligent vehicles. The proposed algorithm is advantageous by leveraging the crucial traffic geometrical prior of road surface profile, and both the noise and outliers are elegantly handled by robust correntropy-based metric. More specifically, the road surface correction (RSC) method transforms each individual LiDAR measurement from its locally planar road surface to a globally ideal plane. This procedure essentially guarantees the reduction of vehicle's motion from arbitrary 3D motion to physically feasible 2D motion. To deal with the noise and outliers, a correntropy-based multi-frame matching (CorrMM) algorithm is proposed which has a robust objective function with respect to point-to-plane residual error. An efficient solver inspired by M-estimator and retraction technique on Lie group is developed, which elegantly converts the optimization of highly non-linear objective function into a simple quadratic programming (QP) problem. Extensive experimental results validate that the proposed algorithm attains more crisper 3D object models than several state-of-the-art algorithms on a challenging real traffic dataset.",
        "primary_area": "",
        "author": "Di Wang;Jianru Xue;Wei Zhan;Yinghan Jin;Nanning Zheng;Masayoshi Tomizuka;Di Wang;Jianru Xue;Wei Zhan;Yinghan Jin;Nanning Zheng;Masayoshi Tomizuka",
        "authorids": "/37086061043;/37402347300;/37067099600;/37087323144;/37271536700;/37281933000;/37086061043;/37402347300;/37067099600;/37087323144;/37271536700;/37281933000",
        "aff": "Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi\u2019an Jiaotong University, Xi\u2019an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi\u2019an Jiaotong University, Xi\u2019an, P.R. China; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Zhejiang University, Hangzhou, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi\u2019an Jiaotong University, Xi\u2019an, P.R. China; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967589/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4841612240573831836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;1",
        "aff_unique_norm": "Xi'an Jiao Tong University;University of California, Berkeley;Zhejiang University",
        "aff_unique_dep": "Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab;Department of Mechanical Engineering;",
        "aff_unique_url": "http://www.xjtu.edu.cn;https://www.berkeley.edu;http://www.zju.edu.cn",
        "aff_unique_abbr": "XJTU;UC Berkeley;ZJU",
        "aff_campus_unique_index": "0;0;1;2;0;1",
        "aff_campus_unique": "Xi'an;Berkeley;Hangzhou",
        "aff_country_unique_index": "0;0;1;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968099",
        "title": "Precision Modeling and Optimally-safe Design of Quadcopters for Controlled Crash Landing in Case of Rotor Failure",
        "track": "main",
        "status": "Poster",
        "abstract": "The seminal work cited in [1],[2] showed, for the first time, that flight stability of quadcopters would be possible in case of one or even multiple rotor failures. However, the quadcopter can remain airborne only by going through a spinning maneuver about an axis, fixed w.r.t the vehicle (i.e., resolved yaw). Furthermore, positional control can be achieved by periodically tilting this axis. This paper builds upon this concept with two major improvements: (1) introducing a precise aerodynamic model of propellers that takes the flapping torque due to unbalanced lifting force in the advancing and retreating blades subjected to freestream, into account, and (2) adding to the stability and flight efficiency of the quadcopter by introducing symmetric fixed tilting angles to the trust vectors. In our previous work [3], it was shown how the flight stability and energy efficiency can be improved by introducing fixed tilting angles in the thrust vectors. For controlled crash landing in case of one rotor failure, where a resolved yaw maneuver would be inevitable, introducing a titling angle in rotors can generate a reasonable resolved-rate-yaw spinning speed to keep the quadcopter airborne at a lower rotational speed of the blades by taking advantage of the freestream generated by spinning. This tilting angle would also lead to passive stability in yaw motion of the quadcopter before the failure. Our hypothesis was successfully tested via simulations.",
        "primary_area": "",
        "author": "Mojtaba Hedayatpour;Mehran Mehrandezh;Farrokh Janabi-Sharifi;Mojtaba Hedayatpour;Mehran Mehrandezh;Farrokh Janabi-Sharifi",
        "authorids": "/37086329590;/37283215200;/37278157400;/37086329590;/37283215200;/37278157400",
        "aff": "Department of Mechanical & Industrial Engineering, Ryerson University, Canada; Department of Mechanical & Industrial Engineering, Ryerson University, Canada; Department of Mechanical & Industrial Engineering, Ryerson University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968099/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14919700472152166707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ryerson University",
        "aff_unique_dep": "Department of Mechanical & Industrial Engineering",
        "aff_unique_url": "https://www.ryerson.ca",
        "aff_unique_abbr": "Ryerson",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8967911",
        "title": "Precision Pouring into Unknown Containers by Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots have developed considerably in recent years. This study aims to propose two approaches for controlling the motion of a service robot as it pours liquid precisely from an unknown container into another unknown container without the need of any external tools. To realize this task, we must resolve two sub-tasks, which are determining the poured volume and controlling the pouring action. Our first proposal concentrates on the target container. The poured volume is calculated using a model of target container and the height of liquid in the target container. The action is controlled using a proportional-derivative controller, which considers the angular speed of the pouring container as a process variable and the poured volume as a control variable. Our second method concentrates on the pouring container. The poured volume is calculated using the relation between the angle of the pouring container and poured volume. The action is controlled with a simple proportional controller that takes the angular speed of the pouring container as a process variable and target angle as a control variable. A point cloud is used to model the two containers. These two methods were implemented in a dualarm robot system for testing, and the results show that both methods are effective for controlling precise pouring tasks.",
        "primary_area": "",
        "author": "Chenyu Dong;Masaru Takizawa;Shunsuke Kudoh;Takashi Suehiro;Chenyu Dong;Masaru Takizawa;Shunsuke Kudoh;Takashi Suehiro",
        "authorids": "/37087321753;/37086201345;/37330860300;/37294400400;/37087321753;/37086201345;/37330860300;/37294400400",
        "aff": "1-5-1, Chofugaoka, Graduate School of Informatics and Engineering at the University of Electro-Communications, Chofu, Tokyo, Japan; 1-5-1, Chofugaoka, Graduate School of Information Systems at the University of Electro-Communications, Chofu, Tokyo, Japan; 1-5-1, Chofugaoka, Graduate School of Informatics and Engineering at the University of Electro-Communications, Chofu, Tokyo, Japan; 1-5-1, Chofugaoka, Graduate School of Informatics and Engineering at the University of Electro-Communications, Chofu, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967911/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12790292494802364250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Electro-Communications",
        "aff_unique_dep": "Graduate School of Informatics and Engineering",
        "aff_unique_url": "https://www.uec.ac.jp",
        "aff_unique_abbr": "UEC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chofu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967558",
        "title": "Predicting Grasp Success with a Soft Sensing Skin and Shape-Memory Actuated Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensors have been increasingly used to support rigid robot grippers in object grasping and manipulation. However, rigid grippers are often limited in their ability to handle compliant, delicate, or irregularly shaped objects. In recent years, grippers made from soft and flexible materials have become increasingly popular for certain manipulation tasks, e.g., grasping, due to their ability to conform to the object shape without the need for precise control. Although promising, such soft robot grippers currently suffer from the lack of available sensing modalities. In this work, we introduce a soft and stretchable sensing skin and incorporate it into the two fingers of a shape-memory actuated soft gripper. The onboard sensing skin includes a 9-axis inertial measurement unit (IMU) and five discrete pressure sensors per finger. We use this sensorized soft gripper to study grasp success and stability of over 2585 grasps with various objects using several machine learning methods. Our experiments show that LSTMs were the most accurate predictors of grasp success and stability, compared to SVMs, FFNNs, and ST-HMP. We also evaluated the effects on performance of each sensor's data, and the success rates for individual objects. The results show that the accelerometer data of the IMUs has the largest contribution to the overall grasp prediction, which we attribute to its ability to detect precise movements of the gripper during grasping.",
        "primary_area": "",
        "author": "Julian Zimmer;Tess Hellebrekers;Tamim Asfour;Carmel Majidi;Oliver Kroemer;Julian Zimmer;Tess Hellebrekers;Tamim Asfour;Carmel Majidi;Oliver Kroemer",
        "authorids": "/37087324069;/37085635447;/37295529100;/37589572800;/37593222300;/37087324069;/37085635447;/37295529100;/37589572800;/37593222300",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967558/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5212418127893433734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;School of Computer Science, Robotics Institute",
        "aff_unique_url": "https://www.kit.edu;https://www.cmu.edu",
        "aff_unique_abbr": "KIT;CMU",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Karlsruhe;Pittsburgh",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "8968559",
        "title": "Prediction of Human Arm Target for Robot Reaching Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "The raise of collaborative robotics has allowed to create new spaces where robots and humans work in proximity. Consequently, to predict human movements and his/her final intention becomes crucial to anticipate robot next move, preserving safety and increasing efficiency. In this paper we propose a human-arm prediction algorithm that allows to infer if the human operator is moving towards the robot to intentionally interact with it. The human hand position is tracked by an RGB-D camera online. By combining the Minimum Jerk model with Semi-Adaptable Neural Networks we obtain a reliable prediction of the human hand trajectory and final target in a short amount of time. The proposed algorithm was tested in a multi-movements scenario with FANUC LR Mate 200iD/7L industrial robot.",
        "primary_area": "",
        "author": "Chiara Talignani Landi;Yujiao Cheng;Federica Ferraguti;Marcello Bonf\u00e8;Cristian Secchi;Masayoshi Tomizuka;Chiara Talignani Landi;Yujiao Cheng;Federica Ferraguti;Marcello Bonf\u00e8;Cristian Secchi;Masayoshi Tomizuka",
        "authorids": "/37086033341;/37086963685;/37075262200;/37300903100;/37300905500;/37281933000;/37086033341;/37086963685;/37075262200;/37300903100;/37300905500;/37281933000",
        "aff": "Department of Science and Methods for Engineering, University of Modena and Reggio Emilia, Italy; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA; Department of Science and Methods for Engineering, University of Modena and Reggio Emilia, Italy; Department of Engineering, University of Ferrara, Italy; Department of Science and Methods for Engineering, University of Modena and Reggio Emilia, Italy; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968559/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4548498375236848241&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;1",
        "aff_unique_norm": "University of Modena and Reggio Emilia;University of California, Berkeley;University of Ferrara",
        "aff_unique_dep": "Department of Science and Methods for Engineering;Department of Mechanical Engineering;Department of Engineering",
        "aff_unique_url": "https://www.unimore.it;https://www.berkeley.edu;https://www.unife.it",
        "aff_unique_abbr": ";UC Berkeley;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;0;0;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "8968110",
        "title": "Predictive Inverse Kinematics: optimizing Future Trajectory through Implicit Time Integration and Future Jacobian Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an inverse kinematics (IK) method which can control future velocities and accelerations for multi-body systems. The proposed IK method is formulated as a quadratic programing (QP) that optimizes future joint trajectories. The features of the proposed IK are: (1) the evaluation of accelerations at future time instances, (2) the trajectory representation that can implicitly integrate the time integral formula into QP, (3) the computation of future Jacobian matrices based on the comprehensive theory of differential kinematics proposed in our previous work. Those features enable a stable and fast IK computation while evaluating the future accelerations. We also conducted thorough numerical studies to show the efficiency of the proposed method.",
        "primary_area": "",
        "author": "Ko Ayusawa;Wael Suleiman;Eiichi Yoshida;Ko Ayusawa;Wael Suleiman;Eiichi Yoshida",
        "authorids": "/37543258600;/37400542000;/37286468100;/37543258600;/37400542000;/37286468100",
        "aff": "CNRS-AIST JRL (Joint Robotics Laboratory), UMI13218/RL Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology (IS-AIST), Japan; Electrical and Computer Engineering Department, Faculty of Engineering, University of Sherbrooke, Canada; CNRS-AIST JRL (Joint Robotics Laboratory), UMI13218/RL Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology (IS-AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968110/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2330342283871704522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;University of Sherbrooke",
        "aff_unique_dep": "Intelligent Systems Research Institute;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.aist.go.jp;https://www.usherbrooke.ca",
        "aff_unique_abbr": "AIST;USherb",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;Canada"
    },
    {
        "id": "8967994",
        "title": "Predictive and adaptive maps for long-term visual navigation in changing environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we compare different map management techniques for long-term visual navigation in changing environments. In this scenario, the navigation system needs to continuously update and refine its feature map in order to adapt to the environment appearance change. To achieve reliable long-term navigation, the map management techniques have to (i) select features useful for the current navigation task, (ii) remove features that are obsolete, (iii) and add new features from the current camera view to the map. We propose several map management strategies and evaluate their performance with regard to the robot localisation accuracy in long-term teach-and-repeat navigation. Our experiments, performed over three months, indicate that strategies which model cyclic changes of the environment appearance and predict which features are going to be visible at a particular time and location, outperform strategies which do not explicitly model the temporal evolution of the changes.",
        "primary_area": "",
        "author": "Lucie Halodov\u00e1;Eli\u0161ka Dvo\u0159r\u00e1kov\u00e1;Filip Majer;Tom\u00e1\u0161 Vintr;Oscar Martinez Mozos;Feras Dayoub;Tom\u00e1\u0161 Krajn\u00edk;Lucie Halodov\u00e1;Eli\u0161ka Dvo\u0159r\u00e1kov\u00e1;Filip Majer;Tom\u00e1\u0161 Vintr;Oscar Martinez Mozos;Feras Dayoub;Tom\u00e1\u0161 Krajn\u00edk",
        "authorids": "/37086579343;/37087322658;/37086573530;/38229378200;/37564352300;/37866588000;/38547272600;/37086579343;/37087322658;/37086573530;/38229378200;/37564352300;/37866588000;/38547272600",
        "aff": "Artificial Intelligence Center, Czech Technical University; Artificial Intelligence Center, Czech Technical University; Artificial Intelligence Center, Czech Technical University; Artificial Intelligence Center, Czech Technical University; Technical University of Cartagena, Spain; Australian Centre for Robotic Vision, QUT; Artificial Intelligence Center, Czech Technical University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967994/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3663807341596930232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "Czech Technical University;Technical University of Cartagena;Queensland University of Technology",
        "aff_unique_dep": "Artificial Intelligence Center;;Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.cvut.cz;https://www.uctc.es;https://www.qut.edu.au",
        "aff_unique_abbr": "CTU;UCTC;QUT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;2;0",
        "aff_country_unique": "Czech Republic;Spain;Australia"
    },
    {
        "id": "8968218",
        "title": "Preliminary Evaluation of an Orbital Camera for Teleoperation of Remote Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional teleoperative interfaces, used for remote manipulation in the nuclear industry, utilise multiple stationary CCTV cameras for situational awareness. This is cognitively challenging for the human operator, who must mentally combine information from multiple 2D views, before attempting 3D reasoning about the remote environment. To enhance performance on telemanipulation tasks, this paper explores the merits of employing an orbital camera view. The orbital camera's gaze direction is automatically fixated towards the robot's moving end-effector. Meanwhile, the camera can be controlled by the operator to move on a spherical surface around the end-effector, in addition to zooming capability. The robot's Cartesian motion coordinates are also continuously transformed to be controllable with respect to the axes of the orbital camera view. Human test-subject experiments were conducted in a simulation environment using novice robot operators, and a variety of metrics were collected. Although the results do not show an objective difference between the camera modes, participant interviews suggest the orbital camera is the preferred method for visual feedback with its dynamic views helping to overcome positioning difficulties associated with stationary cameras. The experiment also revealed significant confounding factors that contributed to the results being inconclusive. These are discussed and recommendations are made for future empirical experiments to evaluate such systems.",
        "primary_area": "",
        "author": "Mohammed Talha;Rustam Stolkin;Mohammed Talha;Rustam Stolkin",
        "authorids": "/38504236800;/37424300500;/38504236800;/37424300500",
        "aff": "Metallurgy & Materials, University of Birmingham, UK; Metallurgy & Materials, University of Birmingham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968218/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8833733775854675883&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Birmingham",
        "aff_unique_dep": "Metallurgy & Materials",
        "aff_unique_url": "https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967524",
        "title": "Printing-while-moving: a new paradigm for large-scale robotic 3D Printing",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Mehmet Efe Tiryaki;Xu Zhang;Quang-Cuong Pham;Mehmet Efe Tiryaki;Xu Zhang;Quang-Cuong Pham",
        "authorids": "/37087324110;/37087323943;/38191381800;/37087324110;/37087323943;/38191381800",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967524/",
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15244656778012826742&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "8967681",
        "title": "Privacy-Preserving Robot Vision with Anonymized Faces by Extreme Low Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "As smart cameras are becoming ubiquitous in mobile robot systems, there is an increasing concern in camera devices invading people's privacy by recording unwanted images. We want to fundamentally protect privacy by blurring unwanted blocks in images, such as faces, yet ensure that the robots can understand the video for their perception. In this paper, we propose a novel mobile robot framework with a deep learning-based privacy-preserving camera system. The proposed camera system detects privacy-sensitive blocks, i.e., human face, from extreme low resolution (LR) images, and then dynamically enhances the resolution of only privacy-insensitive blocks, e.g., backgrounds. Keeping all the face blocks to be extreme LR of 15x15 pixels, we can guarantee that human faces are never at high resolution (HR) in any of processing or memory, thus yielding strong privacy protection even from cracking or backdoors. Our camera system produces an image on a real-time basis, the human faces of which are in extreme LR while the backgrounds are in HR. We experimentally confirm that our proposed face detection camera system outperforms the state-of-the-art small face detection algorithm, while the robot performs ORB-SLAM2 well even with videos of extreme LR faces. Therefore, with the proposed system, we do not too much sacrifice robot perception performance to protect privacy.",
        "primary_area": "",
        "author": "Myeung Un Kim;Harim Lee;Hyun Jong Yang;Michael S. Ryoo;Myeung Un Kim;Harim Lee;Hyun Jong Yang;Michael S. Ryoo",
        "authorids": "/37086044637;/37086432998;/37291243600;/37397559800;/37086044637;/37086432998;/37291243600;/37397559800",
        "aff": "Ulsan National Institute of Science and Technology, Ulsan, South Korea; Ulsan National Institute of Science and Technology, Ulsan, South Korea; Ulsan National Institute of Science and Technology, Ulsan, South Korea; EgoVid Inc., Ulsan, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967681/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16495577339461528192&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Egovid Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unist.ac.kr;",
        "aff_unique_abbr": "UNIST;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ulsan;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967648",
        "title": "Proposal of a Peristaltic Motion Type Duct Cleaning Robot for Traveling in a Flexible Pipe",
        "track": "main",
        "status": "Poster",
        "abstract": "The cleaning of residential ventilation ducts is necessary to prevent damage to health. However, since residential ventilation ducts are usually thin and curved, cleaning them is difficult. It is also difficult to obtain thrust within the duct using a wheel or a snake type robot because it is hard to obtain an appropriate reaction force in a deformed pipe. Therefore, the pipe must be gripped stably even if it is flexible so that thrust can be generated to run the cleaning robot through the pipe. In this paper, we modeled a cleaning robot that uses peristaltic motion running through a flexible duct with an inner diameter of 50 mm. Then, the validity of the model was verified by experiment. Finally, a cleaning experiment was conducted and the cleaning rate was 98.7 %.",
        "primary_area": "",
        "author": "F. Ito;T. Kawaguchi;M. Kamata;Y. Yamada;T. Nakamura;F. Ito;T. Kawaguchi;M. Kamata;Y. Yamada;T. Nakamura",
        "authorids": "/37088233849;/37086477798;/37086125114;/37085823730;/37309580500;/37088233849;/37086477798;/37086125114;/37085823730;/37309580500",
        "aff": "Department of Precision Mechanics, Faculty of Science and Engineering, Chuo University, Bunkyo-ku, Japan; Department of Precision Mechanics, Faculty of Science and Engineering, Chuo University, Bunkyo-ku, Japan; Department of Precision Mechanics, Faculty of Science and Engineering, Chuo University, Bunkyo-ku, Japan; Department of Design Engineering and Technology, Tokyo Denki University Research and Development Initiative, Chuo University; Department of Precision Mechanics, Faculty of Science and Engineering, Chuo University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967648/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4616080054813655115&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Chuo University;Tokyo Denki University",
        "aff_unique_dep": "Department of Precision Mechanics;Department of Design Engineering and Technology",
        "aff_unique_url": "https://www.chuo-u.ac.jp;https://www.tdu.ac.jp",
        "aff_unique_abbr": "Chuo U;TDU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bunkyo-ku;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967943",
        "title": "Proto-object based saliency for event-driven cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots can rely on attention mechanisms to explore complex scenes and select salient stimuli relevant for behaviour. Stimulus selection should be fast to efficiently allocate available (and limited) computational resources to process in detail a subset of the otherwise overwhelmingly large sensory input. The amount of processing required is a product of the amount of data sampled by a robot's sensors; while a standard RGB camera produces a fixed amount of data for every pixel of the sensor, an event-camera produces data only for where there is a contrast change in the field of view, and does so with a lower latency. In this paper, we describe the implementation of a state-of-the-art bottom-up attention model, based on structuring the visual scene in terms of proto-objects. As an event-camera encodes different visual information compared to frame-based cameras, the original algorithm must be adapted and modified. We find that the event-camera's inherent detection of edges removes the need for some early stages of processing in the model. We describe the modifications, compare the event-driven algorithm to the original, and validate the potential for use on the iCub humanoid robot.",
        "primary_area": "",
        "author": "Massimiliano Iacono;Giulia D\u2019Angelo;Arren Glover;Vadim Tikhanoff;Ernst Niebur;Chiara Bartolozzi;Massimiliano Iacono;Giulia D\u2019Angelo;Arren Glover;Vadim Tikhanoff;Ernst Niebur;Chiara Bartolozzi",
        "authorids": "/37086578442;/37087324255;/38536087000;/37697036800;/37265500300;/37681790700;/37086578442;/37087324255;/38536087000;/37697036800;/37265500300;/37681790700",
        "aff": "Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967943/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12514180492284191030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968072",
        "title": "Quickly Inserting Pegs into Uncertain Holes using Multi-view Images and Deep Network Trained on Synthetic Data",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the use of robots to autonomously assemble parts with variations in colors and textures. Specifically, we focus on peg-in-hole assembly with some initial position uncertainty and holes located on surfaces of different colors and textures. Two in-hand cameras and a force-torque sensor are used to account for the position uncertainty. A program sequence comprising learning-based visual servoing, spiral search, and impedance control is implemented to perform the peg-in-hole task with feedback from the above sensors. Contributions are mainly made in the learning-based visual servoing component of the sequence, where a deep neural network is trained with various sets of synthetic data generated using the concept of domain randomization to predict where a hole is. In the experiments and analysis section, the network is analyzed and compared, and a real-world robotic system to insert pegs to holes using the proposed method is implemented. The results show that the implemented peg-in-hole assembly system can perform successful peg-in-hole insertions on surfaces with various colors and textures. It can generally speed up the entire peg-in-hole process, especially when the initial position uncertainty is large.",
        "primary_area": "",
        "author": "Joshua C. Triyonoputro;Weiwei Wan;Kensuke Harada;Joshua C. Triyonoputro;Weiwei Wan;Kensuke Harada",
        "authorids": "/37086606247;/37085689483;/37277067400;/37086606247;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan; Graduate School of Engineering Science, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968072/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7227017942710670239&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Graduate School of Engineering Science",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968566",
        "title": "RGB-to-TSDF: Direct TSDF Prediction from a Single RGB Image for Dense 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel method to predict 3D TSDF voxels from a single image for dense 3D reconstruction. 3D reconstruction with RGB images has two inherent problems: scale ambiguity and sparse reconstruction. With the advent of deep learning, depth prediction from a single RGB image has addressed these problems. However, as the predicted depth is typically noisy, de-noising methods such as TSDF fusion should be adapted for the accurate scene reconstruction. To integrate the two-step processing of depth prediction and TSDF generation, we design an RGB-to-TSDF network to directly predict 3D TSDF voxels from a single RGB image. The TSDF using our network can be generated more efficiently in terms of time and accuracy than the TSDF converted from depth prediction. We also use the predicted TSDF for a more accurate and robust camera pose estimation to complete scene reconstruction. The global TSDF is updated from TSDF prediction and pose estimation, and thus dense isosurface can be extracted. In the experiments, we evaluate our TSDF prediction and camera pose estimation results against the conventional method.",
        "primary_area": "",
        "author": "Hanjun Kim;Jiyoun Moon;Beomhee Lee;Hanjun Kim;Jiyoun Moon;Beomhee Lee",
        "authorids": "/37086550265;/37086935314;/37281108400;/37086550265;/37086935314;/37281108400",
        "aff": "Department of Electrical and Computer Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Republic of Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Republic of Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968566/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10518048982430272568&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968593",
        "title": "RINS-W: Robust Inertial Navigation System on Wheels",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a real-time approach for long-term inertial navigation based only on an Inertial Measurement Unit (IMU) for self-localizing wheeled robots. The approach builds upon two components: 1) a robust detector that uses recurrent deep neural networks to dynamically detect a variety of situations of interest, such as zero velocity or no lateral slip; and 2) a state-of-the-art Kalman filter which incorporates this knowledge as pseudo-measurements for localization. Evaluations on a publicly available car dataset demonstrates that the proposed scheme may achieve a final distance error of 20 m for a 21 km long trajectory of a vehicle driving for over an hour, equipped with an IMU of moderate precision (the gyro drift rate is 10 deg/h). To our knowledge, this is the first paper which combines sophisticated deep learning techniques with state-of the-art filtering methods for pure inertial navigation on wheeled vehicles and as such opens up for novel data-driven inertial navigation techniques. Moreover, albeit taylored for IMU-only based localization, our method may be used as a component for self-localization of wheeled robots equipped with a more complete sensor suite.",
        "primary_area": "",
        "author": "Martin Brossard;Axel Barrau;Silv\u00e8re Bonnabel;Martin Brossard;Axel Barrau;Silv\u00e8re Bonnabel",
        "authorids": "/37086302663;/38488659000;/37398922500;/37086302663;/38488659000;/37398922500",
        "aff": "MINES ParisTech, PSL Research University, Centre for Robotics, Paris, France; Safran Tech, Groupe Safran, Rue des Jeunes Bois-Ch\u00e2teaufort, France; MINES ParisTech, PSL Research University, Centre for Robotics, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968593/",
        "gs_citation": 105,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10059816219503013103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "MINES ParisTech;Safran Tech",
        "aff_unique_dep": "Centre for Robotics;",
        "aff_unique_url": "https://www.minesparistech.fr;",
        "aff_unique_abbr": "MPT;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967892",
        "title": "RISE-SLAM: A Resource-aware Inverse Schmidt Estimator for SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the RISE-SLAM algorithm for performing visual-inertial simultaneous localization and mapping (SLAM), while improving estimation consistency. Specifically, in order to achieve real-time operation, existing approaches often assume previously-estimated states to be perfectly known, which leads to inconsistent estimates. Instead, based on the idea of the Schmidt-Kalman filter, which has processing cost linear in the size of the state vector but quadratic memory requirements, we derive a new consistent approximate method in the information domain, which has linear memory requirements and adjustable (constant to linear) processing cost. In particular, this method, the resource-aware inverse Schmidt estimator (RISE), allows trading estimation accuracy for computational efficiency. Furthermore, and in order to better address the requirements of a SLAM system during an exploration vs. a relocalization phase, we employ different configurations of RISE (in terms of the number and order of states updated) to maximize accuracy while preserving efficiency. Lastly, we evaluate the proposed RISE-SLAM algorithm on publicly-available datasets and demonstrate its superiority, both in terms of accuracy and efficiency, as compared to alternative visual-inertial SLAM systems.",
        "primary_area": "",
        "author": "Tong Ke;Kejian J. Wu;Stergios I. Roumeliotis;Tong Ke;Kejian J. Wu;Stergios I. Roumeliotis",
        "authorids": "/37087323518;/37085423996;/37274078800;/37087323518;/37085423996;/37274078800",
        "aff": "Univ. of Minnesota, Minneapolis, MN, USA; Univ. of Minnesota, Minneapolis, MN, USA; Univ. of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967892/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5067790735976412032&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967869",
        "title": "ROI-based Robotic Grasp Detection for Object Overlapping Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasp detection considering the affiliations between grasps and their owner in object overlapping scenes is a necessary and challenging task for the practical use of the robotic grasping approach. In this paper, a robotic grasp detection algorithm named ROI-GD is proposed to provide a feasible solution to this problem based on Region of Interest (ROI), which is the region proposal for objects. ROI-GD uses features from ROIs to detect grasps instead of the whole scene. It has two stages: the first stage is to provide ROIs in the input image and the second-stage is the grasp detector based on ROI features. We also contribute a multi-object grasp dataset, (a) which is much larger than Cornell Grasp Dataset, by labeling Visual Manipulation Relationship Dataset. Experimental results demonstrate that ROI-GD performs much better in object overlapping scenes and at the meantime, remains comparable with state-of-the-art grasp detection algorithms on Cornell Grasp Dataset and Jacquard Dataset. Robotic experiments demonstrate that ROI-GD can help robots grasp the target in single-object and multi-object scenes with the overall success rates of 92.5% and 83.8% respectively.",
        "primary_area": "",
        "author": "Hanbo Zhang;Xuguang Lan;Site Bai;Xinwen Zhou;Zhiqiang Tian;Nanning Zheng;Hanbo Zhang;Xuguang Lan;Site Bai;Xinwen Zhou;Zhiqiang Tian;Nanning Zheng",
        "authorids": "/37086441588;/37270865300;/37087324621;/37086441733;/37597665600;/37271536700;/37086441588;/37270865300;/37087324621;/37086441733;/37597665600;/37271536700",
        "aff": "National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967869/",
        "gs_citation": 213,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2475465843377166538&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "School of Electronic and Information Engineering",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968551",
        "title": "RONet: Real-time Range-only Indoor Localization via Stacked Bidirectional LSTM with Residual Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a three-layered bidirectional Long Short-term Memory (Bi-LSTM) with residual attention, named as RONet, is proposed to achieve localization using range measurements. Accordingly, we acquired our own datasets and tested RONet using realistic conditions. It is shown that the RONet can estimate the position of the mobile robot in real time using the Nvidia Jetson AGX Xavier based only on range measurements. We also analyzed the sequence length of LSTM as a type of hyperparameters. We found that optimal sequence length is eight for more than eight anchors and twelve for fewer anchors compared to sequences with different lengths, given that construction of the network with the optimal sequence length estimates the position precisely and accounts for uncertainties. As verified experimentally, RONet yields more precise performance and results in increased robustness against outliers compared to a conventional range-only approach based on a particle filtering and the other conventional deep-learning-based approaches. We set three cases, reduced the number of anchors, and verified that the RONet was a robust solution. We also confirmed that it is the best solution that yields the smallest Root-Mean-Square-Error (RMSE) values, equal to 4.466 cm, 3.210 cm, and 3.090 cm, in the cases where three, five, and eight anchors were deployed, respectively.",
        "primary_area": "",
        "author": "Hyungtae Lim;Changgue Park;Hyun Myung;Hyungtae Lim;Changgue Park;Hyun Myung",
        "authorids": "/37086920570;/37087321807;/37424926900;/37086920570;/37087321807;/37424926900",
        "aff": "Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968551/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5438911459472767573&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Urban Robotics Laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967633",
        "title": "Radar Localization and Mapping for Indoor Disaster Environments via Multi-modal Registration to Prior LiDAR Map",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a localization and mapping algorithm that leverages a radar system in low-visibility environments. We aim to address disaster situations in which prior knowledge of a place is available from CAD or light detection and ranging (LiDAR) maps, but incoming visibility is severely limited. In smoky environments, typical sensors (e.g., cameras and LiDARs) fail to perform reliably due to the large particles in the air. Radars recently attracted attention for their robust perception in low-visibility environments; however, radar measurements' angular ambiguity and low resolution prevented the direct application to the simultaneous localization and mapping (SLAM) framework. In this paper, we propose registering radar measurements against a previously built dense LiDAR map for localization and applying radar-map refinement for mapping. Our proposed method overcomes the significant density discrepancy between LiDAR and radar with a density-independent point registration algorithm. We validate the proposed method in an environment containing dense fog.",
        "primary_area": "",
        "author": "Yeong Sang Park;Joowan Kim;Ayoung Kim;Yeong Sang Park;Joowan Kim;Ayoung Kim",
        "authorids": "/37086069179;/37086057108;/37403315600;/37086069179;/37086057108;/37403315600",
        "aff": "Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967633/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10029811020397056041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968501",
        "title": "Range-limited, Distributed Algorithms on Higher-Order Voronoi Partitions in Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of distributed computation of higher order Voronoi partition over a bounded region by a group of robots with both range-limited visibility sensors and communication devices. We model the sensing and communication capabilities by discs with limited radius. Motivated by the concept of dominating region in higher-order Voronoi partition, we propose a detecting ray based algorithm, which computes the boundary points of the dominating region of a robot in an omnidirectional manner, with local position information of its neighbors within the communication range. Simulations are provided to demonstrate the performance of our proposed algorithm by using a thirteen-robot group.",
        "primary_area": "",
        "author": "Lingxuan Kong;Qingchen Liu;Changbin Brad Yu;Lingxuan Kong;Qingchen Liu;Changbin Brad Yu",
        "authorids": "/37087322551;/37085653776;/37087324522;/37087322551;/37085653776;/37087324522",
        "aff": "Optus-Curtin Centre of Execellence in Artificial Intelligence, Curtin University, Australia and the Australian National University; Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany; Optus-Curtin Centre of Execellence in Artificial Intelligence, Curtin University, Australia and the Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968501/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16239255526543447021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Curtin University;Technical University of Munich",
        "aff_unique_dep": "Optus-Curtin Centre of Excellence in Artificial Intelligence;Chair of Information-Oriented Control",
        "aff_unique_url": "https://www.curtin.edu.au;https://www.tum.de",
        "aff_unique_abbr": "Curtin;TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;Germany"
    },
    {
        "id": "8967762",
        "title": "RangeNet ++: Fast and Accurate LiDAR Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception in autonomous vehicles is often carried out through a suite of different sensing modalities. Given the massive amount of openly available labeled RGB data and the advent of high-quality deep learning algorithms for image-based recognition, high-level semantic perception tasks are pre-dominantly solved using high-resolution cameras. As a result of that, other sensor modalities potentially useful for this task are often ignored. In this paper, we push the state of the art in LiDAR-only semantic segmentation forward in order to provide another independent source of semantic information to the vehicle. Our approach can accurately perform full semantic segmentation of LiDAR point clouds at sensor frame rate. We exploit range images as an intermediate representation in combination with a Convolutional Neural Network (CNN) exploiting the rotating LiDAR sensor model. To obtain accurate results, we propose a novel post-processing algorithm that deals with problems arising from this intermediate representation such as discretization errors and blurry CNN outputs. We implemented and thoroughly evaluated our approach including several comparisons to the state of the art. Our experiments show that our approach outperforms state-of-the-art approaches, while still running online on a single embedded GPU. The code can be accessed at https://github.com/PRBonn/lidar-bonnetal.",
        "primary_area": "",
        "author": "Andres Milioto;Ignacio Vizzo;Jens Behley;Cyrill Stachniss;Andres Milioto;Ignacio Vizzo;Jens Behley;Cyrill Stachniss",
        "authorids": "/37086400161;/37087323326;/37593243900;/37329668600;/37086400161;/37087323326;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967762/",
        "gs_citation": 1350,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7722219276489943321&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968098",
        "title": "Rapid Collision Detection for Multicopter Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a continuous-time collision detection algorithm for quickly detecting whether certain polynomial trajectories in time intersect with convex obstacles. The algorithm is used in conjunction with an existing multicopter trajectory generation method to achieve rapid, obstacle-aware motion planning in environments with both static convex obstacles and dynamic convex obstacles whose boundaries do not rotate. In general, this problem is difficult because the presence of convex obstacles makes the feasible space of trajectories nonconvex. The performance of the algorithm is benchmarked using Monte Carlo simulations, and experimental results are presented that demonstrate the use of the method to plan collision-free multicopter trajectories in milliseconds in environments with both static and dynamic obstacles.",
        "primary_area": "",
        "author": "Nathan Bucki;Mark W. Mueller;Nathan Bucki;Mark W. Mueller",
        "authorids": "/37086575621;/37086448968;/37086575621;/37086448968",
        "aff": "High Performance Robotics Lab, University of California, Berkeley, USA; High Performance Robotics Lab, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968098/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3498265410730999048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "High Performance Robotics Lab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967964",
        "title": "Rapid Design of Mechanical Logic Based on Quasi-Static Electromechanical Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Mechanical logic is a class of dynamic electromechanical mechanisms which leverages carefully designed mechanical structures to generate programmed control actions from a constant electrical power supply; thus, it can be employed as a control method for fully printable autonomous robots. Composed of a bistable buckled beam driven by conductive super-coiled polymer (CSCP) actuators, this type of electromechanical system features non-trivial relationships between its design parameters and resulting behavioral characteristics. In this paper we present an efficient method to rapidly design mechanical logic structures from desired behavioral specifications. We describe this dynamic system with a simplified, quasi-static model, whose validity is verified by time constant comparison. An analytical formula of the mechanical logic's behavioral characteristics, i.e. its oscillation period, is then derived as a simplified expression of the design parameters. Based on this expression, we formulate the design of mechanical logic from behavioral specifications into an optimization problem that maximizes the robustness to manufacturing tolerances, as demonstrated by an example case study.",
        "primary_area": "",
        "author": "Wenzhong Yan;Yunchen Yu;Ankur Mehta;Wenzhong Yan;Yunchen Yu;Ankur Mehta",
        "authorids": "/37087323423;/37087321995;/37086302574;/37087323423;/37087321995;/37086302574",
        "aff": "School of Engineering, University of California, Los Angeles, CA; School of Engineering, University of California, Los Angeles, CA; School of Engineering, University of California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967964/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16884328490781104444&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967553",
        "title": "Rapid Estimation of Optical Properties for Simulation-Based Evaluation of Pose Estimation Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "A growing trend in computer vision is the use of synthetic images for the evaluation of computer vision algorithms such as 3D pose estimation. This is partly due to the availability of high-quality render engines, which provide highly realistic synthetic images. However, the realism of the rendered images, and thus the reliability of the evaluations, strongly depends on how accurately the scenes are modeled and it requires considerable time and knowledge to do the modeling manually. Automating the modeling process is therefore crucial for making the rendering of photo-realistic synthetic images accessible to the wider robotics community. We present a method for automatically modeling object and light properties for rigid, opaque plastic objects commonly found in industry. Our method relies on recordings of the environment captured with a consumer 360^{\\mathrm{o}}360^{\\mathrm{o}} camera to model the light, and on analysis-by-synthesis to estimate the optical properties of the objects. We show that the synthetic images rendered based on our automatic modeling method can be used to predict the overall performance of a monocular 3D pose estimation algorithm.",
        "primary_area": "",
        "author": "Thorbj\u00f8rn Mosekj\u00e6r Iversen;Jakob Wilm;Dirk Kraft;Thorbj\u00f8rn Mosekj\u00e6r Iversen;Jakob Wilm;Dirk Kraft",
        "authorids": "/37086208129;/37075188100;/37528711100;/37086208129;/37075188100;/37528711100",
        "aff": "All authors are with the Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; All authors are with the Maersk Mc-Kinney Moller Institute, University of Southern, Denmark; All authors are with the Maersk Mc-Kinney Moller Institute, University of Southern, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967553/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13159039564197146686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "USD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8968056",
        "title": "Rapid Trajectory optimization Using C-FROST with Illustration on a Cassie-Series Dynamic Walking Biped",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the big attractions of low-dimensional models for gait design has been the ability to compute solutions rapidly, whereas one of their drawbacks has been the difficulty in mapping the solutions back to the target robot. This paper presents a set of tools for rapidly determining solutions for \u201chumanoids\u201d without removing or lumping degrees of freedom. The main tools are: (1) C-FROST, an open-source C++ interface for FROST, a direct collocation optimization tool; and (2) multi-threading. The results will be illustrated on a 20-DoF floating-base model for a Cassie-series bipedal robot through numerical optimization and physical experiments.",
        "primary_area": "",
        "author": "Ayonga Hereid;Omar Harib;Ross Hartley;Yukai Gong;Jessy W. Grizzle;Ayonga Hereid;Omar Harib;Ross Hartley;Yukai Gong;Jessy W. Grizzle",
        "authorids": "/37077055000;/37085798764;/37085796864;/37086962231;/37277141500;/37077055000;/37085798764;/37085796864;/37086962231;/37277141500",
        "aff": "Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA; College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA; College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA; College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968056/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10282281458833970572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Ohio State University;University of Michigan",
        "aff_unique_dep": "Mechanical and Aerospace Engineering;College of Engineering and the Robotics Institute",
        "aff_unique_url": "https://www.osu.edu;https://www.umich.edu",
        "aff_unique_abbr": "OSU;UM",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Columbus;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968456",
        "title": "Rapid and Robust Monocular Visual-Inertial Initialization with Gravity Estimation via Vertical Edges",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular visual-inertial tracking without good initialization easily fails due to its non-linear nature. Rapid and accurate metric initialization is crucial. In this paper, we propose a novel monocular visual-inertial initialization method which can initialize the IMU states, camera poses, and scale in a rapid and robust way. To avoid mixing gravity and accelerometer bias, we propose to use the detected vertical edges to estimate a better gravity. This improves the observability to the underlying problem even without sufficient movement, so we can solve all the states crucial for a good initialization. We evaluate our approach on EuRoC dataset and compare with existing state-of-the-art methods. The experimental results demonstrate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Jinyu Li;Hujun Bao;Guofeng Zhang;Jinyu Li;Hujun Bao;Guofeng Zhang",
        "authorids": "/37087323904;/37271755400;/37405938800;/37087323904;/37271755400;/37405938800",
        "aff": "The authors are affiliated with State Key Lab of CAD&CG, Zhejiang University, and ZJU-SenseTime Joint Lab of 3D Vision.; The authors are affiliated with State Key Lab of CAD&CG, Zhejiang University, and ZJU-SenseTime Joint Lab of 3D Vision.; The authors are affiliated with State Key Lab of CAD&CG, Zhejiang University, and ZJU-SenseTime Joint Lab of 3D Vision.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968456/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12413284272826265841&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Lab of CAD&CG",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967590",
        "title": "ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals",
        "track": "main",
        "status": "Poster",
        "abstract": "Mapping and localization are essential capabilities of robotic systems. Although the majority of mapping systems focus on static environments, the deployment in real-world situations requires them to handle dynamic objects. In this paper, we propose an approach for an RGB-D sensor that is able to consistently map scenes containing multiple dynamic elements. For localization and mapping, we employ an efficient direct tracking on the truncated signed distance function (TSDF) and leverage color information encoded in the TSDF to estimate the pose of the sensor. The TSDF is efficiently represented using voxel hashing, with most computations parallelized on a GPU. For detecting dynamics, we exploit the residuals obtained after an initial registration, together with the explicit modeling of free space in the model. We evaluate our approach on existing datasets, and provide a new dataset showing highly dynamic scenes. These experiments show that our approach often surpass other state-of-the-art dense SLAM methods. We make available our dataset with the ground truth for both the trajectory of the RGB-D sensor obtained by a motion capture system and the model of the static environment using a high-precision terrestrial laser scanner. Finally, we release our approach as open source code.",
        "primary_area": "",
        "author": "Emanuele Palazzolo;Jens Behley;Philipp Lottes;Philippe Gigu\u00e8re;Cyrill Stachniss;Emanuele Palazzolo;Jens Behley;Philipp Lottes;Philippe Gigu\u00e8re;Cyrill Stachniss",
        "authorids": "/37086455423;/37593243900;/37085797781;/37560636500;/37329668600;/37086455423;/37593243900;/37085797781;/37560636500;/37329668600",
        "aff": "University of Bonn, Germany; Laval University, Qu\u00e9bec, Canada; University of Bonn, Germany; Laval University, Qu\u00e9bec, Canada; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967590/",
        "gs_citation": 235,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2346988346703303891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Bonn;Laval University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.laval.ca",
        "aff_unique_abbr": "UBonn;Laval",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Qu\u00e9bec",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Germany;Canada"
    },
    {
        "id": "8968557",
        "title": "Reactive Interaction Through Body Motion and the Phase-State-Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "Between humans, body motion is an intuitive and ubiquitous means to coordinate interactions, but so far collaborative robots have not embraced this mode of communication. One reason for this is that conventional behavior generation systems use finite state machines which make it exceptionally difficult to ingest and produce the inherently continuous and concurrent information flow that body motion provides. We propose a new, reactive motion generator based on a dynamical system instead. It mimics a conventional state machine except that transitions are not instantaneous but time-extended, reversible, and have phases. Moreover, consecutive states and transitions may overlap during execution. Most notably, more than one transition can be active at the same time if they share predecessor state. Together, these unique features enable instantaneous and gradual responses to novel information and continuous decision processes without changing the state graph itself. We demonstrate the system's capabilities in an object handover task coordinated by body motion.",
        "primary_area": "",
        "author": "Raphael Deimel;Raphael Deimel",
        "authorids": "/37076967100;/37076967100",
        "aff": "Control Systems Laboratory, Technische Universitt Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968557/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6897562352724243073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Technische Universitaet Berlin",
        "aff_unique_dep": "Control Systems Laboratory",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967967",
        "title": "Real-Time 6D Object Pose Estimation on CPU",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a fast and accurate 6D object pose estimation from a RGB-D image. Our proposed method is template matching based and consists of three main technical components, PCOF-MOD (multimodal PCOF), balanced pose tree (BPT) and optimum memory rearrangement for a coarse-to-fine search. Our model templates on densely sampled viewpoints and PCOF-MOD which explicitly handles a certain range of 3D object pose improve the robustness against background clutters. BPT which is an efficient tree-based data structures for a large number of templates and template matching on rearranged feature maps where nearby features are linearly aligned accelerate the pose estimation. The experimental evaluation on tabletop and bin-picking dataset showed that our method achieved higher accuracy and faster speed in comparison with state-of-the-art techniques including recent CNN based approaches. Moreover, our model templates can be trained solely from 3D CAD in a few minutes and the pose estimation run in near real-time (23 fps) on CPU. These features are suitable for any real applications.",
        "primary_area": "",
        "author": "Yoshinori Konishi;Kosuke Hattori;Manabu Hashimoto;Yoshinori Konishi;Kosuke Hattori;Manabu Hashimoto",
        "authorids": "/38041239500;/37087322530;/37065831800;/38041239500;/37087322530;/37065831800",
        "aff": "OMRON Corporation, Kyoto, Japan; OMRON Corporation, Kyoto, Japan; Dept. Engineering, Chukyo Univ, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967967/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8752243753923047907&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "OMRON Corporation;Chukyo University",
        "aff_unique_dep": ";Dept. Engineering",
        "aff_unique_url": "https://www.omron.com;https://www.chukyo-u.ac.jp",
        "aff_unique_abbr": "OMRON;Chukyo Univ",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Kyoto;Nagoya",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967706",
        "title": "Real-Time Quad-Rotor Path Planning Using Convex Optimization and Compound State-Triggered Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "The contribution of this paper is the application of compound state-triggered constraints (STCs) to real-time quadrotor path planning. Originally developed for rocket landing applications, STCs are made up of a trigger condition and a constraint condition that are arranged such that satisfaction of the former implies satisfaction of the latter. Compound STCs go a step further by allowing multiple trigger and constraint conditions to be combined via Boolean \u201cand\u201d or \u201cor\u201d operations. The logical implications embodied by STCs can be formulated using continuous variables, and thus enable the incorporation of discrete decision making into a continuous optimization framework. In this paper, compound STCs are used to solve quad-rotor path planning problems that would typically require the use of computationally expensive mixed-integer programming techniques. Two scenarios are considered: (1) a quad-rotor flying through a hoop, and (2) a pair of quadrotors carrying a beam-like payload through an obstacle course. Successive convexification is used to solve the resulting non-convex optimization problem. Monte-Carlo simulation results show that our approach can reliably generate trajectories at rates upwards of 3 and 1.5 Hz for the first and second scenarios, respectively.",
        "primary_area": "",
        "author": "Michael Szmuk;Danylo Malyuta;Taylor P. Reynolds;Margaret Skye Mceowen;Beh\u00e7et A\u00e7ikme\u015fe;Michael Szmuk;Danylo Malyuta;Taylor P. Reynolds;Margaret Skye Mceowen;Beh\u00e7et A\u00e7ikme\u015fe",
        "authorids": "/37086062141;/37086577078;/37086597098;/37087324627;/38556527000;/37086062141;/37086577078;/37086597098;/37087324627;/38556527000",
        "aff": "Autonomous Control Laboratory, University of Washington, Seattle, WA, USA; Autonomous Control Laboratory, University of Washington, Seattle, WA, USA; Robotics, Aerospace and Information Networks Laboratory, University of Washington, Seattle, WA, USA; Autonomous Control Laboratory, University of Washington, Seattle, WA, USA; Autonomous Control Laboratory, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967706/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=444115336367483378&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Autonomous Control Laboratory",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967557",
        "title": "Real-time Model-based Image Color Correction for Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a new underwater imaging formation model presented that the coefficients related to the direct and backscatter transmission signals are dependent on the type of water, camera specifications, water depth, and imaging range. This paper proposes an underwater color correction method that integrates this new model on an underwater robot, using information from a pressure depth sensor for water depth and a visual odometry system for estimating scene distance. Experiments were performed with and without a color chart over coral reefs and a shipwreck in the Caribbean. We demonstrate the performance of our proposed method by comparing it with other statistic-, physic-, and learning-based color correction methods. Applications for our proposed method include improved 3D reconstruction and more robust underwater robot navigation.",
        "primary_area": "",
        "author": "Monika Roznere;Alberto Quattrini Li;Monika Roznere;Alberto Quattrini Li",
        "authorids": "/37087322448;/37085808885;/37087322448;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967557/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12556620650720690874&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hanover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967933",
        "title": "Real-time monitoring of human task advancement",
        "track": "main",
        "status": "Poster",
        "abstract": "In collaborative robotics applications, human behaviour is a major source of uncertainty. Predicting the evolution of the current human activity might be beneficial to the effectiveness of task planning, as it enables a higher level of coordination of robot and human activities. This paper addresses the problem of monitoring the advancement of human tasks in real-time giving an estimate of their expected duration. The proposed method relies on dynamic time warping to align the current activity with a reference template. No training phase is required, as the prototypical execution is learnt online from previous instances of the same activity. The applicability and performance of the method within an industrial context have been verified on a realistic assembly task.",
        "primary_area": "",
        "author": "Riccardo Maderna;Paolo Lanfredini;Andrea Maria Zanchettin;Paolo Rocco;Riccardo Maderna;Paolo Lanfredini;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086455306;/37087324167;/37546427600;/37274178600;/37086455306;/37087324167;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967933/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9197922743702490184&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967927",
        "title": "Rebellion and Obedience: The Effects of Intention Prediction in Cooperative Handheld Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Within this work, we explore intention inference for user actions in the context of a handheld robot setup. Handheld robots share the shape and properties of handheld tools while being able to process task information and aid manipulation. Here, we propose an intention prediction model to enhance cooperative task solving. The model derives intention from the combined information about the user's gaze pattern and task knowledge. Within experimental studies, the model is validated through a comparison of user frustration for the case where the robot follows the predicted location of the user's intended action versus doing the opposite (rebellion). The proposed model yields real-time capabilities and reliable accuracy up to 1.5 s prior to predicted actions being executed.",
        "primary_area": "",
        "author": "Janis Stolzenwald;Walterio W. Mayol-Cuevas;Janis Stolzenwald;Walterio W. Mayol-Cuevas",
        "authorids": "/37086317459;/38270046600;/37086317459;/38270046600",
        "aff": "Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967927/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5373910405414766511&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "Bristol",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968155",
        "title": "Recalling Candidates of Grasping Method from an Object Image using Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are required to support people's work. In order to alleviate the burden on people, it is desirable that robot can automatically generate and execute complicated motions according to simple directions from people. However, there are multiple grasping methods for one object. In order to select a motion suitable for the direction, it is important to estimate candidates of grasping method for the object. In this research, we purpose to recall candidates of grasping position and hand shape from an object image. In learning, a network that outputs a plurality of grasping method candidates for one object image to each channel of a multi-channel image is used. At this time, a plurality of grasping methods are not learned at same time, learned one by one. The similar grasping method for the similar object shape is automatically clustered to each output channel in the learning process, and a grasping method having a characteristic difference is presented as a candidate. We show the usefulness of this method using experimental examples.",
        "primary_area": "",
        "author": "Makoto Sanada;Tadashi Matsuo;Nobutaka Shimada;Yoshiaki Shirai;Makoto Sanada;Tadashi Matsuo;Nobutaka Shimada;Yoshiaki Shirai",
        "authorids": "/37087322795;/38187189800;/37269959300;/37269955100;/37087322795;/38187189800;/37269959300;/37269955100",
        "aff": "Advanced Information Science and Engineering, 1-1-1, Nojihigashi, Ritsumeikan University Graduate School of Information Science and Engineering, Kusatsu city, Shiga, Japan; Faculty of Information Science and Enginering, 1-1-1, Nojihigashi, Ritsumeikan University, Kusatsu city, Shiga, Japan; Faculty of Information Science and Enginering, 1-1-1, Nojihigashi, Ritsumeikan University, Kusatsu city, Shiga, Japan; Faculty of Information Science and Enginering, 1-1-1, Nojihigashi, Ritsumeikan University, Kusatsu city, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968155/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11144754984619468711&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Graduate School of Information Science and Engineering",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967640",
        "title": "Reconfiguration Motion Planning for Variable Topology Truss",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an algorithm to do motion planning for a new class of self-reconfigurable modular robot: the variable topology truss (VTT). Modular robots consist of many modules that can be configured into various structures, and motion planning problem for modular robots with many degrees of freedom and many motion constraints is a significant challenge. In this paper, we propose a novel motion planning algorithm for modular robots to handle this problem with huge state space inspired by DNA replication process - the topology of DNA can be changed by cutting and resealing strands as tanglements form. In a variable topology truss, a single node with enough edge modules can split into a pair of nodes and two separate nodes can be merged to become an individual one. This self-reconfiguration ability results in more potential applications for this type of robots in unstructured environment, such as space and underseas but also leads to more challenges for reconfiguration planning. A novel way to model the robot in a nonuniform grid space is presented and a simple local planner is also developed to check the validation of possible actions. This approach significantly simplifies the problem and some experiment results show that the complicated problem can be solved in a reasonable time.",
        "primary_area": "",
        "author": "Chao Liu;Mark Yim;Chao Liu;Mark Yim",
        "authorids": "/37086114571;/37274063600;/37086114571;/37274063600",
        "aff": "GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967640/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7236354341393338578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Mechanical Engineering and Applied Mechanics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968448",
        "title": "Reconstructing Endovascular Catheter Interaction Forces in 3D using Multicore Optical Shape Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Catheterization instruments are increasingly being improved to accurately diagnose and treat cardiovascular conditions. However, current catheter systems provide limited information about the shape of the catheter and tissue-instrument interaction forces during an intervention. Furthermore, relying on inconsistent feedback of such interaction forces during an intervention may result in tissue injury. This paper presents the first steps to estimate the interaction forces between a catheter and a mock-up arterial environment. We base the proposed method on a Pseudo-Rigid Body approximation of the catheter and integrate three-dimensional shape information provided by Fiber Bragg Grating sensors inside the catheter. The reconstructed forces along the catheter body can be fed back to the surgeon in visual and/or haptic form. In this work, the estimated forces are displayed in real-time in a graphical user interface with the reconstructed catheter shape. Experimental validation demonstrates a root mean square error of 0.03 N and a mean reconstruction error of 0.02 N.",
        "primary_area": "",
        "author": "Christoff M. Heunis;Vincenza Belfiore;Marilena Vendittelli;Sarthak Misra;Christoff M. Heunis;Vincenza Belfiore;Marilena Vendittelli;Sarthak Misra",
        "authorids": "/37086456773;/37087323738;/37283187500;/37536488800;/37086456773;/37087323738;/37283187500;/37536488800",
        "aff": "Surgical Robotics Laboratory, University of Twente, The Netherlands; Department of Information Engineering, Electronics and Telecommunications and with the Robotics Laboratory at the Department of Computer, Control and Management Engineering, Sapienza University of Rome, Italy; Department of Information Engineering, Electronics and Telecommunications and with the Robotics Laboratory at the Department of Computer, Control and Management Engineering, Sapienza University of Rome, Italy; Surgical Robotics Laboratory, University of Twente, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968448/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18369053652770943770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Twente;Sapienza University of Rome",
        "aff_unique_dep": "Surgical Robotics Laboratory;Department of Information Engineering, Electronics and Telecommunications",
        "aff_unique_url": "https://www.utwente.nl;https://www.uniroma1.it",
        "aff_unique_abbr": ";Sapienza",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Rome",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Netherlands;Italy"
    },
    {
        "id": "8968536",
        "title": "Region-wise Polynomial Regression for 3D Mobile Gaze Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of mobile gaze tracking techniques, a 3D gaze point can be calculated as the middle point between two 3D visual axes. To infer gaze directions and eyeball positions, a nonlinear optimization problem is typically formulated to minimize the angular disparities between the training gaze directions and prediction ones. Nonetheless, the experimental results reported by some previous works show that this kind of approaches are very likely to yield large prediction errors hence considered less useful for human-machine interactions. In this study, we aim to address this widespread issue in three aspects. At first, instead of using a global regression model, a simple local polynomial model is proposed to back-project a pupil center onto its corresponding visual axis. Based on the Leave-One-Out cross-validation criterion, the partition structure is automatically learned in the process of resolving a homography-like relationship. Secondly, a good starting point for nonlinear-optimization is obtained by the image eyeball center, which can be estimated by systematic parallax errors. Meanwhile, it is necessary to add the suitable constraints for 3D eye positions. Otherwise, the optimization may end up with trivial solutions, i.e., faraway eye positions. Thirdly, we explore a strategy for designing the spatial distribution of calibration points in a principled manner. The experiment results demonstrate that an encouraging gaze estimation accuracy can be achieved by our proposed framework for both the normal vision and eyewear users.",
        "primary_area": "",
        "author": "Dan Su;You Fu Li;Hao Chen;Dan Su;You Fu Li;Hao Chen",
        "authorids": "/37086117273;/37279884400;/37086336612;/37086117273;/37279884400;/37086336612",
        "aff": "Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong; Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong; Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968536/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8226989747109264342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967630",
        "title": "Reinforcement Learning Boat Autopilot: A Sample-efficient and Model Predictive Control based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this research we focus on developing a reinforcement learning system for a challenging task: autonomous control of a real-sized boat, with difficulties arising from large uncertainties in the challenging ocean environment and the extremely high cost of exploring and sampling with a real boat. To this end, we explore a novel Gaussian processes (GP) based reinforcement learning approach that combines sample-efficient model-based reinforcement learning and model predictive control (MPC). Our approach, sample-efficient probabilistic model predictive control (SPMPC), iteratively learns a Gaussian process dynamics model and uses it to efficiently update control signals within the MPC closed control loop. A system using SPMPC is built to efficiently learn an autopilot task. After investigating its performance in a simulation modeled upon real boat driving data, the proposed system successfully learns to drive a real-sized boat equipped with a single engine and sensors measuring GPS, speed, direction, and wind in an autopilot task without human demonstration.",
        "primary_area": "",
        "author": "Yunduan Cui;Shigeki Osaki;Takamitsu Matsubara;Yunduan Cui;Shigeki Osaki;Takamitsu Matsubara",
        "authorids": "/37085661022;/37087324072;/37533262700;/37085661022;/37087324072;/37533262700",
        "aff": "Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan; FURUNO ELECTRIC CO., LTD., Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967630/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16676457229924629707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nara Institute of Science and Technology;FURUNO ELECTRIC CO., LTD.",
        "aff_unique_dep": "Division of Information Science, Graduate School of Science and Technology;",
        "aff_unique_url": "https://www.naist.edu/;",
        "aff_unique_abbr": "NAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967856",
        "title": "Reinforcement Learning of Trajectory Distributions: Applications in Assisted Teleoperation and Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "The majority of learning from demonstration approaches do not address suboptimal demonstrations or cases when drastic changes in the environment occur after the demonstrations were made. For example, in real teleoperation tasks, the demonstrations provided by the user are often suboptimal due to interface and hardware limitations. In tasks involving co-manipulation and manipulation planning, the environment often changes due to unexpected obstacles rendering previous demonstrations invalid. This paper presents a reinforcement learning algorithm that exploits the use of relevance functions to tackle such problems. This paper introduces the Pearson correlation as a measure of the relevance of policy parameters in regards to each of the components of the cost function to be optimized. The method is demonstrated in a static environment where the quality of the teleoperation is compromised by the visual interface (operating a robot in a three-dimensional task by using a simple 2D monitor). Afterward, we tested the method on a dynamic environment using a real 7-DoF robot arm where distributions are computed online via Gaussian Process regression.",
        "primary_area": "",
        "author": "Marco Ewerton;Guilherme Maeda;Dorothea Koert;Zlatko Kolev;Masaki Takahashi;Jan Peters;Marco Ewerton;Guilherme Maeda;Dorothea Koert;Zlatko Kolev;Masaki Takahashi;Jan Peters",
        "authorids": "/37085357736;/37085364007;/37085651782;/37087322050;/37275389800;/37533077600;/37085357736;/37085364007;/37085651782;/37087322050;/37275389800;/37533077600",
        "aff": "Intelligent Autonomous Systems Group, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Brain Robot Interface (BRI), ATR Computational Neuroscience Laboratory, Soraku-gun Kyoto, Japan; Intelligent Autonomous Systems Group, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Intelligent Autonomous Systems Group, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Faculty of Science and Technology, Keio University, Kanagawa, Japan; Intelligent Autonomous Systems Group, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967856/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9272835601291913541&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;ATR Computational Neuroscience Laboratory;Keio University",
        "aff_unique_dep": "Intelligent Autonomous Systems Group;Department of Brain Robot Interface (BRI);Faculty of Science and Technology",
        "aff_unique_url": "https://www.tu-darmstadt.de;;https://www.keio.ac.jp",
        "aff_unique_abbr": "TUD;;Keio",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Darmstadt;;Kanagawa",
        "aff_country_unique_index": "0;1;0;0;1;0",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "8968217",
        "title": "Relaxing the Conservatism of Passivity Condition for Impedance Controlled Series Elastic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a practical and less conservative passivity analysis for series elastic actuators (SEAs) by introducing load port definition and shows that the achievable stiffness by the impedance control of SEA can be set higher than the inherent stiffness of SEA depending on the condition of the load dynamics. Since SEA can inherently measure or estimate a transmitted force thanks to its embedded spring element, impedance control is often exploited to render compliant behaviors related between the motion and the force. Although the stability of the SEA control system is of great importance, the conventional passivity analysis gives conservative criteria, and indeed limits the actual actuator performance. To tackle the conservatism of the conventional passivity in SEAs, we first explore the dynamic characteristics of SEA including load dynamics, which has been ignored for the sake of simplicity of the passivity analysis by excluding uncertain load dynamics. The inclusion of the load dynamics into the passivity analysis allows us to properly derive the less conservative limit of achievable stiffness by impedance control and the factors that determine the limit. The proposed analysis is verified by numerical simulations and applied to a passivity observer design for experimental validation on an actual SEA setup.",
        "primary_area": "",
        "author": "Hyunwook Lee;Jinoh Lee;Jee-Hwan Ryu;Sehoon Oh;Hyunwook Lee;Jinoh Lee;Jee-Hwan Ryu;Sehoon Oh",
        "authorids": "/37086045435;/37085391573;/37274994300;/37279132500;/37086045435;/37085391573;/37274994300;/37279132500",
        "aff": "Department of Robotics Engineering, DGIST, Daegu, Korea; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Department of Civil and Environmental Engineering, KAIST, Daejeon, Korea; Department of Robotics Engineering, DGIST, Daegu, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968217/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3905124340252306890&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology;Istituto Italiano di Tecnologia;KAIST",
        "aff_unique_dep": "Department of Robotics Engineering;Department of Advanced Robotics;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr;https://www.iit.it;https://www.kaist.ac.kr",
        "aff_unique_abbr": "DGIST;IIT;KAIST",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Daegu;Genova;Daejeon",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "South Korea;Italy"
    },
    {
        "id": "8967842",
        "title": "Representation Learning via Parallel Subset Reconstruction for 3D Point Cloud Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Three-dimensional (3D) point cloud processing has attracted a great deal of attention in computer vision, robotics, and the machine learning community because of significant progress in deep neural networks on 3D data. Another trend in the community is learning of generative models based on generative adversarial networks. In this paper, we propose a framework for 3D point cloud generation based on a combination of auto-encoders and generative adversarial networks. The framework first trains auto-encoders to learn latent representations, and then trains generative adversarial networks in the learned latent space. We focus on improving the training method for auto-encoders in order to generate 3D point clouds with higher fidelity and coverage. We add parallel sub-decoders that reconstruct subsets of the input point cloud. In order to construct these subsets, we introduce a point sampling algorithm that imposes a method to sample spatially localized point sets. These local subsets are utilized to measure local reconstruction losses. We train auto-encoders to learn an effective latent representation for both global and local shape reconstruction based on the multi-task learning approach. Furthermore, we add global and local adversarial losses to generate more plausible point clouds. Quantitative and qualitative evaluations demonstrate that the proposed method outperforms state-of-the-art method on the task of 3D point cloud generation.",
        "primary_area": "",
        "author": "Kohei Matsuzaki;Kazuyuki Tasaka;Kohei Matsuzaki;Kazuyuki Tasaka",
        "authorids": "/37085774778;/37086528940;/37085774778;/37086528940",
        "aff": "Media Recognition Laboratory, KDDI Research, Inc, Saitama, Japan; Media Recognition Laboratory, KDDI Research, Inc, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967842/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18281141053005795867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KDDI Research, Inc",
        "aff_unique_dep": "Media Recognition Laboratory",
        "aff_unique_url": "https://www.kddi-research.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967861",
        "title": "Representing Robot Task Plans as Robust Logical-Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "It is difficult to create robust, reusable, and reactive behaviors for robots that can be easily extended and combined. Frameworks such as Behavior Trees are flexible but difficult to characterize, especially when designing reactions and recovery behaviors to consistently converge to a desired goal condition. We propose a framework which we call Robust Logical-Dynamical Systems (RLDS), which combines the advantages of task representations like behavior trees with theoretical guarantees on performance. RLDS can also be constructed automatically from simple sequential task plans and will still achieve robust, reactive behavior in dynamic real-world environments. In this work, we describe both our proposed framework and a case study on a simple household manipulation task, with examples for how specific pieces can be implemented to achieve robust behavior. Finally, we show how in the context of these manipulation tasks, a combination of an RLDS with planning can achieve better results under adversarial conditions.",
        "primary_area": "",
        "author": "Chris Paxton;Nathan Ratliff;Clemens Eppner;Dieter Fox;Chris Paxton;Nathan Ratliff;Clemens Eppner;Dieter Fox",
        "authorids": "/37085403975;/37579950900;/37571607800;/37284329000;/37085403975;/37579950900;/37571607800;/37284329000",
        "aff": "NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967861/",
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15771794994190076903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NV",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968533",
        "title": "ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Since deep-learning-based method has been widely-used and is capable of generating generic model, most existing methods about action recognition use either two-stream structure, considering spatial and temporal features separately, or C3D, costing lots of prices in memory and time. We aim to design a robust system to extract spatiotemporal features with aggregation mechanism to integrate local features in temporal order. In light of this, we propose ResFlow to estimate optical flow and predict action recognition simultaneously. Leveraging the characteristic of optical flow estimation, we extract spatiotemporal feature via an autoencoder. Via a novel Sequentially Pooling Mechanism which literally pool global spatiotemporal feature sequentially, we extract spatiotemporal feature at each time and aggregate these local features into global feature. This design use only RGB images as input with temporal information encoded, pre-trained by optical flow, and sequentially aggregate spatiotemporal features in high efficiency. We evaluate our ability of estimating optical flow on FlyingChairs dataset and show the promising results of action recognition on UCF-101 dataset through a series of experiments.",
        "primary_area": "",
        "author": "Tso-Hsin Yeh;Chuan Kuo;An-Sheng Liu;Yu-Hung Liu;Yu-Huan Yang;Zi-Jun Li;Jui-Ting Shen;Li-Chen Fu;Tso-Hsin Yeh;Chuan Kuo;An-Sheng Liu;Yu-Hung Liu;Yu-Huan Yang;Zi-Jun Li;Jui-Ting Shen;Li-Chen Fu",
        "authorids": "/37086100869;/37087323800;/37074672100;/37086608818;/37086095883;/37086268387;/37085530160;/37278448600;/37086100869;/37087323800;/37074672100;/37086608818;/37086095883;/37086268387;/37085530160;/37278448600",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968533/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13329165497855385308&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "National Taiwan University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.ntu.edu.tw",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968083",
        "title": "Research on Finite Ground Effect of a Rotor",
        "track": "main",
        "status": "Poster",
        "abstract": "The enrichment of the application scenarios of rotorcrafts presents new challenges for the study of their aerodynamic characteristics, such as operating above a building surface of finite size. In this paper, the ground effect is divided into infinite ground effect and finite ground effect, and three types of finite ground effects with different blocked area are studied. Through numerical simulations, the rotor thrust data and flow field figures in ground effect are obtained. Based on the rotor thrust data, mathematical models are established to describe the rotor thrust alteration caused by infinite and finite ground effect. The analysis of the flow field reveals the mechanism of the finite ground effect.",
        "primary_area": "",
        "author": "Xinkuang Wang;Yong Liu;Chengwei Huang;Xinkuang Wang;Yong Liu;Chengwei Huang",
        "authorids": "/37086441556;/37537598400;/37085725057;/37086441556;/37537598400;/37085725057",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968083/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15211257433282689772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.nust.edu.cn",
        "aff_unique_abbr": "NUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968611",
        "title": "Resilience by Reconfiguration: Exploiting Heterogeneity in Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method to maintain high resource availability in a networked heterogeneous multi-robot system subject to resource failures. In our model, resources such as sensing and computation are available on robots. The robots are engaged in a joint task using these pooled resources. When a resource on a particular robot becomes unavailable (e.g., a sensor ceases to function), the system automatically reconfigures so that the robot continues to have access to this resource by communicating with other robots. Specifically, we consider the problem of selecting edges to be modified in the system's communication graph after a resource failure has occurred. We define a metric that allows us to characterize the quality of the resource distribution in the network represented by the communication graph. Upon a resource becoming unavailable due to failure, we reconFigure the network so that the resource distribution is brought as close to the maximal resource distribution as possible without a large change in the number of active inter-robot communication links. Our approach uses mixed integer semi-definite programming to achieve this goal. We employ a simulated annealing method to compute a spatial formation that satisfies the inter-robot distances imposed by the topology, along with other constraints. Our method can compute a communication topology, spatial formation, and formation change motion planning in a few seconds. We validate our method in simulation and real-robot experiments with a team of seven quadrotors.",
        "primary_area": "",
        "author": "Ragesh K. Ramachandran;James A. Preiss;Gaurav S. Sukhatme;Ragesh K. Ramachandran;James A. Preiss;Gaurav S. Sukhatme",
        "authorids": "/37087324984;/37086138258;/37278934100;/37087324984;/37086138258;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968611/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11442591758034637025&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967879",
        "title": "Resolving Elevation Ambiguity in 1-D Radar Array Measurements using Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by requirements for future automotive radar, we study the problem of resolving target elevation from measurements by a one-dimensional horizontal radar antenna array. This is a challenging and ill-posed problem, since such measurements contain only indirect and highly ambiguous elevation cues. As a consequence, traditional model-based approaches fail. We instead propose to use a machine-learning-based approach that learns to exploit the subtle elevation cues and prior knowledge of the scene from the data. We design an encoder-decoder structured deep convolutional neural network that takes a radar return intensity image in the range-azimuth plane as input and produces a depth image in the elevation-azimuth plane as output. We train the network with over 200 000 radar frames collected in highway environments. Through experimental evaluations, we demonstrate the feasibility of resolving the highly ambiguous elevation information in such environments.",
        "primary_area": "",
        "author": "Jayakrishnan Unnikrishnan;Urs Niesen;Jayakrishnan Unnikrishnan;Urs Niesen",
        "authorids": "/37572645200;/38477793500;/37572645200;/38477793500",
        "aff": "Qualcomm Flarion Technologies, Inc, Bridgewater, USA; Qualcomm Flarion Technologies, Inc, Bridgewater, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967879/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8719799150851909445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Qualcomm Flarion Technologies, Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.qualcomm.com",
        "aff_unique_abbr": "QFT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bridgewater",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968130",
        "title": "Responsive Joint Attention in Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Joint attention has been shown to be not only crucial for human-human interaction but also human-robot interaction. Joint attention can help to make cooperation more efficient, support disambiguation in instances of uncertainty and make interactions appear more natural and familiar. In this paper, we present an autonomous gaze system that uses multimodal perception capabilities to model responsive joint attention mechanisms. We investigate the effects of our system on people\u2019s perception of a robot within a problem-solving task. Results from a user study suggest that responsive joint attention mechanisms evoke higher perceived feelings of social presence on scales that regard the direction of the robot\u2019s perception.",
        "primary_area": "",
        "author": "Andr\u00e9 Pereira;Catharine Oertel;Leonor Fermoselle;Joe Mendelson;Joakim Gustafson;Andr\u00e9 Pereira;Catharine Oertel;Leonor Fermoselle;Joe Mendelson;Joakim Gustafson",
        "authorids": "/37678412800;/38253487600;/37087322456;/37087324974;/38315954500;/37678412800;/38253487600;/37087322456;/37087324974;/38315954500",
        "aff": "Speech, Music and Hearing Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Computer-Human Interaction Lab for Learning & Instruction at \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Speech, Music and Hearing Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Speech, Music and Hearing Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Speech, Music and Hearing Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968130/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16535716509822802942&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;EPFL",
        "aff_unique_dep": "EECS;Computer-Human Interaction Lab for Learning & Instruction",
        "aff_unique_url": "https://www.kth.se;https://epfl.ch",
        "aff_unique_abbr": "KTH;EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stockholm;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Sweden;Switzerland"
    },
    {
        "id": "8968047",
        "title": "Retrieval-based Localization Based on Domain-invariant Feature Learning under Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization is a crucial problem in mobile robotics and autonomous driving. One solution is to retrieve images with known pose from a database for the localization of query images. However, in environments with drastically varying conditions (e.g. illumination changes, seasons, occlusion, dynamic objects), retrieval-based localization is severely hampered and becomes a challenging problem. In this paper, a novel domain-invariant feature learning method (DIFL) is proposed based on ComboGAN, a multi-domain image translation network architecture. By introducing a feature consistency loss (FCL) between the encoded features of the original image and translated image in another domain, we are able to train the encoders to generate domain-invariant features in a self-supervised manner. To retrieve a target image from the database, the query image is first encoded using the encoder belonging to the query domain to obtain a domain-invariant feature vector. We then preform retrieval by selecting the database image with the most similar domain-invariant feature vector. We validate the proposed approach on the CMU-Seasons dataset, where we outperform state-of-the-art learning-based descriptors in retrieval-based localization for high and medium precision scenarios.",
        "primary_area": "",
        "author": "Hanjiang Hu;Hesheng Wang;Zhe Liu;Chenguang Yang;Weidong Chen;Le Xie;Hanjiang Hu;Hesheng Wang;Zhe Liu;Chenguang Yang;Weidong Chen;Le Xie",
        "authorids": "/37087321985;/37292567100;/38505849700;/37087321876;/37279187800;/37829449800;/37087321985;/37292567100;/38505849700;/37087321876;/37279187800;/37829449800",
        "aff": "School of Material Science and Engineering, Shanghai Jiao Tong University, China; School of Material Science and Engineering, Shanghai Jiao Tong University, China; School of Material Science and Engineering, Shanghai Jiao Tong University, China; School of Material Science and Engineering, Shanghai Jiao Tong University, China; School of Material Science and Engineering, Shanghai Jiao Tong University, China; School of Material Science and Engineering, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968047/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11780725373492686156&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Material Science and Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967862",
        "title": "Right of Way, Assertiveness and Social Recognition in Human-Robot Doorway Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "We expand on previous work for negotiating human-robot navigation contention around doorways to produce a more socially-compliant autonomous robot behaviour. Our goal is to improve the integration of robots navigating in human environments by eliciting human recognition of the robot's right of way. This is achieved by incorporating feedback from a user study of our previous system to create a more communicative, reciprocal, and assertive behaviour. Our contribution includes both the updated behaviour and a new user study that evaluates and compares the system to its predecessor. Results show that participants are more likely to respect the robot's right of way given the new robot behaviour, but their responses also highlight the challenges of socially integrating robots into human spaces.",
        "primary_area": "",
        "author": "Jack Thomas;Richard Vaughan;Jack Thomas;Richard Vaughan",
        "authorids": "/37085779244;/37335176000;/37085779244;/37335176000",
        "aff": "School of Computing Science, Simon Fraser University, 8888 University Drive, Burnaby, B.C., Canada; School of Computing Science, Simon Fraser University, 8888 University Drive, Burnaby, B.C., Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967862/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17610027471575432428&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8968084",
        "title": "Riverine Coverage with an Autonomous Surface Vehicle over Known Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Environmental monitoring and surveying operations on rivers currently are performed primarily with manually-operated boats. In this domain, autonomous coverage of areas is of vital importance, for improving both the quality and the efficiency of coverage. This paper leverages human expertise in river exploration and data collection strategies to automate and optimize these processes using autonomous surface vehicles (ASVs). In particular, three deterministic algorithms for both partial and complete coverage of a river segment are proposed, providing varying path length, coverage density, and turning patterns. These strategies resulted in increases in accuracy and efficiency compared to human performance. The proposed methods were extensively tested in simulation using maps of real rivers of different shapes and sizes. In addition, to verify their performance in real world operations, the algorithms were deployed successfully on several parts of the Congaree River in South Carolina, USA, resulting in total of more than 35km of coverage trajectories in the field.",
        "primary_area": "",
        "author": "Nare Karapetyan;Adam Braude;Jason Moulton;Joshua A. Burstein;Scott White;Jason M. O\u2019Kane;Ioannis Rekleitis;Nare Karapetyan;Adam Braude;Jason Moulton;Joshua A. Burstein;Scott White;Jason M. O\u2019Kane;Ioannis Rekleitis",
        "authorids": "/37086299803;/37087322129;/37086453416;/37087323177;/37087323748;/37279835400;/37281356300;/37086299803;/37087322129;/37086453416;/37087323177;/37087323748;/37279835400;/37281356300",
        "aff": "Computer Science & Engineering Department, University of South Carolina; Computer Science Department, University of Puget Sound; Computer Science & Engineering Department, University of South Carolina; Earth, Ocean, and Environment Department, University of South, Carolina; Earth, Ocean, and Environment Department, University of South, Carolina; Computer Science & Engineering Department, University of South Carolina; Computer Science & Engineering Department, University of South Carolina",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968084/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11630672800160622716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "University of South Carolina;University of Puget Sound",
        "aff_unique_dep": "Computer Science & Engineering Department;Computer Science Department",
        "aff_unique_url": "https://www.sc.edu;https://www.pugetsound.edu",
        "aff_unique_abbr": "USC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968167",
        "title": "RoFICoM \u2013 First Open-Hardware Connector for Metamorphic Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present RoFICoM, a new retractable connection device that allows for mechanical, electric, and data communication connection between separable robotic modules. The device is intentionally designed to be used in lattice-type metamorphic robots, however, its applicability is much wider. The main novelty of our solution lies primarily in a new unique flat design and spatial compactness of the connector. With a flat connector, much more space is left for the body of a robotic module in the structure. Moreover, the connector is also fully self-contained device with well defined mechanical, electrical and data interfaces, hence it can be easily embedded in various robotic solutions. Our RoFICoM connector is easy to produce, it is open-hardware and free for non-commercial use. In the paper, we give construction details and report on a couple of experiments we performed to demonstrate key features of the connection achieved with two RoFICoM devices.",
        "primary_area": "",
        "author": "Jan Mr\u00e1zek;Ji\u0159\u00ed Barnat;Jan Mr\u00e1zek;Ji\u0159\u00ed Barnat",
        "authorids": "/37085536357;/37063396900;/37085536357;/37063396900",
        "aff": "Faculty of Informatics, Masaryk University, Brno, Czech Republic; Faculty of Informatics, Masaryk University, Brno, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968167/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8146556098391246042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Masaryk University",
        "aff_unique_dep": "Faculty of Informatics",
        "aff_unique_url": "https://www.muni.cz",
        "aff_unique_abbr": "MU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brno",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8968131",
        "title": "Roboat: An Autonomous Surface Vehicle for Urban Waterways",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned surface vehicles (USVs) are typically designed for open area marine applications. In this paper, we present a new autonomy system (Roboat) for urban waterways which requires robust localization, perception, planning, and control. A novel localization system, based on the extended Kalman filter (EKF), is proposed for USVs, which utilizes LiDAR, camera, and IMU to provide a decimeter-level precision in dynamic GPS-attenuated urban waterways. Area and shape filters are proposed to crop water reflections and street obstacles from a pointcloud. Euclidean clustering and multi-object contour tracking are then introduced to detect and track the static and moving objects reliably in urban waters. An efficient path planner is tailored to calculate optimal trajectories to avoid these static and dynamic obstacles. Lastly, a nonlinear model predictive control (NMPC) scheme with full state integration is formulated for the four-control-input robot to accurately track the trajectory from the planner in rough water. Extensive experiments show that the robot is able to autonomously navigate in both the indoor waterway and the cluttered outdoor waterway in the presence of static and dynamic obstacles, implying that Roboat could have a great impact on the future of transportation in many coastal and riverside cities.",
        "primary_area": "",
        "author": "Wei Wang;Banti Gheneti;Luis A. Mateos;Fabio Duarte;Carlo Ratti;Daniela Rus;Wei Wang;Banti Gheneti;Luis A. Mateos;Fabio Duarte;Carlo Ratti;Daniela Rus",
        "authorids": "/37073346500;/37086430928;/38228214600;/37086125892;/37590016800;/37279652300;/37073346500;/37086430928;/38228214600;/37086125892;/37590016800;/37279652300",
        "aff": "SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968131/",
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5988579593486650513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "SENSEable City Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968235",
        "title": "Robot Finger with Remote Center of Motion Mechanism for Covering Joints with Thick Skin",
        "track": "main",
        "status": "Poster",
        "abstract": "An end-effector such as a gripper or multi-fingered hand is essential to enable robots to grasp and manipulate objects of various size and shape. Soft skin increases the grasp stability and can provide space for tactile sensors. However, covering the joints with skin is challenging, typically causing a considerable surface area of multi-segment robot fingers not to be covered by skin. This also creates the risk that objects get pinched in the joints when flexing the fingers. The current paper suggests using a remote center motion (RCM) mechanism to move the center of joint rotation to the surface of a thick skin layer. In particular, a 6-bar mechanism is used. Thereby, a thick soft skin layer with a continuous surface can be realized. Furthermore, adaptive joint coupling with linkages is implemented. In the current paper a 2-fingered gripper is realized, and objects of various size and shape are grasped (from thin paper to objects of 135 mm diameter). The current gripper was manufactured with 3D-printed material to enable rapid prototyping, therefore the payload was limited to only 1 kg for this version. Overall, this paper shows the feasibility of an RCM for a robot finger and discusses the benefits and limitations of such a mechanism.",
        "primary_area": "",
        "author": "Chincheng Hsu;Alexander Schmitz;Kosuke Kusayanagi;Shigeki Sugano;Chincheng Hsu;Alexander Schmitz;Kosuke Kusayanagi;Shigeki Sugano",
        "authorids": "/37087054791;/37587110100;/37087045319;/37274050800;/37087054791;/37587110100;/37087045319;/37274050800",
        "aff": "Sugano Lab, Waseda University, Tokyo, Japan; Sugano Lab, Waseda University, Tokyo, Japan; Sugano Lab, Waseda University, Tokyo, Japan; Sugano Lab, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968235/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10614261705572935351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Sugano Lab",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968042",
        "title": "Robot Learning of Shifting Objects for Grasping in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic grasping in cluttered environments is often infeasible due to obstacles preventing possible grasps. Then, pre-grasping manipulation like shifting or pushing an object becomes necessary. We developed an algorithm that can learn, in addition to grasping, to shift objects in such a way that their grasp probability increases. Our research contribution is threefold: First, we present an algorithm for learning the optimal pose of manipulation primitives like clamping or shifting. Second, we learn non-prehensible actions that explicitly increase the grasping probability. Making one skill (shifting) directly dependent on another (grasping) removes the need of sparse rewards, leading to more data-efficient learning. Third, we apply a real-world solution to the industrial task of bin picking, resulting in the ability to empty bins completely. The system is trained in a self-supervised manner with around 25 000 grasp and 2500 shift actions. Our robot is able to grasp and file objects with 274\u00b13 picks per hour. Furthermore, we demonstrate the system's ability to generalize to novel objects.",
        "primary_area": "",
        "author": "Lars Berscheid;Pascal Mei\u00dfner;Torsten Kr\u00f6ger;Lars Berscheid;Pascal Mei\u00dfner;Torsten Kr\u00f6ger",
        "authorids": "/37085380166;/38303891500;/37283223400;/37085380166;/38303891500;/37283223400",
        "aff": "Intelligent Process Automation and Robotics Lab (IPR), Karlsruhe Institute of Technology (KIT); Intelligent Process Automation and Robotics Lab (IPR), Karlsruhe Institute of Technology (KIT); Intelligent Process Automation and Robotics Lab (IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968042/",
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6652820645666843777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Intelligent Process Automation and Robotics Lab (IPR)",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968306",
        "title": "Robot Learning via Human Adversarial Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Much work in robotics has focused on \u201chumanin-the-loop\u201d learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",
        "primary_area": "",
        "author": "Jiali Duan;Qian Wang;Lerrel Pinto;C.-C. Jay Kuo;Stefanos Nikolaidis;Jiali Duan;Qian Wang;Lerrel Pinto;C.-C. Jay Kuo;Stefanos Nikolaidis",
        "authorids": "/37087322982;/37087322509;/37085796211;/37659728300;/37643766400;/37087322982;/37087322509;/37085796211;/37659728300;/37643766400",
        "aff": "Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968306/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15726215313966982840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Southern California;Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Robotics Institute",
        "aff_unique_url": "https://www.usc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "USC;CMU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Los Angeles;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967847",
        "title": "Robot Localization in Floor Plans Using a Room Layout Edge Extraction Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Indoor localization is one of the crucial enablers for deployment of service robots. Although several successful techniques for indoor localization have been proposed, the majority of them relies on maps generated from data gathered with the same sensor modality used for localization. Typically, tedious labor by experts is needed to acquire this data, thus limiting the readiness of the system as well as its ease of installation for inexperienced operators. In this paper, we propose a memory and computationally efficient monocular camera-based localization system that allows a robot to estimate its pose given an architectural floor plan. Our method employs a convolutional neural network to predict room layout edges from a single camera image and estimates the robot pose using a particle filter that matches the extracted edges to the given floor plan. We evaluate our localization system using multiple real-world experiments and demonstrate that it has the robustness and accuracy required for reliable indoor navigation.",
        "primary_area": "",
        "author": "Federico Boniardi;Abhinav Valada;Rohit Mohan;Tim Caselitz;Wolfram Burgard;Federico Boniardi;Abhinav Valada;Rohit Mohan;Tim Caselitz;Wolfram Burgard",
        "authorids": "/37085634709;/38075825200;/37087323734;/37085771058;/37270485300;/37085634709;/38075825200;/37087323734;/37085771058;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967847/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17550774073210025027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968019",
        "title": "Robot Localization via Odometry-assisted Ultra-wideband Ranging with Stochastic Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of accurate and high-rate self-localization for a mobile robot. We adaptively combine the speed information acquired by proprioceptive sensors with intermittent positioning samples acquired via ultra-wideband (UWB) radios. These are triggered only if and when needed to reduce the positioning uncertainty, itself modeled by a probabilistic cost function. Our formulation is agnostic w.r.t. the source of uncertainty and enables an intuitive specification of user navigation requirements along with stochastic guarantees on the system operation. Experimental results in simulation and with a real platform show that our approach i) meets these guarantees in practice ii) achieves the same accuracy of a fixed periodic sampling but with significantly higher scalability and lower energy consumption iii) is resilient to errors in UWB estimates, enabling the use of low-accuracy ranging schemes which further improve these two performance metrics.",
        "primary_area": "",
        "author": "Valerio Magnago;Pablo Corbal\u00e1n;Gian Pietro Picco;Luigi Palopoli;Daniele Fontanelli;Valerio Magnago;Pablo Corbal\u00e1n;Gian Pietro Picco;Luigi Palopoli;Daniele Fontanelli",
        "authorids": "/37086254678;/37086190936;/37299595000;/37268097200;/37398642200;/37086254678;/37086190936;/37299595000;/37268097200;/37398642200",
        "aff": "Dipartimento di Ingegneria e Scienza dell\u2019Informazione (DISI), University of Trento, Italy; Dipartimento di Ingegneria e Scienza dell\u2019Informazione (DISI), University of Trento, Italy; Dipartimento di Ingegneria e Scienza dell\u2019Informazione (DISI), University of Trento, Italy; Dipartimento di Ingegneria e Scienza dell\u2019Informazione (DISI), University of Trento, Italy; Dipartimento di Ingegneria Industriale (DII), University of Trento, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968019/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1264910798665852970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Trento",
        "aff_unique_dep": "Dipartimento di Ingegneria e Scienza dell\u2019Informazione (DISI)",
        "aff_unique_url": "https://www.unitn.it",
        "aff_unique_abbr": "UniTN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968060",
        "title": "Robot-Based Machining of Unmodeled Objects via Feature Detection in Dense Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Machining applications using robots are still not common in industrial settings. Reasons are the unintuitive programming concepts which typically require expert knowledge and the inflexibility regarding small alterations of the workpieces. We present a prototypical solution for an intuitive and flexible robotic machining concept for unmodeled work pieces. For this we use a high resolution laser scanner to record very dense point clouds. Algorithms to detect linear edges with obtuse angled corners, linear edges with acute angled corners, linear inner edges and circular edges were developed, demonstrated and validated. To accurately execute generated trajectories in practice, an algorithm to directly calibrate the transformation between the sensor and the milling tool was developed. For the algorithms and the calibration process a repeatability tolerance of 0.2 mm is achieved.",
        "primary_area": "",
        "author": "Dennis Hartmann;Michael Mende;Denis \u0160togl;Bj\u00f6m Hein;Torsten Kr\u00f6ger;Dennis Hartmann;Michael Mende;Denis \u0160togl;Bj\u00f6m Hein;Torsten Kr\u00f6ger",
        "authorids": "/37086933778;/38468626000;/37085474285;/37604448500;/37283223400;/37086933778;/38468626000;/37085474285;/37604448500;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968060/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11172837523742342967&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967988",
        "title": "Robotic Cutting of Solids Based on Fracture Mechanics and FEM",
        "track": "main",
        "status": "Poster",
        "abstract": "Cutting skills are important for robots to acquire not only because of a need from kitchen automation, but also because of the technical challenge for robotic manipulation. Modeling of fracture and deformation during a cutting action, often based on the finite element method (FEM), provides the force and shape information used in knife control to implement a skill such as slice, chop, or dice. However, an object's 3D mesh model can be computationally prohibitive for achieving a desired accuracy since numerous tiny elements must be used near the knife's moving edge. To address this issue, we represent the object as evenly spaced slices normal to the cutting plane such that cutting of each slice requires only a 2D mesh. Fracture and force can be then interpolated between every two adjacent slices. Experiment with an Adept arm and an ATI force/torque (F/T) sensor has demonstrated reasonable accuracy in force ad shape modeling.",
        "primary_area": "",
        "author": "Prajjwal Jamdagni;Yan-Bin Jia;Prajjwal Jamdagni;Yan-Bin Jia",
        "authorids": "/37087325098;/37273296400;/37087325098;/37273296400",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967988/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1134528610600635224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968574",
        "title": "Robotic Tracking Control with Kernel Trick-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, reinforcement learning has been developed dramatically and is widely used to solve control problems, e.g., playing games. However, there are still some problems for reinforcement learning to perform robotic control tasks. Fortunately, the kernel trick-based methods provide a chance to deal with those challenges. This work aims at developing a kernel trick-based learning control method to carry out robotic tracking control tasks. A reward system, in this work, is presented in order to speed up the learning processes. And then, a kernel trick-based reinforcement learning tracking controller is presented to perform tracking control tasks on a robotic manipulator system. To evaluate the policy and assist the reward system to accelerate the speed of finding the optimal control policy, a critic system is introduced. Finally, from the comparison with the benchmark, the simulation results illustrate that our algorithm has faster convergence rate and can execute tracking control tasks effectively, the reward function and the critic system proposed in this work is efficient.",
        "primary_area": "",
        "author": "Yazhou Hu;Wenxue Wang;Hao Liu;Lianqing Liu;Yazhou Hu;Wenxue Wang;Hao Liu;Lianqing Liu",
        "authorids": "/37087322850;/37085440848;/37087324857;/37280779700;/37087322850;/37085440848;/37087324857;/37280779700",
        "aff": "State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; department of mathematics, Georgia Institute of Technology, Atlanta, GA, USA; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968574/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=203020864733477551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Georgia Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics;Department of Mathematics",
        "aff_unique_url": "http://www.cas.cn;https://www.gatech.edu",
        "aff_unique_abbr": "CAS;Georgia Tech",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Shenyang;Atlanta",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8967652",
        "title": "Robotic Ultrasound for Catheter Navigation in Endovascular Procedures",
        "track": "main",
        "status": "Poster",
        "abstract": "Endovascular procedures require real time visual feedback on the location of inserted catheters. This is currently achieved using X-ray fluoroscopy, which causes exposure to radiation. This study describes an alternative method using a robotic ultrasound system for catheter tracking and navigation in endovascular interventions, focusing on endovascular aneurysm repair. This approach relies on the registration of pre-operative images to provide both a tracking trajectory and visual feedback of the real-time catheter position. The procedure was validated on healthy volunteers and on a phantom that included a realistic vessel structure, showing an average tracking error of the moving catheter tip of 1.78\u00b11.02 mm.",
        "primary_area": "",
        "author": "Fernanda Langsch;Salvatore Virga;Javier Esteban;R\u00fcdiger G\u00f6bl;Nassir Navab;Fernanda Langsch;Salvatore Virga;Javier Esteban;R\u00fcdiger G\u00f6bl;Nassir Navab",
        "authorids": "/37087322608;/37086087638;/37087322265;/37086453222;/37282965500;/37087322608;/37086087638;/37087322265;/37086453222;/37282965500",
        "aff": "Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967652/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6788418287727944856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Computer Aided Medical Procedures",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968564",
        "title": "Robots that Take Advantage of Human Trust",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans often assume that robots are rational. We believe robots take optimal actions given their objective; hence, when we are uncertain about what the robot's objective is, we interpret the robot's actions as optimal with respect to our estimate of its objective. This approach makes sense when robots straightforwardly optimize their objective, and enables humans to learn what the robot is trying to achieve. However, our insight is that-when robots are aware that humans learn by trusting that the robot actions are rational-intelligent robots do not act as the human expects; instead, they take advantage of the human's trust, and exploit this trust to more efficiently optimize their own objective. In this paper, we formally model instances of human-robot interaction (HRI) where the human does not know the robot's objective using a two-player game. We formulate different ways in which the robot can model the uncertain human, and compare solutions of this game when the robot has conservative, optimistic, rational, and trusting human models. In an offline linear-quadratic case study and a real-time user study, we show that trusting human models can naturally lead to communicative robot behavior, which influences end-users and increases their involvement.",
        "primary_area": "",
        "author": "Dylan P. Losey;Dorsa Sadigh;Dylan P. Losey;Dorsa Sadigh",
        "authorids": "/37085812055;/38234464200;/37085812055;/38234464200",
        "aff": "Stanford Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA; Stanford Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968564/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1939461563316939138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Intelligent and Interactive Autonomous Systems Group (ILIAD)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968157",
        "title": "Robust Deformation Model Approximation for Robotic Cable Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable manipulation is a challenging task for robots. The major challenge is that cables have high degrees of freedom and are easy to deform during manipulation. In this paper, we propose a novel framework SPR-RWLS to manipulate cables, which includes real-time cable tracking and robust local deformation model approximation. For cable tracking, structure preserved registration (SPR) is utilized to robustly estimate the movement of selected points on a cable even in the presence of sensor noise, outliers, and occlusions. Robust weighted least squares (RWLS) is then applied to calculate the local deformation model of the cable under uncertainties. We show that SPR-RWLS enables the dual-arm robots to manipulate cables with different thicknesses and lengths to different desired curvatures in multiple scenarios. We also show that real-time implementation of the proposed method can be simplified by parallel computation.",
        "primary_area": "",
        "author": "Shiyu Jin;Changhao Wang;Masayoshi Tomizuka;Shiyu Jin;Changhao Wang;Masayoshi Tomizuka",
        "authorids": "/37087321850;/37086426211;/37281933000;/37087321850;/37086426211;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968157/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2075475824256172930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967816",
        "title": "Robust Grasp Planning Over Uncertain Shape Completions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for planning robust grasps over uncertain shape completed objects. For shape completion, a deep neural network is trained to take a partial view of the object as input and outputs the completed shape as a voxel grid. The key part of the network is dropout layers which are enabled not only during training but also at run-time to generate a set of shape samples representing the shape uncertainty through Monte Carlo sampling. Given the set of shape completed objects, we generate grasp candidates on the mean object shape but evaluate them based on their joint performance in terms of analytical grasp metrics on all the shape candidates. We experimentally validate and benchmark our method against another state-of-the-art method with a Barrett hand on 90000 grasps in simulation and 200 grasps on a real Franka Emika Panda. All experimental results show statistically significant improvements both in terms of grasp quality metrics and grasp success rate, demonstrating that planning shape-uncertainty-aware grasps brings significant advantages over solely planning on a single shape estimate, especially when dealing with complex or unknown objects.",
        "primary_area": "",
        "author": "Jens Lundell;Francesco Verdoja;Ville Kyrki;Jens Lundell;Francesco Verdoja;Ville Kyrki",
        "authorids": "/37086575749;/37085381448;/37274001900;/37086575749;/37085381448;/37274001900",
        "aff": "School of Electrical Engineering, Aalto University, Finland; School of Electrical Engineering, Aalto University, Finland; School of Electrical Engineering, Aalto University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967816/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11791862595516615220&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "8968040",
        "title": "Robust Hand-Eye Calibration via Iteratively Re-weighted Rank-Constrained Semi-Definite Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of estimating the Euclidean transformation relating two rigidly attached reference frames from motion measurements: a problem that is commonly referred to as the Hand-Eye calibration. The motion measurements are often affected by synchronization issues and hardware malfunctions. When using pose sensors, such as Electromagnetic or Inertial Measurement Units, the measurements are often less reliable than those obtained by a traditional robot-link and camera pair. Corrupt measurements, whether due to disturbances, large synchronization mismatches or malfunctions, are considered outliers that ought to be filtered out of the estimation process. While this may be achieved non-deterministically by using Random Sample Consensus, we propose a deterministic, robust and accurate method for solving the Hand-Eye calibration problem despite the presence of large amounts of outliers and high levels of measurement noise. The proposed method is based on a reformulation of this estimation problem as a rank-constrained semi-definite programming problem allowing for robustness to be enforced via an iteratively re-weighted optimization approach.",
        "primary_area": "",
        "author": "Chinmay Samant;Adlane Habed;Michel de Mathelin;Laurent Goffin;Chinmay Samant;Adlane Habed;Michel de Mathelin;Laurent Goffin",
        "authorids": "/37087324798;/37269096500;/37085959455;/38233019500;/37087324798;/37269096500;/37085959455;/38233019500",
        "aff": "ICube Laboratory, University of Strasbourg (France)-CNRS; ICube Laboratory, University of Strasbourg (France)-CNRS; ICube Laboratory, University of Strasbourg (France)-CNRS; ICube Laboratory, University of Strasbourg (France)-CNRS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968040/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2320380719686250316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube Laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "Unistra",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8967702",
        "title": "Robust High Accuracy Visual-Inertial-Laser SLAM System",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, many excellent works on visual-inertial SLAM and laser-based SLAM have been proposed. Although inertial measurement unit (IMU) significantly improve the motion estimate performance by reducing the impact of illumination variation or texture-less region on visual tracking, tracking failures occur when in such an environment for a long time. Similarly, when in structure-less environments, laser module will fail since lack of sufficient geometric features. Besides, motion estimation by moving lidar has the problem of distortion since range measurements are received continuously. To solve these problems, we propose a robust and high-accuracy visual-inertial-laser SLAM system. The system starts with a visual-inertial tightly-coupled method for motion estimation, followed by scan matching to further optimize the estimation and register point cloud on the map. Furthermore, we enable modules to be adjusted automatically and flexibly. That is, when one of these modules fails, the remaining modules will undertake the motion-tracking task. For further improving the accuracy, loop closure and proximity detection are implemented to eliminate drift accumulation. When loop or proximity is detected, we perform six degree-of-freedom (6-DOF) pose graph optimization to achieve the global consistency. The performance of our system is verified on public dataset, and the experimental results show that the proposed method achieves superior accuracy against other state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Zengyuan Wang;Jianhua Zhang;Shengyong Chen;Conger Yuan;Jingqian Zhang;Jianwei Zhang;Zengyuan Wang;Jianhua Zhang;Shengyong Chen;Conger Yuan;Jingqian Zhang;Jianwei Zhang",
        "authorids": "/37086404166;/37678556700;/37290961700;/37087322827;/37087322363;/37281460600;/37086404166;/37678556700;/37290961700;/37087322827;/37087322363;/37281460600",
        "aff": "Computer Science and Technology, Zhejiang University of Technology; Computer Science and Technology, Zhejiang University of Technology; Shengyong Chen is with School of Computer Science and Engineering, Tianjin University of Technology; Computer Science and Technology, Zhejiang University of Technology; Computer Science and Technology, Zhejiang University of Technology; TAMS group, University of Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967702/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=688609538104895085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Zhejiang University of Technology;Tianjin University of Technology;University of Hamburg",
        "aff_unique_dep": "Computer Science and Technology;School of Computer Science and Engineering;TAMS group",
        "aff_unique_url": "https://www.zjut.edu.cn;http://www.tjut.edu.cn;https://www.uni-hamburg.de",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "8968045",
        "title": "Robust Impedance Shaping of Redundant Teleoperators with Time-Delay via Sliding Mode Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a robust impedance shaping controller for teleoperation systems. An integral sliding mode control law (ISM) is employed together with standard robot inverse dynamics to reject disturbances and uncertainties acting on the robot model and obtain an ideal fully-decoupled system. Higher level optimization-based controllers are responsible for enforcing the desired end effector impedance on master and slave manipulators, as well as for solving possible kinematic redundancies and satisfying control constraints. A three-plus-one channel teleoperation architecture is proposed, with an in-depth analysis of its stability and transparency properties in presence of variable communication delays, based on Llewellyn' s absolute stability theorem. Impedance parameters tuning criteria are derived and the proposed scheme performance is compared in simulation with a time-domain passivity approach. The validation of the proposed controller is carried out on a ABB YuMi dual-arm redundant robot, with one arm employed as a master and the other one as a slave device.",
        "primary_area": "",
        "author": "Davide Nicolis;Fabio Allevi;Paolo Rocco;Davide Nicolis;Fabio Allevi;Paolo Rocco",
        "authorids": "/37086169595;/37087323881;/37274178600;/37086169595;/37087323881;/37274178600",
        "aff": "Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968045/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8637628154566191607&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967726",
        "title": "Robust Loop Closure Detection based on Bag of SuperPoints and Graph Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection (LCD) is a crucial technique for robots, which can correct accumulated localization errors after long time explorations. In this paper, we propose a robust LCD algorithm based on Bag of SuperPoints and graph verification. The system first extracts interest points and feature descriptors using the SuperPoint neural network. Then a visual vocabulary is trained in an incremental and self-supervised manner considering the relations between consecutive training images. Finally, a topological graph is constructed using matched feature points to verify candidate loop closures obtained by a Bag-of-Words (BoW) framework. Comparative experiments with state-of-the-art LCD algorithms on several typical datasets have been carried out. The results demonstrate that our proposed graph verification method can significantly improve the accuracy of image matching and the overall LCD approach outperforms existing methods.",
        "primary_area": "",
        "author": "Haosong Yue;Jinyu Miao;Yue Yu;Weihai Chen;Changyun Wen;Haosong Yue;Jinyu Miao;Yue Yu;Weihai Chen;Changyun Wen",
        "authorids": "/37851695500;/37087325080;/37086142901;/37279188000;/37280264000;/37851695500;/37087325080;/37086142901;/37279188000;/37280264000",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, China; School of Automation Science and Electrical Engineering, Beihang University, China; School of Automation Science and Electrical Engineering, Beihang University, China; School of Automation Science and Electrical Engineering, Beihang University, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967726/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8167505887430018753&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Beihang University;Nanyang Technological University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering;School of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "Beihang;NTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "8967585",
        "title": "Robust Non-Rigid Point Set Registration Algorithm Considering Anisotropic Uncertainties Based on Coherent Point Drift",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-rigid point set registration (PSR) is an outstanding and fundamental problem in fields of robotics, computer vision, medical image analysis and imageguided surgery. The aim of a non-rigid registration problem is to align together two point sets that have been deformed. We have derived and presented a novel registration algorithm that non-rigidly registers two point sets together. The assumption of isotropic localization error is shared in the previous non-rigid registration algorithms. In this paper, the position localization error is generalized to the anisotropic cases, which means that the error distribution is not the same in different spatial directions. The motivation of considering the anisotropic characteristic is that the point localization error is actually different in three spatial directions in real applications. Mathematically, the difficulty in dealing with the anisotropic error case comes from the change from a standard deviation that is a scalar to a covariance matrix. The formulas for updating the parameters in both expectation and maximization steps are derived. In the expectation step, we compute the posterior probabilities that represent the correspondences between points in two PSs. In the maximization step, given the current posteriors, the covariance matrix of the position localization error and the non-rigid transformation are updated. To facilitate the proposed algorithm, the low-rank approximation variation of our method is also presented. We have demonstrated through experiments that the proposed algorithm outperforms the state-of-the-art ones in terms of registration and accuracy and robustness to noise. More specifically, most of the experimental results have passed the statistical tests at the 5% significance level.",
        "primary_area": "",
        "author": "Zhe Min;Jin Pan;Ang Zhang;Max Q.-H. Meng;Zhe Min;Jin Pan;Ang Zhang;Max Q.-H. Meng",
        "authorids": "/37086002886;/37087244420;/37087246928;/37274117000;/37086002886;/37087244420;/37087246928;/37274117000",
        "aff": "Robotics, Perception and Artificial Intelligence Lab, Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Robotics, Perception and Artificial Intelligence Lab, Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Robotics, Perception and Artificial Intelligence Lab, Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Robotics, Perception and Artificial Intelligence Lab, Chinese University of Hong Kong, N.T., Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967585/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8844803228293695261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Robotics, Perception and Artificial Intelligence Lab",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "N.T.",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967549",
        "title": "Robust Outdoor Self-localization In Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In outdoor scenarios changing conditions (e.g., seasonal, weather and lighting effects) have a substantial impact on the appearance of a scene, which often prevents successful visual localization. The application of an unsupervised Slow Feature Analysis (SFA) on the images captured by an autonomous robot enables self-localization from a single image. However, changes occurring during the training phase or over a more extended period can affect the learned representations. To address the problem, we propose to join long-term recordings from an outdoor environment based on their position correspondences. The established hierarchical model trained on raw images performs well, but as an extension, we extract Fourier components of the views and use that for learning of spatial representations, which reduces the computation time and makes it adequate to run on an ARM embedded system. We present the experimental results from a simulated environment and real-world outdoor recordings collected over a full year, which has effects like different day time, weather, seasons and dynamic objects. Results show an increasing invariance w.r.t. changing conditions over time, thus an outdoor robot can improve its localization performance during operation.",
        "primary_area": "",
        "author": "Muhammad Haris;Mathias Franzius;Ute Bauer-Wersing;Muhammad Haris;Mathias Franzius;Ute Bauer-Wersing",
        "authorids": "/37086511353;/37589849700;/37085643370;/37086511353;/37589849700;/37085643370",
        "aff": "Faculty of Computer Science and Engineering, Frankfurt University of Applied Sciences, Frankfurt, Germany; Research Institute Europe GmbH, Offenbach, Germany; Faculty of Computer Science and Engineering, Frankfurt University of Applied Sciences, Frankfurt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967549/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18057174798884215435&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Frankfurt University of Applied Sciences;Research Institute Europe GmbH",
        "aff_unique_dep": "Faculty of Computer Science and Engineering;",
        "aff_unique_url": "https://www.frankfurt-university.de;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Frankfurt;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968208",
        "title": "Robust Real-time RGB-D Visual Odometry in Dynamic Environments via Rigid Motion Model",
        "track": "main",
        "status": "Poster",
        "abstract": "In the paper, we propose a robust real-time visual odometry in dynamic environments via rigid-motion model updated by scene flow. The proposed algorithm consists of spatial motion segmentation and temporal motion tracking. The spatial segmentation first generates several motion hypotheses by using a grid-based scene flow and clusters the extracted motion hypotheses, separating objects that move independently of one another. Further, we use a dual-mode motion model to consistently distinguish between the static and dynamic parts in the temporal motion tracking stage. Finally, the proposed algorithm estimates the pose of a camera by taking advantage of the region classified as static parts. In order to evaluate the performance of visual odometry under the existence of dynamic rigid objects, we use self-collected dataset containing RGB-D images and motion capture data for ground-truth. We compare our algorithm with state-of-the-art visual odometry algorithms. The validation results suggest that the proposed algorithm can estimate the pose of a camera robustly and accurately in dynamic environments.",
        "primary_area": "",
        "author": "Sangil Lee;Clark Youngdong Son;H. Jin Kim;Sangil Lee;Clark Youngdong Son;H. Jin Kim",
        "authorids": "/37085698774;/37086100767;/37599626400;/37085698774;/37086100767;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea; Department of Mechanical and Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea; Department of Mechanical and Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968208/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10196422202878087115&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968126",
        "title": "Robust Trajectory Planning for a Multirotor against Disturbance based on Hamilton-Jacobi Reachability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Ensuring safety in trajectory planning of multirotor systems is an essential element for risk-free operation. Even if the generated trajectory is known to be safe in the planning phase, unknown disturbance during an actual operation can lead to a dangerous situation. This paper proposes safety-guaranteed receding horizon planning against unknown, but bounded, disturbances. We first characterize forward reachable set (FRS) of the system, the set of states after a certain duration considering all possible disturbances, using Hamilton-Jacobi (HJ) reachability analysis. To compute the FRSs in real-time, we conservatively approximate the true FRS and perform ellipsoidal parameterization on the FRSs. Using the FRSs, we can plan a robust trajectory that avoids risky regions and rapidly re-plan the trajectory when the system encounters sudden disturbance. The proposed method is validated through an experiment of avoiding obstacles in a wind.",
        "primary_area": "",
        "author": "Hoseong Seo;Donggun Lee;Clark Youngdong Son;Claire J. Tomlin;H. Jin Kim;Hoseong Seo;Donggun Lee;Clark Youngdong Son;Claire J. Tomlin;H. Jin Kim",
        "authorids": "/37085446499;/37086933984;/37086100767;/37271692600;/37599626400;/37085446499;/37086933984;/37086100767;/37271692600;/37599626400",
        "aff": ">Automation and Systems Research Institute and Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USA; Institute of Engineering Research and Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968126/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13368248167741153874&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Seoul National University;University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.berkeley.edu",
        "aff_unique_abbr": "SNU;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Seoul;Berkeley",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "8967894",
        "title": "Robust UAV Position and Attitude Estimation using Multiple GNSS Receivers for Laser-based 3D Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Small-sized unmanned aerial vehicles (UAVs) have been widely investigated for use in a variety of applications such as remote sensing and aerial surveying. Direct three-dimensional (3D) mapping using a small-sized UAV equipped with a laser scanner is required for numerous remote sensing applications. In direct 3D mapping, the precise information about the position and attitude of the UAV is necessary for constructing 3D maps. In this study, we propose a novel and robust technique for estimating the position and attitude of small-sized UAVs by employing multiple low-cost and light-weight global navigation satellite system (GNSS) antennas/receivers. Using the \u201credundancy'' of multiple GNSS receivers, we enhance the performance of real-time kinematic (RTK)-GNSS by employing single-frequency GNSS receivers. This method consists of two approaches: hybrid GNSS fix solutions and consistency examination of the GNSS signal strength. The fix rate of RTK-GNSS using single-frequency GNSS receivers can be highly enhanced to combine multiple RTK-GNSS to fix solutions in the multiple antennas. In addition, positioning accuracy and fix rate can be further enhanced to detect multipath signals by using multiple GNSS antennas. In this study, we developed a prototype UAV that is equipped with six GNSS antennas /receivers. From the static test results, we conclude that the proposed technique can enhance the accuracy of the position and attitude estimation in multipath environments. From the flight test, the proposed system could generate a 3D map with an accuracy of 5 cm.",
        "primary_area": "",
        "author": "Taro Suzuki;Daichi Inoue;Yoshiharu Amano;Taro Suzuki;Daichi Inoue;Yoshiharu Amano",
        "authorids": "/37087323760;/37087324733;/37549683800;/37087323760;/37087324733;/37549683800",
        "aff": "Future Robotics Technology Center, Chiba Institute of Technology, Japan; Waseda University, Japan; Waseda University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967894/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17043893619218754445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Chiba Institute of Technology;Waseda University",
        "aff_unique_dep": "Future Robotics Technology Center;",
        "aff_unique_url": "https://www.chibatech.ac.jp;https://www.waseda.jp/top",
        "aff_unique_abbr": ";Waseda",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968048",
        "title": "Robust and Efficient Vehicles Motion Estimation with Low-Cost Multi-Camera and Odometer-Gyroscope",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a robust and efficient estimation approach with multi-camera, odometer and gyroscope. Robust initialization, tightly-coupled optimization estimator and multi-camera loop-closure detection are utilized in the proposed approach. In initialization, the measurements of odometer and gyroscope are used to compute scale, and then estimate the bias of sensors. In estimator, the pre-integration of odometer and gyroscope is derived and combined with the measurements of multi-camera to estimate the motion in a tightly-coupled optimization framework. In loop-closure detection, a connection between different cameras of the vehicle can be built, which significantly improve the success rate of loop-closure detection. The proposed algorithm is validated in multiple real-world datasets collected in different places, time, weather and illumination. Experimental results show that the proposed approach can estimate the motion of vehicles robustly and efficiently.",
        "primary_area": "",
        "author": "Wenlong Ye;Renjie Zheng;Fangqiang Zhang;Zizhou Ouyang;Yong Liu;Wenlong Ye;Renjie Zheng;Fangqiang Zhang;Zizhou Ouyang;Yong Liu",
        "authorids": "/37086914589;/37087323824;/37087324663;/37087324180;/37066946100;/37086914589;/37087323824;/37087324663;/37087324180;/37066946100",
        "aff": "Institute of Cyber-Systems and Control Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control Zhejiang University, Zhejiang, China; SAIC Motor Corporation Limited, Shanghai, China; SAIC Motor Corporation Limited, Shanghai, China; Institute of Cyber-Systems and Control Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968048/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9613280907511817451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Zhejiang University;SAIC Motor Corporation Limited",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.saicmotor.com",
        "aff_unique_abbr": "ZJU;SAIC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zhejiang;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967955",
        "title": "Robust, Compliant Assembly with Elastic Parts and Model Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an approach to generate robot motions for robust parts assembly. The computation of motions for parts assembly usually requires an exact model of all relevant objects. Generating detailed object models, including friction and dynamics, is often complex and time-consuming, especially in the context of elastic parts. In addition, executing motions on real hardware will usually introduce further uncertainty. For this reason, we propose an approach that is inherently robust against model parameter uncertainties and unknown characteristics of elastic parts. Our planner explicitly takes into account the internal states of articulated objects, as well as uncertain model parameters, by constructing a search tree in the belief-parameter-space. It yields successful assembly motions from coarse object models and thus eliminates the need for detailed parameter tuning. We evaluated our approach with respect to four assembly tasks. Extensive simulations show that our planner significantly increases the success-rate compared to previous approaches. Numerous experiments on a real robot confirm the simulated results.",
        "primary_area": "",
        "author": "Florian Wirnshofer;Philipp S. Schmitt;Philine Meister;Georg v. Wichert;Wolfram Burgard;Florian Wirnshofer;Philipp S. Schmitt;Philine Meister;Georg v. Wichert;Wolfram Burgard",
        "authorids": "/37085450321;/37086094898;/37086937503;/37330987000;/37270485300;/37085450321;/37086094898;/37086937503;/37330987000;/37270485300",
        "aff": "Siemens Corporate Technology, Otto-Hahn-Ring 6, Munich, Germany; Siemens Corporate Technology, Otto-Hahn-Ring 6, Munich, Germany; Siemens Corporate Technology, Otto-Hahn-Ring 6, Munich, Germany; Siemens Corporate Technology, Otto-Hahn-Ring 6, Munich, Germany; Dep. of Computer Science, University of Freiburg, Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967955/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1585580104396224399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Siemens AG;University of Freiburg",
        "aff_unique_dep": "Corporate Technology;Department of Computer Science",
        "aff_unique_url": "https://www.siemens.com;https://www.uni-freiburg.de",
        "aff_unique_abbr": "Siemens;Uni Freiburg",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Munich;Freiburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968539",
        "title": "Rolling-Shutter Modelling for Direct Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a direct visual-inertial odometry (VIO) method which estimates the motion of the sensor setup and sparse 3D geometry of the environment based on measurements from a rolling-shutter camera and an inertial measurement unit (IMU). The visual part of the system performs a photometric bundle adjustment on a sparse set of points. This direct approach does not extract feature points and is able to track not only corners, but any pixels with sufficient gradient magnitude. Neglecting rolling-shutter effects in the visual part severely degrades accuracy and robustness of the system. In this paper, we incorporate a rolling-shutter model into the photometric bundle adjustment that estimates a set of recent keyframe poses and the inverse depth of a sparse set of points. IMU information is accumulated between several frames using measurement preintegration, and is inserted into the optimization as an additional constraint between selected keyframes. For every keyframe we estimate not only the pose but also velocity and biases to correct the IMU measurements. Unlike systems with global-shutter cameras, we use both IMU measurements and rolling-shutter effects of the camera to estimate velocity and biases for every state. Last, we evaluate our system on a new dataset that contains global-shutter and rolling-shutter images, IMU data and ground-truth poses for ten different sequences, which we make publicly available. Evaluation shows that the proposed method outperforms a system where rolling shutter is not modelled and achieves similar accuracy to the global-shutter method on global-shutter data.",
        "primary_area": "",
        "author": "David Schubert;Nikolaus Demmel;Lukas von Stumberg;Vladyslav Usenko;Daniel Cremers;David Schubert;Nikolaus Demmel;Lukas von Stumberg;Vladyslav Usenko;Daniel Cremers",
        "authorids": "/37085793073;/37595100200;/37087321837;/37085511551;/37282875300;/37085793073;/37595100200;/37087321837;/37085511551;/37282875300",
        "aff": "Computer Vision Group, Technical University of Munich, Germany; Computer Vision Group, Technical University of Munich, Germany; Computer Vision Group, Technical University of Munich, Germany; Computer Vision Group, Technical University of Munich, Germany; Computer Vision Group, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968539/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18431152300459718567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Computer Vision Group",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967723",
        "title": "Routing a Fleet of Automated Vehicles in a Capacitated Transportation Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Routing of a fleet of automated unit-occupancy vehicles in a capacitated transportation network is an emerging problem that needs to be addressed to realize large-scale automated transportation systems. We adopt an existing network-flow-based model for the problem and present a new reformulation based on Dantzig-Wolfe decomposition. This reformulation allows us to apply the column generation solution technique which, in turn, enables us to solve large-scale problem instances with tens of thousands of requests on networks with thousands of links. We empirically compare our method to the state-of-the-art approach on several standard benchmark instances and find that the computational time of our solution approach scales qualitatively better in all tested problem instance parameters: namely, in the size of the transportation network, in the magnitude of demand intensity, and in the number of demand flows.",
        "primary_area": "",
        "author": "Martin Schaefer;Michal \u010c\u00e1p;Jan Mrkos;Ji\u0159\u00ed Vok\u0159\u00ednek;Martin Schaefer;Michal \u010c\u00e1p;Jan Mrkos;Ji\u0159\u00ed Vok\u0159\u00ednek",
        "authorids": "/37087323284;/37705371300;/37087323619;/37331059100;/37087323284;/37705371300;/37087323619;/37331059100",
        "aff": "Computer Science Department, Czech Technical University in Prague; Computer Science Department, Czech Technical University in Prague; Computer Science Department, Czech Technical University in Prague; Computer Science Department, Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967723/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18329612169384499698&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8968492",
        "title": "SIMDop: SIMD optimized Bounding Volume Hierarchies for Collision Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel data structure for SIMD optimized simultaneous bounding volume hierarchy (BVH) traversals like they appear for instance in collision detection tasks. In contrast to all previous approaches, we consider both the traversal algorithm and the construction of the BVH. The main idea is to increase the branching factor of the BVH according to the available SIMD registers and parallelize the simultaneous BVH traversal using SIMD operations. This requires a novel BVH construction method because traditional BVHs for collision detection usually are simple binary trees. To do that, we present a new BVH construction method based on a clustering algorithm, Batch Neural Gas, that is able to build efficient n-ary tree structures along with SIMD optimized simultaneous BVH traversal. Our results show that our new data structure outperforms binary trees significantly.",
        "primary_area": "",
        "author": "Toni Tan;Ren\u00e9 Weller;Gabriel Zachmann;Toni Tan;Ren\u00e9 Weller;Gabriel Zachmann",
        "authorids": "/37087322492;/37846882500;/37267417400;/37087322492;/37846882500;/37267417400",
        "aff": "University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968492/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6040736882029852749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "Uni Bremen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967703",
        "title": "SVIn2: An Underwater SLAM System using Sonar, Visual, Inertial, and Depth Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel tightly-coupled keyframe-based Simultaneous Localization and Mapping (SLAM) system with loop-closing and relocalization capabilities targeted for the underwater domain.Our previous work, SVIn, augmented the state-of-the-art visual-inertial state estimation package OKVIS to accommodate acoustic data from sonar in a non-linear optimization-based framework. This paper addresses drift and loss of localization - one of the main problems affecting other packages in underwater domain - by providing the following main contributions: a robust initialization method to refine scale using depth measurements, a fast preprocessing step to enhance the image quality, and a real-time loop-closing and relocalization method using bag of words (BoW). An additional contribution is the addition of depth measurements from a pressure sensor to the tightly-coupled optimization formulation. Experimental results on datasets collected with a custom-made underwater sensor suite and an autonomous underwater vehicle from challenging underwater environments with poor visibility demonstrate performance never achieved before in terms of accuracy and robustness.",
        "primary_area": "",
        "author": "Sharmin Rahman;Alberto Quattrini Li;Ioannis Rekleitis;Sharmin Rahman;Alberto Quattrini Li;Ioannis Rekleitis",
        "authorids": "/37085989996;/37085808885;/37281356300;/37085989996;/37085808885;/37281356300",
        "aff": "Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967703/",
        "gs_citation": 133,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15300424707613690643&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of South Carolina;Dartmouth College",
        "aff_unique_dep": "Computer Science and Engineering Department;Department of Computer Science",
        "aff_unique_url": "https://www.sc.edu;https://www.dartmouth.edu",
        "aff_unique_abbr": "USC;Dartmouth",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Columbia;Hanover",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967744",
        "title": "Safe Path Planning with Gaussian Process Regulated Risk Map",
        "track": "main",
        "status": "Poster",
        "abstract": "Government data identifies driver behaviour errors as a factor in 94% of car crashes, and autonomous vehicles (AVs), which avoids risky driver behaviours completely, are expected to reduce the number of road crashes significantly. Thus, one of the central focuses of developing AVs is to ensure safety during navigation. However, in reality, AV safety has been far below its expectation, and so far, no government has allowed for complete autonomous driving without human supervision. This paper proposes a dynamic safe path planning algorithm for AVs with Gaussian process regulated risk map. By reasonably assuming that the output of the object detection and tracking module follows a multi-variate Gaussian distribution, we put forward a safe path planning paradigm with Gaussian process regulated risk map, ensuring safety with high confidence. Both simulation results and in-vehicle tests demonstrate the effectiveness of the proposed algorithm.",
        "primary_area": "",
        "author": "Hongliang Guo;Zehui Meng;Zefan Huang;Leong Wei Kang;Ziyue Chen;Malika Meghjani;Marcelo Ang;Daniela Rus;Hongliang Guo;Zehui Meng;Zefan Huang;Leong Wei Kang;Ziyue Chen;Malika Meghjani;Marcelo Ang;Daniela Rus",
        "authorids": "/37085490043;/37085887226;/37087323099;/37087321870;/37086081623;/37393934900;/37279138700;/37279652300;/37085490043;/37085887226;/37087323099;/37087321870;/37086081623;/37393934900;/37279138700;/37279652300",
        "aff": "Singapore MIT Alliance for Research and Technology, Singapore; Singapore MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Singapore MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Singapore MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967744/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12564850791902026746&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;1;0;1;2",
        "aff_unique_norm": "Singapore MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;Computer Science & Artificial Intelligence Laboratory",
        "aff_unique_url": ";https://www.nus.edu.sg;https://web.mit.edu",
        "aff_unique_abbr": ";NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8968463",
        "title": "Safe physical HRI: Toward a unified treatment of speed and separation monitoring together with power and force limiting",
        "track": "main",
        "status": "Poster",
        "abstract": "So-called collaborative robots are a current trend in industrial robotics. However, they still face many problems in practical application such as reduced speed to ascertain their collaborativeness. The standards prescribe two regimes: (i) speed and separation monitoring and (ii) power and force limiting, where the former requires reliable estimation of distances between the robot and human body parts and the latter imposes constraints on the energy absorbed during collisions prior to robot stopping. Following the standards, we deploy the two collaborative regimes in a single application and study the performance in a mock collaborative task under the individual regimes, including transitions between them. Additionally, we compare the performance under \u201csafety zone monitoring\u201d with keypoint pair-wise separation distance assessment relying on an RGB-D sensor and skeleton extraction algorithm to track human body parts in the workspace. Best performance has been achieved in the following setting: robot operates at full speed until a distance threshold between any robot and human body part is crossed; then, reduced robot speed per power and force limiting is triggered. Robot is halted only when the operator's head crosses a predefined distance from selected robot parts. We demonstrate our methodology on a setup combining a KUICA LBR iiwa robot, Intel RealSense RGB-D sensor and OpenPose for human pose estimation.",
        "primary_area": "",
        "author": "Petr Svarny;Michael Tesar;Jan Kristof Behrens;Matej Hoffmann;Petr Svarny;Michael Tesar;Jan Kristof Behrens;Matej Hoffmann",
        "authorids": "/37087322921;/37087324001;/37086828985;/37594773300;/37087322921;/37087324001;/37086828985;/37594773300",
        "aff": "Department of Cybernetics, Czech Technical University in Prague; Czech Institute of Informatics, Robotics, and Cybernetics of the Czech Technical University in Prague.; Czech Institute of Informatics, Robotics, and Cybernetics of the Czech Technical University in Prague.; Department of Cybernetics, Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968463/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5277169808886862562&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Czech Technical University in Prague;Czech Technical University",
        "aff_unique_dep": "Department of Cybernetics;Institute of Informatics, Robotics, and Cybernetics",
        "aff_unique_url": "https://www.cvut.cz;https://www.cvut.cz",
        "aff_unique_abbr": "CTU;CTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8967948",
        "title": "Sample Efficient Interactive End-to-End Deep Learning for Self-Driving Cars with Selective Multi-Class Safe Dataset Aggregation",
        "track": "main",
        "status": "Poster",
        "abstract": "The objective of this paper is to develop a sample efficient end-to-end deep learning method for self-driving cars, where we attempt to increase the value of the information extracted from samples, through careful analysis obtained from each call to expert driver's policy. End-to-end imitation learning is a popular method for computing self-driving car policies. The standard approach relies on collecting pairs of inputs (camera images) and outputs (steering angle, etc.) from an expert policy and fitting a deep neural network to this data to learn the driving policy. Although this approach had some successful demonstrations in the past, learning a good policy might require a lot of samples from the expert driver, which might be resource-consuming. In this work, we develop a novel framework based on the Safe Dataset Aggregation (safe DAgger) approach, where the current learned policy is automatically segmented into different trajectory classes, and the algorithm identifies trajectory segments/classes with the weak performance at each step. Once the trajectory segments with weak performance identified, the sampling algorithm focuses on calling the expert policy only on these segments, which improves the convergence rate. The presented simulation results show that the proposed approach can yield significantly better performance compared to the standard Safe DAgger algorithm while using the same amount of samples from the expert.",
        "primary_area": "",
        "author": "Yunus Bicer;Ali Alizadeh;Nazim Kemal Ure;Ahmetcan Erdogan;Orkun Kizilirmak;Yunus Bicer;Ali Alizadeh;Nazim Kemal Ure;Ahmetcan Erdogan;Orkun Kizilirmak",
        "authorids": "/37087104539;/37086960780;/38189666100;/37086876225;/37087324986;/37087104539;/37086960780;/38189666100;/37086876225;/37087324986",
        "aff": "Faculty of Aeronautics and Astronautics, Istanbul Technical University, Turkey; Faculty of Aeronautics and Astronautics, Istanbul Technical University, Turkey; Faculty of Aeronautics and Astronautics, Istanbul Technical University, Turkey; AVL Turkey, Istanbul, Turkey; AVL Turkey, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967948/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1882563825655208169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Istanbul Technical University;AVL Turkey",
        "aff_unique_dep": "Faculty of Aeronautics and Astronautics;",
        "aff_unique_url": "https://www.itu.edu.tr;",
        "aff_unique_abbr": "ITU;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Istanbul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "8967834",
        "title": "Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has proven to be a great success in allowing agents to learn complex tasks. However, its application to actual robots can be prohibitively expensive. Furthermore, the unpredictability of human behavior in human-robot interaction tasks can hinder convergence to a good policy. In this paper, we present an architecture that allows agents to learn models of stochastic environments and use them to accelerate learning. We descirbe how an environment model can be learned online and used to generate synthetic transitions, as well as how an agent can leverage these synthetic data to accelerate learning. We validate our approach using an experiment in which a robotic arm has to complete a task composed of a series of actions based on human gestures. Results show that our approach leads to significantly faster learning, requiring much less interaction with the environment. Furthermore, we demonstrate how learned models can be used by a robot to produce optimal plans in real world applications.",
        "primary_area": "",
        "author": "Mohammad Thabet;Massimiliano Patacchiola;Angelo Cangelosi;Mohammad Thabet;Massimiliano Patacchiola;Angelo Cangelosi",
        "authorids": "/37085963109;/37085817688;/37428592400;/37085963109;/37085817688;/37428592400",
        "aff": "School of Computer Science, University of Manchester, United Kingdom; School of Informatics, University of Edinbrugh, United Kingdom; School of Computer Science, University of Manchester, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967834/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13531545060384721578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Manchester;University of Edinburgh",
        "aff_unique_dep": "School of Computer Science;School of Informatics",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "UoM;Edinburgh",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Manchester;Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967922",
        "title": "Sampling-based Motion Planning for Aerial Pick-and-Place",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a motion planning approach for an aerial pick-and-place task where an aerial manipulator is supposed to pick up or place an object at locations specified as way-points. In particular, we focus on situations where such way-point constraints are imposed on certain partial state variables, rather than on full state variables. Our proposed framework, based on rapidly exploring random trees star (RRT*) in a bidirectional manner, enables an aerial manipulator to find an optimal trajectory that satisfies way-point constraints with only partial specifications. Here, we suggest an extra merging process to integrate the trees, each originated from the start and goal point. In the merging process, we search various candidate points satisfying a given condition that partially constrains state variables, and select a way-point with full specifications optimal in the perspective of the entire trajectory. Simulation and experiment results are included to validate the proposed framework.",
        "primary_area": "",
        "author": "Hyoin Kim;Hoseong Seo;Jongchan Kim;H. Jin Kim;Hyoin Kim;Hoseong Seo;Jongchan Kim;H. Jin Kim",
        "authorids": "/37085698471;/37085446499;/37600787300;/37599626400;/37085698471;/37085446499;/37600787300;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967922/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2287282120170712753&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968578",
        "title": "Sampling-based motion planning of 3D solid objects guided by multiple approximate solutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planners are often used to solve motion planning problems for robots with many degrees of freedom. These planners explore the related configuration space by random sampling. The well-known issue of the sampling-based planners is the narrow passage problem. Narrow passages are small collision-free regions in the configuration space that are, due to their volume, difficult to cover by the random samples. The volume of the narrow passages can be artificially increased by reducing the size of the robot, e.g., by scaling-down its geometry, which increases the probability of placing the random samples into the narrow passages. This allows us to find an approximate solution (trajectory) and use it as a guide to find the solution for a larger robot. Guiding along an approximate solution may, however, fail if this solution leads through such parts of the configuration space that are not reachable or traversable by a larger robot. To improve this guiding process, we propose to compute several approximate solutions leading through different parts of the configuration space, and use all of them to guide the search for a larger robot. We introduce the concept of disabled regions that are prohibited from the exploration using the sampling process. The disabled regions are defined using trajectories already found in the space being searched. The proposed method can solve planning problems with narrow passages with higher success rate than other state-of-the-art planners.",
        "primary_area": "",
        "author": "Vojt\u011bch Von\u00e1sek;Robert P\u011bni\u010dka;Vojt\u011bch Von\u00e1sek;Robert P\u011bni\u010dka",
        "authorids": "/37072261400;/37085674700;/37072261400;/37085674700",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague, Technick\u00e1 2, 166 27 Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Technick\u00e1 2, 166 27 Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968578/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6393634473034841818&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8967775",
        "title": "Scaffold-Based Asynchronous Distributed Self-Reconfiguration By Continuous Module Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed self-reconfiguration in large-scale modular robots is a slow process and increasing its speed a major challenge. In this article, we propose an improved and asynchronous version of a previously proposed distributed self-reconfiguration algorithm to build a parametric scaffolding structure. This scaffold can then be coated to form the desired final object. The scaffolding is built through a continuous feeding of modules into the growing shape from an underneath reserve of modules which shows a reconfiguration time improved by a factor of 3\u221aN compared to the previous and synchronous version of the algorithm, therefore attaining an O(N1/3) reconfiguration time, with N the number of modules in the system. Our algorithm uses a local motion coordination algorithm and pipelining techniques to ensure that modules can traverse the structure without collisions or creating deadlocks. Last but not least, our algorithm manages uncertainty in the motion duration of modules without negatively impacting reconfiguration time.",
        "primary_area": "",
        "author": "Pierre Thalamy;Beno\u00eet Piranda;Fr\u00e9d\u00e9ric Lassabe;Julien Bourgeois;Pierre Thalamy;Beno\u00eet Piranda;Fr\u00e9d\u00e9ric Lassabe;Julien Bourgeois",
        "authorids": "/37087324441;/38340189300;/37423013100;/37545876400;/37087324441;/38340189300;/37423013100;/37545876400",
        "aff": "Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, 1 cours Leprince-Ringuet, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, 1 cours Leprince-Ringuet, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, 1 cours Leprince-Ringuet, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, 1 cours Leprince-Ringuet, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967775/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6898534038857469434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "FEMTO-ST Institute",
        "aff_unique_url": "https://www.ubfc.fr",
        "aff_unique_abbr": "UBFC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montb\u00e9liard",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "8968114",
        "title": "Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity",
        "track": "main",
        "status": "Poster",
        "abstract": "Large, richly annotated datasets have accelerated progress in fields such as computer vision and natural language processing, but replicating these successes in robotics has been challenging. While prior data collection methodologies such as self-supervision have resulted in large datasets, the data can have poor signal-to-noise ratio. By contrast, previous efforts to collect task demonstrations with humans provide better quality data, but they cannot reach the same data magnitude. Furthermore, neither approach places guarantees on the diversity of the data collected, in terms of solution strategies. In this work, we leverage and extend the RoboTurk platform to scale up data collection for robotic manipulation using remote teleoperation. The primary motivation for our platform is two-fold: (1) to address the shortcomings of prior work and increase the total quantity of manipulation data collected through human supervision by an order of magnitude without sacrificing the quality of the data and (2) to collect data on challenging manipulation tasks across several operators and observe a diverse set of emergent behaviors and solutions. We collected over 111 hours of robot manipulation data across 54 users and 3 challenging manipulation tasks in 1 week, resulting in the largest robot dataset collected via remote teleoperation. We evaluate the quality of our platform, the diversity of demonstrations in our dataset, and the utility of our dataset via quantitative and qualitative analysis. For additional results, supplementary videos, and to download our dataset, visit http;//roboturk.stanford.edu/realrobotdataset.",
        "primary_area": "",
        "author": "Ajay Mandlekar;Jonathan Booher;Max Spero;Albert Tung;Anchit Gupta;Yuke Zhu;Animesh Garg;Silvio Savarese;Li Fei-Fei;Ajay Mandlekar;Jonathan Booher;Max Spero;Albert Tung;Anchit Gupta;Yuke Zhu;Animesh Garg;Silvio Savarese;Li Fei-Fei",
        "authorids": "/37086331393;/37087323001;/37087321992;/37087323479;/37087324501;/37086080772;/37086330576;/37298502600;/38273560700;/37086331393;/37087323001;/37087321992;/37087323479;/37087324501;/37086080772;/37086330576;/37298502600;/38273560700",
        "aff": "Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University; Nvidia, USA; Stanford AI Lab (SAIL), Stanford University; Stanford AI Lab (SAIL), Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968114/",
        "gs_citation": 105,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13193042806796165929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Stanford University;NVIDIA",
        "aff_unique_dep": "Stanford AI Lab (SAIL);NVIDIA Corporation",
        "aff_unique_url": "https://www.stanford.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Stanford;NVIDIA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968181",
        "title": "Scheduling of Mobile Workstations for Overlapping Production Time and Delivery Time",
        "track": "main",
        "status": "Poster",
        "abstract": "Many existing mobile service robots, including the robots in Robocup@Home, perform their designated tasks only when the robots are stationary. The efficiency of these robots can be improved if they can perform some tasks while moving. In this paper, we propose the concept of mobile workstations, which combine mobile platforms with production machinery to increase efficiency by overlapping production time and delivery time. We present a model of mobile workstations and their jobs and describe the task planning algorithm for a team of mobile workstations. The temporal planning problem for mobile workstations combines both features of job shop scheduling problems (JSP) and traveling salesman problem (TSP), but there is little work in the literature that tackles both JSP and TSP simultaneously. Our first algorithm is a complete search algorithm which returns an optimal temporal plan with minimum makespan, and our second algorithm conducts a local search in the space of task graphs so as to quickly return suboptimal temporal plans. According to our experiments, when the number of jobs is small, our second algorithm can generate near-optimal temporal plans, and when the number of jobs is large, our algorithm can generate much shorter plans than SGPlan 5 and a version of job shop scheduling algorithms.",
        "primary_area": "",
        "author": "Dohee Lee;Tsz-Chiu Au;Dohee Lee;Tsz-Chiu Au",
        "authorids": "/37088998317;/37597553100;/37088998317;/37597553100",
        "aff": "School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea; School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968181/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:GTa1XBkav3oJ:scholar.google.com/&scioq=Scheduling+of+Mobile+Workstations+for+Overlapping+Production+Time+and+Delivery+Time&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ulsan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967582",
        "title": "Seeing Behind Things: Extending Semantic Segmentation to Occluded Regions",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation and instance level segmentation made substantial progress in recent years due to the emergence of deep neural networks (DNNs). A number of deep architectures with Convolution Neural Networks (CNNs) were proposed that surpass the traditional machine learning approaches for segmentation by a large margin. These architectures predict the directly observable semantic category of each pixel by usually optimizing a cross-entropy loss. In this work we push the limit of semantic segmentation towards predicting semantic labels of directly visible as well as occluded objects or objects parts, where the network's input is a single depth image. We group the semantic categories into one background and multiple foreground object groups, and we propose a modification of the standard cross-entropy loss to cope with the settings. In our experiments we demonstrate that a CNN trained by minimizing the proposed loss is able to predict semantic categories for visible and occluded object parts without requiring to increase the network size (compared to a standard segmentation task). The results are validated on a newly generated dataset (augmented from SUNCG) dataset.",
        "primary_area": "",
        "author": "Pulak Purkait;Christopher Zach;Ian Reid;Pulak Purkait;Christopher Zach;Ian Reid",
        "authorids": "/38003985600;/37298496900;/37282640200;/38003985600;/37298496900;/37282640200",
        "aff": "The University of Adelaide, Australia; Chalmers University of Technology, Sweden; The University of Adelaide, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967582/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5054457550935032352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Adelaide;Chalmers University of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.adelaide.edu.au;https://www.chalmers.se",
        "aff_unique_abbr": "Adelaide;Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;Sweden"
    },
    {
        "id": "8967829",
        "title": "Seeing Beyond Appearance - Mapping Real Images into Geometrical Domains for Unsupervised CAD-based Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "While convolutional neural networks are dominating the field of computer vision, one usually does not have access to the large amount of domain-relevant data needed for their training. Therefore, it has become common practice to use available synthetic samples along domain adaptation schemes to prepare algorithms for the target domain. Tackling this problem from a different angle, we introduce a pipeline to map unseen target samples into the synthetic domain used to train task-specific methods. Denoising the data and retaining only the features these recognition algorithms are familiar with, our solution greatly improves their performance. As this mapping is easier to learn than the opposite one (i.e., to generate realistic features to augment the source samples), we demonstrate how our whole solution can be trained purely on augmented synthetic data and still performs better than methods trained with domain-relevant information (e.g., real images or realistic textures for the 3D models). Applying our approach to object recognition from texture-less CAD data, we present a custom generative network which fully utilizes the purely geometrical information to learn robust features and to achieve a more refined mapping for unseen color images.",
        "primary_area": "",
        "author": "Benjamin Planche;Sergey Zakharov;Ziyan Wu;Andreas Hutter;Harald Kosch;Slobodan Ilic;Benjamin Planche;Sergey Zakharov;Ziyan Wu;Andreas Hutter;Harald Kosch;Slobodan Ilic",
        "authorids": "/37086303940;/37086299755;/37962338100;/37273869400;/37283801100;/37266931500;/37086303940;/37086299755;/37962338100;/37273869400;/37283801100;/37266931500",
        "aff": "Siemens Corporate Technology; Siemens Corporate Technology; Siemens Corporate Technology; Siemens Corporate Technology; University of Passau; Siemens Corporate Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967829/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1816910141014341370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Siemens AG;University of Passau",
        "aff_unique_dep": "Corporate Technology;",
        "aff_unique_url": "https://www.siemens.com;https://www.uni-passau.de",
        "aff_unique_abbr": "Siemens;UP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968527",
        "title": "Seeking the Analytical Approximation of the Stance Dynamics of the 3D Spring-Loaded Inverted Pendulum Model By Using Perturbation Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "The Spring-Loaded Inverted Pendulum (SLIP) has been widely exploited in both biomechanical and robotics research due to its simple form in mathematics and high accuracy in fitting experimental biology data. However the intrinsic nonlinearity of the SLIP dynamics makes accurate analytical representation unavailable. Traditional methods take advantage of numerical integration to handle this issue while several existing analytical approximations focusing on 2D-SLIP model. The 3D-SLIP suitable to physical reality is rarely investigated. This paper presents a novel perturbation-based approach to obtain the closed-form analytical approximations of the 3D-SLIP model in stance phase. In contrast to existing work ignoring the gravitational forces, the proposed approach just relies on assumptions of small leg compression and small leg swept angle. The performance of the derived approximations has been evaluated via comprehensive numerical analysis. The quality of accurate apex prediction promises the approximation as an advantageous and reliable tool for locomotion control of legged robots.",
        "primary_area": "",
        "author": "Haitao Yu;Shengjun Wang;Kaizheng Shan;Jun Li;Lixian Zhang;Haibo Gao;Haitao Yu;Shengjun Wang;Kaizheng Shan;Jun Li;Lixian Zhang;Haibo Gao",
        "authorids": "/37593335400;/37087012734;/37086430507;/37087324248;/37406065300;/37535800300;/37593335400;/37087012734;/37086430507;/37087324248;/37406065300;/37535800300",
        "aff": "State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968527/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10381877368127316223&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and Systems",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968607",
        "title": "Segregation and Flow of Modules in a Robot Swarm Utilising the Brazil Nut Effect",
        "track": "main",
        "status": "Poster",
        "abstract": "A lot of research has been conducted on swarm and modular robots and their reconfiguration. For this kind of robot system, it is best to simplify each individual module in order to avoid making the swarm system too complex in the interest of reducing the computing power necessary for a task.This paper proposes a swarm robot system capable of self-segregation by changing the size of each agent, utilising the Brazil Nut Effect. The self-segregation allowed by this effect lead to the simplification of the control protocol necessary for the swarm.We simulated a swarm robot system consisting of circular modules capable of changing their radius and, with the aid of externally supplied vibrations, utilising the Brazil Nut Effect to achieve segregation of the swarm. The effect also allowed for the migration of individual modules through the swarm. Additionally, we harnessed this segregation effect in simulation to create a flow of modules within the swarm, whilst the swarm was confined within a vibrating container.Lastly, we took the first steps toward physical verification of the experimental results by designing and building a prototype for a circular robot module capable of changing its radius in a manner inspired by a spiral torsion spring.",
        "primary_area": "",
        "author": "Devwrat Joshi;Masahiro Shimizu;Koh Hosoda;Devwrat Joshi;Masahiro Shimizu;Koh Hosoda",
        "authorids": "/37089406072;/38541662800;/37270101900;/37089406072;/38541662800;/37270101900",
        "aff": "School of Engineering Science, System Science faculty, Osaka University, Japan; Hosoda Laboratory, affiliated with the School of Engineering Science, System Science faculty, Osaka University, Japan; Hosoda Laboratory, affiliated with the School of Engineering Science, System Science faculty, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968607/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16376079048000570491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "School of Engineering Science, System Science faculty",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967951",
        "title": "Self-Organized Adaptive Paths in Multi-Robot Manufacturing: Reconfigurable and Pattern-Independent Fibre Deployment",
        "track": "main",
        "status": "Poster",
        "abstract": "Using multi-robot systems for autonomous construction allows for parallelization and scalability. Swarm construction furthermore exploits robot interactions and collaboration, such that the robot swarm collectively constructs artifacts beyond what a single comparable robot could achieve. Here we present an alternative concept of swarm construction that is distinct because it uses continuous building material. Our approach is unique in its use of braiding techniques for construction. We deploy fibres that potentially allow for structures that are not possible with building blocks. To achieve maximal scalability we restrict ourselves to a decentralized approach. The main challenges are the local coordination of the robot teams, self-organized task allocation, and the dynamic reconfiguration of the braiding scheme at runtime. We successfully validate our approach in multi-robot experiments that show both braiding and branching of the braid. In addition, we show options for implementing an open system-that is robots can join and leave the braiding process on the fly.",
        "primary_area": "",
        "author": "Catriona Eschke;Mary Katherine Heinrich;Mostafa Wahby;Heiko Haman;Catriona Eschke;Mary Katherine Heinrich;Mostafa Wahby;Heiko Haman",
        "authorids": "/37087324334;/37085995806;/37085672835;/37087325237;/37087324334;/37085995806;/37085672835;/37087325237",
        "aff": "Eschke is currently with the Division Metallic Biomaterials, Institute of Materials Research, Helmholtz-Zentrum Geesthacht, Geesthacht, Germany; Institute of Computer Engineering, University of Lubeck, Lubeck, Germany; Institute of Computer Engineering, University of Lubeck, Lubeck, Germany; Institute of Computer Engineering, University of Lubeck, Lubeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967951/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1590698565756732356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Helmholtz-Zentrum Geesthacht;University of Lubeck",
        "aff_unique_dep": "Division Metallic Biomaterials, Institute of Materials Research;Institute of Computer Engineering",
        "aff_unique_url": "https://www.hzg.de;https://www.uni-luebeck.de",
        "aff_unique_abbr": "HZG;",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Geesthacht;Lubeck",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968210",
        "title": "Self-modeling Tracking Control of Crawler Fire Fighting Robot Based on Causal Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a self-modeling method based on a causal network is proposed for the tracking control of the Crawler Fire Fighting Robot (CFFR). The method mainly consists of two parts, one is a motion model, based on data driving, learning to establish the correspondence between control signal sequence and vehicle motion, estimating the motion state of the next moment from historical data, eliminating complex CFFR modeling. The other is the tracking network. Based on the simulation data of the motion model, the relationship between the target trajectory and the current control command is learned, which simplifies the design and cumbersome tuning of the complex controller. The effectiveness of the proposed method is verified in both simulated and real-world environments. Qualitative and quantitative experimental results verify the accuracy of the tracking.",
        "primary_area": "",
        "author": "Wenkai Chang;Peng Li;Caiyun Yang;Tao Lu;Yinghao Cai;Shuo Wang;Wenkai Chang;Peng Li;Caiyun Yang;Tao Lu;Yinghao Cai;Shuo Wang",
        "authorids": "/37085869505;/37087324649;/37087321931;/37855750400;/37654083400;/37280458600;/37085869505;/37087324649;/37087321931;/37855750400;/37654083400;/37280458600",
        "aff": "State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968210/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:98esNiQoXCMJ:scholar.google.com/&scioq=Self-modeling+Tracking+Control+of+Crawler+Fire+Fighting+Robot+Based+on+Causal+Network&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation",
        "aff_unique_url": "http://www.ia.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967916",
        "title": "Self-supervised 3D Shape and Viewpoint Estimation from Single Images for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a convolutional neural network for joint 3D shape prediction and viewpoint estimation from a single input image. During training, our network gets the learning signal from a silhouette of an object in the input image-a form of self-supervision. It does not require ground truth data for 3D shapes and the viewpoints. Because it relies on such a weak form of supervision, our approach can easily be applied to real-world data. We demonstrate that our method produces reasonable qualitative and quantitative results on natural images for both shape estimation and viewpoint prediction. Unlike previous approaches, our method does not require multiple views of the same object instance in the dataset, which significantly expands the applicability in practical robotics scenarios. We showcase it by using the hallucinated shapes to improve the performance on the task of grasping real-world objects both in simulation and with a PR2 robot.",
        "primary_area": "",
        "author": "Oier Mees;Maxim Tatarchenko;Thomas Brox;Wolfram Burgard;Oier Mees;Maxim Tatarchenko;Thomas Brox;Wolfram Burgard",
        "authorids": "/37086205346;/37085535160;/37541664500;/37270485300;/37086205346;/37085535160;/37541664500;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967916/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7956786933263686891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "UoF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967915",
        "title": "Self-supervised Transfer Learning for Instance Segmentation through Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance segmentation of unknown objects from images is regarded as relevant for several robot skills including grasping, tracking and object sorting. Recent results from computer vision have shown that large hand-labeled datasets enable high segmentation performance. To overcome the time-consuming process of manually labeling data for new environments, we present a transfer learning approach for robots that learn to segment objects by interacting with their environment in a self-supervised manner. Our robot pushes unknown objects on a table and uses information from optical flow to create training labels given by object masks. To achieve this, we fine-tune an existing DeepMask instance segmentation network on the self-labeled training data acquired by the robot. We evaluate our trained network (SelfDeepMask) on a set of real images showing challenging and cluttered scenes with novel objects. Here, SelfDeepMask outperforms the DeepMask network trained on the COCO dataset by 8.6% in average precision.",
        "primary_area": "",
        "author": "Andreas Eitel;Nico Hauff;Wolfram Burgard;Andreas Eitel;Nico Hauff;Wolfram Burgard",
        "authorids": "/37085450155;/37087325266;/37270485300;/37085450155;/37087325266;/37270485300",
        "aff": "Autonomous Intelligent Systems, University of Freiburg, Germany; Autonomous Intelligent Systems, University of Freiburg, Germany; Autonomous Intelligent Systems, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967915/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8222997933480335848&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "Autonomous Intelligent Systems",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968041",
        "title": "Semantic Mates: Intuitive Geometric Constraints for Efficient Assembly Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we enhance our knowledge-based and constraint-based approach of robot programming with the concept of Semantic Mates. They describe intended mechanical connections between parts of an assembly. This allows deriving appropriate assembly poses from the type of connection and the geometric properties of the involved parts. The paper presents an ontology-based representation of Semantic Mates that is used to augment object models with additional information regarding their potential use in an assembly. Such semantically annotated object models can be used in our instruction framework to program a robot to perform assembly tasks through simple drag-and-drop operations in a graphical user interface. We conducted a user study with 21 participants in order to evaluate the efficiency and usability of the Semantic Mates concept based on a use-case from the domain of mechanical assembly. Across different experience levels in robotics, the participants achieved a significantly faster workflow and improved perceived usability compared to the manual specification of constraint-based assembly operations.",
        "primary_area": "",
        "author": "Fabian Wildgrube;Alexander Perzylo;Markus Rickert;Alois Knoll;Fabian Wildgrube;Alexander Perzylo;Markus Rickert;Alois Knoll",
        "authorids": "/37087322336;/38016028000;/37681876600;/37276234100;/37087322336;/38016028000;/37681876600;/37276234100",
        "aff": "fortiss, An-Institut Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; fortiss, An-Institut Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; fortiss, An-Institut Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Technische Universit\u00e4t M\u00fcnchen, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968041/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4490112657663978145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "fortiss, An-Institut",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968140",
        "title": "Semantically Assisted Loop Closure in SLAM Using NDT Histograms",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise knowledge of pose is of great importance for reliable operation of mobile robots in outdoor environments. Simultaneous localization and mapping (SLAM) is the online construction of a map during exploration of an environment. One of the components of SLAM is loop closure detection, identifying that the same location has been visited and is present on the existing map, and localizing against it. We have shown in previous work that using semantics from a deep segmentation network in conjunction with the Normal Distributions Transform (NDT) point cloud registration improves the robustness, speed and accuracy of lidar odometry. In this work we extend the method for loop closure detection, using the labels already available from local registration into NDT Histograms, and we present a SLAM pipeline based on Semantic assisted NDT and PointNet ++. We experimentally demonstrate on sequences from the KITTI benchmark that the map descriptor we propose outperforms NDT Histograms without semantics, and we validate its use on a SLAM task.",
        "primary_area": "",
        "author": "Anestis Zaganidis;Alexandros Zerntev;Tom Duckett;Grzegorz Cielniak;Anestis Zaganidis;Alexandros Zerntev;Tom Duckett;Grzegorz Cielniak",
        "authorids": "/37086310699;/37087322984;/37419160900;/37550177700;/37086310699;/37087322984;/37419160900;/37550177700",
        "aff": "Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, UK.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, UK.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, UK.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, UK.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968140/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=381117299017684095&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "Lincoln Centre for Autonomous Systems (LCAS)",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967789",
        "title": "Semi-Autonomous Interventional Manipulation using Pneumatically Attachable Flexible Rails",
        "track": "main",
        "status": "Poster",
        "abstract": "During laparoscopic surgery, tissues frequently need to be retracted and mobilized for manipulation or visualisation. State-of-the-art robotic platforms for minimally invasive surgery (MIS) typically rely on rigid tools to interact with soft tissues. Such tools offer a very narrow contact surface thus applying relatively large forces that can lead to tissue damage, posing a risk for the success of the procedure and ultimately for the patient. In this paper, we show how the use of Pneumatically Attachable Flexible (PAF) rail, a vacuum-based soft attachment for laparoscopic applications, can reduce such risk by offering a larger contact surface between the tool and the tissue. Ex vivo experiments are presented investigating the short- and long-term effects of different levels of vacuum pressure on the tissues surface. These experiments aim at evaluating the best trade-off between applied pressure, potential damage, task duration and connection stability. A hybrid control system has been developed to perform and investigate the organ repositioning task using the proposed system. The task is only partially automated allowing the surgeon to be part of the control loop. A gradient-based planning algorithm is integrated with learning from teleoperation algorithm which allows the robot to improve the learned trajectory. The use of Similar Smooth Path Repositioning (SSPR) algorithm is proposed to improve a demonstrated trajectory based on a known cost function. The results obtained show that a smoother trajectory allows to decrease the minimum level of pressure needed to guarantee active suction during PAF positioning and placement.",
        "primary_area": "",
        "author": "C.D\u2019 Ettorre;A. Stilli;G. Dwyer;J. B. Neves;M. Tran;D. Stoyanov;C.D\u2019 Ettorre;A. Stilli;G. Dwyer;J. B. Neves;M. Tran;D. Stoyanov",
        "authorids": "/37087323509;/37085447649;/37085406315;/37087321838;/37086692521;/37563622300;/37087323509;/37085447649;/37085406315;/37087321838;/37086692521;/37563622300",
        "aff": "The Centre for Medical Image Computing (CMIC), Wellcome/EPSRC Centre for Interventioal and Surgical Sciences (WEISS), University College London, London, UK; The Centre for Medical Image Computing (CMIC), Wellcome/EPSRC Centre for Interventioal and Surgical Sciences (WEISS), University College London, London, UK; The Centre for Medical Image Computing (CMIC), Wellcome/EPSRC Centre for Interventioal and Surgical Sciences (WEISS), University College London, London, UK; The Research Department of Surgical Biotechnology, University College of London, Royal Free Hospital, London, UK; The Research Department of Surgical Biotechnology, University College of London, Royal Free Hospital, London, UK; The Centre for Medical Image Computing (CMIC), Wellcome/EPSRC Centre for Interventioal and Surgical Sciences (WEISS), University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967789/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16903463215391457737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Centre for Medical Image Computing (CMIC)",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967875",
        "title": "SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition and loop-closure detection are main challenges in the localization, mapping and navigation tasks of self-driving vehicles. In this paper, we solve the loop-closure detection problem by incorporating the deep-learning based point cloud description method and the coarse-to-fine sequence matching strategy. More specifically, we propose a deep neural network to extract a global descriptor from the original large-scale 3D point cloud, then based on which, a typical place analysis approach is presented to investigate the feature space distribution of the global descriptors and select several super keyframes. Finally, a coarse-to-fine strategy, which includes a super keyframe based coarse matching stage and a local sequence matching stage, is presented to ensure the loop-closure detection accuracy and real-time performance simultaneously. Thanks to the sequence matching operation, the proposed approach obtains an improvement against the existing deep-learning based methods. Experiment results on a self-driving vehicle validate the effectiveness of the proposed loop-closure detection algorithm.",
        "primary_area": "",
        "author": "Zhe Liu;Chuanzhe Suo;Shunbo Zhou;Fan Xu;Huanshu Wei;Wen Chen;Hesheng Wang;Xinwu Liang;Yun-Hui Liu;Zhe Liu;Chuanzhe Suo;Shunbo Zhou;Fan Xu;Huanshu Wei;Wen Chen;Hesheng Wang;Xinwu Liang;Yun-Hui Liu",
        "authorids": "/38505849700;/37086937363;/37086345412;/37086550869;/37087324321;/37087239966;/37292567100;/37858807000;/37279412600;/38505849700;/37086937363;/37086345412;/37086550869;/37087324321;/37087239966;/37292567100;/37858807000;/37279412600",
        "aff": "T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Aeronautics and Astronautics, Shanghai Jiao Tong University, China; School of Instrument Science and Engineering, Southeast University, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Instrument Science and Engineering, Southeast University, China; Department of Automation, Shanghai Jiao Tong University, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967875/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4086272153444567345&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;2;0;0;2;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Shanghai Jiao Tong University;Southeast University",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;School of Aeronautics and Astronautics;School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sjtu.edu.cn;https://www.seu.edu.cn/",
        "aff_unique_abbr": "CUHK;SJTU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968493",
        "title": "Sequential clustering for tactile image compression to enable direct adaptive feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "The sense of touch is often crucial for humans to perform manipulation tasks. Providing tactile feedback during teleoperation or for users of prosthetic devices would be beneficial. However, the representation of tactile information constitutes a major technical challenge, since the numerous and possibly multimodal sensor readings are massive compared to the available tactile display technology. We introduce an algorithm that deploys two stages of K-means clustering along and across tactile image frames that render tactile sensor information at each time instant. In this manner, the massive tactile information is adaptively compressed in real-time while preserving its physical meaning, thus, remains intuitive and direct. We experimentally verify and examine the characteristics of our algorithm by evaluating the original and compressed tactile data. The data was gathered during the active tactile exploration of several objects of daily living by an Allegro robot hand that was covered with 15 uSkin sensor modules providing 2403-axis force vector measurements at each time instant. Our novel algorithm is straight forward enough to be implemented into tactile feedback systems. Finally, our algorithm allows for the direct feedback of massive tactile sensor data for a broad variety of tactile sensors and tactile displays, thereby, enables the compressed yet intuitive representation of massive tactile sensor information for real-time applications.",
        "primary_area": "",
        "author": "Andreas Geier;Gang Yan;Tito Pradhono Tomo;Shun Ogasa;Sophon Somlor;Alexander Schmitz;Shigeki Sugano;Andreas Geier;Gang Yan;Tito Pradhono Tomo;Shun Ogasa;Sophon Somlor;Alexander Schmitz;Shigeki Sugano",
        "authorids": "/37086485457;/37086935752;/37085618711;/37086166387;/37085510233;/37587110100;/37274050800;/37086485457;/37086935752;/37085618711;/37086166387;/37085510233;/37587110100;/37274050800",
        "aff": "Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, 169 Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968493/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12128475737626249229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Modern Mechanical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968288",
        "title": "Setup and Method for Remote Center of Motion Positioning Guidance During Robot-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "During robot-assisted surgery, a Remote Center of Motion (RCM) is often implemented to constrain instrument motion through and about a specific point in space. Aligning and re-positioning this point during surgery is not trivial, as this is a defined, yet often non-visualised, point in space. When misaligned with the patient surrounding anatomy is excessively strained, potentially causing post-operative complications. Not being able to safely re-position the RCM for these purposes limits the use of surgical robotics. This work introduces a general approach relying on anatomy-based haptic fixtures to simplify and improve RCM positioning during robot-assisted surgery. The proposed approach is extended with a novel method and mechanism to mechanically implement such fixtures. This is applied for the use case of vitreoretinal surgery, for which purpose a dedicated robotic setup and fixture mechanism was developed. These were used to conduct an initial experimental validation, during which the feasibility of both a virtual and mechanical implementation is reviewed. Initial outcomes suggest that both implementations are feasible. With the currently used impedance-type system, the mechanical implementation is shown to offer at least one order of magnitude stiffness increase when compared to an equivalent virtual implementation.",
        "primary_area": "",
        "author": "Jonas Smits;Dominiek Reynaerts;Emmanuel Vander Poorten;Jonas Smits;Dominiek Reynaerts;Emmanuel Vander Poorten",
        "authorids": "/37086455887;/37297035700;/37293929100;/37086455887;/37297035700;/37293929100",
        "aff": "Department of Mechanical Engineering - Robot Assisted Surgery Group, KU Leuven- University of Leuven, Heverlee, Belgium; Department of Mechanical Engineering - Robot Assisted Surgery Group, KU Leuven- University of Leuven, Heverlee, Belgium; Department of Mechanical Engineering - Robot Assisted Surgery Group, KU Leuven- University of Leuven, Heverlee, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968288/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6150307707546321765&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KU Leuven- University of Leuven",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Heverlee",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "8967997",
        "title": "Sharing is Caring: Socially-Compliant Autonomous Intersection Negotiation",
        "track": "main",
        "status": "Poster",
        "abstract": "Current methods for autonomous management use strict first-come, first-serve (FCFS) ordering to manage incoming autonomous vehicles at an intersection. In this work, we present a coordination policy that swaps agent ordering to increase the system-wide performance while ensuring that the swaps are socially compliant. By considering an agent's Social Value Orientation (SVO), a social psychology metric for their willingness to help another vehicle, the central coordinator can reduce system delays while ensuring each individual vehicle increases their own utility. The FCFS-SVO algorithm is both computationally tractable and accounts for a variety of real-world agent types, such as human drivers and a variety of social orientations. Simulation results show that average vehicle delays decrease with swapping by enabling cooperation between agents. In addition, we show that the proportion of human drivers, as well as, the distribution of prosocial and egoistic vehicles in the system can have a prominent effect on the performance of the system.",
        "primary_area": "",
        "author": "Noam Buckman;Alyssa Pierson;Wilko Schwarting;Sertac Karaman;Daniela Rus;Noam Buckman;Alyssa Pierson;Wilko Schwarting;Sertac Karaman;Daniela Rus",
        "authorids": "/37087324071;/37085345711;/37085590089;/37304113000;/37279652300;/37087324071;/37085345711;/37085590089;/37304113000;/37279652300",
        "aff": "CSAIL, Massachusetts Institute of Technology, Cambridge, MA; CSAIL, Massachusetts Institute of Technology, Cambridge, MA; CSAIL, Massachusetts Institute of Technology, Cambridge, MA; LIDS, Massachusetts Institute of Technology, Cambridge, MA, USA; CSAIL, Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967997/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18440818558978101972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967925",
        "title": "Siamese Convolutional Neural Network for Sub-millimeter-accurate Camera Pose Estimation and Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Servoing (VS), where images taken from a camera typically attached to the robot end-effector are used to guide the robot motions, is an important technique to tackle robotic tasks that require a high level of accuracy. We propose a new neural network, based on a Siamese architecture, for highly accurate camera pose estimation. This, in turn, can be used as a final refinement step following a coarse VS or, if applied in an iterative manner, as a standalone VS on its own. The key feature of our neural network is that it outputs the relative pose between any pair of images, and does so with sub-millimeter accuracy. We show that our network can reduce pose estimation errors to 0.6 mm in translation and 0.4 degrees in rotation, from initial errors of 10 mm / 5 degrees if applied once, or of several cm / tens of degrees if applied iteratively. The network can generalize to similar objects, is robust against changing lighting conditions, and to partial occlusions (when used iteratively). The high accuracy achieved enables tackling low-tolerance assembly tasks downstream: using our network, an industrial robot can achieve 97.5% success rate on a VGA-connector insertion task without any force sensing mechanism.",
        "primary_area": "",
        "author": "Cunjun Yu;Zhongang Cai;Hung Pham;Quang-Cuong Pham;Cunjun Yu;Zhongang Cai;Hung Pham;Quang-Cuong Pham",
        "authorids": "/37087324540;/37089016626;/37086073905;/38191381800;/37087324540;/37089016626;/37086073905;/38191381800",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Eureka Robotics; Eureka Robotics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967925/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13817589747951706152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Nanyang Technological University;Eureka Robotics",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8967695",
        "title": "Sim-to-(Multi)-Real: Transfer of Low-Level Robust Control Policies to Multiple Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrotor stabilizing controllers often require careful, model-specific tuning for safe operation. We use reinforcement learning to train policies in simulation that transfer remarkably well to multiple different physical quadrotors. Our policies are low-level, i.e., we map the rotorcrafts' state directly to the motor outputs. The trained control policies are very robust to external disturbances and can withstand harsh initial conditions such as throws. We show how different training methodologies (change of the cost function, modeling of noise, use of domain randomization) might affect flight performance. To the best of our knowledge, this is the first work that demonstrates that a simple neural network can learn a robust stabilizing low-level quadrotor controller (without the use of a stabilizing PD controller) that is shown to generalize to multiple quadrotors. The video of our experiments can be found at https://sites.google.com/view/sim-to-multi-quad.",
        "primary_area": "",
        "author": "Artem Molchanov;Tao Chen;Wolfgang H\u00f6nig;James A. Preiss;Nora Ayanian;Gaurav S. Sukhatme;Artem Molchanov;Tao Chen;Wolfgang H\u00f6nig;James A. Preiss;Nora Ayanian;Gaurav S. Sukhatme",
        "authorids": "/37085487060;/37087323572;/37543456200;/37086138258;/37546534600;/37278934100;/37085487060;/37087323572;/37543456200;/37086138258;/37546534600;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967695/",
        "gs_citation": 145,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11989842351381424646&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967642",
        "title": "Sim-to-Real Learning for Casualty Detection from Ground Projected Point Cloud Data",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of human body detection-particularly a human body lying on the ground (a.k.a. casualty)-using point cloud data. This ability to detect a casualty is one of the most important features of mobile rescue robots, in order for them to be able to operate autonomously. We propose a deep-learning-based casualty detection method using a deep convolutional neural network (CNN). This network is trained to be able to detect a casualty using a point-cloud data input. In the method we propose, the point cloud input is pre-processed to generate a depth image-like ground-projected heightmap. This heightmap is generated based on the projected distance of each point onto the detected ground plane within the point cloud data. The generated heightmap-in image form-is then used as an input for the CNN to detect a human body lying on the ground. To train the neural network, we propose a novel sim-to-real approach, in which the network model is trained using synthetic data obtained in simulation and then tested on real sensor data. To make the model transferable to real data implementations, during the training we adopt specific data augmentation strategies with the synthetic training data. The experimental results show that data augmentation introduced during the training process is essential for improving the performance of the trained model on real data. More specifically, the results demonstrate that the data augmentations on raw point-cloud data have contributed to a considerable improvement of the trained model performance.",
        "primary_area": "",
        "author": "Roni Permana Saputra;Nemanja Rakicevic;Petar Kormushev;Roni Permana Saputra;Nemanja Rakicevic;Petar Kormushev",
        "authorids": "/37086076815;/37085609151;/37590229500;/37086076815;/37085609151;/37590229500",
        "aff": "Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College London, UK; Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College London, UK; Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967642/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1797709423747918935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson School of Design Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968053",
        "title": "Sim-to-Real Transfer for Biped Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new approach for transfer of dynamic robot control policies such as biped locomotion from simulation to real hardware. Key to our approach is to perform system identification of the model parameters \u03bc of the hardware (e.g. friction, center-of-mass) in two distinct stages, before policy learning (pre-sysID) and after policy learning (post-sysID). Pre-sysID begins by collecting trajectories from the physical hardware based on a set of generic motion sequences. Because the trajectories may not be related to the task of interest, presysID does not attempt to accurately identify the true value of \u03bc, but only to approximate the range of \u03bc to guide the policy learning. Next, a Projected Universal Policy (PUP) is created by simultaneously training a network that projects \u03bc to a low-dimensional latent variable \u03b7 and a family of policies that are conditioned on \u03b7. The second round of system identification (post-sysID) is then carried out by deploying the PUP on the robot hardware using task-relevant trajectories. We use Bayesian Optimization to determine the values for \u03b7 that optimize the performance of PUP on the real hardware. We have used this approach to create three successful biped locomotion controllers (walk forward, walk backwards, walk sideways) on the Darwin OP2 robot.",
        "primary_area": "",
        "author": "Wenhao Yu;Visak CV Kumar;Greg Turk;C. Karen Liu;Wenhao Yu;Visak CV Kumar;Greg Turk;C. Karen Liu",
        "authorids": "/37085891022;/37086312258;/37334922800;/38240584300;/37085891022;/37086312258;/37334922800;/38240584300",
        "aff": "School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968053/",
        "gs_citation": 129,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15245941644852094101&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Interactive Computing",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968029",
        "title": "Simitate: A Hybrid Imitation Learning Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Simitate - a hybrid benchmarking suite targeting the evaluation of approaches for imitation learning. A dataset containing 1938 sequences where humans perform daily activities in a realistic environment is presented. The dataset is strongly coupled with an integration into a simulator. RGB and depth streams with a resolution of 960\u00d7540 at 30Hz and accurate ground truth poses for the demonstrator's hand, as well as the object in 6 DOF at 120Hz are provided. Along with our dataset we provide the 3D model of the used environment, labeled object images and pre-trained models. A benchmarking suite that aims at fostering comparability and reproducibility supports the development of imitation learning approaches. Further, we propose and integrate evaluation metrics on assessing the quality of effect and trajectory of the imitation performed in simulation. Simitate is available on our project website: https://agas.uni-koblenz.de/simitate/.",
        "primary_area": "",
        "author": "Raphael Memmesheimer;Ivanna Kramer;Viktor Seib;Dietrich Paulus;Raphael Memmesheimer;Ivanna Kramer;Viktor Seib;Dietrich Paulus",
        "authorids": "/37085706250;/37087235839;/37085711644;/37297934300;/37085706250;/37087235839;/37085711644;/37297934300",
        "aff": "Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany; Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany; Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany; Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968029/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12980874981705719577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Koblenz-Landau",
        "aff_unique_dep": "Institute for Computational Visualistics",
        "aff_unique_url": "https://www.uni-koblenz-landau.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968106",
        "title": "Simulation-based physics reasoning for consistent scene estimation in an HRI context",
        "track": "main",
        "status": "Poster",
        "abstract": "Reasoning about spatial and geometric relations between objects in a tabletop human-robot interaction is a challenge due to the perception not being always consistent: objects placed on a table seem to be slightly in the air; they overlap; they disappear due to occlusions. Yet, interpreting and anchoring perceptual data in a physically consistent estimation of the scene is a crucial ability for humans, and thus robots in HRI context. In this paper we present a simulation-based physics reasoner integrated in a lightweight situation-assessment framework called Underworlds, that allows the robot to stabilize objects and build at run-time a consistent estimation of the scene, even for entirely hidden objects, while inferring the actions performed by its human partner.",
        "primary_area": "",
        "author": "Yoan Sallami;S\u00e9verin Lemaignan;Aur\u00e9lie Clodic;Rachid Alami;Yoan Sallami;S\u00e9verin Lemaignan;Aur\u00e9lie Clodic;Rachid Alami",
        "authorids": "/37086575879;/38482927400;/37296056000;/37278643600;/37086575879;/38482927400;/37296056000;/37278643600",
        "aff": "LAAS-CNRS, CNRS, Toulouse, France; Author is with Bristol Robotics Lab, University of the West of England, Bristol, United Kingdom; LAAS-CNRS, CNRS, Toulouse, France; LAAS-CNRS, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968106/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11563146715967958051&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "LAAS-CNRS;University of the West of England",
        "aff_unique_dep": ";Bristol Robotics Lab",
        "aff_unique_url": "https://www.laas.fr;https://www.uwe.ac.uk",
        "aff_unique_abbr": "LAAS-CNRS;UWE",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Toulouse;Bristol",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "8968247",
        "title": "Simultaneous Drone Localisation and Wind Turbine Model Fitting During Autonomous Surface Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for simultaneous localisation and wind turbine model fitting for a drone performing an automated surface inspection. We use a skeletal parameterisation of the turbine that can be easily integrated into a non-linear least squares optimiser, combined with a pose graph representation of the drone's 3-D trajectory, allowing us to optimise both sets of parameters simultaneously. Given images from an onboard camera, we use a CNN to infer projections of the skeletal model, enabling correspondence constraints to be established through a cost function. This is then coupled with GPS/IMU measurements taken at key frames in the graph to allow successive optimisation as the drone navigates around the turbine. We present two variants of the cost function, one based on traditional 2D point correspondences and the other on direct image interpolation within the inferred projections. Results from experiments on simulated and real-world data show that simultaneous optimisation provides improvements to localisation over only optimising the pose and that combined use of both cost functions proves most effective.",
        "primary_area": "",
        "author": "Oliver Moolan-Feroze;Konstantinos Karachalios;Dimitrios N. Nikolaidis;Andrew Calway;Oliver Moolan-Feroze;Konstantinos Karachalios;Dimitrios N. Nikolaidis;Andrew Calway",
        "authorids": "/37085785817;/37086145480;/37086935504;/37326243500;/37085785817;/37086145480;/37086935504;/37326243500",
        "aff": "Department of Computer Science, University of Bristol, 75 Woodland Road, Bristol, United Kingdom; Perceptual Robotics, 5 Hope Road, Bristol, UK, United Kingdom; Perceptual Robotics, 5 Hope Road, Bristol, UK, United Kingdom; Department of Computer Science, University of Bristol, 75 Woodland Road, Bristol, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968247/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18321339236588953422&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Bristol;Perceptual Robotics",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.bristol.ac.uk;",
        "aff_unique_abbr": "Bristol;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968095",
        "title": "Simultaneous Transparent and Non-Transparent Object Segmentation With Multispectral Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "For an autonomous mobile system such as an autonomous robot that moves throughout a city, semantic segmentation is important. Performing semantic segmentation under diverse conditions, in turn, requires 1) a robust ability to recognize objects in low-visibility environments, such as at night and 2) the ability to recognize objects that transmit visible light, such as glass and acrylic used in doors and windows. To satisfy these requirements, using RGB images and infrared images simultaneously is considered effective. Visibility and infrared transmission characteristics are different for different objects; therefore, merely entering them into the conventional semantic segmentation framework is not applicable. For example, when a pedestrian is present behind a glass, the visible image captures the pedestrian rather than the glass and the infrared image captures the glass. In this research, we propose a new semantic segmentation method having a three-stream structure, focusing on the difference in the transmission characteristics. This method extracts not only valid features for ordinary non-transparent objects but also features effective for the recognition of transparent objects by utilizing differences in objects to be imaged owing to transmission characteristics. Furthermore, we constructed a new dataset called \u201ccoaxials\u201d for the visible and infrared coaxial dataset and demonstrated that we can obtain better segmentation performance compared with the conventional method.",
        "primary_area": "",
        "author": "Atsuro Okazawa;Tomoyuki Takahata;Tatsuya Harada;Atsuro Okazawa;Tomoyuki Takahata;Tatsuya Harada",
        "authorids": "/37087322352;/37414602200;/37274148900;/37087322352;/37414602200;/37274148900",
        "aff": "Department of Image Processing Technology, Olympus Corporation, Japan; Department of Mechano-Informatics, The University of Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Japan, RIKEN, Tokyo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968095/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14466383864008629662&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Olympus Corporation;University of Tokyo",
        "aff_unique_dep": "Department of Image Processing Technology;Department of Mechano-Informatics",
        "aff_unique_url": "https://www.olympus.com;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Olympus;UTokyo",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967821",
        "title": "Situation Awareness for Proactive Robots in HRI",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception of the intention of humans prior to an interaction is a demanding skill during human-robot interaction (HRI). This skill is even more sought after during robot-initiated HRI. Initiating an interaction in an inappropriate situation can be avoided when robots are equipped with the ability to decide when to interact and when not to. Many of the existing systems investigate only a few characteristics of humans which demonstrate inner state of mind and are based on complex monitoring mechanisms which limit their use in most of the scenarios. This work presents an autoregressive model based on observable physical and emotional human cues to determine the level of interest displayed by a human towards an interaction with a robot. This model was implemented on a service robotic platform and the behavior of the robot was controlled using the model. The behavior of the robot was determined by means of proxemic approach and the nature of conversation with the human. The outcomes of the model were evaluated by analyzing user feedback in different situations inside a simulated social environment. Using the model, robot was given the ability to analyze the situation of its human user in an emotionally intelligent manner, prior to an interaction. The behavior of the model was reviewed by user feedback in order to validate the findings. Results of the experiment are presented and findings of the study are discussed.",
        "primary_area": "",
        "author": "Chapa Sirithunge;H. M. Ravindu;T. Bandara;A. G. Buddhika;P. Jayasekara;D. P. Chandima;Chapa Sirithunge;H. M. Ravindu;T. Bandara;A. G. Buddhika;P. Jayasekara;D. P. Chandima",
        "authorids": "/37086522596;/37086521864;/37087016784;/37085575395;/37691719500;/38475277300;/37086522596;/37086521864;/37087016784;/37085575395;/37691719500;/38475277300",
        "aff": "The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka; The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka; The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka; The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka; The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka; The Intelligent Service Robotics Group, Department of Electrical Engineering, University of Moratuwa, Katubedda, Sri Lanka",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967821/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14795602986900622109&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Moratuwa",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.mrt.ac.lk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Katubedda",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Sri Lanka"
    },
    {
        "id": "8967901",
        "title": "Skill Interaction Categories for Communication in Flexible Human-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible human-robot cooperation can be coordinated by dynamic task allocation, where team members observe task progress and repeatedly decide to execute outstanding operations from a commonly known task model. Such task-level coordination strategies do not cover cases, where a high level of abstraction for task modelling implies operations infeasible for one single agent due to limited capabilities. Task-level coordination can handle these operations by introducing additional operation-level coordination for more fine-grained interaction, e.g. to hand over a tool or provide a helping hand. We contribute an approach to classify operations regarding the interaction they require. Based on this classification, we show how robots can plan and issue communication to coordinate respective interaction within dynamic plan execution. Against the background of Smart Factories, a smartphone app is used as communication channel and evaluated in a user study.",
        "primary_area": "",
        "author": "Dominik Riedelbauch;Stephan Schweizer;Dominik Henrich;Dominik Riedelbauch;Stephan Schweizer;Dominik Henrich",
        "authorids": "/37086314275;/37087323233;/37328758200;/37086314275;/37087323233;/37328758200",
        "aff": "Chair for Applied Computer Science III (Robotics and Embedded Systems), University of Bayreuth, Bayreuth, Germany; Chair for Applied Computer Science III (Robotics and Embedded Systems), University of Bayreuth, Bayreuth, Germany; Chair for Applied Computer Science III (Robotics and Embedded Systems), University of Bayreuth, Bayreuth, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967901/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7474237787982492492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bayreuth",
        "aff_unique_dep": "Chair for Applied Computer Science III (Robotics and Embedded Systems)",
        "aff_unique_url": "https://www.uni-bayreuth.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bayreuth",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967972",
        "title": "Small-Scale Compliant Dual Arm with Tail for Winged Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Winged aerial robots represent an evolution of aerial manipulation robots, replacing the multirotor vehicles by fixed or flapping wing platforms. The development of this morphology is motivated in terms of efficiency, endurance and safety in some inspection operations where multirotor platforms may not be suitable. This paper presents a first prototype of compliant dual arm as preliminary step towards the realization of a winged aerial robot capable of perching and manipulating with the wings folded. The dual arm provides 6 DOF (degrees of freedom) for end effector positioning in a human-like kinematic configuration, with a reach of 25 cm (half-scale w.r.t. the human arm), and 0.2 kg weight. The prototype is built with micro metal gear motors, measuring the joint angles and the deflection with small potentiometers. The paper covers the design, electronics, modeling and control of the arms. Experimental results in test-bench validate the developed prototype and its functionalities, including joint position and torque control, bimanual grasping, the dynamic equilibrium with the tail, and the generation of 3D maps with laser sensors attached at the arms.",
        "primary_area": "",
        "author": "Alejandro Suarez;Manuel Perez;Guillermo Heredia;Anibal Ollero;Alejandro Suarez;Manuel Perez;Guillermo Heredia;Anibal Ollero",
        "authorids": "/37085663079;/37086580758;/37355441300;/37265412000;/37085663079;/37086580758;/37355441300;/37265412000",
        "aff": "GRVC Robotics Labs, University of Seville, Spain; GRVC Robotics Labs, University of Seville, Spain; GRVC Robotics Labs, University of Seville, Spain; GRVC Robotics Labs, University of Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967972/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=525613975689622909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "GRVC Robotics Labs",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8967959",
        "title": "Soft Action Particle Deep Reinforcement Learning for a Continuous Action Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances of actor-critic methods in deep reinforcement learning have enabled performing several continuous control problems. However, existing actor-critic algorithms require a large number of parameters to model policy and value functions where it can lead to overfitting issue and is difficult to tune hyperparameter. In this paper, we introduce a new off-policy actor-critic algorithm, which can reduce a significant number of parameters compared to existing actorcritic algorithms without any performance loss. The proposed method replaces the actor network with a set of action particles that employ few parameters. Then, the policy distribution is represented using state action value network with action particles. During the learning phase, to improve the performance of policy distribution, the location of action particles is updated to maximize state action values. To enhance the exploration and stable convergence, we add perturbation to action particles during training. In the experiment, we validate the proposed method in MuJoCo environments and empirically show that our method shows similar or better performance than the state-of-the-art actor-critic method with a smaller number of parameters. The experimental video can be found at http: //rllab.snu.ac.kr/multimedia.",
        "primary_area": "",
        "author": "Minjae Kang;Kyungjae Lee;Songhwai Oh;Minjae Kang;Kyungjae Lee;Songhwai Oh",
        "authorids": "/37087323855;/493655068209513;/37068116900;/37087323855;/493655068209513;/37068116900",
        "aff": "The Department of Electrical and Computer Engineering and ASRI, Seoul National University, Korea; The Department of Electrical and Computer Engineering and ASRI, Seoul National University, Korea; The Department of Electrical and Computer Engineering and ASRI, Seoul National University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967959/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15903595254341778811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968281",
        "title": "Soft Pneumatic Helical Actuator with High Contraction Ratio",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft contraction actuator has always been an important research field in soft robotics. This paper presents a novel soft contraction actuator which can realize high-ratio contraction when pressurized by pneumatic power. This actuator can be easily made by soft materials including rubber tube, one-way extensible cloth, inextensible cloth and wire. 2 types of structures are presented based on different working circumstances. When pressurized, the actuator can curve and then coil to a helical shape due to the different extensibilities of its opposite sides, a high contraction length and large contraction force can be achieved synchronously. Experiments are conducted to show the relationship between contraction force and contraction ratio of this actuator. The high contraction ratio of this actuator is revealed by comparing with McKibben actuator under the same condition, the maximal contraction ratio reaches 78% and the actuation stress is 8.36kPa.",
        "primary_area": "",
        "author": "Peizheng Yuan;Ginjiro Kawano;Hideyuki Tsukagoshi;Peizheng Yuan;Ginjiro Kawano;Hideyuki Tsukagoshi",
        "authorids": "/37087325090;/37086449363;/37274012400;/37087325090;/37086449363;/37274012400",
        "aff": "Tokyo Institute of Technology, Tokyo, Japan; Tokyo Institute of Technology, Tokyo, Japan; Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968281/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4102032055915426379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968074",
        "title": "Soft Polymer-Electrolyte-Fuel-Cell Tube Realizing Air-Hose-Free Thin McKibben Muscles",
        "track": "main",
        "status": "Poster",
        "abstract": "Among the various pneumatic actuators, thin McKibben muscles are particularly attractive owing to their high performance in terms of high contraction ratio, high flexibility, and productivity. One of the challenges for thin McKibben muscles and other pneumatic actuators is the fact that they generally need air hoses and air sources like compressors. This necessarily leads to bulky systems. To solve this problem, we propose and study a new approach to driving pneumatic actuators that exploits electrolysis/synthesis of water by a polymer electrolyte fuel cell (PEFC). This method could in-principle have high applicability to thin McKibben muscles. However, one challenge must still be addressed for the realization of an electrically driven thin McKibben muscle: the development of a tube-shaped soft PEFC. This paper proposes an electrically driven thin McKibben muscle with a tube-shaped soft PEFC realized through a flowing non-electrolytic plating method. First, the proposed thin McKibben muscle is briefly described. Then, a novel method for plating a tube-shaped soft PEFC using reflux is introduced, and its fundamental operation is tested. After the evaluation of the PEFC, we report a prototype realization of the proposed thin McKibben muscle. The developed prototype has a length of over 170 mm, a diameter of 4 mm, and high flexibility for bending. Finally, we elaborate on a driving experiment through which fundamental characteristics were experimentally evaluated. The prototype thin McKibben muscle succeeded in electrically controlling contraction and expansion motion with a flexible and bendable structure.",
        "primary_area": "",
        "author": "Hiroyuki Nabae;Akio Kodaira;Tetsuya Horiuchi;Kinji Asaka;Gen Endo;Koichi Suzumori;Hiroyuki Nabae;Akio Kodaira;Tetsuya Horiuchi;Kinji Asaka;Gen Endo;Koichi Suzumori",
        "authorids": "/37085590608;/37086692128;/37086687680;/37275258500;/37282128000;/37283170500;/37085590608;/37086692128;/37086687680;/37275258500;/37282128000;/37283170500",
        "aff": "School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Osaka; National Institute of Advanced Industrial Science and Technology, Osaka; School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968074/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2103456371127102423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "School of Engineering;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Titech;AIST",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Ookayama;Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967596",
        "title": "Sparse-3D Lidar Outdoor Map-Based Autonomous Vehicle Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Difficulties in capturing unique structures in the outdoor environment hinders the map-based Autonomous Vehicles (AV) localization performance. Accordingly, this necessitates the use of high resolution sensors to capture more information from the environment. However, this approach is costly and limits the mass deployment of AV. To overcome this drawback, in this paper, we propose a novel outdoor map-based localization method for Autonomous Vehicles in urban environments using sparse 3D lidar scan data. In the proposed method, a Point-to-Distribution (P2D) formulation of the Normal Distributions Transform (NDT) approach is applied in a Monte Carlo Localization (MCL) framework. The formulation improves the measurement model of localization by taking individual lidar point measurements into consideration. Additionally, to apply the localization to scalable outdoor environments, a flexible and efficient map structure is implemented. The experimental results indicate that the proposed approach significantly improves the localization and its robustness in outdoor AV environments, especially with limited sparse lidar data.",
        "primary_area": "",
        "author": "Syed Zeeshan Ahmed;Vincensius Billy Saputra;Saurab Verma;Kun Zhang;Albertus Hendrawan Adiwahono;Syed Zeeshan Ahmed;Vincensius Billy Saputra;Saurab Verma;Kun Zhang;Albertus Hendrawan Adiwahono",
        "authorids": "/37086459056;/37085734838;/37085628589;/37086459041;/37546317700;/37086459056;/37085734838;/37085628589;/37086459041;/37546317700",
        "aff": "Department of Robotics and Automation Systems, Institute of Infocomm Research, A*STAR, Singapore; Department of Robotics and Automation Systems, Institute of Infocomm Research, A*STAR, Singapore; Department of Robotics and Automation Systems, Institute of Infocomm Research, A*STAR, Singapore; Department of Robotics and Automation Systems, Institute of Infocomm Research, A*STAR, Singapore; Department of Robotics and Automation Systems, Institute of Infocomm Research, A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967596/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6242200206143848519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Institute of Infocomm Research",
        "aff_unique_dep": "Department of Robotics and Automation Systems",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8968504",
        "title": "Spatiotemporal Representation of Dynamic Scences",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel representation of dynamic scenes perceived by moving agents. This type of environments require constant updates of the map information that uses conventional geometric representations due to the changing relative position of dynamic object to the static scene. We show that this changed representation of the environment increases the robustness and accuracy in the perception of the scene and simplifies significantly the processing and complexity of the perception module. At the same time, the changed representation allows also a better prioritization of attention to the moving object around the robot that takes into account not the Euclidean distance but the time-to-interaction (TTI), which is the core contribution of this approach. We present the mathematical framework behind the pro-posed representation and show examples, how this framework simplifies and robustifies the processing in the perception modules of a moving agent.",
        "primary_area": "",
        "author": "Darius Burschka;Darius Burschka",
        "authorids": "/37267429200;/37267429200",
        "aff": "Faculty of Informatics, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968504/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2576345154431531417&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Faculty of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968073",
        "title": "Specification-Based Maneuvering of Quadcopters Through Hoops",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of navigating quadcopters through a sequence of hoops. The specification may be given directly or indirectly via a linear temporal logic (LTL) formula. We approach this problem in three phases. First, we introduce a planner that generates a path through a given sequence of hoops. Second, we augment our planner to leverage a given specification in linear temporal logic (LTL) and generate a sequence that satisfies this specification. Third, we implement cross-entropy optimization on this planner to enhance trajectory performance where quadcopter trajectories are modified within the solution space to optimize over a cost function. We implement this planner as a novel interaction modality between users and quadcopters on the Robotarium. Simulation and experimental results are provided.",
        "primary_area": "",
        "author": "Christopher Banks;Kyle Slovak;Samuel Coogan;Magnus Egerstedt;Christopher Banks;Kyle Slovak;Samuel Coogan;Magnus Egerstedt",
        "authorids": "/37087322560;/37087322008;/38232457300;/37269707500;/37087322560;/37087322008;/38232457300;/37269707500",
        "aff": "Institute of Technology, Atlanta, USA; Institute of Technology, Atlanta, USA; Institute of Technology, Atlanta, USA; Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968073/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3722166626264250402&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967709",
        "title": "Specifying and Synthesizing Human-Robot Handovers",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a controller for human-robot handovers that is automatically synthesized from high-level specifications in Signal Temporal Logic (STL). In contrast to existing controllers, this approach can provide formal guarantees on the timing of each of the handover phases. Using synthesis also allows end-users to specify and dynamically change the robot's behaviors using high-level requirements of goals and constraints rather than by tuning low-level controller parameters. We illustrate the proposed approach by replicating the behavior of existing handover strategies from the literature. We also identify specification parameters that are likely to lead to successful handovers using a public database of human-human handovers.",
        "primary_area": "",
        "author": "Alap Kshirsagar;Hadas Kress-Gazit;Guy Hoffman;Alap Kshirsagar;Hadas Kress-Gazit;Guy Hoffman",
        "authorids": "/37086803567;/38307602100;/37274165500;/37086803567;/38307602100;/37274165500",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, New York; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, New York; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967709/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3838218044725496181&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967864",
        "title": "Spiking Neural Network on Neuromorphic Hardware for Energy-Efficient Unidimensional SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy-efficient simultaneous localization and mapping (SLAM) is crucial for mobile robots exploring unknown environments. The mammalian brain solves SLAM via a network of specialized neurons, exhibiting asynchronous computations and event-based communications, with very low energy consumption. We propose a brain-inspired spiking neural network (SNN) architecture that solves the unidimensional SLAM by introducing spike-based reference frame transformation, visual likelihood computation, and Bayesian inference. We integrated our neuromorphic algorithm to Intel's Loihi neuromorphic processor, a non-Von Neumann hardware that mimics the brain's computing paradigms. We performed comparative analyses for accuracy and energy-efficiency between our neuromorphic approach and the GMapping algorithm, which is widely used in small environments. Our Loihi-based SNN architecture consumes 100 times less energy than GMapping run on a CPU while having comparable accuracy in head direction localization and map-generation. These results pave the way for scaling our approach towards active-SLAM alternative solutions for Loihi-controlled autonomous robots.",
        "primary_area": "",
        "author": "Guangzhi Tang;Arpit Shah;Konstantinos P. Michmizos;Guangzhi Tang;Arpit Shah;Konstantinos P. Michmizos",
        "authorids": "/37087322548;/37087323160;/37062249500;/37087322548;/37087323160;/37062249500",
        "aff": "Computational Brain Lab, Rutgers University, New Jersey, USA; Computational Brain Lab, Rutgers University, New Jersey, USA; Computational Brain Lab, Rutgers University, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967864/",
        "gs_citation": 124,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9974490221371015084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Computational Brain Lab",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Jersey",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967982",
        "title": "Spiral Zipper Manipulator for Aerial Grasping and Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel manipulator for aerial vehicles to perform grasping and manipulation tasks. The goal is to design a low-cost, relatively light but strong manipulator with a large workspace and compact storage space that can be mounted on an unmanned aerial system. A novel design solution based on the Spiral Zipper, an expanding tube, combined with tether actuators is presented. A model of the system is introduced and the control method and pose estimator are developed and tested with some experiments showing the reliable performance of the overall system. An experiment with a self-sealing suction cup gripper demonstrates manipulation while mounted on the aerial vehicle frame.",
        "primary_area": "",
        "author": "Chao Liu;Abhraneel Bera;Thulani Tsabedze;Daniel Edgar;Mark Yim;Chao Liu;Abhraneel Bera;Thulani Tsabedze;Daniel Edgar;Mark Yim",
        "authorids": "/37086114571;/37087325352;/37086109275;/37086112622;/37274063600;/37086114571;/37087325352;/37086109275;/37086112622;/37274063600",
        "aff": "GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab and Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967982/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2283102058746827582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Mechanical Engineering and Applied Mechanics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967673",
        "title": "Stability and Gait Switching of Underactuated Biped Walkers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new gait switching approach for underactuated biped walkers. The switching condition relies on a reduced region of attraction - that of the unactuated dynamics - which is shown to be sufficient to predict falls. A gait transition is accordingly stable (as in \u201cthe robot does not fall if the biped's state is within the reduced region of attraction of the switched-in gait when switching takes place. Two- and five-link biped models complete a sequence of random gait transitions using the switching logic. The condition is also used to enlarge the full region of stability of the five-link model by embedding feedback-stabilized trajectories from a gait library in a mapping. The mapping stitches stable trajectories to the orbit of the desired gait based on each gait's reduced region of attraction. This improves the robustness of the five-link model walking on uneven terrain without ground perception regardless of the size of the gait library.",
        "primary_area": "",
        "author": "Martin Fevre;Hai Lin;James P. Schmiedeler;Martin Fevre;Hai Lin;James P. Schmiedeler",
        "authorids": "/37086345471;/37291989100;/37282121600;/37086345471;/37291989100;/37282121600",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame, USA; Department of Electrical Engineering, University of Notre Dame, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967673/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4132281155739798028&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967811",
        "title": "StarNet: Pedestrian Trajectory Prediction using Deep Neural Network in Star Topology",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectory prediction is crucial for many important applications. This problem is a great challenge because of complicated interactions among pedestrians. Previous methods model only the pairwise interactions between pedestrians, which not only oversimplifies the interactions among pedestrians but also is computationally inefficient. In this paper, we propose a novel model StarNet to deal with these issues. StarNet has a star topology which includes a unique hub network and multiple host networks. The hub network takes observed trajectories of all pedestrians to produce a comprehensive description of the interpersonal interactions. Then the host networks, each of which corresponds to one pedestrian, consult the description and predict future trajectories. The star topology gives StarNet two advantages over conventional models. First, StarNet is able to consider the collective influence among all pedestrians in the hub network, making more accurate predictions. Second, StarNet is computationally efficient since the number of host network is linear to the number of pedestrians. Experiments on multiple public datasets demonstrate that StarNet outperforms multiple state-of-the-arts by a large margin in terms of both accuracy and efficiency.",
        "primary_area": "",
        "author": "Yanliang Zhu;Deheng Qian;Dongchun Ren;Huaxia Xia;Yanliang Zhu;Deheng Qian;Dongchun Ren;Huaxia Xia",
        "authorids": "/37086798364;/37086798523;/37086800405;/37088755529;/37086798364;/37086798523;/37086800405;/37088755529",
        "aff": "Meituan-Dianping Group, Beijing, China; Meituan-Dianping Group, Beijing, China; Meituan-Dianping Group, Beijing, China; Meituan-Dianping Group, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967811/",
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11507931483863610790&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Meituan-Dianping Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.meituan.com",
        "aff_unique_abbr": "Meituan-Dianping",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967938",
        "title": "State Representation Learning with Robotic Priors for Partially Observable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Recurrent State Representation Learning (RSRL) to tackle the problem of state representation learning in robotics for partially observable environments. To learn low-dimensional state representations, we combine a Long Short Term Memory network with robotic priors. RSRL introduces new priors with landmarks and combines them with existing robotics priors from the literature to train the representations. To evaluate the quality of the learned state representation, we introduce validation networks that help us better visualize and quantitatively analyze the learned state representations. We show that the learned representations are low-dimensional, locally consistent, and can approximate the underlying true state for robot localization in simulated 3D maze environments. We use the learned representations for reinforcement learning and show that we achieve similar performance as training with the true state. The learned representations are robust to landmark misclassification errors.",
        "primary_area": "",
        "author": "Marco Morik;Divyam Rastogi;Rico Jonschkowski;Oliver Brock;Marco Morik;Divyam Rastogi;Rico Jonschkowski;Oliver Brock",
        "authorids": "/37087323178;/37087322881;/37086203015;/37279727100;/37087323178;/37087322881;/37086203015;/37279727100",
        "aff": "Robotics and Biology Laboratory at Technische Universtit\u00e4t, Berlin, Germany; Robotics and Biology Laboratory at Technische Universtit\u00e4t, Berlin, Germany; Now at Robotics at Google, USA; Robotics and Biology Laboratory at Technische Universtit\u00e4t, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967938/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4361808847472381068&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin;Google",
        "aff_unique_dep": "Robotics and Biology Laboratory;Robotics",
        "aff_unique_url": "https://www.tu-berlin.de;https://www.google.com",
        "aff_unique_abbr": "TU Berlin;Google",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Berlin;Mountain View",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "8968012",
        "title": "Stereo Visual Inertial LiDAR Simultaneous Localization and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is a fundamental task to mobile and aerial robotics. LiDAR based systems have proven to be superior compared to vision based systems due to its accuracy and robustness. In spite of its superiority, pure LiDAR based systems fail in certain degenerate cases like traveling through a tunnel. We propose Stereo Visual Inertial LiDAR (VIL) SLAM that performs better on these degenerate cases and has comparable performance on all other cases. VIL-SLAM accomplishes this by incorporating tightly-coupled stereo visual inertial odometry (VIO) with LiDAR mapping and LiDAR enhanced visual loop closure. The system generates loop-closure corrected 6-DOF LiDAR poses in real-time and lcm voxel dense maps near real-time. VIL-SLAM demonstrates improved accuracy and robustness compared to state-of-the-art LiDAR methods.",
        "primary_area": "",
        "author": "Weizhao Shao;Srinivasan Vijayarangan;Cong Li;George Kantor;Weizhao Shao;Srinivasan Vijayarangan;Cong Li;George Kantor",
        "authorids": "/37087324143;/37086289991;/37087324018;/37273878300;/37087324143;/37086289991;/37087324018;/37273878300",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968012/",
        "gs_citation": 153,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=150789895843647805&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968250",
        "title": "Stochastic Path Planning for Autonomous Underwater Gliders with Safety Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous underwater gliders frequently execute extensive missions with high levels of uncertainty due to limitations of sensing, control and oceanic forecasting. Glider path planning seeks an optimal path with respect to conflicting objectives, such as travel cost and safety, that must be explicitly balanced subject to these uncertainties. In this paper, we derive a set of recursive equations for state probability and expected travel cost conditional on safety, and use them to implement a new stochastic variant of FMT* in the context of two types of objective functions that allow a glider to reach a destination region with minimum cost or maximum probability of arrival given a safety threshold. We demonstrate the framework using three simulated examples that illustrate how user-prescribed safety constraints affect the results.",
        "primary_area": "",
        "author": "Chanyeol Yoo;Stuart Anstee;Robert Fitch;Chanyeol Yoo;Stuart Anstee;Robert Fitch",
        "authorids": "/37086933786;/37601910400;/38466367800;/37086933786;/37601910400;/38466367800",
        "aff": "University of Technology Sydney, Ultimo, NSW, Australia; Department of Defence, Defence Science and Technology Group, Australia; University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968250/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6399664068106944935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Technology Sydney;Defence Science and Technology Group",
        "aff_unique_dep": ";Department of Defence",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dstgroup.com.au",
        "aff_unique_abbr": "UTS;DST Group",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ultimo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967857",
        "title": "Stochastic Sampling Simulation for Pedestrian Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Urban environments pose a significant challenge for autonomous vehicles (AVs) as they must safely navigate while in close proximity to many pedestrians. It is crucial for the AV to correctly understand and predict the future trajectories of pedestrians to avoid collision and plan a safe path. Deep neural networks (DNNs) have shown promising results in accurately predicting pedestrian trajectories, relying on large amounts of annotated real-world data to learn pedestrian behavior. However, collecting and annotating these large real-world pedestrian datasets is costly in both time and labor. This paper describes a novel method using a stochastic sampling-based simulation to train DNNs for pedestrian trajectory prediction with social interaction. Our novel simulation method can generate vast amounts of automatically-annotated, realistic, and naturalistic synthetic pedestrian trajectories based on small amounts of real annotation. We then use such synthetic trajectories to train an off-the-shelf state-of-the-art deep learning approach Social GAN (Generative Adversarial Network) to perform pedestrian trajectory prediction. Our proposed architecture, trained only using synthetic trajectories, achieves better prediction results compared to those trained on human-annotated real-world data using the same network. Our work demonstrates the effectiveness and potential of using simulation as a substitution for human annotation efforts to train high-performing prediction algorithms such as the DNNs.",
        "primary_area": "",
        "author": "Cyrus Anderson;Xiaoxiao Du;Ram Vasudevan;Matthew Johnson-Roberson;Cyrus Anderson;Xiaoxiao Du;Ram Vasudevan;Matthew Johnson-Roberson",
        "authorids": "/37086423879;/37086200273;/37648237800;/38271635400;/37086423879;/37086200273;/37648237800;/38271635400",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967857/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15971944810945123796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968254",
        "title": "Structured Reward Shaping using Signal Temporal Logic specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has become a popular technique to train autonomous agents to learn control policies that enable them to accomplish complex tasks in uncertain environments. A key component of an RL algorithm is the definition of a reward function that maps each state and an action that can be taken in that state to some real-valued reward. Typically, reward functions informally capture an implicit (albeit vague) specification on the desired behavior of the agent. In this paper, we propose the use of the logical formalism of Signal Temporal Logic(STL) as a formal specification for the desired behaviors of the agent. Furthermore, we propose algorithms to locally shape rewards in each state with the goal of satisfying the high-level STL specification. We demonstrate our technique on two case studies, a cart-pole balancing problem with a discrete action space, and controlling the actuation of a simulated quadrotor for point-to-point movement.The proposed framework is agnostic to any specific RL algorithm, as locally shaped rewards can be easily used in concert with any deep RL algorithm.",
        "primary_area": "",
        "author": "Anand Balakrishnan;Jyotirmoy V. Deshmukh;Anand Balakrishnan;Jyotirmoy V. Deshmukh",
        "authorids": "/37086022637;/37395154300;/37086022637;/37395154300",
        "aff": "Cyber-Physical Systems: Verification, Intelligence, Design and Analysis (CPS-VIDA) Group, University of Southern California, Los Angeles, California; Cyber-Physical Systems: Verification, Intelligence, Design and Analysis (CPS-VIDA) Group, University of Southern California, Los Angeles, California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968254/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1016521274265463489&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "CPS-VIDA Group",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968595",
        "title": "Study on Elastic Elements Allocation for Energy-Efficient Robotic Cheetah Leg",
        "track": "main",
        "status": "Poster",
        "abstract": "The biomimetic approach in robotics is promising: nature has found many good solutions through millions of years of evolution. However, creating a design that enables fast and energy-efficient locomotion remains a major challenge. This paper focuses on the development of a full leg mechanism for a fast and energy-efficient 4-legged robot inspired by a cheetah morphology. In particular, we analyze how the allocation of flexible elements and their stiffness affects the cost of transport and peak power characteristics for vertical jumps and a galloping motion. The study includes the femur and full leg mechanism's locomotory behavior simulation, capturing its interaction with the ground.",
        "primary_area": "",
        "author": "Ivan I. Borisov;Ivan A. Kulagin;Anastasiya E. Larkina;Artem A. Egorov;Sergey A. Kolyubin;Stefano Stramigioli;Ivan I. Borisov;Ivan A. Kulagin;Anastasiya E. Larkina;Artem A. Egorov;Sergey A. Kolyubin;Stefano Stramigioli",
        "authorids": "/37086250938;/37087325139;/37087323411;/37087323498;/37887676700;/37282439300;/37086250938;/37087325139;/37087323411;/37087323498;/37887676700;/37282439300",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968595/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7278417150078700484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ITMO University",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab",
        "aff_unique_url": "https://www.itmo.ru",
        "aff_unique_abbr": "ITMO",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Saint Petersburg",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "8967931",
        "title": "Study on Stumbles of the Elderly from a Depth Perception Dependency Test",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the relationship between the depth perception and an approaching motion toward an object. We propose the depth perception dependency test, which is the combination of tests of a motion and depth perception based on the situation that an object is placed on the human\u2019s pathway. Firstly, as the motion test, we set the ball approach motion and asked elderly participants to approach and contact a ball by their foot, because this motion is easy to measure and requires localization skill and motion planning skill. The swing/support legs positions at the toeoff time of the swing leg just before contacting the ball was analyzed. Secondly, as the depth perception test, the pseudo3D image test was proposed. The coordinate transformation model for the calculation of the depth perception ability was also proposed. Through the proposed test and the proposed model, it was clarified that the participants who are regarded as perceiving the strong visual illusion perceive the objects closer than its real position, and their swing leg toe off positions in the ball approaching motion were significantly farther than other participants. Thus, it can be concluded that there was a relationship between the depth perception and the approaching motion that is thought to be a higher risk of stumbles.",
        "primary_area": "",
        "author": "Emiko Uchiyama;Toshihiro Mino;Hiroki Obara;Tomoki Tanaka;Wataru Takano;Yoshihiko Nakamura;Katsuya Iijima;Emiko Uchiyama;Toshihiro Mino;Hiroki Obara;Tomoki Tanaka;Wataru Takano;Yoshihiko Nakamura;Katsuya Iijima",
        "authorids": "/37086606144;/37087324280;/37087032437;/37089443961;/37295985700;/37280754600;/37087324878;/37086606144;/37087324280;/37087032437;/37089443961;/37295985700;/37280754600;/37087324878",
        "aff": "graduate school of information science and technology, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan; graduate school of information science and technology, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan; graduate school of information science and technology, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan; graduate school of medicine, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan; center for mathematical modeling and data science, Osaka University, Japan; graduate school of information science and technology, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan; institute of gerontology, university of Tokyo, Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967931/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3842189220562268122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "University of Tokyo;Osaka University",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Center for Mathematical Modeling and Data Science",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "UTokyo;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hongo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967704",
        "title": "SuMa++: Efficient LiDAR-based Semantic SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable and accurate localization and mapping are key components of most autonomous systems. Besides geometric information about the mapped environment, the semantics plays an important role to enable intelligent navigation behaviors. In most realistic environments, this task is particularly complicated due to dynamics caused by moving objects, which can corrupt the mapping step or derail localization. In this paper, we propose an extension of a recently published surfel-based mapping approach exploiting three-dimensional laser range scans by integrating semantic information to facilitate the mapping process. The semantic information is efficiently extracted by a fully convolutional neural network and rendered on a spherical projection of the laser range data. This computed semantic segmentation results in point-wise labels for the whole scan, allowing us to build a semantically-enriched map with labeled surfels. This semantic map enables us to reliably filter moving objects, but also improve the projective scan matching via semantic constraints. Our experimental evaluation on challenging highways sequences from KITTI dataset with very few static structures and a large amount of moving cars shows the advantage of our semantic SLAM approach in comparison to a purely geometric, state-of-the-art approach.",
        "primary_area": "",
        "author": "Xieyuanli Chen;Andres Milioto;Emanuele Palazzolo;Philippe Gigu\u00e8re;Jens Behley;Cyrill Stachniss;Xieyuanli Chen;Andres Milioto;Emanuele Palazzolo;Philippe Gigu\u00e8re;Jens Behley;Cyrill Stachniss",
        "authorids": "/37086247697;/37086400161;/37086455423;/37560636500;/37593243900;/37329668600;/37086247697;/37086400161;/37086455423;/37560636500;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; Laval University, Qu\u00e9bec, Canada; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967704/",
        "gs_citation": 568,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17819336038615594910&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Bonn;Laval University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.laval.ca",
        "aff_unique_abbr": "UBonn;Laval",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Qu\u00e9bec",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Germany;Canada"
    },
    {
        "id": "8967661",
        "title": "Synchronizing Virtual Constraints and Preview Controller: a Walking Pattern Generator for the Humanoid Robot COMAN+",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel hybrid walking pattern generator which combines results from the virtual constraints and the preview control theories for bipedal locomotion. This choice is motivated by findings in biomechanics that show how the dynamic motion of the human walk is mainly generated by the sagittal component of the stepping. Thus, we choose the conservative preview control to generate the lateral motion while we pick a more dynamical framework such as the virtual constraints for the sagittal motion. We investigate how the time-dependent preview control and the time-independent virtual constraints approach can be integrated together in a humanoid locomotion and finally we show promising results on COMAN+, the new humanoid robot from Istituto Italiano di Tecnologia.",
        "primary_area": "",
        "author": "Francesco Ruscelli;Arturo Laurenzi;Enrico Mingo Hoffman;Nikos G. Tsagarakis;Francesco Ruscelli;Arturo Laurenzi;Enrico Mingo Hoffman;Nikos G. Tsagarakis",
        "authorids": "/37086034535;/37086141170;/37085377101;/37295830800;/37086034535;/37086141170;/37085377101;/37295830800",
        "aff": "Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967661/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9831605848331513690&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Advanced Robotics",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968543",
        "title": "Synthesizing Robot Manipulation Programs from a Single Observed Human Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Programming by Demonstration (PbD) lets users with little technical background program a wide variety of manipulation tasks for robots, but it should be as intuitive as possible for users while requiring as little time as possible. In this paper, we present a Programming by Demonstration system that synthesizes manipulation programs from a single observed demonstration, allowing users to program new tasks for a robot simply by performing the task once themselves. A human-in-the-loop interface helps users make corrections to the perceptual state as needed. We introduce Object Interaction Programs as a representation of multi-object, bimanual manipulation tasks and present algorithms for extracting programs from observed demonstrations and transferring programs to a robot to perform the task in a new scene. We demonstrate the expressivity and generalizability of our approach through an evaluation on a benchmark of complex tasks.",
        "primary_area": "",
        "author": "Justin Huang;Dieter Fox;Maya Cakmak;Justin Huang;Dieter Fox;Maya Cakmak",
        "authorids": "/37085770493;/37284329000;/37409159800;/37085770493;/37284329000;/37409159800",
        "aff": "Jet Propulsion Laboratory, Pasadena, CA, USA; School for Computer Science and Engineering, University of Washington, Seattle, WA, USA; School for Computer Science and Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968543/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7872481246788238192&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Jet Propulsion Laboratory;University of Washington",
        "aff_unique_dep": ";School for Computer Science and Engineering",
        "aff_unique_url": "https://www.jpl.nasa.gov;https://www.washington.edu",
        "aff_unique_abbr": "JPL;UW",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Pasadena;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968066",
        "title": "Systematic benchmarking for reproducibility of computer vision algorithms for real-time systems: The example of optic flow estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Until now there have been few formalized methods for conducting systematic benchmarking aiming at reproducible results when it comes to computer vision algorithms. This is evident from lists of algorithms submitted to prominent datasets, authors of a novel method in many cases primarily state the performance of their algorithms in relation to a shallow description of the hardware system where it was evaluated. There are significant problems linked to this non-systematic approach of reporting performance, especially when comparing different approaches and when it comes to the reproducibility of claimed results. Furthermore how to conduct retrospective performance analysis such as an algorithm's suitability for embedded real-time systems over time with underlying hardware and software changes in place. This paper proposes and demonstrates a systematic way of addressing such challenges by adopting containerization of software aiming at formalization and reproducibility of benchmarks. Our results show maintainers of broadly accepted datasets in the computer vision community to strive for systematic comparison and reproducibility of submissions to increase the value and adoption of computer vision algorithms in the future.",
        "primary_area": "",
        "author": "Bj\u00f6rnborg Nguyen;Christian Berger;Ola Benderius;Bj\u00f6rnborg Nguyen;Christian Berger;Ola Benderius",
        "authorids": "/37086070232;/37085352034;/37085523485;/37086070232;/37085352034;/37085523485",
        "aff": "Applied artificial intelligence, Chalmers University of Technology, Gothenburg, Sweden; Cyber Physical Systems, University of Gothenburg, Gothenburg, Sweden; Applied artificial intelligence, Chalmers University of Technology, Gothenburg, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968066/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6375694952476785798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Chalmers University of Technology;University of Gothenburg",
        "aff_unique_dep": "Applied artificial intelligence;Cyber Physical Systems",
        "aff_unique_url": "https://www.chalmers.se;https://www.gu.se",
        "aff_unique_abbr": "Chalmers;GU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gothenburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "8967792",
        "title": "TIP Model: A Combination of Unstable Subsystems for Lateral Balance in Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "Balancing or postural stability is one of important locomotor subfunctions in bipedal gaits. The inverted pendulum and virtual pivot point (VPP) are common modeling approaches to analyze balance control in human and robot walking. In this paper, we employ the VPP concept to investigate posture control in the frontal plane. The outcomes demonstrate that unlike posture control in the sagittal plane, the VPP in the frontal plane is place below center of mass. This finding explains a novel hybrid strategy for lateral stability in human walking. The here proposed model shows that switching between unstable inverted virtual pendulums generate stable posture control in the frontal plane. This outcome is consistent within a group of seven human subjects walking at normal and slow speeds.",
        "primary_area": "",
        "author": "Vahid Firouzi;Andre Seyfarth;Maziar A. Sharbafi;Vahid Firouzi;Andre Seyfarth;Maziar A. Sharbafi",
        "authorids": "/37087323278;/37394272400;/37394631900;/37087323278;/37394272400;/37394631900",
        "aff": "Electrical and Computer Engineering Department, University of Tehran, Tehran, Iran; Lauflabor Laboratory, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Lauflabor Laboratory, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967792/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12057170343959309142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Tehran;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Electrical and Computer Engineering Department;Lauflabor Laboratory",
        "aff_unique_url": "https://www.ut.ac.ir;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "UT;TU Darmstadt",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Tehran;Darmstadt",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Iran;Germany"
    },
    {
        "id": "8968462",
        "title": "TZC: Efficient Inter-Process Communication for Robotics Middleware with Partial Serialization",
        "track": "main",
        "status": "Poster",
        "abstract": "Inter-process communication (IPC) is one of the core functions of modern robotics middleware. We propose an efficient IPC technique called TZC (Towards Zero-Copy). As a core component of TZC, we design a novel algorithm called partial serialization. Our formulation can generate messages that can be divided into two parts. During message transmission, one part is transmitted through a socket and the other part uses shared memory. The part within shared memory is never copied or serialized during its lifetime. We have integrated TZC with ROS and ROS2 and find that TZC can be easily combined with current open-source platforms. By using TZC, the overhead of IPC remains constant when the message size grows. In particular, when the message size is 4MB (less than the size of a full HD image), TZC can reduce the overhead of ROS IPC from tens of milliseconds to hundreds of microseconds and can reduce the overhead of ROS2 IPC from hundreds of milliseconds to less than 1 millisecond. We also demonstrate the benefits of TZC by integrating it with TurtleBot2 to be used in autonomous driving scenarios. We show that by using TZC, the braking distance can be 16% shorter than with ROS.",
        "primary_area": "",
        "author": "Yu-Ping Wang;Wende Tan;Xu-Qiang Hu;Dinesh Manocha;Shi-Min Hu;Yu-Ping Wang;Wende Tan;Xu-Qiang Hu;Dinesh Manocha;Shi-Min Hu",
        "authorids": "/37085396500;/37089406192;/37087325104;/37267825600;/37089548402;/37085396500;/37089406192;/37087325104;/37267825600;/37089548402",
        "aff": "BNRist Ministry of Education, Tsinghua University, and the Key Laboratory of Pervasive Computing, Beijing, China; BNRist Ministry of Education, Tsinghua University, and the Key Laboratory of Pervasive Computing, Beijing, China; BNRist Ministry of Education, Tsinghua University, and the Key Laboratory of Pervasive Computing, Beijing, China; Department of Computer Science and Electrical & Computer Engineering, University of Maryland, USA; BNRist Ministry of Education, Tsinghua University, and the Key Laboratory of Pervasive Computing, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968462/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14758973306034599156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Tsinghua University;University of Maryland",
        "aff_unique_dep": "BNRist Ministry of Education;Department of Computer Science and Electrical & Computer Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.umd.edu",
        "aff_unique_abbr": "THU;UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8968204",
        "title": "Tactile-Based Insertion for Dense Box-Packing",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of using high-resolution tactile sensors to control the insertion of objects in a boxpacking scenario. In this paper, we propose an insertion strategy that leverages tactile sensing to: 1) safely probe the box with the grasped object while monitoring incipient slip to maintain a stable grasp on the object. 2) estimate and correct for residual position uncertainties to insert the object into a designated gap without disturbing the environment.Our proposed methodology is based on two neural networks that estimate the error direction and error magnitude, from a stream of tactile imprints, acquired by two GelSlim fingers, during the insertion process. The system is trained on four objects with basic geometric shapes, which we show generalizes to four other common objects. Based on the estimated positional errors, a heuristic controller iteratively adjusts the position of the object and eventually inserts it successfully without requiring prior knowledge of the geometry of the object. The key insight is that dense tactile feedback contains useful information with respect to the contact interaction between the grasped object and its environment. We achieve high success rate and show that unknown objects can be inserted with an average of 6 attempts of the probe-correct loop. The method's ability to generalize to novel objects makes it a good fit for box packing in warehouse automation.",
        "primary_area": "",
        "author": "Siyuan Dong;Alberto Rodriguez;Siyuan Dong;Alberto Rodriguez",
        "authorids": "/37086249096;/38194796600;/37086249096;/38194796600",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968204/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13501574216492568027&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967929",
        "title": "Talk to the Vehicle: Language Conditioned Autonomous Navigation of Self Driving Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel pipeline that blends encodings from natural language and 3D semantic maps obtained from visual imagery to generate local trajectories that are executed by a low-level controller. The pipeline precludes the need for a prior registered map through a local waypoint generator neural network. The waypoint generator network (WGN) maps semantics and natural language encodings (NLE) to local waypoints. A local planner then generates a trajectory from the ego location of the vehicle (an outdoor car in this case) to these locally generated waypoints while a low-level controller executes these plans faithfully. The efficacy of the pipeline is verified in the CARLA simulator environment as well as on local semantic maps built from real-world KITTI dataset. In both these environments (simulated and real-world) we show the ability of the WGN to generate waypoints accurately by mapping NLE of varying sequence lengths and levels of complexity. We compare with baseline approaches and show significant performance gain over them. And finally, we show real implementations on our electric car verifying that the pipeline lends itself to practical and tangible realizations in uncontrolled outdoor settings. In loop execution of the proposed pipeline that involves repetitive invocations of the network is critical for any such language-based navigation framework. This effort successfully accomplishes this thereby bypassing the need for prior metric maps or strategies for metric level localization during traversal.",
        "primary_area": "",
        "author": "N. N. Sriram;Tirth Maniar;Jayaganesh Kalyanasundaram;Vineet Gandhi;Brojeshwar Bhowmick;K Madhava Krishna;N. N. Sriram;Tirth Maniar;Jayaganesh Kalyanasundaram;Vineet Gandhi;Brojeshwar Bhowmick;K Madhava Krishna",
        "authorids": "/37086955830;/37087325160;/37087322570;/37075471000;/37571664300;/37395945400;/37086955830;/37087325160;/37087322570;/37075471000;/37571664300;/37395945400",
        "aff": "International Institute of Information Technology, Hyderabad, India; International Institute of Information Technology, Hyderabad, India; International Institute of Information Technology, Hyderabad, India; International Institute of Information Technology, Hyderabad, India; TCS Research and Innovation Labs, Kolkata, India; International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967929/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13529292850900454558&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "International Institute of Information Technology;Tata Consultancy Services",
        "aff_unique_dep": ";Research and Innovation Labs",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.tcs.com",
        "aff_unique_abbr": "IIIT Hyderabad;TCS",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Hyderabad;Kolkata",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8967680",
        "title": "Task-Motion Planning with Reinforcement Learning for Adaptable Mobile Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Task-motion planning (TMP) addresses the problem of efficiently generating executable and low-cost task plans in a discrete space such that the (initially unknown) action costs are determined by motion plans in a corresponding continuous space. A task-motion plan for a mobile service robot that behaves in a highly dynamic domain can be sensitive to domain uncertainty and changes, leading to suboptimal behaviors or execution failures. In this paper, we propose a novel framework, TMP-RL, which is an integration of TMP and reinforcement learning (RL), to solve the problem of robust TMP in dynamic and uncertain domains. The robot first generates a low-cost, feasible task-motion plan by iteratively planning in the discrete space and updating relevant action costs evaluated by the motion planner in continuous space. During execution, the robot learns via model-free RL to further improve its task-motion plans. RL enables adaptability to the current domain, but can be costly with regards to experience; using TMP, which does not rely on experience, can jump-start the learning process before executing in the real world. TMP-RL is evaluated in a mobile service robot domain where the robot navigates in an office area, showing significantly improved adaptability to unseen domain dynamics over TMP and task planning (TP)-RL methods.",
        "primary_area": "",
        "author": "Yuqian Jiang;Fangkai Yang;Shiqi Zhang;Peter Stone;Yuqian Jiang;Fangkai Yang;Shiqi Zhang;Peter Stone",
        "authorids": "/37086936635;/37087324475;/37086294744;/37269574900;/37086936635;/37087324475;/37086294744;/37269574900",
        "aff": "Department of Computer Science, University of Texas at Austin, Austin, TX, USA; NVIDIA Corporation, Redmond, WA, USA; Department of Computer Science, SUNY-Binghamton, Binghamton, NY, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967680/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8981285044779755876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Texas at Austin;NVIDIA;State University of New York at Binghamton",
        "aff_unique_dep": "Department of Computer Science;NVIDIA Corporation;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.nvidia.com;https://www.binghamton.edu",
        "aff_unique_abbr": "UT Austin;NVIDIA;SUNY-Binghamton",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Austin;Redmond;Binghamton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967992",
        "title": "Task-oriented Grasping in Object Stacking Scenes with CRF-based Semantic Model",
        "track": "main",
        "status": "Poster",
        "abstract": "In task-oriented grasping, the robot is supposed to manipulate the objects in a task-compatible manner, which is more important but more challenging than just stably grasping. However, most of existing works perform task-oriented grasping only in single object scenes. This greatly limits their practical application in real world scenes, in which there are usually multiple stacked objects with serious overlaps and occlusions. To perform task-oriented grasping in object stacking scenes, in this paper, we firstly build a synthetic dataset named Object Stacking Grasping Dataset (OSGD) for task-oriented grasping in object stacking scenes. Secondly, a Conditional Random Field (CRF) is constructed to model the semantic contents in object regions. The modelled semantic contents can be illustrated as incompatibility of task labels and continuity of task regions. This proposed approach can greatly reduce the interference of overlaps and occlusions in object stacking scenes. To embed the CRF-based semantic model into our grasp detection network, we implement the inference process of CRFs as a RNN so that the whole model, Task-oriented Grasping CRFs (TOG-CRFs) can be trained end to end. Finally, in object stacking scenes, the constructed model can help robot achieve 69.4% success rate for task-oriented grasping.",
        "primary_area": "",
        "author": "Chenjie Yang;Xuguang Lan;Hanbo Zhang;Nanning Zheng;Chenjie Yang;Xuguang Lan;Hanbo Zhang;Nanning Zheng",
        "authorids": "/37086800069;/37270865300;/37086441588;/37271536700;/37086800069;/37270865300;/37086441588;/37271536700",
        "aff": "the National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; the National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; the National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China; the National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, No.28 Xianning Road, Xi\u2019an, Shaanxi, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967992/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=631032445217025692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xi\u2019an Jiao Tong University",
        "aff_unique_dep": "School of Electronic and Information Engineering",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967910",
        "title": "Task-specific Self-body Controller Acquisition by Musculoskeletal Humanoids: Application to Pedal Control in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The musculoskeletal humanoid has many benefits that human beings have, but the modeling of its complex flexible body is difficult. Although we have developed an online acquisition method of the nonlinear relationship between joints and muscles, we could not completely match the actual robot and its self-body image. When realizing a certain task, the direct relationship between the control input and task state needs to be learned. So, we construct a neural network representing the time-series relationship between the control input and task state, and realize the intended task state by applying the network to a real-time control. In this research, we conduct accelerator pedal control experiments as one application, and verify the effectiveness of this study.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Kei Tsuzuki;Shogo Makino;Moritaka Onitsuka;Koki Shinjo;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Kento Kawaharazuka;Kei Tsuzuki;Shogo Makino;Moritaka Onitsuka;Koki Shinjo;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086101930;/37086598284;/37086105354;/37086573419;/37087324644;/38238750500;/37280639000;/37085684621;/37286658200;/37086101930;/37086598284;/37086105354;/37086573419;/37087324644;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, The University of Tokyo, 7-3-1, Hongo, Bunkyo-ku, Tokyo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967910/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11198498190577282606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967675",
        "title": "Teaching a Drone to Accompany a Person from Demonstrations using Non-Linear ASFM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a new method based on the Aerial Social Force Model (ASFM) to allow human-drone side-by-side social navigation in real environments. To tackle this problem, the present work proposes a new nonlinear-based approach using Neural Networks. To learn and test the rightness of the new approach, we built a new dataset with simulated environments and we recorded motion controls provided by a human expert tele-operating the drone. The recorded data is then used to train a neural network which maps interaction forces to acceleration commands. The system is also reinforced with a human path prediction module to improve the drone's navigation, as well as, a collision detection module to completely avoid possible impacts. Moreover, a performance metric is defined which allows us to numerically evaluate and compare the fulfillment of the different learned policies. The method was validated by a large set of simulations; we also conducted real-life experiments with an autonomous drone to verify the framework described for the navigation process. In addition, a user study has been realized to reveal the social acceptability of the method.",
        "primary_area": "",
        "author": "Ana\u00eds Garrell;Carles Coll;Ren\u00e9 Alqu\u00e9zar;Alberto Sanfeliu;Ana\u00eds Garrell;Carles Coll;Ren\u00e9 Alqu\u00e9zar;Alberto Sanfeliu",
        "authorids": "/37586306600;/37087323792;/37323737500;/37270957300;/37586306600;/37087323792;/37323737500;/37270957300",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC). Llorens Artigas 4-6, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC). Llorens Artigas 4-6, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC). Llorens Artigas 4-6, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC). Llorens Artigas 4-6, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967675/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15109503605645252150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "CSIC-UPC",
        "aff_unique_url": "https://www.iri.upc.edu/",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968540",
        "title": "Teleoperated Hexapod Robot for Imitation Learning Task Training",
        "track": "main",
        "status": "Poster",
        "abstract": "To operate successfully in the unstructured environment of homes and small businesses, robots will be implemented by unskilled operators who cannot explicitly program their motions. Recently, imitation learning has been used to train robots that manipulate their environment based on pixel-to-action control. The robot actions are determined by camera inputs without programmed trajectories. Such training is often performed on robotic hardware which was not designed for imitation learning. This paper describes a new robot which is designed expressly to improve the training speed and ability of pixel-to-action policies. In particular, hexapod robot hardware is designed for teleoperation, thus improving correspondence and simplifying human control.",
        "primary_area": "",
        "author": "Austin Gurley;Austin Gurley",
        "authorids": "/37087322696;/37087322696",
        "aff": "Deft Dynamics, Birmingham, AL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968540/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:CQrU8cTDe2AJ:scholar.google.com/&scioq=Teleoperated+Hexapod+Robot+for+Imitation+Learning+Task+Training&hl=en&as_sdt=0,14",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Deft Dynamics",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Birmingham",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968030",
        "title": "Teleoperating Robots from the International Space Station: Microgravity Effects on Performance with Force Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Sending humans to Mars' surface to build habitats is, for now, prohibitively dangerous and costly. An alternative is to have humans in orbiters, teleoperating robots on Mars to construct habitats, deferring human arrival until these habitats are finished. This paper describes the Kontur-2 experiments, in which the feasibility of this scenario was tested with the International Space Station as an orbiter, a cosmonaut operating a force-feedback joystick as an input device for teleoperation, and Earth as the planet where the teleoperated robot is located. In particular, we focus on human teleoperation performance, which is known to deteriorate under conditions of spaceflight. We investigate whether the provision of force feedback at the joystick is as beneficial as under terrestrial conditions. Our results show that, to support humans operating in weightlessness, haptic assistance needs to be adjusted to the altered environmental condition.",
        "primary_area": "",
        "author": "Bernhard Weber;Ribin Balachandran;Cornelia Riecke;Freek Stulp;Martin Stelzer;Bernhard Weber;Ribin Balachandran;Cornelia Riecke;Freek Stulp;Martin Stelzer",
        "authorids": "/37710671800;/37085381760;/37085812883;/37681682200;/37085821770;/37710671800;/37085381760;/37085812883;/37681682200;/37085821770",
        "aff": "German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), M\u00fcnchner Str.20, We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), M\u00fcnchner Str.20, We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), M\u00fcnchner Str.20, We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), M\u00fcnchner Str.20, We\u03b2ling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), M\u00fcnchner Str.20, We\u03b2ling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968030/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6673146686280626434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Robotics and Mechatronics Center",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968248",
        "title": "TendencyRL: Multi-stage Discriminative Hints for Efficient Goal-Oriented Reverse Curriculum Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning algorithms have been proven successful in a variety of simulation tasks with dense reward feedback. However, real-world RL applications, e.g. robotic manipulation, remain challenging as most of them are multi-stage and a positive reward can only be received when the final goal is accomplished. In this work, we propose a potential solution to such problems with the introduction of an experience-based tendency reward shaping mechanism, which provides the robot with additional hints based on a discriminative learning on past experience. The reward along with a stage-awareness network help accelerate solving a multistage task split into shorter phases in a reverse curriculum learning manner. We extensively study the advantages of TRL on the standard long-term goal-oriented robotics domains such as pick-and-place, and show that TRL performs more efficiently and robustly than prior approaches in tasks with large state space. In addition, we demonstrate that TRL can solve difficult robot manipulation challenges directly from perception.",
        "primary_area": "",
        "author": "Chen Wang;Junfeng Ding;Xiangyu Chen;Zelin Ye;Jialu Wang;Ziruo Cai;Cewu Lu;Chen Wang;Junfeng Ding;Xiangyu Chen;Zelin Ye;Jialu Wang;Ziruo Cai;Cewu Lu",
        "authorids": "/37087233611;/37087325248;/37087322976;/37087324206;/37087324970;/37087322793;/37085483529;/37087233611;/37087325248;/37087322976;/37087324206;/37087324970;/37087322793;/37085483529",
        "aff": "Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University; Department of Computer Science, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968248/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3363374881421721748&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967663",
        "title": "TerrainFusion: Real-time Digital Surface Model Reconstruction based on Monocular SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an algorithm which can generate live digtial surface model (DSM) during the flight based on simultaneous localization and mapping (SLAM). We process the keyframe which is output by a monocular SLAM system to generate a local DSM, and fuse the local DSM to the global tiled DSM incrementally. During the local DSM generation, a local digital elevation model (DEM) is estimated by projecting the filtered 2D Delaunay mesh to a 3D mesh, and a local orthomosaic is obtained by projecting triangle image patches onto a 2D mesh. During the DSM fusion, both the local DEM and orthomosaic are split into tiles and fused to the global tiled DEM and orthomosaic respectively with multiband algorithm. Both the efficient DSM generation and fusion algorithms contribute to achieving a real-time reconstruction. Qualitative and quantitative experiments on a public aerial image dataset with different scenarios are performed to validate the effectiveness of the proposed method. Compared with traditional structure from motion (SfM) based approaches, the presented system is able to output both large-scale high-quality DEM and orthomosaic in real-time with low computational cost.",
        "primary_area": "",
        "author": "Wei Wang;Yong Zhao;Pengcheng Han;Pengcheng Zhao;Shuhui Bu;Wei Wang;Yong Zhao;Pengcheng Han;Pengcheng Zhao;Shuhui Bu",
        "authorids": "/37087322346;/37086205716;/37086811972;/37087322869;/37409668400;/37087322346;/37086205716;/37086811972;/37087322869;/37409668400",
        "aff": "Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967663/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8048040043506195628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northwestern Polytechnical University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.nwpu.edu.cn",
        "aff_unique_abbr": "NPU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967993",
        "title": "The ANBOT: An Intelligent Robotic Co-worker for Industrial Abrasive Blasting",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the ANBOT, an intelligent robotic coworker for physical human-robot collaboration. The ANBOT system assists workers performing industrial abrasive blasting, shielding them from the large forces experienced during this physically demanding task. The co-operative robotic system combines the strength and endurance of robots with the decision making of skilled workers. The inherent challenges in human-robot collaboration, combined with the difficult blasting environment required novel design decisions to be made and new solutions to be developed. These include an approach for handling kinematic singularities in a manner suitable for human-robot co-operation, estimating worker pose under poor visibility conditions, and an intuitive control scheme that adapts the robotic assistance based on the estimated strength of the worker. In this work we summarise the ANBOT system and present findings from preliminary site trials. The trials included several real industrial blasting tasks under the control of a skilled abrasive blasting worker who had no experience working alongside a robot. Results demonstrate the suitability of the ANBOT for practical industrial applications.",
        "primary_area": "",
        "author": "Marc G. Carmichael;Stefano Aldini;Richardo Khonasty;Antony Tran;Christian Reeks;Dikai Liu;Kenneth J. Waldron;Gamini Dissanayake;Marc G. Carmichael;Stefano Aldini;Richardo Khonasty;Antony Tran;Christian Reeks;Dikai Liu;Kenneth J. Waldron;Gamini Dissanayake",
        "authorids": "/37601543500;/37086936135;/37085669336;/37085587369;/37085775531;/37290601500;/37281582300;/37279864800;/37601543500;/37086936135;/37085669336;/37085587369;/37085775531;/37290601500;/37281582300;/37279864800",
        "aff": "Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967993/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2831515564228254868&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "8967784",
        "title": "The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot can now grasp an object more effectively than ever before, but once it has the object what happens next? We show that a mild relaxation of the task and workspace constraints implicit in existing object grasping datasets can cause neural network based grasping algorithms to fail on even a simple block stacking task when executed under more realistic circumstances. To address this, we introduce the JHU CoSTAR Block Stacking Dataset (BSD), where a robot interacts with 5.1 cm colored blocks to complete an order-fulfillment style block stacking task. It contains dynamic scenes and real time-series data in a less constrained environment than comparable datasets. There are nearly 12,000 stacking attempts and over 2 million frames of real data. We discuss the ways in which this dataset provides a valuable resource for a broad range of other topics of investigation. We find that hand-designed neural networks that work on prior datasets do not generalize to this task. Thus, to establish a baseline for this dataset, we demonstrate an automated search of neural network based models using a novel multiple-input HyperTree MetaModel, and find a final model which makes reasonable 3D pose predictions for grasping and stacking on our dataset. The CoSTAR BSD, code, and instructions are available at sites.google.com/site/costardataset.",
        "primary_area": "",
        "author": "Andrew Hundt;Varun Jain;Chia-Hung Lin;Chris Paxton;Gregory D. Hager;Andrew Hundt;Varun Jain;Chia-Hung Lin;Chris Paxton;Gregory D. Hager",
        "authorids": "/37086575744;/37087323037;/37087323836;/37085403975;/37276163200;/37086575744;/37087323037;/37087323836;/37085403975;/37276163200",
        "aff": "Department of Computer Science, Johns Hopkins University; Department of Computer Science, Johns Hopkins University; Department of Computer Science, Johns Hopkins University; NVIDIA, USA; Department of Computer Science, Johns Hopkins University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967784/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3819240000069912192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;NVIDIA",
        "aff_unique_dep": "Department of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.jhu.edu;https://www.nvidia.com",
        "aff_unique_abbr": "JHU;NV",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968139",
        "title": "The Impact of Domain Randomization on Object Detection: A Case Study on Parametric Shapes and Synthetic Textures",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in deep learning\u2013based object detection techniques have revolutionized their applicability in several fields. However, since these methods rely on unwieldy and large amounts of data, a common practice is to download models pre-trained on standard datasets and fine-tune them for specific application domains with a small set of domain\u2013relevant images. In this work, we show that using synthetic datasets that are not necessarily photo-realistic can be a better alternative to simply fine-tune pre-trained networks. Specifically, our results show an impressive 25%improvement in the mAP metric over a fine-tuning baseline when only about 200 labelled images are available to train. Finally, an ablation study of our results is presented to delineate the individual contribution of different components in the randomization pipeline.",
        "primary_area": "",
        "author": "Atabak Dehban;Jo\u00e3o Borrego;Rui Figueiredo;Plinio Moreno;Alexandre Bernardino;Jos\u00e1 Santos-Victor;Atabak Dehban;Jo\u00e3o Borrego;Rui Figueiredo;Plinio Moreno;Alexandre Bernardino;Jos\u00e1 Santos-Victor",
        "authorids": "/37085794792;/37086392388;/38546857000;/38274327100;/37442087500;/38274231800;/37085794792;/37086392388;/38546857000;/38274327100;/37442087500;/38274231800",
        "aff": "Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968139/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17883517457529310178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Universidade de Lisboa",
        "aff_unique_dep": "Institute for Systems and Robotics",
        "aff_unique_url": "https://www IST Lisbon",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Lisbon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "8967909",
        "title": "The MaSTr1325 dataset for training deep USV obstacle detection models",
        "track": "main",
        "status": "Poster",
        "abstract": "The progress of obstacle detection via semantic segmentation on unmanned surface vehicles (USVs) has been significantly lagging behind the developments in the related field of autonomous cars. The reason is the lack of large curated training datasets from USV domain required for development of data-hungry deep CNNs. This paper addresses this issue by presenting MaSTr1325, a marine semantic segmentation training dataset tailored for development of obstacle detection methods in small-sized coastal USVs. The dataset contains 1325 diverse images captured over a two year span with a real USV, covering a range of realistic conditions encountered in a coastal surveillance task. The images are per-pixel semantically labeled. The dataset exceeds previous attempts in this domain in size, scene complexity and domain realism. In addition, a dataset augmentation protocol is proposed to address slight appearance differences of the images in the training set and those in deployment. The accompanying experimental evaluation provides a detailed analysis of popular deep architectures, annotation accuracy and influence of the training set size. MaSTr1325 will be released to research community to facilitate progress in obstacle detection for USVs.",
        "primary_area": "",
        "author": "Borja Bovcon;Jon Muhovi\u010d;Janez Per\u0161;Matej Kristan;Borja Bovcon;Jon Muhovi\u010d;Janez Per\u0161;Matej Kristan",
        "authorids": "/37086214245;/37087325006;/38110704000;/37395968400;/37086214245;/37087325006;/38110704000;/37395968400",
        "aff": "Faculty of Computer and Information Science, University of Ljubljana, Slovenia; Faculty of Electrical Engineering, University of Ljubljana, Slovenia; Faculty of Electrical Engineering, University of Ljubljana, Slovenia; Faculty of Computer and Information Science, University of Ljubljana, Slovenia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967909/",
        "gs_citation": 127,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6757328251394838446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Ljubljana",
        "aff_unique_dep": "Faculty of Computer and Information Science",
        "aff_unique_url": "https://www.fcis.unilj.si",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Ljubljana",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Slovenia"
    },
    {
        "id": "8968562",
        "title": "The RGB-D Triathlon: Towards Agile Visual Toolboxes for Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep networks have brought significant advances in robot perception, enabling to improve the capabilities of robots in several visual tasks, ranging from object detection and recognition to pose estimation, semantic scene segmentation and many others. Still, most approaches typically address visual tasks in isolation, resulting in overspecialized models which achieve strong performances in specific applications but work poorly in other (often related) tasks. This is clearly sub-optimal for a robot which is often required to perform simultaneously multiple visual recognition tasks in order to properly act and interact with the environment. This problem is exacerbated by the limited computational and memory resources typically available onboard to a robotic platform. The problem of learning flexible models which can handle multiple tasks in a lightweight manner has recently gained attention in the computer vision community and benchmarks supporting this research have been proposed. In this work we study this problem in the robot vision context, proposing a new benchmark, the RGB-D Triathlon, and evaluating state of the art algorithms in this novel challenging scenario. We also define a new evaluation protocol, better suited to the robot vision setting. Results shed light on the strengths and weaknesses of existing approaches and on open issues, suggesting directions for future research.",
        "primary_area": "",
        "author": "Fabio Cermelli;Massimiliano Mancini;Elisa Ricci;Barbara Caputo;Fabio Cermelli;Massimiliano Mancini;Elisa Ricci;Barbara Caputo",
        "authorids": "/37086174513;/37086196695;/37299091700;/37271024800;/37086174513;/37086196695;/37299091700;/37271024800",
        "aff": "Politecnico di Torino, Turin, Italy; Sapienza University of Rome, Rome, Italy; Fondazione Bruno Kessler, Trento, Italy; Politecnico di Torino, Turin, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968562/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7429543580341832386&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Politecnico di Torino;Sapienza University of Rome;Fondazione Bruno Kessler",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.polito.it;https://www.uniroma1.it;https://www.fbk.eu",
        "aff_unique_abbr": "Polito;Sapienza;FBK",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Turin;Rome;Trento",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967854",
        "title": "The Robot Show Must Go On: Effective Responses to Robot Failures",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper consists of a failure analysis of two robot performance productions. Both productions included three-week rehearsal periods, and culminated in live performances including both robots and humans. To develop these productions, a theater artist collaborated with a robotics lab to develop, (1) a narrative dance performed live on stage and (2) an improvisational performance in a public space. While the interdisciplinary team did not set out to explore robot failures, failures played an ever-present role during the eighteen rehearsals and two live performances. This paper details strategies for addressing, planning for, and rehearsing responses to robot failures on stage, both technical and choreographic. In addition to scaffolding future robot theater performances, we discuss how these strategies apply to other customer- and audience-facing robots, including sponsor demos. The on-stage exploration of robot chairs and human performers also suggests that humans can conceptualize minimal robots as both characters and props, moving fluidly from one to the other. We hope these strategies ensure that future audiences will want the robot shows to go on, as well as expand ideas about the types of robots that can be cast in future human-robot productions.",
        "primary_area": "",
        "author": "Abrar Fallatah;Jeremy Urann;Heather Knight;Abrar Fallatah;Jeremy Urann;Heather Knight",
        "authorids": "/37086804073;/37086803583;/37682412600;/37086804073;/37086803583;/37682412600",
        "aff": "School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR; Arts in Interdisciplinary Studies; Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967854/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16389559946178192080&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Oregon State University;Arts in Interdisciplinary Studies",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;Interdisciplinary Studies",
        "aff_unique_url": "https://osu.edu;",
        "aff_unique_abbr": "OSU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Corvallis;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "8968022",
        "title": "The Role of Robot Payload in the Safety Map Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "In practical robotic applications various types of tools are attached for manipulating objects. Besides adding gravitational load to the robot, which results in larger joint torques, such payloads influence the collision safety characteristics through changing surface curvature properties, reflected mass and effective robot speed along a desired motion direction. In this paper, we evaluate the effect a known, unactuated pay-load that is attached to the end-effector has on the intantaneous reflected inertial parameters and maximum task velocity of a robot. The proposed mass update approach relies on the analysis of the kinetic energy matrices, while the velocity maximization is tackled by formulating static optimization problems with different constraints on angular motion of the end-effector. Finally, for analyzing the validity of the introduced approach in the framework of Safety Maps, we discuss simulation results of a PUMA 560 robot that has an exemplary payload attached to its end-effector.",
        "primary_area": "",
        "author": "Mazin Hamad;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin;Mazin Hamad;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37086346281;/38541896600;/37086148547;/37542865300;/37086346281;/38541896600;/37086148547;/37542865300",
        "aff": "Institute of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich (TUM), Germany; Institute of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich (TUM), Germany; Institute of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich (TUM), Germany; Nico Mansfeld is with the Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968022/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7995838402006958019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Technical University of Munich;German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Systems Intelligence;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tum.de;https://www.dlr.de",
        "aff_unique_abbr": "TUM;DLR",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Munich;Wessling",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968537",
        "title": "The Stability of Human Supervisory Control Operator Behavioral Models Using Hidden Markov Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Human supervisory control (HSC) is a widely used knowledge-based control scheme, in which human operators are in charge of planning and making high-level decisions for systems with embedded autonomy. With the variability of operators' behaviors in such systems, the stability of an operator modeling technique, i.e., that a modeling approach produces similar results across repeated applications, is critical to the extensibility and utility of such a model. Using an unmanned vehicle simulation testbed where such vehicles can be hacked, we compared two operator behavioral models from two different experiments using a hidden Markov modeling (HMM) approach. The resulting HMM models revealed operators' dominant strategies when conducting hacking detection tasks. The similarity between these two models was measured via multiple aspects, including model structure, state distribution, divergence distance, and co-emission probability distance. The similarity measure results demonstrate the stability of modeling human operators in HSC scenarios using HMM models. These results indicate that even when operators perform differently on specific tasks, such an approach can reliably detect whether strategies change across different experiments.",
        "primary_area": "",
        "author": "Haibei Zhu;Mary L. Cummings;Haibei Zhu;Mary L. Cummings",
        "authorids": "/37086184572;/37268062500;/37086184572;/37268062500",
        "aff": "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968537/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10402623668329342416&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968589",
        "title": "The \u201cSmellicopter,\u201d a bio-hybrid odor localizing nano air vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic airborne chemical source localization has critical applications ranging from search and rescue to hazard detection to pollution assessment. Previous demonstrations on flying robots have required search times in excess of ten minutes, or required computation-intensive signal processing, largely because of the slow response of semiconductor gas sensors. To mitigate these limitations, we developed a hybrid biological/synthetic chemical sensing platform consisting of a moth antenna on an aerial robot. We demonstrate that our robot, a 9 centimeter nano drone, can repeatedly detect and reach the source of a volatile organic chemical plume in less than a minute. We also introduce wind vanes to passively aim the robot upwind, greatly simplifying control. To our knowledge this is the first odor-finding robot to use this approach, and it allows for localization using feedback only from sensors carried on-board rather than GPS, allowing indoor operation. The chemical sensor consists of a hybrid biological/synthetic integrated chemical sensor (electroantennogram) using an excised antenna of the hawkmoth Manduca sexta and associated miniaturized electrophysiology conditioning circuitry. Our robot performs an insect-inspired cast-and-surge search algorithm inspired by the odor-tracking behavior observed in Manduca sexta. These results represent a significant step toward robots that have the speed and sensitivity of biological systems.",
        "primary_area": "",
        "author": "Melanie J. Anderson;Joseph G. Sullivan;Jennifer L. Talley;Kevin M. Brink;Sawyer B. Fuller;Thomas L. Daniel;Melanie J. Anderson;Joseph G. Sullivan;Jennifer L. Talley;Kevin M. Brink;Sawyer B. Fuller;Thomas L. Daniel",
        "authorids": "/37087324243;/37087323319;/37087321725;/38261288600;/37408404900;/37409795900;/37087324243;/37087323319;/37087321725;/38261288600;/37408404900;/37409795900",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, WA; Department of Electrical Engineering, University of Washington, Seattle, WA; Air Force Research Laboratory, Eglin AFB, FL; Air Force Research Laboratory, Eglin AFB, FL; Department of Mechanical Engineering, University of Washington, Seattle, WA; Department of Biology, University of Washington, Seattle, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968589/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5636233326843626838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "University of Washington;Air Force Research Laboratory",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://www.afresearchlab.com",
        "aff_unique_abbr": "UW;AFRL",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Seattle;Eglin AFB",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968238",
        "title": "Thermal-Inertial Odometry for Autonomous Flight Throughout the Night",
        "track": "main",
        "status": "Poster",
        "abstract": "Thermal cameras can enable autonomous flight at night without GPS. However, image-based navigation in the thermal infrared spectrum has been researched significantly less than in the visible spectrum. In this paper, we demonstrate closed-loop controlled outdoor flights at night on a quadrotor. Our state estimator can tightly couple inertial data with either thermal images at nighttime, or visual images at daytime. It is integrated in an autonomy framework for motion planning and control, which runs in real time on a standard embedded computer. We analyze thermal-inertial odometry performance extensively from sunset to sunrise, for various thermal non-uniformity levels, and compare it to visual-inertial odometry at daytime.",
        "primary_area": "",
        "author": "Jeff Delaune;Robert Hewitt;Laura Lytle;Cristina Sorice;Rohan Thakker;Larry Matthies;Jeff Delaune;Robert Hewitt;Laura Lytle;Cristina Sorice;Rohan Thakker;Larry Matthies",
        "authorids": "/37086592626;/37073604800;/37087323006;/37087322965;/37085356248;/37270488400;/37086592626;/37073604800;/37087323006;/37087322965;/37085356248;/37270488400",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968238/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13826781508370020154&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968587",
        "title": "Time Series Motion Generation Considering Long Short-Term Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Kazuki Fujimoto;Sho Sakaino;Toshiaki Tsuji;Kazuki Fujimoto;Sho Sakaino;Toshiaki Tsuji",
        "authorids": "/37086578915;/37393460500;/37287863900;/37086578915;/37393460500;/37287863900",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968587/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11483504262512841648&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "8968104",
        "title": "Time-Optimal Trajectory Generation for Dynamic Vehicles: A Bilevel Optimization Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a general framework to find time-optimal trajectories for dynamic vehicles like drones and autonomous cars. Hindered by its nonlinear objective and complex constraints, this problem is hard even for state-of the-art nonlinear programming (NLP) solvers. The proposed framework addresses the problem by bilevel optimization. Specifically, the original problem is divided into an inner layer, which computes a time-optimal velocity profile along a fixed geometric path, and an outer layer, which refines the geometric path by a Quasi-Newton method. The inner optimization is convex and efficiently solved by interior-point methods. A novel variable reordering method is introduced to accelerate the optimization of the velocity profile. The gradients of the outer layer can be derived from the Lagrange multipliers using sensitivity analysis of parametric optimization problems. The method is guaranteed to return a feasible solution at any time, and numerical experiments on a ground vehicle with friction circle dynamics model show that the proposed method performs more robustly than general NLP solvers.",
        "primary_area": "",
        "author": "Gao Tang;Weidong Sun;Kris Hauser;Gao Tang;Weidong Sun;Kris Hauser",
        "authorids": "/37086290360;/37086574363;/37543748800;/37086290360;/37086574363;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; XYZ Robotics Inc, Shanghai, China; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968104/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13841346388525451179&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;XYZ Robotics Inc",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://illinois.edu;",
        "aff_unique_abbr": "UIUC;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967770",
        "title": "Time-Varying Graph Patrolling Against Attackers with Locally Limited and Imperfect Observation Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of autonomous robots for surveillance is one of the most interesting applications of graph-patrolling algorithms. In recent years, considerable effort has been devoted to tackling the problem of efficiently computing effective patrolling strategies. One of the mainstream approaches is adversarial patrolling, where a model of a strategic attacker is explicitly taken into account. A common assumption made by these techniques is to consider a worst-case attacker, characterized by ubiquitous and perfect observation capabilities. Motivated by the domain of robotic applications, we instead consider a more realistic and limited attacker model capable of gathering noisy observations in a locally limited range of the environment. We assume that the modeled attacker follows a behavior induced by its observations. Thus, we devise a randomized patrolling strategy based on Markov chains that makes observations reveal very little information, while still maintaining a reasonable level of protection in the environment. Our experimental results obtained in simulation confirm time-variance as a practical approach for our objective.",
        "primary_area": "",
        "author": "Carlos Diaz Alvarenga;Nicola Basilico;Stefano Carpin;Carlos Diaz Alvarenga;Nicola Basilico;Stefano Carpin",
        "authorids": "/37087322862;/37545501600;/37328709200;/37087322862;/37545501600;/37328709200",
        "aff": "Department of Computer Science and Engineering, University of California, Merced, CA, USA; Department of Computer Science, University of Milan, Italy; Department of Computer Science and Engineering, University of California, Merced, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967770/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10041674895679301751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Merced;University of Milan",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.ucmerced.edu;https://www.unimi.it",
        "aff_unique_abbr": "UC Merced;UniMi",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "8968472",
        "title": "Time-delay Compensation Using Energy Tank for Satellite Dynamics Robotic Simulators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present a novel approach which compensates the destabilising effects of the time delay intrinsic in the control loop of an admittance-controlled robot employed for satellite dynamics simulation. The method is based on an energy storing element, the tank, which is exploited by the controller to preserve the passivity of the system and to avoid instability. Furthermore, we compare the performance of the proposed method with existing energy-based approaches, namely time-domain-passivity and wave variable transformation. The performance comparison and robustness of the methods are analysed in a Montecarlo simulation and validated experimentally.",
        "primary_area": "",
        "author": "Marco De Stefano;Luca Vezzadini;Cristian Secchi;Marco De Stefano;Luca Vezzadini;Cristian Secchi",
        "authorids": "/37086925998;/37087324950;/37300905500;/37086925998;/37087324950;/37300905500",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; University of Modena and Reggio Emilia, Modena, Italy; University of Modena and Reggio Emilia, Modena, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968472/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14961305669154723920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "German Aerospace Center (DLR);University of Modena and Reggio Emilia",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.dlr.de;https://www.unimore.it",
        "aff_unique_abbr": "DLR;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Modena",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "8968240",
        "title": "Timed-Elastic Smooth Curve Optimization for Mobile-Base Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the use of piecewise Cn smooth curve for mobile-base motion planning and control, coined Timed-Elastic Smooth Curve (TESC) planner. Based on a Timed-Elastic Band, the problem is defined so that the trajectory lies on a spline in SE(2) with non-vanishing n-th derivatives at every point. Formulated as a multi-objective nonlinear optimization problem, it allows imposing soft constraints such as collision-avoidance, velocity, acceleration and jerk limits, and more. The planning process is realtime-capable allowing the robot to navigate in dynamic complex scenarios. The proposed method is compared against the state-of-the-art in various scenarios. Results show that trajectories generated by the TESC planner have smaller average acceleration and are more efficient in terms of total curvature and pseudo-kinetic energy while being produced with more consistency than state-of-the-art planners do.",
        "primary_area": "",
        "author": "J\u00e9r\u00e9mie Deray;Bence Magyar;Joan Sol\u00e0;Juan Andrade-Cetto;J\u00e9r\u00e9mie Deray;Bence Magyar;Joan Sol\u00e0;Juan Andrade-Cetto",
        "authorids": "/37086110846;/37086922547;/37407733200;/38273190300;/37086110846;/37086922547;/37407733200;/38273190300",
        "aff": "CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Catalonia; Edinburgh Centre for Robotics, Heriot-Watt University, Scotland; CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Catalonia; CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Catalonia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968240/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8433562124246485283&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "CSIC-UPC;Heriot-Watt University",
        "aff_unique_dep": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;Edinburgh Centre for Robotics",
        "aff_unique_url": "https://www.csic.es;https://www.hw.ac.uk",
        "aff_unique_abbr": ";HWU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Barcelona;Edinburgh",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Spain;United Kingdom"
    },
    {
        "id": "8968514",
        "title": "Timepix Radiation Detector for Autonomous Radiation Localization and Mapping by Micro Unmanned Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "A system for measuring radiation intensity and for radiation mapping by a micro unmanned robot using the Timepix detector is presented in this paper. Timepix detectors are extremely small, but powerful 14 \u00d7 14 mm, 256 \u00d7 256 px CMOS hybrid pixel detectors, capable of measuring ionizing alpha, beta, gamma radiation, and heaving ions. The detectors, developed at CERN, produce an image free of any digital noise thanks to per-pixel calibration and signal digitization. Traces of individual ionizing particles passing through the sensors can be resolved in the detector images. Particle type and energy estimates can be extracted automatically using machine learning algorithms. This opens unique possibilities in the task of flexible radiation detection by very small unmanned robotic platforms. The detectors are well suited for the use of mobile robots thanks to their small size, lightweight, and minimal power consumption. This sensor is especially appealing for micro aerial vehicles due to their high maneuverability, which can increase the range and resolution of such novel sensory system. We present a ROS-based readout software and real-time image processing pipeline and review options for 3-D localization of radiation sources using pixel detectors. The provided software supports off-the-shelf FITPix, USB Lite readout electronics with Timepix detectors.",
        "primary_area": "",
        "author": "Tomas Baca;Martin Jilek;Petr Manek;Petr Stibinger;Vladimir Linhart;Jan Jakubek;Martin Saska;Tomas Baca;Martin Jilek;Petr Manek;Petr Stibinger;Vladimir Linhart;Jan Jakubek;Martin Saska",
        "authorids": "/37945177400;/37087322174;/37086133409;/37087322276;/37283255300;/37272136800;/37298817800;/37945177400;/37087322174;/37086133409;/37087322276;/37283255300;/37272136800;/37298817800",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague, Technicka 2, Prague 6; Faculty of Electrical Engineering, Czech Technical University in Prague, Technicka 2, Prague 6; Institute of Experimental and Applied Physics, Czech Technical University in Prague Husova 240/5, Prague 1; Faculty of Electrical Engineering, Czech Technical University in Prague, Technicka 2, Prague 6; Faculty of Nuclear Sciences and Physical Engineering, Czech Technical University in Prague, Brehova 7, Prague 1; Advacam s.r.o, U Pergamenky 12, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Technicka 2, Prague 6",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968514/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=652437663108316165&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Czech Technical University in Prague;Advacam s.r.o",
        "aff_unique_dep": "Faculty of Electrical Engineering;",
        "aff_unique_url": "https://www.cvut.cz;",
        "aff_unique_abbr": "CTU;",
        "aff_campus_unique_index": "0;0;1;0;1;0",
        "aff_campus_unique": "Prague 6;Prague;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "8967629",
        "title": "Torso-mounted Vibrotactile Interface to Experimentally Induce Illusory Own-body Perceptions",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent developments in virtual reality and robotic technologies have allowed investigating the behavioural and brain mechanisms that grounds self-consciousness in the multi-sensory (e.g. vision and touch) and sensorimotor processing of bodily signals. Yet, previous technological solutions to apply tactile stimuli for body illusion induction limit participants movements, do not allow for stimulations in dynamic environments (e.g., the subject walking), and can hardly be integrated into real-life settings and complex, interactive, virtual reality environments. Here, we present the development and first validation of a new semi-wearable haptic system, based on vibration technology, to induce a range of bodily illusions that are of relevance for research in psychiatry. This is a first step towards the development of wearable haptic systems able to administer touch and induce specific bodily illusions under dynamic conditions and in real-life settings.",
        "primary_area": "",
        "author": "Atena Fadaei Jouybari;Giulio Rognini;Masayuki Hara;Hannes Bleuler;Olaf Blanke;Atena Fadaei Jouybari;Giulio Rognini;Masayuki Hara;Hannes Bleuler;Olaf Blanke",
        "authorids": "/37087324030;/37590218000;/37301888900;/37296081800;/37542763800;/37087324030;/37590218000;/37301888900;/37296081800;/37542763800",
        "aff": "Ecole Polytechnique Federale de Lausanne (EPFL), School of Life Sciences, Brain Mind Institute, Center for Neuroprosthetics, Campus Biotech H4, Chemin des Mines 9, Genve, Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), School of Life Sciences, Brain Mind Institute, Center for Neuroprosthetics, Campus Biotech H4, Chemin des Mines 9, Genve, Switzerland; Graduate School of Science and Engineering, Saitama University, Saitama, Japan; Ecole Polytechnique Federale de Lausanne (EPFL), School of Engineering, Laboratory of Robotic Systems, Station 17, Lausanne, Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), School of Life Sciences, Brain Mind Institute, Center for Neuroprosthetics, Campus Biotech H4, Chemin des Mines 9, Genve, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967629/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15775508231205818920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne (EPFL);Saitama University;Ecole Polytechnique Federale de Lausanne",
        "aff_unique_dep": "School of Life Sciences;Graduate School of Science and Engineering;School of Engineering",
        "aff_unique_url": "https://www.epfl.ch;https://www.saitama-u.ac.jp;https://www.epfl.ch",
        "aff_unique_abbr": "EPFL;;EPFL",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Lausanne;Saitama",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Switzerland;Japan"
    },
    {
        "id": "8968546",
        "title": "Toward A Ballbot for Physically Leading People: A Human-Centered Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a new human-centered method for indoor service robots to provide people with physical assistance and active guidance while traveling through congested and narrow spaces. As most previous work is robotcentered, this paper develops an end-to-end framework which includes a feedback path of the measured human positions. The framework combines a planning algorithm and a humanrobot interaction module to guide the led person to a specified planned position. The approach is deployed on a person-size dynamically stable mobile robot, the CMU ballbot. Trials were conducted where the ballbot physically led a blindfolded person to safely navigate in a cluttered environment.",
        "primary_area": "",
        "author": "Zhongyu Li;Ralph Hollis;Zhongyu Li;Ralph Hollis",
        "authorids": "/37088691308;/37277029900;/37088691308;/37277029900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Mechanical Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968546/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11336477679643588749&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;Zhejiang University",
        "aff_unique_dep": "Robotics Institute;School of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;http://www.zju.edu.cn",
        "aff_unique_abbr": "CMU;ZJU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pittsburgh;Hangzhou",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8968002",
        "title": "Toward Achieving Formal Guarantees for Human-Aware Controllers in Human-Robot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "With the primary objective of human-robot interaction being to support humans' goals, there exists a need to formally synthesize robot controllers that can provide the desired service. Synthesis techniques have the benefit of providing formal guarantees for specification satisfaction. There is potential to apply these techniques for devising robot controllers whose specifications are coupled with human needs. This paper explores the use of formal methods to construct human-aware robot controllers to support the productivity requirements of humans. We tackle these types of scenarios via human workload-informed models and reactive synthesis. This strategy allows us to synthesize controllers that fulfill formal specifications that are expressed as linear temporal logic formulas. We present a case study in which we reason about a work delivery and pickup task such that the robot increases worker productivity, but not stress induced by high work backlog. We demonstrate our controller using the Toyota HSR, a mobile manipulator robot. The results demonstrate the realization of a robust robot controller that is guaranteed to properly reason and react in collaborative tasks with human partners.",
        "primary_area": "",
        "author": "Rachel Schlossman;Minkyu Kim;Ufuk Topcu;Luis Sentis;Rachel Schlossman;Minkyu Kim;Ufuk Topcu;Luis Sentis",
        "authorids": "/37086798175;/37073338800;/37299604900;/37426747500;/37086798175;/37073338800;/37299604900;/37426747500",
        "aff": "Departments of Mechanical Engineering (R.S., M.K.) or Aerospace Engineering (U.T., L.S.), University of Texas at Austin, Austin, USA; Departments of Mechanical Engineering (R.S., M.K.) or Aerospace Engineering (U.T., L.S.), University of Texas at Austin, Austin, USA; Departments of Mechanical Engineering (R.S., M.K.) or Aerospace Engineering (U.T., L.S.), University of Texas at Austin, Austin, USA; Departments of Mechanical Engineering (R.S., M.K.) or Aerospace Engineering (U.T., L.S.), University of Texas at Austin, Austin, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968002/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16709623238113064073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Departments of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967806",
        "title": "Toward Improving Patient Safety and Surgeon Comfort in a Synergic Robot-Assisted Eye Surgery: A Comparative Study",
        "track": "main",
        "status": "Poster",
        "abstract": "When robotic assistance is present into vitreoretinal surgery, the surgeon will experience reduced sensory input that is otherwise derived from the tool's interaction with the eye wall (sclera). We speculate that disconnecting the surgeon from this sensory input may increase the risk of injury to the eye and affect the surgeon's usual technique. On the other hand, robot autonomous motion to enhance patient safety might inhibit the surgeons tool manipulation and diminish surgeon comfort with the procedure. In this study, to investigate the parameters of patient safety and surgeon comfort in a robot-assisted eye surgery, we implemented three different approaches designed to keep the scleral force in a safe range during a synergic eye manipulation task. To assess the surgeon comfort during these procedures, the amount of interference with the surgeons usual maneuvers has been analyzed by defining quantitative comfort metrics. The first two utilized scleral force control approaches are based on an adaptive force control method in which the robot actively counteracts any excessive force on the sclera. The third control method is based on a virtual fixture approach in which a virtual wall is created for the surgeon in the unsafe directions of manipulation. The performance of the utilized approaches was evaluated in user studies with two experienced retinal surgeons and the outcomes of the procedure were assessed using the defined safety and comfort metrics. Results of these analyses indicate the significance of the opted control paradigm on the outcome of a safe and comfortable robot-assisted eye surgery.",
        "primary_area": "",
        "author": "Ali Ebrahimi;Farshid Alambeigi;Ingrid E. Zimmer-Galler;Peter Gehlbach;Russell H. Taylor;Iulian Iordachita;Ali Ebrahimi;Farshid Alambeigi;Ingrid E. Zimmer-Galler;Peter Gehlbach;Russell H. Taylor;Iulian Iordachita",
        "authorids": "/37086189127;/38542997100;/37087321906;/37547001700;/37277162900;/37330620500;/37086189127;/38542997100;/37087321906;/37547001700;/37277162900;/37330620500",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967806/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18188442423644430045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Johns Hopkins University;Johns Hopkins Hospital",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Wilmer Eye Institute",
        "aff_unique_url": "https://www.jhu.edu;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "JHU;JHH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968025",
        "title": "Toward a Bipedal Robot with Variable Gait Styles: Sagittal Forces Analysis in a Planar Simulation and a Prototype Ball-Tray Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Variable walking styles in bipedal robots may be used to communicate information about purpose and/or personality to human viewers- and may also help accommodate features of the environment. This paper presents variable gait in a simulation and results from a hardware prototype for gravity-driven rolling ball mechanism in a previously proposed bipedal design. First, optimal control inputs that produce a range of variable feasible gaits is generated on a simplified under-actuated planar model. Then, a tray-like mechanism that provides a curved path for a ball to roll on is presented. This mechanism is designed to replicate a notion of pelvic shift, described in Bartenieff Fundamentals, with movement of the ball (which is shaped by the tray) creating a shift of weight. Analysis of two gait styles and two tray designs shows comparable ranges of forces in the direction of travel between the simulated planar model and the hardware mechanism. This work is an important first step in generating feasible, stable- and variable- bipedal gaits using this hardware design.",
        "primary_area": "",
        "author": "U. Huzaifa;C. Fuller;J. Schultz;A. LaViers;U. Huzaifa;C. Fuller;J. Schultz;A. LaViers",
        "authorids": "/37085834336;/37087321847;/37890321900;/37706085100;/37085834336;/37087321847;/37890321900;/37706085100",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, IL, USA; Department of Mechanical Engineering, University of Tulsa, Tulsa, OK, USA; Department of Mechanical Engineering, University of Tulsa, Tulsa, OK, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968025/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16244838951513449670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;University of Tulsa",
        "aff_unique_dep": "Department of Mechanical Science and Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.utulsa.edu",
        "aff_unique_abbr": "UIUC;UTulsa",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Urbana-Champaign;Tulsa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967872",
        "title": "Toward a Human-Machine Interface Based on Electrical Impedance Tomography for Robotic Manipulator Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we proposed a novel human-machine interface (HMI) for robotic manipulator control. The specific target was to adjust the impedance coefficients of the robot controller in real time by measuring the human forearm muscle contractions. We firstly designed a HMI system. Different from the frequently used sEMG technologies, the interface in our study could detect muscle morphological changes within the skin by the electrical impedance tomography (EIT). The sensing front-end was a soft elastic fabric band which was compatible to different arm shapes. With the specific designed sensing hardware and the re-construction algorithms, EIT images indicating forearm muscle shapes were obtained. We then designed a hybrid positon/impedance controller on a UR5 with the impedance coefficients being tuned in real time by the grasp force estimation. A sigmoid regression algorithm was used to map the EIT images to the grasp forces. After implementation of the whole system, two experiments were carried out. The first experiment was the off-line grasp force estimation. With the 1:1 cross validation, an average R2 of 0.83\u00b10.04 and an average of the relative root mean square error (RRMSE) of 0.31\u00b10.10 across 5 subjects were yielded. The second experiment was the real-time robot control. Trajectory tracking task with dynamic uncertainties were investigated and grasp forces were estimated in real-time. With higher muscle contraction levels, smaller position errors were observed and shorter time was needed to return to the expected trajectory when there were external disturbances. The results proved the feasibility of the new approach on human-robot interaction tasks. Future endeavours will be made to get more promising results.",
        "primary_area": "",
        "author": "Enhao Zheng;Yuhua Li;Qining Wang;Hong Qiao;Enhao Zheng;Yuhua Li;Qining Wang;Hong Qiao",
        "authorids": "/38469373000;/37087323586;/37577407400;/37338715300;/38469373000;/37087323586;/37577407400;/37338715300",
        "aff": "The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences No. 95 of Zhongguancun East Road, Beijing, China; School of information engineering, China university of geosciences (Beijing), Beijing, China; The Robotics Research Group, College of Engineering, Peking University, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences No. 95 of Zhongguancun East Road, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967872/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15917547797294463875&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Chinese Academy of Sciences;China University of Geosciences;Peking University",
        "aff_unique_dep": "Institute of Automation;School of Information Engineering;College of Engineering",
        "aff_unique_url": "http://www.ia.cas.cn;http://www.cug.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "CAS;CUG;PKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968237",
        "title": "Toward a Versatile Robotic Platform for Fluoroscopy and MRI-Guided Endovascular Interventions: A Pre-Clinical Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Cardiovascular diseases remain as the most common cause of death worldwide. Remotely manipulated robotic systems are utilized to perform minimally invasive endovascular interventions. The main benefits of this methodology include reduced recovery time, improvement of clinical skills and procedural facilitation. Currently, robotic assistance, precision, and stability of instrument manipulation are compensated by the lack of haptic feedback and an excessive amount of radiation to the patient. This paper proposes a novel master-slave robotic platform that aims to bring the haptic feedback benefit on the master side, providing an intuitive user interface, and clinical familiar workflow. The slave robot is capable of manipulating conventional catheters and guidewires in multi-modal imaging environments. The system has been initially tested in a phantom cannulation study under fluoroscopic guidance, evaluating its reliability and procedural protocol. As the slave robot has been entirely produced by additive manufacturing and using pneumatic actuation, MR compatibility is enabled and was evaluated in a preliminary study. Results of both studies strongly support the applicability of the robot in different imaging environments and prospective clinical translation.",
        "primary_area": "",
        "author": "Mohamed E. M. K. Abdelaziz;Dennis Kundrat;Marco Pupillo;Giulio Dagnino;Trevor M. Y. Kwok;Wenqiang Chi;Vincent Groenhuis;Fran\u00e7oise J. Siepel;Celia Riga;Stefano Stramigioli;Guang-Zhong Yang;Mohamed E. M. K. Abdelaziz;Dennis Kundrat;Marco Pupillo;Giulio Dagnino;Trevor M. Y. Kwok;Wenqiang Chi;Vincent Groenhuis;Fran\u00e7oise J. Siepel;Celia Riga;Stefano Stramigioli;Guang-Zhong Yang",
        "authorids": "/37086453351;/37086952077;/37088726786;/38229367400;/37087324672;/37086143479;/37085817635;/37085997643;/37085591245;/37282439300;/37276270800;/37086453351;/37086952077;/37088726786;/38229367400;/37087324672;/37086143479;/37085817635;/37085997643;/37085591245;/37282439300;/37276270800",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Faculty of Medicine, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Robotics and Mechatronics, University of Twente, Enschede, Netherlands; Robotics and Mechatronics, University of Twente, Enschede, Netherlands; Faculty of Medicine, Imperial College London, UK; Robotics and Mechatronics, University of Twente, Enschede, Netherlands; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968237/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18329221585509289171&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;1;1;0;1;0",
        "aff_unique_norm": "Imperial College London;University of Twente",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery;Robotics and Mechatronics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.utwente.nl",
        "aff_unique_abbr": "Imperial College;UT",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;1;0;1;0",
        "aff_campus_unique": "London;Enschede",
        "aff_country_unique_index": "0;0;0;0;0;0;1;1;0;1;0",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "8968101",
        "title": "Toward an Efficient Hybrid Interaction Paradigm for Object Manipulation in Optical See-Through Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-computer interaction (HCI) plays an important role in the near-field mixed reality, in which the hand-based interaction is one of the most widely-used interaction modes, especially in the applications based on optical see-through head-mounted displays (OST-HMDs). In this paper, such interaction modes as gesture-based interaction (GBI) and physics-based interaction (PBI) are developed to construct a mixed reality system to evaluate the advantages and disadvantages of different interaction modes. The ultimate goal is to find an efficient hybrid paradigm for mixed reality applications based on OST-HMDs to deal with the situations that a single interaction mode cannot handle. The results of the experiment, which compares GBI and PBI, show that PBI leads to a better performance of users regarding their work efficiency in the proposed two tasks. Some statistical tests, including T-test and one-way ANOVA, have also been adopted to prove that the difference regarding the efficiency between different interaction modes is significant. Experiments for combining both interaction modes are put forward in order to seek a good experience for manipulation, which proves that the partially-overlapping style would help to improve work efficiency for manipulation tasks. The experimental results of the proposed two hand-based interaction modes and their hybrid forms can provide some practical suggestions for the development of mixed reality systems based on OST-HMDs.",
        "primary_area": "",
        "author": "Zhenliang Zhang;Dongdong Weng;Jie Guo;Yue Liu;Yongtian Wang;Zhenliang Zhang;Dongdong Weng;Jie Guo;Yue Liu;Yongtian Wang",
        "authorids": "/37086007743;/37410110800;/37673706800;/37279419700;/37281433500;/37086007743;/37410110800;/37673706800;/37279419700;/37281433500",
        "aff": "Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968101/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12772796295895851570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Optics and Photonics",
        "aff_unique_url": "http://www.bit.edu.cn",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967682",
        "title": "Toward model-based benchmarking of robot components",
        "track": "main",
        "status": "Poster",
        "abstract": "The results of scientific experiments performed by different groups are rarely directly comparable. Efforts such as the European Robotics League offer to the community, in the form of competitions, well documented and stable benchmarks to assess the performance of existing systems. However, benchmarks can be equally useful at design time: the Plug&Bench Benchmark Meta-model provides robot designers with a valuable addition to their toolkit. Additionally, it enables -with benchmark composition-to predict system performance given the benchmark results of individual components.",
        "primary_area": "",
        "author": "Gianluca Bardaro;Mohamed El-Shamouly;Giulio Fontana;Ramez Awad;Matteo Matteucci;Gianluca Bardaro;Mohamed El-Shamouly;Giulio Fontana;Ramez Awad;Matteo Matteucci",
        "authorids": "/37086046655;/37087321805;/38556473400;/37085689016;/37298639000;/37086046655;/37087321805;/38556473400;/37085689016;/37298639000",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967682/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12069689482084566190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Politecnico di Milano;Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;",
        "aff_unique_url": "https://www.polimi.it;https://www.ipa.fraunhofer.de/",
        "aff_unique_abbr": "Politecnico di Milano;Fraunhofer IPA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "8967591",
        "title": "Towards A Generic In Vivo In Situ Camera Lens Cleaning Module for Laparoscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a generic cleaning module to address lens fogging and soiling problems for insertable robotic cameras in laparoscopic surgery. The proposed lens cleaning module features minimal intraoperative interruption for surgeons to maintain clear visual field. The technical challenges for developing such a compact modular design involve confining the wiping mechanism within small space, yet delivering sufficient energy for the lens cleaning task. Inspired by thermo-activated phase transformation of shape memory alloy, we develop an effective mesoscale actuation mechanism to overcome the design challenges. A prototype is designed and manufactured for performance evaluation. The design effectiveness was verified by experiments.",
        "primary_area": "",
        "author": "Xiaolong Liu;Hui Liu;Jindong Tan;Xiaolong Liu;Hui Liu;Jindong Tan",
        "authorids": "/37085403010;/37086947266;/37065245900;/37085403010;/37086947266;/37065245900",
        "aff": "Department of Mechanical, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, University of Tennessee, Knoxville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967591/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9994605995472153894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tennessee",
        "aff_unique_dep": "Department of Mechanical",
        "aff_unique_url": "https://www.utk.edu",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Knoxville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968241",
        "title": "Towards Autonomous Industrial-Scale Bathymetric Surveying",
        "track": "main",
        "status": "Poster",
        "abstract": "Both higher efficiency and cost reduction can be gained from automating bathymetric surveying for offshore applications such as pipeline, telecommunication or power cables installation and inspection on the seabed. We present a SLAM system that optimizes the geo-referencing of bathymetry surveys by fusing the dead-reckoning sensor data from the surveying vehicle with constraints from the maximization of the geometric consistency of overlapping regions of the survey. The framework has been extensively tested on bathymetric maps from both simulation and several actual industrial surveys and has proved robustness over different types of terrain. We demonstrate that our system is able to maximize the consistency of the final map even when there are large sections of the survey with reduced topographic variation. The framework has been made publicly available together with the simulation environment used to test it and some of the datasets.",
        "primary_area": "",
        "author": "Ignacio Torroba;Nils Bore;John Folkesson;Ignacio Torroba;Nils Bore;John Folkesson",
        "authorids": "/37086852366;/37085532225;/37282372400;/37086852366;/37085532225;/37282372400",
        "aff": "Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968241/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13429948479536364081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "8967628",
        "title": "Towards Ergonomic Control of Collaborative Effort in Multi-human Mobile-robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a control framework for a multi-human and mobile-robot collaborative team, that takes into account the co-workers' ergonomic requirements as well as the demand for high flexibility in the manufacturing industries. The new MObile Collaborative robotic Assistant (MOCA), which is composed of a lightweight manipulator arm, an underactuated hand, and a mobile platform driven by four omni-directional wheels enabling mobility in the workspace, is able to accomplish multiple tasks in a wide area with a high level of adaptability. In addition, an ergonomics module to anticipate and mitigate the human risk factors by means of a multi-object optimisation is integrated into the framework to ensure human safety and improvement of working conditions. The main advantage of this approach is that MOCA can assist multiple human operators, reducing their physical risks, with fast-adaptive capacities due to agile mobility and advanced interaction and manipulation. We validated the proposed method with an experiment simulating a simple manufacturing line which involves two subjects and the MOCA. The results demonstrate that the proposed framework is able to address multi-workers' ergonomics with a high level of flexibility in the workplace.",
        "primary_area": "",
        "author": "Wansoo Kim;Marta Lorenzini;Pietro Balatti;Yuqiang Wu;Arash Ajoudani;Wansoo Kim;Marta Lorenzini;Pietro Balatti;Yuqiang Wu;Arash Ajoudani",
        "authorids": "/37086291232;/37086249968;/37086577439;/37086920085;/37945239900;/37086291232;/37086249968;/37086577439;/37086920085;/37945239900",
        "aff": "HRI2 Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967628/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16913654555795957041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "HRI2 Laboratory",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968117",
        "title": "Towards Explainable Shared Control using Augmented Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared control plays a pivotal role in establishing effective human-robot interactions. Traditional control-sharing methods strive to complement a human's capabilities at safely completing a task, and thereby rely on users forming a mental model of the expected robot behaviour. However, these methods can often bewilder or frustrate users whenever their actions do not elicit the intended system response, forming a misalignment between the respective internal models of the robot and human. To resolve this model misalignment, we introduce Explainable Shared Control as a paradigm in which assistance and information feedback are jointly considered. Augmented reality is presented as an integral component of this paradigm, by visually unveiling the robot's inner workings to human operators. Explainable Shared Control is instantiated and tested for assistive navigation in a setup involving a robotic wheelchair and a Microsoft HoloLens with add-on eye tracking. Experimental results indicate that the introduced paradigm facilitates transparent assistance by improving recovery times from adverse events associated with model misalignment.",
        "primary_area": "",
        "author": "Mark Zolotas;Yiannis Demiris;Mark Zolotas;Yiannis Demiris",
        "authorids": "/37086096013;/37296338900;/37086096013;/37296338900",
        "aff": "Personal Robotics Lab, Imperial College, London, UK; Personal Robotics Lab, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968117/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15963692404780761333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Personal Robotics Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968451",
        "title": "Towards Generalizing Sensorimotor Control Across Weather Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability of deep learning models to generalize well across different scenarios depends primarily on the quality and quantity of annotated data. Labeling large amounts of data for all possible scenarios that a model may encounter would not be feasible; if even possible. We propose a framework to deal with limited labeled training data and demonstrate it on the application of vision-based vehicle control. We show how limited steering angle data available for only one condition can be transferred to multiple different weather scenarios. This is done by leveraging unlabeled images in a teacher-student learning paradigm complemented with an image-to-image translation network. The translation network transfers the images to a new domain, whereas the teacher provides soft supervised targets to train the student on this domain. Furthermore, we demonstrate how utilization of auxiliary networks can reduce the size of a model at inference time, without affecting the accuracy. The experiments show that our approach generalizes well across multiple different weather conditions using only ground truth labels from one domain.",
        "primary_area": "",
        "author": "Qadeer Khan;Patrick Wenzel;Daniel Cremers;Laura Leal-Taix\u00e9;Qadeer Khan;Patrick Wenzel;Daniel Cremers;Laura Leal-Taix\u00e9",
        "authorids": "/37087321707;/37087322550;/37282875300;/38286861700;/37087321707;/37087322550;/37282875300;/38286861700",
        "aff": "Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968451/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6562800340780384707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967552",
        "title": "Towards Jumping Locomotion for Quadruped Robots on the Moon",
        "track": "main",
        "status": "Poster",
        "abstract": "Jumping locomotion has the potential to enable legged robots to overcome obstacles and travel efficiently on low-gravity celestial bodies. We present how the 22 kg quadruped robot SpaceBok exploits lunar gravity conditions to perform energy-efficient jumps. The robot achieves repetitive, vertical jumps of more than 0.9m meter and powerful single leaps of up to 1.3m. We present the implementation of a reaction wheel, which allows for control of the robots pitch orientation during the flight phase. We also demonstrate the implementation of a parallel elasticity in the legs providing the capability of temporarily storing and reusing energy during jumping. The jumping and attitude controller are subsequently presented. Finally, we analyze the energetics of the system and show that jumping with the integrated elasticity significantly reduces energy consumption compared to non-elastic jumps.",
        "primary_area": "",
        "author": "Hendrik Kolvenbach;Elias Hampp;Patrick Barton;Radek Zenkl;Marco Hutter;Hendrik Kolvenbach;Elias Hampp;Patrick Barton;Radek Zenkl;Marco Hutter",
        "authorids": "/37086574705;/37086936042;/37086934049;/37086937332;/37545251000;/37086574705;/37086936042;/37086934049;/37086937332;/37545251000",
        "aff": "Robotic Systems Lab (RSL) at ETH Zurich, Switzerland; Robotic Systems Lab (RSL) at ETH Zurich, Switzerland; Robotic Systems Lab (RSL) at ETH Zurich, Switzerland; Robotic Systems Lab (RSL) at ETH Zurich, Switzerland; Robotic Systems Lab (RSL) at ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967552/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14740642047497066050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968038",
        "title": "Towards More Realistic Human-Robot Conversation: A Seq2Seq-based Body Gesture Interaction System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel system that enables intelligent robots to exhibit realistic body gestures while communicating with humans. The proposed system consists of a listening model and a speaking model used in corresponding conversational phases. Both models are adapted from the sequence-to-sequence (seq2seq) architecture to synthesize body gestures represented by the movements of twelve upper-body keypoints. All the extracted 2D keypoints are firstly 3D-transformed, then rotated and normalized to discard irrelevant information. Substantial videos of human conversations from Youtube are collected and preprocessed to train the listening and speaking models separately, after which the two models are evaluated using metrics of mean squared error (MSE) and cosine similarity on the test dataset. The tuned system is implemented to drive a virtual avatar as well as Pepper, a physical humanoid robot, to demonstrate the improvement on conversational interaction abilities of our method in practice.",
        "primary_area": "",
        "author": "Minjie Hua;Fuyuan Shi;Yibing Nan;Kai Wang;Hao Chen;Shiguo Lian;Minjie Hua;Fuyuan Shi;Yibing Nan;Kai Wang;Hao Chen;Shiguo Lian",
        "authorids": "/37086935028;/37087322498;/37087325245;/37086234522;/37986428800;/37086232924;/37086935028;/37087322498;/37087325245;/37086234522;/37986428800;/37086232924",
        "aff": "CloudMinds Technologies Inc., Beijing, China; CloudMinds Technologies Inc., Beijing, China; CloudMinds Technologies Inc., Beijing, China; CloudMinds Technologies Inc., Beijing, China; CloudMinds Technologies Inc., Beijing, China; CloudMinds Technologies Inc., Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968038/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7042071056978559814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "CloudMinds Technologies Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cloudminds.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968270",
        "title": "Towards Reversible Dynamic Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present an initial approach towards reversible robot movement primitives. Our approach is a modification of Dynamic Movement Primitives (DMPs), a widely used framework for robot learning from demonstration. DMPs are based on dynamical systems to guarantee properties such as convergence to a goal state, robustness to perturbation, and the ability to generalize to other goal states. Yet a main limitation of their original formulation is that they do not allow for movements to be reversed. Thus, to execute the same task forwards and backwards would mean to learn two separate primitives. We propose to replace the transformation system in DMPs with the Logistic Differential Equation (LDE), a known time-reversible non-linear system. Similarly to the original DMP formulation, our system's temporal evolution is controlled by a phase system, which in our case is derived from the LDE to guarantee reversibility. We evaluate our approach experimentally with demonstration data from a real robot assembly task, and show comparable properties to those of the original DMP system.",
        "primary_area": "",
        "author": "I\u00f1igo Iturrate;Christoffer Sloth;Alja\u017e Kramberger;Henrik Gordon Petersen;Esben Hallundb\u00e6k \u00d8stergaard;Thiusius Rajeeth Savarimuthu;I\u00f1igo Iturrate;Christoffer Sloth;Alja\u017e Kramberger;Henrik Gordon Petersen;Esben Hallundb\u00e6k \u00d8stergaard;Thiusius Rajeeth Savarimuthu",
        "authorids": "/37086185479;/37547023600;/37085387168;/37562505800;/38222653400;/37946053800;/37086185479;/37547023600;/37085387168;/37562505800;/38222653400;/37946053800",
        "aff": "Maersk McKinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk McKinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk McKinney Moller Institute, University of Southern Denmark, Odense, Denmark; Maersk McKinney Moller Institute, University of Southern Denmark, Odense, Denmark; Universal Robots A/S, Odense, Denmark; Maersk McKinney Moller Institute, University of Southern Denmark, Odense, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968270/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3326137913134659887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Southern Denmark;Universal Robots A/S",
        "aff_unique_dep": "Maersk McKinney Moller Institute;",
        "aff_unique_url": "https://www.sdu.dk;https://www.universal-robots.com",
        "aff_unique_abbr": "SDU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Odense;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "8967941",
        "title": "Towards a Natural Motion Generator: a Pipeline to Control a Humanoid based on Motion Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation of the upper body motions of human demonstrators or animation characters to human-shaped robots is studied in this paper. We present a pipeline for motion retargeting by transferring the joints of interest (JOI) of source motions to the target humanoid robot. To this end, we deploy an optimization-based motion retargeting method utilizing link length modifications of the source skeleton and a task (Cartesian) space fine-tuning of JOI motion descriptors. To evaluate the effectiveness of the proposed pipeline, we use two different 3-D motion datasets from three human demonstrators and an Ogre animation character, Bork, and successfully transfer the motions to four different humanoid robots: DARwIn-OP, COmpliant HuMANoid Platform (COMAN), THORMANG, and Atlas. Furthermore, COMAN and THORMANG are actually controlled to show that the proposed method can be deployed to physical robots.",
        "primary_area": "",
        "author": "Sungjoon Choi;Joohyung Kim;Sungjoon Choi;Joohyung Kim",
        "authorids": "/37085405040;/37085576403;/37085405040;/37085576403",
        "aff": "Disney Research, 521 Circle Seven Drive, Glendale, CA, USA; Disney Research, 521 Circle Seven Drive, Glendale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967941/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9665204029310293366&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Disney Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.disney.com",
        "aff_unique_abbr": "Disney Research",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Glendale",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968166",
        "title": "Towards a Robot Architecture for Situated Lifelong Object Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",
        "primary_area": "",
        "author": "Jose L. Part;Oliver Lemon;Jose L. Part;Oliver Lemon",
        "authorids": "/37086360853;/37298847200;/37086360853;/37298847200",
        "aff": "Edinburgh Centre for Robotics, Edinburgh, Scotland, UK; Heriot-Watt University, Edinburgh, Scotland, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968166/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15981914182606127883&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Edinburgh Centre for Robotics;Heriot-Watt University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.hw.ac.uk",
        "aff_unique_abbr": ";HWU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968163",
        "title": "Towards a Robust Aerial Cinematography Platform: Localizing and Tracking Moving Targets in Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of drones for aerial cinematography has revolutionized several applications and industries that require live and dynamic camera viewpoints such as entertainment, sports, and security. However, safely controlling a drone while filming a moving target usually requires multiple expert human operators; hence the need for an autonomous cinematographer. Current approaches have severe real-life limitations such as requiring fully scripted scenes, high-precision motion-capture systems or GPS tags to localize targets, and prior maps of the environment to avoid obstacles and plan for occlusion.In this work, we overcome such limitations and propose a complete system for aerial cinematography that combines: (1) a vision-based algorithm for target localization; (2) a real-time incremental 3D signed-distance map algorithm for occlusion and safety computation; and (3) a real-time camera motion planner that optimizes smoothness, collisions, occlusions and artistic guidelines. We evaluate robustness and real-time performance in series of field experiments and simulations by tracking dynamic targets moving through unknown, unstructured environments. Finally, we verify that despite removing previous limitations, our system achieves state-of-the-art performance.",
        "primary_area": "",
        "author": "Rogerio Bonatti;Cherie Ho;Wenshan Wang;Sanjiban Choudhury;Sebastian Scherer;Rogerio Bonatti;Cherie Ho;Wenshan Wang;Sanjiban Choudhury;Sebastian Scherer",
        "authorids": "/37086934741;/38489350800;/37087322184;/37077381500;/37584159000;/37086934741;/38489350800;/37087322184;/37077381500;/37584159000",
        "aff": "The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; School of Computer Science and Engineering, University of Washington, Seattle, WA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968163/",
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11559858830595151396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Washington",
        "aff_unique_dep": "School of Computer Science;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.washington.edu",
        "aff_unique_abbr": "CMU;UW",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968280",
        "title": "Towards an Open-Source Micro Robot Oceanarium: A Low-Cost, Modular, and Mobile Underwater Motion-Capture System",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro autonomous underwater vehicles (\u03bcAUVs) allow early-stage experimental testing even in small tanks. In contrast to large facilities, these tanks are usually not equipped with high-fidelity motion capture systems due to high cost and reduced required accuracy for proof-of-concept testing.In this work, we introduce low-cost and open-source motion capture architecture based on fiducial markers for small research tanks. We propose a highly modular approach which allows straight-forward adaptation to individual user needs. We demonstrate the performance of our architecture in two experimental setups.",
        "primary_area": "",
        "author": "Daniel A. Duecker;Kevin Eusemann;Edwin Kreuzer;Daniel A. Duecker;Kevin Eusemann;Edwin Kreuzer",
        "authorids": "/37086262227;/37087323684;/37622316900;/37086262227;/37087323684;/37622316900",
        "aff": "Institute of Mechanics and Ocean Engineering, Hamburg University of Technology, Germany; Institute of Mechanics and Ocean Engineering, Hamburg University of Technology, Germany; Institute of Mechanics and Ocean Engineering, Hamburg University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968280/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1374167744077549852&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hamburg University of Technology",
        "aff_unique_dep": "Institute of Mechanics and Ocean Engineering",
        "aff_unique_url": "https://www.tuhh.de/",
        "aff_unique_abbr": "TUHH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hamburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8968186",
        "title": "Towards the Design and Development of a Pediatric Neuroendoscope Tool",
        "track": "main",
        "status": "Poster",
        "abstract": "Hydrocephalus in the pediatric population is often treated with endoscopic procedures, in which a rigid endoscope provides a working channel and needed visualization for brain manipulation. The lack of flexible and steerable endoscopic tools limits the ability of the surgeon to conduct complex operations. In this paper, we propose the design of a novel tool for such procedures that uses the compliance of a bending flexural joint to build a compact steerable multi-joint tool. These joints are machined into a tube made of a super-elastic material to create two joints near the tip of the tool. The directional stiffness properties of the flexural joint are exploited to minimize inter-joint coupling. We perform a static analysis of each joint and a kinematic analysis of the entire robot. We follow this with the design of a hand-held controller for this robot, and analyze its ability to control multiple degrees-of-freedom of the robot while minimizing the coupling between joints.",
        "primary_area": "",
        "author": "Yash Chitalia;Seokhwan Jeong;Ji Bok;Vinh Nguyen;Shreyes Melkote;Joshua J. Chern;Jaydev P. Desai;Yash Chitalia;Seokhwan Jeong;Ji Bok;Vinh Nguyen;Shreyes Melkote;Joshua J. Chern;Jaydev P. Desai",
        "authorids": "/37085813464;/37087324027;/37087323912;/37086040597;/37449528700;/37087322357;/37282117700;/37085813464;/37087324027;/37087323912;/37086040597;/37449528700;/37087322357;/37282117700",
        "aff": "Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Children\u2019s Healthcare of Atlanta, Atlanta, GA, USA; Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968186/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16470879548720715874&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Children\u2019s Healthcare of Atlanta",
        "aff_unique_dep": "Medical Robotics and Automation (RoboMed) Laboratory;",
        "aff_unique_url": "https://www.gatech.edu;https://www.choa.org/",
        "aff_unique_abbr": "Georgia Tech;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968569",
        "title": "Tracking Control of Fully-Constrained Cable-Driven Parallel Robots using Adaptive Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new adaptive tracking controller with learning ability is proposed for fully-constrained cable-driven parallel robots (CDPRs). For these systems, the necessity of maintaining positive and bounded tensions in all cables while coping with disturbances represents a critical control requirement. To achieve this goal, we propose a control law based on adaptive dynamic programming (ADP), with an actorcritic structure. In the critic part, an artificial neural network (NN) approximates the value function which is to evaluate the system performance; in the action part, the controller\u2019s parameters are tuned online to achieve optimal control performance. Additionally, the anti-windup (AW) technique is combined with the adaptive controller to cope with the input saturation problem. The stability of the closed-loop system with the proposed control algorithm is proved using the Lyapunov method. Numerical simulations show the effectiveness of the proposed controller.",
        "primary_area": "",
        "author": "Shuai Li;Damiano Zanotto;Shuai Li;Damiano Zanotto",
        "authorids": "/37086085139;/37887906100;/37086085139;/37887906100",
        "aff": "Dept. of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Dept. of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968569/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3418481100841309550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967995",
        "title": "Training in Task Space to Speed Up and Guide Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent breakthroughs in the reinforcement learning (RL) community have made significant advances towards learning and deploying policies on real world robotic systems. However, even with current state-of-the-art algorithms and computational resources, these methods are still plagued with high sample complexity, and thus long training times, especially for high degree of freedom (DOF) systems. There are also concerns arising from lack of perceived stability or robustness from emerging policies. This paper aims at mitigating these drawbacks by: (1) modeling a complex, high DOF system with a representative simple one, (2) making explicit use of forward and inverse kinematics without forcing the RL algorithm to \u201clearn\u201d them on its own, and (3) learning locomotion policies in Cartesian space instead of joint space. In this paper, these methods are applied to JPL's Robosimian, but they can be readily used on any system with a base and end effector(s). These locomotion policies can be produced in just a few minutes, trained on a single laptop. We compare the robustness of the resulting learned policies to those of other control methods.",
        "primary_area": "",
        "author": "Guillaume Bellegarda;Katie Byl;Guillaume Bellegarda;Katie Byl",
        "authorids": "/37086456120;/37569022700;/37086456120;/37569022700",
        "aff": "Robotics Laboratory, University of California at Santa Barbara (UCSB); Robotics Laboratory, University of California at Santa Barbara (UCSB)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967995/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12418396710287594161&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California at Santa Barbara",
        "aff_unique_dep": "Robotics Laboratory",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967579",
        "title": "Trajectory Estimation for Geo-Fencing Applications on Small-Size Fixed-Wing UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "The steadily increasing popularity of Unmanned Aerial Vehicles (UAVs) is creating new opportunities in diverse fields of technology and business. However, this increase of popularity also raises safety concerns. To tackle the primary concern of keeping the UAV inside a designated region, a novel trajectory estimation algorithm for geo-fencing applications is proposed. We derive the Beta-Trajectory that takes into account constraints in curvature as well as constraints in the change of curvature which is bounded by the maximum roll-rate of the aircraft. We incorporate the Beta-Trajectory into a geo-fencing algorithm. By using our open-source uavAP autopilot, the applicability and necessity of accurate trajectory estimation algorithms for geo-fencing applications are shown on small fixed-wing aircraft. The model and algorithm are validated in high-fidelity simulations as well as in real flight testing.",
        "primary_area": "",
        "author": "Mirco Theile;Simon Yu;Or D. Dantsker;Marco Caccamo;Mirco Theile;Simon Yu;Or D. Dantsker;Marco Caccamo",
        "authorids": "/37086532277;/37087321737;/38564345700;/37272874700;/37086532277;/37087321737;/38564345700;/37272874700",
        "aff": "TUM Department of Mechanical Engineering, Technical University of Munich, Germany; Dept. of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL; TUM Department of Mechanical Engineering, Technical University of Munich, Germany; TUM Department of Mechanical Engineering, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967579/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7352167583000787324&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Technical University of Munich;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Engineering;Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tum.de;https://illinois.edu",
        "aff_unique_abbr": "TUM;UIUC",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Munich;Urbana",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "8968010",
        "title": "Trajectory Optimization for Unknown Constrained Systems using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a reinforcement learning-based algorithm for trajectory optimization for constrained dynamical systems. This problem is motivated by the fact that for most robotic systems, the dynamics may not always be known. Generating smooth, dynamically feasible trajectories could be difficult for such systems. Using sampling-based algorithms for motion planning may result in trajectories that are prone to undesirable control jumps. However, they can usually provide a good reference trajectory which a model-free reinforcement learning algorithm can then exploit by limiting the search domain and quickly finding a dynamically smooth trajectory. We use this idea to train a reinforcement learning agent to learn a dynamically smooth trajectory in a curriculum learning setting. Furthermore, for generalization, we parameterize the policies with goal locations, so that the agent can be trained for multiple goals simultaneously. We show result in both simulated environments as well as real experiments, for a 6-DoF manipulator arm operated in position-controlled mode to validate the proposed idea. We compare the proposed ideas against a PID controller which is used to track a designed trajectory in configuration space. Our experiments show that our RL agent trained with a reference path outperformed a model-free PID controller of the type commonly used on many robotic platforms for trajectory tracking.",
        "primary_area": "",
        "author": "Kei Ota;Devesh K. Jha;Tomoaki Oiki;Mamoru Miura;Takashi Nammoto;Daniel Nikovski;Toshisada Mariyama;Kei Ota;Devesh K. Jha;Tomoaki Oiki;Mamoru Miura;Takashi Nammoto;Daniel Nikovski;Toshisada Mariyama",
        "authorids": "/37087323962;/37072717800;/37714551300;/37087324704;/37085473800;/37284684700;/37087323162;/37087323962;/37072717800;/37714551300;/37087324704;/37085473800;/37284684700;/37087323162",
        "aff": "Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Mitsubishi Electric Research Labs, Cambridge, MA, USA; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Mitsubishi Electric Research Labs, Cambridge, MA, USA; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968010/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15382818759303304693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;1;0",
        "aff_unique_norm": "Mitsubishi Electric Corporation;Mitsubishi Electric Research Labs",
        "aff_unique_dep": "Information Technology R&D Center;",
        "aff_unique_url": "https://www.mitsubishielectric.com;https://www.merl.com",
        "aff_unique_abbr": "MEC;MERL",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;0;0;0;1;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "8968450",
        "title": "Trajectory planning for a bat-like flapping wing robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning flight trajectories is important for practical application of flying systems. This topic has been well studied for fixed and rotary winged aerial vehicles, but far fewer works have explored it for flapping systems. Bat Bot (B2) is a bio-inspired flying robot that mimics bat flight, and it possesses the ability to follow a designed trajectory with its on-board electronics and sensing. However, B2's periodic flapping and its complex aerodynamics present major challenges in modeling and planning feasible flight paths. In this paper, we present a generalized approach that uses a model with direct collocation methods to plan dynamically feasible flight maneuvers. The model is made to be both accurate through collection of load cell force data for parameter selection and computationally inexpensive such that it can be used efficiently in a nonlinear solver. We compute the trajectory of launching B2 to a desired altitude and a banked turn maneuver, and we validate our methods with experimental flight results of tracking the launch trajectory with a PD controller.",
        "primary_area": "",
        "author": "Jonathan Hoff;Usman Syed;Alireza Ramezani;Seth Hutchinson;Jonathan Hoff;Usman Syed;Alireza Ramezani;Seth Hutchinson",
        "authorids": "/37087321873;/37086000427;/37398489300;/37282386200;/37087321873;/37086000427;/37398489300;/37282386200",
        "aff": "Coordinated Science Laboratory, University of Illinois at Urbana-Champaign (UIUC), USA; Coordinated Science Laboratory, University of Illinois at Urbana-Champaign (UIUC), USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Coordinated Science Laboratory, University of Illinois at Urbana-Champaign (UIUC), USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968450/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17757220913299024157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Northeastern University",
        "aff_unique_dep": "Coordinated Science Laboratory;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cs.uiuc.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "UIUC;NU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Urbana-Champaign;Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967571",
        "title": "Transfer learning for vision-based tactile sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the complexity of modeling the elastic properties of materials, the use of machine learning algorithms is continuously increasing for tactile sensing applications. Recent advances in deep neural networks applied to computer vision make vision-based tactile sensors very appealing for their high-resolution and low cost. A soft optical tactile sensor that is scalable to large surfaces with arbitrary shape is discussed in this paper. A supervised learning algorithm trains a model that is able to reconstruct the normal force distribution on the sensor's surface, purely from the images recorded by an internal camera. In order to reduce the training times and the need for large datasets, a calibration procedure is proposed to transfer the acquired knowledge across multiple sensors while maintaining satisfactory performance.",
        "primary_area": "",
        "author": "Carmelo Sferrazza;Raffaello D\u2019Andrea;Carmelo Sferrazza;Raffaello D\u2019Andrea",
        "authorids": "/37085991609;/38525077800;/37085991609;/38525077800",
        "aff": "ETH Zurich, Institute for Dynamic Systems and Control, Switzerland; ETH Zurich, Institute for Dynamic Systems and Control, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967571/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10104472329878663249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8968282",
        "title": "Transferable Trial-Minimizing Progressive Peg-in-hole Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Peg-in-hole is a fine-level manipulation task that requires highly precise location and the normal direction of the hole, which is beyond state-of-the-art object detectors' capability. Therefore, we propose a novel method that trains a robot arm to progressively search for the right inserting pose through trials with both force feedback and visual inputs. Under a reinforcement learning (RL) framework, an agent trying to minimize the number of trials is learned based on the sequentially estimated relative poses with regard to the correct inserting pose. Moreover, our learned dynamics model is transferable. Thanks to our context-independent force and visual feature design, our pre-trained model can be finetuned efficiently for another unseen peg-in-hole case. Extensive experiments show the effectiveness of the proposed framework.",
        "primary_area": "",
        "author": "Junfeng Ding;Chen Wang;Cewu Lu;Junfeng Ding;Chen Wang;Cewu Lu",
        "authorids": "/37087325248;/37087233611;/37085483529;/37087325248;/37087233611;/37085483529",
        "aff": "Department of Computer Science, Shanghai Jiao Tong University, China; Department of Computer Science, Shanghai Jiao Tong University, China; Department of Computer Science, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968282/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17998813139362264673&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967932",
        "title": "Trust But Verify: A Distributed Algorithm for Multi-Robot Wireframe Exploration and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel distributed mapping algorithm for multiple resource-constrained robots operating in a rectilinear 2D environment. The algorithm is built upon the sparse wireframe map representation and updating framework in [1]. We propose an exploration strategy based on the labeling of the vertices in the wireframe map, combined with a map-merging interrupt routine that is activated when robots enter into communication range with one another. The maps are not naively merged, but instead the receiving robot verifies the received information before it is assimilated by attempting to drive to the location where the other robot was when communication was established. The robots do not share a global coordinate frame, so prior to a merge the relative map alignment is determined. This is achieved using the random sample consensus (RANSAC) framework with a custom feature which leverages the structure inherent in the wireframe map representation. This results in a lower rate of false-positive matches compared to another state-of-the-art feature used in point cloud alignment, the 4-point congruent set (4PCS). We show our feature to be more robust to false-positive alignments, a common occurrence when attempting to align sparse structures such as wireframe maps. We present high fidelity simulation results in a ROS-Gazebo environment with lidar-equipped TurtleBots1 to highlight the benefits of our algorithm.1The TurtleBot3 burger configuration www.turtlebot.com.",
        "primary_area": "",
        "author": "Adam Caccavale;Mac Schwager;Adam Caccavale;Mac Schwager",
        "authorids": "/37598694000;/37424620600;/37598694000;/37424620600",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967932/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4464227319878123813&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968481",
        "title": "Twin Kinematics Approach for Robotic-Assisted Tele-Echography",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses a new teleoperation approach for robotic-assisted tele-echography. A teleoperation architecture in the joint space is presented, taking advantage of kinematic similarity between master and slave manipulators. Haptic force feedback is provided based on the slave control command torque, without using force/torque sensing data. The slave manipulator is controlled in the joint space using computed torque techniques and featuring Kalman Active Observers (AOBs). Experiments in a typical telemedice scenario, assess and validate the teleoperation architecture in a clinical context, with a radiologist performing a robotic-assisted abdominal ultrasound examination on a healthy volunteer.",
        "primary_area": "",
        "author": "Luis Santos;Rui Cortes\u00e3o;Jo\u00e3o Quintas;Luis Santos;Rui Cortes\u00e3o;Jo\u00e3o Quintas",
        "authorids": "/37359276900;/37275934700;/37846261900;/37359276900;/37275934700;/37846261900",
        "aff": "Lu\u00eds Santos is with the Institute of Systems and Robotics, University of Coimbra, Portugal; Rui Cortes\u00e3o is with the Electrical and Computer Engineering Department, Institute of Systems and Robotics, University of Coimbra, Portugal; Jo\u00e3o Quintas is with the Instituto Pedro Nunes, Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968481/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1494855743509745546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Coimbra;Instituto Pedro Nunes",
        "aff_unique_dep": "Institute of Systems and Robotics;",
        "aff_unique_url": "https://www.uc.pt;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Coimbra",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "8968054",
        "title": "Two-View Fusion based Convolutional Neural Network for Urban Road Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a two-view fusion based convolutional neural network to estimate road areas in urban environments with LiDAR point clouds as input only. The proposed network takes two transformed LiDAR data representations, the LiDAR imageries and the camera-perspective maps, as inputs. It outputs pixel-wise road detection results in both the LiDAR's imagery view and the camera's perspective view simultaneously, in an end-to-end manner. To make better use of the data associations between two representations, we construct a novel mapping layer to transform features from the LiDAR's imagery view to the camera's perspective view in order to strengthen the road detection performance in the camera's perspective view. Experiments on the KITTI-Road dataset show that the proposed network can achieve the state-of-the-art performance among all LiDAR-only methods in real time.",
        "primary_area": "",
        "author": "Shuo Gu;Yigong Zhang;Jian Yang;Jose M. Alvarez;Hui Kong;Shuo Gu;Yigong Zhang;Jian Yang;Jose M. Alvarez;Hui Kong",
        "authorids": "/37086251612;/37085805552;/37280205100;/37392423100;/37061510500;/37086251612;/37085805552;/37280205100;/37392423100;/37061510500",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; NVIDIA, Santa Clara, CA, USA; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968054/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9241996608541523177&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Nanjing University of Science and Technology;NVIDIA",
        "aff_unique_dep": "School of Computer Science and Engineering;NVIDIA",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.nvidia.com",
        "aff_unique_abbr": "NJUST;NV",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Nanjing;Santa Clara",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "8967608",
        "title": "UAV Landing at an Unknown Location Marked by a Radio Beacon",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of minimizing the time to approach and land near a target radio beacon at an unknown location with an Unmanned Aerial Vehicle (UAV). We show that a cone-like region exists above the target inside of which bearing measurements of a directional antenna lose directionality: signal recordings in all directions yield similar signal strength. We present a geometric model of this region based on antenna simulations and data collected with a real system. Our main contribution is a strategy that takes advantage of a UAV's ability to change altitude and exploits a special structure occurring when approaching the target beacon from above to reduce the flight time required to land near the beacon. We analyze the performance of our strategy and demonstrate through simulations that by exploiting this structure we can achieve shorter flight times than our previous work.",
        "primary_area": "",
        "author": "Nikolaos Stefas;Haluk Bayram;Volkan Isler;Nikolaos Stefas;Haluk Bayram;Volkan Isler",
        "authorids": "/37085893225;/37589874500;/37298487800;/37085893225;/37589874500;/37298487800",
        "aff": "University of Minnesota; Istanbul Medeniyet University; University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967608/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=557427108126914621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Minnesota;Istanbul Medeniyet University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.minnesota.edu;https://www.medun.edu.tr",
        "aff_unique_abbr": "UMN;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;T\u00fcrkiye"
    },
    {
        "id": "8967996",
        "title": "Uncertainty-Aware Imitation Learning using Kernelized Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "During the past few years, probabilistic approaches to imitation learning have earned a relevant place in the robotics literature. One of their most prominent features is that, in addition to extracting a mean trajectory from task demonstrations, they provide a variance estimation. The intuitive meaning of this variance, however, changes across different techniques, indicating either variability or uncertainty. In this paper we leverage kernelized movement primitives (KMP) to provide a new perspective on imitation learning by predicting variability, correlations and uncertainty using a single model. This rich set of information is used in combination with the fusion of optimal controllers to learn robot actions from data, with two main advantages: i) robots become safe when uncertain about their actions and ii) they are able to leverage partial demonstrations, given as elementary sub-tasks, to optimally perform a higher level, more complex task. We showcase our approach in a painting task, where a human user and a KUKA robot collaborate to paint a wooden board. The task is divided into two sub-tasks and we show that the robot becomes compliant (hence safe) outside the training regions and executes the two sub-tasks with optimal gains otherwise.",
        "primary_area": "",
        "author": "Jo\u00e3o Silv\u00e9rio;Yanlong Huang;Fares J. Abu-Dakka;Leonel Rozo;Darwin G. Caldwell;Jo\u00e3o Silv\u00e9rio;Yanlong Huang;Fares J. Abu-Dakka;Leonel Rozo;Darwin G. Caldwell",
        "authorids": "/37085736048;/37086454561;/37086302962;/38228060200;/37295680400;/37085736048;/37086454561;/37086302962;/38228060200;/37295680400",
        "aff": "Idiap Research Institute CH-1920 Martigny, Switzerland; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Bosch Center for Artificial Intelligence, Renningen, Germany; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967996/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9475407915639466408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Idiap Research Institute;Istituto Italiano di Tecnologia;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": ";Department of Advanced Robotics;Artificial Intelligence",
        "aff_unique_url": "https://www.idiap.ch;https://www.iit.it;https://www.bosch-ai.com",
        "aff_unique_abbr": ";IIT;BCAI",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Genova;Renningen",
        "aff_country_unique_index": "0;1;1;2;1",
        "aff_country_unique": "Switzerland;Italy;Germany"
    },
    {
        "id": "8967953",
        "title": "Underactuated Gripper with Forearm Roll Estimation for Human Limbs Manipulation in Rescue Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "The emergence of new robotic technologies such as compliant control and soft robotics, has contributed to safe physical Human-Robot Interaction (pHRI) mainly for assistive applications. However, a robot capable of directly manipulating the human body, which is key for the implementation of autonomous rescue robots, has not been developed so far. In this paper, the development of a gripper and methods for the robotic manipulation of a laying victim's forearm, initiated by the robot is addressed, and validated based on experimental results. An underactuated gripper with added proprioceptive sensors has been designed, with environment sensing and tactile recognition capabilities. This method provides a stable grasping of a human forearm that lays on a surface and is capable of estimating the roll angle of the grasped arm for precise location and safe manipulation. The roll-angle estimation method is based on Machine Learning and has been trained with experimental data obtained from experiments with human volunteers. The resulting method provides robust and precise grasping, tolerant to location inaccuracy with inexpensive sensors. This is one of the very first works on the robotic human-body manipulation.",
        "primary_area": "",
        "author": "Juan M. Gandarias;Francisco Pastor;Antonio J. Mu\u00f1oz-Ram\u00edrez;Alfonso J. Garc\u00eda-Cerezo;Jes\u00fas M. G\u00f3mez-de-Gabriel;Juan M. Gandarias;Francisco Pastor;Antonio J. Mu\u00f1oz-Ram\u00edrez;Alfonso J. Garc\u00eda-Cerezo;Jes\u00fas M. G\u00f3mez-de-Gabriel",
        "authorids": "/37086294706;/37086959007;/37087323285;/38273546700;/38273879300;/37086294706;/37086959007;/37087323285;/38273546700;/38273879300",
        "aff": "Telerobotics and Interactive Systems Laboratory (TaIS Lab), University of M\u00e1laga, M\u00e1laga, Spain; Telerobotics and Interactive Systems Laboratory (TaIS Lab), University of M\u00e1laga, M\u00e1laga, Spain; Telerobotics and Interactive Systems Laboratory (TaIS Lab), University of M\u00e1laga, M\u00e1laga, Spain; Telerobotics and Interactive Systems Laboratory (TaIS Lab), University of M\u00e1laga, M\u00e1laga, Spain; Telerobotics and Interactive Systems Laboratory (TaIS Lab), University of M\u00e1laga, M\u00e1laga, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967953/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18287394536815700801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of M\u00e1laga",
        "aff_unique_dep": "Telerobotics and Interactive Systems Laboratory (TaIS Lab)",
        "aff_unique_url": "https://www.um.es",
        "aff_unique_abbr": "UMA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "M\u00e1laga",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "8968023",
        "title": "Understanding Multi-Robot Systems: on the Concept of Legibility",
        "track": "main",
        "status": "Poster",
        "abstract": "Legibility can be defined as the ability of a robot to communicate its intent to the user. Legibility is relatively little investigated in multi-robot systems, but, in the literature, studies exist where the trajectory of manipulators is analyzed as a factor to improve the collaboration between robots and users. In this paper, we focus on the legibility of a group of mobile robots. To this end, we consider a set of motion-variables: trajectory, dispersion and stiffness. They are typical parameters that determine the motion of a group of robots. To analyze the effect of the motion-variables over legibility, Fisher's exact test and ANOVA (analysis of variance) were carried out. The data for the statistical analysis cover a full factorial plan and they were collected in a virtual reality set-up, where the users shared the environment with a group of robots. We investigate two aspects of legibility: the correctness and the rapidity of communication, namely if the communication happens correctly and how fast it happens. Trajectory was found to be relevant to correctly communicate the intention of the robots, while stiffness and dispersion were relevant for the rapidity of legibility.",
        "primary_area": "",
        "author": "Beatrice Capelli;Valeria Villani;Cristian Secchi;Lorenzo Sabattini;Beatrice Capelli;Valeria Villani;Cristian Secchi;Lorenzo Sabattini",
        "authorids": "/37086348616;/38228363100;/37300905500;/37594737400;/37086348616;/38228363100;/37300905500;/37594737400",
        "aff": "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968023/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10948215745439597145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods for Engineering (DISMI)",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8967871",
        "title": "Unified Balance Control for Biped Robots Including Modification of Footsteps with Angular Momentum and Falling Detection Based on Capturability",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose walking balance control based on Caputurability. The proposed method consists of five strategies: (i) moving Zero Moment Point (ZMP) in the support polygon (ii) landing position modification (iii) landing timing modification (iv) angular momentum control (v) falling detection and fall control. Walking pattern generation calculates the ZMP so that the Capture Point (CP) reaches the position of the supporting foot at the end of the double support phase. Owing to the asymmetry of the reachable landing region, landing timing modification is different in the sagittal and lateral planes, and the step time is extended in the lateral plane depending on the direction of disturbances. The torque around the center of gravity to avoid falling is realized through whole-body inverse kinematics with constraints on the angular momentum. In addition, we propose falling detection considering the reachable landing region. We verified the effectiveness of the proposed method through experiments in which the biped robot was disturbed by pushing during tether-free walking. The robot could prevent breakdown by detecting possible falling and performed knee bending motions to suppress damage.",
        "primary_area": "",
        "author": "Yuta Kojio;Yasuhiro Ishiguro;Kim-Ngoc-Khanh Nguyen;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Yuta Kojio;Yasuhiro Ishiguro;Kim-Ngoc-Khanh Nguyen;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086211574;/37086070588;/37086575960;/37085651948;/38242437800;/37280639000;/37286658200;/37086211574;/37086070588;/37086575960;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967871/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4527001737612337506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967719",
        "title": "Unified Human-Robot Shared Control with Application to Haptic Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot shared control (SC) has largely been studied in two complementary forms, namely divisible shared control (DSC) and interactive shared control (ISC). DSC enables clean division of the human and the robot subtasks, thus enabling them to work independently, while ISC allows for flexible intervention to improve the collaborative performance or experience. This paper presents a unified scheme that combines both forms of SCs to attain the benefits of flexibility as well as ease of use when human and robot jointly work on a task together. Based on the idea that flexibility should be embedded in every task constraint that the robot is controlling, we connect ISC into the robot subtask providing a soft boundary between the divided orthogonal subspaces allowing human to access the robot subtask and intervene whenever necessary. We also propose a new simple yet effective Cartesian stiffness adaptation law that enables the robot to modify its endpoint stiffness in the robot's control subspace in the presence of disagreement from the human. Simulations and real robot studies for a teleoperated path-following scenario were performed to demonstrate the flexibility of the unified shared control (USC), which allows the robot to dynamically adapt its task based on the operator's intentions.",
        "primary_area": "",
        "author": "Cheong Min Ting Samuel;Keng Peng Tee;Cheong Min Ting Samuel;Keng Peng Tee",
        "authorids": "/37087325220;/37275857100;/37087325220;/37275857100",
        "aff": "A*STAR, Institute for Infocomm Research, Singapore; A*STAR, Institute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967719/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4152436169171008404&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "A*STAR",
        "aff_unique_dep": "Institute for Infocomm Research",
        "aff_unique_url": "https://www.a-star.edu.sg",
        "aff_unique_abbr": "A*STAR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "8968534",
        "title": "Unstructured Terrain Navigation and Topographic Mapping with a Low-cost Mobile Cuboid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Current robotic terrain mapping techniques require expensive sensor suites to construct an environmental representation. In this work, we present a cube-shaped robot that can roll through unstructured terrain and construct a detailed topographic map of the surface that it traverses in real time with low computational and monetary expense. Our approach devolves many of the complexities of locomotion and mapping to passive mechanical features. Namely, rolling movement is achieved by sequentially inflating latex bladders that are located on four sides of the robot to destabilize and tip it. Sensing is achieved via arrays of fine plastic pins that passively conform to the geometry of underlying terrain, retracting into the cube. We developed a topography by shade algorithm to process images of the displaced pins to reconstruct terrain contours and elevation. We experimentally validated the efficacy of the proposed robot through object mapping and terrain locomotion tasks.",
        "primary_area": "",
        "author": "Andrew S. Morgan;Robert L. Baines;Hayley McClintock;Brian Scassellati;Andrew S. Morgan;Robert L. Baines;Hayley McClintock;Brian Scassellati",
        "authorids": "/37086455182;/37086842392;/37087322398;/37295620100;/37086455182;/37086842392;/37087322398;/37295620100",
        "aff": "Department of Mechanical Engineering & Materials Science, Yale University, 9 Hillhouse Avenue, New Haven, USA; Department of Mechanical Engineering & Materials Science, Yale University, 9 Hillhouse Avenue, New Haven, USA; Department of Mechanical Engineering & Materials Science, Yale University, 9 Hillhouse Avenue, New Haven, USA; Department of Computer Science, Yale University, 51 Prospect Street, New Haven, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968534/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16667382018484949574&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering & Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New Haven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968016",
        "title": "Unsupervised Task Segmentation Approach for Bimanual Surgical Tasks using Spatiotemporal and Variance Properties",
        "track": "main",
        "status": "Poster",
        "abstract": "In surgical workflow analysis and training in robot-assisted surgery, automatic task segmentation could significantly reduce the manual labeling time and enhance robot learning efficiency. This paper presents an unsupervised segmentation approach to automatically segment a given surgical task without manual intervention. A new segmentation method is presented, which relies only on bimanual kinematic trajectories without the need for prior information about the data. Specifically, surgical tasks are segmented by fusing trajectories' spatiotemporal and variance properties. To demonstrate the effectiveness of the proposed method, detailed experiments were first conducted on our dataset. We segmented trajectories of three different surgical stitches and observed an average F1 score of 77.9% against the ground truths. The same trajectories were then added with different levels of noises and the segmentation comparison was made with four other methods. The proposed algorithm had demonstrated its robustness against the noises. Finally, to assess its generalization ability, the method was evaluated on publicly available JIGSAWS dataset and an average F1 score of 75.5% was achieved.",
        "primary_area": "",
        "author": "Ya-Yen Tsai;Yao Guo;Guang-Zhong Yang;Ya-Yen Tsai;Yao Guo;Guang-Zhong Yang",
        "authorids": "/37086935862;/37086919325;/37276270800;/37086935862;/37086919325;/37276270800",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, SW7 2AZ, London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, SW7 2AZ, London, UK; G.-Z. Yang is also with the Institute of Medical Robotics, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968016/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15162333003807596680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery;Institute of Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Imperial;SJTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "8967556",
        "title": "Unsupervised Traffic Accident Detection in First-Person Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing abnormal events such as traffic violations and accidents in natural driving scenes is essential for successful autonomous driving and advanced driver assistance systems. However, most work on video anomaly detection suffers from two crucial drawbacks. First, they assume cameras are fixed and videos have static backgrounds, which is reasonable for surveillance applications but not for vehicle-mounted cameras. Second, they pose the problem as one-class classification, relying on arduously hand-labeled training datasets that limit recognition to anomaly categories that have been explicitly trained. This paper proposes an unsupervised approach for traffic accident detection in first-person (dashboard-mounted camera) videos. Our major novelty is to detect anomalies by predicting the future locations of traffic participants and then monitoring the prediction accuracy and consistency metrics with three different strategies. We evaluate our approach using a new dataset of diverse traffic accidents, AnAn Accident Detection (A3D), as well as another publicly-available dataset. Experimental results show that our approach outperforms the state-of-the-art. Code and the dataset developed in this work are available at: https:llgithub.comlMoonBtvdltad-IROS2019.",
        "primary_area": "",
        "author": "Yu Yao;Mingze Xu;Yuchen Wang;David J. Crandall;Ella M. Atkins;Yu Yao;Mingze Xu;Yuchen Wang;David J. Crandall;Ella M. Atkins",
        "authorids": "/37086546393;/37086234184;/37087323530;/37282605100;/37299901300;/37086546393;/37086234184;/37087323530;/37282605100;/37299901300",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967556/",
        "gs_citation": 209,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16497716559899099859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Michigan;Indiana University",
        "aff_unique_dep": "Robotics Institute;School of Informatics, Computing, and Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.indiana.edu",
        "aff_unique_abbr": "UM;IU",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Ann Arbor;Bloomington",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967658",
        "title": "Upper Limb Motion Simulation Algorithm for Prosthesis Prescription and Training",
        "track": "main",
        "status": "Poster",
        "abstract": "A simulation algorithm to predict expected upper limb movements of prosthesis users performing activities of daily living (ADL) was developed. It is quite challenging to determine the right type and fit of a prosthesis and provide appropriate training to properly utilize it. The amputee care team typically uses prior experiences to provide prescription and training customized for each individual. It is also very difficult to anticipate expected and undesired compensatory motions due to reduced degrees of freedom of a prosthesis user. We have developed a tool to predict and visualize the expected upper limb movements resulting from using a prescribed prosthesis and its suitability to the needs of the amputee. It is expected to help clinicians make decisions such as the type of the prosthesis, and whether to include a wrist joint, based on the impact it will have on the rest of the joints. The main focus of this work is to use robotics-based methods to simulate human use of prostheses and identify the expected posture of the limited joints on the upper limbs. Unlike other works, this paper does not discuss the control of the prosthesis but the posture of the body. A weighted least-norm inverse kinematics algorithm was used to develop a robotics-based model of the upper limbs and torso. Motion capture data from the subjects were used to determine the weighting matrix the algorithm required. Results show that this approach provides human-like simulation of joint motions and matches the motion capture data. The algorithm uses the individual\u2019s anthropometrics and level of amputation to create a personalized kinematic model of the upper body and the joint motions during ADLs. A graphic user interface (GUI) was created to allow the clinician to input the relevant data resulting in arm movements of the prospective prosthesis user. A custom-made visualization software was developed to display an animation performing the simulated motion. It should be stressed that this work d... Show More",
        "primary_area": "",
        "author": "Dimitrios Menychtas;Stephanie L. Carey;Redwan Alqasemi;Rajiv V. Dubey;Dimitrios Menychtas;Stephanie L. Carey;Redwan Alqasemi;Rajiv V. Dubey",
        "authorids": "/37085723464;/37579720100;/37546405300;/37273301600;/37085723464;/37579720100;/37546405300;/37273301600",
        "aff": "Department of Medical Engineering, University of South Florida 4202 E. Fowler Avenue, Tampa, FL, USA; Faculty in the Department of Mechanical Engineering, University of South Florida 4202 E. Fowler Avenue, Tampa, FL, USA; Faculty in the Department of Mechanical Engineering, University of South Florida 4202 E. Fowler Avenue, Tampa, FL, USA; Faculty in the Department of Mechanical Engineering, University of South Florida 4202 E. Fowler Avenue, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967658/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17810408995613310677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Medical Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968014",
        "title": "Variable Configuration Planner for Legged-Rolling Obstacle Negotiation Locomotion: Application on the CENTAURO Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Hybrid legged-wheeled robots are able to adapt their leg configuration and height to vary their footprint polygons and go over obstacles or traverse narrow spaces. In this paper, we present a variable configuration wheeled motion planner based on the A* algorithm. It takes advantage of the agility of hybrid wheeled-legged robots and plans paths over low-lying obstacles and in narrow spaces. By imposing a symmetry on the robot polygon, the computed plans lie in a low-dimensional search space that provides the robot with configurations to safely negotiate obstacles by expanding or shrinking its footprint polygon. The introduced autonomous planner is demonstrated using simulations and real-world experiments with the CENTAURO robot.",
        "primary_area": "",
        "author": "Vignesh Sushrutha Raghavan;Dimitrios Kanoulas;Arturo Laurenzi;Darwin G. Caldwell;Nikos G. Tsagarakis;Vignesh Sushrutha Raghavan;Dimitrios Kanoulas;Arturo Laurenzi;Darwin G. Caldwell;Nikos G. Tsagarakis",
        "authorids": "/37086454199;/38230575500;/37086141170;/37295680400;/37295830800;/37086454199;/38230575500;/37086141170;/37295680400;/37295830800",
        "aff": "Humanoids and Human-Centered Mechatronics & Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, 16163, Genova, Italy; Humanoids and Human-Centered Mechatronics & Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, 16163, Genova, Italy; Humanoids and Human-Centered Mechatronics & Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, 16163, Genova, Italy; Humanoids and Human-Centered Mechatronics & Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, 16163, Genova, Italy; Humanoids and Human-Centered Mechatronics & Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, 16163, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968014/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5048352897987829582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Humanoids and Human-Centered Mechatronics & Advanced Robotics",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968201",
        "title": "Variable Impedance Control in End-Effector Space: An Action Space for Reinforcement Learning in Contact-Rich Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) of contact-rich manipulation tasks has yielded impressive results in recent years. While many studies in RL focus on varying the observation space or reward model, few efforts focused on the choice of action space (e.g. joint or end-effector space, position, velocity, etc.). However, studies in robot motion control indicate that choosing an action space that conforms to the characteristics of the task can simplify exploration and improve robustness to disturbances. This paper studies the effect of different action spaces in deep RL and advocates for variable impedance control in end-effector space (VICES) as an advantageous action space for constrained and contact-rich tasks. We evaluate multiple action spaces on three prototypical manipulation tasks: Path Following (task with no contact), Door Opening (task with kinematic constraints), and Surface Wiping (task with continuous contact). We show that VICES improves sample efficiency, maintains low energy consumption, and ensures safety across all three experimental setups. Further, RL policies learned with VICES can transfer across different robot models in simulation, and from simulation to real for the same robot. Further information is available at https://stanfordvl.github.io/vices.",
        "primary_area": "",
        "author": "Roberto Mart\u00edn-Mart\u00edn;Michelle A. Lee;Rachel Gardner;Silvio Savarese;Jeannette Bohg;Animesh Garg;Roberto Mart\u00edn-Mart\u00edn;Michelle A. Lee;Rachel Gardner;Silvio Savarese;Jeannette Bohg;Animesh Garg",
        "authorids": "/37085788640;/37086935666;/37087324742;/37298502600;/37591153900;/37086330576;/37085788640;/37086935666;/37087324742;/37298502600;/37591153900;/37086330576",
        "aff": "Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, Nvidia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968201/",
        "gs_citation": 231,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14191315878987302913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Artificial Intelligence Lab (SAIL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968085",
        "title": "Vehicular Multi-Camera Sensor System for Automated Visual Inspection of Electric Power Distribution Equipment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a multi-camera sensor system along with its control algorithm for automated visual inspection from a moving vehicle. To accomplish this task, we propose a unique hardware configuration consisting of a frontal stereo vision system, six lateral cameras motorized to tilt, and a GPS/IMU sensor mounted on the roof of a car. From the frontal stereo system, we detect electric poles and estimate their corresponding 3D positions. Based on this 3D estimation, the tilt angles of the motorized lateral cameras are controlled in real-time to capture high resolution images of the equipment - typically installed a few meters above the road surface. In addition, inertial odometry information from the GPS/IMU module is utilized for pose estimation, object localization, and re-identification among cameras. Experimental results demonstrate the efficiency and robustness of our system for automated electric equipment maintenance, which can reduce human effort significantly.",
        "primary_area": "",
        "author": "Jinsun Park;Ukcheol Shin;Gyumin Shim;Kyungdon Joo;Francois Rameau;Junhyeok Kim;Dong-Geol Choi;In So Kweon;Jinsun Park;Ukcheol Shin;Gyumin Shim;Kyungdon Joo;Francois Rameau;Junhyeok Kim;Dong-Geol Choi;In So Kweon",
        "authorids": "/37085711113;/37087323766;/37087324667;/37085436130;/37892103100;/37085664557;/38542186000;/37270474800;/37085711113;/37087323766;/37087324667;/37085436130;/37892103100;/37085664557;/38542186000;/37270474800",
        "aff": "Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Korea Electric Power Corporation, Korea Electric Power Research Institute, Daejeon, Republic of Korea; Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968085/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2389540127461791384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;0",
        "aff_unique_norm": "KAIST;Korea Electric Power Corporation;Hanbat National University",
        "aff_unique_dep": "School of Electrical Engineering;;Department of Information and Communication Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.kepco.co.kr;http://www.hanbat.ac.kr",
        "aff_unique_abbr": "KAIST;KEPCO;HNU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968484",
        "title": "ViLiVO: Virtual LiDAR-Visual Odometry for an Autonomous Vehicle with a Multi-Camera System",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a multi-camera visual odometry (VO) system for an autonomous vehicle. Our system mainly consists of a virtual LiDAR and a pose tracker. We use a perspective transformation method to synthesize a surroundview image from undistorted fisheye camera images. With a semantic segmentation model, the free space can be extracted. The scans of the virtual LiDAR are generated by discretizing the contours of the free space. As for the pose tracker, we propose a visual odometry system fusing both the feature matching and the virtual LiDAR scan matching results. Only those feature points located in the free space area are utilized to ensure the 2D-2D matching for pose estimation. Furthermore, bundle adjustment (BA) is performed to minimize the feature points reprojection error and scan matching error. We apply our system to an autonomous vehicle equipped with four fisheye cameras. The testing scenarios include an outdoor parking lot as well as an indoor garage. Experimental results demonstrate that our system achieves a more robust and accurate performance comparing with a fisheye camera based monocular visual odometry system.",
        "primary_area": "",
        "author": "Zhenzhen Xiang;Jingrui Yu;Jie Li;Jianbo Su;Zhenzhen Xiang;Jingrui Yu;Jie Li;Jianbo Su",
        "authorids": "/37085750570;/37086665463;/37087324038;/37281319700;/37085750570;/37086665463;/37087324038;/37281319700",
        "aff": "Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; SAIC Motor, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968484/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9999579820134340581&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;SAIC Motor",
        "aff_unique_dep": "Department of Automation;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.saicmotor.com",
        "aff_unique_abbr": "SJTU;SAIC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8968245",
        "title": "View management for lifelong visual maps",
        "track": "main",
        "status": "Poster",
        "abstract": "The time complexity of making observations and loop closures in a graph-based visual SLAM system is a function of the number of views stored [1], [2]. Clever algorithms, such as approximate nearest neighbor search, can make this function sub-linear. Despite this, over time the number of views can still grow to a point at which the speed and/or accuracy of the system becomes unacceptable, especially in computation- and memory-constrained SLAM systems. However, not all views are created equal. Some views are rarely observed, because they have been created in an unusual lighting condition, or from low quality images, or in a location whose appearance has changed. These views can be removed to improve the overall performance of a SLAM system. In this paper, we propose a method for pruning views in a visual SLAM system to maintain its speed and accuracy for long term use.",
        "primary_area": "",
        "author": "Nandan Banerjee;Ryan C. Connolly;Dimitri Lisin;Jimmy Briggs;Mario E. Munich;Nandan Banerjee;Ryan C. Connolly;Dimitri Lisin;Jimmy Briggs;Mario E. Munich",
        "authorids": "/37085745749;/37087324024;/37588049300;/37087051449;/37351952000;/37085745749;/37087324024;/37588049300;/37087051449;/37351952000",
        "aff": "iRobot Corporation, Bedford, MA, USA; iRobot Corporation, Bedford, MA, USA; iRobot Corporation, Bedford, MA, USA; iRobot Corporation, Bedford, MA, USA; iRobot Corporation, Bedford, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968245/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16956742086718349606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "iRobot Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.irobot.com",
        "aff_unique_abbr": "iRobot",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968198",
        "title": "Virtual Lane Boundary Generation for Human-Compatible Autonomous Driving: A Tight Coupling between Perception and Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing autonomous vehicle (AV) navigation algorithms treat lane recognition, obstacle avoidance, local path planning, and lane following as separate functional modules which result in driving behavior that is incompatible with human drivers. It is imperative to design human-compatible navigation algorithms to ensure transportation safety. We develop a new tightly-coupled perception-planning framework that combines all these functionalities to ensure human-compatibility. Using GPS-camera-lidar sensor fusion, we detect actual lane boundaries (ALBs) and propose availability-reasonability-feasibility (ARF) threefold tests to determine if we should generate virtual lane boundaries (VLBs) or follow ALBs. If needed, VLBs are generated using a dynamically adjustable multi-objective optimization framework that considers obstacle avoidance, trajectory smoothness (to satisfy vehicle kinodynamic constraints), trajectory continuity (to avoid sudden movements), GPS following quality (to execute global plan), and lane following or partial direction following (to meeting human expectation). Consequently, vehicle motion is more human compatible than existing approaches. We have implemented our algorithm and tested under open source data with satisfying results.",
        "primary_area": "",
        "author": "Binbin Li;Dezhen Song;Ankit Ramchandani;Hsin-Min Cheng;Di Wang;Yiliang Xu;Baifan Chen;Binbin Li;Dezhen Song;Ankit Ramchandani;Hsin-Min Cheng;Di Wang;Yiliang Xu;Baifan Chen",
        "authorids": "/37086575452;/37275586600;/37087324067;/37086611069;/37086453325;/37075975900;/37600013300;/37086575452;/37275586600;/37087324067;/37086611069;/37086453325;/37075975900;/37600013300",
        "aff": "CSE Department, Texas A&M University, TX, US; CSE Department, Texas A&M University, TX, US; CSE Department, Texas A&M University, TX, US; CSE Department, Texas A&M University, TX, US; CSE Department, Texas A&M University, TX, US; Tencent America, Palo Alto, CA, US; School of Automation, Central South University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968198/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8648942129408143635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Texas A&M University;Tencent;Central South University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Tencent America;School of Automation",
        "aff_unique_url": "https://www.tamu.edu;https://www.tencent.com/en-us;http://www.csu.edu.cn",
        "aff_unique_abbr": "TAMU;Tencent America;",
        "aff_campus_unique_index": "0;0;0;0;0;1;2",
        "aff_campus_unique": "College Station;Palo Alto;Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8967853",
        "title": "Virtual Maps for Autonomous Exploration with Pose SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of autonomous mobile robot exploration in an unknown environment taking into account the robot's mapping rate, map uncertainty, and state estimation uncertainty. This paper presents an exploration framework built upon segment-aided pose SLAM adapted for better active localization. We build on our previous work on expectation maximization (EM) exploration, which explicitly models unknown landmarks as latent variables and predicts their expected uncertainty, to resolve the lack of landmark state in denser instances of SLAM. The proposed system comprises path generation, place recognition forecasting, belief propagation and utility evaluation using a virtual map. We analyze the performance in simulated experiments, showing that our algorithm maintains higher coverage speed in exploration as well as lower mapping and localization error. The real-time applicability is demonstrated on an unmanned ground vehicle.",
        "primary_area": "",
        "author": "Jinkun Wang;Tixiao Shan;Brendan Englot;Jinkun Wang;Tixiao Shan;Brendan Englot",
        "authorids": "/37085734204;/37085681623;/37601539900;/37085734204;/37085681623;/37601539900",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967853/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13710051804314244219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968177",
        "title": "Virtual Region based Multi-robot Path Planning in an Unknown Occluded Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an arbitrary-region based shape-control methodology for a swarm-robotics framework to conquer the traditional obstacle-avoidance problem. In this control approach, during the movement of a team of robots through an unknown occluded environment, a virtual boundary for the robotic crowd that could pass through even a very narrow passage, as a swarm, has been created based on the agents' /robots' sensing information. The primary challenge is to force each and every agent to fit into the arbitrary boundary, thus created, so that they can form a swarm and eventually progress towards the goal while avoiding obstacles. Consequently, the process maximizes the inter-agent cohesion. Furthermore, the virtual region is subdivided into so-called cells designated by a non-overlapping circular geometry. The utmost endeavor is to make an agent place itself at the center of a circular cell and a mechanism has been devised, where each agent is duly attracted and eventually is resident at the center of each cell completely blanketing the entire virtual region. To place each agent inside the stipulated contour, a novel circle-packing algorithm has been proposed such that the contour is fitted with a number of identical circles. Finally, the simulation results along with hardware implementation demonstrate the effectiveness of the proposed control technique.",
        "primary_area": "",
        "author": "Dibyendu Roy;Arijit Chowdhury;Madhubanti Maitra;Samar Bhattacharya;Dibyendu Roy;Arijit Chowdhury;Madhubanti Maitra;Samar Bhattacharya",
        "authorids": "/37085995173;/37085512182;/38554699500;/37534177400;/37085995173;/37085512182;/38554699500;/37534177400",
        "aff": "TCS Research and Innovation, India; TCS Research and Innovation, India; Department of Electrical Engineering, Jadavpur University, Kolkata, India; Department of Electrical Engineering, Jadavpur University, Kolkata, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968177/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11147297454366570170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Tata Consultancy Services;Jadavpur University",
        "aff_unique_dep": "Research and Innovation;Department of Electrical Engineering",
        "aff_unique_url": "https://www.tcs.com;http://www.jaduniv.edu.in",
        "aff_unique_abbr": "TCS;JU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Kolkata",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "8968284",
        "title": "Virtual-mass-ellipsoid Inverted Pendulum Model and Its Applications to 3D Bipedal Locomotion on Uneven Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "It is still an open problem to develop a reduced order model of bipedal walking that closely represents the complex dynamics of humanoid robots. In this paper, we propose control methodologies, removing both the constant CoM height constraint and the constant centroidal angular momentum constraint. We define a capturability criterion. and propose an enhanced intrinsically stable model predict control to fulfill this new capturability criterion. Then the angular momentum can be controlled. The results of simulations using humanoid robot HRP-4 show the proposed methods can improve the stability of bipedal locomotion on uneven terrains.",
        "primary_area": "",
        "author": "Kaixuan Guan;Ko Yamamoto;Yoshihiko Nakamura;Kaixuan Guan;Ko Yamamoto;Yoshihiko Nakamura",
        "authorids": "/37087321862;/37536641800;/37280754600;/37087321862;/37536641800;/37280754600",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968284/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4142777822953698222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8968521",
        "title": "Vision-Aided Localization For Ground Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the problem of vision-based localization for ground robotic applications. In recent years, camera only or camera-IMU (inertial measurement unit) based localization methods are widely studied, in terms of theoretical properties, algorithm design, and real-world applications. However, we experimentally find that none of existing methods is able to perform high-precision and robust localization for ground robots in large-scale complicated 3D environments. To this end, in this paper, we propose a novel vision-based localization algorithm dedicatedly designed for ground robots, by fusing measurements from a camera, an IMU, and the wheel odometer. The first contribution of this paper is that we propose a novel algorithm for approximating the motion manifold for ground robots by parametric representation and performing pose integrating via IMU and wheel odometer measurements. Secondly, we propose a complete localization algorithm, by using a sliding-window based estimator. The estimator is designed based on iterative optimization to fuse measurements from multiple sensors on the proposed manifold representation. We show that, based on a variety of real-world experiments, the proposed algorithm outperforms a number of the state-of-the-art vision based localization algorithms by a significant margin, especially when deployed in large-scale complicated environments.",
        "primary_area": "",
        "author": "Mingming Zhang;Yiming Chen;Mingyang Li;Mingming Zhang;Yiming Chen;Mingyang Li",
        "authorids": "/37087325241;/37900421300;/37086936897;/37087325241;/37900421300;/37086936897",
        "aff": "A.I. Labs, Alibaba Group Inc, Hangzhou, China; A.I. Labs, Alibaba Group Inc, Hangzhou, China; A.I. Labs, Alibaba Group Inc, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968521/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12061660675727929213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Alibaba Group Inc",
        "aff_unique_dep": "A.I. Labs",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967863",
        "title": "Vision-based Automatic Control of a 5-Fingered Assistive Robotic Manipulator for Activities of Daily Living",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive Robotic Manipulators (ARMs) play an important role for people with upper-limb disabilities and the elderly by helping them complete Activities of Daily Living (ADLs). However, as the objects to handle in ADLs differ in size, shape and manipulation constraints, many two or three fingered end-effectors of ARMs have difficulty robustly interacting with these objects. In this paper, we propose vision-based control of a 5-fingered manipulator (Schunk SVH), automatically changing its approach based on object classification using computer vision combined with deep learning. The control method is tested in a simulated environment and achieves a more robust grasp with the properly shaped five-fingered hand than with a comparable three-fingered gripper (Barrett Hand) using the same control sequence. In addition, the final optimal grasp pose (x, y, and \u03b8) is learned through a deep regressor in the penultimate stage of the grasp. This method correctly identifies the optimal grasp pose in 78.35% of cases when considering all three parameters for an object included in the training set, but in a different setting than that of the training set.",
        "primary_area": "",
        "author": "Chen Wang;Daniel Freer;Jindong Liu;Guang-Zhong Yang;Chen Wang;Daniel Freer;Jindong Liu;Guang-Zhong Yang",
        "authorids": "/37087322133;/37086108573;/37879388800;/37276270800;/37087322133;/37086108573;/37879388800;/37276270800",
        "aff": "Hamlyn Centre for Medical Robotics, Imperial College London, London, UK; Hamlyn Centre for Medical Robotics, Imperial College London, London, UK; Hamlyn Centre for Medical Robotics, Imperial College London, London, UK; Hamlyn Centre for Medical Robotics, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967863/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17272968574223045112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Hamlyn Centre for Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8968080",
        "title": "Vision-based Virtual Fixtures Generation for Robotic-Assisted Polyp Dissection Procedures",
        "track": "main",
        "status": "Poster",
        "abstract": "Polyp dissection requires very accurate detection of the region of interest and high-precision cutting with adequate safety margins. Robot-assisted polyp dissection is a solution to accomplish high-quality intervention. This paper proposes a method to constrain the robot to follow an accurate dissection path based on Virtual Fixtures (VF). The VFs are created via specific control points obtained directly from images of the surgical scene and are updated by the vision algorithm. The VF constraints can autonomously adapt themselves to environment changing during the surgical intervention. The entire pipeline is validated through experiments on the da Vinci Research Kit (dVRK) robot.",
        "primary_area": "",
        "author": "Rocco Moccia;Mario Selvaggio;Luigi Villani;Bruno Siciliano;Fanny Ficuciello;Rocco Moccia;Mario Selvaggio;Luigi Villani;Bruno Siciliano;Fanny Ficuciello",
        "authorids": "/37087325268;/37085859695;/37283126300;/37282449100;/37594404000;/37087325268;/37085859695;/37283126300;/37282449100;/37594404000",
        "aff": "Department of Electrical Engineering and Information Technology, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy; Department of Electrical Engineering and Information Technology, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy; Department of Electrical Engineering and Information Technology, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy; Department of Electrical Engineering and Information Technology, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy; Department of Electrical Engineering and Information Technology, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968080/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6778242323031895802&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Napoli Federico II",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.unina.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Napoli",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "8968495",
        "title": "Vision-based magnetic platform for actuator positioning and wireless control of microrobots",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a method to guide microrobots by positioning a magnetic actuator using hybrid vision system. The used actuator mounted at a robot end-effector creates local maxima of the magnetic field magnitude, which results in an attractive point for microrobots in its influence zone. The hybrid vision system serves to control the actuator position through the robotic platform to make the trapped microrobot undergo a planned trajectory. In first validation results, the particle driving is achieved in open loop with no adjustment with respect to the planned trajectory. Such scheme can be used in the case where the microrobot position can not be measured in real time. The second validation results deal with the case of microrobot positioning by visual servoing. This can be used in the case where recovering microrobot position is possible, for example in eye treatment.",
        "primary_area": "",
        "author": "Azaddien ZarroukT;Karim Belharet;Omar TahriT;Azaddien ZarroukT;Karim Belharet;Omar TahriT",
        "authorids": "/37087322416;/37586616100;/37087324548;/37087322416;/37586616100;/37087324548",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968495/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=815474112571107029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "8967714",
        "title": "Visual Domain Adaptation Exploiting Confidence-Samples",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain adaptation methods are used to address a problem, in which train scenario (source domain) and test scenario (target domain) are different. The existing methods mainly perform adaptation via reducing domain discrepancy from the view of a probability distribution. However, the idea of probability distribution matching always leads to a complex optimization process. Thereby these methods are difficult to apply in some scenario like online application or fast perception in dynamic environments. In this paper, we propose a new and simple domain adaptation method that utilizes confidence- samples to facilitate the classifier training on the target domain. Here, the confidence-samples are a subset of the target samples, and they have very credibly predicted labels. In order to detect the samples, a Category Similarity Collaborative Representation (CSCR) is first developed, by which the raw labels of all target samples are predicted using the smallest projection error according to the law of category. After this, the confidence score of the raw predicted labels is evaluated by the energy context information of CSCR. Finally, the target samples with a high confidence score are selected. Because of the linearity of CSCR, our method avoids complex optimization for matching the probability distribution. Empirical studies on a standard dataset demonstrate the advantages of our method.",
        "primary_area": "",
        "author": "Song Tang;Yunfeng Ji;Jianzhi Lyu;Jinpeng Mi;Qingdu Li;Jianwei Zhang;Song Tang;Yunfeng Ji;Jianzhi Lyu;Jinpeng Mi;Qingdu Li;Jianwei Zhang",
        "authorids": "/37087324926;/37087324684;/37087323631;/37086033673;/37089197601;/37281460600;/37087324926;/37087324684;/37087323631;/37086033673;/37089197601;/37281460600",
        "aff": "Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, Shanghai, China; Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, Shanghai, China; Department of Informatics, University of Hamburg, Hamburg, Germany; Department of Informatics, University of Hamburg, Hamburg, Germany; Department of Informatics, University of Hamburg, Hamburg, Germany; Department of Informatics, University of Hamburg, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967714/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12590741059580730500&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;1",
        "aff_unique_norm": "University of Shanghai for Science and Technology;University of Hamburg",
        "aff_unique_dep": "Institute of Machine Intelligence (IMI);Department of Informatics",
        "aff_unique_url": "https://www.ust.sh.cn;https://www.uni-hamburg.de",
        "aff_unique_abbr": "USST;",
        "aff_campus_unique_index": "0;0;1;1;1;1",
        "aff_campus_unique": "Shanghai;Hamburg",
        "aff_country_unique_index": "0;0;1;1;1;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "8967607",
        "title": "Visual-Inertial Odometry Tightly Coupled with Wheel Encoder Adopting Robust Initialization and Online Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Combining camera, IMU and wheel encoder is a wise choice for car positioning because of the low cost and complementarity of the sensors. We propose a novel extended visual-inertial odometry algorithm tightly fusing data from the above three sensors. Firstly we propose an IMU-odometer pre-integration approach utilizing complete IMU measurements and wheel encoder readings, to make scale estimation more accurate in subsequent 4-degrees of freedom (DoF) optimization. Secondly we develop an original initialization module where encoder readings are fully utilized to refine gravity direction and provide an initial value for camera pose in real scale. Thirdly, we design a computationally efficient online extrinsic calibration method by fixing the linearization point for the rotational component of IMU-odometer extrinsic parameters, which is deployed depending on the convergence of accelerometer bias. Experimental results prove the robustness of our initialization module and the accuracy of the whole trajectory, as well as the improvement brought about by online extrinsic calibration. Our program can also run on an Nvidia Jetson TX2 module in real time.",
        "primary_area": "",
        "author": "Jinxu Liu;Wei Gao;Zhanyi Hu;Jinxu Liu;Wei Gao;Zhanyi Hu",
        "authorids": "/37086526741;/37066625700;/37281086500;/37086526741;/37066625700;/37281086500",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967607/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2527709352953131647&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "National Laboratory of Pattern Recognition, Institute of Automation",
        "aff_unique_url": "http://www.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967905",
        "title": "Visual-Inertial Odometry with Point and Line Features",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a tightly-coupled monocular visual-inertial navigation system (VINS) using points and lines with degenerate motion analysis for 3D line triangulation. Based on line segment measurements from images, we propose two sliding window based 3D line triangulation algorithms and compare their performance. Analysis of the proposed algorithms reveals 3 degenerate camera motions that cause triangulation failures. Both geometrical interpretation and Monte-Carlo simulations are provided to verify these degenerate motions which prevent triangulation. In addition, commonly used line representations are compared through a monocular visual SLAM Monte-Carlo simulation. Finally, real-world experiments are conducted to validate the implementation of the proposed VINS system using the \u201cclosest point\u201d line representation.",
        "primary_area": "",
        "author": "Yulin Yang;Patrick Geneva;Kevin Eckenhoff;Guoquan Huang;Yulin Yang;Patrick Geneva;Kevin Eckenhoff;Guoquan Huang",
        "authorids": "/37085990232;/37086125563;/37086115587;/37077670600;/37085990232;/37086125563;/37086115587;/37077670600",
        "aff": "Department of Mechanical Engineering, University of Delaware, Newark, DE, USA; Department of Computer Information and Science, University of Delaware, Newark, DE, USA; Department of Mechanical Engineering, University of Delaware, Newark, DE, USA; Department of Mechanical Engineering, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967905/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1096740964617192108&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967575",
        "title": "Visual-Inertial On-Board Throw-and-Go Initialization for Micro Air Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach to the throw-and-go (TnG) problem for micro air vehicles (MAVs) using visual and inertial sensors. The key challenge is the fast on-board initialization of the visual odometry (VO) system, which usually requires user input to recover the visual scale. Our approach is based on the identification of the gravity vector from the acceleration data computed with images of the ground during in free fall. This enables scaling of the poses reconstructed with visual information. The proposed framework use inertial data to control the MAV attitude so the ground is visible after the throw. Using image to image homography a metric scale is estimated with which the MAV's height is propagated. Unlike existing literature, this approach requires no additional sensor nor user input or pre-throw assumptions and can recover from any initial attitude. We show results on both simulation and real data.",
        "primary_area": "",
        "author": "Martin Scheiber;Jeff Delaune;Roland Brockers;Stephan Weiss;Martin Scheiber;Jeff Delaune;Roland Brockers;Stephan Weiss",
        "authorids": "/37087323697;/37086592626;/37266435300;/37535323400;/37087323697;/37086592626;/37266435300;/37535323400",
        "aff": "Control of Networked Systems Group, Univerist\u00e4t Klagenfurt, Austria; Jet Propulsion Laboratory, California Institute of Technology, Pasadena; Jet Propulsion Laboratory, California Institute of Technology, Pasadena; Control of Networked Systems Group, Univerist\u00e4t Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967575/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1267639233229239613&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt;California Institute of Technology",
        "aff_unique_dep": "Control of Networked Systems Group;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.aau.at;https://www.caltech.edu",
        "aff_unique_abbr": ";Caltech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "8968307",
        "title": "Visual-based Autonomous Driving Deployment from a Stochastic and Uncertainty-aware Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end visual-based imitation learning has been widely applied in autonomous driving. When deploying the trained visual-based driving policy, a deterministic command is usually directly applied without considering the uncertainty of the input data. Such kind of policies may bring dramatical damage when applied in the real world. In this paper, we follow the recent real-to-sim pipeline by translating the testing world image back to the training domain when using the trained policy. In the translating process, a stochastic generator is used to generate various images stylized under the training domain randomly or directionally. Based on those translated images, the trained uncertainty-aware imitation learning policy would output both the predicted action and the data uncertainty motivated by the aleatoric loss function. Through the uncertainty-aware imitation learning policy, we can easily choose the safest one with the lowest uncertainty among the generated images. Experiments in the Carla navigation benchmark show that our strategy outperforms previous methods, especially in dynamic environments.",
        "primary_area": "",
        "author": "Lei Tai;Peng Yun;Yuying Chen;Congcong Liu;Haoyang Ye;Ming Liu;Lei Tai;Peng Yun;Yuying Chen;Congcong Liu;Haoyang Ye;Ming Liu",
        "authorids": "/37086024718;/37086640426;/37086602838;/37086126145;/37086022108;/37085398677;/37086024718;/37086640426;/37086602838;/37086126145;/37086022108;/37085398677",
        "aff": "The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968307/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9968507641416242743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967669",
        "title": "Voice-Controlled Flexible Exotendon (FLEXotendon) Glove For Hand Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a voice-controlled hand rehabilitation device driven by exotendons. A smartphone-based voice recognition system interprets user intention and is utilized for various grasping tasks. A bio-inspired tendon routing mechanism provides four-degrees-of-freedom (DoFs) across the thumb, index finger, and middle finger. A novel thumb sleeve design is presented for stable thumb movement. The exoskeleton is fabricated from polyurethane rubber and rigid 3D-printed parts to provide form-fitting properties while constraining tendon motion. Twisted string actuators and spring units provide active flexion and passive extension, respectively. The compact nature of the actuation unit allows for placement on the forearm, improving the portability of the system. The voice control system allows for easy user manipulation and accessibility and may improve rehabilitation efficiency. The performance of the tendon routing and thumb sleeve design were experimentally evaluated and voice control system was evaluated with various grasping tests.",
        "primary_area": "",
        "author": "Phillip Tran;Seokhwan Jeong;Jaydev P. Desai;Phillip Tran;Seokhwan Jeong;Jaydev P. Desai",
        "authorids": "/37086830310;/37087324027;/37282117700;/37086830310;/37087324027;/37282117700",
        "aff": "Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967669/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9088263331425539190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Medical Robotics and Automation (RoboMed) Laboratory",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967728",
        "title": "Volumetric Tree*: Adaptive Sparse Graph for Effective Exploration of Homotopy Classes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present volumetric tree*, a hybridization of sampling-based and optimization-based motion planning. Volumetric tree* constructs an adaptive sparse graph with volumetric vertices, hyper-spheres encoding free configurations, using a sampling-based motion planner for a homotopy exploration. The coarse-grained paths computed on the sparse graph are refined by optimization-based planning during the execution, while exploiting the probabilistic completeness of the sampling- based planning for the initial path generation. We also suggest a dropout technique probabilistically ensuring that the sampling- based planner is capable of identifying all possible homotopies of solution paths. We compare the proposed algorithm against the state-of-the-art planners in both synthetic and practical benchmarks with varying dimensions, and experimentally show the benefit of the proposed algorithm.",
        "primary_area": "",
        "author": "Donghyuk Kim;Mincheul Kang;Sung-Eui Yoon;Donghyuk Kim;Mincheul Kang;Sung-Eui Yoon",
        "authorids": "/37085771730;/37086439291;/37066068100;/37085771730;/37086439291;/37066068100",
        "aff": "School of Computing; School of Computing; Faculty of School of Computing, Institute of Science and Technology (KAIST) at Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967728/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10495489618277815127&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "School of Computing;Institute of Science and Technology (KAIST)",
        "aff_unique_dep": "Computing;School of Computing",
        "aff_unique_url": ";https://www.kaist.ac.kr",
        "aff_unique_abbr": ";KAIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Daejeon",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";South Korea"
    },
    {
        "id": "8967935",
        "title": "WLR-II, a Hose-less Hydraulic Wheel-legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The performance of traditional hydraulic robots is often limited by their hoses across moving joints or connecting hydraulic drive units, which would reduce their mobility and impede their ability to operate in complex environment. In response to this deficiency, this paper introduces the WLR-II (the second generation of wheel-legged robot), a novel hydraulic wheel-legged robot developed by using hose-less design approach which is focused on improving the reliability of the hydraulic system and perfecting the appearance of the robot. As its notable features, seven Hydraulic Hose-less Joints (HHJ) that include a pair of high and also low pressure oil pipes based on rotary seal, Cylinder-Valve-Skeleton (CVS) integration thighs and arms which are produced by subtractive manufacturing as well as oscillating cylinders driven by gear rack transmission are included. In addition to a description of its design, experimental characterizations of rough pavement adaptability and payload capability together with the achievement of the reliability of hydraulic system are also demonstrated. As a result, we confirmed effectiveness of the hose-less design by moving on the rugged ground, climbing slope, squatting with load, dragging and picking up a heavy load. To the authors' best knowledge, this is the first time that the design of a hose-less hydraulic wheel-legged robot has been presented.",
        "primary_area": "",
        "author": "Xu Li;Haitao Zhou;Songyuan Zhang;Haibo Feng;Yili Fu;Xu Li;Haitao Zhou;Songyuan Zhang;Haibo Feng;Yili Fu",
        "authorids": "/37086152356;/37086149626;/38468925500;/37085664239;/37286601800;/37086152356;/37086149626;/38468925500;/37085664239;/37286601800",
        "aff": "Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang Province, China; Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang Province, China; Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang Province, China; Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang Province, China; Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang Province, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967935/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11006874391125897218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8967817",
        "title": "Wall-Mounted Robot Arm Equipped with 3-DOF Roll-Pitch-Pitch Counterbalance Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of high-capacity motors and harmonic drives increases the manufacturing cost and the energy consumption of the robot. It is well known that most motor torques are used to support the robot mass and payload. To deal with this problem, we propose a wall-mounted 3-DOF roll-pitch-pitch counterbalance mechanism (CBM). Unlike previous CBMs used for floor-mounted industrial robot arms, the proposed CBM can be applied to wall-mounted robots in which the first three joints are all coupled and affected by gravity. This mechanism is composed of pure mechanical components such as coil springs, differential gear structure, and belt-pulley system. A 6-DOF robot arm equipped with the proposed CBM was fabricated to verify the performance of gravity compensation. It is shown that the proposed 3-DOF CBM can effectively compensate for gravitational torques, thus drastically reducing the motor torques required to operate the robot.",
        "primary_area": "",
        "author": "Won-Bum Lee;Byung-Yoon Moon;Tae-Jung Kim;Jae-Bok Song;Won-Bum Lee;Byung-Yoon Moon;Tae-Jung Kim;Jae-Bok Song",
        "authorids": "/37086055736;/37087323189;/37086550177;/37277430400;/37086055736;/37087323189;/37086550177;/37277430400",
        "aff": "School of Mechanical Eng, Korea University, Seoul, Korea; LG Electronics PRI, Gyeonggi-do, Korea; School of Mechanical Eng, Korea University, Seoul, Korea; Jae-Bok Song a Professor of the School of Mechanical Eng., Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967817/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5899515258000460912&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Korea University;LG",
        "aff_unique_dep": "School of Mechanical Engineering;LG Electronics PRI",
        "aff_unique_url": "http://www.korea.ac.kr;",
        "aff_unique_abbr": "KU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8968615",
        "title": "Wearable activity recognition for robust human-robot teaming in safety-critical environments via hybrid neural networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a novel non-visual HAR system that achieves state-of-the-art performance on realistic SCE tasks via a single wearable sensor. We leverage surface electromyography and inertial data from a low-profile wearable sensor to attain performant robot perception while remaining unobtrusive and user-friendly. By capturing both convolutional and temporal features with a hybrid CNN-LSTM classifier, our system is able to robustly and effectively classify complex, full-body human activities with only this single sensor. We perform a rigorous analysis of our method on two datasets representative of SCE tasks, and compare performance with several prominent HAR algorithms. Results show our system substantially outperforms rival algorithms in identifying complex human tasks from minimal sensing hardware, achieving F1-scores up to 84% over 31 strenuous activity classes. To our knowledge, we are the first to robustly identify complex full-body tasks using a single, unobtrusive sensor feasible for real-world use in SCEs. Using our approach, robots will be able to more reliably understand human activity, enabling them to safely navigate sensitive, crowded spaces.",
        "primary_area": "",
        "author": "Andrea E. Frank;Alyssa Kubota;Laurel D. Riek;Andrea E. Frank;Alyssa Kubota;Laurel D. Riek",
        "authorids": "/37087324283;/37086937860;/38548291500;/37087324283;/37086937860;/38548291500",
        "aff": "Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968615/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15723408930762781450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967555",
        "title": "Whole-Body Control of Humanoid Robot in 3D Multi-Contact under Contact Wrench Constraints Including Joint Load Reduction with Self-Collision and Internal Wrench Distribution",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an approach for online whole-body control of position-controlled humanoid robot with 3D multi-contact to cope with contact wrench constraints and joint overload. In our method, robots are controlled under contact wrench constraints with three features: 1) internal wrench control to reduce joint load and prolong the time in which the high-load postures can be maintained 2) feasible utilization of self-collision to reduce joint load by turning off joint servo gains 3) handling degenerated degree of freedom by solving a quadratic optimization problem integrating wrench distribution and inverse kinematics in which internal wrench is controlled only in controllable directions.With our methods, HRP2-JSKNTS could pick up an object under a desk with squatting with the back of the upper leg on the back of the lower leg without sliding at the right arm. We also evaluated the effectiveness of our control to reduce joint load with another experiment.",
        "primary_area": "",
        "author": "Naoki Hiraoka;Masaki Murooka;Hideaki Ito;Iori Yanokura;Kei Okada;Masayuki Inaba;Naoki Hiraoka;Masaki Murooka;Hideaki Ito;Iori Yanokura;Kei Okada;Masayuki Inaba",
        "authorids": "/37087325306;/37085365946;/37087324463;/37086105883;/37280639000;/37286658200;/37087325306;/37085365946;/37087324463;/37086105883;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967555/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11214529002098233757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8967631",
        "title": "Whole-Body Motion Planning for Walking Excavators",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a trajectory planning framework for all-terrain vehicles with legs and wheels such as walking excavators. Our formulation takes into account the whole body of the robot while computing the plans for locomotion. Hence, we can produce motion plans over the rough terrain that would be hard to plan without considering all Degrees of Freedom (DoF) simultaneously. Our planner can also optimize over the contact schedule for all limbs, thereby finding the feasible motions even for the infeasible initial contact schedule. Furthermore, we introduce a novel formulation of the support area constraint. We generate plans for a Menzi Muck M545, a 31 DoF walking excavator with five limbs: four wheeled legs and an arm. We show motion plans for traversing a variety of terrains that require whole-body planning. To the best of our knowledge, this is the first work that addresses motion planning in rough terrain for vehicles with legs and wheels.",
        "primary_area": "",
        "author": "Edo Jelavic;Marco Hutter;Edo Jelavic;Marco Hutter",
        "authorids": "/37086273999;/37545251000;/37086273999;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967631/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2051214604687691761&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "8967527",
        "title": "Whole-Body Motion and Landing Force Control for Quadrupedal Stair Climbing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel framework for quadrupedal stair climbing, which considers force interaction with stairs. For stable and robust climbing, a key issue is to avoid falling down on the stairs. From this point of view, control to minimize rate of change of angular momentum about Center of Mass (CoM) which is produced by ground reaction force (GRF) at contact of robot`s foot is necessary. Using this approach, direct force-based Zero Moment Point (ZMP) for motion planning of the CoM and landing force control are implemented. The direct force-based ZMP method allows the robot to lift its foot with reduced possibility of tilting on the stairs, and the landing force control prevents instant increase of the moment by impact of the GRFs. In addition, terrain recognition to estimate parameters of the stairs and find proper footholds by vision system mounted on the robot is presented. Proposed framework is implemented to quadruped robot, AiDIN-VI, that has torque sensor at each joint, through experiments, capability of ascending several stairs including 3-step stairs which have 21cm height (31% of its maximum leg length) and 26.5\u00b0 inclination is validated.",
        "primary_area": "",
        "author": "Young Hun Lee;Yoon Haeng Lee;Hyunyong Lee;Hansol Kang;Yong Bum Kim;Jun Hyuk Lee;Luong Tin Phan;Sungmoon Jin;Hyungpil Moon;Ja Choon Koo;Hyouk Ryeol Choi;Young Hun Lee;Yoon Haeng Lee;Hyunyong Lee;Hansol Kang;Yong Bum Kim;Jun Hyuk Lee;Luong Tin Phan;Sungmoon Jin;Hyungpil Moon;Ja Choon Koo;Hyouk Ryeol Choi",
        "authorids": "/37085653259;/37085653145;/37085419399;/37086119412;/37085413953;/37280309300;/37085644384;/38254722000;/37274074800;/37288048300;/37290854100;/37085653259;/37085653145;/37085419399;/37086119412;/37085413953;/37280309300;/37085644384;/38254722000;/37274074800;/37288048300;/37290854100",
        "aff": "Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea; Mechanical Engineering, Sungkyunkwan University, Suwon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967527/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7624952361011673862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Sungkyunkwan University",
        "aff_unique_dep": "Mechanical Engineering",
        "aff_unique_url": "http://www.sungkyunkwan.ac.kr",
        "aff_unique_abbr": "SKKU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "8967934",
        "title": "Wide Aperture Imaging Sonar Reconstruction using Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a new framework for reconstructing underwater surfaces from wide aperture imaging sonar sequences. We demonstrate that when the leading object edge in each sonar image can be accurately triangulated in 3D, the remaining surface may be \u201cfilled in\u201d using a generative sensor model. This process generates a full three-dimensional point cloud for each image in the sequence. We propose integrating these surface measurements into a cohesive global map using a truncated signed distance field (TSDF) to fuse the point clouds generated by each image. This allows for reconstructing surfaces with significantly fewer sonar images and viewpoints than previous methods. The proposed method is evaluated by reconstructing a mock-up piling structure and a real world underwater piling, in a test tank environment and in the field, respectively. Our surface reconstructions are quantitatively compared to ground-truth models and are shown to be more accurate than previous state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Eric Westman;Michael Kaess;Eric Westman;Michael Kaess",
        "authorids": "/37085993534;/37324200400;/37085993534;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967934/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18229890850657418192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968438",
        "title": "With Proximity Servoing towards Safe Human-Robot-Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a serial kinematic robot manipulator equipped with multimodal proximity sensing modules not only on the TCP but distributed on the robot's surface. The combination of close distance proximity information from capacitive and time-of-flight (ToF) measurements allows the robot to perform safe reflex-like and collision-free motions in a changing environment, e.g. where humans and robots share the same workspace. Our methods rely on proximity data and combine different strategies to calculate orthogonal avoidance motions. These motions are instantaneous optimal and are fed directly into the motion controller (proximity servoing). The strategies are prioritized, firstly to avoid collision and then secondly to maintain the task motion if kinematic redundancy is available. The motion is then optimized for avoidance, best manipulability, and smallest end-effector velocity deviation. We compare our methods with common force field based methods.",
        "primary_area": "",
        "author": "Yitao Ding;Felix Wilhelm;Leonhard Faulhammer;Ulrike Thomas;Yitao Ding;Felix Wilhelm;Leonhard Faulhammer;Ulrike Thomas",
        "authorids": "/37086576023;/37087324274;/37087323020;/37281523200;/37086576023;/37087324274;/37087323020;/37281523200",
        "aff": "Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968438/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3868055592074065792&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Lab of Robotics and Human-Machine-Interaction",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "8967639",
        "title": "Word2vec to behavior: morphology facilitates the grounding of language in machines",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling machines to respond appropriately to natural language commands could greatly expand the number of people to whom they could be of service. Recently, advances in neural network-trained word embeddings have empowered non-embodied text-processing algorithms, and suggest they could be of similar utility for embodied machines. Here we introduce a method that does so by training robots to act similarly to semantically-similar word 2vec encoded commands. We show that this enables them to act appropriately, after training, to previously-unheard commands. Finally, we show that inducing such an alignment between motoric and linguistic similarities can be facilitated or hindered by the mechanical structure of the robot. This points to future, large scale methods that find and exploit relationships between action, language, and robot structure.",
        "primary_area": "",
        "author": "David Matthews;Sam Kriegman;Collin Cappelle;Josh Bongard;David Matthews;Sam Kriegman;Collin Cappelle;Josh Bongard",
        "authorids": "/37087322915;/37087321880;/37087324589;/37278579000;/37087322915;/37087321880;/37087324589;/37278579000",
        "aff": "University of Vermont; University of Vermont; University of Vermont; University of Vermont",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967639/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=266327236123952079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Vermont",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uvm.edu",
        "aff_unique_abbr": "UVM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8967766",
        "title": "YouWasps: Towards Autonomous Multi-Robot Mobile Deposition for Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile multi-robot construction systems offer new ways to optimise the on-site construction process. In this paper we begin to investigate the functionality requirements for controlling a team of robots to build structures much greater than their individual workspace. To achieve these aims, we present a mobile extruder robot called YouWasp. We also begin to explore methods for collision aware printing and construction task decomposition and allocation. These are deployed via YouWasp and enable it to deposit material autonomously. In doing so, we are able to evaluate the potential for parallelization of tasks and printing autonomy in simulation as well as physical team of robots. Altogether, these results provide a foundation for future work that enable fleets of mobile construction systems to cooperate and help us shape our built environment in new ways.",
        "primary_area": "",
        "author": "Julius Sustarevas;K. X. Benjamin Tan;David Gerber;Robert Stuart-Smith;Vijay M. Pawar;Julius Sustarevas;K. X. Benjamin Tan;David Gerber;Robert Stuart-Smith;Vijay M. Pawar",
        "authorids": "/37086578524;/37087325355;/37087322432;/37086575032;/38191148100;/37086578524;/37087325355;/37087322432;/37086575032;/38191148100",
        "aff": "Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK; Autonomous Manufacturing Laboratory, University College London, Gower Street, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967766/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11461879383087033584&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Autonomous Manufacturing Laboratory",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Gower Street",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "8967738",
        "title": "n-MeRCI: A new Metric to Evaluate the Correlation Between Predictive Uncertainty and True Error",
        "track": "main",
        "status": "Poster",
        "abstract": "As deep learning applications are becoming more and more pervasive in robotics, the question of evaluating the reliability of inferences becomes a central question in the robotics community. This domain, known as predictive uncertainty, has come under the scrutiny of research groups developing Bayesian approaches adapted to deep learning such as Monte Carlo Dropout. Unfortunately, for the time being, the real goal of predictive uncertainty has been swept under the rug. Indeed, these approaches are solely evaluated in terms of raw performance of the network prediction, while the quality of their estimated uncertainty is not assessed. Evaluating such uncertainty prediction quality is especially important in robotics, as actions shall depend on the confidence in perceived information. In this context, the main contribution of this article is to propose a novel metric that is adapted to the evaluation of relative uncertainty assessment and directly applicable to regression with deep neural networks. To experimentally validate this metric, we evaluate it on a toy dataset and then apply it to the task of monocular depth estimation.",
        "primary_area": "",
        "author": "Michel Moukari;Lo\u00efc Simon;Sylvaine Picard;Fr\u00e9d\u00e9ric Jurie;Michel Moukari;Lo\u00efc Simon;Sylvaine Picard;Fr\u00e9d\u00e9ric Jurie",
        "authorids": "/37086525809;/37393831100;/37085772546;/37267287700;/37086525809;/37393831100;/37085772546;/37267287700",
        "aff": "Unicaen, Ensicaen, Cnrs 6 boulevard du Mar\u00e9chal Juin, Normandie Univ, Caen, France; Unicaen, Ensicaen, Cnrs 6 boulevard du Mar\u00e9chal Juin, Normandie Univ, Caen, France; Safran, 1 rue Genevi\u00e8ve Aube, Magny-les-Hameaux, France; Unicaen, Ensicaen, Cnrs 6 boulevard du Mar\u00e9chal Juin, Normandie Univ, Caen, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967738/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2875337726317953354&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Safran",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.safran-group.com",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";France"
    },
    {
        "id": "8967560",
        "title": "optimization Model for Planning Precision Grasps with Multi-Fingered Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "Precision grasps with multi-fingered hands are important for precise placement and in-hand manipulation tasks. Searching precision grasps on the object represented by point cloud, is challenging due to the complex object shape, high-dimensionality, collision and undesired properties of the sensing and positioning. This paper proposes an optimization model to search for precision grasps with multi-fingered hands. The model takes noisy point cloud of the object as input and optimizes the grasp quality by iteratively searching for the palm pose and finger joints positions. The collision between the hand and the object is approximated and penalized by a series of least-squares. The collision approximation is able to handle the point cloud representation of the objects with complex shapes. The proposed optimization model is able to locate collision-free optimal precision grasps efficiently. The average computation time is 0.50 sec/grasp. The searching is robust to the incompleteness and noise of the point cloud. The effectiveness of the algorithm is demonstrated by experiments.",
        "primary_area": "",
        "author": "Yongxiang Fan;Xinghao Zhu;Masayoshi Tomizuka;Yongxiang Fan;Xinghao Zhu;Masayoshi Tomizuka",
        "authorids": "/37085827034;/37087322158;/37281933000;/37085827034;/37087322158;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8967560/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1589309745143065106&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8968575",
        "title": "optimizing Motion-Planning Problem Setup via Bounded Evaluation with Application to Following Surgical Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "A motion-planning problem's setup can drastically affect the quality of solutions returned by the planner. In this work we consider optimizing these setups, with a focus on doing so in a computationally-efficient fashion. Our approach interleaves optimization with motion planning, which allows us to consider the actual motions required of the robot. Similar prior work has treated the planner as a black box: our key insight is that opening this box in a simple-yet-effective manner enables a more efficient approach, by allowing us to bound the work done by the planner to optimizer-relevant computations. Finally, we apply our approach to a surgically-relevant motion-planning task, where our experiments validate our approach by more-efficiently optimizing the fixed insertion pose of a surgical robot.",
        "primary_area": "",
        "author": "Sherdil Niyaz;Alan Kuntz;Oren Salzman;Ron Alterovitz;Siddhartha S. Srinivasa;Sherdil Niyaz;Alan Kuntz;Oren Salzman;Ron Alterovitz;Siddhartha S. Srinivasa",
        "authorids": "/37085898362;/37085508764;/37077497700;/37320259800;/37339877600;/37085898362;/37085508764;/37077497700;/37320259800;/37339877600",
        "aff": "School of Computer Science and Engineering, University of Washington; Department of Computer Science, University of North Carolina, Chapel Hill; The Robotics Institute, Carnegie Mellon University School of Computer Science; Department of Computer Science, University of North Carolina, Chapel Hill; School of Computer Science and Engineering, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/8968575/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17762280884002790593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University of Washington;University of North Carolina;Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science and Engineering;Department of Computer Science;The Robotics Institute",
        "aff_unique_url": "https://www.washington.edu;https://www.unc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UW;UNC;CMU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Seattle;Chapel Hill;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    }
]